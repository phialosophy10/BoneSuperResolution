/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.218366026878357, disc_loss = 0.7147836089134216
Trained batch 1 in epoch 0, gen_loss = 1.0941998362541199, disc_loss = 0.6469087898731232
Trained batch 2 in epoch 0, gen_loss = 0.9997397661209106, disc_loss = 0.5638499359289805
Trained batch 3 in epoch 0, gen_loss = 0.9599983990192413, disc_loss = 0.5123875141143799
Trained batch 4 in epoch 0, gen_loss = 0.9409142017364502, disc_loss = 0.4778965950012207
Trained batch 5 in epoch 0, gen_loss = 0.9291385610898336, disc_loss = 0.44401682416598004
Trained batch 6 in epoch 0, gen_loss = 0.9120784146445138, disc_loss = 0.4150461086205074
Trained batch 7 in epoch 0, gen_loss = 0.8804531693458557, disc_loss = 0.3893297016620636
Trained batch 8 in epoch 0, gen_loss = 0.8888500995106168, disc_loss = 0.36747782594627804
Trained batch 9 in epoch 0, gen_loss = 0.8834382474422455, disc_loss = 0.3490609019994736
Trained batch 10 in epoch 0, gen_loss = 0.8810309984467246, disc_loss = 0.33259641988710925
Trained batch 11 in epoch 0, gen_loss = 0.8813988616069158, disc_loss = 0.3161318066219489
Trained batch 12 in epoch 0, gen_loss = 0.8831734428038964, disc_loss = 0.3006777127201741
Trained batch 13 in epoch 0, gen_loss = 0.8790630911077771, disc_loss = 0.286429688334465
Trained batch 14 in epoch 0, gen_loss = 0.8769288420677185, disc_loss = 0.27404329081376394
Trained batch 15 in epoch 0, gen_loss = 0.8823455907404423, disc_loss = 0.2625976428389549
Trained batch 16 in epoch 0, gen_loss = 0.8870517856934491, disc_loss = 0.25271722060792584
Trained batch 17 in epoch 0, gen_loss = 0.8900835414727529, disc_loss = 0.24327746033668518
Trained batch 18 in epoch 0, gen_loss = 0.8874694548155132, disc_loss = 0.2348638349457791
Trained batch 19 in epoch 0, gen_loss = 0.8828234136104584, disc_loss = 0.22738888897001744
Trained batch 20 in epoch 0, gen_loss = 0.8799572615396409, disc_loss = 0.22389444460471472
Trained batch 21 in epoch 0, gen_loss = 0.879126017743891, disc_loss = 0.22021123868497935
Trained batch 22 in epoch 0, gen_loss = 0.881672397903774, disc_loss = 0.21645126880510993
Trained batch 23 in epoch 0, gen_loss = 0.8850967884063721, disc_loss = 0.21174921902517477
Trained batch 24 in epoch 0, gen_loss = 0.8844409847259521, disc_loss = 0.20909302055835724
Trained batch 25 in epoch 0, gen_loss = 0.8855500817298889, disc_loss = 0.2067156474177654
Trained batch 26 in epoch 0, gen_loss = 0.8897301002785012, disc_loss = 0.20283826302599023
Trained batch 27 in epoch 0, gen_loss = 0.8987133460385459, disc_loss = 0.20140271953174047
Trained batch 28 in epoch 0, gen_loss = 0.9076089036875757, disc_loss = 0.19796221189457794
Trained batch 29 in epoch 0, gen_loss = 0.9152847091356914, disc_loss = 0.19368266115585964
Trained batch 30 in epoch 0, gen_loss = 0.9234600913140082, disc_loss = 0.19025598129918497
Trained batch 31 in epoch 0, gen_loss = 0.9301214143633842, disc_loss = 0.18652760237455368
Trained batch 32 in epoch 0, gen_loss = 0.937915614157012, disc_loss = 0.18247061516299393
Trained batch 33 in epoch 0, gen_loss = 0.9454386374529671, disc_loss = 0.17851176419678857
Trained batch 34 in epoch 0, gen_loss = 0.9528935977390834, disc_loss = 0.17480635579143253
Trained batch 35 in epoch 0, gen_loss = 0.9590295685662164, disc_loss = 0.17138194541136423
Trained batch 36 in epoch 0, gen_loss = 0.9643896785942284, disc_loss = 0.16807459576709852
Trained batch 37 in epoch 0, gen_loss = 0.9715331541864496, disc_loss = 0.16481345323355576
Trained batch 38 in epoch 0, gen_loss = 0.9793689495477921, disc_loss = 0.16170302654306093
Trained batch 39 in epoch 0, gen_loss = 0.9864619970321655, disc_loss = 0.15882522566244006
Trained batch 40 in epoch 0, gen_loss = 0.9921352136425856, disc_loss = 0.15601927505397215
Trained batch 41 in epoch 0, gen_loss = 0.9969033088002887, disc_loss = 0.15345905304309868
Trained batch 42 in epoch 0, gen_loss = 1.001569345939991, disc_loss = 0.15111619416017866
Trained batch 43 in epoch 0, gen_loss = 1.0088023407892748, disc_loss = 0.148892970840362
Trained batch 44 in epoch 0, gen_loss = 1.0158495505650837, disc_loss = 0.1468383215367794
Trained batch 45 in epoch 0, gen_loss = 1.020024633925894, disc_loss = 0.14448746293783188
Trained batch 46 in epoch 0, gen_loss = 1.0234028151694765, disc_loss = 0.14231350050961716
Trained batch 47 in epoch 0, gen_loss = 1.0275910198688507, disc_loss = 0.14030466880649328
Trained batch 48 in epoch 0, gen_loss = 1.0322478304103928, disc_loss = 0.1383406236311611
Trained batch 49 in epoch 0, gen_loss = 1.0360715746879579, disc_loss = 0.13635278694331646
Trained batch 50 in epoch 0, gen_loss = 1.0405363756067612, disc_loss = 0.1344659970525433
Trained batch 51 in epoch 0, gen_loss = 1.044381552017652, disc_loss = 0.13291655051020476
Trained batch 52 in epoch 0, gen_loss = 1.048027180275827, disc_loss = 0.13157251828683997
Trained batch 53 in epoch 0, gen_loss = 1.0513865307525352, disc_loss = 0.1304422071962445
Trained batch 54 in epoch 0, gen_loss = 1.054188695820895, disc_loss = 0.12901485379446637
Trained batch 55 in epoch 0, gen_loss = 1.0577536757503236, disc_loss = 0.12741763244516083
Trained batch 56 in epoch 0, gen_loss = 1.0616398924275448, disc_loss = 0.12578567385412098
Trained batch 57 in epoch 0, gen_loss = 1.0638965203844268, disc_loss = 0.12416279039763171
Trained batch 58 in epoch 0, gen_loss = 1.0665407706115206, disc_loss = 0.12260413037265762
Trained batch 59 in epoch 0, gen_loss = 1.0692717512448628, disc_loss = 0.12109110324333111
Trained batch 60 in epoch 0, gen_loss = 1.0713794505009886, disc_loss = 0.11954534670612851
Trained batch 61 in epoch 0, gen_loss = 1.0740601055083736, disc_loss = 0.11821136317185817
Trained batch 62 in epoch 0, gen_loss = 1.0762450997791593, disc_loss = 0.11681063366787774
Trained batch 63 in epoch 0, gen_loss = 1.0780974756926298, disc_loss = 0.11544050529482774
Trained batch 64 in epoch 0, gen_loss = 1.0793046107658972, disc_loss = 0.11409653797745704
Trained batch 65 in epoch 0, gen_loss = 1.0806533351089016, disc_loss = 0.11282153382445827
Trained batch 66 in epoch 0, gen_loss = 1.0812490128759127, disc_loss = 0.11154927685856819
Trained batch 67 in epoch 0, gen_loss = 1.0826340493033915, disc_loss = 0.11030047277317327
Trained batch 68 in epoch 0, gen_loss = 1.0839694410130598, disc_loss = 0.10905449108585068
Trained batch 69 in epoch 0, gen_loss = 1.0853647129876274, disc_loss = 0.10787048603274993
Trained batch 70 in epoch 0, gen_loss = 1.0856738392735872, disc_loss = 0.10670268176202204
Trained batch 71 in epoch 0, gen_loss = 1.0879610611332788, disc_loss = 0.10562203912478355
Trained batch 72 in epoch 0, gen_loss = 1.0892665075929198, disc_loss = 0.10451940661423827
Trained batch 73 in epoch 0, gen_loss = 1.0918551892847628, disc_loss = 0.1035208834737942
Trained batch 74 in epoch 0, gen_loss = 1.0934971729914347, disc_loss = 0.10245100180308024
Trained batch 75 in epoch 0, gen_loss = 1.0950786204714524, disc_loss = 0.10141444066539407
Trained batch 76 in epoch 0, gen_loss = 1.0964397021702357, disc_loss = 0.10041010440266751
Trained batch 77 in epoch 0, gen_loss = 1.0974933764873407, disc_loss = 0.09941318311179295
Trained batch 78 in epoch 0, gen_loss = 1.0984806803208362, disc_loss = 0.09844182162911078
Trained batch 79 in epoch 0, gen_loss = 1.0999371960759163, disc_loss = 0.09748318260535598
Trained batch 80 in epoch 0, gen_loss = 1.1009844129468187, disc_loss = 0.0965633889729226
Trained batch 81 in epoch 0, gen_loss = 1.102080869965437, disc_loss = 0.09562709075739471
Trained batch 82 in epoch 0, gen_loss = 1.1035647406635514, disc_loss = 0.09473515016935675
Trained batch 83 in epoch 0, gen_loss = 1.1042017624491738, disc_loss = 0.09382397173682139
Trained batch 84 in epoch 0, gen_loss = 1.1049057834288654, disc_loss = 0.09299773378845523
Trained batch 85 in epoch 0, gen_loss = 1.1049225039260333, disc_loss = 0.0921372368628549
Trained batch 86 in epoch 0, gen_loss = 1.105237393543638, disc_loss = 0.09125026694402613
Trained batch 87 in epoch 0, gen_loss = 1.1063094247471204, disc_loss = 0.09044541619633409
Trained batch 88 in epoch 0, gen_loss = 1.1073757865455713, disc_loss = 0.0896623128543744
Trained batch 89 in epoch 0, gen_loss = 1.1085879551039801, disc_loss = 0.08889590421070655
Trained batch 90 in epoch 0, gen_loss = 1.109777182013124, disc_loss = 0.08814429637085605
Trained batch 91 in epoch 0, gen_loss = 1.1106568678565647, disc_loss = 0.08742475485348183
Trained batch 92 in epoch 0, gen_loss = 1.112039130221131, disc_loss = 0.08676821410015065
Trained batch 93 in epoch 0, gen_loss = 1.1121110383500443, disc_loss = 0.08620138307835193
Trained batch 94 in epoch 0, gen_loss = 1.1127441054896305, disc_loss = 0.08554478228876465
Trained batch 95 in epoch 0, gen_loss = 1.113105669617653, disc_loss = 0.0848523717916881
Trained batch 96 in epoch 0, gen_loss = 1.1156120017631768, disc_loss = 0.08428633683505132
Trained batch 97 in epoch 0, gen_loss = 1.1161103662179441, disc_loss = 0.08366948902150806
Trained batch 98 in epoch 0, gen_loss = 1.1160240703158908, disc_loss = 0.0830070889658398
Trained batch 99 in epoch 0, gen_loss = 1.1177321910858153, disc_loss = 0.08237887766212225
Trained batch 100 in epoch 0, gen_loss = 1.1182679032335188, disc_loss = 0.08172578737139702
Trained batch 101 in epoch 0, gen_loss = 1.1197808349833769, disc_loss = 0.08111484545995207
Trained batch 102 in epoch 0, gen_loss = 1.1211721063817588, disc_loss = 0.08054385518709432
Trained batch 103 in epoch 0, gen_loss = 1.121620116325525, disc_loss = 0.07998179176893945
Trained batch 104 in epoch 0, gen_loss = 1.1221347275234403, disc_loss = 0.07937756764392058
Trained batch 105 in epoch 0, gen_loss = 1.1229745340797137, disc_loss = 0.07877595487208862
Trained batch 106 in epoch 0, gen_loss = 1.1233014224845672, disc_loss = 0.07818390805030538
Trained batch 107 in epoch 0, gen_loss = 1.1244409084320068, disc_loss = 0.0776181739444534
Trained batch 108 in epoch 0, gen_loss = 1.1246195101956709, disc_loss = 0.0770835396278342
Trained batch 109 in epoch 0, gen_loss = 1.1256997433575717, disc_loss = 0.07654284833168441
Trained batch 110 in epoch 0, gen_loss = 1.1263085313745447, disc_loss = 0.07599974851551894
Trained batch 111 in epoch 0, gen_loss = 1.1271794076476778, disc_loss = 0.07546996087434568
Trained batch 112 in epoch 0, gen_loss = 1.1272728538091203, disc_loss = 0.07495088314851828
Trained batch 113 in epoch 0, gen_loss = 1.1275628188200164, disc_loss = 0.07441836332477499
Trained batch 114 in epoch 0, gen_loss = 1.127826744577159, disc_loss = 0.07389339961759422
Trained batch 115 in epoch 0, gen_loss = 1.1281334130928433, disc_loss = 0.07341219810768962
Trained batch 116 in epoch 0, gen_loss = 1.128597240162711, disc_loss = 0.07291612406380665
Trained batch 117 in epoch 0, gen_loss = 1.128976131899882, disc_loss = 0.0724149344930962
Trained batch 118 in epoch 0, gen_loss = 1.1294143229973417, disc_loss = 0.07193142861253073
Trained batch 119 in epoch 0, gen_loss = 1.1293679078420003, disc_loss = 0.0714326461777091
Trained batch 120 in epoch 0, gen_loss = 1.1294606401900615, disc_loss = 0.07093951242306262
Trained batch 121 in epoch 0, gen_loss = 1.1292720730187462, disc_loss = 0.07047184455193213
Trained batch 122 in epoch 0, gen_loss = 1.129471195422537, disc_loss = 0.07000980021174603
Trained batch 123 in epoch 0, gen_loss = 1.1306119715013812, disc_loss = 0.06955977222101102
Trained batch 124 in epoch 0, gen_loss = 1.1308998317718506, disc_loss = 0.06912071558088065
Trained batch 125 in epoch 0, gen_loss = 1.131530587635343, disc_loss = 0.06870471976608747
Trained batch 126 in epoch 0, gen_loss = 1.132088250062597, disc_loss = 0.06829365554786339
Trained batch 127 in epoch 0, gen_loss = 1.1324555799365044, disc_loss = 0.06786421147262445
Trained batch 128 in epoch 0, gen_loss = 1.1322035151858663, disc_loss = 0.06743342135563608
Trained batch 129 in epoch 0, gen_loss = 1.1324506053557764, disc_loss = 0.0670002153214927
Trained batch 130 in epoch 0, gen_loss = 1.1323122031816089, disc_loss = 0.06658235313868477
Trained batch 131 in epoch 0, gen_loss = 1.131836931813847, disc_loss = 0.06617015543055128
Trained batch 132 in epoch 0, gen_loss = 1.1313983892139636, disc_loss = 0.06576965433454379
Trained batch 133 in epoch 0, gen_loss = 1.131556930826671, disc_loss = 0.06537128798663616
Trained batch 134 in epoch 0, gen_loss = 1.131327826888473, disc_loss = 0.06496940790503114
Trained batch 135 in epoch 0, gen_loss = 1.1315391133813297, disc_loss = 0.0645872563644148
Trained batch 136 in epoch 0, gen_loss = 1.1309891390974505, disc_loss = 0.06421071360309194
Trained batch 137 in epoch 0, gen_loss = 1.130934476852417, disc_loss = 0.06383626801434203
Trained batch 138 in epoch 0, gen_loss = 1.1308635902061737, disc_loss = 0.06346424741389083
Trained batch 139 in epoch 0, gen_loss = 1.1306632731642041, disc_loss = 0.06309860395932836
Trained batch 140 in epoch 0, gen_loss = 1.1300909071103902, disc_loss = 0.062739327952847
Trained batch 141 in epoch 0, gen_loss = 1.1304969896732922, disc_loss = 0.06240876905069175
Trained batch 142 in epoch 0, gen_loss = 1.1312032687914122, disc_loss = 0.0621178228004308
Trained batch 143 in epoch 0, gen_loss = 1.1309374504619174, disc_loss = 0.06180573316265105
Trained batch 144 in epoch 0, gen_loss = 1.1315277395577266, disc_loss = 0.06148174364633601
Trained batch 145 in epoch 0, gen_loss = 1.1319989072133416, disc_loss = 0.06115274624388716
Trained batch 146 in epoch 0, gen_loss = 1.1318593276601259, disc_loss = 0.06080340839871744
Trained batch 147 in epoch 0, gen_loss = 1.1311791047856614, disc_loss = 0.06046968780306948
Trained batch 148 in epoch 0, gen_loss = 1.1312405135007513, disc_loss = 0.06013636642304443
Trained batch 149 in epoch 0, gen_loss = 1.1312326502799988, disc_loss = 0.059807820537437995
Trained batch 150 in epoch 0, gen_loss = 1.1316801696423664, disc_loss = 0.059494623303758785
Trained batch 151 in epoch 0, gen_loss = 1.1324763799968518, disc_loss = 0.0591891281073913
Trained batch 152 in epoch 0, gen_loss = 1.1324965042226456, disc_loss = 0.05888370930345035
Trained batch 153 in epoch 0, gen_loss = 1.1323673175526905, disc_loss = 0.05858966493495293
Trained batch 154 in epoch 0, gen_loss = 1.1326661117615238, disc_loss = 0.058292899256752385
Trained batch 155 in epoch 0, gen_loss = 1.1331953551524725, disc_loss = 0.058018671826292306
Trained batch 156 in epoch 0, gen_loss = 1.1338736304811612, disc_loss = 0.05777964649638932
Trained batch 157 in epoch 0, gen_loss = 1.1347135546841198, disc_loss = 0.057564237933087195
Trained batch 158 in epoch 0, gen_loss = 1.134737824493984, disc_loss = 0.057357832016247626
Trained batch 159 in epoch 0, gen_loss = 1.1344745732843875, disc_loss = 0.057121599558740854
Trained batch 160 in epoch 0, gen_loss = 1.1343022992151865, disc_loss = 0.05684099742066786
Trained batch 161 in epoch 0, gen_loss = 1.133992635173562, disc_loss = 0.05654917986212689
Trained batch 162 in epoch 0, gen_loss = 1.1340496817980807, disc_loss = 0.056279663773584954
Trained batch 163 in epoch 0, gen_loss = 1.1348396641452139, disc_loss = 0.05601094785805156
Trained batch 164 in epoch 0, gen_loss = 1.1348535790587917, disc_loss = 0.055740744039190535
Trained batch 165 in epoch 0, gen_loss = 1.1350344857537602, disc_loss = 0.05548424868990319
Trained batch 166 in epoch 0, gen_loss = 1.1353282471616826, disc_loss = 0.05522486213371604
Trained batch 167 in epoch 0, gen_loss = 1.1353608674946285, disc_loss = 0.054949949689519904
Trained batch 168 in epoch 0, gen_loss = 1.1352196550933566, disc_loss = 0.054675215017601586
Trained batch 169 in epoch 0, gen_loss = 1.1357926235479467, disc_loss = 0.05443201380617478
Trained batch 170 in epoch 0, gen_loss = 1.1363609631856282, disc_loss = 0.05418131254308405
Trained batch 171 in epoch 0, gen_loss = 1.1363200101741524, disc_loss = 0.05392129276337665
Trained batch 172 in epoch 0, gen_loss = 1.136544213129606, disc_loss = 0.05366238756805142
Trained batch 173 in epoch 0, gen_loss = 1.1360331328435875, disc_loss = 0.053409259439842115
Trained batch 174 in epoch 0, gen_loss = 1.1359033387047903, disc_loss = 0.05316126462072134
Trained batch 175 in epoch 0, gen_loss = 1.1364400644193997, disc_loss = 0.052920071297028866
Trained batch 176 in epoch 0, gen_loss = 1.1368595294359713, disc_loss = 0.05267310169351808
Trained batch 177 in epoch 0, gen_loss = 1.136667909916867, disc_loss = 0.052423349633980335
Trained batch 178 in epoch 0, gen_loss = 1.1365985970257382, disc_loss = 0.052173249415699494
Trained batch 179 in epoch 0, gen_loss = 1.1362815148300596, disc_loss = 0.05193027753848582
Trained batch 180 in epoch 0, gen_loss = 1.13661707896554, disc_loss = 0.051700420484708326
Trained batch 181 in epoch 0, gen_loss = 1.1365471626376058, disc_loss = 0.05145455303264188
Trained batch 182 in epoch 0, gen_loss = 1.136707345644633, disc_loss = 0.05121589321744898
Trained batch 183 in epoch 0, gen_loss = 1.1367469073637673, disc_loss = 0.05097928672077377
Trained batch 184 in epoch 0, gen_loss = 1.13627259344668, disc_loss = 0.05075139422976487
Trained batch 185 in epoch 0, gen_loss = 1.1365421670739368, disc_loss = 0.05052161667876506
Trained batch 186 in epoch 0, gen_loss = 1.1366126658444735, disc_loss = 0.05029939594653679
Trained batch 187 in epoch 0, gen_loss = 1.1369831555701317, disc_loss = 0.050082345037384235
Trained batch 188 in epoch 0, gen_loss = 1.1372582401548113, disc_loss = 0.04986354005991151
Trained batch 189 in epoch 0, gen_loss = 1.1376164204195927, disc_loss = 0.04965007186524178
Trained batch 190 in epoch 0, gen_loss = 1.1376237176475725, disc_loss = 0.049438108694959064
Trained batch 191 in epoch 0, gen_loss = 1.138110348333915, disc_loss = 0.04923224288601583
Trained batch 192 in epoch 0, gen_loss = 1.1378418540707524, disc_loss = 0.04903305552108454
Trained batch 193 in epoch 0, gen_loss = 1.1381630092552029, disc_loss = 0.048832182844467074
Trained batch 194 in epoch 0, gen_loss = 1.138211524180877, disc_loss = 0.04863138071332986
Trained batch 195 in epoch 0, gen_loss = 1.1380815165383475, disc_loss = 0.048431873307278266
Trained batch 196 in epoch 0, gen_loss = 1.1374966208704838, disc_loss = 0.0482446300622246
Trained batch 197 in epoch 0, gen_loss = 1.1371031150673374, disc_loss = 0.04804511418133372
Trained batch 198 in epoch 0, gen_loss = 1.1371066468444901, disc_loss = 0.04784521998266628
Trained batch 199 in epoch 0, gen_loss = 1.1372898620367051, disc_loss = 0.04764943689573556
Trained batch 200 in epoch 0, gen_loss = 1.137105749021122, disc_loss = 0.047447056866329704
Trained batch 201 in epoch 0, gen_loss = 1.136900776093549, disc_loss = 0.04724458342252096
Trained batch 202 in epoch 0, gen_loss = 1.1369505004929792, disc_loss = 0.047040789273425275
Trained batch 203 in epoch 0, gen_loss = 1.1367837710707795, disc_loss = 0.046845078664630946
Trained batch 204 in epoch 0, gen_loss = 1.1367919916059912, disc_loss = 0.04665021431609625
Trained batch 205 in epoch 0, gen_loss = 1.1363776777554484, disc_loss = 0.04645627222783429
Trained batch 206 in epoch 0, gen_loss = 1.1360001016930106, disc_loss = 0.04626274855069564
Trained batch 207 in epoch 0, gen_loss = 1.1362312132349381, disc_loss = 0.04607127639330709
Trained batch 208 in epoch 0, gen_loss = 1.1368937321256793, disc_loss = 0.04590270995567931
Trained batch 209 in epoch 0, gen_loss = 1.1369446192468915, disc_loss = 0.04572469165238242
Trained batch 210 in epoch 0, gen_loss = 1.1367534760615272, disc_loss = 0.0455578882975495
Trained batch 211 in epoch 0, gen_loss = 1.1369874156870932, disc_loss = 0.045386568961647465
Trained batch 212 in epoch 0, gen_loss = 1.1370438684320225, disc_loss = 0.04521042458109663
Trained batch 213 in epoch 0, gen_loss = 1.1366280144620164, disc_loss = 0.0450271145967227
Trained batch 214 in epoch 0, gen_loss = 1.1367838720942653, disc_loss = 0.04485725668843749
Trained batch 215 in epoch 0, gen_loss = 1.1367712390643578, disc_loss = 0.04468139481765253
Trained batch 216 in epoch 0, gen_loss = 1.1367840091204313, disc_loss = 0.04450279475545966
Trained batch 217 in epoch 0, gen_loss = 1.1365568052738084, disc_loss = 0.04432186995069026
Trained batch 218 in epoch 0, gen_loss = 1.136389074804576, disc_loss = 0.04414339127980139
Trained batch 219 in epoch 0, gen_loss = 1.1357668253508482, disc_loss = 0.043971423042768784
Trained batch 220 in epoch 0, gen_loss = 1.1354771518059985, disc_loss = 0.043805958669447254
Trained batch 221 in epoch 0, gen_loss = 1.1353300868927896, disc_loss = 0.04364218776793899
Trained batch 222 in epoch 0, gen_loss = 1.1353718614364419, disc_loss = 0.04347901296438524
Trained batch 223 in epoch 0, gen_loss = 1.135349219398839, disc_loss = 0.043318834149561426
Trained batch 224 in epoch 0, gen_loss = 1.135712463061015, disc_loss = 0.04316531050743328
Trained batch 225 in epoch 0, gen_loss = 1.1353358441749506, disc_loss = 0.043013314718578374
Trained batch 226 in epoch 0, gen_loss = 1.1350520187537576, disc_loss = 0.042862783651798964
Trained batch 227 in epoch 0, gen_loss = 1.1349380554860098, disc_loss = 0.04270706562684816
Trained batch 228 in epoch 0, gen_loss = 1.1352698245943893, disc_loss = 0.042556543956514786
Trained batch 229 in epoch 0, gen_loss = 1.134557316614234, disc_loss = 0.04239512938884613
Trained batch 230 in epoch 0, gen_loss = 1.1341539296236904, disc_loss = 0.042241861438983445
Trained batch 231 in epoch 0, gen_loss = 1.134089725798574, disc_loss = 0.04208442427073445
Trained batch 232 in epoch 0, gen_loss = 1.1340763814459542, disc_loss = 0.041925210096021966
Trained batch 233 in epoch 0, gen_loss = 1.1338730393311915, disc_loss = 0.0417694172833879
Trained batch 234 in epoch 0, gen_loss = 1.1335707771017196, disc_loss = 0.04161465105184532
Trained batch 235 in epoch 0, gen_loss = 1.1336314117504378, disc_loss = 0.041463892541873125
Trained batch 236 in epoch 0, gen_loss = 1.133448691307744, disc_loss = 0.04132349401091536
Trained batch 237 in epoch 0, gen_loss = 1.133568484242223, disc_loss = 0.041200379796028766
Trained batch 238 in epoch 0, gen_loss = 1.1333887083261083, disc_loss = 0.04107732791258763
Trained batch 239 in epoch 0, gen_loss = 1.1334527472654978, disc_loss = 0.040948592850084724
Trained batch 240 in epoch 0, gen_loss = 1.1332237858989922, disc_loss = 0.04080531065819855
Trained batch 241 in epoch 0, gen_loss = 1.1336355524614823, disc_loss = 0.04066836812017747
Trained batch 242 in epoch 0, gen_loss = 1.1337623125241127, disc_loss = 0.040525404102103826
Trained batch 243 in epoch 0, gen_loss = 1.1336580837359194, disc_loss = 0.04038403347348336
Trained batch 244 in epoch 0, gen_loss = 1.1339532784053257, disc_loss = 0.04025205807114134
Trained batch 245 in epoch 0, gen_loss = 1.133893954075449, disc_loss = 0.04012041766484215
Trained batch 246 in epoch 0, gen_loss = 1.1337712187516062, disc_loss = 0.03999150874326948
Trained batch 247 in epoch 0, gen_loss = 1.133800430643943, disc_loss = 0.03985832072418904
Trained batch 248 in epoch 0, gen_loss = 1.133714999539785, disc_loss = 0.039725461855051984
Trained batch 249 in epoch 0, gen_loss = 1.1335345993041992, disc_loss = 0.039593871695920824
Trained batch 250 in epoch 0, gen_loss = 1.1337542172922082, disc_loss = 0.03946613119098829
Trained batch 251 in epoch 0, gen_loss = 1.134018503011219, disc_loss = 0.039337947401070286
Trained batch 252 in epoch 0, gen_loss = 1.133662045708758, disc_loss = 0.03921066890673145
Trained batch 253 in epoch 0, gen_loss = 1.1334041338267289, disc_loss = 0.039079892515080185
Trained batch 254 in epoch 0, gen_loss = 1.132972115161372, disc_loss = 0.038956422234574954
Trained batch 255 in epoch 0, gen_loss = 1.1327204452827573, disc_loss = 0.03882566681932076
Trained batch 256 in epoch 0, gen_loss = 1.1328174316465622, disc_loss = 0.038696574059891214
Trained batch 257 in epoch 0, gen_loss = 1.1328190565109253, disc_loss = 0.038565569629445094
Trained batch 258 in epoch 0, gen_loss = 1.1328306718222423, disc_loss = 0.03844778249435788
Trained batch 259 in epoch 0, gen_loss = 1.1328534236321082, disc_loss = 0.03833928439193047
Trained batch 260 in epoch 0, gen_loss = 1.1328998224031879, disc_loss = 0.038232509046792984
Trained batch 261 in epoch 0, gen_loss = 1.1328819981058136, disc_loss = 0.038112314364638265
Trained batch 262 in epoch 0, gen_loss = 1.132900181831969, disc_loss = 0.03799261887533017
Trained batch 263 in epoch 0, gen_loss = 1.1326173340732402, disc_loss = 0.037883538495269466
Trained batch 264 in epoch 0, gen_loss = 1.1322721364363184, disc_loss = 0.0377795921498031
Trained batch 265 in epoch 0, gen_loss = 1.1323995720174975, disc_loss = 0.03766637737337584
Trained batch 266 in epoch 0, gen_loss = 1.1322036151135906, disc_loss = 0.03754648040415028
Trained batch 267 in epoch 0, gen_loss = 1.1320823284227457, disc_loss = 0.03742849806135993
Trained batch 268 in epoch 0, gen_loss = 1.1321635055719255, disc_loss = 0.037311494826481134
Trained batch 269 in epoch 0, gen_loss = 1.1316616630112684, disc_loss = 0.037191187512750426
Trained batch 270 in epoch 0, gen_loss = 1.1314629393310125, disc_loss = 0.037079522398221425
Trained batch 271 in epoch 0, gen_loss = 1.1310644537648733, disc_loss = 0.036968655642875305
Trained batch 272 in epoch 0, gen_loss = 1.131073114417848, disc_loss = 0.03685429580202633
Trained batch 273 in epoch 0, gen_loss = 1.1310446486420875, disc_loss = 0.036735960787134994
Trained batch 274 in epoch 0, gen_loss = 1.131294524236159, disc_loss = 0.03662136368284171
Trained batch 275 in epoch 0, gen_loss = 1.1310561677252038, disc_loss = 0.03650377297173322
Trained batch 276 in epoch 0, gen_loss = 1.1308983385778075, disc_loss = 0.03638792345602913
Trained batch 277 in epoch 0, gen_loss = 1.1307001386186202, disc_loss = 0.03627220036549052
Trained batch 278 in epoch 0, gen_loss = 1.1307758543653728, disc_loss = 0.03615814650691645
Trained batch 279 in epoch 0, gen_loss = 1.1302514912826673, disc_loss = 0.03604483038320073
Trained batch 280 in epoch 0, gen_loss = 1.1302227704550447, disc_loss = 0.03593324602405902
Trained batch 281 in epoch 0, gen_loss = 1.1302957156448499, disc_loss = 0.03582509358063446
Trained batch 282 in epoch 0, gen_loss = 1.1298033685650506, disc_loss = 0.03571280682387074
Trained batch 283 in epoch 0, gen_loss = 1.1294317186718257, disc_loss = 0.03560135195123583
Trained batch 284 in epoch 0, gen_loss = 1.1298000444445693, disc_loss = 0.03549727071893581
Trained batch 285 in epoch 0, gen_loss = 1.1294486264248829, disc_loss = 0.03539547142312191
Trained batch 286 in epoch 0, gen_loss = 1.1298045090266637, disc_loss = 0.0353038087146493
Trained batch 287 in epoch 0, gen_loss = 1.1303420662879944, disc_loss = 0.035210465176431976
Trained batch 288 in epoch 0, gen_loss = 1.1304923316599176, disc_loss = 0.03511030695346348
Trained batch 289 in epoch 0, gen_loss = 1.130639542382339, disc_loss = 0.03501032921003884
Trained batch 290 in epoch 0, gen_loss = 1.1306676762210544, disc_loss = 0.0349070661032374
Trained batch 291 in epoch 0, gen_loss = 1.1305120726154274, disc_loss = 0.03480427316389978
Trained batch 292 in epoch 0, gen_loss = 1.1303646881832605, disc_loss = 0.0347063561977736
Trained batch 293 in epoch 0, gen_loss = 1.1305780889225654, disc_loss = 0.034611226800753146
Trained batch 294 in epoch 0, gen_loss = 1.1310534081216586, disc_loss = 0.03451683901376643
Trained batch 295 in epoch 0, gen_loss = 1.131194994256303, disc_loss = 0.034419073075106416
Trained batch 296 in epoch 0, gen_loss = 1.131633657397646, disc_loss = 0.03432200985148499
Trained batch 297 in epoch 0, gen_loss = 1.1317539839136521, disc_loss = 0.0342224700448272
Trained batch 298 in epoch 0, gen_loss = 1.1321133646279273, disc_loss = 0.03412511428805647
Trained batch 299 in epoch 0, gen_loss = 1.132041795651118, disc_loss = 0.03402972644350181
Trained batch 300 in epoch 0, gen_loss = 1.1320877324703127, disc_loss = 0.03393278413288221
Trained batch 301 in epoch 0, gen_loss = 1.1324773999239435, disc_loss = 0.03383599787746982
Trained batch 302 in epoch 0, gen_loss = 1.13228175585026, disc_loss = 0.03373617811586474
Trained batch 303 in epoch 0, gen_loss = 1.1318705525053174, disc_loss = 0.03364023568313936
Trained batch 304 in epoch 0, gen_loss = 1.1321610728248221, disc_loss = 0.033547453280752065
Trained batch 305 in epoch 0, gen_loss = 1.1322471409841302, disc_loss = 0.03345702866357112
Trained batch 306 in epoch 0, gen_loss = 1.1323847755158762, disc_loss = 0.03336405768271548
Trained batch 307 in epoch 0, gen_loss = 1.1322218466114689, disc_loss = 0.033273726205081476
Trained batch 308 in epoch 0, gen_loss = 1.1321441058587873, disc_loss = 0.033180333670186524
Trained batch 309 in epoch 0, gen_loss = 1.1321846465910634, disc_loss = 0.033087865782210665
Trained batch 310 in epoch 0, gen_loss = 1.1319867487505701, disc_loss = 0.03299375268004811
Trained batch 311 in epoch 0, gen_loss = 1.1317741500261502, disc_loss = 0.03290272525881823
Trained batch 312 in epoch 0, gen_loss = 1.1316686106946903, disc_loss = 0.03281165271128614
Trained batch 313 in epoch 0, gen_loss = 1.1314326779098267, disc_loss = 0.032720728498545425
Trained batch 314 in epoch 0, gen_loss = 1.1314494197330778, disc_loss = 0.03263155048240035
Trained batch 315 in epoch 0, gen_loss = 1.1314096714876876, disc_loss = 0.032541879439502486
Trained batch 316 in epoch 0, gen_loss = 1.131240110668098, disc_loss = 0.03245112803479663
Trained batch 317 in epoch 0, gen_loss = 1.1310842134667642, disc_loss = 0.032361416638178646
Trained batch 318 in epoch 0, gen_loss = 1.1312952026678103, disc_loss = 0.03227856457321014
Trained batch 319 in epoch 0, gen_loss = 1.13132658675313, disc_loss = 0.03219659998285351
Trained batch 320 in epoch 0, gen_loss = 1.131298816464029, disc_loss = 0.03211713338421652
Trained batch 321 in epoch 0, gen_loss = 1.1314673697726327, disc_loss = 0.03203769480398862
Trained batch 322 in epoch 0, gen_loss = 1.1313038248764842, disc_loss = 0.0319518561074193
Trained batch 323 in epoch 0, gen_loss = 1.1310352532216061, disc_loss = 0.031862713367804704
Trained batch 324 in epoch 0, gen_loss = 1.1308734427965603, disc_loss = 0.03177598132393681
Trained batch 325 in epoch 0, gen_loss = 1.1305749580904019, disc_loss = 0.031692329229946976
Trained batch 326 in epoch 0, gen_loss = 1.1304827323382782, disc_loss = 0.03161752034713505
Trained batch 327 in epoch 0, gen_loss = 1.1303500951063343, disc_loss = 0.03153881118008185
Trained batch 328 in epoch 0, gen_loss = 1.1301089039689503, disc_loss = 0.031456004996645325
Trained batch 329 in epoch 0, gen_loss = 1.1301914551041343, disc_loss = 0.03137348069470714
Trained batch 330 in epoch 0, gen_loss = 1.1301382160618947, disc_loss = 0.03128859020130895
Trained batch 331 in epoch 0, gen_loss = 1.1296771965831158, disc_loss = 0.031204197766169547
Trained batch 332 in epoch 0, gen_loss = 1.129790499761656, disc_loss = 0.031123778567434073
Trained batch 333 in epoch 0, gen_loss = 1.1297967066307981, disc_loss = 0.031043329152061108
Trained batch 334 in epoch 0, gen_loss = 1.1297586558470085, disc_loss = 0.030964668759547953
Trained batch 335 in epoch 0, gen_loss = 1.1296527552462758, disc_loss = 0.03088712284252757
Trained batch 336 in epoch 0, gen_loss = 1.1295047259118507, disc_loss = 0.03080878093650769
Trained batch 337 in epoch 0, gen_loss = 1.1294116240281324, disc_loss = 0.030727722950020707
Trained batch 338 in epoch 0, gen_loss = 1.1292108511854413, disc_loss = 0.030646425996739474
Trained batch 339 in epoch 0, gen_loss = 1.1290865947218502, disc_loss = 0.03056876251597286
Trained batch 340 in epoch 0, gen_loss = 1.1289102321496107, disc_loss = 0.030492094275063653
Trained batch 341 in epoch 0, gen_loss = 1.128869320565497, disc_loss = 0.030415998297275114
Trained batch 342 in epoch 0, gen_loss = 1.1288901209483688, disc_loss = 0.03033870418010274
Trained batch 343 in epoch 0, gen_loss = 1.12890639693238, disc_loss = 0.030264640536949817
Trained batch 344 in epoch 0, gen_loss = 1.1289521555969682, disc_loss = 0.03019008681690995
Trained batch 345 in epoch 0, gen_loss = 1.1289574149027035, disc_loss = 0.030116918918036053
Trained batch 346 in epoch 0, gen_loss = 1.1287804412566962, disc_loss = 0.030041965095041808
Trained batch 347 in epoch 0, gen_loss = 1.1285056040204804, disc_loss = 0.02996630403587873
Trained batch 348 in epoch 0, gen_loss = 1.1283086429011173, disc_loss = 0.029889105936581735
Trained batch 349 in epoch 0, gen_loss = 1.1281266508783614, disc_loss = 0.029814691665981496
Trained batch 350 in epoch 0, gen_loss = 1.128222325928191, disc_loss = 0.029741941047752768
Trained batch 351 in epoch 0, gen_loss = 1.1282387799160047, disc_loss = 0.029668689578432928
Trained batch 352 in epoch 0, gen_loss = 1.1282281629086892, disc_loss = 0.02959545586052385
Trained batch 353 in epoch 0, gen_loss = 1.1280963222185771, disc_loss = 0.029522705081282026
Trained batch 354 in epoch 0, gen_loss = 1.1277733440130528, disc_loss = 0.029449402838027182
Trained batch 355 in epoch 0, gen_loss = 1.127472252658244, disc_loss = 0.029375079548996194
Trained batch 356 in epoch 0, gen_loss = 1.1273111826231499, disc_loss = 0.029301852156755095
Trained batch 357 in epoch 0, gen_loss = 1.127103393970255, disc_loss = 0.02922864000419644
Trained batch 358 in epoch 0, gen_loss = 1.1271060754993831, disc_loss = 0.029159783717104776
Trained batch 359 in epoch 0, gen_loss = 1.1273544006877476, disc_loss = 0.029102930252621364
Trained batch 360 in epoch 0, gen_loss = 1.1272276953647011, disc_loss = 0.029039142332800826
Trained batch 361 in epoch 0, gen_loss = 1.1272993469765173, disc_loss = 0.028977894431973156
Trained batch 362 in epoch 0, gen_loss = 1.1272168973917476, disc_loss = 0.02891054220905543
Trained batch 363 in epoch 0, gen_loss = 1.1272270365075752, disc_loss = 0.028843115136963776
Trained batch 364 in epoch 0, gen_loss = 1.1270701480238405, disc_loss = 0.02877390636067378
Trained batch 365 in epoch 0, gen_loss = 1.1271191385925794, disc_loss = 0.028705100035244
Trained batch 366 in epoch 0, gen_loss = 1.1267994749448604, disc_loss = 0.02863632280529256
Trained batch 367 in epoch 0, gen_loss = 1.1268410413809444, disc_loss = 0.028571481566557297
Trained batch 368 in epoch 0, gen_loss = 1.1265474939087865, disc_loss = 0.028504607813473196
Trained batch 369 in epoch 0, gen_loss = 1.1263370530025378, disc_loss = 0.028436818630182863
Trained batch 370 in epoch 0, gen_loss = 1.126402186254928, disc_loss = 0.02837052203230359
Trained batch 371 in epoch 0, gen_loss = 1.1263351591043576, disc_loss = 0.028304669515339918
Trained batch 372 in epoch 0, gen_loss = 1.1258787327413584, disc_loss = 0.028237735303293605
Trained batch 373 in epoch 0, gen_loss = 1.1257719673256186, disc_loss = 0.028171126898826365
Trained batch 374 in epoch 0, gen_loss = 1.1261534864107767, disc_loss = 0.028107020355761052
Trained batch 375 in epoch 0, gen_loss = 1.1258975998201268, disc_loss = 0.028043000280183365
Trained batch 376 in epoch 0, gen_loss = 1.1260918282387427, disc_loss = 0.02798150568726208
Trained batch 377 in epoch 0, gen_loss = 1.126096981070029, disc_loss = 0.02791765649869506
Trained batch 378 in epoch 0, gen_loss = 1.1262121988475164, disc_loss = 0.027853869164048015
Trained batch 379 in epoch 0, gen_loss = 1.126050124199767, disc_loss = 0.02778966343091605
Trained batch 380 in epoch 0, gen_loss = 1.1260529855104882, disc_loss = 0.02772627831644469
Trained batch 381 in epoch 0, gen_loss = 1.1256969911265748, disc_loss = 0.02766402424020566
Trained batch 382 in epoch 0, gen_loss = 1.1256771012946147, disc_loss = 0.027605877575214086
Trained batch 383 in epoch 0, gen_loss = 1.125462061415116, disc_loss = 0.027546444633723393
Trained batch 384 in epoch 0, gen_loss = 1.1250750747593967, disc_loss = 0.027486698204869188
Trained batch 385 in epoch 0, gen_loss = 1.1251020161290244, disc_loss = 0.02742662290569607
Trained batch 386 in epoch 0, gen_loss = 1.1249672311529018, disc_loss = 0.0273665246019472
Trained batch 387 in epoch 0, gen_loss = 1.1247553817697407, disc_loss = 0.02730872651883737
Trained batch 388 in epoch 0, gen_loss = 1.1246982226028541, disc_loss = 0.027249303790034395
Trained batch 389 in epoch 0, gen_loss = 1.1242606801864428, disc_loss = 0.027187617317749522
Trained batch 390 in epoch 0, gen_loss = 1.1240464330024427, disc_loss = 0.0271265790089155
Trained batch 391 in epoch 0, gen_loss = 1.1240035383676996, disc_loss = 0.027065946008981566
Trained batch 392 in epoch 0, gen_loss = 1.123597940112495, disc_loss = 0.027004510324220847
Trained batch 393 in epoch 0, gen_loss = 1.1239270755482205, disc_loss = 0.02695201485899991
Trained batch 394 in epoch 0, gen_loss = 1.1239026133018204, disc_loss = 0.02689400542220926
Trained batch 395 in epoch 0, gen_loss = 1.123785080030711, disc_loss = 0.02683501426751415
Trained batch 396 in epoch 0, gen_loss = 1.123744130735133, disc_loss = 0.026781367250631377
Trained batch 397 in epoch 0, gen_loss = 1.1236197681882274, disc_loss = 0.026728874507673722
Trained batch 398 in epoch 0, gen_loss = 1.1233358487748264, disc_loss = 0.026674799228969374
Trained batch 399 in epoch 0, gen_loss = 1.1230482265353203, disc_loss = 0.02661708408384584
Trained batch 400 in epoch 0, gen_loss = 1.1230076358205363, disc_loss = 0.026559745017299775
Trained batch 401 in epoch 0, gen_loss = 1.122927147950699, disc_loss = 0.02650265529605824
Trained batch 402 in epoch 0, gen_loss = 1.1227056426978288, disc_loss = 0.026443979136123515
Trained batch 403 in epoch 0, gen_loss = 1.122577994176657, disc_loss = 0.026385851515028258
Trained batch 404 in epoch 0, gen_loss = 1.1222007830937704, disc_loss = 0.026328153225857718
Trained batch 405 in epoch 0, gen_loss = 1.1219956237694313, disc_loss = 0.026273962899955365
Trained batch 406 in epoch 0, gen_loss = 1.121646988889802, disc_loss = 0.026220261618719237
Trained batch 407 in epoch 0, gen_loss = 1.1214768746319939, disc_loss = 0.02616376350245749
Trained batch 408 in epoch 0, gen_loss = 1.1214487832449467, disc_loss = 0.02610758085186368
Trained batch 409 in epoch 0, gen_loss = 1.1211013622400237, disc_loss = 0.026051908542924537
Trained batch 410 in epoch 0, gen_loss = 1.1211210274638341, disc_loss = 0.02599925501611981
Trained batch 411 in epoch 0, gen_loss = 1.1209412821866933, disc_loss = 0.025946110281279508
Trained batch 412 in epoch 0, gen_loss = 1.1207571188416376, disc_loss = 0.025893172768979688
Trained batch 413 in epoch 0, gen_loss = 1.120795012096276, disc_loss = 0.025838459555086665
Trained batch 414 in epoch 0, gen_loss = 1.120603887431593, disc_loss = 0.025783475409317986
Trained batch 415 in epoch 0, gen_loss = 1.120417215503179, disc_loss = 0.025728121042238154
Trained batch 416 in epoch 0, gen_loss = 1.1202506412990945, disc_loss = 0.025673396483943654
Trained batch 417 in epoch 0, gen_loss = 1.1202570091594348, disc_loss = 0.025622127112558193
Trained batch 418 in epoch 0, gen_loss = 1.1200824108214822, disc_loss = 0.02557129666558189
Trained batch 419 in epoch 0, gen_loss = 1.1200655803793953, disc_loss = 0.025519382473569188
Trained batch 420 in epoch 0, gen_loss = 1.1197469401529452, disc_loss = 0.02546540383999446
Trained batch 421 in epoch 0, gen_loss = 1.1196188802402731, disc_loss = 0.025412386215415503
Trained batch 422 in epoch 0, gen_loss = 1.1196451237861147, disc_loss = 0.025361178258442744
Trained batch 423 in epoch 0, gen_loss = 1.1192921452083677, disc_loss = 0.025309512693158193
Trained batch 424 in epoch 0, gen_loss = 1.1192405009269715, disc_loss = 0.02525711349102066
Trained batch 425 in epoch 0, gen_loss = 1.1192328752206524, disc_loss = 0.02520428674061621
Trained batch 426 in epoch 0, gen_loss = 1.1191571022643418, disc_loss = 0.025151935275709497
Trained batch 427 in epoch 0, gen_loss = 1.119081985866912, disc_loss = 0.02509857577360975
Trained batch 428 in epoch 0, gen_loss = 1.1191041898894143, disc_loss = 0.025047160214516563
Trained batch 429 in epoch 0, gen_loss = 1.1189864279225816, disc_loss = 0.024996982228963873
Trained batch 430 in epoch 0, gen_loss = 1.1190819147014839, disc_loss = 0.024948032670643553
Trained batch 431 in epoch 0, gen_loss = 1.1189038161602285, disc_loss = 0.024896687876510743
Trained batch 432 in epoch 0, gen_loss = 1.118920892132898, disc_loss = 0.02484629529218596
Trained batch 433 in epoch 0, gen_loss = 1.118800323542362, disc_loss = 0.02479683321284791
Trained batch 434 in epoch 0, gen_loss = 1.1186567003699555, disc_loss = 0.024748491509228775
Trained batch 435 in epoch 0, gen_loss = 1.1187493619295434, disc_loss = 0.02469910072256734
Trained batch 436 in epoch 0, gen_loss = 1.1189550157269843, disc_loss = 0.024649553501752613
Trained batch 437 in epoch 0, gen_loss = 1.1192009295230587, disc_loss = 0.024606194453458536
Trained batch 438 in epoch 0, gen_loss = 1.1191458543232198, disc_loss = 0.024560577413258153
Trained batch 439 in epoch 0, gen_loss = 1.1190024894746866, disc_loss = 0.024519182801966303
Trained batch 440 in epoch 0, gen_loss = 1.119043127073993, disc_loss = 0.024477897203461923
Trained batch 441 in epoch 0, gen_loss = 1.1190604323445401, disc_loss = 0.024432945535075745
Trained batch 442 in epoch 0, gen_loss = 1.1189163911154254, disc_loss = 0.024387913308280853
Trained batch 443 in epoch 0, gen_loss = 1.1187419232215967, disc_loss = 0.024344060800734674
Trained batch 444 in epoch 0, gen_loss = 1.1185232624579011, disc_loss = 0.02430057210868664
Trained batch 445 in epoch 0, gen_loss = 1.1181747207727133, disc_loss = 0.02425481279948601
Trained batch 446 in epoch 0, gen_loss = 1.1181134478891188, disc_loss = 0.024206092553025724
Trained batch 447 in epoch 0, gen_loss = 1.1180062693144595, disc_loss = 0.02415890159006397
Trained batch 448 in epoch 0, gen_loss = 1.1179991166681915, disc_loss = 0.02411256686012719
Trained batch 449 in epoch 0, gen_loss = 1.1177654666370815, disc_loss = 0.024065906779530147
Trained batch 450 in epoch 0, gen_loss = 1.117628816226105, disc_loss = 0.024018929146866246
Trained batch 451 in epoch 0, gen_loss = 1.1174466839406343, disc_loss = 0.023971899871022103
Trained batch 452 in epoch 0, gen_loss = 1.1172364876496608, disc_loss = 0.023926081810204135
Trained batch 453 in epoch 0, gen_loss = 1.117088570206176, disc_loss = 0.023879422921593
Trained batch 454 in epoch 0, gen_loss = 1.1168008977240258, disc_loss = 0.023832268973014183
Trained batch 455 in epoch 0, gen_loss = 1.1166348159313202, disc_loss = 0.023784502475775713
Trained batch 456 in epoch 0, gen_loss = 1.1169276910485533, disc_loss = 0.023742029450515883
Trained batch 457 in epoch 0, gen_loss = 1.116713422875217, disc_loss = 0.023697399006603392
Trained batch 458 in epoch 0, gen_loss = 1.116675555056736, disc_loss = 0.02365565307393735
Trained batch 459 in epoch 0, gen_loss = 1.1164899320706076, disc_loss = 0.0236127424792832
Trained batch 460 in epoch 0, gen_loss = 1.1163615774436007, disc_loss = 0.023570901937499934
Trained batch 461 in epoch 0, gen_loss = 1.1160278460938178, disc_loss = 0.023531017313989534
Trained batch 462 in epoch 0, gen_loss = 1.1158512129124503, disc_loss = 0.02348806956364546
Trained batch 463 in epoch 0, gen_loss = 1.11561259794338, disc_loss = 0.023443260613993485
Trained batch 464 in epoch 0, gen_loss = 1.1155682795791215, disc_loss = 0.023398486915374956
Trained batch 465 in epoch 0, gen_loss = 1.1154301395487887, disc_loss = 0.023353095117920428
Trained batch 466 in epoch 0, gen_loss = 1.1154051004436338, disc_loss = 0.02330836774711547
Trained batch 467 in epoch 0, gen_loss = 1.1152665458428555, disc_loss = 0.023265350033911184
Trained batch 468 in epoch 0, gen_loss = 1.115127820831372, disc_loss = 0.023221402295998166
Trained batch 469 in epoch 0, gen_loss = 1.1149708343313096, disc_loss = 0.023177271738569153
Trained batch 470 in epoch 0, gen_loss = 1.1148046147544926, disc_loss = 0.023132747179589328
Trained batch 471 in epoch 0, gen_loss = 1.114761419341726, disc_loss = 0.02308816851020033
Trained batch 472 in epoch 0, gen_loss = 1.1147571584134979, disc_loss = 0.023044234070332275
Trained batch 473 in epoch 0, gen_loss = 1.1144927190577432, disc_loss = 0.023000058961662812
Trained batch 474 in epoch 0, gen_loss = 1.11462979228873, disc_loss = 0.022957616410659333
Trained batch 475 in epoch 0, gen_loss = 1.1145462650461357, disc_loss = 0.02291440387000134
Trained batch 476 in epoch 0, gen_loss = 1.1143847832639762, disc_loss = 0.02287179608809795
Trained batch 477 in epoch 0, gen_loss = 1.1142516022696156, disc_loss = 0.02282954764476428
Trained batch 478 in epoch 0, gen_loss = 1.1141000009279909, disc_loss = 0.022786370538357872
Trained batch 479 in epoch 0, gen_loss = 1.1139602928111951, disc_loss = 0.022742461643307857
Trained batch 480 in epoch 0, gen_loss = 1.1139333958189601, disc_loss = 0.02269938628778845
Trained batch 481 in epoch 0, gen_loss = 1.1137507912776283, disc_loss = 0.022656065929454995
Trained batch 482 in epoch 0, gen_loss = 1.113635556174608, disc_loss = 0.022614150985113227
Trained batch 483 in epoch 0, gen_loss = 1.113586782300768, disc_loss = 0.022572527038489568
Trained batch 484 in epoch 0, gen_loss = 1.1135944738830488, disc_loss = 0.02253128377715913
Trained batch 485 in epoch 0, gen_loss = 1.1133906153249151, disc_loss = 0.022488657388224847
Trained batch 486 in epoch 0, gen_loss = 1.1131737762163307, disc_loss = 0.022446933970021683
Trained batch 487 in epoch 0, gen_loss = 1.1132542203928604, disc_loss = 0.022406143440481384
Trained batch 488 in epoch 0, gen_loss = 1.1130592397629362, disc_loss = 0.02236523806685982
Trained batch 489 in epoch 0, gen_loss = 1.1131147081754647, disc_loss = 0.022325427417063667
Trained batch 490 in epoch 0, gen_loss = 1.1129458808850368, disc_loss = 0.02228518505651853
Trained batch 491 in epoch 0, gen_loss = 1.112939474180462, disc_loss = 0.022244203125166413
Trained batch 492 in epoch 0, gen_loss = 1.1126969266856659, disc_loss = 0.022204396760508675
Trained batch 493 in epoch 0, gen_loss = 1.1123451129627613, disc_loss = 0.022165359977985306
Trained batch 494 in epoch 0, gen_loss = 1.112110691118722, disc_loss = 0.02212500124769944
Trained batch 495 in epoch 0, gen_loss = 1.1117724594810316, disc_loss = 0.022087549061031875
Trained batch 496 in epoch 0, gen_loss = 1.1118116965236318, disc_loss = 0.022052822758020153
Trained batch 497 in epoch 0, gen_loss = 1.111690399517496, disc_loss = 0.02201900125671006
Trained batch 498 in epoch 0, gen_loss = 1.1114761885516868, disc_loss = 0.021982548842141274
Trained batch 499 in epoch 0, gen_loss = 1.1114956864118577, disc_loss = 0.02194412838970311
Trained batch 500 in epoch 0, gen_loss = 1.1113941047243967, disc_loss = 0.021905231921833208
Trained batch 501 in epoch 0, gen_loss = 1.1114201836614495, disc_loss = 0.021866461746552327
Trained batch 502 in epoch 0, gen_loss = 1.1113013326529244, disc_loss = 0.021827701463227052
Trained batch 503 in epoch 0, gen_loss = 1.111216880144581, disc_loss = 0.021790348763701447
Trained batch 504 in epoch 0, gen_loss = 1.1110122346641993, disc_loss = 0.021752547013278275
Trained batch 505 in epoch 0, gen_loss = 1.1107933932377887, disc_loss = 0.021713593330283984
Trained batch 506 in epoch 0, gen_loss = 1.1104780573111315, disc_loss = 0.021674257907942966
Trained batch 507 in epoch 0, gen_loss = 1.1104790187022817, disc_loss = 0.02163533423637685
Trained batch 508 in epoch 0, gen_loss = 1.1101703012621942, disc_loss = 0.02159678579462703
Trained batch 509 in epoch 0, gen_loss = 1.110007531152052, disc_loss = 0.021558777335802932
Trained batch 510 in epoch 0, gen_loss = 1.1099039412991174, disc_loss = 0.02152126976275186
Trained batch 511 in epoch 0, gen_loss = 1.1098073079483584, disc_loss = 0.02148386580324768
Trained batch 512 in epoch 0, gen_loss = 1.1096830280900698, disc_loss = 0.021445553278011318
Trained batch 513 in epoch 0, gen_loss = 1.1096555802840666, disc_loss = 0.02140785444456294
Trained batch 514 in epoch 0, gen_loss = 1.1096369823205818, disc_loss = 0.021371265774529462
Trained batch 515 in epoch 0, gen_loss = 1.10941540883031, disc_loss = 0.021333207077140984
Trained batch 516 in epoch 0, gen_loss = 1.1093230200228885, disc_loss = 0.021296460350355713
Trained batch 517 in epoch 0, gen_loss = 1.1092335651970278, disc_loss = 0.021260221047833937
Trained batch 518 in epoch 0, gen_loss = 1.1090534931203073, disc_loss = 0.021223488479569154
Trained batch 519 in epoch 0, gen_loss = 1.1089587820264009, disc_loss = 0.02118772144178645
Trained batch 520 in epoch 0, gen_loss = 1.1087692819264021, disc_loss = 0.021152921483070804
Trained batch 521 in epoch 0, gen_loss = 1.1086128795969075, disc_loss = 0.021118137650941123
Trained batch 522 in epoch 0, gen_loss = 1.1084437900245987, disc_loss = 0.021082790824005927
Trained batch 523 in epoch 0, gen_loss = 1.108381633881394, disc_loss = 0.021047241343291945
Trained batch 524 in epoch 0, gen_loss = 1.1081468135969978, disc_loss = 0.021011045970732257
Trained batch 525 in epoch 0, gen_loss = 1.1081742341754102, disc_loss = 0.020975662810115335
Trained batch 526 in epoch 0, gen_loss = 1.1079677847802525, disc_loss = 0.02094037009692933
Trained batch 527 in epoch 0, gen_loss = 1.107985264875672, disc_loss = 0.020904752204924906
Trained batch 528 in epoch 0, gen_loss = 1.1077627335694427, disc_loss = 0.020868340743281342
Trained batch 529 in epoch 0, gen_loss = 1.1078314970124443, disc_loss = 0.020834683135529664
Trained batch 530 in epoch 0, gen_loss = 1.1076861054210339, disc_loss = 0.020800397544792324
Trained batch 531 in epoch 0, gen_loss = 1.1076444992445464, disc_loss = 0.0207660771651225
Trained batch 532 in epoch 0, gen_loss = 1.1075736328987422, disc_loss = 0.020730608216081494
Trained batch 533 in epoch 0, gen_loss = 1.10748905791772, disc_loss = 0.020695109233828717
Trained batch 534 in epoch 0, gen_loss = 1.1072620177937444, disc_loss = 0.02066046650190707
Trained batch 535 in epoch 0, gen_loss = 1.1071587360616941, disc_loss = 0.020626147699441565
Trained batch 536 in epoch 0, gen_loss = 1.1072253612610659, disc_loss = 0.020591893606668327
Trained batch 537 in epoch 0, gen_loss = 1.1072049242856334, disc_loss = 0.02055815420136008
Trained batch 538 in epoch 0, gen_loss = 1.1072143508684658, disc_loss = 0.02052382955972126
Trained batch 539 in epoch 0, gen_loss = 1.1070060813868488, disc_loss = 0.020489386141438175
Trained batch 540 in epoch 0, gen_loss = 1.107055466629, disc_loss = 0.020456115501741715
Trained batch 541 in epoch 0, gen_loss = 1.106979301054979, disc_loss = 0.020421985480109595
Trained batch 542 in epoch 0, gen_loss = 1.1068993589496086, disc_loss = 0.020388795136221948
Trained batch 543 in epoch 0, gen_loss = 1.106794101788717, disc_loss = 0.02035674284450258
Trained batch 544 in epoch 0, gen_loss = 1.1067293431780754, disc_loss = 0.020326667059845198
Trained batch 545 in epoch 0, gen_loss = 1.1065230511483692, disc_loss = 0.020296801297393228
Trained batch 546 in epoch 0, gen_loss = 1.1063738525240687, disc_loss = 0.020266238316958278
Trained batch 547 in epoch 0, gen_loss = 1.1062066130829553, disc_loss = 0.020234118592177594
Trained batch 548 in epoch 0, gen_loss = 1.1060552994410198, disc_loss = 0.02020102305395464
Trained batch 549 in epoch 0, gen_loss = 1.1059920711950821, disc_loss = 0.020169778804040767
Trained batch 550 in epoch 0, gen_loss = 1.106066282128682, disc_loss = 0.020139187285355454
Trained batch 551 in epoch 0, gen_loss = 1.1058400200976841, disc_loss = 0.020108384729794943
Trained batch 552 in epoch 0, gen_loss = 1.1057742587265442, disc_loss = 0.020077145439917878
Trained batch 553 in epoch 0, gen_loss = 1.1057527229889206, disc_loss = 0.02004536131517928
Trained batch 554 in epoch 0, gen_loss = 1.105665794256571, disc_loss = 0.020014236561182116
Trained batch 555 in epoch 0, gen_loss = 1.105638203753842, disc_loss = 0.01998322685048145
Trained batch 556 in epoch 0, gen_loss = 1.1056270232320473, disc_loss = 0.019952569992065804
Trained batch 557 in epoch 0, gen_loss = 1.1055817301768982, disc_loss = 0.01992086523235859
Trained batch 558 in epoch 0, gen_loss = 1.105455561379414, disc_loss = 0.019889015885576445
Trained batch 559 in epoch 0, gen_loss = 1.1054654639746462, disc_loss = 0.019857356168878532
Trained batch 560 in epoch 0, gen_loss = 1.105360561619893, disc_loss = 0.019825616191554676
Trained batch 561 in epoch 0, gen_loss = 1.1053139337229134, disc_loss = 0.019794187018004814
Trained batch 562 in epoch 0, gen_loss = 1.1051599468049953, disc_loss = 0.01976300503266231
Trained batch 563 in epoch 0, gen_loss = 1.1049664626096158, disc_loss = 0.019731777638414914
Trained batch 564 in epoch 0, gen_loss = 1.1049924290285702, disc_loss = 0.019702013877047373
Trained batch 565 in epoch 0, gen_loss = 1.104836906750716, disc_loss = 0.019671356018349635
Trained batch 566 in epoch 0, gen_loss = 1.1046127660144154, disc_loss = 0.019640504629342987
Trained batch 567 in epoch 0, gen_loss = 1.1044163075341304, disc_loss = 0.01960932876026048
Trained batch 568 in epoch 0, gen_loss = 1.1041815089215712, disc_loss = 0.019578036220387438
Trained batch 569 in epoch 0, gen_loss = 1.1041193185145395, disc_loss = 0.019546692253686816
Trained batch 570 in epoch 0, gen_loss = 1.103897013722702, disc_loss = 0.019515032911609578
Trained batch 571 in epoch 0, gen_loss = 1.1036891976853351, disc_loss = 0.019483825873861976
Trained batch 572 in epoch 0, gen_loss = 1.1036342424039858, disc_loss = 0.01945344345456389
Trained batch 573 in epoch 0, gen_loss = 1.1035910277831844, disc_loss = 0.01942362237128653
Trained batch 574 in epoch 0, gen_loss = 1.1035951467182326, disc_loss = 0.019394399161126626
Trained batch 575 in epoch 0, gen_loss = 1.1033520466751523, disc_loss = 0.019364147212399985
Trained batch 576 in epoch 0, gen_loss = 1.1033285172394698, disc_loss = 0.019333655381836706
Trained batch 577 in epoch 0, gen_loss = 1.103316443189205, disc_loss = 0.019303544950155883
Trained batch 578 in epoch 0, gen_loss = 1.1031296307764729, disc_loss = 0.0192729953092576
Trained batch 579 in epoch 0, gen_loss = 1.1029794977656726, disc_loss = 0.01924255346791048
Trained batch 580 in epoch 0, gen_loss = 1.1029567290706601, disc_loss = 0.019212821340220444
Trained batch 581 in epoch 0, gen_loss = 1.1030534496626903, disc_loss = 0.019183834829476512
Trained batch 582 in epoch 0, gen_loss = 1.1030885515859157, disc_loss = 0.01915520001690049
Trained batch 583 in epoch 0, gen_loss = 1.1030834616251188, disc_loss = 0.01912584797039067
Trained batch 584 in epoch 0, gen_loss = 1.103140648919293, disc_loss = 0.019096502429272376
Trained batch 585 in epoch 0, gen_loss = 1.102988405134084, disc_loss = 0.019066896529569458
Trained batch 586 in epoch 0, gen_loss = 1.1028799475559383, disc_loss = 0.01903784320113809
Trained batch 587 in epoch 0, gen_loss = 1.1029325801701773, disc_loss = 0.0190090756442835
Trained batch 588 in epoch 0, gen_loss = 1.1027434421719031, disc_loss = 0.01897953307166765
Trained batch 589 in epoch 0, gen_loss = 1.1026516064748926, disc_loss = 0.018950873307717997
Trained batch 590 in epoch 0, gen_loss = 1.1024502700355452, disc_loss = 0.01892450924701957
Trained batch 591 in epoch 0, gen_loss = 1.1023332022533223, disc_loss = 0.01889810066829857
Trained batch 592 in epoch 0, gen_loss = 1.1023053601258521, disc_loss = 0.01887066556791764
Trained batch 593 in epoch 0, gen_loss = 1.1022177546313314, disc_loss = 0.018841760120353025
Trained batch 594 in epoch 0, gen_loss = 1.102164492987785, disc_loss = 0.018812913766342112
Trained batch 595 in epoch 0, gen_loss = 1.1020819473786643, disc_loss = 0.018784668566323128
Trained batch 596 in epoch 0, gen_loss = 1.1019205660676237, disc_loss = 0.018756514445370003
Trained batch 597 in epoch 0, gen_loss = 1.1017522501905626, disc_loss = 0.01872808926206948
Trained batch 598 in epoch 0, gen_loss = 1.101707489243732, disc_loss = 0.018699743619184
Trained batch 599 in epoch 0, gen_loss = 1.1016519793868065, disc_loss = 0.01867159169652344
Trained batch 600 in epoch 0, gen_loss = 1.1014398653773023, disc_loss = 0.018643010917705437
Trained batch 601 in epoch 0, gen_loss = 1.1012772965272797, disc_loss = 0.01861474628752079
Trained batch 602 in epoch 0, gen_loss = 1.1011926238216572, disc_loss = 0.018586166064790875
Trained batch 603 in epoch 0, gen_loss = 1.101364179952255, disc_loss = 0.018559046400347046
Trained batch 604 in epoch 0, gen_loss = 1.1012291784128867, disc_loss = 0.01853121532519802
Trained batch 605 in epoch 0, gen_loss = 1.1010876368768145, disc_loss = 0.018503414180741428
Trained batch 606 in epoch 0, gen_loss = 1.1010627554118928, disc_loss = 0.018476781605618595
Trained batch 607 in epoch 0, gen_loss = 1.1009104053832983, disc_loss = 0.01845176770477433
Trained batch 608 in epoch 0, gen_loss = 1.1008289848838142, disc_loss = 0.018427836676609927
Trained batch 609 in epoch 0, gen_loss = 1.1007834342659497, disc_loss = 0.018404798285241743
Trained batch 610 in epoch 0, gen_loss = 1.1006675217233586, disc_loss = 0.01838235404119871
Trained batch 611 in epoch 0, gen_loss = 1.1006214499863145, disc_loss = 0.018359315491074488
Trained batch 612 in epoch 0, gen_loss = 1.1005515004060007, disc_loss = 0.018334554211307943
Trained batch 613 in epoch 0, gen_loss = 1.1004584854899477, disc_loss = 0.018307809158818376
Trained batch 614 in epoch 0, gen_loss = 1.1005535786714011, disc_loss = 0.018281285687561745
Trained batch 615 in epoch 0, gen_loss = 1.1004807204008102, disc_loss = 0.018254910737265494
Trained batch 616 in epoch 0, gen_loss = 1.100244908703784, disc_loss = 0.01822898312335203
Trained batch 617 in epoch 0, gen_loss = 1.100147320228873, disc_loss = 0.018202510731133503
Trained batch 618 in epoch 0, gen_loss = 1.1001451753067855, disc_loss = 0.018176823662803095
Trained batch 619 in epoch 0, gen_loss = 1.1000942845498363, disc_loss = 0.018150667472359452
Trained batch 620 in epoch 0, gen_loss = 1.1000440493106074, disc_loss = 0.018124460562877656
Trained batch 621 in epoch 0, gen_loss = 1.0999341057044516, disc_loss = 0.018098889247789813
Trained batch 622 in epoch 0, gen_loss = 1.0997625865867395, disc_loss = 0.018072928048230793
Trained batch 623 in epoch 0, gen_loss = 1.099817471530957, disc_loss = 0.018046989561042164
Trained batch 624 in epoch 0, gen_loss = 1.0998736296653748, disc_loss = 0.01802112600579858
Trained batch 625 in epoch 0, gen_loss = 1.0997981721410355, disc_loss = 0.017995669815939266
Trained batch 626 in epoch 0, gen_loss = 1.0996028453919686, disc_loss = 0.017971114660992007
Trained batch 627 in epoch 0, gen_loss = 1.0995802056447717, disc_loss = 0.017948115184446382
Trained batch 628 in epoch 0, gen_loss = 1.0995032678347891, disc_loss = 0.017924420545928903
Trained batch 629 in epoch 0, gen_loss = 1.0994037816448816, disc_loss = 0.017899218982543857
Trained batch 630 in epoch 0, gen_loss = 1.0995304838602213, disc_loss = 0.017874130601706884
Trained batch 631 in epoch 0, gen_loss = 1.0993518270080602, disc_loss = 0.017848255526852097
Trained batch 632 in epoch 0, gen_loss = 1.099238859816185, disc_loss = 0.01782294400411512
Trained batch 633 in epoch 0, gen_loss = 1.0992244234784545, disc_loss = 0.017798496545762505
Trained batch 634 in epoch 0, gen_loss = 1.0991983741287172, disc_loss = 0.01777445375039352
Trained batch 635 in epoch 0, gen_loss = 1.099059412595611, disc_loss = 0.017750710250411486
Trained batch 636 in epoch 0, gen_loss = 1.0990732183074652, disc_loss = 0.017725856396482213
Trained batch 637 in epoch 0, gen_loss = 1.098951482193597, disc_loss = 0.01770041553762692
Trained batch 638 in epoch 0, gen_loss = 1.0987748482231057, disc_loss = 0.017675153005479054
Trained batch 639 in epoch 0, gen_loss = 1.0986440127715469, disc_loss = 0.017650102034349403
Trained batch 640 in epoch 0, gen_loss = 1.0986881380706048, disc_loss = 0.017625024343343877
Trained batch 641 in epoch 0, gen_loss = 1.0986199804184222, disc_loss = 0.017600431531302144
Trained batch 642 in epoch 0, gen_loss = 1.098614168018798, disc_loss = 0.01757644942395308
Trained batch 643 in epoch 0, gen_loss = 1.0984586958559404, disc_loss = 0.017553090664517622
Trained batch 644 in epoch 0, gen_loss = 1.0983796444974205, disc_loss = 0.017529309760461482
Trained batch 645 in epoch 0, gen_loss = 1.098247883305092, disc_loss = 0.017505186763282103
Trained batch 646 in epoch 0, gen_loss = 1.0981352530085875, disc_loss = 0.017480294711361
Trained batch 647 in epoch 0, gen_loss = 1.0981234407719271, disc_loss = 0.01745537081090187
Trained batch 648 in epoch 0, gen_loss = 1.0979974012712852, disc_loss = 0.017430555820357463
Trained batch 649 in epoch 0, gen_loss = 1.0979850959777833, disc_loss = 0.017405988725547033
Trained batch 650 in epoch 0, gen_loss = 1.0978931673843924, disc_loss = 0.01738107474177458
Trained batch 651 in epoch 0, gen_loss = 1.097763582972661, disc_loss = 0.01735615878911586
Trained batch 652 in epoch 0, gen_loss = 1.0977596090179491, disc_loss = 0.01733166739276138
Trained batch 653 in epoch 0, gen_loss = 1.097709853532482, disc_loss = 0.01730726353093606
Trained batch 654 in epoch 0, gen_loss = 1.0975949249194779, disc_loss = 0.01728312595718974
Trained batch 655 in epoch 0, gen_loss = 1.0974658347847985, disc_loss = 0.017259348145715905
Trained batch 656 in epoch 0, gen_loss = 1.0974080658757341, disc_loss = 0.01723616319276886
Trained batch 657 in epoch 0, gen_loss = 1.0972678610619078, disc_loss = 0.017212515171245023
Trained batch 658 in epoch 0, gen_loss = 1.0972992078668249, disc_loss = 0.017188730328668852
Trained batch 659 in epoch 0, gen_loss = 1.0971489666086254, disc_loss = 0.017166331655056582
Trained batch 660 in epoch 0, gen_loss = 1.0970968742053195, disc_loss = 0.017145369151704375
Trained batch 661 in epoch 0, gen_loss = 1.096949141731435, disc_loss = 0.017123592694766897
Trained batch 662 in epoch 0, gen_loss = 1.0968436171746003, disc_loss = 0.017100658267385258
Trained batch 663 in epoch 0, gen_loss = 1.0967401993202877, disc_loss = 0.017077258525764097
Trained batch 664 in epoch 0, gen_loss = 1.0966801078696, disc_loss = 0.017053437821700105
Trained batch 665 in epoch 0, gen_loss = 1.0965856009417467, disc_loss = 0.01702985908750825
Trained batch 666 in epoch 0, gen_loss = 1.0963714368518502, disc_loss = 0.01700644326260847
Trained batch 667 in epoch 0, gen_loss = 1.0962281945401322, disc_loss = 0.01698322113900317
Trained batch 668 in epoch 0, gen_loss = 1.096241265579902, disc_loss = 0.01696050982478232
Trained batch 669 in epoch 0, gen_loss = 1.0961434938124757, disc_loss = 0.016937810557533
Trained batch 670 in epoch 0, gen_loss = 1.0961158479023974, disc_loss = 0.01691557297548321
Trained batch 671 in epoch 0, gen_loss = 1.0959988329559565, disc_loss = 0.01689333127156022
Trained batch 672 in epoch 0, gen_loss = 1.0958974716567709, disc_loss = 0.016871072272361873
Trained batch 673 in epoch 0, gen_loss = 1.0958936892737268, disc_loss = 0.016849023719367955
Trained batch 674 in epoch 0, gen_loss = 1.0957669209550929, disc_loss = 0.016826876382584927
Trained batch 675 in epoch 0, gen_loss = 1.0956269498231144, disc_loss = 0.016804982529892504
Trained batch 676 in epoch 0, gen_loss = 1.095480020940744, disc_loss = 0.016782793946195522
Trained batch 677 in epoch 0, gen_loss = 1.0952359904757643, disc_loss = 0.016760686133262925
Trained batch 678 in epoch 0, gen_loss = 1.0952064677612068, disc_loss = 0.016739046505950008
Trained batch 679 in epoch 0, gen_loss = 1.0951227075036833, disc_loss = 0.016717146709732546
Trained batch 680 in epoch 0, gen_loss = 1.095003373034725, disc_loss = 0.01669498210107544
Trained batch 681 in epoch 0, gen_loss = 1.0948522686958313, disc_loss = 0.016672736981336048
Trained batch 682 in epoch 0, gen_loss = 1.0947467854920103, disc_loss = 0.016650360394991924
Trained batch 683 in epoch 0, gen_loss = 1.0946601416632447, disc_loss = 0.016628182828439978
Trained batch 684 in epoch 0, gen_loss = 1.0946397548174336, disc_loss = 0.016606037676449945
Trained batch 685 in epoch 0, gen_loss = 1.0946995242344046, disc_loss = 0.01658442766461983
Trained batch 686 in epoch 0, gen_loss = 1.094704220041611, disc_loss = 0.016562232246935597
Trained batch 687 in epoch 0, gen_loss = 1.09466717184283, disc_loss = 0.01654026681252046
Trained batch 688 in epoch 0, gen_loss = 1.0946091351211504, disc_loss = 0.016518503509283456
Trained batch 689 in epoch 0, gen_loss = 1.0945017569306967, disc_loss = 0.016496322812188578
Trained batch 690 in epoch 0, gen_loss = 1.0944194603932405, disc_loss = 0.016474326471218572
Trained batch 691 in epoch 0, gen_loss = 1.0942521870480797, disc_loss = 0.016452410154554703
Trained batch 692 in epoch 0, gen_loss = 1.0940627333577748, disc_loss = 0.016430681256051908
Trained batch 693 in epoch 0, gen_loss = 1.0940118919016648, disc_loss = 0.016409114845766706
Trained batch 694 in epoch 0, gen_loss = 1.0939113374236675, disc_loss = 0.016387486300705897
Trained batch 695 in epoch 0, gen_loss = 1.0938318715184585, disc_loss = 0.016365966705094232
Trained batch 696 in epoch 0, gen_loss = 1.0935681182650616, disc_loss = 0.016345726525199892
Trained batch 697 in epoch 0, gen_loss = 1.0938557509364917, disc_loss = 0.016329460686611754
Trained batch 698 in epoch 0, gen_loss = 1.0939576879932476, disc_loss = 0.016315238955344084
Trained batch 699 in epoch 0, gen_loss = 1.094023423876081, disc_loss = 0.016301517420714454
Trained batch 700 in epoch 0, gen_loss = 1.0938480388420966, disc_loss = 0.016284257916869136
Trained batch 701 in epoch 0, gen_loss = 1.0937219712129684, disc_loss = 0.01626581644328932
Trained batch 702 in epoch 0, gen_loss = 1.0935283938308868, disc_loss = 0.016247907382864003
Trained batch 703 in epoch 0, gen_loss = 1.093475040556355, disc_loss = 0.016230819104252572
Trained batch 704 in epoch 0, gen_loss = 1.0933802794057428, disc_loss = 0.016212495224523945
Trained batch 705 in epoch 0, gen_loss = 1.093213609865637, disc_loss = 0.01619237742126885
Trained batch 706 in epoch 0, gen_loss = 1.0930769863357976, disc_loss = 0.016171621478984693
Trained batch 707 in epoch 0, gen_loss = 1.092982847306688, disc_loss = 0.016150691647787638
Trained batch 708 in epoch 0, gen_loss = 1.092924845235472, disc_loss = 0.01612978087763114
Trained batch 709 in epoch 0, gen_loss = 1.0927414924326078, disc_loss = 0.016109364568813324
Trained batch 710 in epoch 0, gen_loss = 1.0925905546893886, disc_loss = 0.016090147339531943
Trained batch 711 in epoch 0, gen_loss = 1.0925840281703498, disc_loss = 0.016070563741338313
Trained batch 712 in epoch 0, gen_loss = 1.0925171057606144, disc_loss = 0.01605078659681956
Trained batch 713 in epoch 0, gen_loss = 1.0924340269478763, disc_loss = 0.016031083617462444
Trained batch 714 in epoch 0, gen_loss = 1.0925512492239893, disc_loss = 0.016011218471661003
Trained batch 715 in epoch 0, gen_loss = 1.0925047805522408, disc_loss = 0.01599037113948075
Trained batch 716 in epoch 0, gen_loss = 1.0924230232065857, disc_loss = 0.015970418909681518
Trained batch 717 in epoch 0, gen_loss = 1.092390374884964, disc_loss = 0.015950360024914737
Trained batch 718 in epoch 0, gen_loss = 1.0923405443013792, disc_loss = 0.015929897144658332
Trained batch 719 in epoch 0, gen_loss = 1.0922091282904147, disc_loss = 0.015909923588333187
Trained batch 720 in epoch 0, gen_loss = 1.0922792107486856, disc_loss = 0.01589127831259838
Trained batch 721 in epoch 0, gen_loss = 1.0922225382684672, disc_loss = 0.015874431034649396
Trained batch 722 in epoch 0, gen_loss = 1.0921833619866959, disc_loss = 0.01585808602392926
Trained batch 723 in epoch 0, gen_loss = 1.0920875078242127, disc_loss = 0.015839713762767705
Trained batch 724 in epoch 0, gen_loss = 1.0920471542457055, disc_loss = 0.015819934729069215
Trained batch 725 in epoch 0, gen_loss = 1.0919361074272922, disc_loss = 0.015799584915892274
Trained batch 726 in epoch 0, gen_loss = 1.0919370212613961, disc_loss = 0.015779363065753057
Trained batch 727 in epoch 0, gen_loss = 1.0919647135741108, disc_loss = 0.015759447823626573
Trained batch 728 in epoch 0, gen_loss = 1.0918573657017512, disc_loss = 0.015739115565888768
Trained batch 729 in epoch 0, gen_loss = 1.0917301293105295, disc_loss = 0.015718882816623616
Trained batch 730 in epoch 0, gen_loss = 1.0915700444281509, disc_loss = 0.015698662589010485
Trained batch 731 in epoch 0, gen_loss = 1.0915965073909917, disc_loss = 0.01567877775598559
Trained batch 732 in epoch 0, gen_loss = 1.0917264928108674, disc_loss = 0.015659286683068915
Trained batch 733 in epoch 0, gen_loss = 1.0916871697279023, disc_loss = 0.015639879638395762
Trained batch 734 in epoch 0, gen_loss = 1.0915777223450798, disc_loss = 0.015620660328315761
Trained batch 735 in epoch 0, gen_loss = 1.0914548887344806, disc_loss = 0.015601670240832154
Trained batch 736 in epoch 0, gen_loss = 1.0914163640428591, disc_loss = 0.015582286272014098
Trained batch 737 in epoch 0, gen_loss = 1.091421111408611, disc_loss = 0.015562704410249378
Trained batch 738 in epoch 0, gen_loss = 1.0913008861999873, disc_loss = 0.015543197354989276
Trained batch 739 in epoch 0, gen_loss = 1.0911506802649111, disc_loss = 0.015523704783943784
Trained batch 740 in epoch 0, gen_loss = 1.0912197876555716, disc_loss = 0.015504444304802776
Trained batch 741 in epoch 0, gen_loss = 1.091158531586115, disc_loss = 0.015485093449170241
Trained batch 742 in epoch 0, gen_loss = 1.0911398643118857, disc_loss = 0.015465688067008923
Trained batch 743 in epoch 0, gen_loss = 1.0911874340106082, disc_loss = 0.015446831822637544
Trained batch 744 in epoch 0, gen_loss = 1.0912194250414036, disc_loss = 0.015428135151296679
Trained batch 745 in epoch 0, gen_loss = 1.091150170037318, disc_loss = 0.01540917847669139
Trained batch 746 in epoch 0, gen_loss = 1.091045345008932, disc_loss = 0.01539007062817097
Trained batch 747 in epoch 0, gen_loss = 1.0910332688992037, disc_loss = 0.015370698902431632
Trained batch 748 in epoch 0, gen_loss = 1.0910405461714965, disc_loss = 0.01535151753015381
Trained batch 749 in epoch 0, gen_loss = 1.0910538390477498, disc_loss = 0.015332653381318475
Trained batch 750 in epoch 0, gen_loss = 1.0910830062810337, disc_loss = 0.015314041796935903
Trained batch 751 in epoch 0, gen_loss = 1.0911281229333674, disc_loss = 0.015295680731295315
Trained batch 752 in epoch 0, gen_loss = 1.0911971048846505, disc_loss = 0.015277618475757405
Trained batch 753 in epoch 0, gen_loss = 1.0911122271173512, disc_loss = 0.015258827006869853
Trained batch 754 in epoch 0, gen_loss = 1.0910435210790066, disc_loss = 0.015240438425349109
Trained batch 755 in epoch 0, gen_loss = 1.0909911373620311, disc_loss = 0.01522295408127349
Trained batch 756 in epoch 0, gen_loss = 1.0908779394043957, disc_loss = 0.015205744575586691
Trained batch 757 in epoch 0, gen_loss = 1.0907918011922006, disc_loss = 0.015187761546613275
Trained batch 758 in epoch 0, gen_loss = 1.0907079207567358, disc_loss = 0.015169388347944032
Trained batch 759 in epoch 0, gen_loss = 1.090585185979542, disc_loss = 0.015150871630957179
Trained batch 760 in epoch 0, gen_loss = 1.0904169315264196, disc_loss = 0.015132488215445576
Trained batch 761 in epoch 0, gen_loss = 1.0903114087468997, disc_loss = 0.015113795528449901
Trained batch 762 in epoch 0, gen_loss = 1.0901456109661887, disc_loss = 0.015095161570377677
Trained batch 763 in epoch 0, gen_loss = 1.090094927015729, disc_loss = 0.015077092165812479
Trained batch 764 in epoch 0, gen_loss = 1.0899234136724785, disc_loss = 0.01506000870163096
Trained batch 765 in epoch 0, gen_loss = 1.0897408567427345, disc_loss = 0.015042846401431172
Trained batch 766 in epoch 0, gen_loss = 1.0896043759592198, disc_loss = 0.015026293686169747
Trained batch 767 in epoch 0, gen_loss = 1.089540201627339, disc_loss = 0.015009882064380994
Trained batch 768 in epoch 0, gen_loss = 1.0895034632075127, disc_loss = 0.014994082873098561
Trained batch 769 in epoch 0, gen_loss = 1.0893100682017092, disc_loss = 0.014978112601796044
Trained batch 770 in epoch 0, gen_loss = 1.089217966864545, disc_loss = 0.014961396114195271
Trained batch 771 in epoch 0, gen_loss = 1.0892930315720604, disc_loss = 0.014944530048750225
Trained batch 772 in epoch 0, gen_loss = 1.0894480612885598, disc_loss = 0.014927552541281744
Trained batch 773 in epoch 0, gen_loss = 1.0893601454043573, disc_loss = 0.014909947497074706
Trained batch 774 in epoch 0, gen_loss = 1.0893233443075612, disc_loss = 0.01489227353129536
Trained batch 775 in epoch 0, gen_loss = 1.089195336800875, disc_loss = 0.014874179211229724
Trained batch 776 in epoch 0, gen_loss = 1.0891201163964535, disc_loss = 0.01485622680564429
Trained batch 777 in epoch 0, gen_loss = 1.0889520312642684, disc_loss = 0.01483953462995632
Trained batch 778 in epoch 0, gen_loss = 1.088861647558151, disc_loss = 0.014824708177832425
Trained batch 779 in epoch 0, gen_loss = 1.088815432939774, disc_loss = 0.014810928204007303
Trained batch 780 in epoch 0, gen_loss = 1.0886581908725441, disc_loss = 0.014796173855723162
Trained batch 781 in epoch 0, gen_loss = 1.0885283467562303, disc_loss = 0.014780377908853953
Trained batch 782 in epoch 0, gen_loss = 1.0884445647627001, disc_loss = 0.014764233135040206
Trained batch 783 in epoch 0, gen_loss = 1.0883543064855798, disc_loss = 0.014747775951073724
Trained batch 784 in epoch 0, gen_loss = 1.088320702883848, disc_loss = 0.014730565952119317
Trained batch 785 in epoch 0, gen_loss = 1.0883357798628528, disc_loss = 0.01471357152139076
Trained batch 786 in epoch 0, gen_loss = 1.0882078584146317, disc_loss = 0.014696722509980845
Trained batch 787 in epoch 0, gen_loss = 1.0881615390783639, disc_loss = 0.01467963611750821
Trained batch 788 in epoch 0, gen_loss = 1.0880901690369473, disc_loss = 0.014662438927156938
Trained batch 789 in epoch 0, gen_loss = 1.0879294358476808, disc_loss = 0.014645500702907249
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.07687509059906, disc_loss = 0.0022186441347002983
Trained batch 1 in epoch 1, gen_loss = 1.0498424768447876, disc_loss = 0.0025001405738294125
Trained batch 2 in epoch 1, gen_loss = 1.0726553599039714, disc_loss = 0.0025894104037433863
Trained batch 3 in epoch 1, gen_loss = 1.056385338306427, disc_loss = 0.0023900998930912465
Trained batch 4 in epoch 1, gen_loss = 1.05519642829895, disc_loss = 0.0021607839735224843
Trained batch 5 in epoch 1, gen_loss = 1.0588501691818237, disc_loss = 0.0020042867205726602
Trained batch 6 in epoch 1, gen_loss = 1.0502487591334753, disc_loss = 0.0019023913524246641
Trained batch 7 in epoch 1, gen_loss = 1.0418765991926193, disc_loss = 0.0018060953880194575
Trained batch 8 in epoch 1, gen_loss = 1.0535220437579684, disc_loss = 0.0017574456934299734
Trained batch 9 in epoch 1, gen_loss = 1.05600745677948, disc_loss = 0.0017024617292918265
Trained batch 10 in epoch 1, gen_loss = 1.0572869235819036, disc_loss = 0.0016802035229788585
Trained batch 11 in epoch 1, gen_loss = 1.0555370847384136, disc_loss = 0.0016700025298632681
Trained batch 12 in epoch 1, gen_loss = 1.0542236474844127, disc_loss = 0.0016855331979548703
Trained batch 13 in epoch 1, gen_loss = 1.0489585442202431, disc_loss = 0.0017066187574528158
Trained batch 14 in epoch 1, gen_loss = 1.0543324828147889, disc_loss = 0.0017629200825467705
Trained batch 15 in epoch 1, gen_loss = 1.0492982678115368, disc_loss = 0.0017806783216656186
Trained batch 16 in epoch 1, gen_loss = 1.0464987369144665, disc_loss = 0.0017881868064732237
Trained batch 17 in epoch 1, gen_loss = 1.0493348009056516, disc_loss = 0.001792209617431379
Trained batch 18 in epoch 1, gen_loss = 1.0449742768940173, disc_loss = 0.0017943055503756593
Trained batch 19 in epoch 1, gen_loss = 1.0454041600227355, disc_loss = 0.001792482187738642
Trained batch 20 in epoch 1, gen_loss = 1.0470795517876035, disc_loss = 0.001777441462590581
Trained batch 21 in epoch 1, gen_loss = 1.043858059427955, disc_loss = 0.0017505835540677335
Trained batch 22 in epoch 1, gen_loss = 1.0423206997954326, disc_loss = 0.001735087549921287
Trained batch 23 in epoch 1, gen_loss = 1.0394193157553673, disc_loss = 0.0017306213509679462
Trained batch 24 in epoch 1, gen_loss = 1.0440027546882629, disc_loss = 0.0017337827384471894
Trained batch 25 in epoch 1, gen_loss = 1.0452977808622212, disc_loss = 0.0017092426603015226
Trained batch 26 in epoch 1, gen_loss = 1.0435446633232965, disc_loss = 0.001676458990442808
Trained batch 27 in epoch 1, gen_loss = 1.0435599769864763, disc_loss = 0.001648787161684595
Trained batch 28 in epoch 1, gen_loss = 1.0435661776312466, disc_loss = 0.0016167478310747136
Trained batch 29 in epoch 1, gen_loss = 1.0425105412801108, disc_loss = 0.001593285839771852
Trained batch 30 in epoch 1, gen_loss = 1.0405469786736272, disc_loss = 0.0015732341675057768
Trained batch 31 in epoch 1, gen_loss = 1.0402944758534431, disc_loss = 0.0015509238000959158
Trained batch 32 in epoch 1, gen_loss = 1.0480332446820808, disc_loss = 0.0015728007719823809
Trained batch 33 in epoch 1, gen_loss = 1.0497642439954422, disc_loss = 0.0015926865915603498
Trained batch 34 in epoch 1, gen_loss = 1.0529834236417497, disc_loss = 0.0016553800353514296
Trained batch 35 in epoch 1, gen_loss = 1.052855243285497, disc_loss = 0.0017585089857069154
Trained batch 36 in epoch 1, gen_loss = 1.0549447536468506, disc_loss = 0.0018466667058198033
Trained batch 37 in epoch 1, gen_loss = 1.0568402629149587, disc_loss = 0.0018767353306573472
Trained batch 38 in epoch 1, gen_loss = 1.0560248845662825, disc_loss = 0.0018824505297323833
Trained batch 39 in epoch 1, gen_loss = 1.054877158999443, disc_loss = 0.0018903506745118648
Trained batch 40 in epoch 1, gen_loss = 1.0541049620000327, disc_loss = 0.0018875512930496437
Trained batch 41 in epoch 1, gen_loss = 1.0532150949750627, disc_loss = 0.0018838358422120411
Trained batch 42 in epoch 1, gen_loss = 1.050845721433329, disc_loss = 0.0018899844537034285
Trained batch 43 in epoch 1, gen_loss = 1.0502407970753582, disc_loss = 0.0018803525440902872
Trained batch 44 in epoch 1, gen_loss = 1.0515069895320468, disc_loss = 0.001860792681367861
Trained batch 45 in epoch 1, gen_loss = 1.0518442405306774, disc_loss = 0.001838700544676217
Trained batch 46 in epoch 1, gen_loss = 1.0513672562355691, disc_loss = 0.0018224393963774152
Trained batch 47 in epoch 1, gen_loss = 1.0502423122525215, disc_loss = 0.0018168830865761265
Trained batch 48 in epoch 1, gen_loss = 1.0484006550847267, disc_loss = 0.0018112000543624163
Trained batch 49 in epoch 1, gen_loss = 1.05007239818573, disc_loss = 0.0018070176150649785
Trained batch 50 in epoch 1, gen_loss = 1.0505041982613357, disc_loss = 0.0018122249611598603
Trained batch 51 in epoch 1, gen_loss = 1.049930093380121, disc_loss = 0.0018073588547010261
Trained batch 52 in epoch 1, gen_loss = 1.0502403524686705, disc_loss = 0.0017951998227047471
Trained batch 53 in epoch 1, gen_loss = 1.0500035683314006, disc_loss = 0.0017845797723297168
Trained batch 54 in epoch 1, gen_loss = 1.0486685341054742, disc_loss = 0.001772432422942736
Trained batch 55 in epoch 1, gen_loss = 1.0493909801755632, disc_loss = 0.001758441426708097
Trained batch 56 in epoch 1, gen_loss = 1.0488214241830927, disc_loss = 0.0017513539539976862
Trained batch 57 in epoch 1, gen_loss = 1.0491420071700523, disc_loss = 0.0017645870644502856
Trained batch 58 in epoch 1, gen_loss = 1.0494013964119604, disc_loss = 0.0017726684908650943
Trained batch 59 in epoch 1, gen_loss = 1.049229637781779, disc_loss = 0.001770524236295993
Trained batch 60 in epoch 1, gen_loss = 1.0489601463568015, disc_loss = 0.001763787803805021
Trained batch 61 in epoch 1, gen_loss = 1.049001182279279, disc_loss = 0.0017546587698762455
Trained batch 62 in epoch 1, gen_loss = 1.0485674578046043, disc_loss = 0.0017453015482585346
Trained batch 63 in epoch 1, gen_loss = 1.0504571851342916, disc_loss = 0.0017470064831286436
Trained batch 64 in epoch 1, gen_loss = 1.0514087768701406, disc_loss = 0.0017483404604718088
Trained batch 65 in epoch 1, gen_loss = 1.0516794396169258, disc_loss = 0.0017420852144079452
Trained batch 66 in epoch 1, gen_loss = 1.0520556738127524, disc_loss = 0.0017332673583652324
Trained batch 67 in epoch 1, gen_loss = 1.0514122493126814, disc_loss = 0.001720044925391181
Trained batch 68 in epoch 1, gen_loss = 1.0506725604983345, disc_loss = 0.0017074157004717035
Trained batch 69 in epoch 1, gen_loss = 1.050279222215925, disc_loss = 0.0016942187511761273
Trained batch 70 in epoch 1, gen_loss = 1.050269815283762, disc_loss = 0.0016823831181579701
Trained batch 71 in epoch 1, gen_loss = 1.0494138739175267, disc_loss = 0.0016724845837517125
Trained batch 72 in epoch 1, gen_loss = 1.0498363391993797, disc_loss = 0.0016652591612623775
Trained batch 73 in epoch 1, gen_loss = 1.048069701806919, disc_loss = 0.0016577149996206768
Trained batch 74 in epoch 1, gen_loss = 1.0470189213752747, disc_loss = 0.0016488139952222506
Trained batch 75 in epoch 1, gen_loss = 1.0472777587802786, disc_loss = 0.0016384168074613339
Trained batch 76 in epoch 1, gen_loss = 1.046808982050264, disc_loss = 0.0016276850251710745
Trained batch 77 in epoch 1, gen_loss = 1.0460811876333678, disc_loss = 0.0016167322927429222
Trained batch 78 in epoch 1, gen_loss = 1.0462969760351544, disc_loss = 0.001607234029783101
Trained batch 79 in epoch 1, gen_loss = 1.0471007235348224, disc_loss = 0.0015989842337148729
Trained batch 80 in epoch 1, gen_loss = 1.0474078898076657, disc_loss = 0.0015921963538319149
Trained batch 81 in epoch 1, gen_loss = 1.0471536902392782, disc_loss = 0.00158368946811207
Trained batch 82 in epoch 1, gen_loss = 1.0468360724219357, disc_loss = 0.0015748056403574455
Trained batch 83 in epoch 1, gen_loss = 1.0477931478193827, disc_loss = 0.0015699142407226776
Trained batch 84 in epoch 1, gen_loss = 1.0488478835891275, disc_loss = 0.0015754822203341652
Trained batch 85 in epoch 1, gen_loss = 1.0492354250231455, disc_loss = 0.001596373822648338
Trained batch 86 in epoch 1, gen_loss = 1.0497501081433789, disc_loss = 0.0016137871586171717
Trained batch 87 in epoch 1, gen_loss = 1.0503651262684301, disc_loss = 0.0016313816251402552
Trained batch 88 in epoch 1, gen_loss = 1.0497381914867443, disc_loss = 0.0016446804857990715
Trained batch 89 in epoch 1, gen_loss = 1.0487921092245314, disc_loss = 0.0016475870312812428
Trained batch 90 in epoch 1, gen_loss = 1.048498844052409, disc_loss = 0.0016428444107257566
Trained batch 91 in epoch 1, gen_loss = 1.0495103468065676, disc_loss = 0.0016368818456691731
Trained batch 92 in epoch 1, gen_loss = 1.0493917529300978, disc_loss = 0.001629970026432827
Trained batch 93 in epoch 1, gen_loss = 1.049093486146724, disc_loss = 0.0016235386942850148
Trained batch 94 in epoch 1, gen_loss = 1.0495255382437454, disc_loss = 0.0016183124561058848
Trained batch 95 in epoch 1, gen_loss = 1.0491602905094624, disc_loss = 0.0016132755869572672
Trained batch 96 in epoch 1, gen_loss = 1.0491218493156826, disc_loss = 0.0016082420167465186
Trained batch 97 in epoch 1, gen_loss = 1.0493207354934848, disc_loss = 0.0016022316840648347
Trained batch 98 in epoch 1, gen_loss = 1.0488841617950286, disc_loss = 0.0015958211116605635
Trained batch 99 in epoch 1, gen_loss = 1.0490597069263459, disc_loss = 0.001588463542284444
Trained batch 100 in epoch 1, gen_loss = 1.0486138244666676, disc_loss = 0.0015874962463034408
Trained batch 101 in epoch 1, gen_loss = 1.0478948454062145, disc_loss = 0.0015884130181945569
Trained batch 102 in epoch 1, gen_loss = 1.0474275923469691, disc_loss = 0.0015907666489970193
Trained batch 103 in epoch 1, gen_loss = 1.047099569096015, disc_loss = 0.0015926619917781164
Trained batch 104 in epoch 1, gen_loss = 1.0468454196339563, disc_loss = 0.0015924206447033656
Trained batch 105 in epoch 1, gen_loss = 1.045983854892119, disc_loss = 0.0015925524332384877
Trained batch 106 in epoch 1, gen_loss = 1.0458441343262932, disc_loss = 0.0015922068633469884
Trained batch 107 in epoch 1, gen_loss = 1.0465287030846984, disc_loss = 0.0015899461825567953
Trained batch 108 in epoch 1, gen_loss = 1.0459476211749086, disc_loss = 0.0015890009823007459
Trained batch 109 in epoch 1, gen_loss = 1.045752399076115, disc_loss = 0.001593753271101212
Trained batch 110 in epoch 1, gen_loss = 1.0461567194612176, disc_loss = 0.0015956545101797528
Trained batch 111 in epoch 1, gen_loss = 1.0455061489982265, disc_loss = 0.0015949105644332512
Trained batch 112 in epoch 1, gen_loss = 1.045111451001294, disc_loss = 0.0015921884513072735
Trained batch 113 in epoch 1, gen_loss = 1.0452443920729453, disc_loss = 0.0015885721169118035
Trained batch 114 in epoch 1, gen_loss = 1.044561052840689, disc_loss = 0.0015865377444045051
Trained batch 115 in epoch 1, gen_loss = 1.0454649899540276, disc_loss = 0.0015889327674060419
Trained batch 116 in epoch 1, gen_loss = 1.0461312945072467, disc_loss = 0.0015932343448472456
Trained batch 117 in epoch 1, gen_loss = 1.0459093739420682, disc_loss = 0.0015900244441088606
Trained batch 118 in epoch 1, gen_loss = 1.045735234472932, disc_loss = 0.0015834026476916146
Trained batch 119 in epoch 1, gen_loss = 1.0449532672762871, disc_loss = 0.0015785050888856252
Trained batch 120 in epoch 1, gen_loss = 1.044616944041134, disc_loss = 0.001572204498316292
Trained batch 121 in epoch 1, gen_loss = 1.044953816738285, disc_loss = 0.0015673324266318842
Trained batch 122 in epoch 1, gen_loss = 1.0449435735136512, disc_loss = 0.0015640996024580446
Trained batch 123 in epoch 1, gen_loss = 1.0456205082516516, disc_loss = 0.0015626915861033804
Trained batch 124 in epoch 1, gen_loss = 1.0454874358177184, disc_loss = 0.0015616252585314214
Trained batch 125 in epoch 1, gen_loss = 1.045862505833308, disc_loss = 0.0015613674098396645
Trained batch 126 in epoch 1, gen_loss = 1.0454695637770526, disc_loss = 0.0015597310917283313
Trained batch 127 in epoch 1, gen_loss = 1.0454042879864573, disc_loss = 0.0015590338111906021
Trained batch 128 in epoch 1, gen_loss = 1.0448570126710937, disc_loss = 0.0015625067649936203
Trained batch 129 in epoch 1, gen_loss = 1.0449384107039525, disc_loss = 0.00156490966059769
Trained batch 130 in epoch 1, gen_loss = 1.0450811518057612, disc_loss = 0.0015637826868546202
Trained batch 131 in epoch 1, gen_loss = 1.0454657967343475, disc_loss = 0.00156255602566737
Trained batch 132 in epoch 1, gen_loss = 1.0455687122237414, disc_loss = 0.0015608097747829568
Trained batch 133 in epoch 1, gen_loss = 1.0447230192262735, disc_loss = 0.0015631009257266492
Trained batch 134 in epoch 1, gen_loss = 1.0443968432920951, disc_loss = 0.0015725100546626857
Trained batch 135 in epoch 1, gen_loss = 1.0442589508259998, disc_loss = 0.0015778681755524732
Trained batch 136 in epoch 1, gen_loss = 1.0448873273647614, disc_loss = 0.0015818179482220245
Trained batch 137 in epoch 1, gen_loss = 1.0450464992419533, disc_loss = 0.0015803949364994153
Trained batch 138 in epoch 1, gen_loss = 1.0447013163738113, disc_loss = 0.0015763502476716803
Trained batch 139 in epoch 1, gen_loss = 1.0440262121813637, disc_loss = 0.0015728312315851716
Trained batch 140 in epoch 1, gen_loss = 1.043142834876446, disc_loss = 0.0015670754703204313
Trained batch 141 in epoch 1, gen_loss = 1.0435269437205623, disc_loss = 0.001564488957331083
Trained batch 142 in epoch 1, gen_loss = 1.0436964139238105, disc_loss = 0.0015655897921635084
Trained batch 143 in epoch 1, gen_loss = 1.0431880011326737, disc_loss = 0.0015668722638414085
Trained batch 144 in epoch 1, gen_loss = 1.0431562830661905, disc_loss = 0.0015667373206113176
Trained batch 145 in epoch 1, gen_loss = 1.0431279184883588, disc_loss = 0.0015654831463694317
Trained batch 146 in epoch 1, gen_loss = 1.0424137703415488, disc_loss = 0.00156605094837557
Trained batch 147 in epoch 1, gen_loss = 1.0425600655175544, disc_loss = 0.0015665984793559874
Trained batch 148 in epoch 1, gen_loss = 1.0426334882742607, disc_loss = 0.0015663228028191367
Trained batch 149 in epoch 1, gen_loss = 1.0425155635674794, disc_loss = 0.0015671332456016292
Trained batch 150 in epoch 1, gen_loss = 1.0422846477552754, disc_loss = 0.0015657760017082736
Trained batch 151 in epoch 1, gen_loss = 1.042273236340598, disc_loss = 0.0015628483926871251
Trained batch 152 in epoch 1, gen_loss = 1.0422582599072674, disc_loss = 0.001561210493426283
Trained batch 153 in epoch 1, gen_loss = 1.0420698078421804, disc_loss = 0.0015611059358192293
Trained batch 154 in epoch 1, gen_loss = 1.0417591664098924, disc_loss = 0.0015602034437770566
Trained batch 155 in epoch 1, gen_loss = 1.0416721533506343, disc_loss = 0.0015598433849682363
Trained batch 156 in epoch 1, gen_loss = 1.0421832913805724, disc_loss = 0.0015591496885694848
Trained batch 157 in epoch 1, gen_loss = 1.0420472305032271, disc_loss = 0.001557293569424508
Trained batch 158 in epoch 1, gen_loss = 1.0421303233260628, disc_loss = 0.001557200959277392
Trained batch 159 in epoch 1, gen_loss = 1.042168527841568, disc_loss = 0.0015574097345961492
Trained batch 160 in epoch 1, gen_loss = 1.0419370735654179, disc_loss = 0.0015564902084706038
Trained batch 161 in epoch 1, gen_loss = 1.04195237159729, disc_loss = 0.0015557721572680928
Trained batch 162 in epoch 1, gen_loss = 1.0420593462107373, disc_loss = 0.001557108522978457
Trained batch 163 in epoch 1, gen_loss = 1.0421928421753208, disc_loss = 0.0015581720966487986
Trained batch 164 in epoch 1, gen_loss = 1.042551300019929, disc_loss = 0.001560407796183206
Trained batch 165 in epoch 1, gen_loss = 1.043127982013197, disc_loss = 0.0015628778916385293
Trained batch 166 in epoch 1, gen_loss = 1.0431762376945175, disc_loss = 0.001561858253149193
Trained batch 167 in epoch 1, gen_loss = 1.042608804291203, disc_loss = 0.001561875048667259
Trained batch 168 in epoch 1, gen_loss = 1.04287418917086, disc_loss = 0.0015692826806148789
Trained batch 169 in epoch 1, gen_loss = 1.0429000500370473, disc_loss = 0.0015811202482676461
Trained batch 170 in epoch 1, gen_loss = 1.0427499636572006, disc_loss = 0.0015890321987735553
Trained batch 171 in epoch 1, gen_loss = 1.043232383769612, disc_loss = 0.0015909868115857027
Trained batch 172 in epoch 1, gen_loss = 1.0434266842169568, disc_loss = 0.0015899464471206457
Trained batch 173 in epoch 1, gen_loss = 1.0433777252147938, disc_loss = 0.001587329191174465
Trained batch 174 in epoch 1, gen_loss = 1.0434292640004839, disc_loss = 0.0015838201373948582
Trained batch 175 in epoch 1, gen_loss = 1.0429484911940314, disc_loss = 0.0015805089685520877
Trained batch 176 in epoch 1, gen_loss = 1.042548572613021, disc_loss = 0.001578704042604856
Trained batch 177 in epoch 1, gen_loss = 1.0427065407961942, disc_loss = 0.001576346228503507
Trained batch 178 in epoch 1, gen_loss = 1.0426096633159914, disc_loss = 0.00157299285491814
Trained batch 179 in epoch 1, gen_loss = 1.0427635196182463, disc_loss = 0.0015686162149197319
Trained batch 180 in epoch 1, gen_loss = 1.0423740876313732, disc_loss = 0.0015652049348936596
Trained batch 181 in epoch 1, gen_loss = 1.0424479157715054, disc_loss = 0.0015619579673192086
Trained batch 182 in epoch 1, gen_loss = 1.042919061548723, disc_loss = 0.0015592280351633175
Trained batch 183 in epoch 1, gen_loss = 1.0432768234092256, disc_loss = 0.0015554643500565915
Trained batch 184 in epoch 1, gen_loss = 1.0433045828664624, disc_loss = 0.001551303471048438
Trained batch 185 in epoch 1, gen_loss = 1.0433529721152397, disc_loss = 0.0015474403657579935
Trained batch 186 in epoch 1, gen_loss = 1.0431942936570886, disc_loss = 0.0015447675300273985
Trained batch 187 in epoch 1, gen_loss = 1.0429119382132874, disc_loss = 0.0015425883292993331
Trained batch 188 in epoch 1, gen_loss = 1.043232436848696, disc_loss = 0.0015409587015195814
Trained batch 189 in epoch 1, gen_loss = 1.0432892419789968, disc_loss = 0.0015384122263640166
Trained batch 190 in epoch 1, gen_loss = 1.0433022049085008, disc_loss = 0.001534387018258503
Trained batch 191 in epoch 1, gen_loss = 1.043190438610812, disc_loss = 0.0015310766696832918
Trained batch 192 in epoch 1, gen_loss = 1.0433160594707944, disc_loss = 0.0015282024206579156
Trained batch 193 in epoch 1, gen_loss = 1.0436410304811812, disc_loss = 0.0015247567168547359
Trained batch 194 in epoch 1, gen_loss = 1.0438568857999948, disc_loss = 0.0015233394645082837
Trained batch 195 in epoch 1, gen_loss = 1.043769165265317, disc_loss = 0.0015206862521970797
Trained batch 196 in epoch 1, gen_loss = 1.043354996267309, disc_loss = 0.0015181415660547916
Trained batch 197 in epoch 1, gen_loss = 1.0429321084961747, disc_loss = 0.0015159986464593634
Trained batch 198 in epoch 1, gen_loss = 1.0432395009539235, disc_loss = 0.0015154538659177645
Trained batch 199 in epoch 1, gen_loss = 1.0431253072619437, disc_loss = 0.0015152317265165038
Trained batch 200 in epoch 1, gen_loss = 1.0424961231241179, disc_loss = 0.0015158395132916372
Trained batch 201 in epoch 1, gen_loss = 1.0423860496813708, disc_loss = 0.0015146093628032704
Trained batch 202 in epoch 1, gen_loss = 1.0422364226702987, disc_loss = 0.0015109807319980426
Trained batch 203 in epoch 1, gen_loss = 1.042228091581195, disc_loss = 0.0015073990013893218
Trained batch 204 in epoch 1, gen_loss = 1.0422751961684809, disc_loss = 0.0015042082392383459
Trained batch 205 in epoch 1, gen_loss = 1.042036307089537, disc_loss = 0.0015015424163085274
Trained batch 206 in epoch 1, gen_loss = 1.0419968314792798, disc_loss = 0.0014987384168215203
Trained batch 207 in epoch 1, gen_loss = 1.0418102867328203, disc_loss = 0.0014966403306551422
Trained batch 208 in epoch 1, gen_loss = 1.0418116629979257, disc_loss = 0.0014945317441864947
Trained batch 209 in epoch 1, gen_loss = 1.0418052043233599, disc_loss = 0.001491400992519976
Trained batch 210 in epoch 1, gen_loss = 1.0422168472931848, disc_loss = 0.0014890143443649344
Trained batch 211 in epoch 1, gen_loss = 1.0421190104394589, disc_loss = 0.0014861196321808681
Trained batch 212 in epoch 1, gen_loss = 1.0422442586209293, disc_loss = 0.0014842586729024044
Trained batch 213 in epoch 1, gen_loss = 1.0426653846402034, disc_loss = 0.0014832575120593237
Trained batch 214 in epoch 1, gen_loss = 1.04236469934153, disc_loss = 0.0014818719325608812
Trained batch 215 in epoch 1, gen_loss = 1.0423290288006817, disc_loss = 0.001481667615600465
Trained batch 216 in epoch 1, gen_loss = 1.0424774192994641, disc_loss = 0.0014805010713589664
Trained batch 217 in epoch 1, gen_loss = 1.0425236110293536, disc_loss = 0.0014785984517694578
Trained batch 218 in epoch 1, gen_loss = 1.042587467524559, disc_loss = 0.0014794397263013712
Trained batch 219 in epoch 1, gen_loss = 1.0426454262299971, disc_loss = 0.001477052985732867
Trained batch 220 in epoch 1, gen_loss = 1.042632042552551, disc_loss = 0.0014745913639799503
Trained batch 221 in epoch 1, gen_loss = 1.0427731297037623, disc_loss = 0.0014729583295070574
Trained batch 222 in epoch 1, gen_loss = 1.0425902225511492, disc_loss = 0.0014717026896599362
Trained batch 223 in epoch 1, gen_loss = 1.042617448738643, disc_loss = 0.0014723085493772356
Trained batch 224 in epoch 1, gen_loss = 1.042628583908081, disc_loss = 0.0014726206127347217
Trained batch 225 in epoch 1, gen_loss = 1.0427072243352906, disc_loss = 0.0014730085097500577
Trained batch 226 in epoch 1, gen_loss = 1.0429515150675164, disc_loss = 0.0014729246728959193
Trained batch 227 in epoch 1, gen_loss = 1.0431996698965107, disc_loss = 0.0014715323300231575
Trained batch 228 in epoch 1, gen_loss = 1.0428420929929576, disc_loss = 0.0014701822587577667
Trained batch 229 in epoch 1, gen_loss = 1.0429779638414798, disc_loss = 0.0014697243591122653
Trained batch 230 in epoch 1, gen_loss = 1.0428946941961974, disc_loss = 0.0014678942930614535
Trained batch 231 in epoch 1, gen_loss = 1.0426343807886387, disc_loss = 0.0014651810453305471
Trained batch 232 in epoch 1, gen_loss = 1.0426593711959447, disc_loss = 0.0014616403281049156
Trained batch 233 in epoch 1, gen_loss = 1.042158912644427, disc_loss = 0.0014589423359507043
Trained batch 234 in epoch 1, gen_loss = 1.042337086606533, disc_loss = 0.0014564364645729198
Trained batch 235 in epoch 1, gen_loss = 1.0425050498570425, disc_loss = 0.001453502871484843
Trained batch 236 in epoch 1, gen_loss = 1.0423468917231016, disc_loss = 0.0014502557747572942
Trained batch 237 in epoch 1, gen_loss = 1.0421535763419976, disc_loss = 0.0014472924991698638
Trained batch 238 in epoch 1, gen_loss = 1.0421024800344492, disc_loss = 0.00144475457798222
Trained batch 239 in epoch 1, gen_loss = 1.0420903687675793, disc_loss = 0.00144155618691002
Trained batch 240 in epoch 1, gen_loss = 1.0419653466133656, disc_loss = 0.001438087109656023
Trained batch 241 in epoch 1, gen_loss = 1.0418343529228336, disc_loss = 0.0014345373870316154
Trained batch 242 in epoch 1, gen_loss = 1.0419678472197105, disc_loss = 0.0014316381059238236
Trained batch 243 in epoch 1, gen_loss = 1.041964612046226, disc_loss = 0.001429187166351886
Trained batch 244 in epoch 1, gen_loss = 1.0419375166601064, disc_loss = 0.0014270551110693844
Trained batch 245 in epoch 1, gen_loss = 1.0417156771915714, disc_loss = 0.0014248848937705493
Trained batch 246 in epoch 1, gen_loss = 1.041512037578382, disc_loss = 0.0014234835162724893
Trained batch 247 in epoch 1, gen_loss = 1.0417161184933879, disc_loss = 0.0014228532388862673
Trained batch 248 in epoch 1, gen_loss = 1.041681394040824, disc_loss = 0.0014218292229464765
Trained batch 249 in epoch 1, gen_loss = 1.0417433266639708, disc_loss = 0.0014200561323668807
Trained batch 250 in epoch 1, gen_loss = 1.0418051253276992, disc_loss = 0.0014182043988146334
Trained batch 251 in epoch 1, gen_loss = 1.041584255676421, disc_loss = 0.001416797759399439
Trained batch 252 in epoch 1, gen_loss = 1.0418775548105654, disc_loss = 0.0014148837780458448
Trained batch 253 in epoch 1, gen_loss = 1.0421263453528637, disc_loss = 0.0014157451743784352
Trained batch 254 in epoch 1, gen_loss = 1.0420803289787441, disc_loss = 0.00141582696757955
Trained batch 255 in epoch 1, gen_loss = 1.0419883518479764, disc_loss = 0.00141644008658659
Trained batch 256 in epoch 1, gen_loss = 1.0421348230384204, disc_loss = 0.0014176965640868688
Trained batch 257 in epoch 1, gen_loss = 1.0421096927435822, disc_loss = 0.001422149734977676
Trained batch 258 in epoch 1, gen_loss = 1.04224283906944, disc_loss = 0.0014298444195348467
Trained batch 259 in epoch 1, gen_loss = 1.0422802842580354, disc_loss = 0.0014363165373931855
Trained batch 260 in epoch 1, gen_loss = 1.042250335901633, disc_loss = 0.0014388835509450415
Trained batch 261 in epoch 1, gen_loss = 1.0423338012840913, disc_loss = 0.0014386990630576202
Trained batch 262 in epoch 1, gen_loss = 1.0424242146568152, disc_loss = 0.0014373050285981324
Trained batch 263 in epoch 1, gen_loss = 1.0421584047602885, disc_loss = 0.0014349337352817229
Trained batch 264 in epoch 1, gen_loss = 1.0422260561079348, disc_loss = 0.0014328403940933915
Trained batch 265 in epoch 1, gen_loss = 1.0419165929009144, disc_loss = 0.0014299889787930042
Trained batch 266 in epoch 1, gen_loss = 1.042024312617627, disc_loss = 0.0014280105855103149
Trained batch 267 in epoch 1, gen_loss = 1.0423224535006195, disc_loss = 0.0014265037987488947
Trained batch 268 in epoch 1, gen_loss = 1.0420826773218064, disc_loss = 0.001425097784984746
Trained batch 269 in epoch 1, gen_loss = 1.0420532400961275, disc_loss = 0.0014236339464938888
Trained batch 270 in epoch 1, gen_loss = 1.0422777529132323, disc_loss = 0.0014217175267090354
Trained batch 271 in epoch 1, gen_loss = 1.0421335011282389, disc_loss = 0.0014200098911019536
Trained batch 272 in epoch 1, gen_loss = 1.0425388915634854, disc_loss = 0.0014189583767075843
Trained batch 273 in epoch 1, gen_loss = 1.0424831677092252, disc_loss = 0.001417233133867016
Trained batch 274 in epoch 1, gen_loss = 1.042564822327007, disc_loss = 0.0014154649405232207
Trained batch 275 in epoch 1, gen_loss = 1.0424821642429933, disc_loss = 0.0014143588476514012
Trained batch 276 in epoch 1, gen_loss = 1.0422371320345771, disc_loss = 0.0014139846888108563
Trained batch 277 in epoch 1, gen_loss = 1.0421914256733955, disc_loss = 0.00141348735962847
Trained batch 278 in epoch 1, gen_loss = 1.042202329122892, disc_loss = 0.0014130581434445596
Trained batch 279 in epoch 1, gen_loss = 1.0419455119541714, disc_loss = 0.0014132397708765763
Trained batch 280 in epoch 1, gen_loss = 1.0415179697644243, disc_loss = 0.001413215360450111
Trained batch 281 in epoch 1, gen_loss = 1.0414756276506059, disc_loss = 0.0014127911828501242
Trained batch 282 in epoch 1, gen_loss = 1.0416718196953143, disc_loss = 0.0014115111030681
Trained batch 283 in epoch 1, gen_loss = 1.0415830051815007, disc_loss = 0.0014098383347720274
Trained batch 284 in epoch 1, gen_loss = 1.0417864763945863, disc_loss = 0.001408613622678738
Trained batch 285 in epoch 1, gen_loss = 1.041727569344994, disc_loss = 0.001406754508298672
Trained batch 286 in epoch 1, gen_loss = 1.0416263979486473, disc_loss = 0.0014052816876778153
Trained batch 287 in epoch 1, gen_loss = 1.0418153754952881, disc_loss = 0.0014041912686985193
Trained batch 288 in epoch 1, gen_loss = 1.041712489713847, disc_loss = 0.0014023446851767678
Trained batch 289 in epoch 1, gen_loss = 1.042108974580107, disc_loss = 0.001401109541846632
Trained batch 290 in epoch 1, gen_loss = 1.042466836901465, disc_loss = 0.0014004639479494893
Trained batch 291 in epoch 1, gen_loss = 1.042286729363546, disc_loss = 0.0013993051611142207
Trained batch 292 in epoch 1, gen_loss = 1.0422729194774563, disc_loss = 0.0013992601080635506
Trained batch 293 in epoch 1, gen_loss = 1.0420248585493386, disc_loss = 0.001400125432335043
Trained batch 294 in epoch 1, gen_loss = 1.0417001766673588, disc_loss = 0.0014015819889224939
Trained batch 295 in epoch 1, gen_loss = 1.0414438155051824, disc_loss = 0.0014035096458895635
Trained batch 296 in epoch 1, gen_loss = 1.0418021875599819, disc_loss = 0.0014054016253255584
Trained batch 297 in epoch 1, gen_loss = 1.041743752540358, disc_loss = 0.0014078622139309027
Trained batch 298 in epoch 1, gen_loss = 1.0419902893213124, disc_loss = 0.0014110637566286536
Trained batch 299 in epoch 1, gen_loss = 1.0417998816569647, disc_loss = 0.0014120604163811853
Trained batch 300 in epoch 1, gen_loss = 1.041416645644115, disc_loss = 0.0014125137374058762
Trained batch 301 in epoch 1, gen_loss = 1.041273266274408, disc_loss = 0.0014118883529036547
Trained batch 302 in epoch 1, gen_loss = 1.0412545097936499, disc_loss = 0.0014100768726331369
Trained batch 303 in epoch 1, gen_loss = 1.0413398946586407, disc_loss = 0.0014083119872099672
Trained batch 304 in epoch 1, gen_loss = 1.0412033495355826, disc_loss = 0.0014059772270304137
Trained batch 305 in epoch 1, gen_loss = 1.0410719868404414, disc_loss = 0.0014032030396705214
Trained batch 306 in epoch 1, gen_loss = 1.0408031435665168, disc_loss = 0.0014007045862383242
Trained batch 307 in epoch 1, gen_loss = 1.0403966702424086, disc_loss = 0.0013987724166575142
Trained batch 308 in epoch 1, gen_loss = 1.0401406708658707, disc_loss = 0.001397602428519393
Trained batch 309 in epoch 1, gen_loss = 1.0401172657166757, disc_loss = 0.0013974779048904536
Trained batch 310 in epoch 1, gen_loss = 1.0400459264252346, disc_loss = 0.0013979220904344004
Trained batch 311 in epoch 1, gen_loss = 1.0396728465954463, disc_loss = 0.0013982466715298449
Trained batch 312 in epoch 1, gen_loss = 1.0395282621200854, disc_loss = 0.001398291686897913
Trained batch 313 in epoch 1, gen_loss = 1.0395341458593963, disc_loss = 0.001397504890560036
Trained batch 314 in epoch 1, gen_loss = 1.0394117249382866, disc_loss = 0.0013961819942951911
Trained batch 315 in epoch 1, gen_loss = 1.0392423679557028, disc_loss = 0.0013941134970128254
Trained batch 316 in epoch 1, gen_loss = 1.038868571681555, disc_loss = 0.0013922383822941396
Trained batch 317 in epoch 1, gen_loss = 1.0389013601549018, disc_loss = 0.001390985366610119
Trained batch 318 in epoch 1, gen_loss = 1.0387897457822364, disc_loss = 0.001390138579325219
Trained batch 319 in epoch 1, gen_loss = 1.0390881408005952, disc_loss = 0.0013896902954002143
Trained batch 320 in epoch 1, gen_loss = 1.0392588421563123, disc_loss = 0.0013890638055332075
Trained batch 321 in epoch 1, gen_loss = 1.0389846805830178, disc_loss = 0.0013884593890285733
Trained batch 322 in epoch 1, gen_loss = 1.0391553745550268, disc_loss = 0.0013892503066749626
Trained batch 323 in epoch 1, gen_loss = 1.0391046035069007, disc_loss = 0.0013905917118263236
Trained batch 324 in epoch 1, gen_loss = 1.0392195886832016, disc_loss = 0.0013925414657793365
Trained batch 325 in epoch 1, gen_loss = 1.0393250005011179, disc_loss = 0.0013960154232157656
Trained batch 326 in epoch 1, gen_loss = 1.039161448996366, disc_loss = 0.0014005273616864184
Trained batch 327 in epoch 1, gen_loss = 1.0391198532973849, disc_loss = 0.0014059002757521074
Trained batch 328 in epoch 1, gen_loss = 1.0389378286422568, disc_loss = 0.0014106904366690564
Trained batch 329 in epoch 1, gen_loss = 1.039384877501112, disc_loss = 0.0014158838333308019
Trained batch 330 in epoch 1, gen_loss = 1.0393888397519322, disc_loss = 0.001419300969276476
Trained batch 331 in epoch 1, gen_loss = 1.0395811471235321, disc_loss = 0.0014210738699619535
Trained batch 332 in epoch 1, gen_loss = 1.0394695952489927, disc_loss = 0.0014198377470460695
Trained batch 333 in epoch 1, gen_loss = 1.039744230979931, disc_loss = 0.0014190868593746808
Trained batch 334 in epoch 1, gen_loss = 1.0400347199012985, disc_loss = 0.0014202675208755172
Trained batch 335 in epoch 1, gen_loss = 1.0400215183340369, disc_loss = 0.0014204921064360644
Trained batch 336 in epoch 1, gen_loss = 1.0402412511828392, disc_loss = 0.0014198416576635103
Trained batch 337 in epoch 1, gen_loss = 1.0402580751822545, disc_loss = 0.0014188852145325546
Trained batch 338 in epoch 1, gen_loss = 1.0401351516928996, disc_loss = 0.0014185240570521724
Trained batch 339 in epoch 1, gen_loss = 1.0398585899787791, disc_loss = 0.0014170386107734349
Trained batch 340 in epoch 1, gen_loss = 1.0396901458239625, disc_loss = 0.0014150515692021774
Trained batch 341 in epoch 1, gen_loss = 1.0397659053927975, disc_loss = 0.0014135338737403331
Trained batch 342 in epoch 1, gen_loss = 1.0395288170252874, disc_loss = 0.001413910123472083
Trained batch 343 in epoch 1, gen_loss = 1.0395179780763248, disc_loss = 0.0014147908823783943
Trained batch 344 in epoch 1, gen_loss = 1.0396405512008113, disc_loss = 0.0014139540812365063
Trained batch 345 in epoch 1, gen_loss = 1.0397276990330977, disc_loss = 0.0014126406307264925
Trained batch 346 in epoch 1, gen_loss = 1.0397479192324262, disc_loss = 0.0014121657053226073
Trained batch 347 in epoch 1, gen_loss = 1.039992619691224, disc_loss = 0.0014109878776388928
Trained batch 348 in epoch 1, gen_loss = 1.0399779202603336, disc_loss = 0.0014097113218985732
Trained batch 349 in epoch 1, gen_loss = 1.0398909427438463, disc_loss = 0.0014099606282876006
Trained batch 350 in epoch 1, gen_loss = 1.0398497528839654, disc_loss = 0.0014097752952364477
Trained batch 351 in epoch 1, gen_loss = 1.0399714496664025, disc_loss = 0.001408564296897649
Trained batch 352 in epoch 1, gen_loss = 1.0398816439315213, disc_loss = 0.0014066025843941436
Trained batch 353 in epoch 1, gen_loss = 1.0399971818183102, disc_loss = 0.0014048944024163913
Trained batch 354 in epoch 1, gen_loss = 1.0398917327464465, disc_loss = 0.0014049863314885699
Trained batch 355 in epoch 1, gen_loss = 1.0402861486994819, disc_loss = 0.001408409853426614
Trained batch 356 in epoch 1, gen_loss = 1.0401950922666812, disc_loss = 0.0014152980519782136
Trained batch 357 in epoch 1, gen_loss = 1.0399688790297374, disc_loss = 0.0014233378561437338
Trained batch 358 in epoch 1, gen_loss = 1.040082999424682, disc_loss = 0.0014265795030130443
Trained batch 359 in epoch 1, gen_loss = 1.0402566825350126, disc_loss = 0.0014263309793831366
Trained batch 360 in epoch 1, gen_loss = 1.0402362605871587, disc_loss = 0.0014247426510352508
Trained batch 361 in epoch 1, gen_loss = 1.0399167435603907, disc_loss = 0.0014238838660813745
Trained batch 362 in epoch 1, gen_loss = 1.0399501261303905, disc_loss = 0.001423301488243187
Trained batch 363 in epoch 1, gen_loss = 1.0399982428157724, disc_loss = 0.0014246225428695863
Trained batch 364 in epoch 1, gen_loss = 1.0399561362723782, disc_loss = 0.0014263563215324323
Trained batch 365 in epoch 1, gen_loss = 1.0397572838217835, disc_loss = 0.0014273548706134405
Trained batch 366 in epoch 1, gen_loss = 1.0396385991930637, disc_loss = 0.0014276881860848262
Trained batch 367 in epoch 1, gen_loss = 1.0394807885522428, disc_loss = 0.00142686239458904
Trained batch 368 in epoch 1, gen_loss = 1.0393865289403816, disc_loss = 0.0014251107865815786
Trained batch 369 in epoch 1, gen_loss = 1.0395855201257242, disc_loss = 0.001423062217843442
Trained batch 370 in epoch 1, gen_loss = 1.0393976291234923, disc_loss = 0.0014217872802680233
Trained batch 371 in epoch 1, gen_loss = 1.0393667461410645, disc_loss = 0.0014221827444490245
Trained batch 372 in epoch 1, gen_loss = 1.039201893691403, disc_loss = 0.0014236631039180481
Trained batch 373 in epoch 1, gen_loss = 1.0393160995952586, disc_loss = 0.0014262520247462758
Trained batch 374 in epoch 1, gen_loss = 1.0392708638509114, disc_loss = 0.0014284906834363938
Trained batch 375 in epoch 1, gen_loss = 1.0392602143135476, disc_loss = 0.0014286763641606778
Trained batch 376 in epoch 1, gen_loss = 1.0391953146426052, disc_loss = 0.0014274075543335009
Trained batch 377 in epoch 1, gen_loss = 1.03930334092448, disc_loss = 0.0014255412884435995
Trained batch 378 in epoch 1, gen_loss = 1.0391553715854334, disc_loss = 0.0014237168863646707
Trained batch 379 in epoch 1, gen_loss = 1.0392254098465568, disc_loss = 0.001421878736245593
Trained batch 380 in epoch 1, gen_loss = 1.0392070645735332, disc_loss = 0.0014199272952814955
Trained batch 381 in epoch 1, gen_loss = 1.039149865430063, disc_loss = 0.0014181630652402746
Trained batch 382 in epoch 1, gen_loss = 1.0391328714535069, disc_loss = 0.0014169160843530168
Trained batch 383 in epoch 1, gen_loss = 1.0389889360715945, disc_loss = 0.0014154290623385652
Trained batch 384 in epoch 1, gen_loss = 1.0390143208689504, disc_loss = 0.001413369470415032
Trained batch 385 in epoch 1, gen_loss = 1.0389215881342715, disc_loss = 0.001411052675883966
Trained batch 386 in epoch 1, gen_loss = 1.0390583547818877, disc_loss = 0.0014089497461438525
Trained batch 387 in epoch 1, gen_loss = 1.0390309267437334, disc_loss = 0.0014066997820693884
Trained batch 388 in epoch 1, gen_loss = 1.0387857285134283, disc_loss = 0.0014053096544059773
Trained batch 389 in epoch 1, gen_loss = 1.038773865577502, disc_loss = 0.0014050903556963954
Trained batch 390 in epoch 1, gen_loss = 1.039008242699801, disc_loss = 0.0014057515479047851
Trained batch 391 in epoch 1, gen_loss = 1.0390363131858864, disc_loss = 0.0014059444665504924
Trained batch 392 in epoch 1, gen_loss = 1.0388061933541723, disc_loss = 0.001406278442555882
Trained batch 393 in epoch 1, gen_loss = 1.03879931856533, disc_loss = 0.00140715593284204
Trained batch 394 in epoch 1, gen_loss = 1.0387447236459466, disc_loss = 0.001406416044971328
Trained batch 395 in epoch 1, gen_loss = 1.0387972813061994, disc_loss = 0.001405187708888946
Trained batch 396 in epoch 1, gen_loss = 1.0385714755851014, disc_loss = 0.0014040488296690437
Trained batch 397 in epoch 1, gen_loss = 1.0385463158389432, disc_loss = 0.0014031828337538537
Trained batch 398 in epoch 1, gen_loss = 1.038672459304781, disc_loss = 0.0014022629400820268
Trained batch 399 in epoch 1, gen_loss = 1.0386466737091542, disc_loss = 0.0014011821425810923
Trained batch 400 in epoch 1, gen_loss = 1.0388320608626578, disc_loss = 0.001400516572973907
Trained batch 401 in epoch 1, gen_loss = 1.0389060219425468, disc_loss = 0.0013989068041277578
Trained batch 402 in epoch 1, gen_loss = 1.038911785588371, disc_loss = 0.0013970574988029138
Trained batch 403 in epoch 1, gen_loss = 1.0389359774861004, disc_loss = 0.0013951330698132147
Trained batch 404 in epoch 1, gen_loss = 1.039003069754, disc_loss = 0.0013934422603428915
Trained batch 405 in epoch 1, gen_loss = 1.0388926942947463, disc_loss = 0.0013920515777114228
Trained batch 406 in epoch 1, gen_loss = 1.0389589452040575, disc_loss = 0.0013904241071007138
Trained batch 407 in epoch 1, gen_loss = 1.0391128253118664, disc_loss = 0.0013892107175813768
Trained batch 408 in epoch 1, gen_loss = 1.039004966507331, disc_loss = 0.0013878394082225038
Trained batch 409 in epoch 1, gen_loss = 1.0390098909052408, disc_loss = 0.0013868394509389452
Trained batch 410 in epoch 1, gen_loss = 1.0390180352250444, disc_loss = 0.0013857077224544926
Trained batch 411 in epoch 1, gen_loss = 1.0390203832422646, disc_loss = 0.0013848636475972632
Trained batch 412 in epoch 1, gen_loss = 1.0389760654717324, disc_loss = 0.0013836670575886694
Trained batch 413 in epoch 1, gen_loss = 1.0388471740455443, disc_loss = 0.0013818745747386312
Trained batch 414 in epoch 1, gen_loss = 1.0388459785875068, disc_loss = 0.0013803318451461662
Trained batch 415 in epoch 1, gen_loss = 1.0386847350746393, disc_loss = 0.0013790689362604797
Trained batch 416 in epoch 1, gen_loss = 1.0387162294605081, disc_loss = 0.0013784092463769591
Trained batch 417 in epoch 1, gen_loss = 1.0386718353301143, disc_loss = 0.0013779016197982142
Trained batch 418 in epoch 1, gen_loss = 1.0385558390389764, disc_loss = 0.0013771233920436931
Trained batch 419 in epoch 1, gen_loss = 1.0384838508708136, disc_loss = 0.0013755929837879237
Trained batch 420 in epoch 1, gen_loss = 1.038499646543607, disc_loss = 0.001373989308322614
Trained batch 421 in epoch 1, gen_loss = 1.0386972149118994, disc_loss = 0.0013725379429773044
Trained batch 422 in epoch 1, gen_loss = 1.03869705603196, disc_loss = 0.0013711103298712354
Trained batch 423 in epoch 1, gen_loss = 1.0385879861577503, disc_loss = 0.001369493362770574
Trained batch 424 in epoch 1, gen_loss = 1.038662216943853, disc_loss = 0.0013682877386043614
Trained batch 425 in epoch 1, gen_loss = 1.0387408345797813, disc_loss = 0.0013674128192046246
Trained batch 426 in epoch 1, gen_loss = 1.0385650985414028, disc_loss = 0.0013667296677385076
Trained batch 427 in epoch 1, gen_loss = 1.038699718836312, disc_loss = 0.0013656395935740704
Trained batch 428 in epoch 1, gen_loss = 1.0387906300160157, disc_loss = 0.0013646809452067896
Trained batch 429 in epoch 1, gen_loss = 1.038903198131295, disc_loss = 0.0013632002611492955
Trained batch 430 in epoch 1, gen_loss = 1.0389264708605277, disc_loss = 0.001361185928434998
Trained batch 431 in epoch 1, gen_loss = 1.0389309699336688, disc_loss = 0.0013590827646247042
Trained batch 432 in epoch 1, gen_loss = 1.0390915306280721, disc_loss = 0.001357160768483488
Trained batch 433 in epoch 1, gen_loss = 1.0391613857537372, disc_loss = 0.001355407788382826
Trained batch 434 in epoch 1, gen_loss = 1.0393904488662193, disc_loss = 0.0013536538381461354
Trained batch 435 in epoch 1, gen_loss = 1.0393774287963131, disc_loss = 0.0013519517369536306
Trained batch 436 in epoch 1, gen_loss = 1.0395078836371205, disc_loss = 0.0013504760355573548
Trained batch 437 in epoch 1, gen_loss = 1.0394537857134047, disc_loss = 0.0013494826923709227
Trained batch 438 in epoch 1, gen_loss = 1.039458706873153, disc_loss = 0.0013485558797469563
Trained batch 439 in epoch 1, gen_loss = 1.0393996951254931, disc_loss = 0.0013480372241412458
Trained batch 440 in epoch 1, gen_loss = 1.0394086186307359, disc_loss = 0.0013469617393832916
Trained batch 441 in epoch 1, gen_loss = 1.0394441091636726, disc_loss = 0.0013453619474570406
Trained batch 442 in epoch 1, gen_loss = 1.039418065251938, disc_loss = 0.001343770576909008
Trained batch 443 in epoch 1, gen_loss = 1.039588073620925, disc_loss = 0.0013426515257493636
Trained batch 444 in epoch 1, gen_loss = 1.0396298496910694, disc_loss = 0.0013417525090057445
Trained batch 445 in epoch 1, gen_loss = 1.0396133230940643, disc_loss = 0.001340350299429424
Trained batch 446 in epoch 1, gen_loss = 1.0396957682816508, disc_loss = 0.0013386908735271534
Trained batch 447 in epoch 1, gen_loss = 1.0394488639597381, disc_loss = 0.0013372299459401152
Trained batch 448 in epoch 1, gen_loss = 1.039486504875472, disc_loss = 0.0013363301559021585
Trained batch 449 in epoch 1, gen_loss = 1.0397686428493924, disc_loss = 0.0013370851587711109
Trained batch 450 in epoch 1, gen_loss = 1.0397282529564496, disc_loss = 0.0013376040863773543
Trained batch 451 in epoch 1, gen_loss = 1.0395750255711311, disc_loss = 0.0013381145614821597
Trained batch 452 in epoch 1, gen_loss = 1.0394865521795176, disc_loss = 0.0013386342750562078
Trained batch 453 in epoch 1, gen_loss = 1.0393815959602726, disc_loss = 0.0013384968178277007
Trained batch 454 in epoch 1, gen_loss = 1.039367628621531, disc_loss = 0.0013378802566676514
Trained batch 455 in epoch 1, gen_loss = 1.039483873990544, disc_loss = 0.0013366080110835466
Trained batch 456 in epoch 1, gen_loss = 1.039344604088389, disc_loss = 0.0013353211030311051
Trained batch 457 in epoch 1, gen_loss = 1.0394478886668859, disc_loss = 0.0013345857344030944
Trained batch 458 in epoch 1, gen_loss = 1.0396777935537118, disc_loss = 0.001333963183517728
Trained batch 459 in epoch 1, gen_loss = 1.0396358675282935, disc_loss = 0.0013325663959182312
Trained batch 460 in epoch 1, gen_loss = 1.039610896219142, disc_loss = 0.0013313236289784927
Trained batch 461 in epoch 1, gen_loss = 1.0392748856699312, disc_loss = 0.0013303426111991885
Trained batch 462 in epoch 1, gen_loss = 1.0390640717345747, disc_loss = 0.001329935773338149
Trained batch 463 in epoch 1, gen_loss = 1.039052173623751, disc_loss = 0.0013292588733622387
Trained batch 464 in epoch 1, gen_loss = 1.0393137812614441, disc_loss = 0.0013292794804319098
Trained batch 465 in epoch 1, gen_loss = 1.0392976770329374, disc_loss = 0.0013297906169436008
Trained batch 466 in epoch 1, gen_loss = 1.039407050711695, disc_loss = 0.001330672325297185
Trained batch 467 in epoch 1, gen_loss = 1.0394620911942587, disc_loss = 0.0013308533314121966
Trained batch 468 in epoch 1, gen_loss = 1.039611426879094, disc_loss = 0.0013304828702887174
Trained batch 469 in epoch 1, gen_loss = 1.0397850846990626, disc_loss = 0.001329381506459074
Trained batch 470 in epoch 1, gen_loss = 1.0397504493435983, disc_loss = 0.001328327002833279
Trained batch 471 in epoch 1, gen_loss = 1.039770567947525, disc_loss = 0.0013279311843088165
Trained batch 472 in epoch 1, gen_loss = 1.0398173013398813, disc_loss = 0.0013274041007678508
Trained batch 473 in epoch 1, gen_loss = 1.039858281486648, disc_loss = 0.0013269955167823908
Trained batch 474 in epoch 1, gen_loss = 1.0399484003217596, disc_loss = 0.0013269578769655997
Trained batch 475 in epoch 1, gen_loss = 1.0398916736119936, disc_loss = 0.0013269312177665391
Trained batch 476 in epoch 1, gen_loss = 1.0400196252628942, disc_loss = 0.0013267329177210024
Trained batch 477 in epoch 1, gen_loss = 1.0400521704093182, disc_loss = 0.0013263239299977844
Trained batch 478 in epoch 1, gen_loss = 1.0399185662976387, disc_loss = 0.001325819362708346
Trained batch 479 in epoch 1, gen_loss = 1.0397389635443688, disc_loss = 0.0013251157670310931
Trained batch 480 in epoch 1, gen_loss = 1.0396223234287667, disc_loss = 0.0013243135616905492
Trained batch 481 in epoch 1, gen_loss = 1.039646025020552, disc_loss = 0.0013231505470541673
Trained batch 482 in epoch 1, gen_loss = 1.0396254257632584, disc_loss = 0.0013217807499890449
Trained batch 483 in epoch 1, gen_loss = 1.0396442176881902, disc_loss = 0.0013202497210547959
Trained batch 484 in epoch 1, gen_loss = 1.0395678407138156, disc_loss = 0.0013187158887620208
Trained batch 485 in epoch 1, gen_loss = 1.0394890210265486, disc_loss = 0.0013171385655346337
Trained batch 486 in epoch 1, gen_loss = 1.0394898934530772, disc_loss = 0.0013158899539263127
Trained batch 487 in epoch 1, gen_loss = 1.039562987743831, disc_loss = 0.001314376791715851
Trained batch 488 in epoch 1, gen_loss = 1.0395873190191383, disc_loss = 0.0013126046308706723
Trained batch 489 in epoch 1, gen_loss = 1.0394274426966297, disc_loss = 0.0013111829615141057
Trained batch 490 in epoch 1, gen_loss = 1.0394158297789315, disc_loss = 0.0013099999210651198
Trained batch 491 in epoch 1, gen_loss = 1.0394815657196976, disc_loss = 0.0013089469127400544
Trained batch 492 in epoch 1, gen_loss = 1.0395759711642778, disc_loss = 0.0013078586093308764
Trained batch 493 in epoch 1, gen_loss = 1.0395119033361737, disc_loss = 0.0013072393295639818
Trained batch 494 in epoch 1, gen_loss = 1.0394159295342185, disc_loss = 0.0013072756440096506
Trained batch 495 in epoch 1, gen_loss = 1.0394771154369078, disc_loss = 0.0013074016330187255
Trained batch 496 in epoch 1, gen_loss = 1.039438993878048, disc_loss = 0.0013071724340849944
Trained batch 497 in epoch 1, gen_loss = 1.0394127524521457, disc_loss = 0.0013062990597593244
Trained batch 498 in epoch 1, gen_loss = 1.0394536574522335, disc_loss = 0.0013050383983603594
Trained batch 499 in epoch 1, gen_loss = 1.0392513942718506, disc_loss = 0.0013036282634129748
Trained batch 500 in epoch 1, gen_loss = 1.0392211635193662, disc_loss = 0.001302925596095458
Trained batch 501 in epoch 1, gen_loss = 1.0392085242556386, disc_loss = 0.0013027284484527322
Trained batch 502 in epoch 1, gen_loss = 1.039097523831468, disc_loss = 0.0013026042862667537
Trained batch 503 in epoch 1, gen_loss = 1.0391011900371976, disc_loss = 0.001301735499827561
Trained batch 504 in epoch 1, gen_loss = 1.0389313346088522, disc_loss = 0.0013005152332024779
Trained batch 505 in epoch 1, gen_loss = 1.0390068024043508, disc_loss = 0.0012989831919710082
Trained batch 506 in epoch 1, gen_loss = 1.038961396179726, disc_loss = 0.0012972953286631808
Trained batch 507 in epoch 1, gen_loss = 1.0389658538844642, disc_loss = 0.0012957686322326882
Trained batch 508 in epoch 1, gen_loss = 1.0389710416494045, disc_loss = 0.0012943267095870611
Trained batch 509 in epoch 1, gen_loss = 1.0388400128074722, disc_loss = 0.0012929618171434484
Trained batch 510 in epoch 1, gen_loss = 1.0389057634627983, disc_loss = 0.0012916673930296256
Trained batch 511 in epoch 1, gen_loss = 1.0389391992939636, disc_loss = 0.0012903580959573446
Trained batch 512 in epoch 1, gen_loss = 1.0386921574033028, disc_loss = 0.0012889307575049804
Trained batch 513 in epoch 1, gen_loss = 1.0388524235454515, disc_loss = 0.001287939830081617
Trained batch 514 in epoch 1, gen_loss = 1.0389235663182528, disc_loss = 0.0012875812539595714
Trained batch 515 in epoch 1, gen_loss = 1.0390469427256621, disc_loss = 0.0012885998871787487
Trained batch 516 in epoch 1, gen_loss = 1.0390312957579209, disc_loss = 0.0012902970233485392
Trained batch 517 in epoch 1, gen_loss = 1.0390945737426345, disc_loss = 0.001291565759544365
Trained batch 518 in epoch 1, gen_loss = 1.0390790303548176, disc_loss = 0.0012920860058461138
Trained batch 519 in epoch 1, gen_loss = 1.0390190775577839, disc_loss = 0.0012924797591180183
Trained batch 520 in epoch 1, gen_loss = 1.0391471516376722, disc_loss = 0.0012928434011245757
Trained batch 521 in epoch 1, gen_loss = 1.0391993598006237, disc_loss = 0.001292950628946225
Trained batch 522 in epoch 1, gen_loss = 1.039281523250485, disc_loss = 0.001292331607426458
Trained batch 523 in epoch 1, gen_loss = 1.0393047969759877, disc_loss = 0.0012909427855274007
Trained batch 524 in epoch 1, gen_loss = 1.039391196568807, disc_loss = 0.0012892645799798801
Trained batch 525 in epoch 1, gen_loss = 1.0394486492577615, disc_loss = 0.0012877991729209682
Trained batch 526 in epoch 1, gen_loss = 1.0397137172760502, disc_loss = 0.0012868606833678334
Trained batch 527 in epoch 1, gen_loss = 1.0398148183118214, disc_loss = 0.0012858555803563142
Trained batch 528 in epoch 1, gen_loss = 1.0398831491434282, disc_loss = 0.001285197833165199
Trained batch 529 in epoch 1, gen_loss = 1.0398515040019773, disc_loss = 0.0012843720098179854
Trained batch 530 in epoch 1, gen_loss = 1.0399861685973777, disc_loss = 0.0012843275407970253
Trained batch 531 in epoch 1, gen_loss = 1.0398637065313812, disc_loss = 0.0012849573884837686
Trained batch 532 in epoch 1, gen_loss = 1.0398231102870061, disc_loss = 0.0012859188325027805
Trained batch 533 in epoch 1, gen_loss = 1.0397579143109839, disc_loss = 0.0012868784861495258
Trained batch 534 in epoch 1, gen_loss = 1.0397300439460255, disc_loss = 0.0012871580443749745
Trained batch 535 in epoch 1, gen_loss = 1.0398654457348495, disc_loss = 0.0012866181843030552
Trained batch 536 in epoch 1, gen_loss = 1.0398515140988085, disc_loss = 0.0012853152540384912
Trained batch 537 in epoch 1, gen_loss = 1.0397870276940357, disc_loss = 0.0012839126793280776
Trained batch 538 in epoch 1, gen_loss = 1.039758968220571, disc_loss = 0.0012826777314607412
Trained batch 539 in epoch 1, gen_loss = 1.039655273380103, disc_loss = 0.0012815628743501966
Trained batch 540 in epoch 1, gen_loss = 1.0395763168273262, disc_loss = 0.001281138370663544
Trained batch 541 in epoch 1, gen_loss = 1.0396029712749144, disc_loss = 0.0012816352538512746
Trained batch 542 in epoch 1, gen_loss = 1.0396001037093596, disc_loss = 0.001282050533674256
Trained batch 543 in epoch 1, gen_loss = 1.039440650383339, disc_loss = 0.001282080959968238
Trained batch 544 in epoch 1, gen_loss = 1.0396650890691566, disc_loss = 0.0012817782052438023
Trained batch 545 in epoch 1, gen_loss = 1.0396938698414044, disc_loss = 0.0012802183146216658
Trained batch 546 in epoch 1, gen_loss = 1.039778935516992, disc_loss = 0.0012788438081564263
Trained batch 547 in epoch 1, gen_loss = 1.0395840200847082, disc_loss = 0.0012781959281763552
Trained batch 548 in epoch 1, gen_loss = 1.0394979779403284, disc_loss = 0.0012781253396889672
Trained batch 549 in epoch 1, gen_loss = 1.0393650775605983, disc_loss = 0.0012784094745504923
Trained batch 550 in epoch 1, gen_loss = 1.0393891110610616, disc_loss = 0.0012790760361951203
Trained batch 551 in epoch 1, gen_loss = 1.0393501305277797, disc_loss = 0.0012799940141385246
Trained batch 552 in epoch 1, gen_loss = 1.0393320398563501, disc_loss = 0.0012809492570388503
Trained batch 553 in epoch 1, gen_loss = 1.0392471176407398, disc_loss = 0.001281330353661948
Trained batch 554 in epoch 1, gen_loss = 1.0392905440416422, disc_loss = 0.0012809937460104691
Trained batch 555 in epoch 1, gen_loss = 1.0393671403042704, disc_loss = 0.0012800915184742335
Trained batch 556 in epoch 1, gen_loss = 1.039232946490899, disc_loss = 0.001278981200253835
Trained batch 557 in epoch 1, gen_loss = 1.0391342451922783, disc_loss = 0.0012783335201988018
Trained batch 558 in epoch 1, gen_loss = 1.0390541097132593, disc_loss = 0.0012777013759785174
Trained batch 559 in epoch 1, gen_loss = 1.0391173724617278, disc_loss = 0.0012769669297475568
Trained batch 560 in epoch 1, gen_loss = 1.039176930293255, disc_loss = 0.0012761482487701596
Trained batch 561 in epoch 1, gen_loss = 1.0391289774209156, disc_loss = 0.0012751679973771258
Trained batch 562 in epoch 1, gen_loss = 1.0392846800717748, disc_loss = 0.0012748690435148405
Trained batch 563 in epoch 1, gen_loss = 1.0393551209716931, disc_loss = 0.001276069990023211
Trained batch 564 in epoch 1, gen_loss = 1.039377800553246, disc_loss = 0.001278204962186746
Trained batch 565 in epoch 1, gen_loss = 1.0393162430807052, disc_loss = 0.0012794619290587613
Trained batch 566 in epoch 1, gen_loss = 1.0393223424016693, disc_loss = 0.0012797803012941631
Trained batch 567 in epoch 1, gen_loss = 1.039219277530489, disc_loss = 0.0012796888090825876
Trained batch 568 in epoch 1, gen_loss = 1.0389927855065921, disc_loss = 0.001279784371296471
Trained batch 569 in epoch 1, gen_loss = 1.0391133719368986, disc_loss = 0.0012798914627637713
Trained batch 570 in epoch 1, gen_loss = 1.0391351121319572, disc_loss = 0.0012793157842163577
Trained batch 571 in epoch 1, gen_loss = 1.0391313907775013, disc_loss = 0.0012783706420218454
Trained batch 572 in epoch 1, gen_loss = 1.0389747494802426, disc_loss = 0.0012774555529443381
Trained batch 573 in epoch 1, gen_loss = 1.038930126598903, disc_loss = 0.0012767394471837317
Trained batch 574 in epoch 1, gen_loss = 1.0389612778373387, disc_loss = 0.0012763651303501556
Trained batch 575 in epoch 1, gen_loss = 1.0390368913196855, disc_loss = 0.0012761033001677585
Trained batch 576 in epoch 1, gen_loss = 1.0390723867267628, disc_loss = 0.0012751073269633515
Trained batch 577 in epoch 1, gen_loss = 1.0390951724200925, disc_loss = 0.0012738692517203817
Trained batch 578 in epoch 1, gen_loss = 1.038984768645957, disc_loss = 0.0012729508684270908
Trained batch 579 in epoch 1, gen_loss = 1.0388313916222802, disc_loss = 0.0012723883391149214
Trained batch 580 in epoch 1, gen_loss = 1.0387918044285602, disc_loss = 0.0012722508406760283
Trained batch 581 in epoch 1, gen_loss = 1.0387211517779689, disc_loss = 0.0012714175416014232
Trained batch 582 in epoch 1, gen_loss = 1.0387148450210204, disc_loss = 0.0012699133457135135
Trained batch 583 in epoch 1, gen_loss = 1.0388191954730308, disc_loss = 0.0012688425413216464
Trained batch 584 in epoch 1, gen_loss = 1.0388220591422839, disc_loss = 0.001267972430632187
Trained batch 585 in epoch 1, gen_loss = 1.0387478407739372, disc_loss = 0.0012676848918906772
Trained batch 586 in epoch 1, gen_loss = 1.038765762693025, disc_loss = 0.0012676522969284128
Trained batch 587 in epoch 1, gen_loss = 1.0387245953893987, disc_loss = 0.0012674775095553562
Trained batch 588 in epoch 1, gen_loss = 1.0387384417911134, disc_loss = 0.0012670344300923873
Trained batch 589 in epoch 1, gen_loss = 1.0387415390903667, disc_loss = 0.001266798952503635
Trained batch 590 in epoch 1, gen_loss = 1.0387758335284574, disc_loss = 0.001266737893328556
Trained batch 591 in epoch 1, gen_loss = 1.0387076740530696, disc_loss = 0.0012667235566147389
Trained batch 592 in epoch 1, gen_loss = 1.0386681437090315, disc_loss = 0.001267007034696783
Trained batch 593 in epoch 1, gen_loss = 1.0387070091685864, disc_loss = 0.0012673073755349864
Trained batch 594 in epoch 1, gen_loss = 1.0387114533857138, disc_loss = 0.0012681709714977367
Trained batch 595 in epoch 1, gen_loss = 1.038709320177968, disc_loss = 0.0012694599911462728
Trained batch 596 in epoch 1, gen_loss = 1.0387886535981592, disc_loss = 0.001271676066915787
Trained batch 597 in epoch 1, gen_loss = 1.0388244754295286, disc_loss = 0.0012738840189415114
Trained batch 598 in epoch 1, gen_loss = 1.038829298867208, disc_loss = 0.001276020562639289
Trained batch 599 in epoch 1, gen_loss = 1.0387545707821846, disc_loss = 0.0012768094813024316
Trained batch 600 in epoch 1, gen_loss = 1.0385928734170022, disc_loss = 0.0012762686380064316
Trained batch 601 in epoch 1, gen_loss = 1.0385569491457702, disc_loss = 0.0012755786674793351
Trained batch 602 in epoch 1, gen_loss = 1.0384350021680195, disc_loss = 0.0012754315595724813
Trained batch 603 in epoch 1, gen_loss = 1.0384278191833307, disc_loss = 0.0012753570769583522
Trained batch 604 in epoch 1, gen_loss = 1.0384095088509488, disc_loss = 0.0012747493945831849
Trained batch 605 in epoch 1, gen_loss = 1.0384349892831872, disc_loss = 0.001274011002372483
Trained batch 606 in epoch 1, gen_loss = 1.038421644901326, disc_loss = 0.0012730490236007646
Trained batch 607 in epoch 1, gen_loss = 1.038384483735028, disc_loss = 0.0012722195690577408
Trained batch 608 in epoch 1, gen_loss = 1.0386454220280075, disc_loss = 0.0012725637766895035
Trained batch 609 in epoch 1, gen_loss = 1.0386617647819831, disc_loss = 0.0012771078347243736
Trained batch 610 in epoch 1, gen_loss = 1.0385768890575964, disc_loss = 0.0012853133207135232
Trained batch 611 in epoch 1, gen_loss = 1.0386744052950854, disc_loss = 0.0012896720173896528
Trained batch 612 in epoch 1, gen_loss = 1.0386799473746955, disc_loss = 0.0012902099159462636
Trained batch 613 in epoch 1, gen_loss = 1.0386736601688187, disc_loss = 0.0012898468251297621
Trained batch 614 in epoch 1, gen_loss = 1.038745878479345, disc_loss = 0.0012891924066461501
Trained batch 615 in epoch 1, gen_loss = 1.0385924060042802, disc_loss = 0.0012883769889519394
Trained batch 616 in epoch 1, gen_loss = 1.0387720780589011, disc_loss = 0.0012913984299382283
Trained batch 617 in epoch 1, gen_loss = 1.0387473385117971, disc_loss = 0.0012979000387864012
Trained batch 618 in epoch 1, gen_loss = 1.0387504040135707, disc_loss = 0.0013039617984283336
Trained batch 619 in epoch 1, gen_loss = 1.0387257221244997, disc_loss = 0.001307577699903519
Trained batch 620 in epoch 1, gen_loss = 1.038763243507072, disc_loss = 0.0013097817642125338
Trained batch 621 in epoch 1, gen_loss = 1.0388125283733443, disc_loss = 0.0013109855001965998
Trained batch 622 in epoch 1, gen_loss = 1.0389010055681294, disc_loss = 0.001311940440002165
Trained batch 623 in epoch 1, gen_loss = 1.0388144868879745, disc_loss = 0.0013135047890663815
Trained batch 624 in epoch 1, gen_loss = 1.0387347054481506, disc_loss = 0.0013153162695467473
Trained batch 625 in epoch 1, gen_loss = 1.0387014140145847, disc_loss = 0.001315981478277094
Trained batch 626 in epoch 1, gen_loss = 1.038625525230426, disc_loss = 0.0013153149279954426
Trained batch 627 in epoch 1, gen_loss = 1.0386032538998657, disc_loss = 0.001314267652664648
Trained batch 628 in epoch 1, gen_loss = 1.0385960858842338, disc_loss = 0.0013131586541806678
Trained batch 629 in epoch 1, gen_loss = 1.0388043315637678, disc_loss = 0.0013124280347717955
Trained batch 630 in epoch 1, gen_loss = 1.0386781787910098, disc_loss = 0.0013130214505330047
Trained batch 631 in epoch 1, gen_loss = 1.038722064581853, disc_loss = 0.001314519873700146
Trained batch 632 in epoch 1, gen_loss = 1.0388301954638526, disc_loss = 0.0013153105272578978
Trained batch 633 in epoch 1, gen_loss = 1.0387366078441451, disc_loss = 0.0013148164923254353
Trained batch 634 in epoch 1, gen_loss = 1.0386858847197584, disc_loss = 0.0013138157695964507
Trained batch 635 in epoch 1, gen_loss = 1.038791446284678, disc_loss = 0.001312764003743277
Trained batch 636 in epoch 1, gen_loss = 1.038697023500266, disc_loss = 0.0013117765454214293
Trained batch 637 in epoch 1, gen_loss = 1.0387209606208023, disc_loss = 0.001310776327835209
Trained batch 638 in epoch 1, gen_loss = 1.0387758019384643, disc_loss = 0.00130945919278327
Trained batch 639 in epoch 1, gen_loss = 1.0388142728246748, disc_loss = 0.0013083326367450353
Trained batch 640 in epoch 1, gen_loss = 1.0389459697579073, disc_loss = 0.0013075219681588192
Trained batch 641 in epoch 1, gen_loss = 1.0389133837549858, disc_loss = 0.0013075727210351124
Trained batch 642 in epoch 1, gen_loss = 1.0389961131253103, disc_loss = 0.0013070957216290788
Trained batch 643 in epoch 1, gen_loss = 1.03898197440257, disc_loss = 0.0013059072483183457
Trained batch 644 in epoch 1, gen_loss = 1.0390048199845838, disc_loss = 0.0013044437597498528
Trained batch 645 in epoch 1, gen_loss = 1.0390569240131615, disc_loss = 0.0013030035226265597
Trained batch 646 in epoch 1, gen_loss = 1.0389531846208586, disc_loss = 0.0013017368028706898
Trained batch 647 in epoch 1, gen_loss = 1.0388654782264322, disc_loss = 0.0013006194141196852
Trained batch 648 in epoch 1, gen_loss = 1.038834895209649, disc_loss = 0.001299783601671334
Trained batch 649 in epoch 1, gen_loss = 1.0387287968855639, disc_loss = 0.0012996042783533295
Trained batch 650 in epoch 1, gen_loss = 1.0386134137023246, disc_loss = 0.0012992750057974221
Trained batch 651 in epoch 1, gen_loss = 1.0385765446110007, disc_loss = 0.0012982544818899502
Trained batch 652 in epoch 1, gen_loss = 1.0385986979120907, disc_loss = 0.0012971671256874965
Trained batch 653 in epoch 1, gen_loss = 1.0386105382114375, disc_loss = 0.0012961672884657758
Trained batch 654 in epoch 1, gen_loss = 1.0385191339572877, disc_loss = 0.0012953649827311142
Trained batch 655 in epoch 1, gen_loss = 1.0384052503944896, disc_loss = 0.0012946139183729495
Trained batch 656 in epoch 1, gen_loss = 1.0383172473406683, disc_loss = 0.0012938267909911073
Trained batch 657 in epoch 1, gen_loss = 1.0383310675802202, disc_loss = 0.0012930660413653875
Trained batch 658 in epoch 1, gen_loss = 1.03829203670412, disc_loss = 0.0012922159963437922
Trained batch 659 in epoch 1, gen_loss = 1.0382043761737418, disc_loss = 0.0012912242007918062
Trained batch 660 in epoch 1, gen_loss = 1.0382859781722618, disc_loss = 0.0012901205644444752
Trained batch 661 in epoch 1, gen_loss = 1.0382524187651285, disc_loss = 0.001288870068907448
Trained batch 662 in epoch 1, gen_loss = 1.038248237891075, disc_loss = 0.00128755092144653
Trained batch 663 in epoch 1, gen_loss = 1.0381906642073608, disc_loss = 0.0012862941996472836
Trained batch 664 in epoch 1, gen_loss = 1.0380413206896388, disc_loss = 0.0012851348083336746
Trained batch 665 in epoch 1, gen_loss = 1.038059623839261, disc_loss = 0.0012839626279738578
Trained batch 666 in epoch 1, gen_loss = 1.0381850777179942, disc_loss = 0.0012830862273393
Trained batch 667 in epoch 1, gen_loss = 1.0381555782999108, disc_loss = 0.001282220086405921
Trained batch 668 in epoch 1, gen_loss = 1.0381268678937436, disc_loss = 0.0012816849193116023
Trained batch 669 in epoch 1, gen_loss = 1.03816307418382, disc_loss = 0.0012811545601006903
Trained batch 670 in epoch 1, gen_loss = 1.0382461292910683, disc_loss = 0.001280688441415066
Trained batch 671 in epoch 1, gen_loss = 1.0382420476526022, disc_loss = 0.0012801033123780922
Trained batch 672 in epoch 1, gen_loss = 1.0382133429153182, disc_loss = 0.0012793888033552437
Trained batch 673 in epoch 1, gen_loss = 1.0381731784485215, disc_loss = 0.0012785850615860365
Trained batch 674 in epoch 1, gen_loss = 1.038182457199803, disc_loss = 0.0012777595289689661
Trained batch 675 in epoch 1, gen_loss = 1.0382883479080256, disc_loss = 0.0012766625253864585
Trained batch 676 in epoch 1, gen_loss = 1.0381898572737216, disc_loss = 0.0012753670940593854
Trained batch 677 in epoch 1, gen_loss = 1.038231584790182, disc_loss = 0.001274073062693648
Trained batch 678 in epoch 1, gen_loss = 1.0382669095789385, disc_loss = 0.001272934420414568
Trained batch 679 in epoch 1, gen_loss = 1.0381342507460538, disc_loss = 0.0012718439026417293
Trained batch 680 in epoch 1, gen_loss = 1.0382338289647375, disc_loss = 0.0012705521631993424
Trained batch 681 in epoch 1, gen_loss = 1.038191107186404, disc_loss = 0.0012693387759908149
Trained batch 682 in epoch 1, gen_loss = 1.0381919199690812, disc_loss = 0.0012682538171398343
Trained batch 683 in epoch 1, gen_loss = 1.03826525964235, disc_loss = 0.0012671679667842558
Trained batch 684 in epoch 1, gen_loss = 1.0382628308595532, disc_loss = 0.001266200133313826
Trained batch 685 in epoch 1, gen_loss = 1.038296617154825, disc_loss = 0.0012656556084818607
Trained batch 686 in epoch 1, gen_loss = 1.0383655528661293, disc_loss = 0.0012657484328584391
Trained batch 687 in epoch 1, gen_loss = 1.0383749399767366, disc_loss = 0.0012663291733567116
Trained batch 688 in epoch 1, gen_loss = 1.0385220881297383, disc_loss = 0.0012668568566772704
Trained batch 689 in epoch 1, gen_loss = 1.0384740328443223, disc_loss = 0.0012666096093396292
Trained batch 690 in epoch 1, gen_loss = 1.0385191526840807, disc_loss = 0.0012663296952354418
Trained batch 691 in epoch 1, gen_loss = 1.0385079127171135, disc_loss = 0.0012665846508038041
Trained batch 692 in epoch 1, gen_loss = 1.0387016944210938, disc_loss = 0.0012681147433558015
Trained batch 693 in epoch 1, gen_loss = 1.0387034474600976, disc_loss = 0.0012709707274505605
Trained batch 694 in epoch 1, gen_loss = 1.0388141084918014, disc_loss = 0.001273688703370046
Trained batch 695 in epoch 1, gen_loss = 1.038670478538535, disc_loss = 0.0012756790687301967
Trained batch 696 in epoch 1, gen_loss = 1.038764328833461, disc_loss = 0.001276622174178762
Trained batch 697 in epoch 1, gen_loss = 1.038784688899032, disc_loss = 0.0012766389354875306
Trained batch 698 in epoch 1, gen_loss = 1.0387443975999802, disc_loss = 0.0012763020798506667
Trained batch 699 in epoch 1, gen_loss = 1.0387203810896193, disc_loss = 0.0012758485531334633
Trained batch 700 in epoch 1, gen_loss = 1.038662577321628, disc_loss = 0.0012751008790303899
Trained batch 701 in epoch 1, gen_loss = 1.0386441866217175, disc_loss = 0.001274218373090172
Trained batch 702 in epoch 1, gen_loss = 1.038703502665882, disc_loss = 0.0012733809656402624
Trained batch 703 in epoch 1, gen_loss = 1.0386845632032915, disc_loss = 0.001272540921904279
Trained batch 704 in epoch 1, gen_loss = 1.0386137542995155, disc_loss = 0.0012718577289636782
Trained batch 705 in epoch 1, gen_loss = 1.0386749306751717, disc_loss = 0.001271131682102819
Trained batch 706 in epoch 1, gen_loss = 1.0385996790384133, disc_loss = 0.001270006575356231
Trained batch 707 in epoch 1, gen_loss = 1.0386976900242142, disc_loss = 0.0012696016640540496
Trained batch 708 in epoch 1, gen_loss = 1.0387392882231428, disc_loss = 0.0012696143457296926
Trained batch 709 in epoch 1, gen_loss = 1.0387171865349085, disc_loss = 0.0012694443904788194
Trained batch 710 in epoch 1, gen_loss = 1.0386376658404761, disc_loss = 0.001269685948459476
Trained batch 711 in epoch 1, gen_loss = 1.0385470005233637, disc_loss = 0.001269908691641974
Trained batch 712 in epoch 1, gen_loss = 1.0386066874815738, disc_loss = 0.00126986531206037
Trained batch 713 in epoch 1, gen_loss = 1.038633235028478, disc_loss = 0.0012692790934183383
Trained batch 714 in epoch 1, gen_loss = 1.0385668674549022, disc_loss = 0.0012685794117078967
Trained batch 715 in epoch 1, gen_loss = 1.038489705856952, disc_loss = 0.0012677891869143473
Trained batch 716 in epoch 1, gen_loss = 1.038423972814818, disc_loss = 0.0012666830399532827
Trained batch 717 in epoch 1, gen_loss = 1.038453292713856, disc_loss = 0.001265495418595905
Trained batch 718 in epoch 1, gen_loss = 1.0385232396185482, disc_loss = 0.0012644892496523812
Trained batch 719 in epoch 1, gen_loss = 1.0385023050838047, disc_loss = 0.0012633226374115718
Trained batch 720 in epoch 1, gen_loss = 1.0386074802911893, disc_loss = 0.001262406543717137
Trained batch 721 in epoch 1, gen_loss = 1.0384628582859303, disc_loss = 0.001261798751795564
Trained batch 722 in epoch 1, gen_loss = 1.0386242089924476, disc_loss = 0.0012619030654393677
Trained batch 723 in epoch 1, gen_loss = 1.038675913329941, disc_loss = 0.001262696397782481
Trained batch 724 in epoch 1, gen_loss = 1.0386866955921568, disc_loss = 0.0012636642379220576
Trained batch 725 in epoch 1, gen_loss = 1.0386955674029579, disc_loss = 0.0012641296589784915
Trained batch 726 in epoch 1, gen_loss = 1.0387861605687516, disc_loss = 0.0012640190754579623
Trained batch 727 in epoch 1, gen_loss = 1.038840306165454, disc_loss = 0.0012638140664481337
Trained batch 728 in epoch 1, gen_loss = 1.038862530259602, disc_loss = 0.0012636291570511144
Trained batch 729 in epoch 1, gen_loss = 1.0388777847159398, disc_loss = 0.0012631845938389458
Trained batch 730 in epoch 1, gen_loss = 1.0388867574579574, disc_loss = 0.0012623562816184565
Trained batch 731 in epoch 1, gen_loss = 1.0388902730303384, disc_loss = 0.0012613588754743557
Trained batch 732 in epoch 1, gen_loss = 1.0388245861494525, disc_loss = 0.0012603481680946997
Trained batch 733 in epoch 1, gen_loss = 1.0390260631284531, disc_loss = 0.001259697733593823
Trained batch 734 in epoch 1, gen_loss = 1.0390597444813268, disc_loss = 0.0012587721383145243
Trained batch 735 in epoch 1, gen_loss = 1.0390201412627231, disc_loss = 0.0012575870200832826
Trained batch 736 in epoch 1, gen_loss = 1.0390445795440932, disc_loss = 0.0012564510409135796
Trained batch 737 in epoch 1, gen_loss = 1.0389301816460885, disc_loss = 0.0012553618664567442
Trained batch 738 in epoch 1, gen_loss = 1.0389080580742336, disc_loss = 0.0012543499503232392
Trained batch 739 in epoch 1, gen_loss = 1.0389732959302695, disc_loss = 0.0012534074399170366
Trained batch 740 in epoch 1, gen_loss = 1.0390425889115584, disc_loss = 0.0012525515010666515
Trained batch 741 in epoch 1, gen_loss = 1.03894329882375, disc_loss = 0.001251803380991031
Trained batch 742 in epoch 1, gen_loss = 1.038980422478826, disc_loss = 0.0012510304459014063
Trained batch 743 in epoch 1, gen_loss = 1.0390545619271134, disc_loss = 0.0012501738200753412
Trained batch 744 in epoch 1, gen_loss = 1.0389817444270089, disc_loss = 0.0012492765314273862
Trained batch 745 in epoch 1, gen_loss = 1.0389666549322112, disc_loss = 0.0012483257176051786
Trained batch 746 in epoch 1, gen_loss = 1.0390374338132151, disc_loss = 0.0012476827093001724
Trained batch 747 in epoch 1, gen_loss = 1.0391564082334386, disc_loss = 0.001247053912193029
Trained batch 748 in epoch 1, gen_loss = 1.0392627735163404, disc_loss = 0.0012462909714749657
Trained batch 749 in epoch 1, gen_loss = 1.0393273018201192, disc_loss = 0.0012453931733422603
Trained batch 750 in epoch 1, gen_loss = 1.0392911281788872, disc_loss = 0.0012445581400504686
Trained batch 751 in epoch 1, gen_loss = 1.0391891489320613, disc_loss = 0.0012436717669457875
Trained batch 752 in epoch 1, gen_loss = 1.0391445530363288, disc_loss = 0.001242607499328708
Trained batch 753 in epoch 1, gen_loss = 1.0390355905582165, disc_loss = 0.0012418483544526428
Trained batch 754 in epoch 1, gen_loss = 1.0390004413017373, disc_loss = 0.0012414786921481028
Trained batch 755 in epoch 1, gen_loss = 1.038901956544982, disc_loss = 0.0012409668200200907
Trained batch 756 in epoch 1, gen_loss = 1.0389577974731414, disc_loss = 0.0012404639472264694
Trained batch 757 in epoch 1, gen_loss = 1.039043758428191, disc_loss = 0.0012401402308998782
Trained batch 758 in epoch 1, gen_loss = 1.0390760443898528, disc_loss = 0.001239804972339868
Trained batch 759 in epoch 1, gen_loss = 1.039109192788601, disc_loss = 0.0012392396242112706
Trained batch 760 in epoch 1, gen_loss = 1.0391684813662365, disc_loss = 0.0012383933637092935
Trained batch 761 in epoch 1, gen_loss = 1.0391080438152074, disc_loss = 0.0012374275074929508
Trained batch 762 in epoch 1, gen_loss = 1.0391107295318793, disc_loss = 0.0012364663762866788
Trained batch 763 in epoch 1, gen_loss = 1.0389851620372053, disc_loss = 0.0012355365308004075
Trained batch 764 in epoch 1, gen_loss = 1.0390225382412182, disc_loss = 0.0012344793017856242
Trained batch 765 in epoch 1, gen_loss = 1.038959958690265, disc_loss = 0.0012334126896056524
Trained batch 766 in epoch 1, gen_loss = 1.03893940871511, disc_loss = 0.0012322842977355772
Trained batch 767 in epoch 1, gen_loss = 1.038933033278833, disc_loss = 0.0012312289009817807
Trained batch 768 in epoch 1, gen_loss = 1.0389971452509628, disc_loss = 0.0012300112207134961
Trained batch 769 in epoch 1, gen_loss = 1.0389357062129232, disc_loss = 0.0012288373044174914
Trained batch 770 in epoch 1, gen_loss = 1.0388814151364387, disc_loss = 0.0012276831574707223
Trained batch 771 in epoch 1, gen_loss = 1.0388454638151308, disc_loss = 0.001226620896457914
Trained batch 772 in epoch 1, gen_loss = 1.0389347488944929, disc_loss = 0.0012256095711401461
Trained batch 773 in epoch 1, gen_loss = 1.0388303941226438, disc_loss = 0.0012244894653958814
Trained batch 774 in epoch 1, gen_loss = 1.038757669387325, disc_loss = 0.0012233503323964654
Trained batch 775 in epoch 1, gen_loss = 1.0388186719921446, disc_loss = 0.0012223111677401191
Trained batch 776 in epoch 1, gen_loss = 1.0388210893751264, disc_loss = 0.0012213123697913976
Trained batch 777 in epoch 1, gen_loss = 1.0386360467706057, disc_loss = 0.0012208223582684137
Trained batch 778 in epoch 1, gen_loss = 1.0385388865856517, disc_loss = 0.0012205802493376612
Trained batch 779 in epoch 1, gen_loss = 1.0385080467431973, disc_loss = 0.0012202511353862997
Trained batch 780 in epoch 1, gen_loss = 1.038429936968868, disc_loss = 0.00122005434751674
Trained batch 781 in epoch 1, gen_loss = 1.0384871275985943, disc_loss = 0.0012197620505208025
Trained batch 782 in epoch 1, gen_loss = 1.0384874967322952, disc_loss = 0.0012192937268118468
Trained batch 783 in epoch 1, gen_loss = 1.0385420567983268, disc_loss = 0.0012187248801415174
Trained batch 784 in epoch 1, gen_loss = 1.0385384833736784, disc_loss = 0.001218122905483588
Trained batch 785 in epoch 1, gen_loss = 1.0385669209726591, disc_loss = 0.0012176109031100495
Trained batch 786 in epoch 1, gen_loss = 1.0385532752531457, disc_loss = 0.0012169146530961515
Trained batch 787 in epoch 1, gen_loss = 1.0385215776372076, disc_loss = 0.0012163645228495713
Trained batch 788 in epoch 1, gen_loss = 1.0385392877841026, disc_loss = 0.001215821632140709
Trained batch 789 in epoch 1, gen_loss = 1.0383693982528734, disc_loss = 0.0012153248848243252
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.031261920928955, disc_loss = 0.000878137769177556
Trained batch 1 in epoch 2, gen_loss = 1.070375680923462, disc_loss = 0.0008193168614525348
Trained batch 2 in epoch 2, gen_loss = 1.0566759904225667, disc_loss = 0.0007210114466336867
Trained batch 3 in epoch 2, gen_loss = 1.0525492429733276, disc_loss = 0.0006408162298612297
Trained batch 4 in epoch 2, gen_loss = 1.047298049926758, disc_loss = 0.0005912522436119616
Trained batch 5 in epoch 2, gen_loss = 1.0255393584569295, disc_loss = 0.0006226058176252991
Trained batch 6 in epoch 2, gen_loss = 1.0408970628465926, disc_loss = 0.0006541524032529976
Trained batch 7 in epoch 2, gen_loss = 1.0454874783754349, disc_loss = 0.0007003699793131091
Trained batch 8 in epoch 2, gen_loss = 1.0590475532743666, disc_loss = 0.0007752074743621051
Trained batch 9 in epoch 2, gen_loss = 1.0539909482002259, disc_loss = 0.0008624729176517576
Trained batch 10 in epoch 2, gen_loss = 1.0449057004668496, disc_loss = 0.0009340946298007938
Trained batch 11 in epoch 2, gen_loss = 1.0438987364371617, disc_loss = 0.0009802321874303743
Trained batch 12 in epoch 2, gen_loss = 1.0383726404263423, disc_loss = 0.0010057950902801866
Trained batch 13 in epoch 2, gen_loss = 1.0459872271333421, disc_loss = 0.0010076393996964075
Trained batch 14 in epoch 2, gen_loss = 1.0451823353767395, disc_loss = 0.000977154813396434
Trained batch 15 in epoch 2, gen_loss = 1.0419792756438255, disc_loss = 0.0009491859163972549
Trained batch 16 in epoch 2, gen_loss = 1.0442552917143877, disc_loss = 0.0009300365311312763
Trained batch 17 in epoch 2, gen_loss = 1.0462537937694125, disc_loss = 0.0009092765006547173
Trained batch 18 in epoch 2, gen_loss = 1.0405263022372597, disc_loss = 0.0008859892504436797
Trained batch 19 in epoch 2, gen_loss = 1.0422109961509705, disc_loss = 0.0008615121332695708
Trained batch 20 in epoch 2, gen_loss = 1.045109851019723, disc_loss = 0.0008417917124461383
Trained batch 21 in epoch 2, gen_loss = 1.04676001180302, disc_loss = 0.000823316963347183
Trained batch 22 in epoch 2, gen_loss = 1.048856636752253, disc_loss = 0.0008059713721234838
Trained batch 23 in epoch 2, gen_loss = 1.052083397905032, disc_loss = 0.0007916166966121333
Trained batch 24 in epoch 2, gen_loss = 1.0524409580230714, disc_loss = 0.0007802315056324005
Trained batch 25 in epoch 2, gen_loss = 1.0516789234601533, disc_loss = 0.0007686258669799337
Trained batch 26 in epoch 2, gen_loss = 1.0545862250857883, disc_loss = 0.0007567015763251456
Trained batch 27 in epoch 2, gen_loss = 1.0516337347882134, disc_loss = 0.0007422395231385183
Trained batch 28 in epoch 2, gen_loss = 1.0530286760165775, disc_loss = 0.0007376051738713708
Trained batch 29 in epoch 2, gen_loss = 1.0511301656564076, disc_loss = 0.0007361107748389865
Trained batch 30 in epoch 2, gen_loss = 1.0528896181814131, disc_loss = 0.0007396041886926057
Trained batch 31 in epoch 2, gen_loss = 1.0556748267263174, disc_loss = 0.0007481970524167991
Trained batch 32 in epoch 2, gen_loss = 1.054494978803577, disc_loss = 0.0007522277962628075
Trained batch 33 in epoch 2, gen_loss = 1.0532316092182608, disc_loss = 0.0007598499779466211
Trained batch 34 in epoch 2, gen_loss = 1.052665947164808, disc_loss = 0.0007755708473268896
Trained batch 35 in epoch 2, gen_loss = 1.0500814881589677, disc_loss = 0.0007923479352029972
Trained batch 36 in epoch 2, gen_loss = 1.0494107587917432, disc_loss = 0.0008034816545094489
Trained batch 37 in epoch 2, gen_loss = 1.0500482320785522, disc_loss = 0.0008061637689886419
Trained batch 38 in epoch 2, gen_loss = 1.0493709704814813, disc_loss = 0.0008030280311150142
Trained batch 39 in epoch 2, gen_loss = 1.0505729645490647, disc_loss = 0.0008010465033294167
Trained batch 40 in epoch 2, gen_loss = 1.0479697323426969, disc_loss = 0.0008063098357524723
Trained batch 41 in epoch 2, gen_loss = 1.0489594496431804, disc_loss = 0.000821424658559928
Trained batch 42 in epoch 2, gen_loss = 1.0481410816658374, disc_loss = 0.0008484282859785179
Trained batch 43 in epoch 2, gen_loss = 1.0453354905952106, disc_loss = 0.0008821075574484315
Trained batch 44 in epoch 2, gen_loss = 1.045853606859843, disc_loss = 0.0009143254764947212
Trained batch 45 in epoch 2, gen_loss = 1.0454468286555747, disc_loss = 0.0009336762134056619
Trained batch 46 in epoch 2, gen_loss = 1.0463098490491827, disc_loss = 0.0009389050432451148
Trained batch 47 in epoch 2, gen_loss = 1.0459248671929042, disc_loss = 0.0009331368316149261
Trained batch 48 in epoch 2, gen_loss = 1.0464897447702837, disc_loss = 0.0009248900382865068
Trained batch 49 in epoch 2, gen_loss = 1.04540287733078, disc_loss = 0.0009230690490221605
Trained batch 50 in epoch 2, gen_loss = 1.0459029838150622, disc_loss = 0.000929205689245981
Trained batch 51 in epoch 2, gen_loss = 1.0452616902498097, disc_loss = 0.000941056645667861
Trained batch 52 in epoch 2, gen_loss = 1.04455488582827, disc_loss = 0.0009479594305992337
Trained batch 53 in epoch 2, gen_loss = 1.0447695608492251, disc_loss = 0.0009430922428792757
Trained batch 54 in epoch 2, gen_loss = 1.043613110889088, disc_loss = 0.0009342516513160345
Trained batch 55 in epoch 2, gen_loss = 1.0431119267429625, disc_loss = 0.0009236103583784175
Trained batch 56 in epoch 2, gen_loss = 1.042163520528559, disc_loss = 0.0009133646738503063
Trained batch 57 in epoch 2, gen_loss = 1.0407137028102218, disc_loss = 0.0009038023804194005
Trained batch 58 in epoch 2, gen_loss = 1.0408752449488237, disc_loss = 0.0008949198073439174
Trained batch 59 in epoch 2, gen_loss = 1.0407758990923563, disc_loss = 0.0008873333698526646
Trained batch 60 in epoch 2, gen_loss = 1.0410793492051422, disc_loss = 0.0008816670494718996
Trained batch 61 in epoch 2, gen_loss = 1.042927368994682, disc_loss = 0.0008758928086007795
Trained batch 62 in epoch 2, gen_loss = 1.0428994307442316, disc_loss = 0.0008691497172953354
Trained batch 63 in epoch 2, gen_loss = 1.0417851023375988, disc_loss = 0.0008686057262821123
Trained batch 64 in epoch 2, gen_loss = 1.0416259875664344, disc_loss = 0.0008669941999519674
Trained batch 65 in epoch 2, gen_loss = 1.0409596345641396, disc_loss = 0.0008624631048984487
Trained batch 66 in epoch 2, gen_loss = 1.0415740618065221, disc_loss = 0.0008551415973412457
Trained batch 67 in epoch 2, gen_loss = 1.041817572186975, disc_loss = 0.0008497110294924556
Trained batch 68 in epoch 2, gen_loss = 1.0428384905276091, disc_loss = 0.0008518917142730746
Trained batch 69 in epoch 2, gen_loss = 1.0439097455569677, disc_loss = 0.0008623943518614397
Trained batch 70 in epoch 2, gen_loss = 1.0453036032931906, disc_loss = 0.0008755404896489804
Trained batch 71 in epoch 2, gen_loss = 1.0465587261650298, disc_loss = 0.0008869963466066918
Trained batch 72 in epoch 2, gen_loss = 1.0455356575038335, disc_loss = 0.0008895567108794078
Trained batch 73 in epoch 2, gen_loss = 1.0459271943246997, disc_loss = 0.0008897407297391092
Trained batch 74 in epoch 2, gen_loss = 1.0464799690246582, disc_loss = 0.0008897960756439715
Trained batch 75 in epoch 2, gen_loss = 1.0460649540549831, disc_loss = 0.0008907832437360316
Trained batch 76 in epoch 2, gen_loss = 1.0447525800048532, disc_loss = 0.0008908016875525331
Trained batch 77 in epoch 2, gen_loss = 1.0436837673187256, disc_loss = 0.0008918265375541523
Trained batch 78 in epoch 2, gen_loss = 1.0429597512076172, disc_loss = 0.0008905663253014459
Trained batch 79 in epoch 2, gen_loss = 1.0428943865001201, disc_loss = 0.0008902574936655583
Trained batch 80 in epoch 2, gen_loss = 1.0414642294247944, disc_loss = 0.0008940695613237489
Trained batch 81 in epoch 2, gen_loss = 1.0416846660579122, disc_loss = 0.0009025292170784868
Trained batch 82 in epoch 2, gen_loss = 1.0425558384642544, disc_loss = 0.0009109599572600774
Trained batch 83 in epoch 2, gen_loss = 1.0431750182594572, disc_loss = 0.0009141676339259859
Trained batch 84 in epoch 2, gen_loss = 1.043673001317417, disc_loss = 0.0009125022645628847
Trained batch 85 in epoch 2, gen_loss = 1.0435473399106847, disc_loss = 0.0009090649590118204
Trained batch 86 in epoch 2, gen_loss = 1.0442255413395234, disc_loss = 0.0009073155999702841
Trained batch 87 in epoch 2, gen_loss = 1.0437022169882602, disc_loss = 0.0009067223280991046
Trained batch 88 in epoch 2, gen_loss = 1.0442212264189559, disc_loss = 0.0009073967887794997
Trained batch 89 in epoch 2, gen_loss = 1.0429991020096674, disc_loss = 0.0009134550510983293
Trained batch 90 in epoch 2, gen_loss = 1.0431711084240085, disc_loss = 0.0009282624312538326
Trained batch 91 in epoch 2, gen_loss = 1.042942235003347, disc_loss = 0.0009467848130557484
Trained batch 92 in epoch 2, gen_loss = 1.042379028053694, disc_loss = 0.0009614176186357415
Trained batch 93 in epoch 2, gen_loss = 1.0425043955762336, disc_loss = 0.0009646002110960754
Trained batch 94 in epoch 2, gen_loss = 1.0419574072486475, disc_loss = 0.0009627222950496759
Trained batch 95 in epoch 2, gen_loss = 1.041578219582637, disc_loss = 0.0009587096868320563
Trained batch 96 in epoch 2, gen_loss = 1.04277498574601, disc_loss = 0.000953328186950944
Trained batch 97 in epoch 2, gen_loss = 1.042061803292255, disc_loss = 0.0009480894000355002
Trained batch 98 in epoch 2, gen_loss = 1.0430298020141293, disc_loss = 0.00094465150749499
Trained batch 99 in epoch 2, gen_loss = 1.0432810735702516, disc_loss = 0.0009422762837493792
Trained batch 100 in epoch 2, gen_loss = 1.0423976418995622, disc_loss = 0.0009412253557907252
Trained batch 101 in epoch 2, gen_loss = 1.0426751375198364, disc_loss = 0.0009391195404425482
Trained batch 102 in epoch 2, gen_loss = 1.042769198278779, disc_loss = 0.0009347049607578846
Trained batch 103 in epoch 2, gen_loss = 1.0427949864130754, disc_loss = 0.0009297898725960224
Trained batch 104 in epoch 2, gen_loss = 1.0426210846219743, disc_loss = 0.0009251608183452239
Trained batch 105 in epoch 2, gen_loss = 1.0426655006858538, disc_loss = 0.0009219163311052329
Trained batch 106 in epoch 2, gen_loss = 1.0425386506820393, disc_loss = 0.0009189119318252099
Trained batch 107 in epoch 2, gen_loss = 1.0424048039648268, disc_loss = 0.0009171603098231437
Trained batch 108 in epoch 2, gen_loss = 1.041851853011945, disc_loss = 0.0009149361336112467
Trained batch 109 in epoch 2, gen_loss = 1.0405699410221794, disc_loss = 0.0009120802328900688
Trained batch 110 in epoch 2, gen_loss = 1.0413711591883823, disc_loss = 0.0009098890521207002
Trained batch 111 in epoch 2, gen_loss = 1.040843797049352, disc_loss = 0.0009101813523427284
Trained batch 112 in epoch 2, gen_loss = 1.0407778177641134, disc_loss = 0.0009122741822281077
Trained batch 113 in epoch 2, gen_loss = 1.04059278808142, disc_loss = 0.000915461448337801
Trained batch 114 in epoch 2, gen_loss = 1.040808149524357, disc_loss = 0.0009175503472088958
Trained batch 115 in epoch 2, gen_loss = 1.0404924015546668, disc_loss = 0.0009180180442916904
Trained batch 116 in epoch 2, gen_loss = 1.0404166212448707, disc_loss = 0.000916212907858973
Trained batch 117 in epoch 2, gen_loss = 1.0411199184797577, disc_loss = 0.0009129169553427531
Trained batch 118 in epoch 2, gen_loss = 1.0418929918473507, disc_loss = 0.0009090431876374925
Trained batch 119 in epoch 2, gen_loss = 1.0416656518975893, disc_loss = 0.0009054120314734367
Trained batch 120 in epoch 2, gen_loss = 1.0410900288376927, disc_loss = 0.0009017751430938682
Trained batch 121 in epoch 2, gen_loss = 1.0404986558390446, disc_loss = 0.0008975005812168152
Trained batch 122 in epoch 2, gen_loss = 1.0399787372689906, disc_loss = 0.0008928667099926833
Trained batch 123 in epoch 2, gen_loss = 1.0393620455457317, disc_loss = 0.0008891374785772284
Trained batch 124 in epoch 2, gen_loss = 1.0386024355888366, disc_loss = 0.0008870479038450867
Trained batch 125 in epoch 2, gen_loss = 1.0392091061387743, disc_loss = 0.0008850541043867697
Trained batch 126 in epoch 2, gen_loss = 1.0385480354151388, disc_loss = 0.0008820006626155814
Trained batch 127 in epoch 2, gen_loss = 1.038963635917753, disc_loss = 0.000878086714010351
Trained batch 128 in epoch 2, gen_loss = 1.0390710548837057, disc_loss = 0.0008745843674554381
Trained batch 129 in epoch 2, gen_loss = 1.039090405519192, disc_loss = 0.0008714806852647318
Trained batch 130 in epoch 2, gen_loss = 1.0392621013954395, disc_loss = 0.0008687302865663842
Trained batch 131 in epoch 2, gen_loss = 1.0384639966668505, disc_loss = 0.0008657028612850064
Trained batch 132 in epoch 2, gen_loss = 1.0391760835970254, disc_loss = 0.0008648913213633057
Trained batch 133 in epoch 2, gen_loss = 1.0392376340147276, disc_loss = 0.0008686099691427689
Trained batch 134 in epoch 2, gen_loss = 1.0389490158469588, disc_loss = 0.0008766522613802442
Trained batch 135 in epoch 2, gen_loss = 1.0390626555856537, disc_loss = 0.0008850425211301841
Trained batch 136 in epoch 2, gen_loss = 1.0388579155406812, disc_loss = 0.0008878148709811325
Trained batch 137 in epoch 2, gen_loss = 1.0382686348065087, disc_loss = 0.0008875359772650552
Trained batch 138 in epoch 2, gen_loss = 1.0379794583046178, disc_loss = 0.0008871694587057176
Trained batch 139 in epoch 2, gen_loss = 1.0378432235547475, disc_loss = 0.0008864651479858107
Trained batch 140 in epoch 2, gen_loss = 1.037346323753925, disc_loss = 0.0008849878671598878
Trained batch 141 in epoch 2, gen_loss = 1.0370075253533646, disc_loss = 0.0008837095556885634
Trained batch 142 in epoch 2, gen_loss = 1.037254162184842, disc_loss = 0.0008816419904432878
Trained batch 143 in epoch 2, gen_loss = 1.0367693880365954, disc_loss = 0.0008784581534402807
Trained batch 144 in epoch 2, gen_loss = 1.0372049557751624, disc_loss = 0.0008772077733361773
Trained batch 145 in epoch 2, gen_loss = 1.0380580666130537, disc_loss = 0.0008770486249027085
Trained batch 146 in epoch 2, gen_loss = 1.0377902834593844, disc_loss = 0.0008773319700378037
Trained batch 147 in epoch 2, gen_loss = 1.0381267042578877, disc_loss = 0.0008761957629955046
Trained batch 148 in epoch 2, gen_loss = 1.0377364542660297, disc_loss = 0.0008728978001034425
Trained batch 149 in epoch 2, gen_loss = 1.0381860987345377, disc_loss = 0.0008718217267111565
Trained batch 150 in epoch 2, gen_loss = 1.0383693374545369, disc_loss = 0.0008741655467549919
Trained batch 151 in epoch 2, gen_loss = 1.0384288783136166, disc_loss = 0.0008756562848774545
Trained batch 152 in epoch 2, gen_loss = 1.0384959496703803, disc_loss = 0.0008762155796836428
Trained batch 153 in epoch 2, gen_loss = 1.037825916494642, disc_loss = 0.0008749815995590278
Trained batch 154 in epoch 2, gen_loss = 1.0379063352461784, disc_loss = 0.0008769453429962478
Trained batch 155 in epoch 2, gen_loss = 1.0385122024095976, disc_loss = 0.0008808286162466408
Trained batch 156 in epoch 2, gen_loss = 1.038195479827322, disc_loss = 0.0008811790017473398
Trained batch 157 in epoch 2, gen_loss = 1.0375434854362584, disc_loss = 0.0008798356135184228
Trained batch 158 in epoch 2, gen_loss = 1.0376188365168542, disc_loss = 0.0008804961845334385
Trained batch 159 in epoch 2, gen_loss = 1.037858633697033, disc_loss = 0.0008811204321318655
Trained batch 160 in epoch 2, gen_loss = 1.037549962908585, disc_loss = 0.0008806190509508185
Trained batch 161 in epoch 2, gen_loss = 1.037232165719256, disc_loss = 0.0008797659012302182
Trained batch 162 in epoch 2, gen_loss = 1.0374217472193432, disc_loss = 0.0008796615034350382
Trained batch 163 in epoch 2, gen_loss = 1.0376838372974861, disc_loss = 0.0008798344591391137
Trained batch 164 in epoch 2, gen_loss = 1.0368552337993275, disc_loss = 0.0008827561842432867
Trained batch 165 in epoch 2, gen_loss = 1.036456929272916, disc_loss = 0.0008900638756339427
Trained batch 166 in epoch 2, gen_loss = 1.0361890475193183, disc_loss = 0.0009002620959027062
Trained batch 167 in epoch 2, gen_loss = 1.0356086485442662, disc_loss = 0.0009099141425394919
Trained batch 168 in epoch 2, gen_loss = 1.0347192555489624, disc_loss = 0.0009195707349544777
Trained batch 169 in epoch 2, gen_loss = 1.0341433767010184, disc_loss = 0.0009262038714950904
Trained batch 170 in epoch 2, gen_loss = 1.0340270699813352, disc_loss = 0.0009312504207734454
Trained batch 171 in epoch 2, gen_loss = 1.0338491218727688, disc_loss = 0.0009341223636130413
Trained batch 172 in epoch 2, gen_loss = 1.0342224956936918, disc_loss = 0.0009359452122152175
Trained batch 173 in epoch 2, gen_loss = 1.0345125242896465, disc_loss = 0.0009361454819251472
Trained batch 174 in epoch 2, gen_loss = 1.0342270047324045, disc_loss = 0.0009347275842446833
Trained batch 175 in epoch 2, gen_loss = 1.0340291620655493, disc_loss = 0.0009323424851159375
Trained batch 176 in epoch 2, gen_loss = 1.0341034972735044, disc_loss = 0.0009303366037619715
Trained batch 177 in epoch 2, gen_loss = 1.0340608211045854, disc_loss = 0.0009278480249347186
Trained batch 178 in epoch 2, gen_loss = 1.0335237893312337, disc_loss = 0.0009270008356185557
Trained batch 179 in epoch 2, gen_loss = 1.0331784374184079, disc_loss = 0.0009285040345275774
Trained batch 180 in epoch 2, gen_loss = 1.0329186508010106, disc_loss = 0.0009309769706486708
Trained batch 181 in epoch 2, gen_loss = 1.0330697494548755, disc_loss = 0.0009337918897502247
Trained batch 182 in epoch 2, gen_loss = 1.0332931247565265, disc_loss = 0.0009351869325581022
Trained batch 183 in epoch 2, gen_loss = 1.0333162623903025, disc_loss = 0.0009347123145151114
Trained batch 184 in epoch 2, gen_loss = 1.033160022142771, disc_loss = 0.0009328551219172171
Trained batch 185 in epoch 2, gen_loss = 1.032957273465331, disc_loss = 0.0009302962702819177
Trained batch 186 in epoch 2, gen_loss = 1.0331003528865264, disc_loss = 0.0009278752293218585
Trained batch 187 in epoch 2, gen_loss = 1.0328579075793003, disc_loss = 0.0009250524261857363
Trained batch 188 in epoch 2, gen_loss = 1.032702991571376, disc_loss = 0.0009225511465470489
Trained batch 189 in epoch 2, gen_loss = 1.0329814063875298, disc_loss = 0.00092019063809666
Trained batch 190 in epoch 2, gen_loss = 1.0329552252255185, disc_loss = 0.0009177054500412098
Trained batch 191 in epoch 2, gen_loss = 1.032956191028158, disc_loss = 0.0009159451574305422
Trained batch 192 in epoch 2, gen_loss = 1.0327078950219821, disc_loss = 0.0009147445897455931
Trained batch 193 in epoch 2, gen_loss = 1.032736598830862, disc_loss = 0.0009127609085498051
Trained batch 194 in epoch 2, gen_loss = 1.033211596806844, disc_loss = 0.0009103929522471168
Trained batch 195 in epoch 2, gen_loss = 1.0330194633226006, disc_loss = 0.000908386208145518
Trained batch 196 in epoch 2, gen_loss = 1.0329752219509958, disc_loss = 0.0009070362772811487
Trained batch 197 in epoch 2, gen_loss = 1.0329658380060485, disc_loss = 0.0009060178188409543
Trained batch 198 in epoch 2, gen_loss = 1.032649464942702, disc_loss = 0.0009047329442191812
Trained batch 199 in epoch 2, gen_loss = 1.0321677723526954, disc_loss = 0.0009037745691603049
Trained batch 200 in epoch 2, gen_loss = 1.032461329775663, disc_loss = 0.000903113250822218
Trained batch 201 in epoch 2, gen_loss = 1.0328719430040605, disc_loss = 0.000902772930365443
Trained batch 202 in epoch 2, gen_loss = 1.0324429493819551, disc_loss = 0.0009042520389727
Trained batch 203 in epoch 2, gen_loss = 1.0324535664974475, disc_loss = 0.000905378182092225
Trained batch 204 in epoch 2, gen_loss = 1.0320664949533416, disc_loss = 0.0009064206782523997
Trained batch 205 in epoch 2, gen_loss = 1.03215254250082, disc_loss = 0.0009078650892987956
Trained batch 206 in epoch 2, gen_loss = 1.03228612654451, disc_loss = 0.0009090723242084293
Trained batch 207 in epoch 2, gen_loss = 1.0322148499007409, disc_loss = 0.0009093620803748938
Trained batch 208 in epoch 2, gen_loss = 1.0320539465931613, disc_loss = 0.0009086673923892873
Trained batch 209 in epoch 2, gen_loss = 1.0317992814949581, disc_loss = 0.0009069399143170033
Trained batch 210 in epoch 2, gen_loss = 1.0321548027449874, disc_loss = 0.0009057783795922324
Trained batch 211 in epoch 2, gen_loss = 1.031895249800862, disc_loss = 0.0009048245355754845
Trained batch 212 in epoch 2, gen_loss = 1.0313674793556822, disc_loss = 0.0009044981520609851
Trained batch 213 in epoch 2, gen_loss = 1.0316759409191452, disc_loss = 0.000904007755800925
Trained batch 214 in epoch 2, gen_loss = 1.031876769731211, disc_loss = 0.000902783645988377
Trained batch 215 in epoch 2, gen_loss = 1.0320112517586462, disc_loss = 0.0009003911753232522
Trained batch 216 in epoch 2, gen_loss = 1.0316762330894647, disc_loss = 0.0008978289204664648
Trained batch 217 in epoch 2, gen_loss = 1.0313078895074512, disc_loss = 0.0008954569792701786
Trained batch 218 in epoch 2, gen_loss = 1.0310675806650833, disc_loss = 0.0008928188579699203
Trained batch 219 in epoch 2, gen_loss = 1.0306072617119009, disc_loss = 0.0008908417566668835
Trained batch 220 in epoch 2, gen_loss = 1.030289684485526, disc_loss = 0.0008884564849887279
Trained batch 221 in epoch 2, gen_loss = 1.0300414836084522, disc_loss = 0.0008861706318147061
Trained batch 222 in epoch 2, gen_loss = 1.0299191148826359, disc_loss = 0.0008843036546244499
Trained batch 223 in epoch 2, gen_loss = 1.0299884474703245, disc_loss = 0.0008829325773019393
Trained batch 224 in epoch 2, gen_loss = 1.0296596490012275, disc_loss = 0.0008813670907531761
Trained batch 225 in epoch 2, gen_loss = 1.0303016093979895, disc_loss = 0.0008797607500779863
Trained batch 226 in epoch 2, gen_loss = 1.0303752921226266, disc_loss = 0.0008786432318120686
Trained batch 227 in epoch 2, gen_loss = 1.0304286375380398, disc_loss = 0.0008783174716722497
Trained batch 228 in epoch 2, gen_loss = 1.0310516159607332, disc_loss = 0.0008786250830792688
Trained batch 229 in epoch 2, gen_loss = 1.031123881754668, disc_loss = 0.0008794619310799096
Trained batch 230 in epoch 2, gen_loss = 1.0310825888728683, disc_loss = 0.0008801603219844804
Trained batch 231 in epoch 2, gen_loss = 1.0311413489539047, disc_loss = 0.000880507565257019
Trained batch 232 in epoch 2, gen_loss = 1.0310978388070038, disc_loss = 0.0008803071488392471
Trained batch 233 in epoch 2, gen_loss = 1.0312166570598245, disc_loss = 0.0008798259645989005
Trained batch 234 in epoch 2, gen_loss = 1.0311782583277276, disc_loss = 0.000878816663827549
Trained batch 235 in epoch 2, gen_loss = 1.031001053624234, disc_loss = 0.0008774404119260183
Trained batch 236 in epoch 2, gen_loss = 1.0313168925072072, disc_loss = 0.0008760453470764517
Trained batch 237 in epoch 2, gen_loss = 1.031671568125236, disc_loss = 0.0008751888310159126
Trained batch 238 in epoch 2, gen_loss = 1.0316648662838477, disc_loss = 0.0008737101149209483
Trained batch 239 in epoch 2, gen_loss = 1.0316631133357683, disc_loss = 0.0008717159152486904
Trained batch 240 in epoch 2, gen_loss = 1.0314920740008848, disc_loss = 0.0008695593106906274
Trained batch 241 in epoch 2, gen_loss = 1.031448930748238, disc_loss = 0.000867898855574837
Trained batch 242 in epoch 2, gen_loss = 1.0317323070494726, disc_loss = 0.0008662674014807253
Trained batch 243 in epoch 2, gen_loss = 1.0318411930662688, disc_loss = 0.0008644252779586317
Trained batch 244 in epoch 2, gen_loss = 1.0319354942866734, disc_loss = 0.0008622782593545485
Trained batch 245 in epoch 2, gen_loss = 1.0316740637872277, disc_loss = 0.0008601391312005604
Trained batch 246 in epoch 2, gen_loss = 1.0316295474164399, disc_loss = 0.0008580999878736642
Trained batch 247 in epoch 2, gen_loss = 1.0314725228855688, disc_loss = 0.0008565464074396709
Trained batch 248 in epoch 2, gen_loss = 1.0317469557605115, disc_loss = 0.0008557549653010046
Trained batch 249 in epoch 2, gen_loss = 1.031693498134613, disc_loss = 0.0008549655338283629
Trained batch 250 in epoch 2, gen_loss = 1.031382360306394, disc_loss = 0.0008551282446415895
Trained batch 251 in epoch 2, gen_loss = 1.0312489607031383, disc_loss = 0.0008562800672186154
Trained batch 252 in epoch 2, gen_loss = 1.0311533551913477, disc_loss = 0.0008591269846939346
Trained batch 253 in epoch 2, gen_loss = 1.0309230919898025, disc_loss = 0.0008619283655966361
Trained batch 254 in epoch 2, gen_loss = 1.0308706306943707, disc_loss = 0.0008638288095301273
Trained batch 255 in epoch 2, gen_loss = 1.0310351294465363, disc_loss = 0.0008648115667710954
Trained batch 256 in epoch 2, gen_loss = 1.03108601857716, disc_loss = 0.0008646865440568803
Trained batch 257 in epoch 2, gen_loss = 1.030897172384484, disc_loss = 0.0008639720820843481
Trained batch 258 in epoch 2, gen_loss = 1.030845475472999, disc_loss = 0.0008629912276335175
Trained batch 259 in epoch 2, gen_loss = 1.0310494675086095, disc_loss = 0.0008618998520362836
Trained batch 260 in epoch 2, gen_loss = 1.0308954590125101, disc_loss = 0.00086042067489651
Trained batch 261 in epoch 2, gen_loss = 1.031191562650768, disc_loss = 0.0008590943565483753
Trained batch 262 in epoch 2, gen_loss = 1.0314243639829948, disc_loss = 0.0008576135588199
Trained batch 263 in epoch 2, gen_loss = 1.031407388096506, disc_loss = 0.0008557421497243922
Trained batch 264 in epoch 2, gen_loss = 1.0312482701157624, disc_loss = 0.0008535853510212927
Trained batch 265 in epoch 2, gen_loss = 1.0313525748880286, disc_loss = 0.0008515455430510096
Trained batch 266 in epoch 2, gen_loss = 1.0312004571550348, disc_loss = 0.0008499723674262062
Trained batch 267 in epoch 2, gen_loss = 1.0315456537168417, disc_loss = 0.0008493374332476324
Trained batch 268 in epoch 2, gen_loss = 1.0316825263119098, disc_loss = 0.0008487340052470177
Trained batch 269 in epoch 2, gen_loss = 1.0316018996415315, disc_loss = 0.0008472969830984733
Trained batch 270 in epoch 2, gen_loss = 1.0316501266402072, disc_loss = 0.0008455654180942042
Trained batch 271 in epoch 2, gen_loss = 1.031394841916421, disc_loss = 0.0008443536948214066
Trained batch 272 in epoch 2, gen_loss = 1.0312377489530122, disc_loss = 0.0008437336851491324
Trained batch 273 in epoch 2, gen_loss = 1.0310325866198018, disc_loss = 0.0008429608878808736
Trained batch 274 in epoch 2, gen_loss = 1.0310729399594394, disc_loss = 0.0008418897848406976
Trained batch 275 in epoch 2, gen_loss = 1.0309153855710789, disc_loss = 0.0008405055792747484
Trained batch 276 in epoch 2, gen_loss = 1.0310844256129075, disc_loss = 0.0008392297417565925
Trained batch 277 in epoch 2, gen_loss = 1.0311761978718874, disc_loss = 0.000837706019469577
Trained batch 278 in epoch 2, gen_loss = 1.031439688897902, disc_loss = 0.0008365248396073044
Trained batch 279 in epoch 2, gen_loss = 1.0314595626933234, disc_loss = 0.0008356334156165499
Trained batch 280 in epoch 2, gen_loss = 1.0311920509219594, disc_loss = 0.0008347814044462736
Trained batch 281 in epoch 2, gen_loss = 1.031282293669721, disc_loss = 0.0008337306202816982
Trained batch 282 in epoch 2, gen_loss = 1.0315236807290742, disc_loss = 0.0008331544409537286
Trained batch 283 in epoch 2, gen_loss = 1.0316196316984338, disc_loss = 0.0008328278518476995
Trained batch 284 in epoch 2, gen_loss = 1.0315667418011447, disc_loss = 0.0008320921265087172
Trained batch 285 in epoch 2, gen_loss = 1.0315145856433816, disc_loss = 0.0008312860263431758
Trained batch 286 in epoch 2, gen_loss = 1.0311881897756863, disc_loss = 0.0008308776330408877
Trained batch 287 in epoch 2, gen_loss = 1.0313036404550076, disc_loss = 0.0008317731382905751
Trained batch 288 in epoch 2, gen_loss = 1.0313705973146696, disc_loss = 0.0008335949241378664
Trained batch 289 in epoch 2, gen_loss = 1.0314885945155703, disc_loss = 0.000835666300002325
Trained batch 290 in epoch 2, gen_loss = 1.0314742666749201, disc_loss = 0.0008383481462263659
Trained batch 291 in epoch 2, gen_loss = 1.0313039887441349, disc_loss = 0.0008401696733478138
Trained batch 292 in epoch 2, gen_loss = 1.0315426844378788, disc_loss = 0.0008414831558209065
Trained batch 293 in epoch 2, gen_loss = 1.031543518410248, disc_loss = 0.0008419933450704466
Trained batch 294 in epoch 2, gen_loss = 1.0317081423129066, disc_loss = 0.0008420465544647522
Trained batch 295 in epoch 2, gen_loss = 1.0315652558126964, disc_loss = 0.0008418066367134137
Trained batch 296 in epoch 2, gen_loss = 1.031469874911838, disc_loss = 0.0008417656314943413
Trained batch 297 in epoch 2, gen_loss = 1.031626062105166, disc_loss = 0.0008420316040892491
Trained batch 298 in epoch 2, gen_loss = 1.0317783738458435, disc_loss = 0.000842979288505029
Trained batch 299 in epoch 2, gen_loss = 1.0315793766578039, disc_loss = 0.0008460614842867168
Trained batch 300 in epoch 2, gen_loss = 1.0314527256940291, disc_loss = 0.0008499055039764156
Trained batch 301 in epoch 2, gen_loss = 1.031539081145596, disc_loss = 0.0008530319917566198
Trained batch 302 in epoch 2, gen_loss = 1.0316381055136326, disc_loss = 0.0008549701393445148
Trained batch 303 in epoch 2, gen_loss = 1.0318329481309967, disc_loss = 0.0008562712561175239
Trained batch 304 in epoch 2, gen_loss = 1.031806842420922, disc_loss = 0.0008567337180510713
Trained batch 305 in epoch 2, gen_loss = 1.0316710505220625, disc_loss = 0.0008568261255277321
Trained batch 306 in epoch 2, gen_loss = 1.0316958320645633, disc_loss = 0.0008577691524400276
Trained batch 307 in epoch 2, gen_loss = 1.0316976217867493, disc_loss = 0.0008595632977878929
Trained batch 308 in epoch 2, gen_loss = 1.032019569457156, disc_loss = 0.0008614532125648111
Trained batch 309 in epoch 2, gen_loss = 1.0321439083545438, disc_loss = 0.0008631454618279672
Trained batch 310 in epoch 2, gen_loss = 1.0320946685370909, disc_loss = 0.0008644029883468685
Trained batch 311 in epoch 2, gen_loss = 1.0321999503633914, disc_loss = 0.0008662237119913185
Trained batch 312 in epoch 2, gen_loss = 1.032343662013642, disc_loss = 0.0008678497163952289
Trained batch 313 in epoch 2, gen_loss = 1.0322210667239633, disc_loss = 0.0008694212356319793
Trained batch 314 in epoch 2, gen_loss = 1.0322537323785206, disc_loss = 0.0008709708449526853
Trained batch 315 in epoch 2, gen_loss = 1.0322019872786123, disc_loss = 0.0008722370728235869
Trained batch 316 in epoch 2, gen_loss = 1.0324874191254094, disc_loss = 0.0008734057925322772
Trained batch 317 in epoch 2, gen_loss = 1.032512406508128, disc_loss = 0.000874963123259814
Trained batch 318 in epoch 2, gen_loss = 1.03262841178332, disc_loss = 0.0008761833926778124
Trained batch 319 in epoch 2, gen_loss = 1.0326065190136433, disc_loss = 0.0008766513575210411
Trained batch 320 in epoch 2, gen_loss = 1.0326914133683915, disc_loss = 0.0008770711523244256
Trained batch 321 in epoch 2, gen_loss = 1.0326350505307595, disc_loss = 0.0008770703962282423
Trained batch 322 in epoch 2, gen_loss = 1.0325054679492678, disc_loss = 0.0008772995382231652
Trained batch 323 in epoch 2, gen_loss = 1.032479182437614, disc_loss = 0.0008789486023432138
Trained batch 324 in epoch 2, gen_loss = 1.032335055057819, disc_loss = 0.0008807625317981897
Trained batch 325 in epoch 2, gen_loss = 1.0323591294464158, disc_loss = 0.0008807209782992301
Trained batch 326 in epoch 2, gen_loss = 1.0322581491339098, disc_loss = 0.0008797084844837802
Trained batch 327 in epoch 2, gen_loss = 1.0320837315989704, disc_loss = 0.0008780905687095449
Trained batch 328 in epoch 2, gen_loss = 1.0321040834699358, disc_loss = 0.000876361467485602
Trained batch 329 in epoch 2, gen_loss = 1.0319866805365592, disc_loss = 0.0008749026204565201
Trained batch 330 in epoch 2, gen_loss = 1.0319805955598722, disc_loss = 0.0008738763549321491
Trained batch 331 in epoch 2, gen_loss = 1.031941682100296, disc_loss = 0.0008733993791869886
Trained batch 332 in epoch 2, gen_loss = 1.0319829921464663, disc_loss = 0.0008727962639030382
Trained batch 333 in epoch 2, gen_loss = 1.031860042474941, disc_loss = 0.0008718443142694929
Trained batch 334 in epoch 2, gen_loss = 1.0318791211541019, disc_loss = 0.0008709485488839503
Trained batch 335 in epoch 2, gen_loss = 1.031683936715126, disc_loss = 0.0008704178370473008
Trained batch 336 in epoch 2, gen_loss = 1.0314278729945332, disc_loss = 0.0008701159302193605
Trained batch 337 in epoch 2, gen_loss = 1.0313941134503608, disc_loss = 0.0008690712659877378
Trained batch 338 in epoch 2, gen_loss = 1.0313069328094302, disc_loss = 0.0008676816219296362
Trained batch 339 in epoch 2, gen_loss = 1.0316474735736847, disc_loss = 0.0008670471333008369
Trained batch 340 in epoch 2, gen_loss = 1.0317231843198849, disc_loss = 0.000867635502426713
Trained batch 341 in epoch 2, gen_loss = 1.0319036137290865, disc_loss = 0.0008689678934122278
Trained batch 342 in epoch 2, gen_loss = 1.0318426974660801, disc_loss = 0.0008705980607726592
Trained batch 343 in epoch 2, gen_loss = 1.0317497424954591, disc_loss = 0.0008713291001270612
Trained batch 344 in epoch 2, gen_loss = 1.0319150390832321, disc_loss = 0.0008714570275818308
Trained batch 345 in epoch 2, gen_loss = 1.0318445113697492, disc_loss = 0.0008705894535439724
Trained batch 346 in epoch 2, gen_loss = 1.031929747687293, disc_loss = 0.0008694618827628471
Trained batch 347 in epoch 2, gen_loss = 1.0319311253983399, disc_loss = 0.0008680324129366862
Trained batch 348 in epoch 2, gen_loss = 1.0319229424170573, disc_loss = 0.0008671036948127016
Trained batch 349 in epoch 2, gen_loss = 1.031988992180143, disc_loss = 0.0008656335292783167
Trained batch 350 in epoch 2, gen_loss = 1.0320885006518785, disc_loss = 0.0008642844491946031
Trained batch 351 in epoch 2, gen_loss = 1.0320764774964615, disc_loss = 0.000863022476799167
Trained batch 352 in epoch 2, gen_loss = 1.032153691009489, disc_loss = 0.0008617709703293626
Trained batch 353 in epoch 2, gen_loss = 1.0322472660218256, disc_loss = 0.0008610491250348304
Trained batch 354 in epoch 2, gen_loss = 1.0321833585349607, disc_loss = 0.000861342833787334
Trained batch 355 in epoch 2, gen_loss = 1.0318631091144648, disc_loss = 0.0008630549798888322
Trained batch 356 in epoch 2, gen_loss = 1.0317949888085116, disc_loss = 0.0008659009654264041
Trained batch 357 in epoch 2, gen_loss = 1.0316933919597604, disc_loss = 0.0008689018406849302
Trained batch 358 in epoch 2, gen_loss = 1.0315441441071067, disc_loss = 0.0008721622032169149
Trained batch 359 in epoch 2, gen_loss = 1.0313440064589183, disc_loss = 0.000874042160527703
Trained batch 360 in epoch 2, gen_loss = 1.031439194388667, disc_loss = 0.0008742392013640171
Trained batch 361 in epoch 2, gen_loss = 1.0311782175664743, disc_loss = 0.0008742469456979429
Trained batch 362 in epoch 2, gen_loss = 1.0312892031078496, disc_loss = 0.0008752702806079529
Trained batch 363 in epoch 2, gen_loss = 1.0309932023941815, disc_loss = 0.000875782321420227
Trained batch 364 in epoch 2, gen_loss = 1.0309247475780854, disc_loss = 0.0008750615302594506
Trained batch 365 in epoch 2, gen_loss = 1.0312158147819708, disc_loss = 0.0008742320188289365
Trained batch 366 in epoch 2, gen_loss = 1.0314401016248345, disc_loss = 0.0008735277569295753
Trained batch 367 in epoch 2, gen_loss = 1.0313250394942968, disc_loss = 0.000872483652963875
Trained batch 368 in epoch 2, gen_loss = 1.0312576101724371, disc_loss = 0.0008715361830441478
Trained batch 369 in epoch 2, gen_loss = 1.0310909172973117, disc_loss = 0.0008704090776469408
Trained batch 370 in epoch 2, gen_loss = 1.0309244996775193, disc_loss = 0.0008690916426194897
Trained batch 371 in epoch 2, gen_loss = 1.0313171983085654, disc_loss = 0.0008690301478328433
Trained batch 372 in epoch 2, gen_loss = 1.0314489505565838, disc_loss = 0.0008698276483020608
Trained batch 373 in epoch 2, gen_loss = 1.0314276258256985, disc_loss = 0.0008698348867187754
Trained batch 374 in epoch 2, gen_loss = 1.0313819950421652, disc_loss = 0.0008699177980888634
Trained batch 375 in epoch 2, gen_loss = 1.0312395871002624, disc_loss = 0.000869925050829671
Trained batch 376 in epoch 2, gen_loss = 1.0310351118168717, disc_loss = 0.0008699531040545948
Trained batch 377 in epoch 2, gen_loss = 1.0308847570860828, disc_loss = 0.0008702417961093869
Trained batch 378 in epoch 2, gen_loss = 1.0309828568574306, disc_loss = 0.0008706785937357143
Trained batch 379 in epoch 2, gen_loss = 1.030958567951855, disc_loss = 0.0008710458153999705
Trained batch 380 in epoch 2, gen_loss = 1.0308496659509154, disc_loss = 0.0008709724810557426
Trained batch 381 in epoch 2, gen_loss = 1.0307522211711444, disc_loss = 0.0008705516583658023
Trained batch 382 in epoch 2, gen_loss = 1.0310206134699031, disc_loss = 0.0008705446045078561
Trained batch 383 in epoch 2, gen_loss = 1.030850081704557, disc_loss = 0.0008707774917790326
Trained batch 384 in epoch 2, gen_loss = 1.0307596567389252, disc_loss = 0.0008708508182528683
Trained batch 385 in epoch 2, gen_loss = 1.0307400672855773, disc_loss = 0.0008711244322394547
Trained batch 386 in epoch 2, gen_loss = 1.030674388704374, disc_loss = 0.0008709406643685974
Trained batch 387 in epoch 2, gen_loss = 1.0309493764466846, disc_loss = 0.0008705877722210981
Trained batch 388 in epoch 2, gen_loss = 1.0310335485671664, disc_loss = 0.0008698718987882932
Trained batch 389 in epoch 2, gen_loss = 1.0312513475234693, disc_loss = 0.0008690077683870466
Trained batch 390 in epoch 2, gen_loss = 1.0311868680102745, disc_loss = 0.0008683242858774588
Trained batch 391 in epoch 2, gen_loss = 1.0311396752997322, disc_loss = 0.0008677601880644572
Trained batch 392 in epoch 2, gen_loss = 1.0311765641959871, disc_loss = 0.0008672929034033985
Trained batch 393 in epoch 2, gen_loss = 1.031219961830807, disc_loss = 0.0008665561905162655
Trained batch 394 in epoch 2, gen_loss = 1.0310182962236525, disc_loss = 0.000865997696999767
Trained batch 395 in epoch 2, gen_loss = 1.0310560192423637, disc_loss = 0.0008657686208754618
Trained batch 396 in epoch 2, gen_loss = 1.0311477386981474, disc_loss = 0.0008655539087004613
Trained batch 397 in epoch 2, gen_loss = 1.0309601047230725, disc_loss = 0.0008649013878165711
Trained batch 398 in epoch 2, gen_loss = 1.0307823216407221, disc_loss = 0.0008638976940524561
Trained batch 399 in epoch 2, gen_loss = 1.0306722983717918, disc_loss = 0.000862848561591818
Trained batch 400 in epoch 2, gen_loss = 1.0305541090834467, disc_loss = 0.0008616046755756959
Trained batch 401 in epoch 2, gen_loss = 1.0305535476006085, disc_loss = 0.0008604092405737142
Trained batch 402 in epoch 2, gen_loss = 1.0303328864036068, disc_loss = 0.0008593526221528677
Trained batch 403 in epoch 2, gen_loss = 1.0303697749824807, disc_loss = 0.0008588989554428366
Trained batch 404 in epoch 2, gen_loss = 1.0305319234176917, disc_loss = 0.0008588544026241396
Trained batch 405 in epoch 2, gen_loss = 1.030442161953508, disc_loss = 0.0008582089472937127
Trained batch 406 in epoch 2, gen_loss = 1.0305587130916791, disc_loss = 0.0008572353544520301
Trained batch 407 in epoch 2, gen_loss = 1.030822456029116, disc_loss = 0.000856224156664479
Trained batch 408 in epoch 2, gen_loss = 1.0306767185917693, disc_loss = 0.0008552080000526429
Trained batch 409 in epoch 2, gen_loss = 1.030548310134469, disc_loss = 0.0008541807288832099
Trained batch 410 in epoch 2, gen_loss = 1.0306682521409363, disc_loss = 0.0008529663885974183
Trained batch 411 in epoch 2, gen_loss = 1.0307203191287309, disc_loss = 0.0008515062361466246
Trained batch 412 in epoch 2, gen_loss = 1.0307590593437306, disc_loss = 0.000850155707671404
Trained batch 413 in epoch 2, gen_loss = 1.030820334447179, disc_loss = 0.0008487932194628335
Trained batch 414 in epoch 2, gen_loss = 1.0307727062558554, disc_loss = 0.0008476320150622492
Trained batch 415 in epoch 2, gen_loss = 1.0307976642193704, disc_loss = 0.0008467194013344572
Trained batch 416 in epoch 2, gen_loss = 1.0307605745409318, disc_loss = 0.0008457066497248452
Trained batch 417 in epoch 2, gen_loss = 1.0310398658211721, disc_loss = 0.0008448951720437213
Trained batch 418 in epoch 2, gen_loss = 1.0311269798540557, disc_loss = 0.0008437879935633792
Trained batch 419 in epoch 2, gen_loss = 1.0310228342101688, disc_loss = 0.0008426998340014723
Trained batch 420 in epoch 2, gen_loss = 1.0309381425522286, disc_loss = 0.0008417132360066537
Trained batch 421 in epoch 2, gen_loss = 1.0309046097276335, disc_loss = 0.0008404895052770638
Trained batch 422 in epoch 2, gen_loss = 1.0308602884869766, disc_loss = 0.0008392975231892391
Trained batch 423 in epoch 2, gen_loss = 1.030797856877435, disc_loss = 0.0008381463074946847
Trained batch 424 in epoch 2, gen_loss = 1.0308844058653888, disc_loss = 0.0008368778850554544
Trained batch 425 in epoch 2, gen_loss = 1.0309596576601128, disc_loss = 0.0008357699435508149
Trained batch 426 in epoch 2, gen_loss = 1.0309059949334387, disc_loss = 0.000834637356701741
Trained batch 427 in epoch 2, gen_loss = 1.0308150165827474, disc_loss = 0.0008338100335231077
Trained batch 428 in epoch 2, gen_loss = 1.0308078692787455, disc_loss = 0.0008332620080835066
Trained batch 429 in epoch 2, gen_loss = 1.0307797732741333, disc_loss = 0.0008326143265274072
Trained batch 430 in epoch 2, gen_loss = 1.0308159488812954, disc_loss = 0.0008318800070099403
Trained batch 431 in epoch 2, gen_loss = 1.030713765847462, disc_loss = 0.0008309047618105844
Trained batch 432 in epoch 2, gen_loss = 1.0305252035275343, disc_loss = 0.0008299982191496862
Trained batch 433 in epoch 2, gen_loss = 1.0303879231901212, disc_loss = 0.0008294918896412597
Trained batch 434 in epoch 2, gen_loss = 1.0302841264626075, disc_loss = 0.0008294100480437835
Trained batch 435 in epoch 2, gen_loss = 1.0304182692678696, disc_loss = 0.0008298623549283072
Trained batch 436 in epoch 2, gen_loss = 1.0303920833415243, disc_loss = 0.0008306887376551608
Trained batch 437 in epoch 2, gen_loss = 1.0301707482229085, disc_loss = 0.0008316589501440806
Trained batch 438 in epoch 2, gen_loss = 1.0299619868024334, disc_loss = 0.0008326395288675149
Trained batch 439 in epoch 2, gen_loss = 1.029993212223053, disc_loss = 0.0008335869159385435
Trained batch 440 in epoch 2, gen_loss = 1.0299235383669536, disc_loss = 0.0008338558231665206
Trained batch 441 in epoch 2, gen_loss = 1.0299357382150798, disc_loss = 0.0008335748736244074
Trained batch 442 in epoch 2, gen_loss = 1.029765945659534, disc_loss = 0.000833343162422613
Trained batch 443 in epoch 2, gen_loss = 1.0297027725625683, disc_loss = 0.000832968526443798
Trained batch 444 in epoch 2, gen_loss = 1.0296711515844539, disc_loss = 0.0008324185712655399
Trained batch 445 in epoch 2, gen_loss = 1.029631357690144, disc_loss = 0.0008316845183481041
Trained batch 446 in epoch 2, gen_loss = 1.0295421433128766, disc_loss = 0.0008309145200340248
Trained batch 447 in epoch 2, gen_loss = 1.0295484399955188, disc_loss = 0.0008299796932728246
Trained batch 448 in epoch 2, gen_loss = 1.0293694738555856, disc_loss = 0.0008289727552447526
Trained batch 449 in epoch 2, gen_loss = 1.0293215329117245, disc_loss = 0.0008279654705741753
Trained batch 450 in epoch 2, gen_loss = 1.0292805767640836, disc_loss = 0.0008272676308693038
Trained batch 451 in epoch 2, gen_loss = 1.0293786170999562, disc_loss = 0.0008271035655356317
Trained batch 452 in epoch 2, gen_loss = 1.0293308492527893, disc_loss = 0.0008270506697982369
Trained batch 453 in epoch 2, gen_loss = 1.0292881287404618, disc_loss = 0.0008268401973946471
Trained batch 454 in epoch 2, gen_loss = 1.029234040569473, disc_loss = 0.0008263019924205574
Trained batch 455 in epoch 2, gen_loss = 1.0292472772692378, disc_loss = 0.0008255595421998582
Trained batch 456 in epoch 2, gen_loss = 1.0291561575634995, disc_loss = 0.0008247425287800966
Trained batch 457 in epoch 2, gen_loss = 1.0290295554560864, disc_loss = 0.000823766683539941
Trained batch 458 in epoch 2, gen_loss = 1.0289174265071976, disc_loss = 0.0008228937564554679
Trained batch 459 in epoch 2, gen_loss = 1.0289233206406883, disc_loss = 0.0008220860652964684
Trained batch 460 in epoch 2, gen_loss = 1.0287796565353742, disc_loss = 0.0008212814273321779
Trained batch 461 in epoch 2, gen_loss = 1.0286866476783505, disc_loss = 0.0008203357362235772
Trained batch 462 in epoch 2, gen_loss = 1.028496618533495, disc_loss = 0.0008195314969848359
Trained batch 463 in epoch 2, gen_loss = 1.028341271368594, disc_loss = 0.0008187771340529032
Trained batch 464 in epoch 2, gen_loss = 1.0283732054054096, disc_loss = 0.0008181365817705149
Trained batch 465 in epoch 2, gen_loss = 1.0284823387733344, disc_loss = 0.0008173078486432078
Trained batch 466 in epoch 2, gen_loss = 1.0285188650165942, disc_loss = 0.0008164186668043809
Trained batch 467 in epoch 2, gen_loss = 1.0285377949476242, disc_loss = 0.0008153139963561001
Trained batch 468 in epoch 2, gen_loss = 1.0288912153193184, disc_loss = 0.0008147272279114723
Trained batch 469 in epoch 2, gen_loss = 1.02893215176907, disc_loss = 0.0008145297694198312
Trained batch 470 in epoch 2, gen_loss = 1.0290275054119702, disc_loss = 0.0008150797056512721
Trained batch 471 in epoch 2, gen_loss = 1.028911753478697, disc_loss = 0.0008156319944014362
Trained batch 472 in epoch 2, gen_loss = 1.0288679950081017, disc_loss = 0.0008163329498865986
Trained batch 473 in epoch 2, gen_loss = 1.0289097715027724, disc_loss = 0.0008173644128118009
Trained batch 474 in epoch 2, gen_loss = 1.0288464492245724, disc_loss = 0.0008182508211680933
Trained batch 475 in epoch 2, gen_loss = 1.0290330389217168, disc_loss = 0.0008186738959615346
Trained batch 476 in epoch 2, gen_loss = 1.0292686052792228, disc_loss = 0.0008190073496593744
Trained batch 477 in epoch 2, gen_loss = 1.0292678132466193, disc_loss = 0.0008194488044594372
Trained batch 478 in epoch 2, gen_loss = 1.0292663831800408, disc_loss = 0.000819903359474276
Trained batch 479 in epoch 2, gen_loss = 1.0293481326351563, disc_loss = 0.0008196236308625278
Trained batch 480 in epoch 2, gen_loss = 1.0293403277773867, disc_loss = 0.000818774769270963
Trained batch 481 in epoch 2, gen_loss = 1.0294272428478937, disc_loss = 0.0008178774384695735
Trained batch 482 in epoch 2, gen_loss = 1.0294268645855211, disc_loss = 0.0008168991422642207
Trained batch 483 in epoch 2, gen_loss = 1.0295238491178544, disc_loss = 0.0008159050565094626
Trained batch 484 in epoch 2, gen_loss = 1.0294952664178671, disc_loss = 0.00081503760026403
Trained batch 485 in epoch 2, gen_loss = 1.029473638951533, disc_loss = 0.0008145094572024137
Trained batch 486 in epoch 2, gen_loss = 1.0295102790885393, disc_loss = 0.0008140880369736184
Trained batch 487 in epoch 2, gen_loss = 1.0295559611232554, disc_loss = 0.0008138937419509423
Trained batch 488 in epoch 2, gen_loss = 1.0295506385450226, disc_loss = 0.0008137093150820621
Trained batch 489 in epoch 2, gen_loss = 1.0296389298779625, disc_loss = 0.0008134873248921822
Trained batch 490 in epoch 2, gen_loss = 1.0296158318364208, disc_loss = 0.0008131350025955716
Trained batch 491 in epoch 2, gen_loss = 1.0294382327455815, disc_loss = 0.0008126446489591106
Trained batch 492 in epoch 2, gen_loss = 1.0295791139950858, disc_loss = 0.0008120941512738156
Trained batch 493 in epoch 2, gen_loss = 1.0294924293935057, disc_loss = 0.0008112035247168281
Trained batch 494 in epoch 2, gen_loss = 1.0294705672697588, disc_loss = 0.0008102093622761054
Trained batch 495 in epoch 2, gen_loss = 1.029485988761148, disc_loss = 0.0008093337514911846
Trained batch 496 in epoch 2, gen_loss = 1.0294547112175156, disc_loss = 0.0008085322811926942
Trained batch 497 in epoch 2, gen_loss = 1.029489623255519, disc_loss = 0.000808084952417316
Trained batch 498 in epoch 2, gen_loss = 1.029472340323882, disc_loss = 0.0008079154466027823
Trained batch 499 in epoch 2, gen_loss = 1.0296465480327606, disc_loss = 0.0008082012693048455
Trained batch 500 in epoch 2, gen_loss = 1.0297487579181999, disc_loss = 0.0008087883508339442
Trained batch 501 in epoch 2, gen_loss = 1.0297686144175282, disc_loss = 0.0008093952320157124
Trained batch 502 in epoch 2, gen_loss = 1.0298412829696777, disc_loss = 0.0008098339136235349
Trained batch 503 in epoch 2, gen_loss = 1.0298812566768556, disc_loss = 0.0008102634535120275
Trained batch 504 in epoch 2, gen_loss = 1.0297677999675865, disc_loss = 0.0008105869626852287
Trained batch 505 in epoch 2, gen_loss = 1.029814194902601, disc_loss = 0.0008108445090400938
Trained batch 506 in epoch 2, gen_loss = 1.0299088368284162, disc_loss = 0.0008108543631730002
Trained batch 507 in epoch 2, gen_loss = 1.029960057749523, disc_loss = 0.0008104167475642849
Trained batch 508 in epoch 2, gen_loss = 1.0299508013050775, disc_loss = 0.000809789312468688
Trained batch 509 in epoch 2, gen_loss = 1.0298805992977291, disc_loss = 0.000809066503950139
Trained batch 510 in epoch 2, gen_loss = 1.029768545916869, disc_loss = 0.0008083363595589952
Trained batch 511 in epoch 2, gen_loss = 1.029817248811014, disc_loss = 0.0008078425925077681
Trained batch 512 in epoch 2, gen_loss = 1.0295713945903742, disc_loss = 0.0008076688940328188
Trained batch 513 in epoch 2, gen_loss = 1.0294830197258218, disc_loss = 0.0008076743081443968
Trained batch 514 in epoch 2, gen_loss = 1.0294593675622663, disc_loss = 0.0008077568250247142
Trained batch 515 in epoch 2, gen_loss = 1.0296292675789012, disc_loss = 0.0008078799603322824
Trained batch 516 in epoch 2, gen_loss = 1.0297925415767692, disc_loss = 0.0008082838649762438
Trained batch 517 in epoch 2, gen_loss = 1.0298814038282196, disc_loss = 0.0008092346620515823
Trained batch 518 in epoch 2, gen_loss = 1.0298754595837383, disc_loss = 0.0008101939357842296
Trained batch 519 in epoch 2, gen_loss = 1.0298739828742467, disc_loss = 0.0008110320923151448
Trained batch 520 in epoch 2, gen_loss = 1.0299636243401014, disc_loss = 0.0008118003906213791
Trained batch 521 in epoch 2, gen_loss = 1.0299361420088802, disc_loss = 0.0008122270406755508
Trained batch 522 in epoch 2, gen_loss = 1.029943638618316, disc_loss = 0.0008122528750488595
Trained batch 523 in epoch 2, gen_loss = 1.0299259691520501, disc_loss = 0.0008120669862024401
Trained batch 524 in epoch 2, gen_loss = 1.0299194866135006, disc_loss = 0.0008118496830796911
Trained batch 525 in epoch 2, gen_loss = 1.029863386439733, disc_loss = 0.0008117973437300837
Trained batch 526 in epoch 2, gen_loss = 1.0299263926791964, disc_loss = 0.0008119043934537165
Trained batch 527 in epoch 2, gen_loss = 1.0298837670548395, disc_loss = 0.0008120018803421055
Trained batch 528 in epoch 2, gen_loss = 1.0300731452741785, disc_loss = 0.0008118146851558471
Trained batch 529 in epoch 2, gen_loss = 1.029978699391743, disc_loss = 0.0008112880941656119
Trained batch 530 in epoch 2, gen_loss = 1.0300066550797213, disc_loss = 0.0008106269742026329
Trained batch 531 in epoch 2, gen_loss = 1.0300274871121673, disc_loss = 0.0008097237147368084
Trained batch 532 in epoch 2, gen_loss = 1.0301829150425337, disc_loss = 0.0008088717665536395
Trained batch 533 in epoch 2, gen_loss = 1.0301790501964225, disc_loss = 0.000808128069600959
Trained batch 534 in epoch 2, gen_loss = 1.030225480271277, disc_loss = 0.0008074909201105099
Trained batch 535 in epoch 2, gen_loss = 1.0301615109861786, disc_loss = 0.0008072784204064667
Trained batch 536 in epoch 2, gen_loss = 1.0302149020759752, disc_loss = 0.0008081792946666431
Trained batch 537 in epoch 2, gen_loss = 1.0304111028470957, disc_loss = 0.0008093824207745527
Trained batch 538 in epoch 2, gen_loss = 1.0301160096901025, disc_loss = 0.0008106997644495053
Trained batch 539 in epoch 2, gen_loss = 1.030263720949491, disc_loss = 0.000812561789158887
Trained batch 540 in epoch 2, gen_loss = 1.0302980006732694, disc_loss = 0.0008142764711612233
Trained batch 541 in epoch 2, gen_loss = 1.0303785986785958, disc_loss = 0.0008168585334386423
Trained batch 542 in epoch 2, gen_loss = 1.030543997911239, disc_loss = 0.0008198744862346394
Trained batch 543 in epoch 2, gen_loss = 1.0304721189553248, disc_loss = 0.0008226174952463171
Trained batch 544 in epoch 2, gen_loss = 1.0304634381871705, disc_loss = 0.000823462959389638
Trained batch 545 in epoch 2, gen_loss = 1.0304323084406801, disc_loss = 0.0008233562346923953
Trained batch 546 in epoch 2, gen_loss = 1.0306364889554611, disc_loss = 0.0008246963154682056
Trained batch 547 in epoch 2, gen_loss = 1.0306907614869794, disc_loss = 0.000830124722962373
Trained batch 548 in epoch 2, gen_loss = 1.0306770172926898, disc_loss = 0.0008381169742818935
Trained batch 549 in epoch 2, gen_loss = 1.0307208989966998, disc_loss = 0.0008453556040661748
Trained batch 550 in epoch 2, gen_loss = 1.0306854063066944, disc_loss = 0.0008498429018727752
Trained batch 551 in epoch 2, gen_loss = 1.0307162839217463, disc_loss = 0.0008523212602902778
Trained batch 552 in epoch 2, gen_loss = 1.03075462342602, disc_loss = 0.000853810870565666
Trained batch 553 in epoch 2, gen_loss = 1.0308583681118617, disc_loss = 0.000854955695156388
Trained batch 554 in epoch 2, gen_loss = 1.030775687608633, disc_loss = 0.0008556237574855521
Trained batch 555 in epoch 2, gen_loss = 1.0309424120530808, disc_loss = 0.0008555876147969318
Trained batch 556 in epoch 2, gen_loss = 1.0308435153704358, disc_loss = 0.0008553657770099175
Trained batch 557 in epoch 2, gen_loss = 1.030737269522896, disc_loss = 0.0008554684462323685
Trained batch 558 in epoch 2, gen_loss = 1.0308029312567122, disc_loss = 0.0008559671157412065
Trained batch 559 in epoch 2, gen_loss = 1.0305579872003623, disc_loss = 0.0008560996243301946
Trained batch 560 in epoch 2, gen_loss = 1.0304441873827508, disc_loss = 0.0008557321694775015
Trained batch 561 in epoch 2, gen_loss = 1.0303936627199641, disc_loss = 0.0008551325993193976
Trained batch 562 in epoch 2, gen_loss = 1.0305448754642614, disc_loss = 0.0008544286858368182
Trained batch 563 in epoch 2, gen_loss = 1.0306219947887652, disc_loss = 0.0008538501624699933
Trained batch 564 in epoch 2, gen_loss = 1.0306581654379854, disc_loss = 0.0008532598197451933
Trained batch 565 in epoch 2, gen_loss = 1.0307524207413408, disc_loss = 0.0008529416713682612
Trained batch 566 in epoch 2, gen_loss = 1.0308518267813183, disc_loss = 0.0008531539945048485
Trained batch 567 in epoch 2, gen_loss = 1.0306789229663325, disc_loss = 0.0008528104148687087
Trained batch 568 in epoch 2, gen_loss = 1.030808121227841, disc_loss = 0.0008523787037503819
Trained batch 569 in epoch 2, gen_loss = 1.0308463373727965, disc_loss = 0.0008521780032631859
Trained batch 570 in epoch 2, gen_loss = 1.0307615389965878, disc_loss = 0.0008513836455963643
Trained batch 571 in epoch 2, gen_loss = 1.0307472391978845, disc_loss = 0.000850649767970891
Trained batch 572 in epoch 2, gen_loss = 1.0308129315184882, disc_loss = 0.000850243672753325
Trained batch 573 in epoch 2, gen_loss = 1.0308336312347173, disc_loss = 0.0008494005791939477
Trained batch 574 in epoch 2, gen_loss = 1.0308121517430182, disc_loss = 0.0008488594723926129
Trained batch 575 in epoch 2, gen_loss = 1.0309766454415188, disc_loss = 0.0008484074358724077
Trained batch 576 in epoch 2, gen_loss = 1.03098720363769, disc_loss = 0.0008480321286359973
Trained batch 577 in epoch 2, gen_loss = 1.0310527911235716, disc_loss = 0.0008485206289746183
Trained batch 578 in epoch 2, gen_loss = 1.0309853617597327, disc_loss = 0.0008503379946552854
Trained batch 579 in epoch 2, gen_loss = 1.031173920014809, disc_loss = 0.0008543237498339169
Trained batch 580 in epoch 2, gen_loss = 1.0311905139489757, disc_loss = 0.0008595543316939746
Trained batch 581 in epoch 2, gen_loss = 1.0312851278232955, disc_loss = 0.0008656683972899889
Trained batch 582 in epoch 2, gen_loss = 1.0313761348789798, disc_loss = 0.000871187079616776
Trained batch 583 in epoch 2, gen_loss = 1.0314504859382159, disc_loss = 0.0008741932449569728
Trained batch 584 in epoch 2, gen_loss = 1.0314546083792662, disc_loss = 0.0008751238718664703
Trained batch 585 in epoch 2, gen_loss = 1.0315526207152488, disc_loss = 0.0008749742078878551
Trained batch 586 in epoch 2, gen_loss = 1.0316770424022381, disc_loss = 0.0008742889789313084
Trained batch 587 in epoch 2, gen_loss = 1.0316205400796163, disc_loss = 0.0008733804728404213
Trained batch 588 in epoch 2, gen_loss = 1.0315715091742563, disc_loss = 0.0008724378646234389
Trained batch 589 in epoch 2, gen_loss = 1.0317016717741045, disc_loss = 0.0008717879532615386
Trained batch 590 in epoch 2, gen_loss = 1.031696304956265, disc_loss = 0.0008711410711390201
Trained batch 591 in epoch 2, gen_loss = 1.0317256874530703, disc_loss = 0.0008703296470402338
Trained batch 592 in epoch 2, gen_loss = 1.0316555398511644, disc_loss = 0.0008695729919646444
Trained batch 593 in epoch 2, gen_loss = 1.0316397420284322, disc_loss = 0.0008687656081747264
Trained batch 594 in epoch 2, gen_loss = 1.03160049204065, disc_loss = 0.0008678926203885124
Trained batch 595 in epoch 2, gen_loss = 1.03157462759706, disc_loss = 0.0008671965185184057
Trained batch 596 in epoch 2, gen_loss = 1.0316612206312081, disc_loss = 0.000866447882516188
Trained batch 597 in epoch 2, gen_loss = 1.0316936681701188, disc_loss = 0.0008655458856740014
Trained batch 598 in epoch 2, gen_loss = 1.0316947862779557, disc_loss = 0.0008646258373996663
Trained batch 599 in epoch 2, gen_loss = 1.0316851833462715, disc_loss = 0.0008638918278059767
Trained batch 600 in epoch 2, gen_loss = 1.031683564681975, disc_loss = 0.0008634189475492765
Trained batch 601 in epoch 2, gen_loss = 1.031794600213485, disc_loss = 0.0008629608675129743
Trained batch 602 in epoch 2, gen_loss = 1.031823866897159, disc_loss = 0.0008626086742112917
Trained batch 603 in epoch 2, gen_loss = 1.0319066818384146, disc_loss = 0.0008626799072645487
Trained batch 604 in epoch 2, gen_loss = 1.0319088611721008, disc_loss = 0.0008630542085055755
Trained batch 605 in epoch 2, gen_loss = 1.0320046450635387, disc_loss = 0.0008634270350667786
Trained batch 606 in epoch 2, gen_loss = 1.0320471023413456, disc_loss = 0.0008637295277651915
Trained batch 607 in epoch 2, gen_loss = 1.0321347302708186, disc_loss = 0.0008634579600862038
Trained batch 608 in epoch 2, gen_loss = 1.032074838142677, disc_loss = 0.0008626821687829655
Trained batch 609 in epoch 2, gen_loss = 1.032154129665406, disc_loss = 0.000862017882029816
Trained batch 610 in epoch 2, gen_loss = 1.0319898950878024, disc_loss = 0.0008619849905623168
Trained batch 611 in epoch 2, gen_loss = 1.0318501133934346, disc_loss = 0.0008623614832888254
Trained batch 612 in epoch 2, gen_loss = 1.0319361962852043, disc_loss = 0.0008626229777897223
Trained batch 613 in epoch 2, gen_loss = 1.0321096923529907, disc_loss = 0.0008627021697945954
Trained batch 614 in epoch 2, gen_loss = 1.0321326282935415, disc_loss = 0.0008626054838958492
Trained batch 615 in epoch 2, gen_loss = 1.0320595814423128, disc_loss = 0.0008622913176493187
Trained batch 616 in epoch 2, gen_loss = 1.0321078344913897, disc_loss = 0.0008618401021415872
Trained batch 617 in epoch 2, gen_loss = 1.0321123735032807, disc_loss = 0.0008612388042690877
Trained batch 618 in epoch 2, gen_loss = 1.0320695213046713, disc_loss = 0.0008606025277710669
Trained batch 619 in epoch 2, gen_loss = 1.0320567880907365, disc_loss = 0.0008600117195577871
Trained batch 620 in epoch 2, gen_loss = 1.0321291080419568, disc_loss = 0.000859324327589803
Trained batch 621 in epoch 2, gen_loss = 1.032193849899378, disc_loss = 0.0008586733401255155
Trained batch 622 in epoch 2, gen_loss = 1.0321654044988642, disc_loss = 0.000858106505920674
Trained batch 623 in epoch 2, gen_loss = 1.0323190589745839, disc_loss = 0.0008575826472784124
Trained batch 624 in epoch 2, gen_loss = 1.0322462151527405, disc_loss = 0.0008570004092063755
Trained batch 625 in epoch 2, gen_loss = 1.032298318208597, disc_loss = 0.0008562489082354653
Trained batch 626 in epoch 2, gen_loss = 1.0321524138465832, disc_loss = 0.0008556439300001624
Trained batch 627 in epoch 2, gen_loss = 1.0320555458592762, disc_loss = 0.0008555087802659537
Trained batch 628 in epoch 2, gen_loss = 1.0320062695133287, disc_loss = 0.000855374794473001
Trained batch 629 in epoch 2, gen_loss = 1.0322247123907482, disc_loss = 0.0008555926499418944
Trained batch 630 in epoch 2, gen_loss = 1.0321237730148667, disc_loss = 0.0008565872557931351
Trained batch 631 in epoch 2, gen_loss = 1.0321610203083558, disc_loss = 0.0008576462022563048
Trained batch 632 in epoch 2, gen_loss = 1.0321968090477713, disc_loss = 0.0008583135885318173
Trained batch 633 in epoch 2, gen_loss = 1.0321947384143852, disc_loss = 0.0008580160800720879
Trained batch 634 in epoch 2, gen_loss = 1.0321362414697963, disc_loss = 0.000857298584071934
Trained batch 635 in epoch 2, gen_loss = 1.0320573788393967, disc_loss = 0.0008563273476049415
Trained batch 636 in epoch 2, gen_loss = 1.0321261169771947, disc_loss = 0.0008553281595524374
Trained batch 637 in epoch 2, gen_loss = 1.0322079198861196, disc_loss = 0.0008544273149478687
Trained batch 638 in epoch 2, gen_loss = 1.032241703758777, disc_loss = 0.0008534688221258644
Trained batch 639 in epoch 2, gen_loss = 1.0321581903845072, disc_loss = 0.0008524569735527621
Trained batch 640 in epoch 2, gen_loss = 1.032097250734588, disc_loss = 0.0008514878908884181
Trained batch 641 in epoch 2, gen_loss = 1.0321363206964416, disc_loss = 0.0008505778370415676
Trained batch 642 in epoch 2, gen_loss = 1.0321272283468053, disc_loss = 0.0008497632442757018
Trained batch 643 in epoch 2, gen_loss = 1.032149817262377, disc_loss = 0.0008488425546432759
Trained batch 644 in epoch 2, gen_loss = 1.0321746513825054, disc_loss = 0.0008479185132111256
Trained batch 645 in epoch 2, gen_loss = 1.0320462198818432, disc_loss = 0.0008469930140034154
Trained batch 646 in epoch 2, gen_loss = 1.0320111660537248, disc_loss = 0.0008461288858145343
Trained batch 647 in epoch 2, gen_loss = 1.0320435698017663, disc_loss = 0.0008452972742591634
Trained batch 648 in epoch 2, gen_loss = 1.03207501296086, disc_loss = 0.000844493319455517
Trained batch 649 in epoch 2, gen_loss = 1.0321740003732534, disc_loss = 0.0008437510240876761
Trained batch 650 in epoch 2, gen_loss = 1.032111157286918, disc_loss = 0.0008430707079040805
Trained batch 651 in epoch 2, gen_loss = 1.0320129335109443, disc_loss = 0.0008424939177937497
Trained batch 652 in epoch 2, gen_loss = 1.0319542049631407, disc_loss = 0.0008417902007851619
Trained batch 653 in epoch 2, gen_loss = 1.03185303468223, disc_loss = 0.0008410081645261656
Trained batch 654 in epoch 2, gen_loss = 1.0319109690098363, disc_loss = 0.0008404360582895633
Trained batch 655 in epoch 2, gen_loss = 1.0320510901510715, disc_loss = 0.0008400917254110071
Trained batch 656 in epoch 2, gen_loss = 1.031989016035739, disc_loss = 0.0008397856499550402
Trained batch 657 in epoch 2, gen_loss = 1.0319651047328322, disc_loss = 0.0008393933347781616
Trained batch 658 in epoch 2, gen_loss = 1.0319579046485277, disc_loss = 0.000838967329982883
Trained batch 659 in epoch 2, gen_loss = 1.031899676178441, disc_loss = 0.0008388296700132107
Trained batch 660 in epoch 2, gen_loss = 1.0319428135515523, disc_loss = 0.0008389221071251549
Trained batch 661 in epoch 2, gen_loss = 1.031867932246891, disc_loss = 0.0008386498881789526
Trained batch 662 in epoch 2, gen_loss = 1.0317460917959027, disc_loss = 0.0008378641398150901
Trained batch 663 in epoch 2, gen_loss = 1.031690848071173, disc_loss = 0.0008370424171538703
Trained batch 664 in epoch 2, gen_loss = 1.0315827555226205, disc_loss = 0.0008365750406900266
Trained batch 665 in epoch 2, gen_loss = 1.03158224711905, disc_loss = 0.0008362177985335082
Trained batch 666 in epoch 2, gen_loss = 1.0316112378369207, disc_loss = 0.0008357322888362963
Trained batch 667 in epoch 2, gen_loss = 1.0315991983620707, disc_loss = 0.0008349806606831603
Trained batch 668 in epoch 2, gen_loss = 1.0316174464197259, disc_loss = 0.0008341023374000155
Trained batch 669 in epoch 2, gen_loss = 1.0315701875224041, disc_loss = 0.0008331805777105281
Trained batch 670 in epoch 2, gen_loss = 1.031656960527872, disc_loss = 0.0008322480233775135
Trained batch 671 in epoch 2, gen_loss = 1.0316730069794826, disc_loss = 0.0008313032555980456
Trained batch 672 in epoch 2, gen_loss = 1.0316889795293425, disc_loss = 0.0008306224411794567
Trained batch 673 in epoch 2, gen_loss = 1.0317414262351368, disc_loss = 0.0008300738373105635
Trained batch 674 in epoch 2, gen_loss = 1.0316874084649263, disc_loss = 0.000829696257413296
Trained batch 675 in epoch 2, gen_loss = 1.0316703154666889, disc_loss = 0.0008289972431491027
Trained batch 676 in epoch 2, gen_loss = 1.0316593158368346, disc_loss = 0.0008284124831245673
Trained batch 677 in epoch 2, gen_loss = 1.031532441004891, disc_loss = 0.0008282353588358284
Trained batch 678 in epoch 2, gen_loss = 1.031461008781888, disc_loss = 0.000828372925216989
Trained batch 679 in epoch 2, gen_loss = 1.031559098029838, disc_loss = 0.0008287813748371691
Trained batch 680 in epoch 2, gen_loss = 1.031543750507366, disc_loss = 0.0008292083274656852
Trained batch 681 in epoch 2, gen_loss = 1.0315109357631103, disc_loss = 0.0008291328033165053
Trained batch 682 in epoch 2, gen_loss = 1.0314376878703495, disc_loss = 0.0008284902298067236
Trained batch 683 in epoch 2, gen_loss = 1.031325846649053, disc_loss = 0.0008277627233337891
Trained batch 684 in epoch 2, gen_loss = 1.0313603863228846, disc_loss = 0.0008271320877013809
Trained batch 685 in epoch 2, gen_loss = 1.0313344838494114, disc_loss = 0.0008264216789767029
Trained batch 686 in epoch 2, gen_loss = 1.0313641203369464, disc_loss = 0.0008257097803611034
Trained batch 687 in epoch 2, gen_loss = 1.0314171072528806, disc_loss = 0.0008249507239502977
Trained batch 688 in epoch 2, gen_loss = 1.0314808235286108, disc_loss = 0.0008242259371502958
Trained batch 689 in epoch 2, gen_loss = 1.031660037541735, disc_loss = 0.0008236747845185691
Trained batch 690 in epoch 2, gen_loss = 1.03159857598469, disc_loss = 0.0008233326821705574
Trained batch 691 in epoch 2, gen_loss = 1.0316252588708965, disc_loss = 0.0008233681688432762
Trained batch 692 in epoch 2, gen_loss = 1.031688344513011, disc_loss = 0.000823287153570351
Trained batch 693 in epoch 2, gen_loss = 1.0317582129916816, disc_loss = 0.0008229819525535465
Trained batch 694 in epoch 2, gen_loss = 1.0317594201444722, disc_loss = 0.0008225949598591869
Trained batch 695 in epoch 2, gen_loss = 1.0317502443989117, disc_loss = 0.0008221745588082416
Trained batch 696 in epoch 2, gen_loss = 1.0316720204681713, disc_loss = 0.0008218775628312655
Trained batch 697 in epoch 2, gen_loss = 1.0316514638399326, disc_loss = 0.0008217815738940213
Trained batch 698 in epoch 2, gen_loss = 1.0318267184265693, disc_loss = 0.0008216089573737103
Trained batch 699 in epoch 2, gen_loss = 1.0317836893456322, disc_loss = 0.0008214253610640299
Trained batch 700 in epoch 2, gen_loss = 1.0316842769760208, disc_loss = 0.0008214555433348483
Trained batch 701 in epoch 2, gen_loss = 1.0316785812547744, disc_loss = 0.0008215663141905638
Trained batch 702 in epoch 2, gen_loss = 1.031826445676524, disc_loss = 0.0008215611610486428
Trained batch 703 in epoch 2, gen_loss = 1.0318259419873357, disc_loss = 0.0008215836795360784
Trained batch 704 in epoch 2, gen_loss = 1.0319402568729212, disc_loss = 0.0008218640908442028
Trained batch 705 in epoch 2, gen_loss = 1.0319778698868523, disc_loss = 0.0008221389611408962
Trained batch 706 in epoch 2, gen_loss = 1.0319729717145378, disc_loss = 0.0008219486777613051
Trained batch 707 in epoch 2, gen_loss = 1.0320008337329336, disc_loss = 0.0008217347827965281
Trained batch 708 in epoch 2, gen_loss = 1.0320156754660506, disc_loss = 0.0008214085332023726
Trained batch 709 in epoch 2, gen_loss = 1.0319597963715943, disc_loss = 0.0008209868869785233
Trained batch 710 in epoch 2, gen_loss = 1.0319232126663842, disc_loss = 0.000820472624478567
Trained batch 711 in epoch 2, gen_loss = 1.0318853686867135, disc_loss = 0.0008198054997439122
Trained batch 712 in epoch 2, gen_loss = 1.031793589260936, disc_loss = 0.0008191301396645953
Trained batch 713 in epoch 2, gen_loss = 1.031775939614833, disc_loss = 0.0008183999470063663
Trained batch 714 in epoch 2, gen_loss = 1.031780386387885, disc_loss = 0.0008177534915414033
Trained batch 715 in epoch 2, gen_loss = 1.031763553869125, disc_loss = 0.0008170140917370988
Trained batch 716 in epoch 2, gen_loss = 1.031785194594491, disc_loss = 0.0008165432053000824
Trained batch 717 in epoch 2, gen_loss = 1.0316818915203754, disc_loss = 0.0008163264844413201
Trained batch 718 in epoch 2, gen_loss = 1.031560586125529, disc_loss = 0.0008161051874785711
Trained batch 719 in epoch 2, gen_loss = 1.031562884317504, disc_loss = 0.0008154629110221221
Trained batch 720 in epoch 2, gen_loss = 1.0315842896327894, disc_loss = 0.0008145991244604268
Trained batch 721 in epoch 2, gen_loss = 1.0316281257573918, disc_loss = 0.0008137591675249924
Trained batch 722 in epoch 2, gen_loss = 1.031531050657006, disc_loss = 0.0008131312287499855
Trained batch 723 in epoch 2, gen_loss = 1.0315457212002896, disc_loss = 0.0008127435737568307
Trained batch 724 in epoch 2, gen_loss = 1.0315121961462086, disc_loss = 0.0008128385493684368
Trained batch 725 in epoch 2, gen_loss = 1.03155080953577, disc_loss = 0.0008133181997409063
Trained batch 726 in epoch 2, gen_loss = 1.03153023742744, disc_loss = 0.0008142988923179662
Trained batch 727 in epoch 2, gen_loss = 1.0315337891762073, disc_loss = 0.0008153725226733074
Trained batch 728 in epoch 2, gen_loss = 1.0313788104613295, disc_loss = 0.0008164526272808816
Trained batch 729 in epoch 2, gen_loss = 1.0312919822457718, disc_loss = 0.0008172588766359545
Trained batch 730 in epoch 2, gen_loss = 1.0311601879495602, disc_loss = 0.0008178990337736179
Trained batch 731 in epoch 2, gen_loss = 1.0311140442480806, disc_loss = 0.0008183776513223925
Trained batch 732 in epoch 2, gen_loss = 1.0312634864250276, disc_loss = 0.0008189814806829103
Trained batch 733 in epoch 2, gen_loss = 1.0312604429936214, disc_loss = 0.0008199637212651929
Trained batch 734 in epoch 2, gen_loss = 1.031293545126104, disc_loss = 0.0008209600690459249
Trained batch 735 in epoch 2, gen_loss = 1.0311459281846234, disc_loss = 0.000821632765920462
Trained batch 736 in epoch 2, gen_loss = 1.0309883660991932, disc_loss = 0.0008226009951978657
Trained batch 737 in epoch 2, gen_loss = 1.0309952089618537, disc_loss = 0.0008239883006962715
Trained batch 738 in epoch 2, gen_loss = 1.030961525537003, disc_loss = 0.0008253312554657497
Trained batch 739 in epoch 2, gen_loss = 1.0310185378467716, disc_loss = 0.0008262762163311079
Trained batch 740 in epoch 2, gen_loss = 1.031064193017087, disc_loss = 0.000826827288813752
Trained batch 741 in epoch 2, gen_loss = 1.031158520927969, disc_loss = 0.0008269332336082067
Trained batch 742 in epoch 2, gen_loss = 1.031082979362072, disc_loss = 0.0008265261542361323
Trained batch 743 in epoch 2, gen_loss = 1.0310156657811134, disc_loss = 0.0008259441379308437
Trained batch 744 in epoch 2, gen_loss = 1.031100497789831, disc_loss = 0.0008252423493177537
Trained batch 745 in epoch 2, gen_loss = 1.031123413796719, disc_loss = 0.0008245570760183773
Trained batch 746 in epoch 2, gen_loss = 1.0311383533988452, disc_loss = 0.0008239383938657793
Trained batch 747 in epoch 2, gen_loss = 1.0311937909075284, disc_loss = 0.0008232800385042873
Trained batch 748 in epoch 2, gen_loss = 1.0311733008385977, disc_loss = 0.0008225295490354302
Trained batch 749 in epoch 2, gen_loss = 1.0311543747584024, disc_loss = 0.0008218282480762961
Trained batch 750 in epoch 2, gen_loss = 1.0311603833451253, disc_loss = 0.0008212202631447715
Trained batch 751 in epoch 2, gen_loss = 1.0310727855626574, disc_loss = 0.0008205651917531678
Trained batch 752 in epoch 2, gen_loss = 1.031002124783844, disc_loss = 0.0008197527827413946
Trained batch 753 in epoch 2, gen_loss = 1.0311932408841282, disc_loss = 0.0008195744029273136
Trained batch 754 in epoch 2, gen_loss = 1.031207470546495, disc_loss = 0.0008196290374065854
Trained batch 755 in epoch 2, gen_loss = 1.0311482580250533, disc_loss = 0.000820140133034555
Trained batch 756 in epoch 2, gen_loss = 1.0311503087513672, disc_loss = 0.0008208790501323436
Trained batch 757 in epoch 2, gen_loss = 1.0311272259123407, disc_loss = 0.000821763041531661
Trained batch 758 in epoch 2, gen_loss = 1.0310318510837078, disc_loss = 0.0008227121399472283
Trained batch 759 in epoch 2, gen_loss = 1.0309891540753213, disc_loss = 0.0008236514336826267
Trained batch 760 in epoch 2, gen_loss = 1.0309895978807306, disc_loss = 0.0008240964747810829
Trained batch 761 in epoch 2, gen_loss = 1.0310359553402177, disc_loss = 0.0008241078663234516
Trained batch 762 in epoch 2, gen_loss = 1.030939087877111, disc_loss = 0.0008239340452533178
Trained batch 763 in epoch 2, gen_loss = 1.0309840441530287, disc_loss = 0.0008242147071194087
Trained batch 764 in epoch 2, gen_loss = 1.0309403855816213, disc_loss = 0.0008247839478476071
Trained batch 765 in epoch 2, gen_loss = 1.0308822422208113, disc_loss = 0.0008251515199305968
Trained batch 766 in epoch 2, gen_loss = 1.0309258137563684, disc_loss = 0.0008250482416931222
Trained batch 767 in epoch 2, gen_loss = 1.030949905126666, disc_loss = 0.0008245398221902178
Trained batch 768 in epoch 2, gen_loss = 1.0309737248755555, disc_loss = 0.0008238087999139415
Trained batch 769 in epoch 2, gen_loss = 1.0309902936607211, disc_loss = 0.0008230999601035766
Trained batch 770 in epoch 2, gen_loss = 1.0310584214720127, disc_loss = 0.00082248906423679
Trained batch 771 in epoch 2, gen_loss = 1.031097715305541, disc_loss = 0.0008221302879333358
Trained batch 772 in epoch 2, gen_loss = 1.0309616579429606, disc_loss = 0.0008219657313519303
Trained batch 773 in epoch 2, gen_loss = 1.0309964061861507, disc_loss = 0.0008219068214585776
Trained batch 774 in epoch 2, gen_loss = 1.0308397501514803, disc_loss = 0.0008220609032451326
Trained batch 775 in epoch 2, gen_loss = 1.0308849564993505, disc_loss = 0.0008224484530934936
Trained batch 776 in epoch 2, gen_loss = 1.0309728486043912, disc_loss = 0.0008232044211690382
Trained batch 777 in epoch 2, gen_loss = 1.0309608487512887, disc_loss = 0.0008233430492025824
Trained batch 778 in epoch 2, gen_loss = 1.0310063078253504, disc_loss = 0.0008229257510184455
Trained batch 779 in epoch 2, gen_loss = 1.0310791040842349, disc_loss = 0.0008224118194051791
Trained batch 780 in epoch 2, gen_loss = 1.0310330533645522, disc_loss = 0.0008217563762151542
Trained batch 781 in epoch 2, gen_loss = 1.0310446279280632, disc_loss = 0.0008211114502902253
Trained batch 782 in epoch 2, gen_loss = 1.0310973080486479, disc_loss = 0.0008203997249403698
Trained batch 783 in epoch 2, gen_loss = 1.0310418696275778, disc_loss = 0.0008198223846861487
Trained batch 784 in epoch 2, gen_loss = 1.0311728935332816, disc_loss = 0.0008194815878538343
Trained batch 785 in epoch 2, gen_loss = 1.0311483319934087, disc_loss = 0.0008192800857820169
Trained batch 786 in epoch 2, gen_loss = 1.0311191465984912, disc_loss = 0.0008190819056560564
Trained batch 787 in epoch 2, gen_loss = 1.03102691713626, disc_loss = 0.0008188783629216209
Trained batch 788 in epoch 2, gen_loss = 1.0309952270093223, disc_loss = 0.0008187879588142455
Trained batch 789 in epoch 2, gen_loss = 1.0310773083680793, disc_loss = 0.0008189738900702788
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.0065733194351196, disc_loss = 0.0010560756782069802
Trained batch 1 in epoch 3, gen_loss = 1.0023088157176971, disc_loss = 0.0009558605379424989
Trained batch 2 in epoch 3, gen_loss = 1.001842478911082, disc_loss = 0.0008603446573639909
Trained batch 3 in epoch 3, gen_loss = 1.0080919116735458, disc_loss = 0.0008006998687051237
Trained batch 4 in epoch 3, gen_loss = 1.0132360100746154, disc_loss = 0.0007561549777165055
Trained batch 5 in epoch 3, gen_loss = 1.01114621758461, disc_loss = 0.0007010866878166174
Trained batch 6 in epoch 3, gen_loss = 1.0092880300113134, disc_loss = 0.0006615802870198552
Trained batch 7 in epoch 3, gen_loss = 1.0182549729943275, disc_loss = 0.0006557367414643522
Trained batch 8 in epoch 3, gen_loss = 1.0185331967141893, disc_loss = 0.0006563189057891981
Trained batch 9 in epoch 3, gen_loss = 1.018319410085678, disc_loss = 0.0006522995216073468
Trained batch 10 in epoch 3, gen_loss = 1.0180423205549067, disc_loss = 0.000636428015158427
Trained batch 11 in epoch 3, gen_loss = 1.0181743949651718, disc_loss = 0.0006213458958275927
Trained batch 12 in epoch 3, gen_loss = 1.0193791435315058, disc_loss = 0.0006003396500510952
Trained batch 13 in epoch 3, gen_loss = 1.0199006497859955, disc_loss = 0.0005823111361158746
Trained batch 14 in epoch 3, gen_loss = 1.0213669975598654, disc_loss = 0.0005739046454740067
Trained batch 15 in epoch 3, gen_loss = 1.0255637355148792, disc_loss = 0.0005645237542921677
Trained batch 16 in epoch 3, gen_loss = 1.0233731164651758, disc_loss = 0.0005543285343960366
Trained batch 17 in epoch 3, gen_loss = 1.0208788679705725, disc_loss = 0.0005413575886955692
Trained batch 18 in epoch 3, gen_loss = 1.0219523749853436, disc_loss = 0.0005240338497586842
Trained batch 19 in epoch 3, gen_loss = 1.0237545877695085, disc_loss = 0.0005114400286402087
Trained batch 20 in epoch 3, gen_loss = 1.0268366705803644, disc_loss = 0.000496701050516484
Trained batch 21 in epoch 3, gen_loss = 1.024261699481444, disc_loss = 0.0004855238155207851
Trained batch 22 in epoch 3, gen_loss = 1.0231772376143413, disc_loss = 0.00047411413296409273
Trained batch 23 in epoch 3, gen_loss = 1.0230270798007648, disc_loss = 0.0004623597081566307
Trained batch 24 in epoch 3, gen_loss = 1.022827455997467, disc_loss = 0.0004524234012933448
Trained batch 25 in epoch 3, gen_loss = 1.0260740358095903, disc_loss = 0.00044539862350435357
Trained batch 26 in epoch 3, gen_loss = 1.0245377178545352, disc_loss = 0.0004390323565867557
Trained batch 27 in epoch 3, gen_loss = 1.025916759456907, disc_loss = 0.00043388206696753126
Trained batch 28 in epoch 3, gen_loss = 1.025930696520312, disc_loss = 0.00042980762774622516
Trained batch 29 in epoch 3, gen_loss = 1.0251075744628906, disc_loss = 0.0004240501550763535
Trained batch 30 in epoch 3, gen_loss = 1.0236508231009207, disc_loss = 0.0004195029872672392
Trained batch 31 in epoch 3, gen_loss = 1.0226762648671865, disc_loss = 0.00041442971314609167
Trained batch 32 in epoch 3, gen_loss = 1.0241122444470723, disc_loss = 0.0004095536886862564
Trained batch 33 in epoch 3, gen_loss = 1.0241679356378668, disc_loss = 0.000406139027344419
Trained batch 34 in epoch 3, gen_loss = 1.0255134224891662, disc_loss = 0.00040123149311901735
Trained batch 35 in epoch 3, gen_loss = 1.0272603415780597, disc_loss = 0.0003956267755711451
Trained batch 36 in epoch 3, gen_loss = 1.02658611536026, disc_loss = 0.00038993482657305494
Trained batch 37 in epoch 3, gen_loss = 1.0283170577726866, disc_loss = 0.0003858180191998958
Trained batch 38 in epoch 3, gen_loss = 1.0267027876315973, disc_loss = 0.00038299112146397907
Trained batch 39 in epoch 3, gen_loss = 1.0285790696740151, disc_loss = 0.0003840759567538043
Trained batch 40 in epoch 3, gen_loss = 1.027591825985327, disc_loss = 0.000388099177010789
Trained batch 41 in epoch 3, gen_loss = 1.0261810365177335, disc_loss = 0.0003938507881165216
Trained batch 42 in epoch 3, gen_loss = 1.0236706927765247, disc_loss = 0.00040614903399580006
Trained batch 43 in epoch 3, gen_loss = 1.024228954857046, disc_loss = 0.0004171208668346728
Trained batch 44 in epoch 3, gen_loss = 1.0258777274025812, disc_loss = 0.0004312575235316116
Trained batch 45 in epoch 3, gen_loss = 1.0263379682665286, disc_loss = 0.0004483715807588811
Trained batch 46 in epoch 3, gen_loss = 1.0280083747620279, disc_loss = 0.0004652798323807842
Trained batch 47 in epoch 3, gen_loss = 1.0293715794881184, disc_loss = 0.00047522471231786767
Trained batch 48 in epoch 3, gen_loss = 1.0287860267016353, disc_loss = 0.00048125931863644524
Trained batch 49 in epoch 3, gen_loss = 1.0304244661331177, disc_loss = 0.0004894808269455097
Trained batch 50 in epoch 3, gen_loss = 1.032535291185566, disc_loss = 0.0005031035737677788
Trained batch 51 in epoch 3, gen_loss = 1.0334713963361888, disc_loss = 0.0005184189523368751
Trained batch 52 in epoch 3, gen_loss = 1.0317092391679872, disc_loss = 0.0005322217725476532
Trained batch 53 in epoch 3, gen_loss = 1.0308137525010992, disc_loss = 0.0005395741865396741
Trained batch 54 in epoch 3, gen_loss = 1.0308352893049066, disc_loss = 0.0005429098623360253
Trained batch 55 in epoch 3, gen_loss = 1.028753784086023, disc_loss = 0.0005468488221335324
Trained batch 56 in epoch 3, gen_loss = 1.029684653407649, disc_loss = 0.0005530332520975845
Trained batch 57 in epoch 3, gen_loss = 1.0282508730888367, disc_loss = 0.0005608577196434108
Trained batch 58 in epoch 3, gen_loss = 1.0282342777413838, disc_loss = 0.0005693045862599166
Trained batch 59 in epoch 3, gen_loss = 1.0287249386310577, disc_loss = 0.0005775811914645601
Trained batch 60 in epoch 3, gen_loss = 1.028646129076598, disc_loss = 0.000584118600436639
Trained batch 61 in epoch 3, gen_loss = 1.0279280793282293, disc_loss = 0.0005882979234992226
Trained batch 62 in epoch 3, gen_loss = 1.026485696671501, disc_loss = 0.0005892356374903419
Trained batch 63 in epoch 3, gen_loss = 1.0261310655623674, disc_loss = 0.0005878663066596346
Trained batch 64 in epoch 3, gen_loss = 1.0264774817686815, disc_loss = 0.0005845982274667431
Trained batch 65 in epoch 3, gen_loss = 1.0256295240286626, disc_loss = 0.0005820962090211017
Trained batch 66 in epoch 3, gen_loss = 1.028057685538904, disc_loss = 0.0005860976367031655
Trained batch 67 in epoch 3, gen_loss = 1.0281716217012966, disc_loss = 0.0005954531787959722
Trained batch 68 in epoch 3, gen_loss = 1.028000693390335, disc_loss = 0.0006031094925002317
Trained batch 69 in epoch 3, gen_loss = 1.0279768313680375, disc_loss = 0.0006091735348620984
Trained batch 70 in epoch 3, gen_loss = 1.0281544655141697, disc_loss = 0.0006136525302230131
Trained batch 71 in epoch 3, gen_loss = 1.027629379596975, disc_loss = 0.0006143412366428594
Trained batch 72 in epoch 3, gen_loss = 1.0264962446199704, disc_loss = 0.0006124621852419071
Trained batch 73 in epoch 3, gen_loss = 1.0259439429721318, disc_loss = 0.0006092469590618526
Trained batch 74 in epoch 3, gen_loss = 1.0258198086420696, disc_loss = 0.0006038174993591383
Trained batch 75 in epoch 3, gen_loss = 1.025825737338317, disc_loss = 0.0005983700864721629
Trained batch 76 in epoch 3, gen_loss = 1.02510884597704, disc_loss = 0.0005944900864027682
Trained batch 77 in epoch 3, gen_loss = 1.0246081543274415, disc_loss = 0.0005918422348958512
Trained batch 78 in epoch 3, gen_loss = 1.0244127655331092, disc_loss = 0.0005904279337588792
Trained batch 79 in epoch 3, gen_loss = 1.0245580740273, disc_loss = 0.0005892529665288748
Trained batch 80 in epoch 3, gen_loss = 1.0239137646592693, disc_loss = 0.0005867946738474945
Trained batch 81 in epoch 3, gen_loss = 1.023723055676716, disc_loss = 0.0005828090748187472
Trained batch 82 in epoch 3, gen_loss = 1.0225784577519061, disc_loss = 0.000578834854083203
Trained batch 83 in epoch 3, gen_loss = 1.023170334952218, disc_loss = 0.0005764827780824687
Trained batch 84 in epoch 3, gen_loss = 1.0219488129896277, disc_loss = 0.000577747289036565
Trained batch 85 in epoch 3, gen_loss = 1.0224524694819783, disc_loss = 0.0005818845130243274
Trained batch 86 in epoch 3, gen_loss = 1.022739905050431, disc_loss = 0.0005869388061136693
Trained batch 87 in epoch 3, gen_loss = 1.0223145031116225, disc_loss = 0.0005886303036029196
Trained batch 88 in epoch 3, gen_loss = 1.022232838561026, disc_loss = 0.0005870973092917185
Trained batch 89 in epoch 3, gen_loss = 1.0215233431922064, disc_loss = 0.0005838980720404329
Trained batch 90 in epoch 3, gen_loss = 1.0221735265228775, disc_loss = 0.0005808323039673269
Trained batch 91 in epoch 3, gen_loss = 1.0224726938683053, disc_loss = 0.0005796522031153512
Trained batch 92 in epoch 3, gen_loss = 1.023107285140663, disc_loss = 0.0005795863401945881
Trained batch 93 in epoch 3, gen_loss = 1.0232584742789572, disc_loss = 0.0005792856087630734
Trained batch 94 in epoch 3, gen_loss = 1.0231108577627885, disc_loss = 0.000578228676520092
Trained batch 95 in epoch 3, gen_loss = 1.0224630416681368, disc_loss = 0.0005758850423565794
Trained batch 96 in epoch 3, gen_loss = 1.0218729143290175, disc_loss = 0.0005720432746624958
Trained batch 97 in epoch 3, gen_loss = 1.0219890067771988, disc_loss = 0.0005681776163662422
Trained batch 98 in epoch 3, gen_loss = 1.0231480243230107, disc_loss = 0.000565977079201151
Trained batch 99 in epoch 3, gen_loss = 1.022960348725319, disc_loss = 0.000563665343215689
Trained batch 100 in epoch 3, gen_loss = 1.0227509341617622, disc_loss = 0.0005612621674000627
Trained batch 101 in epoch 3, gen_loss = 1.0236972354206384, disc_loss = 0.0005587535395570026
Trained batch 102 in epoch 3, gen_loss = 1.0239617020181082, disc_loss = 0.0005573133459920516
Trained batch 103 in epoch 3, gen_loss = 1.0244654652017813, disc_loss = 0.0005561910220421851
Trained batch 104 in epoch 3, gen_loss = 1.0244653037616185, disc_loss = 0.0005554289496060283
Trained batch 105 in epoch 3, gen_loss = 1.0245284196340814, disc_loss = 0.0005548154146691679
Trained batch 106 in epoch 3, gen_loss = 1.024313386912658, disc_loss = 0.0005536776272118718
Trained batch 107 in epoch 3, gen_loss = 1.0244320658621964, disc_loss = 0.0005517085454711276
Trained batch 108 in epoch 3, gen_loss = 1.0233515244011486, disc_loss = 0.0005493327356349472
Trained batch 109 in epoch 3, gen_loss = 1.0228078620000318, disc_loss = 0.0005482444018443031
Trained batch 110 in epoch 3, gen_loss = 1.023476629106848, disc_loss = 0.0005481420522702539
Trained batch 111 in epoch 3, gen_loss = 1.023899847375495, disc_loss = 0.0005475375648010024
Trained batch 112 in epoch 3, gen_loss = 1.0237313524811669, disc_loss = 0.0005455240620139459
Trained batch 113 in epoch 3, gen_loss = 1.0243821232988124, disc_loss = 0.0005432411902196085
Trained batch 114 in epoch 3, gen_loss = 1.0239377255025117, disc_loss = 0.0005410325457848123
Trained batch 115 in epoch 3, gen_loss = 1.023759283382317, disc_loss = 0.0005390120641095564
Trained batch 116 in epoch 3, gen_loss = 1.0242016076022744, disc_loss = 0.0005375892272155382
Trained batch 117 in epoch 3, gen_loss = 1.0239250361919403, disc_loss = 0.0005355894228175156
Trained batch 118 in epoch 3, gen_loss = 1.0235403625905013, disc_loss = 0.0005342460972620879
Trained batch 119 in epoch 3, gen_loss = 1.024122174580892, disc_loss = 0.0005330161453457549
Trained batch 120 in epoch 3, gen_loss = 1.0243255629027186, disc_loss = 0.0005306757763817075
Trained batch 121 in epoch 3, gen_loss = 1.0232590070513428, disc_loss = 0.0005279672231914506
Trained batch 122 in epoch 3, gen_loss = 1.0237172149061187, disc_loss = 0.0005262695279869637
Trained batch 123 in epoch 3, gen_loss = 1.0239679299054607, disc_loss = 0.0005257666637208463
Trained batch 124 in epoch 3, gen_loss = 1.0233059811592102, disc_loss = 0.0005246310739312321
Trained batch 125 in epoch 3, gen_loss = 1.0227065110017384, disc_loss = 0.0005229381222595712
Trained batch 126 in epoch 3, gen_loss = 1.0226622665022302, disc_loss = 0.0005208944311039155
Trained batch 127 in epoch 3, gen_loss = 1.0227669361047447, disc_loss = 0.0005187904434933444
Trained batch 128 in epoch 3, gen_loss = 1.0229070644045986, disc_loss = 0.000516586491653999
Trained batch 129 in epoch 3, gen_loss = 1.0229489780389345, disc_loss = 0.0005149452510522679
Trained batch 130 in epoch 3, gen_loss = 1.0231186574651996, disc_loss = 0.0005135153358507162
Trained batch 131 in epoch 3, gen_loss = 1.0229555517435074, disc_loss = 0.00051155299363679
Trained batch 132 in epoch 3, gen_loss = 1.0231501110514303, disc_loss = 0.0005094665592830432
Trained batch 133 in epoch 3, gen_loss = 1.0229756018119072, disc_loss = 0.0005072665853867196
Trained batch 134 in epoch 3, gen_loss = 1.0231516542258086, disc_loss = 0.0005059958987489895
Trained batch 135 in epoch 3, gen_loss = 1.0233525287579088, disc_loss = 0.0005069934225449449
Trained batch 136 in epoch 3, gen_loss = 1.0234456414723918, disc_loss = 0.0005100469226459463
Trained batch 137 in epoch 3, gen_loss = 1.023469005373941, disc_loss = 0.000512390980831064
Trained batch 138 in epoch 3, gen_loss = 1.0232507758003344, disc_loss = 0.0005136734878027932
Trained batch 139 in epoch 3, gen_loss = 1.0230493626424244, disc_loss = 0.0005133092085348576
Trained batch 140 in epoch 3, gen_loss = 1.0236010783953025, disc_loss = 0.0005123783070148226
Trained batch 141 in epoch 3, gen_loss = 1.0238155961876185, disc_loss = 0.0005114585371084617
Trained batch 142 in epoch 3, gen_loss = 1.0238721449892003, disc_loss = 0.000510745926864341
Trained batch 143 in epoch 3, gen_loss = 1.023858302583297, disc_loss = 0.0005095691554338878
Trained batch 144 in epoch 3, gen_loss = 1.024002103558902, disc_loss = 0.0005082985309980296
Trained batch 145 in epoch 3, gen_loss = 1.0245979514024028, disc_loss = 0.0005069611777873608
Trained batch 146 in epoch 3, gen_loss = 1.0251997259198402, disc_loss = 0.0005053424369068627
Trained batch 147 in epoch 3, gen_loss = 1.0253302692561537, disc_loss = 0.0005032920662661372
Trained batch 148 in epoch 3, gen_loss = 1.0256219162236924, disc_loss = 0.0005013765421486616
Trained batch 149 in epoch 3, gen_loss = 1.0259327407677967, disc_loss = 0.0004994399621500634
Trained batch 150 in epoch 3, gen_loss = 1.0257672754344562, disc_loss = 0.0004973664800967984
Trained batch 151 in epoch 3, gen_loss = 1.0255649940747964, disc_loss = 0.0004955198299668202
Trained batch 152 in epoch 3, gen_loss = 1.0254914967063207, disc_loss = 0.0004942893993917524
Trained batch 153 in epoch 3, gen_loss = 1.0253799662187502, disc_loss = 0.0004935347112825491
Trained batch 154 in epoch 3, gen_loss = 1.026047162471279, disc_loss = 0.0004930751562501574
Trained batch 155 in epoch 3, gen_loss = 1.025620997334138, disc_loss = 0.0004916513479166987
Trained batch 156 in epoch 3, gen_loss = 1.0260759755304665, disc_loss = 0.0004897679425264371
Trained batch 157 in epoch 3, gen_loss = 1.0265444098394128, disc_loss = 0.00048806536607473756
Trained batch 158 in epoch 3, gen_loss = 1.0261630940737214, disc_loss = 0.0004862188528154233
Trained batch 159 in epoch 3, gen_loss = 1.0262257937341928, disc_loss = 0.00048501519468118203
Trained batch 160 in epoch 3, gen_loss = 1.0265929065876125, disc_loss = 0.00048348256524201045
Trained batch 161 in epoch 3, gen_loss = 1.0265617904103832, disc_loss = 0.00048172372987243797
Trained batch 162 in epoch 3, gen_loss = 1.0265258020418553, disc_loss = 0.00048007845367587805
Trained batch 163 in epoch 3, gen_loss = 1.026584473688428, disc_loss = 0.0004786480053664446
Trained batch 164 in epoch 3, gen_loss = 1.025947578386827, disc_loss = 0.0004770855322324981
Trained batch 165 in epoch 3, gen_loss = 1.0255425956593938, disc_loss = 0.00047585150947182785
Trained batch 166 in epoch 3, gen_loss = 1.0252627601880513, disc_loss = 0.00047522265335801474
Trained batch 167 in epoch 3, gen_loss = 1.0252849704452924, disc_loss = 0.0004755829417956106
Trained batch 168 in epoch 3, gen_loss = 1.0251428774122655, disc_loss = 0.0004761446654499018
Trained batch 169 in epoch 3, gen_loss = 1.0248183204847223, disc_loss = 0.0004764369805343449
Trained batch 170 in epoch 3, gen_loss = 1.024768154174961, disc_loss = 0.0004759194708581774
Trained batch 171 in epoch 3, gen_loss = 1.0243068476055943, disc_loss = 0.0004754601087729815
Trained batch 172 in epoch 3, gen_loss = 1.0244057536814255, disc_loss = 0.0004782378232790254
Trained batch 173 in epoch 3, gen_loss = 1.0251155310663684, disc_loss = 0.0004822564456510176
Trained batch 174 in epoch 3, gen_loss = 1.0246321071897235, disc_loss = 0.0004830522046956633
Trained batch 175 in epoch 3, gen_loss = 1.02492245151238, disc_loss = 0.00048240459760894407
Trained batch 176 in epoch 3, gen_loss = 1.0245389608340074, disc_loss = 0.0004838537049905981
Trained batch 177 in epoch 3, gen_loss = 1.0247691300477875, disc_loss = 0.0004889422974005091
Trained batch 178 in epoch 3, gen_loss = 1.0247874053496888, disc_loss = 0.0004923151703239237
Trained batch 179 in epoch 3, gen_loss = 1.025291379292806, disc_loss = 0.0004928115839397327
Trained batch 180 in epoch 3, gen_loss = 1.025436328919553, disc_loss = 0.0004922504815303859
Trained batch 181 in epoch 3, gen_loss = 1.0253228368339957, disc_loss = 0.0004917825986362564
Trained batch 182 in epoch 3, gen_loss = 1.0254783747626133, disc_loss = 0.0004915073238850108
Trained batch 183 in epoch 3, gen_loss = 1.0255845318669858, disc_loss = 0.0004911529308035666
Trained batch 184 in epoch 3, gen_loss = 1.025485670888746, disc_loss = 0.0004908089296313355
Trained batch 185 in epoch 3, gen_loss = 1.02551600369074, disc_loss = 0.0004903161845054798
Trained batch 186 in epoch 3, gen_loss = 1.025538652975929, disc_loss = 0.0004902495583955119
Trained batch 187 in epoch 3, gen_loss = 1.025000772260605, disc_loss = 0.0004908461307925964
Trained batch 188 in epoch 3, gen_loss = 1.0251967027073814, disc_loss = 0.0004918940607692415
Trained batch 189 in epoch 3, gen_loss = 1.0251784001526079, disc_loss = 0.000492628941796475
Trained batch 190 in epoch 3, gen_loss = 1.025403563576843, disc_loss = 0.0004934383830828445
Trained batch 191 in epoch 3, gen_loss = 1.0250302481775482, disc_loss = 0.0004939700885794688
Trained batch 192 in epoch 3, gen_loss = 1.0250041852343268, disc_loss = 0.0004946634158615138
Trained batch 193 in epoch 3, gen_loss = 1.0256794270166416, disc_loss = 0.0004985426873936001
Trained batch 194 in epoch 3, gen_loss = 1.0261156629293393, disc_loss = 0.0005087081729494131
Trained batch 195 in epoch 3, gen_loss = 1.0258998883013823, disc_loss = 0.0005200600198990361
Trained batch 196 in epoch 3, gen_loss = 1.025865684305956, disc_loss = 0.0005304530068823056
Trained batch 197 in epoch 3, gen_loss = 1.0262603825993009, disc_loss = 0.000539228897935692
Trained batch 198 in epoch 3, gen_loss = 1.0263104947967145, disc_loss = 0.0005458838120044382
Trained batch 199 in epoch 3, gen_loss = 1.0265368378162385, disc_loss = 0.0005502921580045949
Trained batch 200 in epoch 3, gen_loss = 1.0264033144386253, disc_loss = 0.0005524195323811743
Trained batch 201 in epoch 3, gen_loss = 1.0261852434366057, disc_loss = 0.0005543492539926423
Trained batch 202 in epoch 3, gen_loss = 1.0263139426414603, disc_loss = 0.000557134969514368
Trained batch 203 in epoch 3, gen_loss = 1.0261620665882147, disc_loss = 0.0005619273826025664
Trained batch 204 in epoch 3, gen_loss = 1.026166114283771, disc_loss = 0.0005687456954236529
Trained batch 205 in epoch 3, gen_loss = 1.0261903315493204, disc_loss = 0.0005750656423206414
Trained batch 206 in epoch 3, gen_loss = 1.0263088621954988, disc_loss = 0.0005792921718608156
Trained batch 207 in epoch 3, gen_loss = 1.0265563689172268, disc_loss = 0.0005809167178085772
Trained batch 208 in epoch 3, gen_loss = 1.0264915128073624, disc_loss = 0.0005812951040278194
Trained batch 209 in epoch 3, gen_loss = 1.0262070948169344, disc_loss = 0.0005804960542480417
Trained batch 210 in epoch 3, gen_loss = 1.0261629562807308, disc_loss = 0.0005787477004551439
Trained batch 211 in epoch 3, gen_loss = 1.0261965132546875, disc_loss = 0.0005767329057562165
Trained batch 212 in epoch 3, gen_loss = 1.0260036523353326, disc_loss = 0.0005749872076202691
Trained batch 213 in epoch 3, gen_loss = 1.0254768821123605, disc_loss = 0.0005735919332658332
Trained batch 214 in epoch 3, gen_loss = 1.02562951126764, disc_loss = 0.0005729085842938011
Trained batch 215 in epoch 3, gen_loss = 1.0257396882882825, disc_loss = 0.000572811245850365
Trained batch 216 in epoch 3, gen_loss = 1.0256976639070818, disc_loss = 0.0005737124374383108
Trained batch 217 in epoch 3, gen_loss = 1.025514668554341, disc_loss = 0.0005749973900767829
Trained batch 218 in epoch 3, gen_loss = 1.0253698779567737, disc_loss = 0.0005767580054511133
Trained batch 219 in epoch 3, gen_loss = 1.0254645388234744, disc_loss = 0.0005787850938345813
Trained batch 220 in epoch 3, gen_loss = 1.0254762660863712, disc_loss = 0.0005813215450200408
Trained batch 221 in epoch 3, gen_loss = 1.025734623541703, disc_loss = 0.0005829631326550216
Trained batch 222 in epoch 3, gen_loss = 1.025950878992209, disc_loss = 0.0005838570082946493
Trained batch 223 in epoch 3, gen_loss = 1.02616576078747, disc_loss = 0.0005855471378838827
Trained batch 224 in epoch 3, gen_loss = 1.026369788646698, disc_loss = 0.0005889596467992912
Trained batch 225 in epoch 3, gen_loss = 1.026412527909321, disc_loss = 0.0005928569789347445
Trained batch 226 in epoch 3, gen_loss = 1.0266617413134302, disc_loss = 0.0005958050812260219
Trained batch 227 in epoch 3, gen_loss = 1.0269356074563243, disc_loss = 0.000597904991688362
Trained batch 228 in epoch 3, gen_loss = 1.026951387199252, disc_loss = 0.0006005560345571553
Trained batch 229 in epoch 3, gen_loss = 1.0272662004698878, disc_loss = 0.0006035391250169714
Trained batch 230 in epoch 3, gen_loss = 1.0269510235105241, disc_loss = 0.0006077064772477188
Trained batch 231 in epoch 3, gen_loss = 1.0267609840837018, disc_loss = 0.0006134057745431823
Trained batch 232 in epoch 3, gen_loss = 1.0271040267698754, disc_loss = 0.0006183817748593909
Trained batch 233 in epoch 3, gen_loss = 1.0273342652198596, disc_loss = 0.000622508019924315
Trained batch 234 in epoch 3, gen_loss = 1.0271946858852468, disc_loss = 0.0006253764913863245
Trained batch 235 in epoch 3, gen_loss = 1.0273734242734263, disc_loss = 0.0006273849431960054
Trained batch 236 in epoch 3, gen_loss = 1.0275310164765468, disc_loss = 0.0006276506156697948
Trained batch 237 in epoch 3, gen_loss = 1.0276268437629987, disc_loss = 0.0006269292924024884
Trained batch 238 in epoch 3, gen_loss = 1.0279251259739928, disc_loss = 0.0006261426362668838
Trained batch 239 in epoch 3, gen_loss = 1.0280204323430857, disc_loss = 0.0006253240490574778
Trained batch 240 in epoch 3, gen_loss = 1.0279987815504747, disc_loss = 0.0006240692795872596
Trained batch 241 in epoch 3, gen_loss = 1.0282774609475096, disc_loss = 0.0006224194844397677
Trained batch 242 in epoch 3, gen_loss = 1.0286774755505377, disc_loss = 0.0006208754892685209
Trained batch 243 in epoch 3, gen_loss = 1.0287111648282066, disc_loss = 0.0006194323744790889
Trained batch 244 in epoch 3, gen_loss = 1.0285951032930492, disc_loss = 0.000618139856699284
Trained batch 245 in epoch 3, gen_loss = 1.028580283004094, disc_loss = 0.0006167351279352844
Trained batch 246 in epoch 3, gen_loss = 1.0287328965750784, disc_loss = 0.0006149822187625053
Trained batch 247 in epoch 3, gen_loss = 1.028169765587776, disc_loss = 0.0006150521843547692
Trained batch 248 in epoch 3, gen_loss = 1.028294124756472, disc_loss = 0.0006189187579548892
Trained batch 249 in epoch 3, gen_loss = 1.0287935585975647, disc_loss = 0.0006248654511291534
Trained batch 250 in epoch 3, gen_loss = 1.0285478521628209, disc_loss = 0.0006306655531047855
Trained batch 251 in epoch 3, gen_loss = 1.0283234154894239, disc_loss = 0.0006347560771419445
Trained batch 252 in epoch 3, gen_loss = 1.0281569766904055, disc_loss = 0.000638183684174796
Trained batch 253 in epoch 3, gen_loss = 1.0280345312253696, disc_loss = 0.0006406602166010081
Trained batch 254 in epoch 3, gen_loss = 1.028248113744399, disc_loss = 0.0006422459506247119
Trained batch 255 in epoch 3, gen_loss = 1.0280321075115353, disc_loss = 0.0006430432308661693
Trained batch 256 in epoch 3, gen_loss = 1.0281393340125622, disc_loss = 0.0006432130843118297
Trained batch 257 in epoch 3, gen_loss = 1.027958444846693, disc_loss = 0.0006428244126628536
Trained batch 258 in epoch 3, gen_loss = 1.0277028990528299, disc_loss = 0.0006421238330505702
Trained batch 259 in epoch 3, gen_loss = 1.027793666949639, disc_loss = 0.0006407478972015759
Trained batch 260 in epoch 3, gen_loss = 1.027616199405714, disc_loss = 0.0006391773897671887
Trained batch 261 in epoch 3, gen_loss = 1.0276225350285304, disc_loss = 0.0006378061754716994
Trained batch 262 in epoch 3, gen_loss = 1.0277150397971555, disc_loss = 0.0006366538985728856
Trained batch 263 in epoch 3, gen_loss = 1.0277947887326733, disc_loss = 0.0006352103982587296
Trained batch 264 in epoch 3, gen_loss = 1.0277605825999998, disc_loss = 0.000633912793644001
Trained batch 265 in epoch 3, gen_loss = 1.0276030156397282, disc_loss = 0.0006327035741576806
Trained batch 266 in epoch 3, gen_loss = 1.0275402624955339, disc_loss = 0.0006322304586629637
Trained batch 267 in epoch 3, gen_loss = 1.0277580914657507, disc_loss = 0.000631651635259588
Trained batch 268 in epoch 3, gen_loss = 1.0278217608600744, disc_loss = 0.0006305084617996284
Trained batch 269 in epoch 3, gen_loss = 1.0280526679975015, disc_loss = 0.0006291590085041847
Trained batch 270 in epoch 3, gen_loss = 1.0276787982655626, disc_loss = 0.0006283514197452709
Trained batch 271 in epoch 3, gen_loss = 1.0278321011539768, disc_loss = 0.0006299120481986285
Trained batch 272 in epoch 3, gen_loss = 1.0275775347000513, disc_loss = 0.0006329701988358262
Trained batch 273 in epoch 3, gen_loss = 1.027408458890706, disc_loss = 0.0006349049651435318
Trained batch 274 in epoch 3, gen_loss = 1.0272897841713646, disc_loss = 0.000635767291056585
Trained batch 275 in epoch 3, gen_loss = 1.0275352592917457, disc_loss = 0.0006365230747442051
Trained batch 276 in epoch 3, gen_loss = 1.0275236824359275, disc_loss = 0.0006373182144743098
Trained batch 277 in epoch 3, gen_loss = 1.0279212859894733, disc_loss = 0.0006376309232914439
Trained batch 278 in epoch 3, gen_loss = 1.0279511080847845, disc_loss = 0.0006370893071925495
Trained batch 279 in epoch 3, gen_loss = 1.0279890826770237, disc_loss = 0.0006366345255498475
Trained batch 280 in epoch 3, gen_loss = 1.0277491307343452, disc_loss = 0.0006368540001521881
Trained batch 281 in epoch 3, gen_loss = 1.0276527096193733, disc_loss = 0.0006380078205999799
Trained batch 282 in epoch 3, gen_loss = 1.027914760390777, disc_loss = 0.0006407269330875448
Trained batch 283 in epoch 3, gen_loss = 1.0278081749106798, disc_loss = 0.0006436603784812844
Trained batch 284 in epoch 3, gen_loss = 1.0277521553792452, disc_loss = 0.0006452143112128078
Trained batch 285 in epoch 3, gen_loss = 1.0274610775750834, disc_loss = 0.0006453972626815329
Trained batch 286 in epoch 3, gen_loss = 1.0274283410364742, disc_loss = 0.0006447464467706938
Trained batch 287 in epoch 3, gen_loss = 1.0273948334571388, disc_loss = 0.0006436203022227952
Trained batch 288 in epoch 3, gen_loss = 1.0272429527708404, disc_loss = 0.0006422765031243452
Trained batch 289 in epoch 3, gen_loss = 1.027003876505227, disc_loss = 0.0006409115774721582
Trained batch 290 in epoch 3, gen_loss = 1.0271214009150607, disc_loss = 0.000639437441144033
Trained batch 291 in epoch 3, gen_loss = 1.0267158295602015, disc_loss = 0.0006380259088373724
Trained batch 292 in epoch 3, gen_loss = 1.0268279812441752, disc_loss = 0.0006375872488224993
Trained batch 293 in epoch 3, gen_loss = 1.026775790112359, disc_loss = 0.0006379925643017066
Trained batch 294 in epoch 3, gen_loss = 1.0269382684917774, disc_loss = 0.000638461284984645
Trained batch 295 in epoch 3, gen_loss = 1.026752447759783, disc_loss = 0.0006384939665499464
Trained batch 296 in epoch 3, gen_loss = 1.0268364538648715, disc_loss = 0.0006382641066880959
Trained batch 297 in epoch 3, gen_loss = 1.026755142531939, disc_loss = 0.0006372039858232278
Trained batch 298 in epoch 3, gen_loss = 1.0268430095851222, disc_loss = 0.0006361900286902408
Trained batch 299 in epoch 3, gen_loss = 1.0267992782592774, disc_loss = 0.0006357042703408904
Trained batch 300 in epoch 3, gen_loss = 1.0269498151798184, disc_loss = 0.0006357787556089987
Trained batch 301 in epoch 3, gen_loss = 1.0266022605217056, disc_loss = 0.000636070514021099
Trained batch 302 in epoch 3, gen_loss = 1.0266645806457344, disc_loss = 0.0006357236510690566
Trained batch 303 in epoch 3, gen_loss = 1.0264766857420142, disc_loss = 0.0006348702345349011
Trained batch 304 in epoch 3, gen_loss = 1.0265191811030028, disc_loss = 0.0006341076778060925
Trained batch 305 in epoch 3, gen_loss = 1.026475056908489, disc_loss = 0.0006332861993738048
Trained batch 306 in epoch 3, gen_loss = 1.026516284344639, disc_loss = 0.0006326493795855723
Trained batch 307 in epoch 3, gen_loss = 1.0265447588322998, disc_loss = 0.0006319131540507229
Trained batch 308 in epoch 3, gen_loss = 1.0265292062342746, disc_loss = 0.0006312819504918242
Trained batch 309 in epoch 3, gen_loss = 1.0263446990520724, disc_loss = 0.0006306946092198843
Trained batch 310 in epoch 3, gen_loss = 1.0264973998836382, disc_loss = 0.0006301530949502638
Trained batch 311 in epoch 3, gen_loss = 1.026366542547177, disc_loss = 0.0006295981576187889
Trained batch 312 in epoch 3, gen_loss = 1.0264144339881385, disc_loss = 0.0006293262800513454
Trained batch 313 in epoch 3, gen_loss = 1.026428653935718, disc_loss = 0.0006290755766591466
Trained batch 314 in epoch 3, gen_loss = 1.0262952528302631, disc_loss = 0.0006283575777492915
Trained batch 315 in epoch 3, gen_loss = 1.0263570554648773, disc_loss = 0.0006272072652469042
Trained batch 316 in epoch 3, gen_loss = 1.0264637767328448, disc_loss = 0.0006259988545097134
Trained batch 317 in epoch 3, gen_loss = 1.0265709472902167, disc_loss = 0.0006247432996264846
Trained batch 318 in epoch 3, gen_loss = 1.02648591789706, disc_loss = 0.0006236769599737132
Trained batch 319 in epoch 3, gen_loss = 1.0263986771926283, disc_loss = 0.0006230902229162893
Trained batch 320 in epoch 3, gen_loss = 1.02643982105166, disc_loss = 0.0006229166352466428
Trained batch 321 in epoch 3, gen_loss = 1.0262634496881355, disc_loss = 0.0006225344581512868
Trained batch 322 in epoch 3, gen_loss = 1.026168069787808, disc_loss = 0.0006218067862417104
Trained batch 323 in epoch 3, gen_loss = 1.0261282804939482, disc_loss = 0.0006216529665251096
Trained batch 324 in epoch 3, gen_loss = 1.0263269473956182, disc_loss = 0.0006221130084192667
Trained batch 325 in epoch 3, gen_loss = 1.0264920045627406, disc_loss = 0.0006221718647380851
Trained batch 326 in epoch 3, gen_loss = 1.026584563816724, disc_loss = 0.0006220188210892778
Trained batch 327 in epoch 3, gen_loss = 1.02673998747657, disc_loss = 0.0006221057971809542
Trained batch 328 in epoch 3, gen_loss = 1.026709188987419, disc_loss = 0.0006235848937914665
Trained batch 329 in epoch 3, gen_loss = 1.0266138981689106, disc_loss = 0.0006263215881931088
Trained batch 330 in epoch 3, gen_loss = 1.0266005051100002, disc_loss = 0.0006291995003409374
Trained batch 331 in epoch 3, gen_loss = 1.0264969225748475, disc_loss = 0.000630911502116486
Trained batch 332 in epoch 3, gen_loss = 1.0265847142036255, disc_loss = 0.0006313719004046525
Trained batch 333 in epoch 3, gen_loss = 1.0264015454732016, disc_loss = 0.00063102983652292
Trained batch 334 in epoch 3, gen_loss = 1.0262212721269521, disc_loss = 0.0006301290497666836
Trained batch 335 in epoch 3, gen_loss = 1.026263603497119, disc_loss = 0.0006291888757914421
Trained batch 336 in epoch 3, gen_loss = 1.026086359950838, disc_loss = 0.0006283661755211568
Trained batch 337 in epoch 3, gen_loss = 1.0258784080750845, disc_loss = 0.0006278688928884587
Trained batch 338 in epoch 3, gen_loss = 1.0254771317352587, disc_loss = 0.0006281885342582494
Trained batch 339 in epoch 3, gen_loss = 1.0255591562565636, disc_loss = 0.0006293133060834782
Trained batch 340 in epoch 3, gen_loss = 1.025741735686305, disc_loss = 0.0006303077547341896
Trained batch 341 in epoch 3, gen_loss = 1.0256120759492728, disc_loss = 0.000630437239586874
Trained batch 342 in epoch 3, gen_loss = 1.025507953702187, disc_loss = 0.0006301836341869972
Trained batch 343 in epoch 3, gen_loss = 1.0254455233036086, disc_loss = 0.0006297466881606365
Trained batch 344 in epoch 3, gen_loss = 1.0253646778023762, disc_loss = 0.0006288239486478404
Trained batch 345 in epoch 3, gen_loss = 1.0251211370691398, disc_loss = 0.0006278050433648508
Trained batch 346 in epoch 3, gen_loss = 1.0251544069831584, disc_loss = 0.0006267959285129576
Trained batch 347 in epoch 3, gen_loss = 1.0249688815453957, disc_loss = 0.0006255516208271394
Trained batch 348 in epoch 3, gen_loss = 1.0253729798049163, disc_loss = 0.0006247718435632769
Trained batch 349 in epoch 3, gen_loss = 1.0253845887524742, disc_loss = 0.0006239477424865721
Trained batch 350 in epoch 3, gen_loss = 1.0252684947432276, disc_loss = 0.000622895946372977
Trained batch 351 in epoch 3, gen_loss = 1.0254075474698434, disc_loss = 0.0006219329855577433
Trained batch 352 in epoch 3, gen_loss = 1.0254804238719237, disc_loss = 0.0006211024236871278
Trained batch 353 in epoch 3, gen_loss = 1.0257035542679371, disc_loss = 0.0006202600946426944
Trained batch 354 in epoch 3, gen_loss = 1.0256016521386697, disc_loss = 0.0006194021190028034
Trained batch 355 in epoch 3, gen_loss = 1.0256961019856206, disc_loss = 0.0006187153697518104
Trained batch 356 in epoch 3, gen_loss = 1.0258057215968435, disc_loss = 0.0006178603704457226
Trained batch 357 in epoch 3, gen_loss = 1.026166696621719, disc_loss = 0.0006170345526159346
Trained batch 358 in epoch 3, gen_loss = 1.0263034608370747, disc_loss = 0.000616255542806552
Trained batch 359 in epoch 3, gen_loss = 1.0260124198264546, disc_loss = 0.0006155030765916713
Trained batch 360 in epoch 3, gen_loss = 1.0261148050881488, disc_loss = 0.0006146790935652114
Trained batch 361 in epoch 3, gen_loss = 1.026067048640541, disc_loss = 0.0006140863375518939
Trained batch 362 in epoch 3, gen_loss = 1.0257685087600688, disc_loss = 0.000614257731862025
Trained batch 363 in epoch 3, gen_loss = 1.0258798499356259, disc_loss = 0.0006149958042862216
Trained batch 364 in epoch 3, gen_loss = 1.0257492507973762, disc_loss = 0.0006159861257526233
Trained batch 365 in epoch 3, gen_loss = 1.0257548189879766, disc_loss = 0.0006172382502986469
Trained batch 366 in epoch 3, gen_loss = 1.0256608456616831, disc_loss = 0.00061913540443927
Trained batch 367 in epoch 3, gen_loss = 1.0256866147012815, disc_loss = 0.0006208835922497319
Trained batch 368 in epoch 3, gen_loss = 1.0254829160889314, disc_loss = 0.0006221901528145437
Trained batch 369 in epoch 3, gen_loss = 1.025729167622489, disc_loss = 0.0006233606054494786
Trained batch 370 in epoch 3, gen_loss = 1.0256961919869374, disc_loss = 0.0006246073561770128
Trained batch 371 in epoch 3, gen_loss = 1.0253821106687668, disc_loss = 0.000626427885162161
Trained batch 372 in epoch 3, gen_loss = 1.0252909399868655, disc_loss = 0.0006287583736649742
Trained batch 373 in epoch 3, gen_loss = 1.0254969929947573, disc_loss = 0.0006294728624917701
Trained batch 374 in epoch 3, gen_loss = 1.0255528305371602, disc_loss = 0.0006297486273494239
Trained batch 375 in epoch 3, gen_loss = 1.025463359945632, disc_loss = 0.0006296420808521748
Trained batch 376 in epoch 3, gen_loss = 1.0255877407223224, disc_loss = 0.0006293042285219007
Trained batch 377 in epoch 3, gen_loss = 1.025668665687874, disc_loss = 0.0006284851188726462
Trained batch 378 in epoch 3, gen_loss = 1.0258281540744851, disc_loss = 0.0006276791371846827
Trained batch 379 in epoch 3, gen_loss = 1.0260618600406144, disc_loss = 0.00062688523715846
Trained batch 380 in epoch 3, gen_loss = 1.025911911109614, disc_loss = 0.0006259885070655432
Trained batch 381 in epoch 3, gen_loss = 1.0257389228693479, disc_loss = 0.0006251583059537176
Trained batch 382 in epoch 3, gen_loss = 1.025581547392255, disc_loss = 0.0006245165397568093
Trained batch 383 in epoch 3, gen_loss = 1.0256823852347832, disc_loss = 0.000624155796648059
Trained batch 384 in epoch 3, gen_loss = 1.0257161522840526, disc_loss = 0.0006238669716048526
Trained batch 385 in epoch 3, gen_loss = 1.0258623051211007, disc_loss = 0.0006238216298033358
Trained batch 386 in epoch 3, gen_loss = 1.0259026090304058, disc_loss = 0.0006236216260252029
Trained batch 387 in epoch 3, gen_loss = 1.0257643014192581, disc_loss = 0.0006231702136199264
Trained batch 388 in epoch 3, gen_loss = 1.0258731543251665, disc_loss = 0.0006224621487359438
Trained batch 389 in epoch 3, gen_loss = 1.0258988589812548, disc_loss = 0.0006215361380152619
Trained batch 390 in epoch 3, gen_loss = 1.0258875852045806, disc_loss = 0.0006205459077925305
Trained batch 391 in epoch 3, gen_loss = 1.0259313423718726, disc_loss = 0.0006194557363229177
Trained batch 392 in epoch 3, gen_loss = 1.026120323716229, disc_loss = 0.0006183939591585126
Trained batch 393 in epoch 3, gen_loss = 1.0259637701027284, disc_loss = 0.0006174814073250128
Trained batch 394 in epoch 3, gen_loss = 1.0257826456540748, disc_loss = 0.0006170636987169214
Trained batch 395 in epoch 3, gen_loss = 1.0257861013665344, disc_loss = 0.0006167381509684022
Trained batch 396 in epoch 3, gen_loss = 1.0256702003611124, disc_loss = 0.0006166377741657549
Trained batch 397 in epoch 3, gen_loss = 1.0254347622394562, disc_loss = 0.0006166993458354589
Trained batch 398 in epoch 3, gen_loss = 1.0252268354695542, disc_loss = 0.000616819994548338
Trained batch 399 in epoch 3, gen_loss = 1.025143000036478, disc_loss = 0.0006174048024331569
Trained batch 400 in epoch 3, gen_loss = 1.025030566272593, disc_loss = 0.0006181065595468989
Trained batch 401 in epoch 3, gen_loss = 1.024961621607121, disc_loss = 0.0006187630055888686
Trained batch 402 in epoch 3, gen_loss = 1.0250509441934212, disc_loss = 0.0006189535178920652
Trained batch 403 in epoch 3, gen_loss = 1.024861592172396, disc_loss = 0.0006189237412922246
Trained batch 404 in epoch 3, gen_loss = 1.0248322045361553, disc_loss = 0.0006188537575876524
Trained batch 405 in epoch 3, gen_loss = 1.0247262087948803, disc_loss = 0.0006185841906555983
Trained batch 406 in epoch 3, gen_loss = 1.0247475553203274, disc_loss = 0.0006184016822546112
Trained batch 407 in epoch 3, gen_loss = 1.0247021150939606, disc_loss = 0.0006187647966226887
Trained batch 408 in epoch 3, gen_loss = 1.0247935732885793, disc_loss = 0.0006202371216542486
Trained batch 409 in epoch 3, gen_loss = 1.0246458393771474, disc_loss = 0.0006220187842434204
Trained batch 410 in epoch 3, gen_loss = 1.0246087364906813, disc_loss = 0.0006232929457850876
Trained batch 411 in epoch 3, gen_loss = 1.0245926238379433, disc_loss = 0.0006237610687094275
Trained batch 412 in epoch 3, gen_loss = 1.0247447741810982, disc_loss = 0.0006237310843559695
Trained batch 413 in epoch 3, gen_loss = 1.024500246497168, disc_loss = 0.0006236637979259395
Trained batch 414 in epoch 3, gen_loss = 1.0246747490871384, disc_loss = 0.0006237275553067742
Trained batch 415 in epoch 3, gen_loss = 1.0245748289789145, disc_loss = 0.0006238953863500613
Trained batch 416 in epoch 3, gen_loss = 1.0245944983381734, disc_loss = 0.0006238932143637187
Trained batch 417 in epoch 3, gen_loss = 1.0247014636913556, disc_loss = 0.0006239727883013166
Trained batch 418 in epoch 3, gen_loss = 1.0247291589693692, disc_loss = 0.0006241444916103751
Trained batch 419 in epoch 3, gen_loss = 1.0248370895783105, disc_loss = 0.0006243928141235042
Trained batch 420 in epoch 3, gen_loss = 1.0248340658507267, disc_loss = 0.0006243502635123305
Trained batch 421 in epoch 3, gen_loss = 1.024770817626709, disc_loss = 0.0006239013699138806
Trained batch 422 in epoch 3, gen_loss = 1.0246411525329517, disc_loss = 0.0006231622113425165
Trained batch 423 in epoch 3, gen_loss = 1.0246849847289752, disc_loss = 0.0006224175032466004
Trained batch 424 in epoch 3, gen_loss = 1.0249401945226333, disc_loss = 0.0006220409668201361
Trained batch 425 in epoch 3, gen_loss = 1.0249611738142272, disc_loss = 0.0006220669678219446
Trained batch 426 in epoch 3, gen_loss = 1.024839726209082, disc_loss = 0.0006222738599144599
Trained batch 427 in epoch 3, gen_loss = 1.0248668146467654, disc_loss = 0.0006225756460310626
Trained batch 428 in epoch 3, gen_loss = 1.0246792717691346, disc_loss = 0.0006229901363862036
Trained batch 429 in epoch 3, gen_loss = 1.0246754743332087, disc_loss = 0.0006236616793822302
Trained batch 430 in epoch 3, gen_loss = 1.0247263261171062, disc_loss = 0.000623892312441313
Trained batch 431 in epoch 3, gen_loss = 1.0245780285309862, disc_loss = 0.0006238555985907658
Trained batch 432 in epoch 3, gen_loss = 1.0244939511697781, disc_loss = 0.0006238253079459618
Trained batch 433 in epoch 3, gen_loss = 1.0245233491269126, disc_loss = 0.0006236505736197207
Trained batch 434 in epoch 3, gen_loss = 1.0245359045335616, disc_loss = 0.0006233191960317286
Trained batch 435 in epoch 3, gen_loss = 1.024523902923689, disc_loss = 0.0006227676075209816
Trained batch 436 in epoch 3, gen_loss = 1.0246425916182913, disc_loss = 0.0006218617466316735
Trained batch 437 in epoch 3, gen_loss = 1.0247279108931484, disc_loss = 0.0006210350310036564
Trained batch 438 in epoch 3, gen_loss = 1.0246341744425085, disc_loss = 0.0006201094474403743
Trained batch 439 in epoch 3, gen_loss = 1.0246502404863185, disc_loss = 0.0006192188767189774
Trained batch 440 in epoch 3, gen_loss = 1.0246358658451071, disc_loss = 0.0006185586176785723
Trained batch 441 in epoch 3, gen_loss = 1.0244928402868332, disc_loss = 0.0006180095786402082
Trained batch 442 in epoch 3, gen_loss = 1.0245648919863302, disc_loss = 0.0006176667264229082
Trained batch 443 in epoch 3, gen_loss = 1.0246248421099808, disc_loss = 0.0006172416308857522
Trained batch 444 in epoch 3, gen_loss = 1.0247585916787052, disc_loss = 0.00061676396698602
Trained batch 445 in epoch 3, gen_loss = 1.0247243718983348, disc_loss = 0.0006159424896713768
Trained batch 446 in epoch 3, gen_loss = 1.024608407911305, disc_loss = 0.000615198376034574
Trained batch 447 in epoch 3, gen_loss = 1.024630098869758, disc_loss = 0.0006145207994125355
Trained batch 448 in epoch 3, gen_loss = 1.0247519402567686, disc_loss = 0.0006137363817026831
Trained batch 449 in epoch 3, gen_loss = 1.024642398489846, disc_loss = 0.0006129823532925609
Trained batch 450 in epoch 3, gen_loss = 1.0247781426044895, disc_loss = 0.0006124596917800948
Trained batch 451 in epoch 3, gen_loss = 1.0248409838011834, disc_loss = 0.0006117111482939259
Trained batch 452 in epoch 3, gen_loss = 1.0246422421063808, disc_loss = 0.0006107801995389204
Trained batch 453 in epoch 3, gen_loss = 1.024794488620128, disc_loss = 0.0006099227816315207
Trained batch 454 in epoch 3, gen_loss = 1.0248569783273633, disc_loss = 0.0006090804505619927
Trained batch 455 in epoch 3, gen_loss = 1.0246427350661211, disc_loss = 0.0006081942993707918
Trained batch 456 in epoch 3, gen_loss = 1.024880350940337, disc_loss = 0.0006075024764199743
Trained batch 457 in epoch 3, gen_loss = 1.0248591851719602, disc_loss = 0.0006070224485702215
Trained batch 458 in epoch 3, gen_loss = 1.0249872949128578, disc_loss = 0.0006071419626880693
Trained batch 459 in epoch 3, gen_loss = 1.0249668200378832, disc_loss = 0.0006074672062823083
Trained batch 460 in epoch 3, gen_loss = 1.0250149806254338, disc_loss = 0.0006078051239589973
Trained batch 461 in epoch 3, gen_loss = 1.0248542030652363, disc_loss = 0.0006081823034887807
Trained batch 462 in epoch 3, gen_loss = 1.0250102366536018, disc_loss = 0.0006083764396892
Trained batch 463 in epoch 3, gen_loss = 1.0249613001942635, disc_loss = 0.0006082333369516258
Trained batch 464 in epoch 3, gen_loss = 1.0248865491600447, disc_loss = 0.0006081100502264216
Trained batch 465 in epoch 3, gen_loss = 1.0248048649581205, disc_loss = 0.0006081664917829183
Trained batch 466 in epoch 3, gen_loss = 1.0249006820950315, disc_loss = 0.0006081539489953565
Trained batch 467 in epoch 3, gen_loss = 1.0248479345160673, disc_loss = 0.0006076821314659006
Trained batch 468 in epoch 3, gen_loss = 1.024946650589453, disc_loss = 0.0006070164927300801
Trained batch 469 in epoch 3, gen_loss = 1.0249675219363354, disc_loss = 0.0006062409500876303
Trained batch 470 in epoch 3, gen_loss = 1.0248792737152925, disc_loss = 0.0006054670993530839
Trained batch 471 in epoch 3, gen_loss = 1.0249266845442482, disc_loss = 0.0006048626381910299
Trained batch 472 in epoch 3, gen_loss = 1.0250789828078692, disc_loss = 0.0006046758509148996
Trained batch 473 in epoch 3, gen_loss = 1.0249593284311174, disc_loss = 0.0006045840846933129
Trained batch 474 in epoch 3, gen_loss = 1.0249609295945419, disc_loss = 0.0006041354612802694
Trained batch 475 in epoch 3, gen_loss = 1.0247093444110966, disc_loss = 0.0006037941655281544
Trained batch 476 in epoch 3, gen_loss = 1.0247496541441112, disc_loss = 0.0006031182700335155
Trained batch 477 in epoch 3, gen_loss = 1.0247851216144641, disc_loss = 0.0006027373464383033
Trained batch 478 in epoch 3, gen_loss = 1.024952378302875, disc_loss = 0.000602563956660308
Trained batch 479 in epoch 3, gen_loss = 1.0250393231709798, disc_loss = 0.0006024491900764891
Trained batch 480 in epoch 3, gen_loss = 1.0250346690354377, disc_loss = 0.0006021881739431295
Trained batch 481 in epoch 3, gen_loss = 1.0249850156396256, disc_loss = 0.0006017497023294633
Trained batch 482 in epoch 3, gen_loss = 1.0250179071604095, disc_loss = 0.0006011702233525842
Trained batch 483 in epoch 3, gen_loss = 1.025040846225644, disc_loss = 0.0006004868117404028
Trained batch 484 in epoch 3, gen_loss = 1.0252895586269417, disc_loss = 0.000600022756519785
Trained batch 485 in epoch 3, gen_loss = 1.0251614138667966, disc_loss = 0.0005995838026721663
Trained batch 486 in epoch 3, gen_loss = 1.0251105848768653, disc_loss = 0.0005993350072574058
Trained batch 487 in epoch 3, gen_loss = 1.0251515413649748, disc_loss = 0.0005993902067246859
Trained batch 488 in epoch 3, gen_loss = 1.025030813699851, disc_loss = 0.0005993114587418061
Trained batch 489 in epoch 3, gen_loss = 1.0249435265453495, disc_loss = 0.000598883561460938
Trained batch 490 in epoch 3, gen_loss = 1.024953896183589, disc_loss = 0.0005984063618690773
Trained batch 491 in epoch 3, gen_loss = 1.0249837245640716, disc_loss = 0.0005977304250499275
Trained batch 492 in epoch 3, gen_loss = 1.0249176772564468, disc_loss = 0.0005969907314803274
Trained batch 493 in epoch 3, gen_loss = 1.0247894727025437, disc_loss = 0.0005962083930432936
Trained batch 494 in epoch 3, gen_loss = 1.024865654141012, disc_loss = 0.0005956395657091035
Trained batch 495 in epoch 3, gen_loss = 1.0248419833519766, disc_loss = 0.0005954469883832762
Trained batch 496 in epoch 3, gen_loss = 1.0249506293887822, disc_loss = 0.0005955739153567346
Trained batch 497 in epoch 3, gen_loss = 1.025110090951843, disc_loss = 0.000596039722402193
Trained batch 498 in epoch 3, gen_loss = 1.0252688560552732, disc_loss = 0.0005970617560219516
Trained batch 499 in epoch 3, gen_loss = 1.0251304265260697, disc_loss = 0.0005989107229688671
Trained batch 500 in epoch 3, gen_loss = 1.0251844168423179, disc_loss = 0.0006012532534670296
Trained batch 501 in epoch 3, gen_loss = 1.0251735670870519, disc_loss = 0.0006029745819827679
Trained batch 502 in epoch 3, gen_loss = 1.0253616975505593, disc_loss = 0.000604231352217738
Trained batch 503 in epoch 3, gen_loss = 1.0254454256759749, disc_loss = 0.0006050895399167775
Trained batch 504 in epoch 3, gen_loss = 1.0255721685909989, disc_loss = 0.0006055080941313472
Trained batch 505 in epoch 3, gen_loss = 1.0255711143431456, disc_loss = 0.0006056473473500619
Trained batch 506 in epoch 3, gen_loss = 1.0256840330374077, disc_loss = 0.0006057088348233367
Trained batch 507 in epoch 3, gen_loss = 1.0257732200575627, disc_loss = 0.0006057965360601583
Trained batch 508 in epoch 3, gen_loss = 1.0255765043682106, disc_loss = 0.0006059712785182243
Trained batch 509 in epoch 3, gen_loss = 1.0254136985423519, disc_loss = 0.0006062787322626522
Trained batch 510 in epoch 3, gen_loss = 1.0254047619153375, disc_loss = 0.0006065875641924626
Trained batch 511 in epoch 3, gen_loss = 1.0253839248325676, disc_loss = 0.0006067753613194782
Trained batch 512 in epoch 3, gen_loss = 1.0253114652680142, disc_loss = 0.0006067914158170752
Trained batch 513 in epoch 3, gen_loss = 1.0253208605463866, disc_loss = 0.0006068805447525475
Trained batch 514 in epoch 3, gen_loss = 1.0252460529503313, disc_loss = 0.0006070214660230174
Trained batch 515 in epoch 3, gen_loss = 1.0254626651835996, disc_loss = 0.0006073267120304391
Trained batch 516 in epoch 3, gen_loss = 1.0254787304645812, disc_loss = 0.0006078180547781574
Trained batch 517 in epoch 3, gen_loss = 1.025394174468103, disc_loss = 0.000608629391960841
Trained batch 518 in epoch 3, gen_loss = 1.025461004304059, disc_loss = 0.0006093160421280226
Trained batch 519 in epoch 3, gen_loss = 1.025389734025185, disc_loss = 0.0006096814612157267
Trained batch 520 in epoch 3, gen_loss = 1.0255641302311946, disc_loss = 0.000609838683487742
Trained batch 521 in epoch 3, gen_loss = 1.0254740671636502, disc_loss = 0.0006100884989701065
Trained batch 522 in epoch 3, gen_loss = 1.0253999789403911, disc_loss = 0.0006105003879976728
Trained batch 523 in epoch 3, gen_loss = 1.025332502395142, disc_loss = 0.0006106847224617999
Trained batch 524 in epoch 3, gen_loss = 1.0250476313772656, disc_loss = 0.0006107355941120269
Trained batch 525 in epoch 3, gen_loss = 1.0250790136168664, disc_loss = 0.0006103279107963372
Trained batch 526 in epoch 3, gen_loss = 1.0250161883953175, disc_loss = 0.0006097859918218075
Trained batch 527 in epoch 3, gen_loss = 1.025065755753806, disc_loss = 0.0006091977462402252
Trained batch 528 in epoch 3, gen_loss = 1.0252540156611423, disc_loss = 0.0006087309820786566
Trained batch 529 in epoch 3, gen_loss = 1.0253209082585462, disc_loss = 0.0006083086463304254
Trained batch 530 in epoch 3, gen_loss = 1.025277705740345, disc_loss = 0.0006079647256569628
Trained batch 531 in epoch 3, gen_loss = 1.0254596561417544, disc_loss = 0.0006075632219634779
Trained batch 532 in epoch 3, gen_loss = 1.0255052918117444, disc_loss = 0.0006069611002222371
Trained batch 533 in epoch 3, gen_loss = 1.0256171172924256, disc_loss = 0.0006063752367031719
Trained batch 534 in epoch 3, gen_loss = 1.0255775440519102, disc_loss = 0.0006057405336509745
Trained batch 535 in epoch 3, gen_loss = 1.0254624163481727, disc_loss = 0.0006050282083188944
Trained batch 536 in epoch 3, gen_loss = 1.025426577145383, disc_loss = 0.0006042591789492373
Trained batch 537 in epoch 3, gen_loss = 1.025431717417054, disc_loss = 0.0006034840010327277
Trained batch 538 in epoch 3, gen_loss = 1.0253577108507033, disc_loss = 0.0006028100178269877
Trained batch 539 in epoch 3, gen_loss = 1.0251860486136541, disc_loss = 0.0006023568640456587
Trained batch 540 in epoch 3, gen_loss = 1.0252106656869546, disc_loss = 0.0006021462207285226
Trained batch 541 in epoch 3, gen_loss = 1.0251266110647208, disc_loss = 0.0006021700455642622
Trained batch 542 in epoch 3, gen_loss = 1.0250861235305968, disc_loss = 0.0006019585681695433
Trained batch 543 in epoch 3, gen_loss = 1.0250602100482757, disc_loss = 0.0006014413642707736
Trained batch 544 in epoch 3, gen_loss = 1.025051805404348, disc_loss = 0.0006007532524254703
Trained batch 545 in epoch 3, gen_loss = 1.024947661292422, disc_loss = 0.0006000249815949976
Trained batch 546 in epoch 3, gen_loss = 1.024843334062008, disc_loss = 0.0005995692212827984
Trained batch 547 in epoch 3, gen_loss = 1.02488128764786, disc_loss = 0.0005992127481895162
Trained batch 548 in epoch 3, gen_loss = 1.0248134743103348, disc_loss = 0.0005989479506589754
Trained batch 549 in epoch 3, gen_loss = 1.0248918939720502, disc_loss = 0.0005989011359898458
Trained batch 550 in epoch 3, gen_loss = 1.0250855583677274, disc_loss = 0.0005988583505944266
Trained batch 551 in epoch 3, gen_loss = 1.0249670086347538, disc_loss = 0.0005986734841048863
Trained batch 552 in epoch 3, gen_loss = 1.0251171613688064, disc_loss = 0.0005992564516027069
Trained batch 553 in epoch 3, gen_loss = 1.0252487645467696, disc_loss = 0.0006004194919991186
Trained batch 554 in epoch 3, gen_loss = 1.0251996904880076, disc_loss = 0.0006011167685616644
Trained batch 555 in epoch 3, gen_loss = 1.0252547372373746, disc_loss = 0.0006011184840703889
Trained batch 556 in epoch 3, gen_loss = 1.025163196682716, disc_loss = 0.0006006385718421723
Trained batch 557 in epoch 3, gen_loss = 1.0251067380110424, disc_loss = 0.0006001567824334357
Trained batch 558 in epoch 3, gen_loss = 1.025121685963837, disc_loss = 0.0005998754847475306
Trained batch 559 in epoch 3, gen_loss = 1.0251633585563729, disc_loss = 0.0005996256035359693
Trained batch 560 in epoch 3, gen_loss = 1.0253243077672527, disc_loss = 0.0005997681501103605
Trained batch 561 in epoch 3, gen_loss = 1.0253850010578318, disc_loss = 0.0006001474949921932
Trained batch 562 in epoch 3, gen_loss = 1.0253124665832858, disc_loss = 0.0006001441638747588
Trained batch 563 in epoch 3, gen_loss = 1.0251959425971864, disc_loss = 0.0006002316351041631
Trained batch 564 in epoch 3, gen_loss = 1.0251123493751593, disc_loss = 0.0006004905917185185
Trained batch 565 in epoch 3, gen_loss = 1.0252325684358712, disc_loss = 0.0006005851020565497
Trained batch 566 in epoch 3, gen_loss = 1.0253353514158325, disc_loss = 0.0006005587987139791
Trained batch 567 in epoch 3, gen_loss = 1.025394308944823, disc_loss = 0.0006003184183318295
Trained batch 568 in epoch 3, gen_loss = 1.0255248624117805, disc_loss = 0.0006001317681634622
Trained batch 569 in epoch 3, gen_loss = 1.0255837137239021, disc_loss = 0.0006001172949541605
Trained batch 570 in epoch 3, gen_loss = 1.0255542659508994, disc_loss = 0.0005999498424597734
Trained batch 571 in epoch 3, gen_loss = 1.0256037797544386, disc_loss = 0.000600081321780718
Trained batch 572 in epoch 3, gen_loss = 1.0255703849110096, disc_loss = 0.0006001358681891104
Trained batch 573 in epoch 3, gen_loss = 1.0257439987169326, disc_loss = 0.0006001981785056467
Trained batch 574 in epoch 3, gen_loss = 1.0257333541953046, disc_loss = 0.0006003556602745844
Trained batch 575 in epoch 3, gen_loss = 1.0256849281075928, disc_loss = 0.0006005874585702663
Trained batch 576 in epoch 3, gen_loss = 1.0256680239837752, disc_loss = 0.0006006998107580959
Trained batch 577 in epoch 3, gen_loss = 1.0258369998535894, disc_loss = 0.0006008368405377714
Trained batch 578 in epoch 3, gen_loss = 1.0258988837915792, disc_loss = 0.0006008820444341856
Trained batch 579 in epoch 3, gen_loss = 1.0259656834191289, disc_loss = 0.0006007448430644782
Trained batch 580 in epoch 3, gen_loss = 1.026200676128499, disc_loss = 0.0006005682301194217
Trained batch 581 in epoch 3, gen_loss = 1.0261932556162174, disc_loss = 0.0006002122046987212
Trained batch 582 in epoch 3, gen_loss = 1.0262068274908573, disc_loss = 0.0005997493430042773
Trained batch 583 in epoch 3, gen_loss = 1.02627062225995, disc_loss = 0.0005991801141658782
Trained batch 584 in epoch 3, gen_loss = 1.0264001389853974, disc_loss = 0.0005986274648646816
Trained batch 585 in epoch 3, gen_loss = 1.0263746993126723, disc_loss = 0.0005985074601827091
Trained batch 586 in epoch 3, gen_loss = 1.026244408328854, disc_loss = 0.0005985431481353872
Trained batch 587 in epoch 3, gen_loss = 1.0261420919781639, disc_loss = 0.0005986029373037986
Trained batch 588 in epoch 3, gen_loss = 1.0262672330406202, disc_loss = 0.0005986761459232828
Trained batch 589 in epoch 3, gen_loss = 1.0263838820538278, disc_loss = 0.0005988068054617635
Trained batch 590 in epoch 3, gen_loss = 1.0264897017712924, disc_loss = 0.0005988266076307583
Trained batch 591 in epoch 3, gen_loss = 1.0266156307346113, disc_loss = 0.0005987383537275664
Trained batch 592 in epoch 3, gen_loss = 1.0266132264273966, disc_loss = 0.0005987492717775433
Trained batch 593 in epoch 3, gen_loss = 1.0267500411781798, disc_loss = 0.0005993981529307483
Trained batch 594 in epoch 3, gen_loss = 1.0269114830914665, disc_loss = 0.0005998913250313759
Trained batch 595 in epoch 3, gen_loss = 1.0268627701189694, disc_loss = 0.0006000942698999811
Trained batch 596 in epoch 3, gen_loss = 1.026783373287974, disc_loss = 0.0006000408573944661
Trained batch 597 in epoch 3, gen_loss = 1.0267618087223143, disc_loss = 0.0005998739322838623
Trained batch 598 in epoch 3, gen_loss = 1.0266858746292993, disc_loss = 0.0005995879909216048
Trained batch 599 in epoch 3, gen_loss = 1.0266492159167926, disc_loss = 0.0005992156039428665
Trained batch 600 in epoch 3, gen_loss = 1.0267253432813381, disc_loss = 0.0005988073262384861
Trained batch 601 in epoch 3, gen_loss = 1.0267447533203518, disc_loss = 0.0005983157127918104
Trained batch 602 in epoch 3, gen_loss = 1.0268726954808085, disc_loss = 0.0005978105879965227
Trained batch 603 in epoch 3, gen_loss = 1.0268457408575034, disc_loss = 0.0005972722389098081
Trained batch 604 in epoch 3, gen_loss = 1.0267216377021853, disc_loss = 0.0005967393168007708
Trained batch 605 in epoch 3, gen_loss = 1.0267861469744062, disc_loss = 0.0005962125801743721
Trained batch 606 in epoch 3, gen_loss = 1.0266672913874983, disc_loss = 0.0005955546928688199
Trained batch 607 in epoch 3, gen_loss = 1.0265984735206555, disc_loss = 0.0005949301171312982
Trained batch 608 in epoch 3, gen_loss = 1.026520320640996, disc_loss = 0.0005943244739142376
Trained batch 609 in epoch 3, gen_loss = 1.0264446912241765, disc_loss = 0.0005936361871970833
Trained batch 610 in epoch 3, gen_loss = 1.0264446197867199, disc_loss = 0.0005929517323113505
Trained batch 611 in epoch 3, gen_loss = 1.0265591494203392, disc_loss = 0.0005923151687954422
Trained batch 612 in epoch 3, gen_loss = 1.0266141524906065, disc_loss = 0.0005916575124237738
Trained batch 613 in epoch 3, gen_loss = 1.0266114037471796, disc_loss = 0.000590995137619745
Trained batch 614 in epoch 3, gen_loss = 1.0266320774225686, disc_loss = 0.0005903509594793469
Trained batch 615 in epoch 3, gen_loss = 1.0266990393593713, disc_loss = 0.0005897610937207393
Trained batch 616 in epoch 3, gen_loss = 1.0267109421702219, disc_loss = 0.000589272953715927
Trained batch 617 in epoch 3, gen_loss = 1.026684276590841, disc_loss = 0.000588852544998958
Trained batch 618 in epoch 3, gen_loss = 1.0266561848088882, disc_loss = 0.0005885309062319655
Trained batch 619 in epoch 3, gen_loss = 1.0267462562168799, disc_loss = 0.0005882436455126041
Trained batch 620 in epoch 3, gen_loss = 1.0266944893700296, disc_loss = 0.0005880055528984445
Trained batch 621 in epoch 3, gen_loss = 1.0266369889786773, disc_loss = 0.000587733045687908
Trained batch 622 in epoch 3, gen_loss = 1.0265903283466689, disc_loss = 0.0005874751595575452
Trained batch 623 in epoch 3, gen_loss = 1.026556322016777, disc_loss = 0.0005872916119234362
Trained batch 624 in epoch 3, gen_loss = 1.0265165077209473, disc_loss = 0.0005871534491889179
Trained batch 625 in epoch 3, gen_loss = 1.026426150775946, disc_loss = 0.0005869707981099973
Trained batch 626 in epoch 3, gen_loss = 1.0264614772948732, disc_loss = 0.0005869194873117736
Trained batch 627 in epoch 3, gen_loss = 1.0265119573113266, disc_loss = 0.0005869881965417955
Trained batch 628 in epoch 3, gen_loss = 1.0265397123388342, disc_loss = 0.0005871266609598959
Trained batch 629 in epoch 3, gen_loss = 1.0266645683182611, disc_loss = 0.000587362168118402
Trained batch 630 in epoch 3, gen_loss = 1.0266285488609277, disc_loss = 0.0005875686669250635
Trained batch 631 in epoch 3, gen_loss = 1.0266380428890638, disc_loss = 0.0005877547388726144
Trained batch 632 in epoch 3, gen_loss = 1.0265939248869957, disc_loss = 0.0005880217031575004
Trained batch 633 in epoch 3, gen_loss = 1.026549694383934, disc_loss = 0.0005885295720740841
Trained batch 634 in epoch 3, gen_loss = 1.0264975929823448, disc_loss = 0.0005890297386740283
Trained batch 635 in epoch 3, gen_loss = 1.0266674913512837, disc_loss = 0.0005894496159883562
Trained batch 636 in epoch 3, gen_loss = 1.0266794023371566, disc_loss = 0.0005897234336621445
Trained batch 637 in epoch 3, gen_loss = 1.0265024333351458, disc_loss = 0.0005903187938940312
Trained batch 638 in epoch 3, gen_loss = 1.026421303853556, disc_loss = 0.0005908586544036451
Trained batch 639 in epoch 3, gen_loss = 1.0264976551756262, disc_loss = 0.0005913719860927813
Trained batch 640 in epoch 3, gen_loss = 1.026431856958803, disc_loss = 0.0005916325646861603
Trained batch 641 in epoch 3, gen_loss = 1.0263749603356156, disc_loss = 0.0005914284896636468
Trained batch 642 in epoch 3, gen_loss = 1.0262033860568496, disc_loss = 0.0005913555901280342
Trained batch 643 in epoch 3, gen_loss = 1.0261715098012307, disc_loss = 0.00059187247472821
Trained batch 644 in epoch 3, gen_loss = 1.026174762544706, disc_loss = 0.0005929032160156919
Trained batch 645 in epoch 3, gen_loss = 1.0260308454095763, disc_loss = 0.0005940581537096909
Trained batch 646 in epoch 3, gen_loss = 1.0259533708762534, disc_loss = 0.0005946401467077561
Trained batch 647 in epoch 3, gen_loss = 1.0260269339253874, disc_loss = 0.0005950982068711317
Trained batch 648 in epoch 3, gen_loss = 1.0259484330935544, disc_loss = 0.0005958895851931146
Trained batch 649 in epoch 3, gen_loss = 1.025977961558562, disc_loss = 0.0005979139536905747
Trained batch 650 in epoch 3, gen_loss = 1.026013873597627, disc_loss = 0.0006003737347357879
Trained batch 651 in epoch 3, gen_loss = 1.025946081324589, disc_loss = 0.0006024774568915321
Trained batch 652 in epoch 3, gen_loss = 1.0260301960737745, disc_loss = 0.0006042168462138401
Trained batch 653 in epoch 3, gen_loss = 1.0260110720764242, disc_loss = 0.0006055431641618342
Trained batch 654 in epoch 3, gen_loss = 1.026017454289298, disc_loss = 0.0006062589203654469
Trained batch 655 in epoch 3, gen_loss = 1.0261328015930768, disc_loss = 0.0006067076686942927
Trained batch 656 in epoch 3, gen_loss = 1.0261408331005903, disc_loss = 0.0006071927317041093
Trained batch 657 in epoch 3, gen_loss = 1.0261964418424299, disc_loss = 0.0006077107357704803
Trained batch 658 in epoch 3, gen_loss = 1.026172831224925, disc_loss = 0.0006084376167045265
Trained batch 659 in epoch 3, gen_loss = 1.02627560144121, disc_loss = 0.0006091915062191247
Trained batch 660 in epoch 3, gen_loss = 1.0263465611368372, disc_loss = 0.0006097794255754613
Trained batch 661 in epoch 3, gen_loss = 1.0262963173072503, disc_loss = 0.0006100622948689606
Trained batch 662 in epoch 3, gen_loss = 1.0264699048226416, disc_loss = 0.0006099174113987719
Trained batch 663 in epoch 3, gen_loss = 1.026420674051147, disc_loss = 0.0006097898049229554
Trained batch 664 in epoch 3, gen_loss = 1.026398315286278, disc_loss = 0.0006102268192812072
Trained batch 665 in epoch 3, gen_loss = 1.0264385319328881, disc_loss = 0.0006107040645111374
Trained batch 666 in epoch 3, gen_loss = 1.026647579544845, disc_loss = 0.0006110059699382928
Trained batch 667 in epoch 3, gen_loss = 1.0265938093562326, disc_loss = 0.0006113027289201656
Trained batch 668 in epoch 3, gen_loss = 1.0264979390641855, disc_loss = 0.0006115143444884696
Trained batch 669 in epoch 3, gen_loss = 1.0265107161963163, disc_loss = 0.0006115355224821217
Trained batch 670 in epoch 3, gen_loss = 1.0266046445877826, disc_loss = 0.0006113459375040153
Trained batch 671 in epoch 3, gen_loss = 1.0265367936697745, disc_loss = 0.0006109166764266168
Trained batch 672 in epoch 3, gen_loss = 1.026496428702951, disc_loss = 0.0006104116776077987
Trained batch 673 in epoch 3, gen_loss = 1.026388615458231, disc_loss = 0.0006101935455411153
Trained batch 674 in epoch 3, gen_loss = 1.0263695209997672, disc_loss = 0.000610376598606645
Trained batch 675 in epoch 3, gen_loss = 1.0263754663735452, disc_loss = 0.0006108346322693273
Trained batch 676 in epoch 3, gen_loss = 1.0263277833711801, disc_loss = 0.0006111942287885269
Trained batch 677 in epoch 3, gen_loss = 1.026427405158327, disc_loss = 0.0006117464669404557
Trained batch 678 in epoch 3, gen_loss = 1.0265120047532756, disc_loss = 0.0006130599345297268
Trained batch 679 in epoch 3, gen_loss = 1.02647876064567, disc_loss = 0.0006148136985275949
Trained batch 680 in epoch 3, gen_loss = 1.0265130197599246, disc_loss = 0.0006164274457602785
Trained batch 681 in epoch 3, gen_loss = 1.0264884662593214, disc_loss = 0.0006172824298513676
Trained batch 682 in epoch 3, gen_loss = 1.026574116063851, disc_loss = 0.0006173794919871732
Trained batch 683 in epoch 3, gen_loss = 1.0267129677255251, disc_loss = 0.0006171319346428353
Trained batch 684 in epoch 3, gen_loss = 1.0266654277369924, disc_loss = 0.0006168156455230158
Trained batch 685 in epoch 3, gen_loss = 1.0267023819528585, disc_loss = 0.0006163383691260081
Trained batch 686 in epoch 3, gen_loss = 1.0267133933140895, disc_loss = 0.0006160885775109327
Trained batch 687 in epoch 3, gen_loss = 1.0266453892339107, disc_loss = 0.0006160013077152503
Trained batch 688 in epoch 3, gen_loss = 1.0267009743758313, disc_loss = 0.0006159400857690348
Trained batch 689 in epoch 3, gen_loss = 1.0266990568326868, disc_loss = 0.0006157701138231526
Trained batch 690 in epoch 3, gen_loss = 1.026812425570619, disc_loss = 0.0006153041436390846
Trained batch 691 in epoch 3, gen_loss = 1.0268122312650516, disc_loss = 0.0006147845915462849
Trained batch 692 in epoch 3, gen_loss = 1.0268719165356128, disc_loss = 0.000614212325816634
Trained batch 693 in epoch 3, gen_loss = 1.0268396951623198, disc_loss = 0.0006135994349265812
Trained batch 694 in epoch 3, gen_loss = 1.026845858079924, disc_loss = 0.0006129919282468907
Trained batch 695 in epoch 3, gen_loss = 1.027070968315519, disc_loss = 0.0006123791692056559
Trained batch 696 in epoch 3, gen_loss = 1.0270437824845826, disc_loss = 0.0006118470363965635
Trained batch 697 in epoch 3, gen_loss = 1.027018712038297, disc_loss = 0.0006114732955928016
Trained batch 698 in epoch 3, gen_loss = 1.0271477699279785, disc_loss = 0.0006112373834216064
Trained batch 699 in epoch 3, gen_loss = 1.0271534953798567, disc_loss = 0.0006111056393378281
Trained batch 700 in epoch 3, gen_loss = 1.02718683792419, disc_loss = 0.0006108196196843805
Trained batch 701 in epoch 3, gen_loss = 1.0272047706479022, disc_loss = 0.0006105962315205475
Trained batch 702 in epoch 3, gen_loss = 1.0272606356893461, disc_loss = 0.0006105515663412692
Trained batch 703 in epoch 3, gen_loss = 1.0272343946112827, disc_loss = 0.0006105217997339258
Trained batch 704 in epoch 3, gen_loss = 1.0273083260718812, disc_loss = 0.0006102943689734113
Trained batch 705 in epoch 3, gen_loss = 1.0272211251785668, disc_loss = 0.0006100629887044978
Trained batch 706 in epoch 3, gen_loss = 1.027188444070128, disc_loss = 0.0006098602825968067
Trained batch 707 in epoch 3, gen_loss = 1.027097360815032, disc_loss = 0.0006095425064325606
Trained batch 708 in epoch 3, gen_loss = 1.0270582368578998, disc_loss = 0.0006091213464600327
Trained batch 709 in epoch 3, gen_loss = 1.0270968618527265, disc_loss = 0.0006085666123831736
Trained batch 710 in epoch 3, gen_loss = 1.027049751808204, disc_loss = 0.0006079499102968778
Trained batch 711 in epoch 3, gen_loss = 1.0269555130533958, disc_loss = 0.0006073424336729373
Trained batch 712 in epoch 3, gen_loss = 1.0269589386514661, disc_loss = 0.0006066992702005042
Trained batch 713 in epoch 3, gen_loss = 1.026930356810407, disc_loss = 0.0006060475928735651
Trained batch 714 in epoch 3, gen_loss = 1.0269789069682569, disc_loss = 0.000605426597493616
Trained batch 715 in epoch 3, gen_loss = 1.0270115038036634, disc_loss = 0.0006048575390363438
Trained batch 716 in epoch 3, gen_loss = 1.0269558517005155, disc_loss = 0.0006044490306582653
Trained batch 717 in epoch 3, gen_loss = 1.0269009685117887, disc_loss = 0.0006043764109852007
Trained batch 718 in epoch 3, gen_loss = 1.0269233112706595, disc_loss = 0.0006043195419645932
Trained batch 719 in epoch 3, gen_loss = 1.0269773602485657, disc_loss = 0.0006043385313508528
Trained batch 720 in epoch 3, gen_loss = 1.0269843263864187, disc_loss = 0.0006043061193786937
Trained batch 721 in epoch 3, gen_loss = 1.0269676471681146, disc_loss = 0.0006043801511326028
Trained batch 722 in epoch 3, gen_loss = 1.0269632171298457, disc_loss = 0.0006046104390809524
Trained batch 723 in epoch 3, gen_loss = 1.0270067565348926, disc_loss = 0.0006046915501499232
Trained batch 724 in epoch 3, gen_loss = 1.0269693354080462, disc_loss = 0.0006046966520531488
Trained batch 725 in epoch 3, gen_loss = 1.0270160337289174, disc_loss = 0.0006045824571709231
Trained batch 726 in epoch 3, gen_loss = 1.0269346156015358, disc_loss = 0.0006044492478159921
Trained batch 727 in epoch 3, gen_loss = 1.0268416109157132, disc_loss = 0.0006044209333864913
Trained batch 728 in epoch 3, gen_loss = 1.0268679998702637, disc_loss = 0.0006042056736660564
Trained batch 729 in epoch 3, gen_loss = 1.0268617606326325, disc_loss = 0.0006037757859751901
Trained batch 730 in epoch 3, gen_loss = 1.026836703071516, disc_loss = 0.0006032770699013991
Trained batch 731 in epoch 3, gen_loss = 1.0268756235069265, disc_loss = 0.0006027581678166517
Trained batch 732 in epoch 3, gen_loss = 1.0268197518253717, disc_loss = 0.0006023470443304334
Trained batch 733 in epoch 3, gen_loss = 1.0267527721395935, disc_loss = 0.0006020807466271133
Trained batch 734 in epoch 3, gen_loss = 1.0267296714036642, disc_loss = 0.0006016545913571834
Trained batch 735 in epoch 3, gen_loss = 1.026721024237897, disc_loss = 0.0006010552822811841
Trained batch 736 in epoch 3, gen_loss = 1.0267880689984585, disc_loss = 0.0006004727533091242
Trained batch 737 in epoch 3, gen_loss = 1.026852478745184, disc_loss = 0.0005999308996251784
Trained batch 738 in epoch 3, gen_loss = 1.0268413103481753, disc_loss = 0.0005995286943468786
Trained batch 739 in epoch 3, gen_loss = 1.0268487523536425, disc_loss = 0.0005994954071522099
Trained batch 740 in epoch 3, gen_loss = 1.0267849053770264, disc_loss = 0.0005996109432578225
Trained batch 741 in epoch 3, gen_loss = 1.0267885346618302, disc_loss = 0.0005998214947571538
Trained batch 742 in epoch 3, gen_loss = 1.0267715593687137, disc_loss = 0.0005998743120742295
Trained batch 743 in epoch 3, gen_loss = 1.0267438072991628, disc_loss = 0.0005997324404292627
Trained batch 744 in epoch 3, gen_loss = 1.0267439014959656, disc_loss = 0.0005993155227941242
Trained batch 745 in epoch 3, gen_loss = 1.0268364433628625, disc_loss = 0.0005989459549985394
Trained batch 746 in epoch 3, gen_loss = 1.0268152933044128, disc_loss = 0.0005986949487084678
Trained batch 747 in epoch 3, gen_loss = 1.026845851205887, disc_loss = 0.0005986432828805049
Trained batch 748 in epoch 3, gen_loss = 1.026785503401457, disc_loss = 0.000598647702832393
Trained batch 749 in epoch 3, gen_loss = 1.0266866346995036, disc_loss = 0.0005986583507813824
Trained batch 750 in epoch 3, gen_loss = 1.0266145394740505, disc_loss = 0.0005986901834619836
Trained batch 751 in epoch 3, gen_loss = 1.0265884361368545, disc_loss = 0.0005986556721991486
Trained batch 752 in epoch 3, gen_loss = 1.0265512305743507, disc_loss = 0.0005985367933610098
Trained batch 753 in epoch 3, gen_loss = 1.0265376495903935, disc_loss = 0.0005982870277764945
Trained batch 754 in epoch 3, gen_loss = 1.0265899602151074, disc_loss = 0.0005979626253902579
Trained batch 755 in epoch 3, gen_loss = 1.026709529694426, disc_loss = 0.0005977568494763642
Trained batch 756 in epoch 3, gen_loss = 1.0265702155653678, disc_loss = 0.0005977628713566256
Trained batch 757 in epoch 3, gen_loss = 1.0265346207216106, disc_loss = 0.0005981510378259705
Trained batch 758 in epoch 3, gen_loss = 1.026681559987376, disc_loss = 0.0005986654303076202
Trained batch 759 in epoch 3, gen_loss = 1.0266831440360922, disc_loss = 0.0005989493112314162
Trained batch 760 in epoch 3, gen_loss = 1.026721486437493, disc_loss = 0.0005988635665422878
Trained batch 761 in epoch 3, gen_loss = 1.0267480929379702, disc_loss = 0.0005985243789880082
Trained batch 762 in epoch 3, gen_loss = 1.026794090652216, disc_loss = 0.0005981469237793976
Trained batch 763 in epoch 3, gen_loss = 1.0267732800301457, disc_loss = 0.0005977343931419017
Trained batch 764 in epoch 3, gen_loss = 1.0268306732177734, disc_loss = 0.0005973404729350781
Trained batch 765 in epoch 3, gen_loss = 1.0267839707220192, disc_loss = 0.0005969895969511875
Trained batch 766 in epoch 3, gen_loss = 1.026728672651766, disc_loss = 0.0005966267406625061
Trained batch 767 in epoch 3, gen_loss = 1.0267566967134674, disc_loss = 0.0005962113574279707
Trained batch 768 in epoch 3, gen_loss = 1.0267458141857688, disc_loss = 0.0005957105861631887
Trained batch 769 in epoch 3, gen_loss = 1.0267990486962455, disc_loss = 0.0005951666515645595
Trained batch 770 in epoch 3, gen_loss = 1.0267402605478557, disc_loss = 0.0005945643148038913
Trained batch 771 in epoch 3, gen_loss = 1.0266964954415752, disc_loss = 0.0005940876549717227
Trained batch 772 in epoch 3, gen_loss = 1.0265689418201767, disc_loss = 0.0005938970403041555
Trained batch 773 in epoch 3, gen_loss = 1.0266458399074023, disc_loss = 0.0005940128579475251
Trained batch 774 in epoch 3, gen_loss = 1.0266806254079266, disc_loss = 0.0005941824563553617
Trained batch 775 in epoch 3, gen_loss = 1.0266168569166636, disc_loss = 0.0005943649368568866
Trained batch 776 in epoch 3, gen_loss = 1.0265694259063003, disc_loss = 0.0005946053773571679
Trained batch 777 in epoch 3, gen_loss = 1.0266002100200458, disc_loss = 0.0005948489967235041
Trained batch 778 in epoch 3, gen_loss = 1.0266168898734263, disc_loss = 0.000595097199274557
Trained batch 779 in epoch 3, gen_loss = 1.026518392104369, disc_loss = 0.0005955644996272615
Trained batch 780 in epoch 3, gen_loss = 1.026562912210765, disc_loss = 0.0005960985952222103
Trained batch 781 in epoch 3, gen_loss = 1.0265292619805202, disc_loss = 0.0005967048978384779
Trained batch 782 in epoch 3, gen_loss = 1.0264422646884261, disc_loss = 0.0005973221538728162
Trained batch 783 in epoch 3, gen_loss = 1.0265361751828874, disc_loss = 0.0005980957787925239
Trained batch 784 in epoch 3, gen_loss = 1.0264312592281657, disc_loss = 0.0005990422546943637
Trained batch 785 in epoch 3, gen_loss = 1.0264924288402684, disc_loss = 0.0006001803238029561
Trained batch 786 in epoch 3, gen_loss = 1.0264905626013439, disc_loss = 0.0006013157283943478
Trained batch 787 in epoch 3, gen_loss = 1.026502955080894, disc_loss = 0.000602201022481638
Trained batch 788 in epoch 3, gen_loss = 1.0265962125683918, disc_loss = 0.0006025444809686751
Trained batch 789 in epoch 3, gen_loss = 1.0265938882586323, disc_loss = 0.0006025701432261923
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.07850980758667, disc_loss = 0.0005849144654348493
Trained batch 1 in epoch 4, gen_loss = 1.05178564786911, disc_loss = 0.0005440647073555738
Trained batch 2 in epoch 4, gen_loss = 1.0324862202008565, disc_loss = 0.0005466417060233653
Trained batch 3 in epoch 4, gen_loss = 1.034738227725029, disc_loss = 0.0005594790854956955
Trained batch 4 in epoch 4, gen_loss = 1.0254687190055847, disc_loss = 0.0005881295772269368
Trained batch 5 in epoch 4, gen_loss = 1.0350409249464672, disc_loss = 0.0006031510226118068
Trained batch 6 in epoch 4, gen_loss = 1.029312593596322, disc_loss = 0.0006633611462478127
Trained batch 7 in epoch 4, gen_loss = 1.040135070681572, disc_loss = 0.000788067583926022
Trained batch 8 in epoch 4, gen_loss = 1.0358999305301242, disc_loss = 0.0009637698013749388
Trained batch 9 in epoch 4, gen_loss = 1.0420802354812622, disc_loss = 0.0011029139859601855
Trained batch 10 in epoch 4, gen_loss = 1.0422641255638816, disc_loss = 0.0011938145087862556
Trained batch 11 in epoch 4, gen_loss = 1.0369553069273632, disc_loss = 0.001246638586356615
Trained batch 12 in epoch 4, gen_loss = 1.037156994526203, disc_loss = 0.001262957830196963
Trained batch 13 in epoch 4, gen_loss = 1.0376565711838859, disc_loss = 0.001251449783532215
Trained batch 14 in epoch 4, gen_loss = 1.0381562153498332, disc_loss = 0.001226497336756438
Trained batch 15 in epoch 4, gen_loss = 1.038095884025097, disc_loss = 0.0011903820995939896
Trained batch 16 in epoch 4, gen_loss = 1.0357637580703287, disc_loss = 0.0011509150602197385
Trained batch 17 in epoch 4, gen_loss = 1.0295368764135573, disc_loss = 0.0011077287619830007
Trained batch 18 in epoch 4, gen_loss = 1.0273981847261127, disc_loss = 0.0010692356767034845
Trained batch 19 in epoch 4, gen_loss = 1.0291221022605896, disc_loss = 0.001032953307731077
Trained batch 20 in epoch 4, gen_loss = 1.0314298186983382, disc_loss = 0.0010059983081494768
Trained batch 21 in epoch 4, gen_loss = 1.031866723840887, disc_loss = 0.0009847106888297606
Trained batch 22 in epoch 4, gen_loss = 1.0282158618387969, disc_loss = 0.0009622165146182575
Trained batch 23 in epoch 4, gen_loss = 1.0268157199025154, disc_loss = 0.0009364467853932487
Trained batch 24 in epoch 4, gen_loss = 1.026155536174774, disc_loss = 0.0009088830708060413
Trained batch 25 in epoch 4, gen_loss = 1.0261407700868754, disc_loss = 0.000883664340318109
Trained batch 26 in epoch 4, gen_loss = 1.0282738893120378, disc_loss = 0.0008611743903235981
Trained batch 27 in epoch 4, gen_loss = 1.0296510181256704, disc_loss = 0.0008442356899779822
Trained batch 28 in epoch 4, gen_loss = 1.0265869950426036, disc_loss = 0.0008347525325571669
Trained batch 29 in epoch 4, gen_loss = 1.0278773883978525, disc_loss = 0.0008294933009892702
Trained batch 30 in epoch 4, gen_loss = 1.031613867129049, disc_loss = 0.000824229855601105
Trained batch 31 in epoch 4, gen_loss = 1.0348891895264387, disc_loss = 0.0008231436604546616
Trained batch 32 in epoch 4, gen_loss = 1.0372762445247534, disc_loss = 0.0008257343716016321
Trained batch 33 in epoch 4, gen_loss = 1.0346286209190594, disc_loss = 0.000827512818539296
Trained batch 34 in epoch 4, gen_loss = 1.0388948559761046, disc_loss = 0.0008278788549692503
Trained batch 35 in epoch 4, gen_loss = 1.037847908006774, disc_loss = 0.0008214555515830094
Trained batch 36 in epoch 4, gen_loss = 1.0361581960239925, disc_loss = 0.00081739917152083
Trained batch 37 in epoch 4, gen_loss = 1.0378209901483435, disc_loss = 0.0008195159806698365
Trained batch 38 in epoch 4, gen_loss = 1.0395835164265754, disc_loss = 0.0008212310688880583
Trained batch 39 in epoch 4, gen_loss = 1.0389711663126946, disc_loss = 0.000823907220910769
Trained batch 40 in epoch 4, gen_loss = 1.0397464167780992, disc_loss = 0.0008276005136416998
Trained batch 41 in epoch 4, gen_loss = 1.0399790761016665, disc_loss = 0.0008302193974876511
Trained batch 42 in epoch 4, gen_loss = 1.0381861938986667, disc_loss = 0.0008289371793115035
Trained batch 43 in epoch 4, gen_loss = 1.037063786929304, disc_loss = 0.0008238453089936891
Trained batch 44 in epoch 4, gen_loss = 1.0366634514596726, disc_loss = 0.0008179750384038521
Trained batch 45 in epoch 4, gen_loss = 1.0359651925771132, disc_loss = 0.00080952221469488
Trained batch 46 in epoch 4, gen_loss = 1.0375044079537088, disc_loss = 0.000799002977301109
Trained batch 47 in epoch 4, gen_loss = 1.0371368763347466, disc_loss = 0.000787855705008648
Trained batch 48 in epoch 4, gen_loss = 1.035852081921636, disc_loss = 0.0007768675099288551
Trained batch 49 in epoch 4, gen_loss = 1.03507319688797, disc_loss = 0.0007670285616768524
Trained batch 50 in epoch 4, gen_loss = 1.0342672969780715, disc_loss = 0.0007579363648569686
Trained batch 51 in epoch 4, gen_loss = 1.0357717413168688, disc_loss = 0.0007496710095438175
Trained batch 52 in epoch 4, gen_loss = 1.03568656264611, disc_loss = 0.0007422702087150921
Trained batch 53 in epoch 4, gen_loss = 1.0350541869799297, disc_loss = 0.0007350971707772394
Trained batch 54 in epoch 4, gen_loss = 1.035483880476518, disc_loss = 0.000726843835383823
Trained batch 55 in epoch 4, gen_loss = 1.0358430232320512, disc_loss = 0.0007182287242488071
Trained batch 56 in epoch 4, gen_loss = 1.0354210368373937, disc_loss = 0.0007119181661931961
Trained batch 57 in epoch 4, gen_loss = 1.0355577263338813, disc_loss = 0.0007063237516659087
Trained batch 58 in epoch 4, gen_loss = 1.0364453469292592, disc_loss = 0.0007005396162917427
Trained batch 59 in epoch 4, gen_loss = 1.036288889249166, disc_loss = 0.0006940264468236516
Trained batch 60 in epoch 4, gen_loss = 1.0358463623484626, disc_loss = 0.0006868052992923949
Trained batch 61 in epoch 4, gen_loss = 1.0357961846936135, disc_loss = 0.0006803171333646582
Trained batch 62 in epoch 4, gen_loss = 1.0356540093346247, disc_loss = 0.000674383945777894
Trained batch 63 in epoch 4, gen_loss = 1.0348499044775963, disc_loss = 0.0006688299386041763
Trained batch 64 in epoch 4, gen_loss = 1.035816084421598, disc_loss = 0.0006634823557061071
Trained batch 65 in epoch 4, gen_loss = 1.0365475361997432, disc_loss = 0.0006590030790186685
Trained batch 66 in epoch 4, gen_loss = 1.0349113674306158, disc_loss = 0.0006541855378708899
Trained batch 67 in epoch 4, gen_loss = 1.0346893107189852, disc_loss = 0.0006490108443198123
Trained batch 68 in epoch 4, gen_loss = 1.0341894350190093, disc_loss = 0.0006433564965424223
Trained batch 69 in epoch 4, gen_loss = 1.0341667209352765, disc_loss = 0.0006376500711277394
Trained batch 70 in epoch 4, gen_loss = 1.0339814709945463, disc_loss = 0.0006313809426501393
Trained batch 71 in epoch 4, gen_loss = 1.0343675116697948, disc_loss = 0.0006251771925841846
Trained batch 72 in epoch 4, gen_loss = 1.0344074637922522, disc_loss = 0.0006197067693255408
Trained batch 73 in epoch 4, gen_loss = 1.0348702765799858, disc_loss = 0.0006154960863421218
Trained batch 74 in epoch 4, gen_loss = 1.0349174420038858, disc_loss = 0.0006124016660032794
Trained batch 75 in epoch 4, gen_loss = 1.035067020278228, disc_loss = 0.0006101135860310597
Trained batch 76 in epoch 4, gen_loss = 1.0340138193848845, disc_loss = 0.0006071391465163535
Trained batch 77 in epoch 4, gen_loss = 1.0342760269458477, disc_loss = 0.0006030276953168093
Trained batch 78 in epoch 4, gen_loss = 1.034600438950937, disc_loss = 0.0005988486888862651
Trained batch 79 in epoch 4, gen_loss = 1.0342046082019807, disc_loss = 0.0005941672667177045
Trained batch 80 in epoch 4, gen_loss = 1.0341531038284302, disc_loss = 0.0005892454605207514
Trained batch 81 in epoch 4, gen_loss = 1.0339165315395449, disc_loss = 0.0005849017823759535
Trained batch 82 in epoch 4, gen_loss = 1.0325853896428303, disc_loss = 0.0005824102854274819
Trained batch 83 in epoch 4, gen_loss = 1.032776260659808, disc_loss = 0.000582985191743189
Trained batch 84 in epoch 4, gen_loss = 1.0328374371809117, disc_loss = 0.0005830353521399529
Trained batch 85 in epoch 4, gen_loss = 1.0334203853163608, disc_loss = 0.0005827437763760234
Trained batch 86 in epoch 4, gen_loss = 1.0331177053780392, disc_loss = 0.0005815768610731559
Trained batch 87 in epoch 4, gen_loss = 1.0323648141189055, disc_loss = 0.0005797725327945293
Trained batch 88 in epoch 4, gen_loss = 1.0331192003207261, disc_loss = 0.0005791790087202438
Trained batch 89 in epoch 4, gen_loss = 1.0340039412180582, disc_loss = 0.000581790336582344
Trained batch 90 in epoch 4, gen_loss = 1.0340889129009876, disc_loss = 0.0005859322773975801
Trained batch 91 in epoch 4, gen_loss = 1.0357614677885305, disc_loss = 0.0005891373874202027
Trained batch 92 in epoch 4, gen_loss = 1.0358615613752795, disc_loss = 0.0005900139170285735
Trained batch 93 in epoch 4, gen_loss = 1.0345869254558644, disc_loss = 0.0005910014614470283
Trained batch 94 in epoch 4, gen_loss = 1.0343016913062648, disc_loss = 0.0005941015133621955
Trained batch 95 in epoch 4, gen_loss = 1.0336115062236786, disc_loss = 0.0006007196272245589
Trained batch 96 in epoch 4, gen_loss = 1.0331864141926324, disc_loss = 0.0006103415212284332
Trained batch 97 in epoch 4, gen_loss = 1.0326994651434374, disc_loss = 0.0006207576351494491
Trained batch 98 in epoch 4, gen_loss = 1.03297297099624, disc_loss = 0.0006300424138316885
Trained batch 99 in epoch 4, gen_loss = 1.033543319106102, disc_loss = 0.0006348332743800711
Trained batch 100 in epoch 4, gen_loss = 1.0334657719819853, disc_loss = 0.0006346378933884996
Trained batch 101 in epoch 4, gen_loss = 1.032267732363121, disc_loss = 0.0006316935290598456
Trained batch 102 in epoch 4, gen_loss = 1.031614615500552, disc_loss = 0.0006285120247924266
Trained batch 103 in epoch 4, gen_loss = 1.0316479911024754, disc_loss = 0.0006252299237810523
Trained batch 104 in epoch 4, gen_loss = 1.031304671083178, disc_loss = 0.000622112371465413
Trained batch 105 in epoch 4, gen_loss = 1.0307491950269014, disc_loss = 0.0006197472963699596
Trained batch 106 in epoch 4, gen_loss = 1.031000640904792, disc_loss = 0.0006182494693790415
Trained batch 107 in epoch 4, gen_loss = 1.0321803048804954, disc_loss = 0.0006165377173467143
Trained batch 108 in epoch 4, gen_loss = 1.0319480130431848, disc_loss = 0.0006146537808331857
Trained batch 109 in epoch 4, gen_loss = 1.032748124816201, disc_loss = 0.000616017198163635
Trained batch 110 in epoch 4, gen_loss = 1.0330615269171226, disc_loss = 0.0006204420622796877
Trained batch 111 in epoch 4, gen_loss = 1.032581171819142, disc_loss = 0.000627621226028298
Trained batch 112 in epoch 4, gen_loss = 1.0327214635578932, disc_loss = 0.0006321971864899027
Trained batch 113 in epoch 4, gen_loss = 1.033029884622808, disc_loss = 0.0006327564824778962
Trained batch 114 in epoch 4, gen_loss = 1.0328226980955704, disc_loss = 0.0006314686412224546
Trained batch 115 in epoch 4, gen_loss = 1.0319980439440957, disc_loss = 0.0006315869148489457
Trained batch 116 in epoch 4, gen_loss = 1.0320894529676845, disc_loss = 0.0006329350666745972
Trained batch 117 in epoch 4, gen_loss = 1.0326438965433735, disc_loss = 0.0006340168488273097
Trained batch 118 in epoch 4, gen_loss = 1.0326478987180887, disc_loss = 0.0006332480745583757
Trained batch 119 in epoch 4, gen_loss = 1.0331510916352271, disc_loss = 0.0006298754771705717
Trained batch 120 in epoch 4, gen_loss = 1.0330551246966213, disc_loss = 0.0006264701276615432
Trained batch 121 in epoch 4, gen_loss = 1.0329421783079866, disc_loss = 0.000623933935025516
Trained batch 122 in epoch 4, gen_loss = 1.0324042100247328, disc_loss = 0.0006219551796084118
Trained batch 123 in epoch 4, gen_loss = 1.0323255499524455, disc_loss = 0.0006205430727277417
Trained batch 124 in epoch 4, gen_loss = 1.0326352667808534, disc_loss = 0.0006187638546107337
Trained batch 125 in epoch 4, gen_loss = 1.0318610715487646, disc_loss = 0.0006165803891249992
Trained batch 126 in epoch 4, gen_loss = 1.0323569971745408, disc_loss = 0.0006147574762379252
Trained batch 127 in epoch 4, gen_loss = 1.032430462539196, disc_loss = 0.0006141320035339959
Trained batch 128 in epoch 4, gen_loss = 1.031683394613192, disc_loss = 0.0006140601398674193
Trained batch 129 in epoch 4, gen_loss = 1.0312912583351135, disc_loss = 0.0006146648767753505
Trained batch 130 in epoch 4, gen_loss = 1.0312359533237136, disc_loss = 0.0006162829190369994
Trained batch 131 in epoch 4, gen_loss = 1.0308032789916703, disc_loss = 0.0006179847801060091
Trained batch 132 in epoch 4, gen_loss = 1.0312793573042505, disc_loss = 0.0006201243800718576
Trained batch 133 in epoch 4, gen_loss = 1.0317282031721144, disc_loss = 0.000621366183296951
Trained batch 134 in epoch 4, gen_loss = 1.0316044953134325, disc_loss = 0.0006207653320247859
Trained batch 135 in epoch 4, gen_loss = 1.0316624926293598, disc_loss = 0.0006189564368576291
Trained batch 136 in epoch 4, gen_loss = 1.031747529541489, disc_loss = 0.000616470265884571
Trained batch 137 in epoch 4, gen_loss = 1.031726575847985, disc_loss = 0.0006132726858081498
Trained batch 138 in epoch 4, gen_loss = 1.031912434444153, disc_loss = 0.0006098789683243313
Trained batch 139 in epoch 4, gen_loss = 1.0317034921475818, disc_loss = 0.0006073154258566709
Trained batch 140 in epoch 4, gen_loss = 1.0317819249545428, disc_loss = 0.0006061121473602409
Trained batch 141 in epoch 4, gen_loss = 1.031948124438944, disc_loss = 0.0006057123741107127
Trained batch 142 in epoch 4, gen_loss = 1.0319487677587496, disc_loss = 0.0006054435270289741
Trained batch 143 in epoch 4, gen_loss = 1.0322808453606234, disc_loss = 0.0006046414094574478
Trained batch 144 in epoch 4, gen_loss = 1.0320958051188238, disc_loss = 0.0006032260103705178
Trained batch 145 in epoch 4, gen_loss = 1.0318031494748103, disc_loss = 0.0006012878994089041
Trained batch 146 in epoch 4, gen_loss = 1.03176472097838, disc_loss = 0.0005986453019134814
Trained batch 147 in epoch 4, gen_loss = 1.031874040896828, disc_loss = 0.0005958518812730216
Trained batch 148 in epoch 4, gen_loss = 1.0315240305542146, disc_loss = 0.0005940594266039076
Trained batch 149 in epoch 4, gen_loss = 1.0317497233549753, disc_loss = 0.0005929906894258844
Trained batch 150 in epoch 4, gen_loss = 1.0317131119058622, disc_loss = 0.0005919649968246023
Trained batch 151 in epoch 4, gen_loss = 1.031982339134342, disc_loss = 0.0005913011169277046
Trained batch 152 in epoch 4, gen_loss = 1.031646573465634, disc_loss = 0.0005911450009995438
Trained batch 153 in epoch 4, gen_loss = 1.0317104141433517, disc_loss = 0.0005918800413749157
Trained batch 154 in epoch 4, gen_loss = 1.0315176902278778, disc_loss = 0.0005935327402473758
Trained batch 155 in epoch 4, gen_loss = 1.031100605542843, disc_loss = 0.0005952531397409844
Trained batch 156 in epoch 4, gen_loss = 1.0308827799596605, disc_loss = 0.0005964677282023262
Trained batch 157 in epoch 4, gen_loss = 1.0306312920926493, disc_loss = 0.000597296571569028
Trained batch 158 in epoch 4, gen_loss = 1.0308654237093415, disc_loss = 0.0005983332276919786
Trained batch 159 in epoch 4, gen_loss = 1.0310939226299525, disc_loss = 0.0005992718929519469
Trained batch 160 in epoch 4, gen_loss = 1.0313576530225528, disc_loss = 0.0005991428018358149
Trained batch 161 in epoch 4, gen_loss = 1.0310173284860304, disc_loss = 0.0005976502476569069
Trained batch 162 in epoch 4, gen_loss = 1.0308236626028284, disc_loss = 0.0005959031398678084
Trained batch 163 in epoch 4, gen_loss = 1.030216304630768, disc_loss = 0.0005949987809311473
Trained batch 164 in epoch 4, gen_loss = 1.0296755610090313, disc_loss = 0.0005945439437213777
Trained batch 165 in epoch 4, gen_loss = 1.0297652246004128, disc_loss = 0.0005939306575750248
Trained batch 166 in epoch 4, gen_loss = 1.0295970425634327, disc_loss = 0.0005923823606324645
Trained batch 167 in epoch 4, gen_loss = 1.0294520244711922, disc_loss = 0.0005899249099456938
Trained batch 168 in epoch 4, gen_loss = 1.0298042473708384, disc_loss = 0.0005878596565756429
Trained batch 169 in epoch 4, gen_loss = 1.0299304856973537, disc_loss = 0.0005855901658993817
Trained batch 170 in epoch 4, gen_loss = 1.031282224850348, disc_loss = 0.0005850674541447889
Trained batch 171 in epoch 4, gen_loss = 1.0308090593925743, disc_loss = 0.0005859626777068073
Trained batch 172 in epoch 4, gen_loss = 1.0311668318820137, disc_loss = 0.0005868854184703622
Trained batch 173 in epoch 4, gen_loss = 1.0304483497279815, disc_loss = 0.0005874329020942283
Trained batch 174 in epoch 4, gen_loss = 1.0308060979843139, disc_loss = 0.0005888104936873008
Trained batch 175 in epoch 4, gen_loss = 1.0313271954655647, disc_loss = 0.000590071400190275
Trained batch 176 in epoch 4, gen_loss = 1.031622797082373, disc_loss = 0.0005903977223791677
Trained batch 177 in epoch 4, gen_loss = 1.0323149153355802, disc_loss = 0.0005900259501676159
Trained batch 178 in epoch 4, gen_loss = 1.0322250107813147, disc_loss = 0.0005891623440316966
Trained batch 179 in epoch 4, gen_loss = 1.031987832321061, disc_loss = 0.0005881032878177293
Trained batch 180 in epoch 4, gen_loss = 1.0320778429837516, disc_loss = 0.0005862777600050724
Trained batch 181 in epoch 4, gen_loss = 1.0323383549412528, disc_loss = 0.0005841487827538103
Trained batch 182 in epoch 4, gen_loss = 1.03246060127769, disc_loss = 0.0005818081924582379
Trained batch 183 in epoch 4, gen_loss = 1.0322660703373991, disc_loss = 0.0005799743189329646
Trained batch 184 in epoch 4, gen_loss = 1.0328881730904451, disc_loss = 0.0005796640227246728
Trained batch 185 in epoch 4, gen_loss = 1.033036050296599, disc_loss = 0.0005787883881136515
Trained batch 186 in epoch 4, gen_loss = 1.0329227610067888, disc_loss = 0.0005771803668386397
Trained batch 187 in epoch 4, gen_loss = 1.0332880904699893, disc_loss = 0.0005753644106741202
Trained batch 188 in epoch 4, gen_loss = 1.0333009387450243, disc_loss = 0.0005737086488537629
Trained batch 189 in epoch 4, gen_loss = 1.0335693638575705, disc_loss = 0.0005721727329441102
Trained batch 190 in epoch 4, gen_loss = 1.0335007366085551, disc_loss = 0.0005709149247566872
Trained batch 191 in epoch 4, gen_loss = 1.033916970404486, disc_loss = 0.0005699932659505672
Trained batch 192 in epoch 4, gen_loss = 1.0334970040024871, disc_loss = 0.0005691592289627062
Trained batch 193 in epoch 4, gen_loss = 1.032972722016659, disc_loss = 0.0005686411989034278
Trained batch 194 in epoch 4, gen_loss = 1.0333086432554783, disc_loss = 0.0005678270655409553
Trained batch 195 in epoch 4, gen_loss = 1.033161539508372, disc_loss = 0.0005665671024519038
Trained batch 196 in epoch 4, gen_loss = 1.0331558796960085, disc_loss = 0.0005650430362846532
Trained batch 197 in epoch 4, gen_loss = 1.0331804237582467, disc_loss = 0.0005631602000012391
Trained batch 198 in epoch 4, gen_loss = 1.0333481017668642, disc_loss = 0.0005613517004618627
Trained batch 199 in epoch 4, gen_loss = 1.0328156399726867, disc_loss = 0.0005598793505487265
Trained batch 200 in epoch 4, gen_loss = 1.0321114902472615, disc_loss = 0.000558635378409923
Trained batch 201 in epoch 4, gen_loss = 1.0320084357615744, disc_loss = 0.0005583171085091446
Trained batch 202 in epoch 4, gen_loss = 1.0322451952642995, disc_loss = 0.0005581543943299935
Trained batch 203 in epoch 4, gen_loss = 1.0324989414098216, disc_loss = 0.000558077989219729
Trained batch 204 in epoch 4, gen_loss = 1.0327143898824367, disc_loss = 0.000557673934537622
Trained batch 205 in epoch 4, gen_loss = 1.0325927071779677, disc_loss = 0.0005565930142500257
Trained batch 206 in epoch 4, gen_loss = 1.0330252494788976, disc_loss = 0.0005550434201863563
Trained batch 207 in epoch 4, gen_loss = 1.0332236034938922, disc_loss = 0.0005530859318521555
Trained batch 208 in epoch 4, gen_loss = 1.0330141457644375, disc_loss = 0.000551184798848735
Trained batch 209 in epoch 4, gen_loss = 1.033145877293178, disc_loss = 0.0005497757120229792
Trained batch 210 in epoch 4, gen_loss = 1.0329125910573662, disc_loss = 0.0005488197304174896
Trained batch 211 in epoch 4, gen_loss = 1.033061241203884, disc_loss = 0.0005491107030533351
Trained batch 212 in epoch 4, gen_loss = 1.0327197067054785, disc_loss = 0.0005514566078667306
Trained batch 213 in epoch 4, gen_loss = 1.0325168672009049, disc_loss = 0.0005557842690157095
Trained batch 214 in epoch 4, gen_loss = 1.0324550661929819, disc_loss = 0.0005612305662632638
Trained batch 215 in epoch 4, gen_loss = 1.032322128061895, disc_loss = 0.0005667416391117042
Trained batch 216 in epoch 4, gen_loss = 1.0323723950144332, disc_loss = 0.0005725207426751565
Trained batch 217 in epoch 4, gen_loss = 1.0324575255770203, disc_loss = 0.0005780780674444315
Trained batch 218 in epoch 4, gen_loss = 1.0323688385149115, disc_loss = 0.0005827558100766813
Trained batch 219 in epoch 4, gen_loss = 1.0322263192046772, disc_loss = 0.0005860584237035999
Trained batch 220 in epoch 4, gen_loss = 1.0319422620993395, disc_loss = 0.0005877176025114338
Trained batch 221 in epoch 4, gen_loss = 1.03209634648787, disc_loss = 0.0005883000835515181
Trained batch 222 in epoch 4, gen_loss = 1.0321964985052032, disc_loss = 0.0005877268244956114
Trained batch 223 in epoch 4, gen_loss = 1.0321464115487677, disc_loss = 0.0005864927922110448
Trained batch 224 in epoch 4, gen_loss = 1.0320709999402364, disc_loss = 0.0005848746838617242
Trained batch 225 in epoch 4, gen_loss = 1.032062673726968, disc_loss = 0.0005830343210280551
Trained batch 226 in epoch 4, gen_loss = 1.0322718019002335, disc_loss = 0.0005813366700156637
Trained batch 227 in epoch 4, gen_loss = 1.0320793805938018, disc_loss = 0.0005808754424817795
Trained batch 228 in epoch 4, gen_loss = 1.031839663545117, disc_loss = 0.000581883163471995
Trained batch 229 in epoch 4, gen_loss = 1.0321124437062636, disc_loss = 0.0005827085960291974
Trained batch 230 in epoch 4, gen_loss = 1.0321576840433724, disc_loss = 0.00058248984421809
Trained batch 231 in epoch 4, gen_loss = 1.0322325787153737, disc_loss = 0.0005814020285093836
Trained batch 232 in epoch 4, gen_loss = 1.0317635758751964, disc_loss = 0.0005801466725568802
Trained batch 233 in epoch 4, gen_loss = 1.0320431750554304, disc_loss = 0.0005787818471982708
Trained batch 234 in epoch 4, gen_loss = 1.0321488388041233, disc_loss = 0.000577304856059082
Trained batch 235 in epoch 4, gen_loss = 1.0318846088849891, disc_loss = 0.0005758889507841698
Trained batch 236 in epoch 4, gen_loss = 1.031720910394242, disc_loss = 0.0005746384547681466
Trained batch 237 in epoch 4, gen_loss = 1.0318456497512947, disc_loss = 0.0005737046472446507
Trained batch 238 in epoch 4, gen_loss = 1.0320603652978044, disc_loss = 0.000573446856281685
Trained batch 239 in epoch 4, gen_loss = 1.0317267288764318, disc_loss = 0.0005746979271255744
Trained batch 240 in epoch 4, gen_loss = 1.031793840198596, disc_loss = 0.0005774243045946066
Trained batch 241 in epoch 4, gen_loss = 1.0318160554594245, disc_loss = 0.0005813203362386273
Trained batch 242 in epoch 4, gen_loss = 1.0316203420544847, disc_loss = 0.0005846117779328929
Trained batch 243 in epoch 4, gen_loss = 1.0319626438813132, disc_loss = 0.0005867418706165168
Trained batch 244 in epoch 4, gen_loss = 1.0317949329103742, disc_loss = 0.0005872011826164564
Trained batch 245 in epoch 4, gen_loss = 1.0318185449615727, disc_loss = 0.0005866935854300675
Trained batch 246 in epoch 4, gen_loss = 1.0316781071033554, disc_loss = 0.0005856336644466077
Trained batch 247 in epoch 4, gen_loss = 1.031776199898412, disc_loss = 0.0005841060299116502
Trained batch 248 in epoch 4, gen_loss = 1.0318717338952674, disc_loss = 0.0005823786173625494
Trained batch 249 in epoch 4, gen_loss = 1.031867208003998, disc_loss = 0.0005806111746351235
Trained batch 250 in epoch 4, gen_loss = 1.0317297385508322, disc_loss = 0.0005789582035620233
Trained batch 251 in epoch 4, gen_loss = 1.0315148839874873, disc_loss = 0.0005774131151690473
Trained batch 252 in epoch 4, gen_loss = 1.03129878581277, disc_loss = 0.0005759744406374091
Trained batch 253 in epoch 4, gen_loss = 1.031559911769206, disc_loss = 0.0005747408640028278
Trained batch 254 in epoch 4, gen_loss = 1.0315372611962113, disc_loss = 0.0005733814468840137
Trained batch 255 in epoch 4, gen_loss = 1.0316767301410437, disc_loss = 0.0005719903861063358
Trained batch 256 in epoch 4, gen_loss = 1.0319924925087955, disc_loss = 0.0005707662008568674
Trained batch 257 in epoch 4, gen_loss = 1.0316905383915864, disc_loss = 0.0005695310664045545
Trained batch 258 in epoch 4, gen_loss = 1.0315741139489252, disc_loss = 0.0005685464120793613
Trained batch 259 in epoch 4, gen_loss = 1.0313821989756364, disc_loss = 0.0005677223257057798
Trained batch 260 in epoch 4, gen_loss = 1.0317049451257991, disc_loss = 0.0005671955657127345
Trained batch 261 in epoch 4, gen_loss = 1.0314894209381278, disc_loss = 0.0005671239470465834
Trained batch 262 in epoch 4, gen_loss = 1.0315211639658126, disc_loss = 0.0005673528332422583
Trained batch 263 in epoch 4, gen_loss = 1.0317223555210866, disc_loss = 0.0005670663634770211
Trained batch 264 in epoch 4, gen_loss = 1.0318933833320185, disc_loss = 0.0005660189827464802
Trained batch 265 in epoch 4, gen_loss = 1.0315694172579544, disc_loss = 0.0005647126169804365
Trained batch 266 in epoch 4, gen_loss = 1.0315219516611278, disc_loss = 0.0005635034635969113
Trained batch 267 in epoch 4, gen_loss = 1.0314335080225077, disc_loss = 0.0005620600517866125
Trained batch 268 in epoch 4, gen_loss = 1.0316339376690662, disc_loss = 0.0005605011288752627
Trained batch 269 in epoch 4, gen_loss = 1.0317266782124836, disc_loss = 0.0005589845421060023
Trained batch 270 in epoch 4, gen_loss = 1.031686673745018, disc_loss = 0.0005576029134015605
Trained batch 271 in epoch 4, gen_loss = 1.031987425597275, disc_loss = 0.0005564340288080583
Trained batch 272 in epoch 4, gen_loss = 1.0321115002090677, disc_loss = 0.0005550857233787604
Trained batch 273 in epoch 4, gen_loss = 1.0323152929326913, disc_loss = 0.000553854111175012
Trained batch 274 in epoch 4, gen_loss = 1.0322635585611517, disc_loss = 0.0005528392650144682
Trained batch 275 in epoch 4, gen_loss = 1.0321173451948857, disc_loss = 0.000551978578859353
Trained batch 276 in epoch 4, gen_loss = 1.0321557461569886, disc_loss = 0.0005512816297934334
Trained batch 277 in epoch 4, gen_loss = 1.0320426748810911, disc_loss = 0.0005505977835206368
Trained batch 278 in epoch 4, gen_loss = 1.0317227274286278, disc_loss = 0.0005498318657559413
Trained batch 279 in epoch 4, gen_loss = 1.0318978350077357, disc_loss = 0.0005489199798570813
Trained batch 280 in epoch 4, gen_loss = 1.0315346503597138, disc_loss = 0.0005477296944655432
Trained batch 281 in epoch 4, gen_loss = 1.0312740762605734, disc_loss = 0.0005465506445756843
Trained batch 282 in epoch 4, gen_loss = 1.0313366607305439, disc_loss = 0.0005455143930095943
Trained batch 283 in epoch 4, gen_loss = 1.0312207087244787, disc_loss = 0.0005442970104410614
Trained batch 284 in epoch 4, gen_loss = 1.0313883925739087, disc_loss = 0.0005429586118879614
Trained batch 285 in epoch 4, gen_loss = 1.031533299834578, disc_loss = 0.0005416825782691644
Trained batch 286 in epoch 4, gen_loss = 1.0319578682919412, disc_loss = 0.0005405210280520777
Trained batch 287 in epoch 4, gen_loss = 1.0323851458314393, disc_loss = 0.0005392596819749289
Trained batch 288 in epoch 4, gen_loss = 1.0325541168348187, disc_loss = 0.0005378405599082276
Trained batch 289 in epoch 4, gen_loss = 1.0323720348292384, disc_loss = 0.000536465492141674
Trained batch 290 in epoch 4, gen_loss = 1.0322689731506138, disc_loss = 0.0005351021005556026
Trained batch 291 in epoch 4, gen_loss = 1.0325967669487, disc_loss = 0.000533872003820948
Trained batch 292 in epoch 4, gen_loss = 1.032630535115968, disc_loss = 0.0005326042831942929
Trained batch 293 in epoch 4, gen_loss = 1.0326467180738643, disc_loss = 0.0005312983088094748
Trained batch 294 in epoch 4, gen_loss = 1.0324435086573585, disc_loss = 0.0005299610478933743
Trained batch 295 in epoch 4, gen_loss = 1.032501803660715, disc_loss = 0.0005286816530487331
Trained batch 296 in epoch 4, gen_loss = 1.0325246128168972, disc_loss = 0.0005276157415957231
Trained batch 297 in epoch 4, gen_loss = 1.0324779762917717, disc_loss = 0.0005267223833232724
Trained batch 298 in epoch 4, gen_loss = 1.0326015823660886, disc_loss = 0.0005260347188656751
Trained batch 299 in epoch 4, gen_loss = 1.0328579451640447, disc_loss = 0.0005253951086100036
Trained batch 300 in epoch 4, gen_loss = 1.0327672904908063, disc_loss = 0.0005248926739588201
Trained batch 301 in epoch 4, gen_loss = 1.0328455210126788, disc_loss = 0.0005246893086355791
Trained batch 302 in epoch 4, gen_loss = 1.0328132533791041, disc_loss = 0.0005249566270907566
Trained batch 303 in epoch 4, gen_loss = 1.0327749340549897, disc_loss = 0.0005255909860160931
Trained batch 304 in epoch 4, gen_loss = 1.0328932896989291, disc_loss = 0.0005260261391636869
Trained batch 305 in epoch 4, gen_loss = 1.032748263451009, disc_loss = 0.0005266641787754743
Trained batch 306 in epoch 4, gen_loss = 1.0326771159513766, disc_loss = 0.0005278709461265592
Trained batch 307 in epoch 4, gen_loss = 1.0324023275019287, disc_loss = 0.0005294220340525121
Trained batch 308 in epoch 4, gen_loss = 1.0324946308213145, disc_loss = 0.0005315399378245021
Trained batch 309 in epoch 4, gen_loss = 1.0325203336054278, disc_loss = 0.0005339826845409979
Trained batch 310 in epoch 4, gen_loss = 1.032431210927258, disc_loss = 0.0005365790511684349
Trained batch 311 in epoch 4, gen_loss = 1.0321627274537697, disc_loss = 0.000539506283483859
Trained batch 312 in epoch 4, gen_loss = 1.0320782406261553, disc_loss = 0.0005436892746839845
Trained batch 313 in epoch 4, gen_loss = 1.0322093428320187, disc_loss = 0.0005488744919736288
Trained batch 314 in epoch 4, gen_loss = 1.0321714401245117, disc_loss = 0.0005546521348786348
Trained batch 315 in epoch 4, gen_loss = 1.032055753129947, disc_loss = 0.0005597648410405816
Trained batch 316 in epoch 4, gen_loss = 1.0318794380227099, disc_loss = 0.0005637782135863027
Trained batch 317 in epoch 4, gen_loss = 1.0317206997541513, disc_loss = 0.0005677018635199733
Trained batch 318 in epoch 4, gen_loss = 1.031918204316525, disc_loss = 0.0005706730343859065
Trained batch 319 in epoch 4, gen_loss = 1.0319383502006532, disc_loss = 0.0005722682793475542
Trained batch 320 in epoch 4, gen_loss = 1.0317631328588706, disc_loss = 0.0005726836355837538
Trained batch 321 in epoch 4, gen_loss = 1.031587220867228, disc_loss = 0.000572354271160135
Trained batch 322 in epoch 4, gen_loss = 1.0313556829104114, disc_loss = 0.0005720008455051813
Trained batch 323 in epoch 4, gen_loss = 1.0313030216428969, disc_loss = 0.0005716291591032828
Trained batch 324 in epoch 4, gen_loss = 1.0312742812816913, disc_loss = 0.0005712781348176158
Trained batch 325 in epoch 4, gen_loss = 1.0315845904906102, disc_loss = 0.000570987875866518
Trained batch 326 in epoch 4, gen_loss = 1.0315978738510645, disc_loss = 0.0005703114658193264
Trained batch 327 in epoch 4, gen_loss = 1.0318194689547144, disc_loss = 0.0005694171687514981
Trained batch 328 in epoch 4, gen_loss = 1.0317256425289398, disc_loss = 0.0005687706844862069
Trained batch 329 in epoch 4, gen_loss = 1.0319647908210754, disc_loss = 0.0005688326902930964
Trained batch 330 in epoch 4, gen_loss = 1.0319140497651345, disc_loss = 0.0005689037143301325
Trained batch 331 in epoch 4, gen_loss = 1.0321130336049091, disc_loss = 0.000569195218227526
Trained batch 332 in epoch 4, gen_loss = 1.0321165373375465, disc_loss = 0.0005693866544163313
Trained batch 333 in epoch 4, gen_loss = 1.032045259447155, disc_loss = 0.0005693439656780045
Trained batch 334 in epoch 4, gen_loss = 1.0318590041416795, disc_loss = 0.0005691132998639551
Trained batch 335 in epoch 4, gen_loss = 1.0316421511982168, disc_loss = 0.0005684426033829888
Trained batch 336 in epoch 4, gen_loss = 1.0312710096645072, disc_loss = 0.0005677590401513635
Trained batch 337 in epoch 4, gen_loss = 1.0312184936548832, disc_loss = 0.0005668956857776
Trained batch 338 in epoch 4, gen_loss = 1.0310299487943846, disc_loss = 0.0005659942658481416
Trained batch 339 in epoch 4, gen_loss = 1.0305953800678254, disc_loss = 0.00056493749789832
Trained batch 340 in epoch 4, gen_loss = 1.0305477716356428, disc_loss = 0.0005640059549008466
Trained batch 341 in epoch 4, gen_loss = 1.030649815386499, disc_loss = 0.0005630734534467821
Trained batch 342 in epoch 4, gen_loss = 1.030676628688334, disc_loss = 0.0005621408692217613
Trained batch 343 in epoch 4, gen_loss = 1.0307810389718344, disc_loss = 0.0005611355492112845
Trained batch 344 in epoch 4, gen_loss = 1.0306793748468592, disc_loss = 0.0005600921971220658
Trained batch 345 in epoch 4, gen_loss = 1.0306749643617972, disc_loss = 0.0005590598412010162
Trained batch 346 in epoch 4, gen_loss = 1.0307051286917255, disc_loss = 0.0005580926003583414
Trained batch 347 in epoch 4, gen_loss = 1.0307654680191785, disc_loss = 0.0005571310600013627
Trained batch 348 in epoch 4, gen_loss = 1.0306112115567598, disc_loss = 0.0005561252234101343
Trained batch 349 in epoch 4, gen_loss = 1.0305454562391554, disc_loss = 0.0005552346241477477
Trained batch 350 in epoch 4, gen_loss = 1.0306216337402323, disc_loss = 0.0005545336955861769
Trained batch 351 in epoch 4, gen_loss = 1.030461498112841, disc_loss = 0.0005539501187492781
Trained batch 352 in epoch 4, gen_loss = 1.0304016477663187, disc_loss = 0.0005533657908270125
Trained batch 353 in epoch 4, gen_loss = 1.0303748989172574, disc_loss = 0.0005526686937592288
Trained batch 354 in epoch 4, gen_loss = 1.0303254243353723, disc_loss = 0.0005518191528070429
Trained batch 355 in epoch 4, gen_loss = 1.0302491635084152, disc_loss = 0.0005510087336169613
Trained batch 356 in epoch 4, gen_loss = 1.0304057730012248, disc_loss = 0.0005502988091041921
Trained batch 357 in epoch 4, gen_loss = 1.0302528034708354, disc_loss = 0.0005497698208812088
Trained batch 358 in epoch 4, gen_loss = 1.0302855130025603, disc_loss = 0.0005491656367748089
Trained batch 359 in epoch 4, gen_loss = 1.030484212934971, disc_loss = 0.0005484983457184474
Trained batch 360 in epoch 4, gen_loss = 1.0305258691145773, disc_loss = 0.0005479699578842438
Trained batch 361 in epoch 4, gen_loss = 1.030368129686756, disc_loss = 0.00054768565796973
Trained batch 362 in epoch 4, gen_loss = 1.030372591222285, disc_loss = 0.0005477751419124561
Trained batch 363 in epoch 4, gen_loss = 1.0302257156306571, disc_loss = 0.0005481461990751956
Trained batch 364 in epoch 4, gen_loss = 1.030173830626762, disc_loss = 0.0005485162798758622
Trained batch 365 in epoch 4, gen_loss = 1.0300967769870342, disc_loss = 0.0005486624561809385
Trained batch 366 in epoch 4, gen_loss = 1.0300820642011368, disc_loss = 0.0005484485804221951
Trained batch 367 in epoch 4, gen_loss = 1.0301565561929475, disc_loss = 0.00054824466730244
Trained batch 368 in epoch 4, gen_loss = 1.0302683568905362, disc_loss = 0.0005483548864794814
Trained batch 369 in epoch 4, gen_loss = 1.03020761190234, disc_loss = 0.0005488298406645127
Trained batch 370 in epoch 4, gen_loss = 1.0302028513018975, disc_loss = 0.0005492724870401247
Trained batch 371 in epoch 4, gen_loss = 1.0299147135147484, disc_loss = 0.000549331001781856
Trained batch 372 in epoch 4, gen_loss = 1.0298794305036918, disc_loss = 0.0005494264616046086
Trained batch 373 in epoch 4, gen_loss = 1.0299762954367673, disc_loss = 0.0005493557911642011
Trained batch 374 in epoch 4, gen_loss = 1.0300140051841735, disc_loss = 0.0005489251183268303
Trained batch 375 in epoch 4, gen_loss = 1.0301198834117422, disc_loss = 0.0005483604354788227
Trained batch 376 in epoch 4, gen_loss = 1.0302126225805408, disc_loss = 0.0005477431790476457
Trained batch 377 in epoch 4, gen_loss = 1.029981939723252, disc_loss = 0.0005471434788122434
Trained batch 378 in epoch 4, gen_loss = 1.029816158685961, disc_loss = 0.0005466175778344455
Trained batch 379 in epoch 4, gen_loss = 1.0299114319838976, disc_loss = 0.0005461428046768752
Trained batch 380 in epoch 4, gen_loss = 1.0298005064015627, disc_loss = 0.0005456400148554038
Trained batch 381 in epoch 4, gen_loss = 1.0296784370981586, disc_loss = 0.0005450526546703344
Trained batch 382 in epoch 4, gen_loss = 1.0293261715388484, disc_loss = 0.0005444307915587343
Trained batch 383 in epoch 4, gen_loss = 1.0294742432112496, disc_loss = 0.0005437873639569565
Trained batch 384 in epoch 4, gen_loss = 1.029649820265832, disc_loss = 0.000543248530911197
Trained batch 385 in epoch 4, gen_loss = 1.029596083831293, disc_loss = 0.0005425192845712049
Trained batch 386 in epoch 4, gen_loss = 1.0296777767112397, disc_loss = 0.0005417276042298767
Trained batch 387 in epoch 4, gen_loss = 1.029673164038314, disc_loss = 0.0005408651560764597
Trained batch 388 in epoch 4, gen_loss = 1.0297261684903143, disc_loss = 0.0005399320645085452
Trained batch 389 in epoch 4, gen_loss = 1.0297144792018793, disc_loss = 0.0005389259566958898
Trained batch 390 in epoch 4, gen_loss = 1.0297348987111046, disc_loss = 0.0005378655743111721
Trained batch 391 in epoch 4, gen_loss = 1.0297451730893583, disc_loss = 0.0005368197492186612
Trained batch 392 in epoch 4, gen_loss = 1.0297819291058994, disc_loss = 0.0005357980960091391
Trained batch 393 in epoch 4, gen_loss = 1.0297126869864874, disc_loss = 0.0005351281860786571
Trained batch 394 in epoch 4, gen_loss = 1.0296450062643123, disc_loss = 0.0005348012826841655
Trained batch 395 in epoch 4, gen_loss = 1.0295817292097844, disc_loss = 0.0005347546160037657
Trained batch 396 in epoch 4, gen_loss = 1.029521168028978, disc_loss = 0.0005347766704981682
Trained batch 397 in epoch 4, gen_loss = 1.029402178585829, disc_loss = 0.0005344902678573008
Trained batch 398 in epoch 4, gen_loss = 1.0293202055127997, disc_loss = 0.0005340834937751629
Trained batch 399 in epoch 4, gen_loss = 1.0292088657617569, disc_loss = 0.0005334650374425109
Trained batch 400 in epoch 4, gen_loss = 1.0291928388828648, disc_loss = 0.0005327367551924958
Trained batch 401 in epoch 4, gen_loss = 1.0291157723659308, disc_loss = 0.0005319220718634616
Trained batch 402 in epoch 4, gen_loss = 1.0291296187464711, disc_loss = 0.0005313374832816764
Trained batch 403 in epoch 4, gen_loss = 1.0291863747752539, disc_loss = 0.0005314067722324715
Trained batch 404 in epoch 4, gen_loss = 1.0289848457148045, disc_loss = 0.0005315699162576808
Trained batch 405 in epoch 4, gen_loss = 1.0288104740856903, disc_loss = 0.0005314754978942873
Trained batch 406 in epoch 4, gen_loss = 1.028749131453418, disc_loss = 0.0005316009730843172
Trained batch 407 in epoch 4, gen_loss = 1.028630354094739, disc_loss = 0.0005324458950638597
Trained batch 408 in epoch 4, gen_loss = 1.0286049136031228, disc_loss = 0.000534529301117591
Trained batch 409 in epoch 4, gen_loss = 1.0286155702137365, disc_loss = 0.0005369548740507126
Trained batch 410 in epoch 4, gen_loss = 1.0288655634634105, disc_loss = 0.0005388911732063468
Trained batch 411 in epoch 4, gen_loss = 1.028837152910464, disc_loss = 0.0005401986212728464
Trained batch 412 in epoch 4, gen_loss = 1.0289645828577276, disc_loss = 0.0005415751028396685
Trained batch 413 in epoch 4, gen_loss = 1.0288055416754478, disc_loss = 0.0005438057689591207
Trained batch 414 in epoch 4, gen_loss = 1.028713788325528, disc_loss = 0.0005470367025791566
Trained batch 415 in epoch 4, gen_loss = 1.0289872350314488, disc_loss = 0.0005504085225206487
Trained batch 416 in epoch 4, gen_loss = 1.02912862309449, disc_loss = 0.0005535638857799263
Trained batch 417 in epoch 4, gen_loss = 1.0291806383851612, disc_loss = 0.0005561566450571837
Trained batch 418 in epoch 4, gen_loss = 1.0292155115302821, disc_loss = 0.0005581457774807212
Trained batch 419 in epoch 4, gen_loss = 1.0291590484834852, disc_loss = 0.0005595053466441597
Trained batch 420 in epoch 4, gen_loss = 1.0290982413178669, disc_loss = 0.0005602967885135941
Trained batch 421 in epoch 4, gen_loss = 1.0290884930658115, disc_loss = 0.0005603542392637571
Trained batch 422 in epoch 4, gen_loss = 1.0289213016241718, disc_loss = 0.0005600918526788755
Trained batch 423 in epoch 4, gen_loss = 1.0286236858030535, disc_loss = 0.0005598956418255528
Trained batch 424 in epoch 4, gen_loss = 1.0284237070644604, disc_loss = 0.0005595005622051438
Trained batch 425 in epoch 4, gen_loss = 1.02861775786664, disc_loss = 0.0005586636342882166
Trained batch 426 in epoch 4, gen_loss = 1.0286241789333155, disc_loss = 0.0005576201303304769
Trained batch 427 in epoch 4, gen_loss = 1.0285607398113357, disc_loss = 0.0005566375648328669
Trained batch 428 in epoch 4, gen_loss = 1.0284911016206364, disc_loss = 0.0005557185928592358
Trained batch 429 in epoch 4, gen_loss = 1.0284317873245061, disc_loss = 0.0005548068883336084
Trained batch 430 in epoch 4, gen_loss = 1.0283205133026547, disc_loss = 0.0005539745465677292
Trained batch 431 in epoch 4, gen_loss = 1.0283482469342373, disc_loss = 0.000553006176738159
Trained batch 432 in epoch 4, gen_loss = 1.028491157031775, disc_loss = 0.0005520046617705095
Trained batch 433 in epoch 4, gen_loss = 1.0285216212821995, disc_loss = 0.0005510009139613141
Trained batch 434 in epoch 4, gen_loss = 1.028463394614472, disc_loss = 0.0005499784647013414
Trained batch 435 in epoch 4, gen_loss = 1.0283612181013877, disc_loss = 0.0005490107175711448
Trained batch 436 in epoch 4, gen_loss = 1.0283980793756533, disc_loss = 0.0005482513520406299
Trained batch 437 in epoch 4, gen_loss = 1.0282434295845904, disc_loss = 0.0005475792679143644
Trained batch 438 in epoch 4, gen_loss = 1.0282795434660683, disc_loss = 0.0005474280701750775
Trained batch 439 in epoch 4, gen_loss = 1.028509722514586, disc_loss = 0.0005477799699292518
Trained batch 440 in epoch 4, gen_loss = 1.02836025409958, disc_loss = 0.0005476652337565528
Trained batch 441 in epoch 4, gen_loss = 1.0281095901226027, disc_loss = 0.0005471394415755179
Trained batch 442 in epoch 4, gen_loss = 1.0279232411567567, disc_loss = 0.0005466903652627921
Trained batch 443 in epoch 4, gen_loss = 1.0280134763803568, disc_loss = 0.0005463302728818595
Trained batch 444 in epoch 4, gen_loss = 1.0280124463392109, disc_loss = 0.0005461281938530672
Trained batch 445 in epoch 4, gen_loss = 1.027759036675697, disc_loss = 0.0005460620685240396
Trained batch 446 in epoch 4, gen_loss = 1.0278664381978762, disc_loss = 0.00054628594184161
Trained batch 447 in epoch 4, gen_loss = 1.0279365490589822, disc_loss = 0.0005470954978851036
Trained batch 448 in epoch 4, gen_loss = 1.0276147366101067, disc_loss = 0.0005475617481088619
Trained batch 449 in epoch 4, gen_loss = 1.0275767193900214, disc_loss = 0.0005474205801470413
Trained batch 450 in epoch 4, gen_loss = 1.0274795502622482, disc_loss = 0.0005469660601473337
Trained batch 451 in epoch 4, gen_loss = 1.0273335874080658, disc_loss = 0.0005463837745493335
Trained batch 452 in epoch 4, gen_loss = 1.0273421629112025, disc_loss = 0.0005455493351221537
Trained batch 453 in epoch 4, gen_loss = 1.0274117394690996, disc_loss = 0.0005446526033525347
Trained batch 454 in epoch 4, gen_loss = 1.0273215362003871, disc_loss = 0.0005437895725673105
Trained batch 455 in epoch 4, gen_loss = 1.0271656526285304, disc_loss = 0.0005430747846331909
Trained batch 456 in epoch 4, gen_loss = 1.0272003618319656, disc_loss = 0.000542261544258397
Trained batch 457 in epoch 4, gen_loss = 1.0271370444755887, disc_loss = 0.000541424096038862
Trained batch 458 in epoch 4, gen_loss = 1.0271146824676747, disc_loss = 0.0005405615348280621
Trained batch 459 in epoch 4, gen_loss = 1.027165253525195, disc_loss = 0.0005398217786062995
Trained batch 460 in epoch 4, gen_loss = 1.0270076188503274, disc_loss = 0.0005398693013685773
Trained batch 461 in epoch 4, gen_loss = 1.0269800917410747, disc_loss = 0.0005416827421490248
Trained batch 462 in epoch 4, gen_loss = 1.0269256158214923, disc_loss = 0.0005453310471398205
Trained batch 463 in epoch 4, gen_loss = 1.0268691441622273, disc_loss = 0.0005492593296241529
Trained batch 464 in epoch 4, gen_loss = 1.0269941540174587, disc_loss = 0.0005522465991777599
Trained batch 465 in epoch 4, gen_loss = 1.0269451609496907, disc_loss = 0.0005545223635409523
Trained batch 466 in epoch 4, gen_loss = 1.0269109380832322, disc_loss = 0.0005560068800502978
Trained batch 467 in epoch 4, gen_loss = 1.0267405438626933, disc_loss = 0.0005565455330647209
Trained batch 468 in epoch 4, gen_loss = 1.0267570959225392, disc_loss = 0.000556612514760663
Trained batch 469 in epoch 4, gen_loss = 1.0268528020128291, disc_loss = 0.000556733744204084
Trained batch 470 in epoch 4, gen_loss = 1.0268471478909698, disc_loss = 0.0005569399633314342
Trained batch 471 in epoch 4, gen_loss = 1.026906575691902, disc_loss = 0.0005573730033297502
Trained batch 472 in epoch 4, gen_loss = 1.026964348920052, disc_loss = 0.0005578205793511209
Trained batch 473 in epoch 4, gen_loss = 1.026920127466258, disc_loss = 0.0005579376510955503
Trained batch 474 in epoch 4, gen_loss = 1.0268105697631835, disc_loss = 0.0005577893279443838
Trained batch 475 in epoch 4, gen_loss = 1.0265858089473068, disc_loss = 0.0005574064077237159
Trained batch 476 in epoch 4, gen_loss = 1.026626727491055, disc_loss = 0.0005566780718687269
Trained batch 477 in epoch 4, gen_loss = 1.0266580710101827, disc_loss = 0.0005558732642902248
Trained batch 478 in epoch 4, gen_loss = 1.0266212878247143, disc_loss = 0.0005550531316587472
Trained batch 479 in epoch 4, gen_loss = 1.0267761254062255, disc_loss = 0.0005541632774717679
Trained batch 480 in epoch 4, gen_loss = 1.0264657878330492, disc_loss = 0.0005538793311700256
Trained batch 481 in epoch 4, gen_loss = 1.0265370294513545, disc_loss = 0.0005558337922076621
Trained batch 482 in epoch 4, gen_loss = 1.0264739405294383, disc_loss = 0.0005588715032657019
Trained batch 483 in epoch 4, gen_loss = 1.0263369712701513, disc_loss = 0.0005608461794832121
Trained batch 484 in epoch 4, gen_loss = 1.026413760111504, disc_loss = 0.0005608019951884586
Trained batch 485 in epoch 4, gen_loss = 1.0264246136318018, disc_loss = 0.000560182505675281
Trained batch 486 in epoch 4, gen_loss = 1.0263255817444663, disc_loss = 0.0005598817191213882
Trained batch 487 in epoch 4, gen_loss = 1.026277359880385, disc_loss = 0.0005600171708897878
Trained batch 488 in epoch 4, gen_loss = 1.0262679268733612, disc_loss = 0.0005600126042980167
Trained batch 489 in epoch 4, gen_loss = 1.0262277226058805, disc_loss = 0.0005596803404433576
Trained batch 490 in epoch 4, gen_loss = 1.0260839276546858, disc_loss = 0.0005590685854510399
Trained batch 491 in epoch 4, gen_loss = 1.0261899561174517, disc_loss = 0.0005585815817495331
Trained batch 492 in epoch 4, gen_loss = 1.0261619704006653, disc_loss = 0.0005579641844834528
Trained batch 493 in epoch 4, gen_loss = 1.0260371674410245, disc_loss = 0.0005571707753643209
Trained batch 494 in epoch 4, gen_loss = 1.0262234596290973, disc_loss = 0.0005566880769846547
Trained batch 495 in epoch 4, gen_loss = 1.0263732441010014, disc_loss = 0.0005563743378285924
Trained batch 496 in epoch 4, gen_loss = 1.026261134646548, disc_loss = 0.0005559408922749525
Trained batch 497 in epoch 4, gen_loss = 1.026067167041771, disc_loss = 0.0005553714251863381
Trained batch 498 in epoch 4, gen_loss = 1.0261324731285921, disc_loss = 0.0005550720188675732
Trained batch 499 in epoch 4, gen_loss = 1.0261868728399277, disc_loss = 0.0005550128865579609
Trained batch 500 in epoch 4, gen_loss = 1.0261657310579113, disc_loss = 0.0005547880939407341
Trained batch 501 in epoch 4, gen_loss = 1.0261957511246442, disc_loss = 0.0005544213030176085
Trained batch 502 in epoch 4, gen_loss = 1.0261002354783044, disc_loss = 0.0005538023238555875
Trained batch 503 in epoch 4, gen_loss = 1.0261513018418873, disc_loss = 0.0005532067323310045
Trained batch 504 in epoch 4, gen_loss = 1.026061755123705, disc_loss = 0.0005532545763434437
Trained batch 505 in epoch 4, gen_loss = 1.0260757641358809, disc_loss = 0.0005544720432643314
Trained batch 506 in epoch 4, gen_loss = 1.0259808814502092, disc_loss = 0.000556993993251544
Trained batch 507 in epoch 4, gen_loss = 1.0257834848456495, disc_loss = 0.0005604688957410105
Trained batch 508 in epoch 4, gen_loss = 1.0257010488004255, disc_loss = 0.0005636316774610141
Trained batch 509 in epoch 4, gen_loss = 1.025701325079974, disc_loss = 0.000565829860958426
Trained batch 510 in epoch 4, gen_loss = 1.025834428120966, disc_loss = 0.0005668266129316835
Trained batch 511 in epoch 4, gen_loss = 1.025694628013298, disc_loss = 0.0005666041347183182
Trained batch 512 in epoch 4, gen_loss = 1.0255500491831968, disc_loss = 0.0005660422113018299
Trained batch 513 in epoch 4, gen_loss = 1.0255203592638098, disc_loss = 0.0005654416658613443
Trained batch 514 in epoch 4, gen_loss = 1.0255418089987005, disc_loss = 0.0005647405223905118
Trained batch 515 in epoch 4, gen_loss = 1.0254340812910434, disc_loss = 0.0005639513178474483
Trained batch 516 in epoch 4, gen_loss = 1.0253550490973304, disc_loss = 0.0005633744896253088
Trained batch 517 in epoch 4, gen_loss = 1.0252953384603773, disc_loss = 0.0005628111674533491
Trained batch 518 in epoch 4, gen_loss = 1.025400058037973, disc_loss = 0.0005624995666777227
Trained batch 519 in epoch 4, gen_loss = 1.0253650583899938, disc_loss = 0.0005626931368169607
Trained batch 520 in epoch 4, gen_loss = 1.025462906671806, disc_loss = 0.0005634121716412628
Trained batch 521 in epoch 4, gen_loss = 1.0253595450600446, disc_loss = 0.0005644561113868626
Trained batch 522 in epoch 4, gen_loss = 1.0253623383222985, disc_loss = 0.0005654588212442974
Trained batch 523 in epoch 4, gen_loss = 1.0253230459589995, disc_loss = 0.000566205747994525
Trained batch 524 in epoch 4, gen_loss = 1.0252144321941195, disc_loss = 0.0005663521558190474
Trained batch 525 in epoch 4, gen_loss = 1.0254130738543015, disc_loss = 0.0005661681225665441
Trained batch 526 in epoch 4, gen_loss = 1.0254088620985709, disc_loss = 0.0005657045056955514
Trained batch 527 in epoch 4, gen_loss = 1.025474003431472, disc_loss = 0.0005652886204023326
Trained batch 528 in epoch 4, gen_loss = 1.0255355973550186, disc_loss = 0.0005649358919297481
Trained batch 529 in epoch 4, gen_loss = 1.025648320508453, disc_loss = 0.000564562817096473
Trained batch 530 in epoch 4, gen_loss = 1.0257789559956998, disc_loss = 0.0005642926580943044
Trained batch 531 in epoch 4, gen_loss = 1.0257153458389126, disc_loss = 0.0005638706283125225
Trained batch 532 in epoch 4, gen_loss = 1.025669025323628, disc_loss = 0.0005631646007685145
Trained batch 533 in epoch 4, gen_loss = 1.025643219773689, disc_loss = 0.0005623224357161357
Trained batch 534 in epoch 4, gen_loss = 1.0256223920349763, disc_loss = 0.0005614858247159119
Trained batch 535 in epoch 4, gen_loss = 1.0258412440098934, disc_loss = 0.0005607797620948769
Trained batch 536 in epoch 4, gen_loss = 1.0257569639154431, disc_loss = 0.0005602674904048315
Trained batch 537 in epoch 4, gen_loss = 1.0257675511464754, disc_loss = 0.000559785337503056
Trained batch 538 in epoch 4, gen_loss = 1.0254505208118063, disc_loss = 0.0005594538584952407
Trained batch 539 in epoch 4, gen_loss = 1.0253056633251685, disc_loss = 0.0005595082074082543
Trained batch 540 in epoch 4, gen_loss = 1.0251911650523682, disc_loss = 0.0005595372944746197
Trained batch 541 in epoch 4, gen_loss = 1.0251751730142924, disc_loss = 0.000559501013110909
Trained batch 542 in epoch 4, gen_loss = 1.025225547686027, disc_loss = 0.0005593412135490585
Trained batch 543 in epoch 4, gen_loss = 1.0251682553002064, disc_loss = 0.0005590308502071232
Trained batch 544 in epoch 4, gen_loss = 1.0250955481048023, disc_loss = 0.0005584787361381507
Trained batch 545 in epoch 4, gen_loss = 1.025041944378025, disc_loss = 0.000557731993507292
Trained batch 546 in epoch 4, gen_loss = 1.0250259875379488, disc_loss = 0.0005569754884175197
Trained batch 547 in epoch 4, gen_loss = 1.0250777606546444, disc_loss = 0.0005561828177626649
Trained batch 548 in epoch 4, gen_loss = 1.025200116829794, disc_loss = 0.0005554327466289762
Trained batch 549 in epoch 4, gen_loss = 1.025198869488456, disc_loss = 0.0005547676130399023
Trained batch 550 in epoch 4, gen_loss = 1.0253761751465702, disc_loss = 0.0005542694619455765
Trained batch 551 in epoch 4, gen_loss = 1.0251983313456825, disc_loss = 0.0005541408380045998
Trained batch 552 in epoch 4, gen_loss = 1.025168321016253, disc_loss = 0.0005543842841144803
Trained batch 553 in epoch 4, gen_loss = 1.0251731941415945, disc_loss = 0.0005547026313229007
Trained batch 554 in epoch 4, gen_loss = 1.0252410390355566, disc_loss = 0.0005548296289398913
Trained batch 555 in epoch 4, gen_loss = 1.0251464255207734, disc_loss = 0.000554593976539109
Trained batch 556 in epoch 4, gen_loss = 1.0252242029462297, disc_loss = 0.0005540851598655256
Trained batch 557 in epoch 4, gen_loss = 1.0253287018627248, disc_loss = 0.0005535177070900754
Trained batch 558 in epoch 4, gen_loss = 1.0254295617608564, disc_loss = 0.0005531489413782658
Trained batch 559 in epoch 4, gen_loss = 1.0253006785043648, disc_loss = 0.0005526547876018282
Trained batch 560 in epoch 4, gen_loss = 1.0251846735277703, disc_loss = 0.0005520425547340158
Trained batch 561 in epoch 4, gen_loss = 1.025096234795886, disc_loss = 0.0005513784625079463
Trained batch 562 in epoch 4, gen_loss = 1.0252471545026316, disc_loss = 0.000550667649823767
Trained batch 563 in epoch 4, gen_loss = 1.0253458165741982, disc_loss = 0.0005499530927396168
Trained batch 564 in epoch 4, gen_loss = 1.025368632784987, disc_loss = 0.0005492522118538947
Trained batch 565 in epoch 4, gen_loss = 1.0253869144529, disc_loss = 0.0005484792008609742
Trained batch 566 in epoch 4, gen_loss = 1.025269001354406, disc_loss = 0.0005477262581094961
Trained batch 567 in epoch 4, gen_loss = 1.0253638546441641, disc_loss = 0.0005471231404338999
Trained batch 568 in epoch 4, gen_loss = 1.025345273198059, disc_loss = 0.000546611914263264
Trained batch 569 in epoch 4, gen_loss = 1.0253814572827857, disc_loss = 0.0005461621876109571
Trained batch 570 in epoch 4, gen_loss = 1.0253320727790927, disc_loss = 0.0005457148386029716
Trained batch 571 in epoch 4, gen_loss = 1.0254928792690063, disc_loss = 0.000545347680192615
Trained batch 572 in epoch 4, gen_loss = 1.025373072108257, disc_loss = 0.0005451199093686878
Trained batch 573 in epoch 4, gen_loss = 1.0254200694868374, disc_loss = 0.0005449047035552668
Trained batch 574 in epoch 4, gen_loss = 1.0254723040953926, disc_loss = 0.0005444968900005535
Trained batch 575 in epoch 4, gen_loss = 1.0254783628301487, disc_loss = 0.0005439378696034206
Trained batch 576 in epoch 4, gen_loss = 1.025547709580724, disc_loss = 0.0005432837162793499
Trained batch 577 in epoch 4, gen_loss = 1.0254299557126516, disc_loss = 0.0005427556270062779
Trained batch 578 in epoch 4, gen_loss = 1.0252132799753046, disc_loss = 0.0005424017233049034
Trained batch 579 in epoch 4, gen_loss = 1.0253992920291835, disc_loss = 0.0005425088173069525
Trained batch 580 in epoch 4, gen_loss = 1.025292204599988, disc_loss = 0.0005427844879362113
Trained batch 581 in epoch 4, gen_loss = 1.025380197566809, disc_loss = 0.0005430843233488119
Trained batch 582 in epoch 4, gen_loss = 1.0253501350433913, disc_loss = 0.000543162658117515
Trained batch 583 in epoch 4, gen_loss = 1.0253111433288822, disc_loss = 0.0005430254811584098
Trained batch 584 in epoch 4, gen_loss = 1.0253621740218921, disc_loss = 0.0005427805151895851
Trained batch 585 in epoch 4, gen_loss = 1.0252723471093097, disc_loss = 0.0005426224663668096
Trained batch 586 in epoch 4, gen_loss = 1.0252947134094303, disc_loss = 0.0005426466756976675
Trained batch 587 in epoch 4, gen_loss = 1.0253138997319604, disc_loss = 0.0005426853822180321
Trained batch 588 in epoch 4, gen_loss = 1.02526889430242, disc_loss = 0.000542626891041875
Trained batch 589 in epoch 4, gen_loss = 1.02534533153146, disc_loss = 0.000542620400295364
Trained batch 590 in epoch 4, gen_loss = 1.025230904319363, disc_loss = 0.000542607560976213
Trained batch 591 in epoch 4, gen_loss = 1.0253384189831245, disc_loss = 0.0005423271602282782
Trained batch 592 in epoch 4, gen_loss = 1.025221623015444, disc_loss = 0.0005418266088304833
Trained batch 593 in epoch 4, gen_loss = 1.0252227064736363, disc_loss = 0.000541306813756084
Trained batch 594 in epoch 4, gen_loss = 1.025288062536416, disc_loss = 0.0005407580434239054
Trained batch 595 in epoch 4, gen_loss = 1.025338359927171, disc_loss = 0.0005401294695443142
Trained batch 596 in epoch 4, gen_loss = 1.0252332457745295, disc_loss = 0.0005394901144879884
Trained batch 597 in epoch 4, gen_loss = 1.0252495485803355, disc_loss = 0.0005388428310540125
Trained batch 598 in epoch 4, gen_loss = 1.025163154271688, disc_loss = 0.0005383457946861225
Trained batch 599 in epoch 4, gen_loss = 1.0252027747035026, disc_loss = 0.0005380127362392765
Trained batch 600 in epoch 4, gen_loss = 1.0251084959844186, disc_loss = 0.0005377428115842579
Trained batch 601 in epoch 4, gen_loss = 1.0251672183754437, disc_loss = 0.0005374666894126631
Trained batch 602 in epoch 4, gen_loss = 1.0251781148697012, disc_loss = 0.0005370464996590355
Trained batch 603 in epoch 4, gen_loss = 1.0251495706916645, disc_loss = 0.0005365229268220642
Trained batch 604 in epoch 4, gen_loss = 1.0251705365732682, disc_loss = 0.0005358853332182654
Trained batch 605 in epoch 4, gen_loss = 1.0253067411015135, disc_loss = 0.0005352592252105745
Trained batch 606 in epoch 4, gen_loss = 1.0253242854231468, disc_loss = 0.000534682025749557
Trained batch 607 in epoch 4, gen_loss = 1.0253090947670371, disc_loss = 0.0005341520118954099
Trained batch 608 in epoch 4, gen_loss = 1.0251774836839322, disc_loss = 0.0005336944076677246
Trained batch 609 in epoch 4, gen_loss = 1.0252330776120795, disc_loss = 0.0005332738113137282
Trained batch 610 in epoch 4, gen_loss = 1.0254185648479555, disc_loss = 0.000532901210518159
Trained batch 611 in epoch 4, gen_loss = 1.0252862993408651, disc_loss = 0.0005323992904629086
Trained batch 612 in epoch 4, gen_loss = 1.0252347996923312, disc_loss = 0.000532016540228216
Trained batch 613 in epoch 4, gen_loss = 1.0252302975336194, disc_loss = 0.0005317193229467735
Trained batch 614 in epoch 4, gen_loss = 1.0252545791912855, disc_loss = 0.0005313141020895096
Trained batch 615 in epoch 4, gen_loss = 1.0253133571573667, disc_loss = 0.0005308075857313967
Trained batch 616 in epoch 4, gen_loss = 1.025272273553635, disc_loss = 0.000530168317724208
Trained batch 617 in epoch 4, gen_loss = 1.0252358159201045, disc_loss = 0.0005295077836782216
Trained batch 618 in epoch 4, gen_loss = 1.0251960837205507, disc_loss = 0.0005288773992754103
Trained batch 619 in epoch 4, gen_loss = 1.0251190444154124, disc_loss = 0.000528370680694934
Trained batch 620 in epoch 4, gen_loss = 1.0250352180522422, disc_loss = 0.0005282381598312024
Trained batch 621 in epoch 4, gen_loss = 1.0251035133550406, disc_loss = 0.000528563684632274
Trained batch 622 in epoch 4, gen_loss = 1.0251198204332905, disc_loss = 0.0005294054033840897
Trained batch 623 in epoch 4, gen_loss = 1.0250179474361432, disc_loss = 0.0005305480515231373
Trained batch 624 in epoch 4, gen_loss = 1.0250617259025574, disc_loss = 0.000531894414452836
Trained batch 625 in epoch 4, gen_loss = 1.0249733424986514, disc_loss = 0.0005329762337288221
Trained batch 626 in epoch 4, gen_loss = 1.024916534408618, disc_loss = 0.000533585373653497
Trained batch 627 in epoch 4, gen_loss = 1.0249498247340987, disc_loss = 0.0005337320479759383
Trained batch 628 in epoch 4, gen_loss = 1.024889219356834, disc_loss = 0.00053361029172981
Trained batch 629 in epoch 4, gen_loss = 1.0250696833171542, disc_loss = 0.0005334343071491088
Trained batch 630 in epoch 4, gen_loss = 1.0251024706427911, disc_loss = 0.0005331524312824584
Trained batch 631 in epoch 4, gen_loss = 1.0249128201151196, disc_loss = 0.000533060459676125
Trained batch 632 in epoch 4, gen_loss = 1.025063870359936, disc_loss = 0.0005331774018127412
Trained batch 633 in epoch 4, gen_loss = 1.0250398525116196, disc_loss = 0.0005332269420394121
Trained batch 634 in epoch 4, gen_loss = 1.0250524140718416, disc_loss = 0.0005332849197012673
Trained batch 635 in epoch 4, gen_loss = 1.0249509977282218, disc_loss = 0.0005333052091750773
Trained batch 636 in epoch 4, gen_loss = 1.024961544262184, disc_loss = 0.0005333568985165306
Trained batch 637 in epoch 4, gen_loss = 1.0249459075516667, disc_loss = 0.0005334149684365051
Trained batch 638 in epoch 4, gen_loss = 1.0249207397581825, disc_loss = 0.0005335256181593915
Trained batch 639 in epoch 4, gen_loss = 1.0248685457743705, disc_loss = 0.000533705588304656
Trained batch 640 in epoch 4, gen_loss = 1.024775767754095, disc_loss = 0.0005338322101999946
Trained batch 641 in epoch 4, gen_loss = 1.0247617732512988, disc_loss = 0.0005340403345441794
Trained batch 642 in epoch 4, gen_loss = 1.0248686969743732, disc_loss = 0.000534265638286723
Trained batch 643 in epoch 4, gen_loss = 1.0248728939650222, disc_loss = 0.0005344363109419059
Trained batch 644 in epoch 4, gen_loss = 1.0248854246250418, disc_loss = 0.0005343588228813957
Trained batch 645 in epoch 4, gen_loss = 1.0248176236824353, disc_loss = 0.0005342523100996396
Trained batch 646 in epoch 4, gen_loss = 1.0248622777288812, disc_loss = 0.0005342564187509223
Trained batch 647 in epoch 4, gen_loss = 1.0251572453129438, disc_loss = 0.0005348169879540859
Trained batch 648 in epoch 4, gen_loss = 1.0252986921367733, disc_loss = 0.0005359318020727732
Trained batch 649 in epoch 4, gen_loss = 1.0253037534310268, disc_loss = 0.0005374753590709028
Trained batch 650 in epoch 4, gen_loss = 1.0252997143660456, disc_loss = 0.0005390896261083148
Trained batch 651 in epoch 4, gen_loss = 1.0252735538899533, disc_loss = 0.0005403096817806649
Trained batch 652 in epoch 4, gen_loss = 1.0253612693016965, disc_loss = 0.0005409186347608795
Trained batch 653 in epoch 4, gen_loss = 1.025246951649313, disc_loss = 0.0005410256792381064
Trained batch 654 in epoch 4, gen_loss = 1.025195353449756, disc_loss = 0.0005409254281042243
Trained batch 655 in epoch 4, gen_loss = 1.0252330384966803, disc_loss = 0.0005406618855464863
Trained batch 656 in epoch 4, gen_loss = 1.0253271437852531, disc_loss = 0.0005402976949663784
Trained batch 657 in epoch 4, gen_loss = 1.025309980096788, disc_loss = 0.0005398170097359869
Trained batch 658 in epoch 4, gen_loss = 1.0252720289418478, disc_loss = 0.0005394864897128853
Trained batch 659 in epoch 4, gen_loss = 1.025342127048608, disc_loss = 0.0005392441327399644
Trained batch 660 in epoch 4, gen_loss = 1.0254811908762322, disc_loss = 0.0005389519452384029
Trained batch 661 in epoch 4, gen_loss = 1.0255180039074485, disc_loss = 0.0005385308908103414
Trained batch 662 in epoch 4, gen_loss = 1.0254220931058915, disc_loss = 0.0005380767118615951
Trained batch 663 in epoch 4, gen_loss = 1.025351640959102, disc_loss = 0.0005375343839604974
Trained batch 664 in epoch 4, gen_loss = 1.0253185705134744, disc_loss = 0.0005369528466345449
Trained batch 665 in epoch 4, gen_loss = 1.0253398643062637, disc_loss = 0.000536427412379789
Trained batch 666 in epoch 4, gen_loss = 1.0253181612116287, disc_loss = 0.0005358203076308934
Trained batch 667 in epoch 4, gen_loss = 1.025372517590751, disc_loss = 0.0005352356196682646
Trained batch 668 in epoch 4, gen_loss = 1.0254160505239205, disc_loss = 0.0005347378449857315
Trained batch 669 in epoch 4, gen_loss = 1.0254309868634637, disc_loss = 0.0005342473275959491
Trained batch 670 in epoch 4, gen_loss = 1.0253903616203104, disc_loss = 0.0005338930439178994
Trained batch 671 in epoch 4, gen_loss = 1.025463779678657, disc_loss = 0.0005336225838705321
Trained batch 672 in epoch 4, gen_loss = 1.0254624129935856, disc_loss = 0.0005333509824977687
Trained batch 673 in epoch 4, gen_loss = 1.025425850726023, disc_loss = 0.0005330758100895084
Trained batch 674 in epoch 4, gen_loss = 1.0255923160800227, disc_loss = 0.0005328696134448465
Trained batch 675 in epoch 4, gen_loss = 1.0256285812904145, disc_loss = 0.0005326669442070615
Trained batch 676 in epoch 4, gen_loss = 1.025609239253547, disc_loss = 0.0005323360743296183
Trained batch 677 in epoch 4, gen_loss = 1.0257281918617125, disc_loss = 0.0005320585325513458
Trained batch 678 in epoch 4, gen_loss = 1.025796276567962, disc_loss = 0.0005317520938209493
Trained batch 679 in epoch 4, gen_loss = 1.0258620922179784, disc_loss = 0.000531421657797182
Trained batch 680 in epoch 4, gen_loss = 1.0257439405907618, disc_loss = 0.0005310932677338329
Trained batch 681 in epoch 4, gen_loss = 1.0257789809857645, disc_loss = 0.0005308638264604672
Trained batch 682 in epoch 4, gen_loss = 1.0257818226758417, disc_loss = 0.0005305959635324187
Trained batch 683 in epoch 4, gen_loss = 1.0257977622817134, disc_loss = 0.00053017612835423
Trained batch 684 in epoch 4, gen_loss = 1.0258777138960622, disc_loss = 0.000529641304594247
Trained batch 685 in epoch 4, gen_loss = 1.0258967713955192, disc_loss = 0.0005290852889950447
Trained batch 686 in epoch 4, gen_loss = 1.0259144943874476, disc_loss = 0.0005287255101497969
Trained batch 687 in epoch 4, gen_loss = 1.025955416002246, disc_loss = 0.0005284388822093566
Trained batch 688 in epoch 4, gen_loss = 1.0259522425419014, disc_loss = 0.000528024518398564
Trained batch 689 in epoch 4, gen_loss = 1.0260233289089755, disc_loss = 0.0005276952650224236
Trained batch 690 in epoch 4, gen_loss = 1.0259646658614472, disc_loss = 0.0005276292269045686
Trained batch 691 in epoch 4, gen_loss = 1.0259630356220841, disc_loss = 0.0005278880296806964
Trained batch 692 in epoch 4, gen_loss = 1.0259621280956406, disc_loss = 0.0005281753823153397
Trained batch 693 in epoch 4, gen_loss = 1.0260138855200336, disc_loss = 0.0005284988106691724
Trained batch 694 in epoch 4, gen_loss = 1.0260990923257183, disc_loss = 0.0005288007407216356
Trained batch 695 in epoch 4, gen_loss = 1.026099770747382, disc_loss = 0.0005290740272326291
Trained batch 696 in epoch 4, gen_loss = 1.0260009092614162, disc_loss = 0.0005291721427526226
Trained batch 697 in epoch 4, gen_loss = 1.0260843797706942, disc_loss = 0.0005292237075527711
Trained batch 698 in epoch 4, gen_loss = 1.0260696050435176, disc_loss = 0.0005292427934979679
Trained batch 699 in epoch 4, gen_loss = 1.0259791697774614, disc_loss = 0.000529158266248747
Trained batch 700 in epoch 4, gen_loss = 1.0260206313003997, disc_loss = 0.0005290129976724069
Trained batch 701 in epoch 4, gen_loss = 1.0261318386450113, disc_loss = 0.0005289580408432998
Trained batch 702 in epoch 4, gen_loss = 1.0261660431052, disc_loss = 0.0005289950682892588
Trained batch 703 in epoch 4, gen_loss = 1.026301667263562, disc_loss = 0.000529081159150089
Trained batch 704 in epoch 4, gen_loss = 1.0261888454991874, disc_loss = 0.0005290169032506896
Trained batch 705 in epoch 4, gen_loss = 1.0262713501541203, disc_loss = 0.0005289496176933181
Trained batch 706 in epoch 4, gen_loss = 1.0262158808984716, disc_loss = 0.0005290154101140336
Trained batch 707 in epoch 4, gen_loss = 1.0261484076411038, disc_loss = 0.0005291269812478071
Trained batch 708 in epoch 4, gen_loss = 1.026188982726825, disc_loss = 0.0005290974378370718
Trained batch 709 in epoch 4, gen_loss = 1.026209541441689, disc_loss = 0.0005289144759700948
Trained batch 710 in epoch 4, gen_loss = 1.0261903295369423, disc_loss = 0.0005286812348841099
Trained batch 711 in epoch 4, gen_loss = 1.0262500370821257, disc_loss = 0.0005285349276838654
Trained batch 712 in epoch 4, gen_loss = 1.0262632602394715, disc_loss = 0.0005282356685540491
Trained batch 713 in epoch 4, gen_loss = 1.0262728502102594, disc_loss = 0.0005278709641596139
Trained batch 714 in epoch 4, gen_loss = 1.0262284594815927, disc_loss = 0.0005274595928637285
Trained batch 715 in epoch 4, gen_loss = 1.0260442853306926, disc_loss = 0.0005269983937866614
Trained batch 716 in epoch 4, gen_loss = 1.0261291320353871, disc_loss = 0.000526585955289842
Trained batch 717 in epoch 4, gen_loss = 1.0260979943288735, disc_loss = 0.0005260615090013956
Trained batch 718 in epoch 4, gen_loss = 1.0260351587900367, disc_loss = 0.0005255402244524823
Trained batch 719 in epoch 4, gen_loss = 1.0260050035185284, disc_loss = 0.0005250309079403653
Trained batch 720 in epoch 4, gen_loss = 1.025979334537596, disc_loss = 0.0005247072367082853
Trained batch 721 in epoch 4, gen_loss = 1.0259220207166804, disc_loss = 0.00052475898882627
Trained batch 722 in epoch 4, gen_loss = 1.0260393250202902, disc_loss = 0.000525004808490846
Trained batch 723 in epoch 4, gen_loss = 1.0261001609965583, disc_loss = 0.0005248750454102365
Trained batch 724 in epoch 4, gen_loss = 1.0259818466778459, disc_loss = 0.0005245878587171821
Trained batch 725 in epoch 4, gen_loss = 1.0260199034181179, disc_loss = 0.0005243446830417653
Trained batch 726 in epoch 4, gen_loss = 1.0260252978811566, disc_loss = 0.0005241033021521407
Trained batch 727 in epoch 4, gen_loss = 1.0259451340515535, disc_loss = 0.0005237812316348996
Trained batch 728 in epoch 4, gen_loss = 1.0259402540649079, disc_loss = 0.0005233476890162571
Trained batch 729 in epoch 4, gen_loss = 1.026000406807416, disc_loss = 0.0005229805517034311
Trained batch 730 in epoch 4, gen_loss = 1.0258873494803171, disc_loss = 0.0005228559640607262
Trained batch 731 in epoch 4, gen_loss = 1.0259898354609807, disc_loss = 0.0005228000918975484
Trained batch 732 in epoch 4, gen_loss = 1.025913204941873, disc_loss = 0.0005228715571522456
Trained batch 733 in epoch 4, gen_loss = 1.0258358800606118, disc_loss = 0.0005231428601294032
Trained batch 734 in epoch 4, gen_loss = 1.025829288018804, disc_loss = 0.0005236635290103692
Trained batch 735 in epoch 4, gen_loss = 1.0258882317044165, disc_loss = 0.0005240909019211476
Trained batch 736 in epoch 4, gen_loss = 1.0259531217967153, disc_loss = 0.0005241789811584919
Trained batch 737 in epoch 4, gen_loss = 1.0258002887734876, disc_loss = 0.0005242373152258351
Trained batch 738 in epoch 4, gen_loss = 1.0257378843221032, disc_loss = 0.0005243804516843854
Trained batch 739 in epoch 4, gen_loss = 1.0257866033831158, disc_loss = 0.0005244747183963694
Trained batch 740 in epoch 4, gen_loss = 1.0257152176579, disc_loss = 0.0005243969635619102
Trained batch 741 in epoch 4, gen_loss = 1.025659439698705, disc_loss = 0.0005241126165312032
Trained batch 742 in epoch 4, gen_loss = 1.0255615518680332, disc_loss = 0.0005236681964814671
Trained batch 743 in epoch 4, gen_loss = 1.025487809411941, disc_loss = 0.0005231978023314901
Trained batch 744 in epoch 4, gen_loss = 1.0254432724626272, disc_loss = 0.0005227288690273768
Trained batch 745 in epoch 4, gen_loss = 1.0254542725335496, disc_loss = 0.0005223429542963065
Trained batch 746 in epoch 4, gen_loss = 1.025349492289455, disc_loss = 0.0005219928453360974
Trained batch 747 in epoch 4, gen_loss = 1.0252787250089135, disc_loss = 0.0005216933454587348
Trained batch 748 in epoch 4, gen_loss = 1.0252206760032154, disc_loss = 0.0005214683540869201
Trained batch 749 in epoch 4, gen_loss = 1.0252213857968648, disc_loss = 0.0005212502907573556
Trained batch 750 in epoch 4, gen_loss = 1.0251880353998726, disc_loss = 0.0005210015760252894
Trained batch 751 in epoch 4, gen_loss = 1.0251616875224925, disc_loss = 0.0005207143557469108
Trained batch 752 in epoch 4, gen_loss = 1.025073123405654, disc_loss = 0.000520430789434241
Trained batch 753 in epoch 4, gen_loss = 1.025080649305718, disc_loss = 0.0005202490911418844
Trained batch 754 in epoch 4, gen_loss = 1.0251432785924697, disc_loss = 0.0005200768921937522
Trained batch 755 in epoch 4, gen_loss = 1.0252487313337426, disc_loss = 0.000519989988158048
Trained batch 756 in epoch 4, gen_loss = 1.0253318150575756, disc_loss = 0.0005201778318942125
Trained batch 757 in epoch 4, gen_loss = 1.025378126818146, disc_loss = 0.0005204513984471854
Trained batch 758 in epoch 4, gen_loss = 1.0252820744973083, disc_loss = 0.0005205986229580127
Trained batch 759 in epoch 4, gen_loss = 1.025293408255828, disc_loss = 0.0005206860013698277
Trained batch 760 in epoch 4, gen_loss = 1.0253069895795703, disc_loss = 0.0005207389918811933
Trained batch 761 in epoch 4, gen_loss = 1.0253187974919797, disc_loss = 0.0005207697083572234
Trained batch 762 in epoch 4, gen_loss = 1.0254701766555305, disc_loss = 0.0005207426166607416
Trained batch 763 in epoch 4, gen_loss = 1.0254950375145018, disc_loss = 0.0005205989769505732
Trained batch 764 in epoch 4, gen_loss = 1.0255229745815002, disc_loss = 0.0005203285259483808
Trained batch 765 in epoch 4, gen_loss = 1.0254960889604634, disc_loss = 0.0005199213288415907
Trained batch 766 in epoch 4, gen_loss = 1.0255521602705218, disc_loss = 0.0005194161370647962
Trained batch 767 in epoch 4, gen_loss = 1.0255145877599716, disc_loss = 0.0005189232207574909
Trained batch 768 in epoch 4, gen_loss = 1.0255118693734953, disc_loss = 0.0005184138920641067
Trained batch 769 in epoch 4, gen_loss = 1.0255041314409925, disc_loss = 0.0005178917513656817
Trained batch 770 in epoch 4, gen_loss = 1.0254874088730175, disc_loss = 0.0005173593606732196
Trained batch 771 in epoch 4, gen_loss = 1.0255065964911267, disc_loss = 0.0005168441350810372
Trained batch 772 in epoch 4, gen_loss = 1.025461173150086, disc_loss = 0.0005163034948431205
Trained batch 773 in epoch 4, gen_loss = 1.0253867427662053, disc_loss = 0.0005157476577718137
Trained batch 774 in epoch 4, gen_loss = 1.0253955337309069, disc_loss = 0.0005152730495319702
Trained batch 775 in epoch 4, gen_loss = 1.0253242695147229, disc_loss = 0.0005148248365847243
Trained batch 776 in epoch 4, gen_loss = 1.0252808175185166, disc_loss = 0.0005143742784740135
Trained batch 777 in epoch 4, gen_loss = 1.0252739931899661, disc_loss = 0.0005138629048745205
Trained batch 778 in epoch 4, gen_loss = 1.025301573288762, disc_loss = 0.0005134044850435806
Trained batch 779 in epoch 4, gen_loss = 1.025253841892267, disc_loss = 0.0005129949834670884
Trained batch 780 in epoch 4, gen_loss = 1.0251468313946157, disc_loss = 0.0005126381138103827
Trained batch 781 in epoch 4, gen_loss = 1.025148234937502, disc_loss = 0.0005124646872307336
Trained batch 782 in epoch 4, gen_loss = 1.0251647784335403, disc_loss = 0.0005123843187099028
Trained batch 783 in epoch 4, gen_loss = 1.0250922533474407, disc_loss = 0.0005122735208306968
Trained batch 784 in epoch 4, gen_loss = 1.0251433430963262, disc_loss = 0.0005119596422052272
Trained batch 785 in epoch 4, gen_loss = 1.0251909067460903, disc_loss = 0.0005114889297607407
Trained batch 786 in epoch 4, gen_loss = 1.025086616848748, disc_loss = 0.0005110371417995824
Trained batch 787 in epoch 4, gen_loss = 1.0250841599279248, disc_loss = 0.0005107273843216527
Trained batch 788 in epoch 4, gen_loss = 1.0251119093749912, disc_loss = 0.0005104936190613183
Trained batch 789 in epoch 4, gen_loss = 1.0252732540233225, disc_loss = 0.0005103708515083712
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.040930151939392, disc_loss = 0.0004163927223999053
Trained batch 1 in epoch 5, gen_loss = 1.0417961478233337, disc_loss = 0.00040571053978055716
Trained batch 2 in epoch 5, gen_loss = 1.068610707918803, disc_loss = 0.00039275123466116685
Trained batch 3 in epoch 5, gen_loss = 1.0498123317956924, disc_loss = 0.00037177977355895564
Trained batch 4 in epoch 5, gen_loss = 1.0420374512672423, disc_loss = 0.0003586104954592884
Trained batch 5 in epoch 5, gen_loss = 1.026537925004959, disc_loss = 0.000384198414394632
Trained batch 6 in epoch 5, gen_loss = 1.0269771388598852, disc_loss = 0.00044768417553443996
Trained batch 7 in epoch 5, gen_loss = 1.0248074904084206, disc_loss = 0.0005374548272811808
Trained batch 8 in epoch 5, gen_loss = 1.03487542602751, disc_loss = 0.0006429600438827442
Trained batch 9 in epoch 5, gen_loss = 1.045427030324936, disc_loss = 0.0007574139686767012
Trained batch 10 in epoch 5, gen_loss = 1.0414080565625972, disc_loss = 0.0008891042459502139
Trained batch 11 in epoch 5, gen_loss = 1.038028284907341, disc_loss = 0.0010331131876834359
Trained batch 12 in epoch 5, gen_loss = 1.0419143942686229, disc_loss = 0.0011696005284857864
Trained batch 13 in epoch 5, gen_loss = 1.0385131750788008, disc_loss = 0.0013194580470943557
Trained batch 14 in epoch 5, gen_loss = 1.0344691356023152, disc_loss = 0.0014233704074285924
Trained batch 15 in epoch 5, gen_loss = 1.033334843814373, disc_loss = 0.0014921241854608525
Trained batch 16 in epoch 5, gen_loss = 1.0349144865484798, disc_loss = 0.0015308723737047438
Trained batch 17 in epoch 5, gen_loss = 1.0371985634167988, disc_loss = 0.001524562808400434
Trained batch 18 in epoch 5, gen_loss = 1.0385697138936896, disc_loss = 0.0014826421331810323
Trained batch 19 in epoch 5, gen_loss = 1.0361376345157622, disc_loss = 0.0014257647300837562
Trained batch 20 in epoch 5, gen_loss = 1.0367731083007086, disc_loss = 0.0013716835279150733
Trained batch 21 in epoch 5, gen_loss = 1.03588529066606, disc_loss = 0.0013216862148097293
Trained batch 22 in epoch 5, gen_loss = 1.0330051028210183, disc_loss = 0.0012750915813502734
Trained batch 23 in epoch 5, gen_loss = 1.0293299729625385, disc_loss = 0.001228676952450769
Trained batch 24 in epoch 5, gen_loss = 1.0290158295631409, disc_loss = 0.0011840956879314035
Trained batch 25 in epoch 5, gen_loss = 1.0278989397562468, disc_loss = 0.001144327795862829
Trained batch 26 in epoch 5, gen_loss = 1.0280629396438599, disc_loss = 0.0011069785692530718
Trained batch 27 in epoch 5, gen_loss = 1.026600895183427, disc_loss = 0.0010742484763406018
Trained batch 28 in epoch 5, gen_loss = 1.0236966589401508, disc_loss = 0.0010477962149989567
Trained batch 29 in epoch 5, gen_loss = 1.0237758378187816, disc_loss = 0.001024432646712133
Trained batch 30 in epoch 5, gen_loss = 1.0247273156719823, disc_loss = 0.0010049565767516352
Trained batch 31 in epoch 5, gen_loss = 1.0241079274564981, disc_loss = 0.0009899121528178512
Trained batch 32 in epoch 5, gen_loss = 1.0261121103257844, disc_loss = 0.0009782955065461326
Trained batch 33 in epoch 5, gen_loss = 1.0272650876465965, disc_loss = 0.0009678819560041815
Trained batch 34 in epoch 5, gen_loss = 1.0256660410336085, disc_loss = 0.0009537606279731595
Trained batch 35 in epoch 5, gen_loss = 1.0228809267282486, disc_loss = 0.000937705679664052
Trained batch 36 in epoch 5, gen_loss = 1.0205799598951597, disc_loss = 0.0009248706530244719
Trained batch 37 in epoch 5, gen_loss = 1.0195228692732359, disc_loss = 0.000912869743172594
Trained batch 38 in epoch 5, gen_loss = 1.020443978982094, disc_loss = 0.0008999728564119253
Trained batch 39 in epoch 5, gen_loss = 1.0215723648667336, disc_loss = 0.0008860039783030515
Trained batch 40 in epoch 5, gen_loss = 1.0220539002883724, disc_loss = 0.0008728437749640561
Trained batch 41 in epoch 5, gen_loss = 1.0223428365730105, disc_loss = 0.0008630265930107617
Trained batch 42 in epoch 5, gen_loss = 1.0224751331085382, disc_loss = 0.0008579084556955888
Trained batch 43 in epoch 5, gen_loss = 1.024244794791395, disc_loss = 0.0008571485149414829
Trained batch 44 in epoch 5, gen_loss = 1.0265952679846022, disc_loss = 0.0008610507159674954
Trained batch 45 in epoch 5, gen_loss = 1.0259811528350995, disc_loss = 0.0008639831057339704
Trained batch 46 in epoch 5, gen_loss = 1.0244992337328322, disc_loss = 0.000863046012261506
Trained batch 47 in epoch 5, gen_loss = 1.022000835587581, disc_loss = 0.0008640443105226344
Trained batch 48 in epoch 5, gen_loss = 1.0231705599901628, disc_loss = 0.0008755423712463365
Trained batch 49 in epoch 5, gen_loss = 1.024001921415329, disc_loss = 0.0008918220209307037
Trained batch 50 in epoch 5, gen_loss = 1.0241183147710913, disc_loss = 0.0009039312349426944
Trained batch 51 in epoch 5, gen_loss = 1.0238986416504934, disc_loss = 0.0009069124965977748
Trained batch 52 in epoch 5, gen_loss = 1.0240919038934528, disc_loss = 0.000902255729910531
Trained batch 53 in epoch 5, gen_loss = 1.0253021750185225, disc_loss = 0.0008946020655760852
Trained batch 54 in epoch 5, gen_loss = 1.0249683846126902, disc_loss = 0.0008838795429751784
Trained batch 55 in epoch 5, gen_loss = 1.0254063680768013, disc_loss = 0.0008718553290236741
Trained batch 56 in epoch 5, gen_loss = 1.02460515499115, disc_loss = 0.0008605547962105719
Trained batch 57 in epoch 5, gen_loss = 1.0255099781628312, disc_loss = 0.0008501948177581653
Trained batch 58 in epoch 5, gen_loss = 1.0255463588035714, disc_loss = 0.0008387072988533241
Trained batch 59 in epoch 5, gen_loss = 1.0238308270772298, disc_loss = 0.0008270731821539811
Trained batch 60 in epoch 5, gen_loss = 1.023146990869866, disc_loss = 0.0008164308626456645
Trained batch 61 in epoch 5, gen_loss = 1.0218147039413452, disc_loss = 0.0008067857941627622
Trained batch 62 in epoch 5, gen_loss = 1.0227373024773976, disc_loss = 0.0008009853486400393
Trained batch 63 in epoch 5, gen_loss = 1.0215590987354517, disc_loss = 0.0007982759725564392
Trained batch 64 in epoch 5, gen_loss = 1.023490362900954, disc_loss = 0.00079570466455502
Trained batch 65 in epoch 5, gen_loss = 1.0233610850391965, disc_loss = 0.0007949670420423375
Trained batch 66 in epoch 5, gen_loss = 1.0237167931314726, disc_loss = 0.0007933253142635212
Trained batch 67 in epoch 5, gen_loss = 1.0248425234766567, disc_loss = 0.0007903288222972632
Trained batch 68 in epoch 5, gen_loss = 1.0243524658507195, disc_loss = 0.0007863306487653998
Trained batch 69 in epoch 5, gen_loss = 1.0238880446978977, disc_loss = 0.0007822152343578637
Trained batch 70 in epoch 5, gen_loss = 1.025011742618722, disc_loss = 0.0007765308460286281
Trained batch 71 in epoch 5, gen_loss = 1.0250731822517183, disc_loss = 0.0007712937080618253
Trained batch 72 in epoch 5, gen_loss = 1.024554473080047, disc_loss = 0.0007651649636363177
Trained batch 73 in epoch 5, gen_loss = 1.0259257216711302, disc_loss = 0.0007588176026852248
Trained batch 74 in epoch 5, gen_loss = 1.0267168474197388, disc_loss = 0.0007524301736460378
Trained batch 75 in epoch 5, gen_loss = 1.0257786449633146, disc_loss = 0.0007451179737568294
Trained batch 76 in epoch 5, gen_loss = 1.0254670598290183, disc_loss = 0.0007369261996233957
Trained batch 77 in epoch 5, gen_loss = 1.024736470136887, disc_loss = 0.0007288719495521106
Trained batch 78 in epoch 5, gen_loss = 1.0245888278454165, disc_loss = 0.0007215103671828556
Trained batch 79 in epoch 5, gen_loss = 1.0243564561009406, disc_loss = 0.0007140373766560514
Trained batch 80 in epoch 5, gen_loss = 1.023996493698638, disc_loss = 0.0007061345333321147
Trained batch 81 in epoch 5, gen_loss = 1.0242232454986107, disc_loss = 0.000698952374766189
Trained batch 82 in epoch 5, gen_loss = 1.024372424705919, disc_loss = 0.0006944852117946966
Trained batch 83 in epoch 5, gen_loss = 1.0259778123526346, disc_loss = 0.0006934868713523471
Trained batch 84 in epoch 5, gen_loss = 1.0265549961258382, disc_loss = 0.0006918171950554311
Trained batch 85 in epoch 5, gen_loss = 1.027059429606726, disc_loss = 0.0006889966467962611
Trained batch 86 in epoch 5, gen_loss = 1.0268882739132847, disc_loss = 0.0006868477455633372
Trained batch 87 in epoch 5, gen_loss = 1.0275633910840207, disc_loss = 0.0006852354380581263
Trained batch 88 in epoch 5, gen_loss = 1.0264142142252977, disc_loss = 0.0006838624990706102
Trained batch 89 in epoch 5, gen_loss = 1.0270515700181326, disc_loss = 0.0006826097911269041
Trained batch 90 in epoch 5, gen_loss = 1.0282792226298825, disc_loss = 0.0006799882838015117
Trained batch 91 in epoch 5, gen_loss = 1.028089284248974, disc_loss = 0.0006774149675513162
Trained batch 92 in epoch 5, gen_loss = 1.0280102010696166, disc_loss = 0.0006753401388758443
Trained batch 93 in epoch 5, gen_loss = 1.0273201611447842, disc_loss = 0.000673248851408642
Trained batch 94 in epoch 5, gen_loss = 1.0269546697014256, disc_loss = 0.0006709486953025733
Trained batch 95 in epoch 5, gen_loss = 1.0264814049005508, disc_loss = 0.0006674144302299586
Trained batch 96 in epoch 5, gen_loss = 1.0268404176554728, disc_loss = 0.00066272616252896
Trained batch 97 in epoch 5, gen_loss = 1.0269193722277272, disc_loss = 0.0006579709823904987
Trained batch 98 in epoch 5, gen_loss = 1.026830873104057, disc_loss = 0.0006533865482491122
Trained batch 99 in epoch 5, gen_loss = 1.026800479888916, disc_loss = 0.0006496484316448913
Trained batch 100 in epoch 5, gen_loss = 1.0274417955096404, disc_loss = 0.0006462382738355151
Trained batch 101 in epoch 5, gen_loss = 1.02706263813318, disc_loss = 0.0006425485315797714
Trained batch 102 in epoch 5, gen_loss = 1.0276050961133345, disc_loss = 0.0006376275665141434
Trained batch 103 in epoch 5, gen_loss = 1.027220062338389, disc_loss = 0.0006328483842970365
Trained batch 104 in epoch 5, gen_loss = 1.026849407241458, disc_loss = 0.0006285461726725944
Trained batch 105 in epoch 5, gen_loss = 1.026447446278806, disc_loss = 0.0006246323061515006
Trained batch 106 in epoch 5, gen_loss = 1.0266962469181167, disc_loss = 0.0006204572558336647
Trained batch 107 in epoch 5, gen_loss = 1.026492698876946, disc_loss = 0.0006157904954980714
Trained batch 108 in epoch 5, gen_loss = 1.025851525844784, disc_loss = 0.0006111973609989979
Trained batch 109 in epoch 5, gen_loss = 1.0251672034913843, disc_loss = 0.0006067696993837176
Trained batch 110 in epoch 5, gen_loss = 1.0246187743839916, disc_loss = 0.0006026950318587584
Trained batch 111 in epoch 5, gen_loss = 1.02473066800407, disc_loss = 0.0005987329805715749
Trained batch 112 in epoch 5, gen_loss = 1.0245577017817877, disc_loss = 0.0005947676574449731
Trained batch 113 in epoch 5, gen_loss = 1.0248712463337077, disc_loss = 0.0005907249689156295
Trained batch 114 in epoch 5, gen_loss = 1.0251802770987801, disc_loss = 0.00058674576405041
Trained batch 115 in epoch 5, gen_loss = 1.0261379886290123, disc_loss = 0.0005827556660419916
Trained batch 116 in epoch 5, gen_loss = 1.026394945434016, disc_loss = 0.0005788774586916487
Trained batch 117 in epoch 5, gen_loss = 1.0259997364828142, disc_loss = 0.0005752702868988508
Trained batch 118 in epoch 5, gen_loss = 1.0259225093016104, disc_loss = 0.000572108660133442
Trained batch 119 in epoch 5, gen_loss = 1.026564608514309, disc_loss = 0.0005698309837195363
Trained batch 120 in epoch 5, gen_loss = 1.0259739889586268, disc_loss = 0.0005689410755313618
Trained batch 121 in epoch 5, gen_loss = 1.0256538435083922, disc_loss = 0.0005682031974100057
Trained batch 122 in epoch 5, gen_loss = 1.0260080385014294, disc_loss = 0.0005670239250587368
Trained batch 123 in epoch 5, gen_loss = 1.024993176902494, disc_loss = 0.0005651970577380252
Trained batch 124 in epoch 5, gen_loss = 1.0244637322425842, disc_loss = 0.0005626883324584924
Trained batch 125 in epoch 5, gen_loss = 1.0247587556876834, disc_loss = 0.0005606916214645257
Trained batch 126 in epoch 5, gen_loss = 1.025097758281888, disc_loss = 0.000558700085437479
Trained batch 127 in epoch 5, gen_loss = 1.025216328445822, disc_loss = 0.0005563397346008969
Trained batch 128 in epoch 5, gen_loss = 1.0251321824946145, disc_loss = 0.0005536779378113957
Trained batch 129 in epoch 5, gen_loss = 1.024734321465859, disc_loss = 0.0005507884477153241
Trained batch 130 in epoch 5, gen_loss = 1.0246527581724503, disc_loss = 0.0005482724166936454
Trained batch 131 in epoch 5, gen_loss = 1.024005474466266, disc_loss = 0.0005456054486509829
Trained batch 132 in epoch 5, gen_loss = 1.0235308121917839, disc_loss = 0.0005430049838780958
Trained batch 133 in epoch 5, gen_loss = 1.0229346574242435, disc_loss = 0.0005404431185117791
Trained batch 134 in epoch 5, gen_loss = 1.0228094074461196, disc_loss = 0.0005374771891554162
Trained batch 135 in epoch 5, gen_loss = 1.0219869135933763, disc_loss = 0.0005343706353040248
Trained batch 136 in epoch 5, gen_loss = 1.0220939273381755, disc_loss = 0.0005315840115768998
Trained batch 137 in epoch 5, gen_loss = 1.022294133901596, disc_loss = 0.0005290402772041726
Trained batch 138 in epoch 5, gen_loss = 1.0235279151003995, disc_loss = 0.0005278085248935097
Trained batch 139 in epoch 5, gen_loss = 1.0231938196080073, disc_loss = 0.000527398402066735
Trained batch 140 in epoch 5, gen_loss = 1.0223583443790463, disc_loss = 0.0005276676956588957
Trained batch 141 in epoch 5, gen_loss = 1.0219563493426418, disc_loss = 0.0005296269384775193
Trained batch 142 in epoch 5, gen_loss = 1.0223846831521788, disc_loss = 0.0005321349366364506
Trained batch 143 in epoch 5, gen_loss = 1.0219157325724761, disc_loss = 0.0005362120192431677
Trained batch 144 in epoch 5, gen_loss = 1.0222087206511663, disc_loss = 0.0005430000696676494
Trained batch 145 in epoch 5, gen_loss = 1.022491111739041, disc_loss = 0.0005534885694194674
Trained batch 146 in epoch 5, gen_loss = 1.022303513118199, disc_loss = 0.0005629691484401662
Trained batch 147 in epoch 5, gen_loss = 1.022955395885416, disc_loss = 0.0005688087548077345
Trained batch 148 in epoch 5, gen_loss = 1.0224648614057759, disc_loss = 0.0005715047223173119
Trained batch 149 in epoch 5, gen_loss = 1.0226550614833831, disc_loss = 0.0005751812670496293
Trained batch 150 in epoch 5, gen_loss = 1.0229332498367258, disc_loss = 0.0005796899372790416
Trained batch 151 in epoch 5, gen_loss = 1.0235893557730473, disc_loss = 0.0005835376982998385
Trained batch 152 in epoch 5, gen_loss = 1.023348853089451, disc_loss = 0.00058736527835862
Trained batch 153 in epoch 5, gen_loss = 1.0230901756069877, disc_loss = 0.0005903754101925553
Trained batch 154 in epoch 5, gen_loss = 1.0233089881558572, disc_loss = 0.0005916965057915678
Trained batch 155 in epoch 5, gen_loss = 1.0233308661442537, disc_loss = 0.0005912529005189964
Trained batch 156 in epoch 5, gen_loss = 1.0235836904519682, disc_loss = 0.0005897408239891942
Trained batch 157 in epoch 5, gen_loss = 1.024014021399655, disc_loss = 0.000587758056018531
Trained batch 158 in epoch 5, gen_loss = 1.0235987106959026, disc_loss = 0.0005853882886992135
Trained batch 159 in epoch 5, gen_loss = 1.023949671536684, disc_loss = 0.0005828207598824519
Trained batch 160 in epoch 5, gen_loss = 1.024167585817183, disc_loss = 0.0005803436793962505
Trained batch 161 in epoch 5, gen_loss = 1.0243540626985055, disc_loss = 0.0005781184720237636
Trained batch 162 in epoch 5, gen_loss = 1.0240462506475625, disc_loss = 0.000576515995398838
Trained batch 163 in epoch 5, gen_loss = 1.0239312285330238, disc_loss = 0.0005759546107672178
Trained batch 164 in epoch 5, gen_loss = 1.0237373453198058, disc_loss = 0.0005764171546395642
Trained batch 165 in epoch 5, gen_loss = 1.0236434807260353, disc_loss = 0.0005770905116216717
Trained batch 166 in epoch 5, gen_loss = 1.0236914100761185, disc_loss = 0.0005778239990799259
Trained batch 167 in epoch 5, gen_loss = 1.0235978677159263, disc_loss = 0.0005785792182862116
Trained batch 168 in epoch 5, gen_loss = 1.0231667862841363, disc_loss = 0.0005795903737758722
Trained batch 169 in epoch 5, gen_loss = 1.0228384796310874, disc_loss = 0.00057931459039751
Trained batch 170 in epoch 5, gen_loss = 1.022916993899652, disc_loss = 0.0005778185868355288
Trained batch 171 in epoch 5, gen_loss = 1.0228969544865365, disc_loss = 0.000575811855649294
Trained batch 172 in epoch 5, gen_loss = 1.0232067266640636, disc_loss = 0.0005740278048543098
Trained batch 173 in epoch 5, gen_loss = 1.0228822272399376, disc_loss = 0.0005722122429803163
Trained batch 174 in epoch 5, gen_loss = 1.0232420464924403, disc_loss = 0.0005700339340338749
Trained batch 175 in epoch 5, gen_loss = 1.0234933705492453, disc_loss = 0.0005677917330434535
Trained batch 176 in epoch 5, gen_loss = 1.0232714879310738, disc_loss = 0.0005655252875557622
Trained batch 177 in epoch 5, gen_loss = 1.0242797765838967, disc_loss = 0.000564030869641561
Trained batch 178 in epoch 5, gen_loss = 1.0243525917969603, disc_loss = 0.000563132194229844
Trained batch 179 in epoch 5, gen_loss = 1.0241754906045066, disc_loss = 0.0005626592188491486
Trained batch 180 in epoch 5, gen_loss = 1.0240174729521103, disc_loss = 0.0005622488877141735
Trained batch 181 in epoch 5, gen_loss = 1.0236907231283712, disc_loss = 0.0005611041690297118
Trained batch 182 in epoch 5, gen_loss = 1.023226657526089, disc_loss = 0.0005597700256742334
Trained batch 183 in epoch 5, gen_loss = 1.023046314392401, disc_loss = 0.0005585274032099456
Trained batch 184 in epoch 5, gen_loss = 1.0229036289292412, disc_loss = 0.0005577630173049968
Trained batch 185 in epoch 5, gen_loss = 1.0230469373605584, disc_loss = 0.0005574227692196346
Trained batch 186 in epoch 5, gen_loss = 1.0229219354410222, disc_loss = 0.0005571964882590614
Trained batch 187 in epoch 5, gen_loss = 1.0231142808148201, disc_loss = 0.0005568321606954262
Trained batch 188 in epoch 5, gen_loss = 1.0230329002022112, disc_loss = 0.000556375369554011
Trained batch 189 in epoch 5, gen_loss = 1.0228268883730236, disc_loss = 0.0005556668638937959
Trained batch 190 in epoch 5, gen_loss = 1.0231138177567127, disc_loss = 0.0005543250854173432
Trained batch 191 in epoch 5, gen_loss = 1.0233701855565112, disc_loss = 0.0005526904657623769
Trained batch 192 in epoch 5, gen_loss = 1.0230090290771248, disc_loss = 0.0005513413533582859
Trained batch 193 in epoch 5, gen_loss = 1.0229407850000047, disc_loss = 0.0005500463849250419
Trained batch 194 in epoch 5, gen_loss = 1.0228050983869112, disc_loss = 0.0005486131444251022
Trained batch 195 in epoch 5, gen_loss = 1.022759816476277, disc_loss = 0.000546748898400716
Trained batch 196 in epoch 5, gen_loss = 1.0227513452471815, disc_loss = 0.0005446802555857614
Trained batch 197 in epoch 5, gen_loss = 1.0230470745250433, disc_loss = 0.000542731666152549
Trained batch 198 in epoch 5, gen_loss = 1.0228100128509292, disc_loss = 0.0005411372088444602
Trained batch 199 in epoch 5, gen_loss = 1.0220638990402222, disc_loss = 0.0005399174322519684
Trained batch 200 in epoch 5, gen_loss = 1.0221670504233138, disc_loss = 0.0005384680933917905
Trained batch 201 in epoch 5, gen_loss = 1.0214704363652976, disc_loss = 0.000537563106497533
Trained batch 202 in epoch 5, gen_loss = 1.0211941758400114, disc_loss = 0.0005372334005720593
Trained batch 203 in epoch 5, gen_loss = 1.0214077529369616, disc_loss = 0.0005379574634870925
Trained batch 204 in epoch 5, gen_loss = 1.0214542205740766, disc_loss = 0.0005391631897953453
Trained batch 205 in epoch 5, gen_loss = 1.0214875638484955, disc_loss = 0.0005406579772011576
Trained batch 206 in epoch 5, gen_loss = 1.02121261957187, disc_loss = 0.000541494298877604
Trained batch 207 in epoch 5, gen_loss = 1.021723732065696, disc_loss = 0.0005415687265457774
Trained batch 208 in epoch 5, gen_loss = 1.0216969243076999, disc_loss = 0.000541733097773531
Trained batch 209 in epoch 5, gen_loss = 1.0214687980356671, disc_loss = 0.0005422474437398792
Trained batch 210 in epoch 5, gen_loss = 1.0215916421741107, disc_loss = 0.0005436803910674933
Trained batch 211 in epoch 5, gen_loss = 1.0215405813365612, disc_loss = 0.0005446461613212036
Trained batch 212 in epoch 5, gen_loss = 1.0215135658850691, disc_loss = 0.0005455371124277486
Trained batch 213 in epoch 5, gen_loss = 1.0214560781126825, disc_loss = 0.0005459902415984466
Trained batch 214 in epoch 5, gen_loss = 1.0216406154078106, disc_loss = 0.0005456303869682733
Trained batch 215 in epoch 5, gen_loss = 1.0217670199495774, disc_loss = 0.0005451430046108457
Trained batch 216 in epoch 5, gen_loss = 1.021908251096576, disc_loss = 0.0005456514929207729
Trained batch 217 in epoch 5, gen_loss = 1.0224628057501732, disc_loss = 0.0005473404642276747
Trained batch 218 in epoch 5, gen_loss = 1.0228874762308653, disc_loss = 0.0005497017397027523
Trained batch 219 in epoch 5, gen_loss = 1.02297561629252, disc_loss = 0.0005522770889828363
Trained batch 220 in epoch 5, gen_loss = 1.0226749680700344, disc_loss = 0.0005540656794639035
Trained batch 221 in epoch 5, gen_loss = 1.0229628169321798, disc_loss = 0.0005542747826480123
Trained batch 222 in epoch 5, gen_loss = 1.0228161980218418, disc_loss = 0.0005535133835685235
Trained batch 223 in epoch 5, gen_loss = 1.0224050751754217, disc_loss = 0.0005527243414300236
Trained batch 224 in epoch 5, gen_loss = 1.0225404850641886, disc_loss = 0.0005529249359258554
Trained batch 225 in epoch 5, gen_loss = 1.022666449567913, disc_loss = 0.0005526606751882999
Trained batch 226 in epoch 5, gen_loss = 1.0224867812337328, disc_loss = 0.0005524935884045289
Trained batch 227 in epoch 5, gen_loss = 1.0221844430555378, disc_loss = 0.0005523484783464626
Trained batch 228 in epoch 5, gen_loss = 1.0220968145470433, disc_loss = 0.0005515221569013037
Trained batch 229 in epoch 5, gen_loss = 1.022077084624249, disc_loss = 0.000550278827089958
Trained batch 230 in epoch 5, gen_loss = 1.022015626812394, disc_loss = 0.0005490817922722847
Trained batch 231 in epoch 5, gen_loss = 1.021725104800586, disc_loss = 0.0005477147193420839
Trained batch 232 in epoch 5, gen_loss = 1.021915655790992, disc_loss = 0.0005463742570603834
Trained batch 233 in epoch 5, gen_loss = 1.0214183335630302, disc_loss = 0.0005464084955374113
Trained batch 234 in epoch 5, gen_loss = 1.0215988422961946, disc_loss = 0.0005485504952338624
Trained batch 235 in epoch 5, gen_loss = 1.0218875150559312, disc_loss = 0.0005508298185058096
Trained batch 236 in epoch 5, gen_loss = 1.0218121296242824, disc_loss = 0.0005532406756304644
Trained batch 237 in epoch 5, gen_loss = 1.0216887946389301, disc_loss = 0.000553976561964153
Trained batch 238 in epoch 5, gen_loss = 1.0217238806780413, disc_loss = 0.0005535282284483142
Trained batch 239 in epoch 5, gen_loss = 1.0218125201761723, disc_loss = 0.0005526124738632158
Trained batch 240 in epoch 5, gen_loss = 1.021712578925849, disc_loss = 0.0005516007068495487
Trained batch 241 in epoch 5, gen_loss = 1.0213386103634006, disc_loss = 0.0005507605552744536
Trained batch 242 in epoch 5, gen_loss = 1.0212075496897286, disc_loss = 0.0005505430161686606
Trained batch 243 in epoch 5, gen_loss = 1.0212636269995423, disc_loss = 0.0005508160074747198
Trained batch 244 in epoch 5, gen_loss = 1.021165188721248, disc_loss = 0.0005510137222792802
Trained batch 245 in epoch 5, gen_loss = 1.0212742427015693, disc_loss = 0.0005505281824446321
Trained batch 246 in epoch 5, gen_loss = 1.021521646725504, disc_loss = 0.0005499125812494909
Trained batch 247 in epoch 5, gen_loss = 1.0213886888757828, disc_loss = 0.0005496092119081427
Trained batch 248 in epoch 5, gen_loss = 1.0216938424780666, disc_loss = 0.0005499241713726198
Trained batch 249 in epoch 5, gen_loss = 1.0217394924163818, disc_loss = 0.0005506397220306099
Trained batch 250 in epoch 5, gen_loss = 1.0219321678359194, disc_loss = 0.0005514483035735015
Trained batch 251 in epoch 5, gen_loss = 1.0219993430470664, disc_loss = 0.0005517869211626165
Trained batch 252 in epoch 5, gen_loss = 1.0219623896444268, disc_loss = 0.0005516685771373038
Trained batch 253 in epoch 5, gen_loss = 1.0222330252955278, disc_loss = 0.0005511520134824086
Trained batch 254 in epoch 5, gen_loss = 1.0226010967703427, disc_loss = 0.0005500616574221674
Trained batch 255 in epoch 5, gen_loss = 1.0226706750690937, disc_loss = 0.0005487663898406936
Trained batch 256 in epoch 5, gen_loss = 1.0226079369333467, disc_loss = 0.0005474558951363062
Trained batch 257 in epoch 5, gen_loss = 1.0224344741928486, disc_loss = 0.0005461979739646817
Trained batch 258 in epoch 5, gen_loss = 1.0224829942103058, disc_loss = 0.0005448210850635788
Trained batch 259 in epoch 5, gen_loss = 1.0223418698861049, disc_loss = 0.0005432942104212438
Trained batch 260 in epoch 5, gen_loss = 1.0222848640091118, disc_loss = 0.0005418083238994374
Trained batch 261 in epoch 5, gen_loss = 1.0226983068553546, disc_loss = 0.0005408152376362905
Trained batch 262 in epoch 5, gen_loss = 1.0227454447474316, disc_loss = 0.0005400320335212536
Trained batch 263 in epoch 5, gen_loss = 1.0230178318240426, disc_loss = 0.0005390971482208415
Trained batch 264 in epoch 5, gen_loss = 1.0232900322608227, disc_loss = 0.0005381864759706418
Trained batch 265 in epoch 5, gen_loss = 1.0232584848439783, disc_loss = 0.0005371662479220483
Trained batch 266 in epoch 5, gen_loss = 1.0234548987520768, disc_loss = 0.0005361655377019859
Trained batch 267 in epoch 5, gen_loss = 1.0235253332266168, disc_loss = 0.0005351287893687702
Trained batch 268 in epoch 5, gen_loss = 1.0233482368373517, disc_loss = 0.0005342636168583861
Trained batch 269 in epoch 5, gen_loss = 1.023019035436489, disc_loss = 0.0005334451733721868
Trained batch 270 in epoch 5, gen_loss = 1.0229365181219094, disc_loss = 0.0005326186553459113
Trained batch 271 in epoch 5, gen_loss = 1.0231786403147614, disc_loss = 0.0005318621593045571
Trained batch 272 in epoch 5, gen_loss = 1.0228473017940591, disc_loss = 0.0005309533007675782
Trained batch 273 in epoch 5, gen_loss = 1.0227895265948164, disc_loss = 0.000529782665680149
Trained batch 274 in epoch 5, gen_loss = 1.0227530899914827, disc_loss = 0.0005284236248222772
Trained batch 275 in epoch 5, gen_loss = 1.0223921809507452, disc_loss = 0.000526989441045705
Trained batch 276 in epoch 5, gen_loss = 1.022506861910493, disc_loss = 0.0005256766132402675
Trained batch 277 in epoch 5, gen_loss = 1.0225040814001782, disc_loss = 0.0005244595426735267
Trained batch 278 in epoch 5, gen_loss = 1.0222052775830779, disc_loss = 0.0005233700974054942
Trained batch 279 in epoch 5, gen_loss = 1.0224241759095873, disc_loss = 0.0005222456463733189
Trained batch 280 in epoch 5, gen_loss = 1.0222884463245758, disc_loss = 0.0005209099523018005
Trained batch 281 in epoch 5, gen_loss = 1.022184464948397, disc_loss = 0.0005195448614726279
Trained batch 282 in epoch 5, gen_loss = 1.0220986560460956, disc_loss = 0.0005182794302655878
Trained batch 283 in epoch 5, gen_loss = 1.0221141612445805, disc_loss = 0.0005171345529932706
Trained batch 284 in epoch 5, gen_loss = 1.0222451220478928, disc_loss = 0.0005161259840589769
Trained batch 285 in epoch 5, gen_loss = 1.0223422836173663, disc_loss = 0.0005151648439712809
Trained batch 286 in epoch 5, gen_loss = 1.0225080760513865, disc_loss = 0.0005143828072888576
Trained batch 287 in epoch 5, gen_loss = 1.0224137655976746, disc_loss = 0.0005136812577701574
Trained batch 288 in epoch 5, gen_loss = 1.022336993044223, disc_loss = 0.0005129223201419049
Trained batch 289 in epoch 5, gen_loss = 1.0222180759084636, disc_loss = 0.0005119073578028073
Trained batch 290 in epoch 5, gen_loss = 1.022307896327317, disc_loss = 0.0005107555283182316
Trained batch 291 in epoch 5, gen_loss = 1.0225312083143077, disc_loss = 0.0005096585112257082
Trained batch 292 in epoch 5, gen_loss = 1.0226063388606388, disc_loss = 0.0005087064974067205
Trained batch 293 in epoch 5, gen_loss = 1.0229065923058256, disc_loss = 0.0005081289077215657
Trained batch 294 in epoch 5, gen_loss = 1.0229350233482102, disc_loss = 0.0005077145966085589
Trained batch 295 in epoch 5, gen_loss = 1.0226531564383894, disc_loss = 0.0005074813545090021
Trained batch 296 in epoch 5, gen_loss = 1.0226865031502463, disc_loss = 0.0005073568339597572
Trained batch 297 in epoch 5, gen_loss = 1.0226830600092076, disc_loss = 0.0005073808772323791
Trained batch 298 in epoch 5, gen_loss = 1.0227169304787116, disc_loss = 0.0005076144001194366
Trained batch 299 in epoch 5, gen_loss = 1.0225075507164, disc_loss = 0.0005078286968637258
Trained batch 300 in epoch 5, gen_loss = 1.022394856741262, disc_loss = 0.0005079056569483391
Trained batch 301 in epoch 5, gen_loss = 1.022259677088024, disc_loss = 0.0005078909067523401
Trained batch 302 in epoch 5, gen_loss = 1.0222114997335, disc_loss = 0.000507655985946936
Trained batch 303 in epoch 5, gen_loss = 1.0220320103199858, disc_loss = 0.000507275572664711
Trained batch 304 in epoch 5, gen_loss = 1.022128508520908, disc_loss = 0.000506916526250816
Trained batch 305 in epoch 5, gen_loss = 1.0220618251881568, disc_loss = 0.0005066075543545831
Trained batch 306 in epoch 5, gen_loss = 1.0222512029281268, disc_loss = 0.0005063082999511886
Trained batch 307 in epoch 5, gen_loss = 1.0223393269947596, disc_loss = 0.0005056282138571373
Trained batch 308 in epoch 5, gen_loss = 1.0224616909490047, disc_loss = 0.0005046275146132256
Trained batch 309 in epoch 5, gen_loss = 1.0226240304208571, disc_loss = 0.0005035195922602959
Trained batch 310 in epoch 5, gen_loss = 1.0225882518713114, disc_loss = 0.0005024313845561661
Trained batch 311 in epoch 5, gen_loss = 1.0227201989828012, disc_loss = 0.0005015109359541944
Trained batch 312 in epoch 5, gen_loss = 1.0228905460705011, disc_loss = 0.0005005703440375668
Trained batch 313 in epoch 5, gen_loss = 1.0230859233315583, disc_loss = 0.0004996429037141085
Trained batch 314 in epoch 5, gen_loss = 1.022803146876986, disc_loss = 0.0004990978606252207
Trained batch 315 in epoch 5, gen_loss = 1.022996758358388, disc_loss = 0.0004994677916858816
Trained batch 316 in epoch 5, gen_loss = 1.0231364826298663, disc_loss = 0.0004997671517904859
Trained batch 317 in epoch 5, gen_loss = 1.023203284485535, disc_loss = 0.000499785166276244
Trained batch 318 in epoch 5, gen_loss = 1.0232916487421735, disc_loss = 0.000499326950866075
Trained batch 319 in epoch 5, gen_loss = 1.0234357502311469, disc_loss = 0.0004986582685887697
Trained batch 320 in epoch 5, gen_loss = 1.0234136622271435, disc_loss = 0.0004981396421703083
Trained batch 321 in epoch 5, gen_loss = 1.0230856539669984, disc_loss = 0.0004976560446283324
Trained batch 322 in epoch 5, gen_loss = 1.022989906209172, disc_loss = 0.000497213908742923
Trained batch 323 in epoch 5, gen_loss = 1.0227444431296102, disc_loss = 0.0004967355468837878
Trained batch 324 in epoch 5, gen_loss = 1.022812085701869, disc_loss = 0.0004961603243226329
Trained batch 325 in epoch 5, gen_loss = 1.022916382258655, disc_loss = 0.0004953797415621648
Trained batch 326 in epoch 5, gen_loss = 1.0228968619935739, disc_loss = 0.0004945302215053782
Trained batch 327 in epoch 5, gen_loss = 1.0230717213778961, disc_loss = 0.0004936335314219255
Trained batch 328 in epoch 5, gen_loss = 1.0230249639340085, disc_loss = 0.0004925752609474924
Trained batch 329 in epoch 5, gen_loss = 1.0234423751180821, disc_loss = 0.0004917333524314348
Trained batch 330 in epoch 5, gen_loss = 1.023297503455528, disc_loss = 0.0004910292420247879
Trained batch 331 in epoch 5, gen_loss = 1.0235698253634464, disc_loss = 0.0004905495984256772
Trained batch 332 in epoch 5, gen_loss = 1.0232322507792406, disc_loss = 0.0004903432944063768
Trained batch 333 in epoch 5, gen_loss = 1.0233003927205138, disc_loss = 0.0004904602828029889
Trained batch 334 in epoch 5, gen_loss = 1.0233826535851207, disc_loss = 0.0004908374487248653
Trained batch 335 in epoch 5, gen_loss = 1.0233082836937337, disc_loss = 0.0004913397407931154
Trained batch 336 in epoch 5, gen_loss = 1.0233344686844936, disc_loss = 0.0004917813311448426
Trained batch 337 in epoch 5, gen_loss = 1.02343944526283, disc_loss = 0.0004919947757207948
Trained batch 338 in epoch 5, gen_loss = 1.023459150903696, disc_loss = 0.0004919117474914762
Trained batch 339 in epoch 5, gen_loss = 1.0238045718740014, disc_loss = 0.000491711861532702
Trained batch 340 in epoch 5, gen_loss = 1.0237677616457785, disc_loss = 0.0004918783986934153
Trained batch 341 in epoch 5, gen_loss = 1.0237832367420197, disc_loss = 0.0004922743504274669
Trained batch 342 in epoch 5, gen_loss = 1.0236681727556725, disc_loss = 0.0004925541006980339
Trained batch 343 in epoch 5, gen_loss = 1.0237001738576001, disc_loss = 0.0004924733296976165
Trained batch 344 in epoch 5, gen_loss = 1.0235856429390284, disc_loss = 0.0004922231912369961
Trained batch 345 in epoch 5, gen_loss = 1.0236490703042531, disc_loss = 0.000492039672233638
Trained batch 346 in epoch 5, gen_loss = 1.0236199328122977, disc_loss = 0.0004920671707064837
Trained batch 347 in epoch 5, gen_loss = 1.0235958578942836, disc_loss = 0.000492234333135969
Trained batch 348 in epoch 5, gen_loss = 1.023562255766467, disc_loss = 0.0004920132895517977
Trained batch 349 in epoch 5, gen_loss = 1.0234162752968925, disc_loss = 0.0004913551362863343
Trained batch 350 in epoch 5, gen_loss = 1.0234510331411986, disc_loss = 0.000490514128956482
Trained batch 351 in epoch 5, gen_loss = 1.0231158841740002, disc_loss = 0.0004896996615157564
Trained batch 352 in epoch 5, gen_loss = 1.0231121444161824, disc_loss = 0.0004891127970998991
Trained batch 353 in epoch 5, gen_loss = 1.0232169318333857, disc_loss = 0.0004885721434842358
Trained batch 354 in epoch 5, gen_loss = 1.023037405416999, disc_loss = 0.0004883348073197109
Trained batch 355 in epoch 5, gen_loss = 1.023290454671624, disc_loss = 0.00048806428212935386
Trained batch 356 in epoch 5, gen_loss = 1.02345969396479, disc_loss = 0.00048730801293660344
Trained batch 357 in epoch 5, gen_loss = 1.023617589606919, disc_loss = 0.00048656089461601064
Trained batch 358 in epoch 5, gen_loss = 1.0235047831840833, disc_loss = 0.00048586687320048214
Trained batch 359 in epoch 5, gen_loss = 1.023491488893827, disc_loss = 0.00048533979105640256
Trained batch 360 in epoch 5, gen_loss = 1.0234587506244057, disc_loss = 0.00048470041632215
Trained batch 361 in epoch 5, gen_loss = 1.023569169953383, disc_loss = 0.00048404167680737425
Trained batch 362 in epoch 5, gen_loss = 1.0236189230742863, disc_loss = 0.0004832965339317189
Trained batch 363 in epoch 5, gen_loss = 1.0236943865215384, disc_loss = 0.0004824690640616809
Trained batch 364 in epoch 5, gen_loss = 1.0236304162299796, disc_loss = 0.0004815406369743869
Trained batch 365 in epoch 5, gen_loss = 1.0236474096449346, disc_loss = 0.0004805291451712882
Trained batch 366 in epoch 5, gen_loss = 1.0236785434572184, disc_loss = 0.0004795763800754935
Trained batch 367 in epoch 5, gen_loss = 1.0235564307026241, disc_loss = 0.0004787235671439861
Trained batch 368 in epoch 5, gen_loss = 1.023518425662343, disc_loss = 0.0004779088121919633
Trained batch 369 in epoch 5, gen_loss = 1.023352618475218, disc_loss = 0.0004772028100764933
Trained batch 370 in epoch 5, gen_loss = 1.0232029909072218, disc_loss = 0.00047638457598895174
Trained batch 371 in epoch 5, gen_loss = 1.0233381730253979, disc_loss = 0.0004755677417892667
Trained batch 372 in epoch 5, gen_loss = 1.0233440041222457, disc_loss = 0.00047472534525200684
Trained batch 373 in epoch 5, gen_loss = 1.0232798117686084, disc_loss = 0.00047376606166568203
Trained batch 374 in epoch 5, gen_loss = 1.023127110004425, disc_loss = 0.00047279560608634103
Trained batch 375 in epoch 5, gen_loss = 1.0229688909776666, disc_loss = 0.00047186390176957887
Trained batch 376 in epoch 5, gen_loss = 1.0230746245510698, disc_loss = 0.00047100725868131363
Trained batch 377 in epoch 5, gen_loss = 1.0230536825127072, disc_loss = 0.00047006938249555236
Trained batch 378 in epoch 5, gen_loss = 1.0228462970980239, disc_loss = 0.00046939345747527313
Trained batch 379 in epoch 5, gen_loss = 1.0227311457458295, disc_loss = 0.0004692161460345807
Trained batch 380 in epoch 5, gen_loss = 1.022699206207055, disc_loss = 0.0004696719156849513
Trained batch 381 in epoch 5, gen_loss = 1.0226166619680315, disc_loss = 0.0004708561608970107
Trained batch 382 in epoch 5, gen_loss = 1.022442259302961, disc_loss = 0.0004720793909018777
Trained batch 383 in epoch 5, gen_loss = 1.0223595028122265, disc_loss = 0.0004729921691553803
Trained batch 384 in epoch 5, gen_loss = 1.0224957075985994, disc_loss = 0.00047370440435486955
Trained batch 385 in epoch 5, gen_loss = 1.0224366289963993, disc_loss = 0.000474460585250331
Trained batch 386 in epoch 5, gen_loss = 1.0223506786102472, disc_loss = 0.0004753736273424089
Trained batch 387 in epoch 5, gen_loss = 1.022447651348163, disc_loss = 0.0004764798554272593
Trained batch 388 in epoch 5, gen_loss = 1.022336359655336, disc_loss = 0.00047766250378038054
Trained batch 389 in epoch 5, gen_loss = 1.022144488340769, disc_loss = 0.00047877370096289384
Trained batch 390 in epoch 5, gen_loss = 1.0218120180737331, disc_loss = 0.0004801410108940471
Trained batch 391 in epoch 5, gen_loss = 1.0218825141082004, disc_loss = 0.0004813290704208027
Trained batch 392 in epoch 5, gen_loss = 1.0220232945665453, disc_loss = 0.0004820678787159025
Trained batch 393 in epoch 5, gen_loss = 1.0219955215901892, disc_loss = 0.0004822724128879493
Trained batch 394 in epoch 5, gen_loss = 1.0219721575326557, disc_loss = 0.0004820639484184735
Trained batch 395 in epoch 5, gen_loss = 1.0219415659555282, disc_loss = 0.00048165675171832036
Trained batch 396 in epoch 5, gen_loss = 1.0219198761118449, disc_loss = 0.00048118971097013284
Trained batch 397 in epoch 5, gen_loss = 1.0219491104684284, disc_loss = 0.0004809338606902206
Trained batch 398 in epoch 5, gen_loss = 1.0217861470423246, disc_loss = 0.00048069845216014987
Trained batch 399 in epoch 5, gen_loss = 1.0218384356796741, disc_loss = 0.0004804118813626701
Trained batch 400 in epoch 5, gen_loss = 1.0216675947729192, disc_loss = 0.0004802222009904989
Trained batch 401 in epoch 5, gen_loss = 1.0216186451378153, disc_loss = 0.0004804249943682312
Trained batch 402 in epoch 5, gen_loss = 1.0216777284742882, disc_loss = 0.0004806923725504761
Trained batch 403 in epoch 5, gen_loss = 1.0213836790016382, disc_loss = 0.00048112248032789514
Trained batch 404 in epoch 5, gen_loss = 1.0215034571694739, disc_loss = 0.00048187412127541996
Trained batch 405 in epoch 5, gen_loss = 1.0213096334135592, disc_loss = 0.0004828888011822165
Trained batch 406 in epoch 5, gen_loss = 1.021390130390992, disc_loss = 0.0004845513223243662
Trained batch 407 in epoch 5, gen_loss = 1.0215107347158825, disc_loss = 0.00048634978492034363
Trained batch 408 in epoch 5, gen_loss = 1.0215995310279735, disc_loss = 0.0004881817266409921
Trained batch 409 in epoch 5, gen_loss = 1.0215080179819247, disc_loss = 0.0004899870888926316
Trained batch 410 in epoch 5, gen_loss = 1.0213788908763524, disc_loss = 0.0004917698901134187
Trained batch 411 in epoch 5, gen_loss = 1.0214327378469763, disc_loss = 0.0004930856716915178
Trained batch 412 in epoch 5, gen_loss = 1.0213544246070898, disc_loss = 0.0004936936255753013
Trained batch 413 in epoch 5, gen_loss = 1.0212228921588493, disc_loss = 0.0004937188376606203
Trained batch 414 in epoch 5, gen_loss = 1.0211649489690022, disc_loss = 0.0004933273970256054
Trained batch 415 in epoch 5, gen_loss = 1.021214166799417, disc_loss = 0.0004926575760551854
Trained batch 416 in epoch 5, gen_loss = 1.0212319123087454, disc_loss = 0.0004920713153050216
Trained batch 417 in epoch 5, gen_loss = 1.0213882361302535, disc_loss = 0.0004917961322066361
Trained batch 418 in epoch 5, gen_loss = 1.0214510513091712, disc_loss = 0.0004920678599854278
Trained batch 419 in epoch 5, gen_loss = 1.0213597768828981, disc_loss = 0.0004926103794354103
Trained batch 420 in epoch 5, gen_loss = 1.0212623141440529, disc_loss = 0.0004930126319961255
Trained batch 421 in epoch 5, gen_loss = 1.021279770898593, disc_loss = 0.0004931227583355398
Trained batch 422 in epoch 5, gen_loss = 1.0211165626280132, disc_loss = 0.0004929992289532275
Trained batch 423 in epoch 5, gen_loss = 1.020977664668605, disc_loss = 0.0004928127893676129
Trained batch 424 in epoch 5, gen_loss = 1.0209066778070786, disc_loss = 0.0004925805989050251
Trained batch 425 in epoch 5, gen_loss = 1.0211762223445193, disc_loss = 0.000492527674511403
Trained batch 426 in epoch 5, gen_loss = 1.0213021701616203, disc_loss = 0.0004925369265280987
Trained batch 427 in epoch 5, gen_loss = 1.0213318868218182, disc_loss = 0.0004925486047846858
Trained batch 428 in epoch 5, gen_loss = 1.0212640981852035, disc_loss = 0.0004924228980009485
Trained batch 429 in epoch 5, gen_loss = 1.0212949603102928, disc_loss = 0.0004920051977996779
Trained batch 430 in epoch 5, gen_loss = 1.0213343234183894, disc_loss = 0.0004913970332278323
Trained batch 431 in epoch 5, gen_loss = 1.021212277589021, disc_loss = 0.0004906670123158687
Trained batch 432 in epoch 5, gen_loss = 1.0214773267851691, disc_loss = 0.000490046768273414
Trained batch 433 in epoch 5, gen_loss = 1.0214785279766205, disc_loss = 0.0004894479237172821
Trained batch 434 in epoch 5, gen_loss = 1.0213955422927594, disc_loss = 0.0004887911933340432
Trained batch 435 in epoch 5, gen_loss = 1.0215339232748801, disc_loss = 0.00048813834485230507
Trained batch 436 in epoch 5, gen_loss = 1.021527017417707, disc_loss = 0.0004878821939941777
Trained batch 437 in epoch 5, gen_loss = 1.0215680706718742, disc_loss = 0.000487825987086053
Trained batch 438 in epoch 5, gen_loss = 1.0215582745764955, disc_loss = 0.0004875809758406234
Trained batch 439 in epoch 5, gen_loss = 1.02131506732919, disc_loss = 0.0004872120484916112
Trained batch 440 in epoch 5, gen_loss = 1.0214451847433232, disc_loss = 0.00048673606817948456
Trained batch 441 in epoch 5, gen_loss = 1.0213853231382586, disc_loss = 0.0004861218299310048
Trained batch 442 in epoch 5, gen_loss = 1.0212292089957415, disc_loss = 0.00048546689711237835
Trained batch 443 in epoch 5, gen_loss = 1.0215351028485342, disc_loss = 0.0004848921200538973
Trained batch 444 in epoch 5, gen_loss = 1.0215303546926948, disc_loss = 0.0004847667540693028
Trained batch 445 in epoch 5, gen_loss = 1.0215016520611373, disc_loss = 0.0004851799854690798
Trained batch 446 in epoch 5, gen_loss = 1.0214184406619744, disc_loss = 0.0004859745857121956
Trained batch 447 in epoch 5, gen_loss = 1.0216138952278666, disc_loss = 0.0004870889350253752
Trained batch 448 in epoch 5, gen_loss = 1.0217092357127864, disc_loss = 0.00048823436842852775
Trained batch 449 in epoch 5, gen_loss = 1.0216906315750547, disc_loss = 0.0004890896970755421
Trained batch 450 in epoch 5, gen_loss = 1.0217823943912059, disc_loss = 0.0004895416831743785
Trained batch 451 in epoch 5, gen_loss = 1.0219473114847082, disc_loss = 0.0004895984814788186
Trained batch 452 in epoch 5, gen_loss = 1.0223690054274552, disc_loss = 0.000489515051993266
Trained batch 453 in epoch 5, gen_loss = 1.0226023187983928, disc_loss = 0.0004892298607306969
Trained batch 454 in epoch 5, gen_loss = 1.0227287220430898, disc_loss = 0.0004890673341943401
Trained batch 455 in epoch 5, gen_loss = 1.0227895968577319, disc_loss = 0.0004890682628588126
Trained batch 456 in epoch 5, gen_loss = 1.0229595199194728, disc_loss = 0.0004891246845790325
Trained batch 457 in epoch 5, gen_loss = 1.023032692452185, disc_loss = 0.0004890995298974383
Trained batch 458 in epoch 5, gen_loss = 1.023093310446521, disc_loss = 0.0004889660489591739
Trained batch 459 in epoch 5, gen_loss = 1.0233385735231897, disc_loss = 0.0004887657678805028
Trained batch 460 in epoch 5, gen_loss = 1.0233614880454256, disc_loss = 0.0004885011361626537
Trained batch 461 in epoch 5, gen_loss = 1.0234389884389323, disc_loss = 0.00048813131623130367
Trained batch 462 in epoch 5, gen_loss = 1.0235544830625052, disc_loss = 0.00048760062156644397
Trained batch 463 in epoch 5, gen_loss = 1.0235054517357514, disc_loss = 0.00048693745160060896
Trained batch 464 in epoch 5, gen_loss = 1.0236375458778875, disc_loss = 0.0004861287226098069
Trained batch 465 in epoch 5, gen_loss = 1.023686994426752, disc_loss = 0.00048534385864650373
Trained batch 466 in epoch 5, gen_loss = 1.0236651643440606, disc_loss = 0.00048463406872686806
Trained batch 467 in epoch 5, gen_loss = 1.0236350467317126, disc_loss = 0.0004839328606370448
Trained batch 468 in epoch 5, gen_loss = 1.0236033220280971, disc_loss = 0.00048326452843597164
Trained batch 469 in epoch 5, gen_loss = 1.0236569238469955, disc_loss = 0.0004827090763664022
Trained batch 470 in epoch 5, gen_loss = 1.0236891795368963, disc_loss = 0.0004821568873166917
Trained batch 471 in epoch 5, gen_loss = 1.0237845469076754, disc_loss = 0.0004817292573673096
Trained batch 472 in epoch 5, gen_loss = 1.023720279178458, disc_loss = 0.0004814416607446825
Trained batch 473 in epoch 5, gen_loss = 1.0237086630320247, disc_loss = 0.00048125992577416403
Trained batch 474 in epoch 5, gen_loss = 1.023818572571403, disc_loss = 0.0004809638942855312
Trained batch 475 in epoch 5, gen_loss = 1.023730690614516, disc_loss = 0.00048046973743952885
Trained batch 476 in epoch 5, gen_loss = 1.023794960550792, disc_loss = 0.000479889782757593
Trained batch 477 in epoch 5, gen_loss = 1.0239725261303172, disc_loss = 0.0004792612023444829
Trained batch 478 in epoch 5, gen_loss = 1.0239489948326461, disc_loss = 0.0004785949036537082
Trained batch 479 in epoch 5, gen_loss = 1.0239526643107335, disc_loss = 0.00047799288502877363
Trained batch 480 in epoch 5, gen_loss = 1.0239791169979469, disc_loss = 0.00047740623745605015
Trained batch 481 in epoch 5, gen_loss = 1.0240496264701067, disc_loss = 0.00047679944696009673
Trained batch 482 in epoch 5, gen_loss = 1.0241527257498748, disc_loss = 0.0004761053065186816
Trained batch 483 in epoch 5, gen_loss = 1.0242451785270832, disc_loss = 0.000475284580257601
Trained batch 484 in epoch 5, gen_loss = 1.0240806030243943, disc_loss = 0.00047444336564272894
Trained batch 485 in epoch 5, gen_loss = 1.0240823335853624, disc_loss = 0.0004736299291565687
Trained batch 486 in epoch 5, gen_loss = 1.024030049356347, disc_loss = 0.0004729313852361813
Trained batch 487 in epoch 5, gen_loss = 1.0242063831843313, disc_loss = 0.0004724161188158953
Trained batch 488 in epoch 5, gen_loss = 1.0242907400023962, disc_loss = 0.00047209467431461315
Trained batch 489 in epoch 5, gen_loss = 1.0242329855354464, disc_loss = 0.0004720602719539691
Trained batch 490 in epoch 5, gen_loss = 1.0241534223138922, disc_loss = 0.0004723592587791017
Trained batch 491 in epoch 5, gen_loss = 1.0243057728540608, disc_loss = 0.0004723510721704792
Trained batch 492 in epoch 5, gen_loss = 1.0242446809704842, disc_loss = 0.0004718485260133171
Trained batch 493 in epoch 5, gen_loss = 1.0243841435021235, disc_loss = 0.0004711599729283334
Trained batch 494 in epoch 5, gen_loss = 1.0243409186902672, disc_loss = 0.0004705784707876967
Trained batch 495 in epoch 5, gen_loss = 1.0242186314877002, disc_loss = 0.00047020663331779597
Trained batch 496 in epoch 5, gen_loss = 1.024055554473424, disc_loss = 0.00046974369192693166
Trained batch 497 in epoch 5, gen_loss = 1.024072321423565, disc_loss = 0.0004694253061698183
Trained batch 498 in epoch 5, gen_loss = 1.0240216421220967, disc_loss = 0.00046924254445525684
Trained batch 499 in epoch 5, gen_loss = 1.0239329181909562, disc_loss = 0.0004690557149151573
Trained batch 500 in epoch 5, gen_loss = 1.024019458217773, disc_loss = 0.0004686893923994676
Trained batch 501 in epoch 5, gen_loss = 1.0239538716604986, disc_loss = 0.0004683095132668857
Trained batch 502 in epoch 5, gen_loss = 1.0238876586879935, disc_loss = 0.0004681130442806523
Trained batch 503 in epoch 5, gen_loss = 1.0237470070521038, disc_loss = 0.00046824006496160383
Trained batch 504 in epoch 5, gen_loss = 1.0237694036842573, disc_loss = 0.0004687161316967219
Trained batch 505 in epoch 5, gen_loss = 1.023852315580421, disc_loss = 0.0004697484850752114
Trained batch 506 in epoch 5, gen_loss = 1.0238808896649754, disc_loss = 0.0004708686992563941
Trained batch 507 in epoch 5, gen_loss = 1.0237602336904195, disc_loss = 0.0004715175766436664
Trained batch 508 in epoch 5, gen_loss = 1.0237023180500697, disc_loss = 0.00047182089707520033
Trained batch 509 in epoch 5, gen_loss = 1.0238035203195086, disc_loss = 0.00047205688037245316
Trained batch 510 in epoch 5, gen_loss = 1.0238578257728697, disc_loss = 0.0004723780019621824
Trained batch 511 in epoch 5, gen_loss = 1.0239351225318387, disc_loss = 0.00047296599457524735
Trained batch 512 in epoch 5, gen_loss = 1.0237451132975126, disc_loss = 0.0004736537116310345
Trained batch 513 in epoch 5, gen_loss = 1.0234789436661316, disc_loss = 0.00047411165363076034
Trained batch 514 in epoch 5, gen_loss = 1.0235540900415587, disc_loss = 0.0004741778493959466
Trained batch 515 in epoch 5, gen_loss = 1.0234737236832463, disc_loss = 0.00047392845439488633
Trained batch 516 in epoch 5, gen_loss = 1.0235664832983995, disc_loss = 0.0004735578636858816
Trained batch 517 in epoch 5, gen_loss = 1.0235348792610022, disc_loss = 0.0004731067659835193
Trained batch 518 in epoch 5, gen_loss = 1.0235653102742455, disc_loss = 0.0004726663129481573
Trained batch 519 in epoch 5, gen_loss = 1.0236499098631051, disc_loss = 0.0004722668825287166
Trained batch 520 in epoch 5, gen_loss = 1.0237901078075915, disc_loss = 0.00047190569402015857
Trained batch 521 in epoch 5, gen_loss = 1.0238570838138974, disc_loss = 0.0004715856908151739
Trained batch 522 in epoch 5, gen_loss = 1.0238105851879082, disc_loss = 0.00047128497023078887
Trained batch 523 in epoch 5, gen_loss = 1.0239509546574745, disc_loss = 0.00047096781233400695
Trained batch 524 in epoch 5, gen_loss = 1.0239627209163848, disc_loss = 0.000470643111496299
Trained batch 525 in epoch 5, gen_loss = 1.024019064105509, disc_loss = 0.000470460975953106
Trained batch 526 in epoch 5, gen_loss = 1.0240501181224266, disc_loss = 0.0004703076777917216
Trained batch 527 in epoch 5, gen_loss = 1.0238560335428426, disc_loss = 0.00047015167162747025
Trained batch 528 in epoch 5, gen_loss = 1.0236954981978765, disc_loss = 0.00047017038267095694
Trained batch 529 in epoch 5, gen_loss = 1.023642327650538, disc_loss = 0.000470322569492295
Trained batch 530 in epoch 5, gen_loss = 1.0238365507395255, disc_loss = 0.0004705040741093823
Trained batch 531 in epoch 5, gen_loss = 1.0238695886350215, disc_loss = 0.0004704401441054336
Trained batch 532 in epoch 5, gen_loss = 1.0236777253938214, disc_loss = 0.00047014294134369505
Trained batch 533 in epoch 5, gen_loss = 1.0236017618063238, disc_loss = 0.0004697669951502654
Trained batch 534 in epoch 5, gen_loss = 1.0238016724586487, disc_loss = 0.00046943383152372526
Trained batch 535 in epoch 5, gen_loss = 1.0236753181957488, disc_loss = 0.00046905469594433395
Trained batch 536 in epoch 5, gen_loss = 1.0237112006439621, disc_loss = 0.00046882647716666153
Trained batch 537 in epoch 5, gen_loss = 1.0239183850669507, disc_loss = 0.00046854874996442894
Trained batch 538 in epoch 5, gen_loss = 1.0239709366893945, disc_loss = 0.00046820359784085564
Trained batch 539 in epoch 5, gen_loss = 1.0238743235667547, disc_loss = 0.0004678745026602108
Trained batch 540 in epoch 5, gen_loss = 1.024027324317784, disc_loss = 0.00046757686695838413
Trained batch 541 in epoch 5, gen_loss = 1.0240705689600913, disc_loss = 0.0004672820714236421
Trained batch 542 in epoch 5, gen_loss = 1.0241044837686457, disc_loss = 0.00046708392848753374
Trained batch 543 in epoch 5, gen_loss = 1.0240302770672476, disc_loss = 0.00046692221676761724
Trained batch 544 in epoch 5, gen_loss = 1.024195651942437, disc_loss = 0.0004669170309880261
Trained batch 545 in epoch 5, gen_loss = 1.024080095164505, disc_loss = 0.00046707375004988644
Trained batch 546 in epoch 5, gen_loss = 1.0241433858217661, disc_loss = 0.0004671715647864353
Trained batch 547 in epoch 5, gen_loss = 1.0240979972329454, disc_loss = 0.0004670129360187753
Trained batch 548 in epoch 5, gen_loss = 1.0242446564368646, disc_loss = 0.000466671685268021
Trained batch 549 in epoch 5, gen_loss = 1.0242936750975522, disc_loss = 0.0004662057678400412
Trained batch 550 in epoch 5, gen_loss = 1.0243171262005497, disc_loss = 0.0004657340505152574
Trained batch 551 in epoch 5, gen_loss = 1.0244558052956194, disc_loss = 0.0004653537531814199
Trained batch 552 in epoch 5, gen_loss = 1.024628189222291, disc_loss = 0.00046513562575039484
Trained batch 553 in epoch 5, gen_loss = 1.0247668087052093, disc_loss = 0.00046493962304092965
Trained batch 554 in epoch 5, gen_loss = 1.0247327431902156, disc_loss = 0.000464865483691274
Trained batch 555 in epoch 5, gen_loss = 1.024752260219279, disc_loss = 0.00046499952209454697
Trained batch 556 in epoch 5, gen_loss = 1.0248485712645512, disc_loss = 0.00046525572484250045
Trained batch 557 in epoch 5, gen_loss = 1.0247802771761425, disc_loss = 0.000465464174770312
Trained batch 558 in epoch 5, gen_loss = 1.024747536199464, disc_loss = 0.0004654004617858876
Trained batch 559 in epoch 5, gen_loss = 1.0247782314462321, disc_loss = 0.00046514942263716614
Trained batch 560 in epoch 5, gen_loss = 1.0248394878365352, disc_loss = 0.0004647615706499744
Trained batch 561 in epoch 5, gen_loss = 1.0247070919788606, disc_loss = 0.0004643281472421598
Trained batch 562 in epoch 5, gen_loss = 1.0245441993430495, disc_loss = 0.00046396967481156367
Trained batch 563 in epoch 5, gen_loss = 1.0247517425751855, disc_loss = 0.0004636690757626045
Trained batch 564 in epoch 5, gen_loss = 1.024678483473516, disc_loss = 0.00046333248599018256
Trained batch 565 in epoch 5, gen_loss = 1.0245726641412338, disc_loss = 0.0004628102750349387
Trained batch 566 in epoch 5, gen_loss = 1.024644698835975, disc_loss = 0.00046234464370023467
Trained batch 567 in epoch 5, gen_loss = 1.0246642588729589, disc_loss = 0.00046199947058046516
Trained batch 568 in epoch 5, gen_loss = 1.0246942093586042, disc_loss = 0.00046180563743616193
Trained batch 569 in epoch 5, gen_loss = 1.024634433420081, disc_loss = 0.00046170333548696107
Trained batch 570 in epoch 5, gen_loss = 1.0247325736461712, disc_loss = 0.0004617298491371122
Trained batch 571 in epoch 5, gen_loss = 1.024767053502423, disc_loss = 0.0004619091182099077
Trained batch 572 in epoch 5, gen_loss = 1.0248222082697285, disc_loss = 0.0004621705362077739
Trained batch 573 in epoch 5, gen_loss = 1.0248833886422346, disc_loss = 0.00046255489119350056
Trained batch 574 in epoch 5, gen_loss = 1.0249647953199303, disc_loss = 0.00046317772272943885
Trained batch 575 in epoch 5, gen_loss = 1.0248347670874662, disc_loss = 0.0004638971484306846
Trained batch 576 in epoch 5, gen_loss = 1.024748929141919, disc_loss = 0.0004645759771353859
Trained batch 577 in epoch 5, gen_loss = 1.024836852166892, disc_loss = 0.00046532379185015924
Trained batch 578 in epoch 5, gen_loss = 1.0247706368385407, disc_loss = 0.00046607391117432193
Trained batch 579 in epoch 5, gen_loss = 1.0245864146742327, disc_loss = 0.0004666819013499631
Trained batch 580 in epoch 5, gen_loss = 1.0245729541204063, disc_loss = 0.000467398911931455
Trained batch 581 in epoch 5, gen_loss = 1.0245400699962866, disc_loss = 0.0004681482294353751
Trained batch 582 in epoch 5, gen_loss = 1.024463447350785, disc_loss = 0.00046884270919709327
Trained batch 583 in epoch 5, gen_loss = 1.0244330219822386, disc_loss = 0.00046932001107849566
Trained batch 584 in epoch 5, gen_loss = 1.024529098139869, disc_loss = 0.00046948827197426993
Trained batch 585 in epoch 5, gen_loss = 1.0244618741725493, disc_loss = 0.0004695173011980069
Trained batch 586 in epoch 5, gen_loss = 1.0246744982428608, disc_loss = 0.0004694634789623379
Trained batch 587 in epoch 5, gen_loss = 1.0248052285236566, disc_loss = 0.0004693793557109319
Trained batch 588 in epoch 5, gen_loss = 1.0248955633927688, disc_loss = 0.00046940014662479203
Trained batch 589 in epoch 5, gen_loss = 1.0249834428399296, disc_loss = 0.00046957618739678904
Trained batch 590 in epoch 5, gen_loss = 1.0250723136056297, disc_loss = 0.0004698769012258259
Trained batch 591 in epoch 5, gen_loss = 1.0249641704800967, disc_loss = 0.0004698685549949398
Trained batch 592 in epoch 5, gen_loss = 1.024864811217805, disc_loss = 0.00046944675793504957
Trained batch 593 in epoch 5, gen_loss = 1.0248375650407489, disc_loss = 0.0004689258676325481
Trained batch 594 in epoch 5, gen_loss = 1.0246653780215929, disc_loss = 0.00046845039145134684
Trained batch 595 in epoch 5, gen_loss = 1.0246915400228245, disc_loss = 0.0004681535154902775
Trained batch 596 in epoch 5, gen_loss = 1.0246628204382444, disc_loss = 0.00046798442943531387
Trained batch 597 in epoch 5, gen_loss = 1.0247179910690092, disc_loss = 0.00046786238210589975
Trained batch 598 in epoch 5, gen_loss = 1.0246379593377917, disc_loss = 0.00046763645382961474
Trained batch 599 in epoch 5, gen_loss = 1.0246872811516126, disc_loss = 0.0004672657586221855
Trained batch 600 in epoch 5, gen_loss = 1.0247355523998052, disc_loss = 0.0004668395255814142
Trained batch 601 in epoch 5, gen_loss = 1.0247499876442145, disc_loss = 0.00046651303978024615
Trained batch 602 in epoch 5, gen_loss = 1.0248221424879325, disc_loss = 0.00046628879901428305
Trained batch 603 in epoch 5, gen_loss = 1.0246981503750314, disc_loss = 0.0004659974811810095
Trained batch 604 in epoch 5, gen_loss = 1.0249466296069878, disc_loss = 0.00046565882975383745
Trained batch 605 in epoch 5, gen_loss = 1.025129394070937, disc_loss = 0.00046535377264518075
Trained batch 606 in epoch 5, gen_loss = 1.025065768393496, disc_loss = 0.00046498858960546
Trained batch 607 in epoch 5, gen_loss = 1.0250526995054985, disc_loss = 0.00046473059734652403
Trained batch 608 in epoch 5, gen_loss = 1.0251257076052023, disc_loss = 0.00046447700641317943
Trained batch 609 in epoch 5, gen_loss = 1.0250946724023975, disc_loss = 0.00046430860013180013
Trained batch 610 in epoch 5, gen_loss = 1.0251997595137738, disc_loss = 0.00046424065302299493
Trained batch 611 in epoch 5, gen_loss = 1.0252668044341156, disc_loss = 0.00046416230630188545
Trained batch 612 in epoch 5, gen_loss = 1.0252130359265388, disc_loss = 0.00046406552693067834
Trained batch 613 in epoch 5, gen_loss = 1.0251945366882733, disc_loss = 0.00046397859198357895
Trained batch 614 in epoch 5, gen_loss = 1.025116126324103, disc_loss = 0.0004638269731402965
Trained batch 615 in epoch 5, gen_loss = 1.0249472085338134, disc_loss = 0.00046363881813101817
Trained batch 616 in epoch 5, gen_loss = 1.0249154230570676, disc_loss = 0.0004634385044146684
Trained batch 617 in epoch 5, gen_loss = 1.0247647381330385, disc_loss = 0.0004632729043370123
Trained batch 618 in epoch 5, gen_loss = 1.0247790824038148, disc_loss = 0.00046320625149743835
Trained batch 619 in epoch 5, gen_loss = 1.0246193641616452, disc_loss = 0.0004633508273283012
Trained batch 620 in epoch 5, gen_loss = 1.024599707836882, disc_loss = 0.0004636670300325914
Trained batch 621 in epoch 5, gen_loss = 1.0247046571835827, disc_loss = 0.00046381560996071124
Trained batch 622 in epoch 5, gen_loss = 1.0247524450525618, disc_loss = 0.0004637038983406692
Trained batch 623 in epoch 5, gen_loss = 1.0248241149462187, disc_loss = 0.0004634624809650398
Trained batch 624 in epoch 5, gen_loss = 1.0248011070251464, disc_loss = 0.00046336136151803656
Trained batch 625 in epoch 5, gen_loss = 1.0246994722003755, disc_loss = 0.0004634565377778845
Trained batch 626 in epoch 5, gen_loss = 1.024671229639312, disc_loss = 0.00046374242542936514
Trained batch 627 in epoch 5, gen_loss = 1.0245658279794037, disc_loss = 0.00046412949430617984
Trained batch 628 in epoch 5, gen_loss = 1.0245188813899393, disc_loss = 0.0004643415990436416
Trained batch 629 in epoch 5, gen_loss = 1.0243818266051157, disc_loss = 0.0004642955475511761
Trained batch 630 in epoch 5, gen_loss = 1.0241775542922709, disc_loss = 0.0004640890449641026
Trained batch 631 in epoch 5, gen_loss = 1.0240765504444702, disc_loss = 0.0004637997899062842
Trained batch 632 in epoch 5, gen_loss = 1.0240950848065657, disc_loss = 0.00046346256996372177
Trained batch 633 in epoch 5, gen_loss = 1.0241536169022039, disc_loss = 0.00046310908995796075
Trained batch 634 in epoch 5, gen_loss = 1.024268439060121, disc_loss = 0.0004627765520126559
Trained batch 635 in epoch 5, gen_loss = 1.024424914294069, disc_loss = 0.0004625140906837088
Trained batch 636 in epoch 5, gen_loss = 1.0245012769145156, disc_loss = 0.00046244800597525405
Trained batch 637 in epoch 5, gen_loss = 1.0244177769530902, disc_loss = 0.00046252117471593917
Trained batch 638 in epoch 5, gen_loss = 1.0242491291722222, disc_loss = 0.00046300806975018024
Trained batch 639 in epoch 5, gen_loss = 1.0241181920282543, disc_loss = 0.0004638218852392129
Trained batch 640 in epoch 5, gen_loss = 1.0240738548094321, disc_loss = 0.00046432548027633446
Trained batch 641 in epoch 5, gen_loss = 1.0241595885463963, disc_loss = 0.00046488908646949943
Trained batch 642 in epoch 5, gen_loss = 1.0243887582425937, disc_loss = 0.00046560200550953724
Trained batch 643 in epoch 5, gen_loss = 1.0243085808820607, disc_loss = 0.0004661987602517482
Trained batch 644 in epoch 5, gen_loss = 1.024309186140696, disc_loss = 0.0004666523258323608
Trained batch 645 in epoch 5, gen_loss = 1.024298149458026, disc_loss = 0.0004671271744770057
Trained batch 646 in epoch 5, gen_loss = 1.0243822195246193, disc_loss = 0.00046770027273439283
Trained batch 647 in epoch 5, gen_loss = 1.024411923079579, disc_loss = 0.00046874855143184426
Trained batch 648 in epoch 5, gen_loss = 1.0245185040729623, disc_loss = 0.00047020158803408665
Trained batch 649 in epoch 5, gen_loss = 1.024638594022164, disc_loss = 0.00047151569871437877
Trained batch 650 in epoch 5, gen_loss = 1.0246171102545778, disc_loss = 0.0004720543347027821
Trained batch 651 in epoch 5, gen_loss = 1.0246520087214335, disc_loss = 0.0004720290689874673
Trained batch 652 in epoch 5, gen_loss = 1.0246265366285536, disc_loss = 0.0004717479600669327
Trained batch 653 in epoch 5, gen_loss = 1.0247389503757522, disc_loss = 0.0004715940272160528
Trained batch 654 in epoch 5, gen_loss = 1.0248688846144058, disc_loss = 0.00047172325660380397
Trained batch 655 in epoch 5, gen_loss = 1.0249121504404195, disc_loss = 0.0004720152596081146
Trained batch 656 in epoch 5, gen_loss = 1.024893690915594, disc_loss = 0.0004723967187374347
Trained batch 657 in epoch 5, gen_loss = 1.02481963270341, disc_loss = 0.0004727519795684799
Trained batch 658 in epoch 5, gen_loss = 1.0248807372923867, disc_loss = 0.0004728863665572444
Trained batch 659 in epoch 5, gen_loss = 1.0248013497302026, disc_loss = 0.00047275355983319143
Trained batch 660 in epoch 5, gen_loss = 1.0248059765654145, disc_loss = 0.00047259810506343296
Trained batch 661 in epoch 5, gen_loss = 1.0248162797750664, disc_loss = 0.00047248357677580073
Trained batch 662 in epoch 5, gen_loss = 1.0248035220359066, disc_loss = 0.0004723412658892632
Trained batch 663 in epoch 5, gen_loss = 1.0248312333441643, disc_loss = 0.00047211983972549905
Trained batch 664 in epoch 5, gen_loss = 1.024853443292747, disc_loss = 0.0004717850487716881
Trained batch 665 in epoch 5, gen_loss = 1.0248986061091896, disc_loss = 0.00047136770476604244
Trained batch 666 in epoch 5, gen_loss = 1.0249871804617692, disc_loss = 0.00047088549827789956
Trained batch 667 in epoch 5, gen_loss = 1.0250130642852384, disc_loss = 0.0004703909338361822
Trained batch 668 in epoch 5, gen_loss = 1.0250257095948463, disc_loss = 0.0004699467929209421
Trained batch 669 in epoch 5, gen_loss = 1.0251848186129955, disc_loss = 0.00046963668792159295
Trained batch 670 in epoch 5, gen_loss = 1.025112749833819, disc_loss = 0.00046952342584473465
Trained batch 671 in epoch 5, gen_loss = 1.0252004252480609, disc_loss = 0.000470025296105329
Trained batch 672 in epoch 5, gen_loss = 1.0253096775526809, disc_loss = 0.0004710562536671978
Trained batch 673 in epoch 5, gen_loss = 1.0252569194894163, disc_loss = 0.0004717049044839318
Trained batch 674 in epoch 5, gen_loss = 1.0252849426092925, disc_loss = 0.00047203309664770065
Trained batch 675 in epoch 5, gen_loss = 1.0251907255698944, disc_loss = 0.00047239810794710044
Trained batch 676 in epoch 5, gen_loss = 1.025232051024585, disc_loss = 0.00047296299827599795
Trained batch 677 in epoch 5, gen_loss = 1.0253356020886637, disc_loss = 0.00047328669550493127
Trained batch 678 in epoch 5, gen_loss = 1.0253355955164634, disc_loss = 0.00047352749120986874
Trained batch 679 in epoch 5, gen_loss = 1.0253778763553676, disc_loss = 0.00047361390070898993
Trained batch 680 in epoch 5, gen_loss = 1.0253342495965887, disc_loss = 0.0004736811695455453
Trained batch 681 in epoch 5, gen_loss = 1.0252765401367567, disc_loss = 0.0004736877976205095
Trained batch 682 in epoch 5, gen_loss = 1.0252559507922931, disc_loss = 0.0004735514737960015
Trained batch 683 in epoch 5, gen_loss = 1.0252589022206982, disc_loss = 0.00047325305491561625
Trained batch 684 in epoch 5, gen_loss = 1.0253658842866438, disc_loss = 0.00047285306144439457
Trained batch 685 in epoch 5, gen_loss = 1.0252917280350065, disc_loss = 0.00047263779383909253
Trained batch 686 in epoch 5, gen_loss = 1.0252676806595649, disc_loss = 0.00047255163125260334
Trained batch 687 in epoch 5, gen_loss = 1.0252630324211232, disc_loss = 0.00047239072512448454
Trained batch 688 in epoch 5, gen_loss = 1.025355531965181, disc_loss = 0.00047221674269116965
Trained batch 689 in epoch 5, gen_loss = 1.0253334095512612, disc_loss = 0.0004721920916315445
Trained batch 690 in epoch 5, gen_loss = 1.0252982105429025, disc_loss = 0.000472469245482997
Trained batch 691 in epoch 5, gen_loss = 1.0253291262712092, disc_loss = 0.00047278389197108375
Trained batch 692 in epoch 5, gen_loss = 1.025292934277357, disc_loss = 0.0004728414754395529
Trained batch 693 in epoch 5, gen_loss = 1.0253390881101405, disc_loss = 0.00047270876531140617
Trained batch 694 in epoch 5, gen_loss = 1.0253201114187995, disc_loss = 0.0004724433801070747
Trained batch 695 in epoch 5, gen_loss = 1.02529066664049, disc_loss = 0.0004721431017572484
Trained batch 696 in epoch 5, gen_loss = 1.0252672974314203, disc_loss = 0.0004719037297479922
Trained batch 697 in epoch 5, gen_loss = 1.0253012619250825, disc_loss = 0.00047164034855961976
Trained batch 698 in epoch 5, gen_loss = 1.0252978486223452, disc_loss = 0.0004712741171373407
Trained batch 699 in epoch 5, gen_loss = 1.0253620554719654, disc_loss = 0.0004707901369485106
Trained batch 700 in epoch 5, gen_loss = 1.0253948449408277, disc_loss = 0.00047024352539398143
Trained batch 701 in epoch 5, gen_loss = 1.025371196602824, disc_loss = 0.0004697557265598803
Trained batch 702 in epoch 5, gen_loss = 1.025395896153294, disc_loss = 0.00046936867331678927
Trained batch 703 in epoch 5, gen_loss = 1.0253705255348573, disc_loss = 0.0004690762104205119
Trained batch 704 in epoch 5, gen_loss = 1.0253369194395998, disc_loss = 0.0004689024287298262
Trained batch 705 in epoch 5, gen_loss = 1.0253189842694204, disc_loss = 0.00046887955481868184
Trained batch 706 in epoch 5, gen_loss = 1.0252659016485093, disc_loss = 0.000468910601367707
Trained batch 707 in epoch 5, gen_loss = 1.025233123514612, disc_loss = 0.00046880726157554417
Trained batch 708 in epoch 5, gen_loss = 1.0252231234219582, disc_loss = 0.0004686219163207969
Trained batch 709 in epoch 5, gen_loss = 1.0252595818378556, disc_loss = 0.00046833806049568957
Trained batch 710 in epoch 5, gen_loss = 1.0252248130099515, disc_loss = 0.00046799186561343424
Trained batch 711 in epoch 5, gen_loss = 1.0253047014722663, disc_loss = 0.0004676159383001341
Trained batch 712 in epoch 5, gen_loss = 1.0252678436952085, disc_loss = 0.00046715396249264824
Trained batch 713 in epoch 5, gen_loss = 1.0252589013229232, disc_loss = 0.0004666502030815144
Trained batch 714 in epoch 5, gen_loss = 1.0252535624103947, disc_loss = 0.00046615973092579787
Trained batch 715 in epoch 5, gen_loss = 1.0252663422396728, disc_loss = 0.0004656503363818128
Trained batch 716 in epoch 5, gen_loss = 1.025192633832349, disc_loss = 0.0004651570438598627
Trained batch 717 in epoch 5, gen_loss = 1.025429475606318, disc_loss = 0.0004649697250271836
Trained batch 718 in epoch 5, gen_loss = 1.025439306989996, disc_loss = 0.00046538179251737763
Trained batch 719 in epoch 5, gen_loss = 1.025520797736115, disc_loss = 0.000465999569880498
Trained batch 720 in epoch 5, gen_loss = 1.0254342203001374, disc_loss = 0.00046694099494361355
Trained batch 721 in epoch 5, gen_loss = 1.0255043124393082, disc_loss = 0.000467626289117061
Trained batch 722 in epoch 5, gen_loss = 1.0255223396408113, disc_loss = 0.0004679926479356698
Trained batch 723 in epoch 5, gen_loss = 1.025366963190927, disc_loss = 0.0004682417628582045
Trained batch 724 in epoch 5, gen_loss = 1.0253413436330598, disc_loss = 0.00046826273188845994
Trained batch 725 in epoch 5, gen_loss = 1.0253676901014712, disc_loss = 0.000468157977703606
Trained batch 726 in epoch 5, gen_loss = 1.0254496651633733, disc_loss = 0.0004681550739808623
Trained batch 727 in epoch 5, gen_loss = 1.0253439159183713, disc_loss = 0.0004681526447761776
Trained batch 728 in epoch 5, gen_loss = 1.025451566783816, disc_loss = 0.0004681865654546264
Trained batch 729 in epoch 5, gen_loss = 1.0254274015557276, disc_loss = 0.0004682905007391364
Trained batch 730 in epoch 5, gen_loss = 1.0254432321736326, disc_loss = 0.0004683331542506001
Trained batch 731 in epoch 5, gen_loss = 1.0254180649590623, disc_loss = 0.00046840409870794466
Trained batch 732 in epoch 5, gen_loss = 1.025420204028589, disc_loss = 0.0004685328830273995
Trained batch 733 in epoch 5, gen_loss = 1.0254824016984216, disc_loss = 0.00046857151137274746
Trained batch 734 in epoch 5, gen_loss = 1.0255231365865591, disc_loss = 0.0004684658758508574
Trained batch 735 in epoch 5, gen_loss = 1.025614746886751, disc_loss = 0.00046827869270956677
Trained batch 736 in epoch 5, gen_loss = 1.0256323772337252, disc_loss = 0.0004680654094003209
Trained batch 737 in epoch 5, gen_loss = 1.0256178976720587, disc_loss = 0.0004679062430357856
Trained batch 738 in epoch 5, gen_loss = 1.0255365648353536, disc_loss = 0.00046783566651900497
Trained batch 739 in epoch 5, gen_loss = 1.0255339594306172, disc_loss = 0.00046778930604026803
Trained batch 740 in epoch 5, gen_loss = 1.0255931264314897, disc_loss = 0.0004677745699906073
Trained batch 741 in epoch 5, gen_loss = 1.0254062382840725, disc_loss = 0.0004677691343662485
Trained batch 742 in epoch 5, gen_loss = 1.0253984253467494, disc_loss = 0.0004677774324804146
Trained batch 743 in epoch 5, gen_loss = 1.0253484056040805, disc_loss = 0.00046778468030454187
Trained batch 744 in epoch 5, gen_loss = 1.0255129120493895, disc_loss = 0.00046785676204552564
Trained batch 745 in epoch 5, gen_loss = 1.025479805133937, disc_loss = 0.00046801588696789064
Trained batch 746 in epoch 5, gen_loss = 1.025434635808988, disc_loss = 0.0004682355712738619
Trained batch 747 in epoch 5, gen_loss = 1.0255299397808983, disc_loss = 0.0004684875656333615
Trained batch 748 in epoch 5, gen_loss = 1.0254211136113818, disc_loss = 0.0004685566901378222
Trained batch 749 in epoch 5, gen_loss = 1.0254706338246664, disc_loss = 0.0004685479057758736
Trained batch 750 in epoch 5, gen_loss = 1.0255393940662734, disc_loss = 0.0004684360901979834
Trained batch 751 in epoch 5, gen_loss = 1.0256586743796126, disc_loss = 0.00046819869073667003
Trained batch 752 in epoch 5, gen_loss = 1.0255910944970321, disc_loss = 0.0004679890400951154
Trained batch 753 in epoch 5, gen_loss = 1.0256764838170627, disc_loss = 0.00046790313079940227
Trained batch 754 in epoch 5, gen_loss = 1.0256479579091862, disc_loss = 0.0004679257033388161
Trained batch 755 in epoch 5, gen_loss = 1.0257050735609872, disc_loss = 0.00046799679957936944
Trained batch 756 in epoch 5, gen_loss = 1.0256186128450038, disc_loss = 0.00046815807157047853
Trained batch 757 in epoch 5, gen_loss = 1.0256046806916712, disc_loss = 0.00046834255895275735
Trained batch 758 in epoch 5, gen_loss = 1.0256470595738005, disc_loss = 0.0004683345242328905
Trained batch 759 in epoch 5, gen_loss = 1.0257321393803547, disc_loss = 0.00046815894029829283
Trained batch 760 in epoch 5, gen_loss = 1.0256990681496618, disc_loss = 0.000467914489053377
Trained batch 761 in epoch 5, gen_loss = 1.0257402251711667, disc_loss = 0.00046760662302776335
Trained batch 762 in epoch 5, gen_loss = 1.025680834703333, disc_loss = 0.0004672401583044659
Trained batch 763 in epoch 5, gen_loss = 1.025680814347966, disc_loss = 0.00046684925940179716
Trained batch 764 in epoch 5, gen_loss = 1.0256578083131827, disc_loss = 0.00046645065267749883
Trained batch 765 in epoch 5, gen_loss = 1.0255795781824046, disc_loss = 0.0004661111281745503
Trained batch 766 in epoch 5, gen_loss = 1.0255522214293946, disc_loss = 0.00046577794390297684
Trained batch 767 in epoch 5, gen_loss = 1.0256092594160389, disc_loss = 0.0004655388533478799
Trained batch 768 in epoch 5, gen_loss = 1.0256176431250354, disc_loss = 0.0004653540220281463
Trained batch 769 in epoch 5, gen_loss = 1.02559507907211, disc_loss = 0.0004650950610793389
Trained batch 770 in epoch 5, gen_loss = 1.025569251771103, disc_loss = 0.00046472778768355966
Trained batch 771 in epoch 5, gen_loss = 1.025535795277882, disc_loss = 0.0004642852998237304
Trained batch 772 in epoch 5, gen_loss = 1.0255697553093035, disc_loss = 0.000463861609105187
Trained batch 773 in epoch 5, gen_loss = 1.02557162759532, disc_loss = 0.00046340559962842115
Trained batch 774 in epoch 5, gen_loss = 1.0255800387936254, disc_loss = 0.00046293682000982843
Trained batch 775 in epoch 5, gen_loss = 1.0255107785162239, disc_loss = 0.0004624692555339185
Trained batch 776 in epoch 5, gen_loss = 1.0254352528462847, disc_loss = 0.00046208633433440414
Trained batch 777 in epoch 5, gen_loss = 1.0253987188204394, disc_loss = 0.00046174113722232286
Trained batch 778 in epoch 5, gen_loss = 1.025361867786525, disc_loss = 0.0004613706428203905
Trained batch 779 in epoch 5, gen_loss = 1.025347434480985, disc_loss = 0.0004609815019368678
Trained batch 780 in epoch 5, gen_loss = 1.0252077519206781, disc_loss = 0.00046059082229760336
Trained batch 781 in epoch 5, gen_loss = 1.0250902614934976, disc_loss = 0.0004602102192009048
Trained batch 782 in epoch 5, gen_loss = 1.0251391092327211, disc_loss = 0.00045981628686006184
Trained batch 783 in epoch 5, gen_loss = 1.0251532203080702, disc_loss = 0.0004593970137629723
Trained batch 784 in epoch 5, gen_loss = 1.025200961957312, disc_loss = 0.00045900878374676877
Trained batch 785 in epoch 5, gen_loss = 1.0251924613959917, disc_loss = 0.0004587678379214365
Trained batch 786 in epoch 5, gen_loss = 1.0251601502734793, disc_loss = 0.0004586657418734382
Trained batch 787 in epoch 5, gen_loss = 1.025130882632309, disc_loss = 0.0004584364481248892
Trained batch 788 in epoch 5, gen_loss = 1.025156191395565, disc_loss = 0.0004580814216770049
Trained batch 789 in epoch 5, gen_loss = 1.025294621835781, disc_loss = 0.00045786435735932127
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 1.0079880952835083, disc_loss = 0.0002835643826983869
Trained batch 1 in epoch 6, gen_loss = 1.0333406329154968, disc_loss = 0.00027809377934318036
Trained batch 2 in epoch 6, gen_loss = 0.985163152217865, disc_loss = 0.00025487572808439535
Trained batch 3 in epoch 6, gen_loss = 1.0007735341787338, disc_loss = 0.0002274666985613294
Trained batch 4 in epoch 6, gen_loss = 0.9884971499443054, disc_loss = 0.00020811202412005514
Trained batch 5 in epoch 6, gen_loss = 1.010163575410843, disc_loss = 0.00020409581338753924
Trained batch 6 in epoch 6, gen_loss = 1.0152658990451269, disc_loss = 0.00021700532566423396
Trained batch 7 in epoch 6, gen_loss = 1.0084433183073997, disc_loss = 0.00023944166423461866
Trained batch 8 in epoch 6, gen_loss = 1.019908328851064, disc_loss = 0.0002516617840026609
Trained batch 9 in epoch 6, gen_loss = 1.0229440867900848, disc_loss = 0.0002508400168153457
Trained batch 10 in epoch 6, gen_loss = 1.0202584158290515, disc_loss = 0.0002494175264887004
Trained batch 11 in epoch 6, gen_loss = 1.0222846070925395, disc_loss = 0.0002515096554513245
Trained batch 12 in epoch 6, gen_loss = 1.0272358014033391, disc_loss = 0.0002574120287765534
Trained batch 13 in epoch 6, gen_loss = 1.0260001591273717, disc_loss = 0.00026529653093478246
Trained batch 14 in epoch 6, gen_loss = 1.025413449605306, disc_loss = 0.0002811007424800967
Trained batch 15 in epoch 6, gen_loss = 1.022381003946066, disc_loss = 0.00030379807049030205
Trained batch 16 in epoch 6, gen_loss = 1.0212341161335217, disc_loss = 0.00032521822910947613
Trained batch 17 in epoch 6, gen_loss = 1.0206821196609073, disc_loss = 0.00033992388166047423
Trained batch 18 in epoch 6, gen_loss = 1.0184670090675354, disc_loss = 0.000349120386281835
Trained batch 19 in epoch 6, gen_loss = 1.0175044417381287, disc_loss = 0.00035019271963392383
Trained batch 20 in epoch 6, gen_loss = 1.0221383344559443, disc_loss = 0.00035120939095837196
Trained batch 21 in epoch 6, gen_loss = 1.0200645056637851, disc_loss = 0.0003559604129722257
Trained batch 22 in epoch 6, gen_loss = 1.0227565350739851, disc_loss = 0.0003652204993514992
Trained batch 23 in epoch 6, gen_loss = 1.0258045295874278, disc_loss = 0.0003811545836166867
Trained batch 24 in epoch 6, gen_loss = 1.0255893087387085, disc_loss = 0.0004018877033377066
Trained batch 25 in epoch 6, gen_loss = 1.0249722324884856, disc_loss = 0.00041821737865505455
Trained batch 26 in epoch 6, gen_loss = 1.0259484935689855, disc_loss = 0.00043156228073510446
Trained batch 27 in epoch 6, gen_loss = 1.0288435518741608, disc_loss = 0.00044367497165304873
Trained batch 28 in epoch 6, gen_loss = 1.0288541234772781, disc_loss = 0.00045641573950857054
Trained batch 29 in epoch 6, gen_loss = 1.0277764638264975, disc_loss = 0.00047236660854347673
Trained batch 30 in epoch 6, gen_loss = 1.0236092305952502, disc_loss = 0.000487476073284333
Trained batch 31 in epoch 6, gen_loss = 1.0231660343706608, disc_loss = 0.0004982725190529891
Trained batch 32 in epoch 6, gen_loss = 1.0243295611757222, disc_loss = 0.0005034016305051574
Trained batch 33 in epoch 6, gen_loss = 1.0247105570400463, disc_loss = 0.0005049714018241502
Trained batch 34 in epoch 6, gen_loss = 1.0245292833873203, disc_loss = 0.000504118947927574
Trained batch 35 in epoch 6, gen_loss = 1.0219372378455267, disc_loss = 0.000501403533740409
Trained batch 36 in epoch 6, gen_loss = 1.0242169096663192, disc_loss = 0.000497634757413982
Trained batch 37 in epoch 6, gen_loss = 1.0248593374302513, disc_loss = 0.0004916604394613961
Trained batch 38 in epoch 6, gen_loss = 1.0237020972447517, disc_loss = 0.0004846755167445502
Trained batch 39 in epoch 6, gen_loss = 1.0254614248871803, disc_loss = 0.000477975085232174
Trained batch 40 in epoch 6, gen_loss = 1.0277843722483007, disc_loss = 0.0004730991048102335
Trained batch 41 in epoch 6, gen_loss = 1.0288893168880826, disc_loss = 0.0004688057330592225
Trained batch 42 in epoch 6, gen_loss = 1.0276085872982823, disc_loss = 0.0004649241509045972
Trained batch 43 in epoch 6, gen_loss = 1.0272841087796472, disc_loss = 0.00046036460579753936
Trained batch 44 in epoch 6, gen_loss = 1.0277644753456117, disc_loss = 0.000454840893831311
Trained batch 45 in epoch 6, gen_loss = 1.027151230884635, disc_loss = 0.00044877042882549375
Trained batch 46 in epoch 6, gen_loss = 1.0262229506005631, disc_loss = 0.00044356523443290846
Trained batch 47 in epoch 6, gen_loss = 1.0270817366739113, disc_loss = 0.0004394407939495674
Trained batch 48 in epoch 6, gen_loss = 1.027859779036775, disc_loss = 0.0004359961716619757
Trained batch 49 in epoch 6, gen_loss = 1.0269147169589996, disc_loss = 0.00043198413331992926
Trained batch 50 in epoch 6, gen_loss = 1.0240445487639482, disc_loss = 0.0004319986220056593
Trained batch 51 in epoch 6, gen_loss = 1.0233717262744904, disc_loss = 0.0004359395584637801
Trained batch 52 in epoch 6, gen_loss = 1.0214363201609198, disc_loss = 0.00043910495961032247
Trained batch 53 in epoch 6, gen_loss = 1.0222878456115723, disc_loss = 0.0004465007411824815
Trained batch 54 in epoch 6, gen_loss = 1.0224589304490523, disc_loss = 0.000451681885169819
Trained batch 55 in epoch 6, gen_loss = 1.0231860769646508, disc_loss = 0.0004541358601792516
Trained batch 56 in epoch 6, gen_loss = 1.022886269970944, disc_loss = 0.0004566977614447017
Trained batch 57 in epoch 6, gen_loss = 1.0221811111631065, disc_loss = 0.0004582948744867061
Trained batch 58 in epoch 6, gen_loss = 1.0219348517514892, disc_loss = 0.00045890604309595614
Trained batch 59 in epoch 6, gen_loss = 1.0214963803688686, disc_loss = 0.00045847506068336466
Trained batch 60 in epoch 6, gen_loss = 1.022804753702195, disc_loss = 0.00045719127443649606
Trained batch 61 in epoch 6, gen_loss = 1.0230242465772936, disc_loss = 0.000455800018126836
Trained batch 62 in epoch 6, gen_loss = 1.02271473691577, disc_loss = 0.00045366886871985143
Trained batch 63 in epoch 6, gen_loss = 1.0227709980681539, disc_loss = 0.0004505956799221167
Trained batch 64 in epoch 6, gen_loss = 1.0237699627876282, disc_loss = 0.00044658067860067465
Trained batch 65 in epoch 6, gen_loss = 1.024095333886869, disc_loss = 0.0004422777673233103
Trained batch 66 in epoch 6, gen_loss = 1.0243472118875874, disc_loss = 0.00043805365827726895
Trained batch 67 in epoch 6, gen_loss = 1.02514647648615, disc_loss = 0.0004340112692957251
Trained batch 68 in epoch 6, gen_loss = 1.0260585382364797, disc_loss = 0.0004304788476935979
Trained batch 69 in epoch 6, gen_loss = 1.0253954061440058, disc_loss = 0.0004279431059590674
Trained batch 70 in epoch 6, gen_loss = 1.0251610606489048, disc_loss = 0.0004276866253144042
Trained batch 71 in epoch 6, gen_loss = 1.0239488755663235, disc_loss = 0.0004323386686640636
Trained batch 72 in epoch 6, gen_loss = 1.02316298795073, disc_loss = 0.00044406198359043527
Trained batch 73 in epoch 6, gen_loss = 1.0226553493254893, disc_loss = 0.0004579692200373707
Trained batch 74 in epoch 6, gen_loss = 1.0234383130073548, disc_loss = 0.00046766509884037076
Trained batch 75 in epoch 6, gen_loss = 1.022686312857427, disc_loss = 0.0004739912474178709
Trained batch 76 in epoch 6, gen_loss = 1.0224766986710685, disc_loss = 0.0004810002060189795
Trained batch 77 in epoch 6, gen_loss = 1.02162505648075, disc_loss = 0.0004938882145021731
Trained batch 78 in epoch 6, gen_loss = 1.022191783295402, disc_loss = 0.0005108705258344689
Trained batch 79 in epoch 6, gen_loss = 1.0239014141261578, disc_loss = 0.0005249854057183256
Trained batch 80 in epoch 6, gen_loss = 1.0232049572614976, disc_loss = 0.0005304079792422047
Trained batch 81 in epoch 6, gen_loss = 1.0233376018884706, disc_loss = 0.0005317844238228778
Trained batch 82 in epoch 6, gen_loss = 1.0234869912446263, disc_loss = 0.0005329230338116232
Trained batch 83 in epoch 6, gen_loss = 1.02328617586976, disc_loss = 0.0005329017547496949
Trained batch 84 in epoch 6, gen_loss = 1.0230542947264278, disc_loss = 0.000530812528450042
Trained batch 85 in epoch 6, gen_loss = 1.022909091655598, disc_loss = 0.0005277751695884522
Trained batch 86 in epoch 6, gen_loss = 1.0231206410232632, disc_loss = 0.0005231535566660265
Trained batch 87 in epoch 6, gen_loss = 1.022079978476871, disc_loss = 0.00051969563702931
Trained batch 88 in epoch 6, gen_loss = 1.0225956506943434, disc_loss = 0.0005223366761844333
Trained batch 89 in epoch 6, gen_loss = 1.0220483693811628, disc_loss = 0.0005295150002994989
Trained batch 90 in epoch 6, gen_loss = 1.0214076015975448, disc_loss = 0.0005359800123407475
Trained batch 91 in epoch 6, gen_loss = 1.0232038770032965, disc_loss = 0.0005381292096938959
Trained batch 92 in epoch 6, gen_loss = 1.0227414939993171, disc_loss = 0.0005368486446421093
Trained batch 93 in epoch 6, gen_loss = 1.0231619407521917, disc_loss = 0.0005342252851287993
Trained batch 94 in epoch 6, gen_loss = 1.02268161459973, disc_loss = 0.0005319104347635354
Trained batch 95 in epoch 6, gen_loss = 1.0230347383767366, disc_loss = 0.0005310019585825406
Trained batch 96 in epoch 6, gen_loss = 1.0224847013188392, disc_loss = 0.0005311466885200154
Trained batch 97 in epoch 6, gen_loss = 1.0218873784250142, disc_loss = 0.0005302376626712764
Trained batch 98 in epoch 6, gen_loss = 1.021104051007165, disc_loss = 0.000528523919373666
Trained batch 99 in epoch 6, gen_loss = 1.021259543299675, disc_loss = 0.0005268901154340711
Trained batch 100 in epoch 6, gen_loss = 1.0210524543677226, disc_loss = 0.0005258871111292669
Trained batch 101 in epoch 6, gen_loss = 1.0207162312432831, disc_loss = 0.0005256212083908145
Trained batch 102 in epoch 6, gen_loss = 1.0206506263862536, disc_loss = 0.0005259142830590401
Trained batch 103 in epoch 6, gen_loss = 1.0208261024493437, disc_loss = 0.0005255918783334962
Trained batch 104 in epoch 6, gen_loss = 1.0209108840851557, disc_loss = 0.0005246890693559267
Trained batch 105 in epoch 6, gen_loss = 1.0209756043722045, disc_loss = 0.0005241008778816564
Trained batch 106 in epoch 6, gen_loss = 1.0216542415529768, disc_loss = 0.000524339020914816
Trained batch 107 in epoch 6, gen_loss = 1.0220428352002744, disc_loss = 0.0005249257747318889
Trained batch 108 in epoch 6, gen_loss = 1.022764833695298, disc_loss = 0.0005249004046605695
Trained batch 109 in epoch 6, gen_loss = 1.0229202779856594, disc_loss = 0.0005234712164647961
Trained batch 110 in epoch 6, gen_loss = 1.0227341727093533, disc_loss = 0.0005213563166074203
Trained batch 111 in epoch 6, gen_loss = 1.022726418716567, disc_loss = 0.0005182375802438141
Trained batch 112 in epoch 6, gen_loss = 1.022778651355642, disc_loss = 0.0005146233371121034
Trained batch 113 in epoch 6, gen_loss = 1.0229260869193495, disc_loss = 0.0005111433954944164
Trained batch 114 in epoch 6, gen_loss = 1.022713756042978, disc_loss = 0.0005076239035469884
Trained batch 115 in epoch 6, gen_loss = 1.0224709413174926, disc_loss = 0.0005039963880649181
Trained batch 116 in epoch 6, gen_loss = 1.0217185723475921, disc_loss = 0.0005005039484886867
Trained batch 117 in epoch 6, gen_loss = 1.0228196230985351, disc_loss = 0.0004975154103811877
Trained batch 118 in epoch 6, gen_loss = 1.0225405041911022, disc_loss = 0.0004956997137863049
Trained batch 119 in epoch 6, gen_loss = 1.021555246412754, disc_loss = 0.0004952230368265494
Trained batch 120 in epoch 6, gen_loss = 1.0217576179622618, disc_loss = 0.0004948919201471788
Trained batch 121 in epoch 6, gen_loss = 1.022263555741701, disc_loss = 0.0004939610572945953
Trained batch 122 in epoch 6, gen_loss = 1.0226395658361234, disc_loss = 0.0004923760355497537
Trained batch 123 in epoch 6, gen_loss = 1.022545646755926, disc_loss = 0.0004904173677665137
Trained batch 124 in epoch 6, gen_loss = 1.0224382891654968, disc_loss = 0.00048822153173387053
Trained batch 125 in epoch 6, gen_loss = 1.0215214722686343, disc_loss = 0.0004862231195032124
Trained batch 126 in epoch 6, gen_loss = 1.0214794353237302, disc_loss = 0.00048417971615210236
Trained batch 127 in epoch 6, gen_loss = 1.0216279695741832, disc_loss = 0.00048221960139471776
Trained batch 128 in epoch 6, gen_loss = 1.021122976791027, disc_loss = 0.00048020127752359035
Trained batch 129 in epoch 6, gen_loss = 1.0210028730905973, disc_loss = 0.00047817775149059554
Trained batch 130 in epoch 6, gen_loss = 1.0204390087200486, disc_loss = 0.0004757671196632201
Trained batch 131 in epoch 6, gen_loss = 1.0206606740301305, disc_loss = 0.0004731492632400301
Trained batch 132 in epoch 6, gen_loss = 1.0205178180135281, disc_loss = 0.0004706193850099116
Trained batch 133 in epoch 6, gen_loss = 1.0202180276166146, disc_loss = 0.00046827027814396756
Trained batch 134 in epoch 6, gen_loss = 1.0198101886996516, disc_loss = 0.0004658589711956059
Trained batch 135 in epoch 6, gen_loss = 1.0202803484657232, disc_loss = 0.00046369543259275174
Trained batch 136 in epoch 6, gen_loss = 1.0206351458591267, disc_loss = 0.0004624110406704832
Trained batch 137 in epoch 6, gen_loss = 1.0207757159419681, disc_loss = 0.0004615827360860261
Trained batch 138 in epoch 6, gen_loss = 1.020800709295616, disc_loss = 0.000460594477615212
Trained batch 139 in epoch 6, gen_loss = 1.0208451445613589, disc_loss = 0.00045907309405655335
Trained batch 140 in epoch 6, gen_loss = 1.020833416610745, disc_loss = 0.0004570529478724306
Trained batch 141 in epoch 6, gen_loss = 1.0210093045738382, disc_loss = 0.00045470586255632185
Trained batch 142 in epoch 6, gen_loss = 1.0209041612965244, disc_loss = 0.0004523985209578479
Trained batch 143 in epoch 6, gen_loss = 1.021437845710251, disc_loss = 0.00045016097808709473
Trained batch 144 in epoch 6, gen_loss = 1.021182275229487, disc_loss = 0.00044794306480165185
Trained batch 145 in epoch 6, gen_loss = 1.0213271293738118, disc_loss = 0.0004463020722303629
Trained batch 146 in epoch 6, gen_loss = 1.0214771474299789, disc_loss = 0.00044500203116172864
Trained batch 147 in epoch 6, gen_loss = 1.0216279348006119, disc_loss = 0.0004436542163799655
Trained batch 148 in epoch 6, gen_loss = 1.0218337866283904, disc_loss = 0.0004417716082882436
Trained batch 149 in epoch 6, gen_loss = 1.0218681530157725, disc_loss = 0.0004394369333749637
Trained batch 150 in epoch 6, gen_loss = 1.0220523673967021, disc_loss = 0.00043705618852211335
Trained batch 151 in epoch 6, gen_loss = 1.0219714206300283, disc_loss = 0.00043481703855114144
Trained batch 152 in epoch 6, gen_loss = 1.022115734277987, disc_loss = 0.0004328429528030421
Trained batch 153 in epoch 6, gen_loss = 1.0224528595224602, disc_loss = 0.00043234999521972624
Trained batch 154 in epoch 6, gen_loss = 1.0221130705648853, disc_loss = 0.0004323601802987527
Trained batch 155 in epoch 6, gen_loss = 1.0221296071242063, disc_loss = 0.00043149236812612985
Trained batch 156 in epoch 6, gen_loss = 1.022019130788791, disc_loss = 0.0004298050976769886
Trained batch 157 in epoch 6, gen_loss = 1.0212372054782095, disc_loss = 0.0004282730327689979
Trained batch 158 in epoch 6, gen_loss = 1.0213036023595798, disc_loss = 0.00042718071981996545
Trained batch 159 in epoch 6, gen_loss = 1.0211177058517933, disc_loss = 0.000426562868824476
Trained batch 160 in epoch 6, gen_loss = 1.0212839242094052, disc_loss = 0.00042610187254309574
Trained batch 161 in epoch 6, gen_loss = 1.0216611336778711, disc_loss = 0.00042593259983990676
Trained batch 162 in epoch 6, gen_loss = 1.0219763356483786, disc_loss = 0.0004258863881899564
Trained batch 163 in epoch 6, gen_loss = 1.0219812749362573, disc_loss = 0.00042604310506359934
Trained batch 164 in epoch 6, gen_loss = 1.0221625284715132, disc_loss = 0.0004266982880918394
Trained batch 165 in epoch 6, gen_loss = 1.0221600317093262, disc_loss = 0.00042763188610544866
Trained batch 166 in epoch 6, gen_loss = 1.0222565035620135, disc_loss = 0.0004287366361882186
Trained batch 167 in epoch 6, gen_loss = 1.0221514396724247, disc_loss = 0.00043011107832821187
Trained batch 168 in epoch 6, gen_loss = 1.0227904185740906, disc_loss = 0.000431591480980371
Trained batch 169 in epoch 6, gen_loss = 1.022681639474981, disc_loss = 0.00043288855269886826
Trained batch 170 in epoch 6, gen_loss = 1.022093477304916, disc_loss = 0.00043341704125669973
Trained batch 171 in epoch 6, gen_loss = 1.0220930610978327, disc_loss = 0.00043296496872688634
Trained batch 172 in epoch 6, gen_loss = 1.0221168705493728, disc_loss = 0.00043201714259003037
Trained batch 173 in epoch 6, gen_loss = 1.021891337701644, disc_loss = 0.00043085433960719647
Trained batch 174 in epoch 6, gen_loss = 1.0225420243399483, disc_loss = 0.00042994275252567605
Trained batch 175 in epoch 6, gen_loss = 1.0223821377889677, disc_loss = 0.00042994118976738804
Trained batch 176 in epoch 6, gen_loss = 1.0223019018685078, disc_loss = 0.00043102346177674607
Trained batch 177 in epoch 6, gen_loss = 1.022174728385518, disc_loss = 0.0004329061402734552
Trained batch 178 in epoch 6, gen_loss = 1.0219558960232655, disc_loss = 0.00043522955893828956
Trained batch 179 in epoch 6, gen_loss = 1.022345092230373, disc_loss = 0.00043759716496020296
Trained batch 180 in epoch 6, gen_loss = 1.021956878143121, disc_loss = 0.00043947136479665304
Trained batch 181 in epoch 6, gen_loss = 1.0217290668042152, disc_loss = 0.00044072045016986484
Trained batch 182 in epoch 6, gen_loss = 1.0219988441858134, disc_loss = 0.0004417569009708673
Trained batch 183 in epoch 6, gen_loss = 1.022003704762977, disc_loss = 0.00044274172816348374
Trained batch 184 in epoch 6, gen_loss = 1.0218908912426716, disc_loss = 0.0004430765949576665
Trained batch 185 in epoch 6, gen_loss = 1.021502209286536, disc_loss = 0.0004427066444521344
Trained batch 186 in epoch 6, gen_loss = 1.0210904714895441, disc_loss = 0.0004418046559741905
Trained batch 187 in epoch 6, gen_loss = 1.0213556869867, disc_loss = 0.0004407177569559513
Trained batch 188 in epoch 6, gen_loss = 1.020813477733148, disc_loss = 0.0004395386052829775
Trained batch 189 in epoch 6, gen_loss = 1.0209445790240639, disc_loss = 0.0004382623353050899
Trained batch 190 in epoch 6, gen_loss = 1.020899600383499, disc_loss = 0.00043730855506024426
Trained batch 191 in epoch 6, gen_loss = 1.0205852913980682, disc_loss = 0.00043667712100159406
Trained batch 192 in epoch 6, gen_loss = 1.0205739449342914, disc_loss = 0.000436110428461764
Trained batch 193 in epoch 6, gen_loss = 1.020626770159633, disc_loss = 0.0004355526350654023
Trained batch 194 in epoch 6, gen_loss = 1.020656836644197, disc_loss = 0.00043475708744387167
Trained batch 195 in epoch 6, gen_loss = 1.0206404148924106, disc_loss = 0.0004338087148091884
Trained batch 196 in epoch 6, gen_loss = 1.0203770383965545, disc_loss = 0.00043284643463155744
Trained batch 197 in epoch 6, gen_loss = 1.0197148940177878, disc_loss = 0.00043246096611990724
Trained batch 198 in epoch 6, gen_loss = 1.0198853516099442, disc_loss = 0.000432698062792755
Trained batch 199 in epoch 6, gen_loss = 1.0195175164937973, disc_loss = 0.00043273172439512565
Trained batch 200 in epoch 6, gen_loss = 1.0194436792117447, disc_loss = 0.0004327550148681172
Trained batch 201 in epoch 6, gen_loss = 1.019363012644324, disc_loss = 0.00043241979823289853
Trained batch 202 in epoch 6, gen_loss = 1.0194157238664299, disc_loss = 0.00043162578536086287
Trained batch 203 in epoch 6, gen_loss = 1.019620536589155, disc_loss = 0.000430402306329936
Trained batch 204 in epoch 6, gen_loss = 1.0203035843081592, disc_loss = 0.0004290839009449772
Trained batch 205 in epoch 6, gen_loss = 1.0204359674916683, disc_loss = 0.0004275585765268278
Trained batch 206 in epoch 6, gen_loss = 1.0201446750889653, disc_loss = 0.0004260427364067215
Trained batch 207 in epoch 6, gen_loss = 1.0205346695505655, disc_loss = 0.0004249742395096781
Trained batch 208 in epoch 6, gen_loss = 1.0206383232865037, disc_loss = 0.0004240726368639921
Trained batch 209 in epoch 6, gen_loss = 1.0202849305811383, disc_loss = 0.0004229026915189544
Trained batch 210 in epoch 6, gen_loss = 1.0202836693745654, disc_loss = 0.0004215022855657881
Trained batch 211 in epoch 6, gen_loss = 1.020353522784305, disc_loss = 0.00042010588539305216
Trained batch 212 in epoch 6, gen_loss = 1.0205322551615361, disc_loss = 0.0004187339851649111
Trained batch 213 in epoch 6, gen_loss = 1.0204806208053483, disc_loss = 0.0004173853131616053
Trained batch 214 in epoch 6, gen_loss = 1.0201785289964012, disc_loss = 0.0004160762093094892
Trained batch 215 in epoch 6, gen_loss = 1.0202617388632562, disc_loss = 0.000415123352299647
Trained batch 216 in epoch 6, gen_loss = 1.0201733494134542, disc_loss = 0.00041379838649983935
Trained batch 217 in epoch 6, gen_loss = 1.0201028309284, disc_loss = 0.00041237990017430303
Trained batch 218 in epoch 6, gen_loss = 1.0202792216109358, disc_loss = 0.0004108678433910165
Trained batch 219 in epoch 6, gen_loss = 1.0204855309291319, disc_loss = 0.0004094485638316573
Trained batch 220 in epoch 6, gen_loss = 1.0203670853942768, disc_loss = 0.00040815868495928747
Trained batch 221 in epoch 6, gen_loss = 1.0206181060623478, disc_loss = 0.00040689453430581827
Trained batch 222 in epoch 6, gen_loss = 1.0202678618409708, disc_loss = 0.00040547157612455916
Trained batch 223 in epoch 6, gen_loss = 1.0199499146214552, disc_loss = 0.0004039892187717799
Trained batch 224 in epoch 6, gen_loss = 1.0202499749925402, disc_loss = 0.0004027754436053025
Trained batch 225 in epoch 6, gen_loss = 1.0201805624286686, disc_loss = 0.0004016516107354474
Trained batch 226 in epoch 6, gen_loss = 1.0201508494725837, disc_loss = 0.00040058045076090423
Trained batch 227 in epoch 6, gen_loss = 1.020641245862894, disc_loss = 0.0003994488699646083
Trained batch 228 in epoch 6, gen_loss = 1.020663295250272, disc_loss = 0.00039821764370746805
Trained batch 229 in epoch 6, gen_loss = 1.0208883591320204, disc_loss = 0.00039706858195764336
Trained batch 230 in epoch 6, gen_loss = 1.0208429944463622, disc_loss = 0.0003957325243706073
Trained batch 231 in epoch 6, gen_loss = 1.0207742046693276, disc_loss = 0.00039434406203483753
Trained batch 232 in epoch 6, gen_loss = 1.0207372187544859, disc_loss = 0.00039292637400789777
Trained batch 233 in epoch 6, gen_loss = 1.0207877464783497, disc_loss = 0.00039154890349829313
Trained batch 234 in epoch 6, gen_loss = 1.0204516661928056, disc_loss = 0.0003908820266394499
Trained batch 235 in epoch 6, gen_loss = 1.0208800291105853, disc_loss = 0.0003903752186812137
Trained batch 236 in epoch 6, gen_loss = 1.0208730835954851, disc_loss = 0.00038957497332675405
Trained batch 237 in epoch 6, gen_loss = 1.0207157322839528, disc_loss = 0.00038892566104137787
Trained batch 238 in epoch 6, gen_loss = 1.020925539557405, disc_loss = 0.00038839932837987233
Trained batch 239 in epoch 6, gen_loss = 1.020959430684646, disc_loss = 0.0003877428695583755
Trained batch 240 in epoch 6, gen_loss = 1.0207860514336107, disc_loss = 0.0003869371609815447
Trained batch 241 in epoch 6, gen_loss = 1.0207809086673516, disc_loss = 0.0003863839838006303
Trained batch 242 in epoch 6, gen_loss = 1.0209232186093742, disc_loss = 0.0003861169512944158
Trained batch 243 in epoch 6, gen_loss = 1.0205751320377725, disc_loss = 0.0003860989988320622
Trained batch 244 in epoch 6, gen_loss = 1.0207967062385714, disc_loss = 0.00038602229650845106
Trained batch 245 in epoch 6, gen_loss = 1.021105289943819, disc_loss = 0.0003854008815043068
Trained batch 246 in epoch 6, gen_loss = 1.020623470848871, disc_loss = 0.0003848955279587568
Trained batch 247 in epoch 6, gen_loss = 1.020583106865806, disc_loss = 0.00038416783131505063
Trained batch 248 in epoch 6, gen_loss = 1.020497220347684, disc_loss = 0.0003834042819001783
Trained batch 249 in epoch 6, gen_loss = 1.020662249326706, disc_loss = 0.00038300815259572116
Trained batch 250 in epoch 6, gen_loss = 1.0205221453985844, disc_loss = 0.0003828883960247559
Trained batch 251 in epoch 6, gen_loss = 1.0202391764947347, disc_loss = 0.00038286709824451317
Trained batch 252 in epoch 6, gen_loss = 1.0204061776281816, disc_loss = 0.0003824827266790768
Trained batch 253 in epoch 6, gen_loss = 1.020647564976234, disc_loss = 0.0003817406823073961
Trained batch 254 in epoch 6, gen_loss = 1.0208855785575568, disc_loss = 0.0003810221583847249
Trained batch 255 in epoch 6, gen_loss = 1.0210419099312276, disc_loss = 0.00038052149341183394
Trained batch 256 in epoch 6, gen_loss = 1.0212015138525907, disc_loss = 0.00038036965329747225
Trained batch 257 in epoch 6, gen_loss = 1.0210747157418452, disc_loss = 0.0003804561519379865
Trained batch 258 in epoch 6, gen_loss = 1.0213467437328059, disc_loss = 0.0003808039350886416
Trained batch 259 in epoch 6, gen_loss = 1.0210525716726597, disc_loss = 0.0003809997050736386
Trained batch 260 in epoch 6, gen_loss = 1.0209304905029093, disc_loss = 0.00038119205171099625
Trained batch 261 in epoch 6, gen_loss = 1.0206750856556055, disc_loss = 0.00038169919871298584
Trained batch 262 in epoch 6, gen_loss = 1.0208248201431884, disc_loss = 0.0003825748724838145
Trained batch 263 in epoch 6, gen_loss = 1.0208967240019278, disc_loss = 0.00038386234342452195
Trained batch 264 in epoch 6, gen_loss = 1.0211026085997528, disc_loss = 0.00038470091399262255
Trained batch 265 in epoch 6, gen_loss = 1.0210622560260887, disc_loss = 0.0003851177326239001
Trained batch 266 in epoch 6, gen_loss = 1.0210774509647813, disc_loss = 0.00038539171907771725
Trained batch 267 in epoch 6, gen_loss = 1.0208601282158893, disc_loss = 0.0003852262395154337
Trained batch 268 in epoch 6, gen_loss = 1.0207751169523784, disc_loss = 0.000384568413717371
Trained batch 269 in epoch 6, gen_loss = 1.0209036045604283, disc_loss = 0.00038366480390929306
Trained batch 270 in epoch 6, gen_loss = 1.0210807275068277, disc_loss = 0.0003826860606934999
Trained batch 271 in epoch 6, gen_loss = 1.0208969539140953, disc_loss = 0.0003819014110002386
Trained batch 272 in epoch 6, gen_loss = 1.0210548453715258, disc_loss = 0.0003814995325628443
Trained batch 273 in epoch 6, gen_loss = 1.0215930418811576, disc_loss = 0.0003814063168043291
Trained batch 274 in epoch 6, gen_loss = 1.0216843065348538, disc_loss = 0.0003812306856376712
Trained batch 275 in epoch 6, gen_loss = 1.0217609247867612, disc_loss = 0.0003808697593753543
Trained batch 276 in epoch 6, gen_loss = 1.0217557657066234, disc_loss = 0.00038060251273936004
Trained batch 277 in epoch 6, gen_loss = 1.0217035033291193, disc_loss = 0.0003808457948239822
Trained batch 278 in epoch 6, gen_loss = 1.0215903161674418, disc_loss = 0.00038144392883329985
Trained batch 279 in epoch 6, gen_loss = 1.0214546190840856, disc_loss = 0.0003823331764579052
Trained batch 280 in epoch 6, gen_loss = 1.0218347557074658, disc_loss = 0.00038385925704929847
Trained batch 281 in epoch 6, gen_loss = 1.02147309873121, disc_loss = 0.00038587450001724
Trained batch 282 in epoch 6, gen_loss = 1.021696540155175, disc_loss = 0.0003884760308628178
Trained batch 283 in epoch 6, gen_loss = 1.021526468471742, disc_loss = 0.000390922116116919
Trained batch 284 in epoch 6, gen_loss = 1.0213944675629598, disc_loss = 0.00039441223055116113
Trained batch 285 in epoch 6, gen_loss = 1.0213425257406035, disc_loss = 0.0003988899736175919
Trained batch 286 in epoch 6, gen_loss = 1.0213113153022342, disc_loss = 0.0004034574570613735
Trained batch 287 in epoch 6, gen_loss = 1.0213847034093406, disc_loss = 0.00040704993560009624
Trained batch 288 in epoch 6, gen_loss = 1.0214806722934684, disc_loss = 0.0004097278757890119
Trained batch 289 in epoch 6, gen_loss = 1.0214950608796087, disc_loss = 0.0004112064918194062
Trained batch 290 in epoch 6, gen_loss = 1.0215730943630652, disc_loss = 0.0004117079126657406
Trained batch 291 in epoch 6, gen_loss = 1.0215286390013891, disc_loss = 0.0004118256707343254
Trained batch 292 in epoch 6, gen_loss = 1.0214890357577353, disc_loss = 0.00041142923690087825
Trained batch 293 in epoch 6, gen_loss = 1.02169488340008, disc_loss = 0.0004107458071983546
Trained batch 294 in epoch 6, gen_loss = 1.0213898038460036, disc_loss = 0.0004104215583183913
Trained batch 295 in epoch 6, gen_loss = 1.0216577949153411, disc_loss = 0.0004110201842539371
Trained batch 296 in epoch 6, gen_loss = 1.021520247965148, disc_loss = 0.00041263571436484013
Trained batch 297 in epoch 6, gen_loss = 1.0214291182940438, disc_loss = 0.0004146921645397564
Trained batch 298 in epoch 6, gen_loss = 1.021281338455685, disc_loss = 0.00041626171578994226
Trained batch 299 in epoch 6, gen_loss = 1.0212342576185862, disc_loss = 0.00041704660946076426
Trained batch 300 in epoch 6, gen_loss = 1.0213506011867841, disc_loss = 0.00041721712141738667
Trained batch 301 in epoch 6, gen_loss = 1.0214877981223807, disc_loss = 0.00041715220906902783
Trained batch 302 in epoch 6, gen_loss = 1.0215993399667267, disc_loss = 0.0004167811099917047
Trained batch 303 in epoch 6, gen_loss = 1.0213308052012795, disc_loss = 0.00041614277386926054
Trained batch 304 in epoch 6, gen_loss = 1.0214116237202628, disc_loss = 0.00041559311207269364
Trained batch 305 in epoch 6, gen_loss = 1.0211816461257686, disc_loss = 0.00041504101900975796
Trained batch 306 in epoch 6, gen_loss = 1.0212058325932158, disc_loss = 0.0004142845893321947
Trained batch 307 in epoch 6, gen_loss = 1.0214203650301152, disc_loss = 0.0004135678028941076
Trained batch 308 in epoch 6, gen_loss = 1.0211234806424978, disc_loss = 0.0004127210484682748
Trained batch 309 in epoch 6, gen_loss = 1.021335381461728, disc_loss = 0.00041177780747661487
Trained batch 310 in epoch 6, gen_loss = 1.021319453355967, disc_loss = 0.0004109268790182816
Trained batch 311 in epoch 6, gen_loss = 1.0214528819689384, disc_loss = 0.0004101294639556914
Trained batch 312 in epoch 6, gen_loss = 1.0215468745642957, disc_loss = 0.00040932931977632147
Trained batch 313 in epoch 6, gen_loss = 1.021554176594801, disc_loss = 0.00040845203607871083
Trained batch 314 in epoch 6, gen_loss = 1.021585778962998, disc_loss = 0.00040742683326936373
Trained batch 315 in epoch 6, gen_loss = 1.021486148804049, disc_loss = 0.0004063728205829084
Trained batch 316 in epoch 6, gen_loss = 1.0217286848495435, disc_loss = 0.0004053315250263608
Trained batch 317 in epoch 6, gen_loss = 1.021950382856453, disc_loss = 0.0004042554423189209
Trained batch 318 in epoch 6, gen_loss = 1.0219297965865897, disc_loss = 0.0004031948694752363
Trained batch 319 in epoch 6, gen_loss = 1.0216791108250618, disc_loss = 0.0004024548339884859
Trained batch 320 in epoch 6, gen_loss = 1.0215702249996388, disc_loss = 0.00040195752017296464
Trained batch 321 in epoch 6, gen_loss = 1.0215051285228374, disc_loss = 0.0004015603433415563
Trained batch 322 in epoch 6, gen_loss = 1.0216326728324772, disc_loss = 0.0004010467082790053
Trained batch 323 in epoch 6, gen_loss = 1.0215393564215414, disc_loss = 0.0004003795608168505
Trained batch 324 in epoch 6, gen_loss = 1.021907901947315, disc_loss = 0.0003999189343169117
Trained batch 325 in epoch 6, gen_loss = 1.0218988084719955, disc_loss = 0.0003997971682691092
Trained batch 326 in epoch 6, gen_loss = 1.02179138212029, disc_loss = 0.000399828557052688
Trained batch 327 in epoch 6, gen_loss = 1.0217668761203929, disc_loss = 0.00039977660497509244
Trained batch 328 in epoch 6, gen_loss = 1.0216942507445268, disc_loss = 0.0003993746597083826
Trained batch 329 in epoch 6, gen_loss = 1.0217835252935237, disc_loss = 0.0003986731289125711
Trained batch 330 in epoch 6, gen_loss = 1.021696821980606, disc_loss = 0.0003978161271979816
Trained batch 331 in epoch 6, gen_loss = 1.0215039569211293, disc_loss = 0.00039694470797257964
Trained batch 332 in epoch 6, gen_loss = 1.0220352651120663, disc_loss = 0.0003963387182131675
Trained batch 333 in epoch 6, gen_loss = 1.0224194922846948, disc_loss = 0.0003957712473558655
Trained batch 334 in epoch 6, gen_loss = 1.0225288732727962, disc_loss = 0.0003948635599791392
Trained batch 335 in epoch 6, gen_loss = 1.0225610850112778, disc_loss = 0.000393868957947537
Trained batch 336 in epoch 6, gen_loss = 1.0223759303107105, disc_loss = 0.00039300937738619504
Trained batch 337 in epoch 6, gen_loss = 1.0225228967045892, disc_loss = 0.0003925760871887974
Trained batch 338 in epoch 6, gen_loss = 1.022711475338556, disc_loss = 0.00039223440138152306
Trained batch 339 in epoch 6, gen_loss = 1.0228645296657786, disc_loss = 0.0003916104311429081
Trained batch 340 in epoch 6, gen_loss = 1.023087876982703, disc_loss = 0.0003908705478077488
Trained batch 341 in epoch 6, gen_loss = 1.0230060843696371, disc_loss = 0.0003901714136983487
Trained batch 342 in epoch 6, gen_loss = 1.0226960891189798, disc_loss = 0.00038955584607324996
Trained batch 343 in epoch 6, gen_loss = 1.022401515481084, disc_loss = 0.000389160522572215
Trained batch 344 in epoch 6, gen_loss = 1.0223613203435704, disc_loss = 0.0003892229708098044
Trained batch 345 in epoch 6, gen_loss = 1.0225412201330153, disc_loss = 0.00038966853132263175
Trained batch 346 in epoch 6, gen_loss = 1.022465008995375, disc_loss = 0.00039001267943881865
Trained batch 347 in epoch 6, gen_loss = 1.0226077637795745, disc_loss = 0.0003900916013642028
Trained batch 348 in epoch 6, gen_loss = 1.0226907506371636, disc_loss = 0.000390116797829261
Trained batch 349 in epoch 6, gen_loss = 1.0226680913993291, disc_loss = 0.00039017925588788265
Trained batch 350 in epoch 6, gen_loss = 1.0225230131054197, disc_loss = 0.0003901978494090186
Trained batch 351 in epoch 6, gen_loss = 1.0224188335917213, disc_loss = 0.00039023336120697587
Trained batch 352 in epoch 6, gen_loss = 1.022115556781758, disc_loss = 0.0003904858684974753
Trained batch 353 in epoch 6, gen_loss = 1.0220021647585313, disc_loss = 0.00039129300434696476
Trained batch 354 in epoch 6, gen_loss = 1.0218383728618352, disc_loss = 0.00039215613137906036
Trained batch 355 in epoch 6, gen_loss = 1.0220439206348377, disc_loss = 0.00039287445151478935
Trained batch 356 in epoch 6, gen_loss = 1.021907802723369, disc_loss = 0.00039341246383501076
Trained batch 357 in epoch 6, gen_loss = 1.0217092058845072, disc_loss = 0.00039370149175362343
Trained batch 358 in epoch 6, gen_loss = 1.0216139340799166, disc_loss = 0.00039395392433363063
Trained batch 359 in epoch 6, gen_loss = 1.0216626576251453, disc_loss = 0.00039406812503431056
Trained batch 360 in epoch 6, gen_loss = 1.0217776996937484, disc_loss = 0.00039450740699059395
Trained batch 361 in epoch 6, gen_loss = 1.0218236833316845, disc_loss = 0.0003952689989774973
Trained batch 362 in epoch 6, gen_loss = 1.021783473898885, disc_loss = 0.00039608657260698947
Trained batch 363 in epoch 6, gen_loss = 1.0218693153871286, disc_loss = 0.0003967155712266653
Trained batch 364 in epoch 6, gen_loss = 1.0219530528538847, disc_loss = 0.0003967448242255072
Trained batch 365 in epoch 6, gen_loss = 1.0219328401844359, disc_loss = 0.00039654113157676813
Trained batch 366 in epoch 6, gen_loss = 1.0221483296529474, disc_loss = 0.0003962501492964298
Trained batch 367 in epoch 6, gen_loss = 1.0216772243704484, disc_loss = 0.00039639777670028866
Trained batch 368 in epoch 6, gen_loss = 1.0214877042990067, disc_loss = 0.0003974432553904324
Trained batch 369 in epoch 6, gen_loss = 1.0218488556307714, disc_loss = 0.0003991555786047389
Trained batch 370 in epoch 6, gen_loss = 1.0218884307097875, disc_loss = 0.00040089866763077777
Trained batch 371 in epoch 6, gen_loss = 1.0216647237539291, disc_loss = 0.0004023756121285416
Trained batch 372 in epoch 6, gen_loss = 1.0217846090288647, disc_loss = 0.00040345086752046613
Trained batch 373 in epoch 6, gen_loss = 1.0218186580879802, disc_loss = 0.00040405691243724633
Trained batch 374 in epoch 6, gen_loss = 1.0217158252398173, disc_loss = 0.0004049113675428089
Trained batch 375 in epoch 6, gen_loss = 1.0216151981594714, disc_loss = 0.00040671526996564043
Trained batch 376 in epoch 6, gen_loss = 1.0215463491270333, disc_loss = 0.0004094386249827746
Trained batch 377 in epoch 6, gen_loss = 1.0215117844639632, disc_loss = 0.0004128370004206084
Trained batch 378 in epoch 6, gen_loss = 1.0217419565510308, disc_loss = 0.0004167259209529014
Trained batch 379 in epoch 6, gen_loss = 1.021670756998815, disc_loss = 0.0004200933090702931
Trained batch 380 in epoch 6, gen_loss = 1.0217131481083046, disc_loss = 0.00042232086093403615
Trained batch 381 in epoch 6, gen_loss = 1.0214007164483294, disc_loss = 0.00042313914786616197
Trained batch 382 in epoch 6, gen_loss = 1.0216886214425607, disc_loss = 0.00042372111182797554
Trained batch 383 in epoch 6, gen_loss = 1.0217323469308515, disc_loss = 0.0004248879122409714
Trained batch 384 in epoch 6, gen_loss = 1.021903174728542, disc_loss = 0.00042622202597052014
Trained batch 385 in epoch 6, gen_loss = 1.0219146919682853, disc_loss = 0.00042737405334933786
Trained batch 386 in epoch 6, gen_loss = 1.0219060005451666, disc_loss = 0.00042791764125884007
Trained batch 387 in epoch 6, gen_loss = 1.021807721441554, disc_loss = 0.00042778609553089465
Trained batch 388 in epoch 6, gen_loss = 1.0215697096981549, disc_loss = 0.0004273561873401552
Trained batch 389 in epoch 6, gen_loss = 1.0215099294980368, disc_loss = 0.0004270306593706407
Trained batch 390 in epoch 6, gen_loss = 1.0214397317308295, disc_loss = 0.0004268464054219345
Trained batch 391 in epoch 6, gen_loss = 1.0213227793574333, disc_loss = 0.0004267792552517286
Trained batch 392 in epoch 6, gen_loss = 1.02143750557766, disc_loss = 0.00042669741827593204
Trained batch 393 in epoch 6, gen_loss = 1.0214511324003868, disc_loss = 0.0004265754261243347
Trained batch 394 in epoch 6, gen_loss = 1.0214293191704569, disc_loss = 0.0004264356917793762
Trained batch 395 in epoch 6, gen_loss = 1.0214011201051751, disc_loss = 0.00042635833756091845
Trained batch 396 in epoch 6, gen_loss = 1.02140588018696, disc_loss = 0.0004262041938565208
Trained batch 397 in epoch 6, gen_loss = 1.0214212679084222, disc_loss = 0.0004257593025695726
Trained batch 398 in epoch 6, gen_loss = 1.021567147925384, disc_loss = 0.00042514092712011013
Trained batch 399 in epoch 6, gen_loss = 1.0215018765628339, disc_loss = 0.00042468200947951115
Trained batch 400 in epoch 6, gen_loss = 1.0215862976048058, disc_loss = 0.0004245913191324714
Trained batch 401 in epoch 6, gen_loss = 1.0217551338435404, disc_loss = 0.00042446740721133755
Trained batch 402 in epoch 6, gen_loss = 1.0216417386573242, disc_loss = 0.0004238720291003697
Trained batch 403 in epoch 6, gen_loss = 1.0217370653506552, disc_loss = 0.0004232296865612256
Trained batch 404 in epoch 6, gen_loss = 1.021619835459156, disc_loss = 0.0004228900635940523
Trained batch 405 in epoch 6, gen_loss = 1.0215633325095248, disc_loss = 0.0004228837774574597
Trained batch 406 in epoch 6, gen_loss = 1.0215594913508441, disc_loss = 0.00042268484369807315
Trained batch 407 in epoch 6, gen_loss = 1.0214453127746488, disc_loss = 0.0004222728848528241
Trained batch 408 in epoch 6, gen_loss = 1.0216240170240984, disc_loss = 0.0004218441306492843
Trained batch 409 in epoch 6, gen_loss = 1.0215165961079482, disc_loss = 0.00042139447434193445
Trained batch 410 in epoch 6, gen_loss = 1.021364204059842, disc_loss = 0.0004209708241939714
Trained batch 411 in epoch 6, gen_loss = 1.0212921681045328, disc_loss = 0.0004204929765691507
Trained batch 412 in epoch 6, gen_loss = 1.0214214724720823, disc_loss = 0.00041992444418784803
Trained batch 413 in epoch 6, gen_loss = 1.021449846489994, disc_loss = 0.00041945967650506926
Trained batch 414 in epoch 6, gen_loss = 1.0212955207709806, disc_loss = 0.0004190565115391383
Trained batch 415 in epoch 6, gen_loss = 1.0214006889324923, disc_loss = 0.00041845740907739615
Trained batch 416 in epoch 6, gen_loss = 1.0212918374178221, disc_loss = 0.0004177508224014721
Trained batch 417 in epoch 6, gen_loss = 1.0216345031295666, disc_loss = 0.00041735222038060137
Trained batch 418 in epoch 6, gen_loss = 1.021679252883984, disc_loss = 0.00041739008730497744
Trained batch 419 in epoch 6, gen_loss = 1.0218074861026945, disc_loss = 0.00041741606509319916
Trained batch 420 in epoch 6, gen_loss = 1.0218682982859306, disc_loss = 0.0004170914085609136
Trained batch 421 in epoch 6, gen_loss = 1.0220202165192338, disc_loss = 0.00041665674942735666
Trained batch 422 in epoch 6, gen_loss = 1.0219927321652713, disc_loss = 0.0004161583446864128
Trained batch 423 in epoch 6, gen_loss = 1.021960438984745, disc_loss = 0.0004155306008146479
Trained batch 424 in epoch 6, gen_loss = 1.0222372599209055, disc_loss = 0.00041478017612997276
Trained batch 425 in epoch 6, gen_loss = 1.0220945527855778, disc_loss = 0.0004141412572577916
Trained batch 426 in epoch 6, gen_loss = 1.0221714040992969, disc_loss = 0.00041370408240122564
Trained batch 427 in epoch 6, gen_loss = 1.0221604919322183, disc_loss = 0.00041341306619428015
Trained batch 428 in epoch 6, gen_loss = 1.0221797939224955, disc_loss = 0.00041326814941718083
Trained batch 429 in epoch 6, gen_loss = 1.0222697906715925, disc_loss = 0.00041320772996736787
Trained batch 430 in epoch 6, gen_loss = 1.022426019135318, disc_loss = 0.0004130562627286269
Trained batch 431 in epoch 6, gen_loss = 1.0224952683956534, disc_loss = 0.0004128071633726062
Trained batch 432 in epoch 6, gen_loss = 1.0224430299521043, disc_loss = 0.00041263012913214073
Trained batch 433 in epoch 6, gen_loss = 1.0225319821164356, disc_loss = 0.00041307877880943057
Trained batch 434 in epoch 6, gen_loss = 1.0223318834414428, disc_loss = 0.0004134721625894014
Trained batch 435 in epoch 6, gen_loss = 1.0223702123952567, disc_loss = 0.00041374300621801596
Trained batch 436 in epoch 6, gen_loss = 1.0225683611645033, disc_loss = 0.00041380299917280776
Trained batch 437 in epoch 6, gen_loss = 1.0225482553107554, disc_loss = 0.0004137572875014771
Trained batch 438 in epoch 6, gen_loss = 1.0225375540435722, disc_loss = 0.0004136078220191873
Trained batch 439 in epoch 6, gen_loss = 1.0224202009764585, disc_loss = 0.0004132669704879597
Trained batch 440 in epoch 6, gen_loss = 1.0222047993115015, disc_loss = 0.000412735436146336
Trained batch 441 in epoch 6, gen_loss = 1.0220006195937885, disc_loss = 0.00041212625616042807
Trained batch 442 in epoch 6, gen_loss = 1.0220693415766644, disc_loss = 0.0004115556817834605
Trained batch 443 in epoch 6, gen_loss = 1.0218534229306486, disc_loss = 0.0004112551283912113
Trained batch 444 in epoch 6, gen_loss = 1.0215623160426537, disc_loss = 0.00041096355505922046
Trained batch 445 in epoch 6, gen_loss = 1.021620846249063, disc_loss = 0.0004104588703491079
Trained batch 446 in epoch 6, gen_loss = 1.0214753173608375, disc_loss = 0.00040974508042290227
Trained batch 447 in epoch 6, gen_loss = 1.0216322680935264, disc_loss = 0.0004091856969239416
Trained batch 448 in epoch 6, gen_loss = 1.021610138012731, disc_loss = 0.0004089212340795003
Trained batch 449 in epoch 6, gen_loss = 1.0216402791606056, disc_loss = 0.00040895437082023514
Trained batch 450 in epoch 6, gen_loss = 1.0218697171782178, disc_loss = 0.00040908356103381427
Trained batch 451 in epoch 6, gen_loss = 1.0219224676885437, disc_loss = 0.0004089819540160083
Trained batch 452 in epoch 6, gen_loss = 1.0217725055633529, disc_loss = 0.00040862600896955946
Trained batch 453 in epoch 6, gen_loss = 1.0215677947199817, disc_loss = 0.000408238250061745
Trained batch 454 in epoch 6, gen_loss = 1.021652488394098, disc_loss = 0.00040779295797200085
Trained batch 455 in epoch 6, gen_loss = 1.0215871190292793, disc_loss = 0.00040715812574968656
Trained batch 456 in epoch 6, gen_loss = 1.021398362758645, disc_loss = 0.00040649808553999944
Trained batch 457 in epoch 6, gen_loss = 1.0213483561594934, disc_loss = 0.0004058327904601066
Trained batch 458 in epoch 6, gen_loss = 1.0213838994892595, disc_loss = 0.00040510368310651854
Trained batch 459 in epoch 6, gen_loss = 1.021317463465359, disc_loss = 0.00040432436833172055
Trained batch 460 in epoch 6, gen_loss = 1.0212780520352263, disc_loss = 0.00040360174613640897
Trained batch 461 in epoch 6, gen_loss = 1.0213761377386201, disc_loss = 0.0004028994294832278
Trained batch 462 in epoch 6, gen_loss = 1.021457657829474, disc_loss = 0.00040219818981841846
Trained batch 463 in epoch 6, gen_loss = 1.0212786728195076, disc_loss = 0.00040156650459658555
Trained batch 464 in epoch 6, gen_loss = 1.0211343878058976, disc_loss = 0.00040103571294019527
Trained batch 465 in epoch 6, gen_loss = 1.0213781820346357, disc_loss = 0.0004005330719778593
Trained batch 466 in epoch 6, gen_loss = 1.0214374387034513, disc_loss = 0.00040002609527542963
Trained batch 467 in epoch 6, gen_loss = 1.0211069893378477, disc_loss = 0.00039945970553924423
Trained batch 468 in epoch 6, gen_loss = 1.0210449423617138, disc_loss = 0.00039905877607502986
Trained batch 469 in epoch 6, gen_loss = 1.0211321503558057, disc_loss = 0.0003985306896016056
Trained batch 470 in epoch 6, gen_loss = 1.021082209427139, disc_loss = 0.00039789444376755806
Trained batch 471 in epoch 6, gen_loss = 1.0210592544684975, disc_loss = 0.000397219228889915
Trained batch 472 in epoch 6, gen_loss = 1.0208237217798293, disc_loss = 0.00039655892329011654
Trained batch 473 in epoch 6, gen_loss = 1.0208234325491425, disc_loss = 0.00039602365651734533
Trained batch 474 in epoch 6, gen_loss = 1.0208816138066743, disc_loss = 0.0003955577716375333
Trained batch 475 in epoch 6, gen_loss = 1.021002580012594, disc_loss = 0.0003952051896122925
Trained batch 476 in epoch 6, gen_loss = 1.0209289841681906, disc_loss = 0.0003950762907657514
Trained batch 477 in epoch 6, gen_loss = 1.0210612358907276, disc_loss = 0.00039534713771036155
Trained batch 478 in epoch 6, gen_loss = 1.021003461083191, disc_loss = 0.0003959459586696391
Trained batch 479 in epoch 6, gen_loss = 1.0210640586912632, disc_loss = 0.0003966509794660548
Trained batch 480 in epoch 6, gen_loss = 1.0211133771031908, disc_loss = 0.0003971122175835924
Trained batch 481 in epoch 6, gen_loss = 1.0210466931469708, disc_loss = 0.0003972623635868274
Trained batch 482 in epoch 6, gen_loss = 1.0209684880377097, disc_loss = 0.00039719086669053543
Trained batch 483 in epoch 6, gen_loss = 1.021073100488048, disc_loss = 0.00039711617001024225
Trained batch 484 in epoch 6, gen_loss = 1.0210208167734833, disc_loss = 0.0003971438467506795
Trained batch 485 in epoch 6, gen_loss = 1.02109245581882, disc_loss = 0.00039737435276067953
Trained batch 486 in epoch 6, gen_loss = 1.021029821901106, disc_loss = 0.0003978770525988695
Trained batch 487 in epoch 6, gen_loss = 1.020866338835388, disc_loss = 0.00039855305589090215
Trained batch 488 in epoch 6, gen_loss = 1.020857360221613, disc_loss = 0.00039909829605404805
Trained batch 489 in epoch 6, gen_loss = 1.020778443861981, disc_loss = 0.0003992856257076599
Trained batch 490 in epoch 6, gen_loss = 1.0208997855118482, disc_loss = 0.0003991382713168229
Trained batch 491 in epoch 6, gen_loss = 1.0209295160886718, disc_loss = 0.00039894786562406925
Trained batch 492 in epoch 6, gen_loss = 1.0206744188469274, disc_loss = 0.0003988954455942519
Trained batch 493 in epoch 6, gen_loss = 1.0209876039491492, disc_loss = 0.0003987910450790959
Trained batch 494 in epoch 6, gen_loss = 1.0209709274648415, disc_loss = 0.00039860671223699814
Trained batch 495 in epoch 6, gen_loss = 1.0208901255842178, disc_loss = 0.00039835062737790484
Trained batch 496 in epoch 6, gen_loss = 1.0208579354602807, disc_loss = 0.00039802359786324747
Trained batch 497 in epoch 6, gen_loss = 1.0209498407850304, disc_loss = 0.0003976813914196685
Trained batch 498 in epoch 6, gen_loss = 1.020929231433448, disc_loss = 0.00039732548163568963
Trained batch 499 in epoch 6, gen_loss = 1.020896125793457, disc_loss = 0.00039699008056049936
Trained batch 500 in epoch 6, gen_loss = 1.0208572560917593, disc_loss = 0.0003965161246639242
Trained batch 501 in epoch 6, gen_loss = 1.0208340610165996, disc_loss = 0.0003960127696664276
Trained batch 502 in epoch 6, gen_loss = 1.021014838285048, disc_loss = 0.0003955450253343005
Trained batch 503 in epoch 6, gen_loss = 1.0210377890912314, disc_loss = 0.0003950567597784689
Trained batch 504 in epoch 6, gen_loss = 1.0209454715842068, disc_loss = 0.00039460830842715335
Trained batch 505 in epoch 6, gen_loss = 1.0209556042912449, disc_loss = 0.0003942497855734164
Trained batch 506 in epoch 6, gen_loss = 1.0210321107089402, disc_loss = 0.00039392727052996575
Trained batch 507 in epoch 6, gen_loss = 1.0208891071672515, disc_loss = 0.0003935551562611317
Trained batch 508 in epoch 6, gen_loss = 1.0208131186151785, disc_loss = 0.0003930982021536117
Trained batch 509 in epoch 6, gen_loss = 1.0207385544683418, disc_loss = 0.0003925317362468466
Trained batch 510 in epoch 6, gen_loss = 1.0206313324534497, disc_loss = 0.00039194778510278917
Trained batch 511 in epoch 6, gen_loss = 1.0205829408951104, disc_loss = 0.0003913570656592924
Trained batch 512 in epoch 6, gen_loss = 1.0206680843937002, disc_loss = 0.00039078818530360095
Trained batch 513 in epoch 6, gen_loss = 1.020595035896227, disc_loss = 0.0003902479756839464
Trained batch 514 in epoch 6, gen_loss = 1.0205909856314799, disc_loss = 0.00038977065216156526
Trained batch 515 in epoch 6, gen_loss = 1.0205829533957695, disc_loss = 0.0003893425152645525
Trained batch 516 in epoch 6, gen_loss = 1.0205012245150553, disc_loss = 0.00038890492791715043
Trained batch 517 in epoch 6, gen_loss = 1.020665703247873, disc_loss = 0.0003885206763041417
Trained batch 518 in epoch 6, gen_loss = 1.0207234929981488, disc_loss = 0.0003881793785841955
Trained batch 519 in epoch 6, gen_loss = 1.020629535156947, disc_loss = 0.0003878276061606392
Trained batch 520 in epoch 6, gen_loss = 1.0206807081850384, disc_loss = 0.0003874695791852068
Trained batch 521 in epoch 6, gen_loss = 1.0205758795199267, disc_loss = 0.0003871129126424818
Trained batch 522 in epoch 6, gen_loss = 1.0204673124544934, disc_loss = 0.00038675374747960684
Trained batch 523 in epoch 6, gen_loss = 1.0206554439914135, disc_loss = 0.00038630007230071306
Trained batch 524 in epoch 6, gen_loss = 1.0204853220213028, disc_loss = 0.0003858825203427668
Trained batch 525 in epoch 6, gen_loss = 1.020599041488234, disc_loss = 0.0003856870417299786
Trained batch 526 in epoch 6, gen_loss = 1.0205942377646011, disc_loss = 0.00038573217703014273
Trained batch 527 in epoch 6, gen_loss = 1.0205446509926608, disc_loss = 0.00038586980404585176
Trained batch 528 in epoch 6, gen_loss = 1.0206970033889007, disc_loss = 0.00038596649723063005
Trained batch 529 in epoch 6, gen_loss = 1.02067364847885, disc_loss = 0.0003858177468467851
Trained batch 530 in epoch 6, gen_loss = 1.0207774873731725, disc_loss = 0.00038548598598912246
Trained batch 531 in epoch 6, gen_loss = 1.0208036537681306, disc_loss = 0.00038510206622207016
Trained batch 532 in epoch 6, gen_loss = 1.020842857365313, disc_loss = 0.0003847307460528373
Trained batch 533 in epoch 6, gen_loss = 1.0207798979925307, disc_loss = 0.00038436227642000377
Trained batch 534 in epoch 6, gen_loss = 1.0208500807530412, disc_loss = 0.000383925186294712
Trained batch 535 in epoch 6, gen_loss = 1.0210127940596039, disc_loss = 0.0003834815787632212
Trained batch 536 in epoch 6, gen_loss = 1.0210932494319795, disc_loss = 0.00038311879237799633
Trained batch 537 in epoch 6, gen_loss = 1.021029251769573, disc_loss = 0.0003827627557547842
Trained batch 538 in epoch 6, gen_loss = 1.0210144540816821, disc_loss = 0.00038243245683408064
Trained batch 539 in epoch 6, gen_loss = 1.0209989974896112, disc_loss = 0.00038214146266168594
Trained batch 540 in epoch 6, gen_loss = 1.0210683179430513, disc_loss = 0.00038181561019499493
Trained batch 541 in epoch 6, gen_loss = 1.021171674187333, disc_loss = 0.000381511969315874
Trained batch 542 in epoch 6, gen_loss = 1.0212538276368521, disc_loss = 0.0003813103354352369
Trained batch 543 in epoch 6, gen_loss = 1.0212289299815893, disc_loss = 0.00038125849924680925
Trained batch 544 in epoch 6, gen_loss = 1.0212443330966003, disc_loss = 0.00038131491548500297
Trained batch 545 in epoch 6, gen_loss = 1.02127832425383, disc_loss = 0.00038142229504123176
Trained batch 546 in epoch 6, gen_loss = 1.0211485239661808, disc_loss = 0.00038158888939632507
Trained batch 547 in epoch 6, gen_loss = 1.0212700481179857, disc_loss = 0.00038193937172206337
Trained batch 548 in epoch 6, gen_loss = 1.0213115728835156, disc_loss = 0.00038243115516115473
Trained batch 549 in epoch 6, gen_loss = 1.021353160793131, disc_loss = 0.0003830327661324356
Trained batch 550 in epoch 6, gen_loss = 1.02120336787454, disc_loss = 0.0003838329361968766
Trained batch 551 in epoch 6, gen_loss = 1.0212199162097946, disc_loss = 0.00038456655216657015
Trained batch 552 in epoch 6, gen_loss = 1.0211051276751928, disc_loss = 0.0003851871911869877
Trained batch 553 in epoch 6, gen_loss = 1.0211212487642516, disc_loss = 0.00038574536550773893
Trained batch 554 in epoch 6, gen_loss = 1.0211357721337326, disc_loss = 0.000386337927580121
Trained batch 555 in epoch 6, gen_loss = 1.0210981979001341, disc_loss = 0.0003868920789533123
Trained batch 556 in epoch 6, gen_loss = 1.0210575351167197, disc_loss = 0.00038753346642001726
Trained batch 557 in epoch 6, gen_loss = 1.021127524128097, disc_loss = 0.00038854419527462503
Trained batch 558 in epoch 6, gen_loss = 1.0211715497782916, disc_loss = 0.00038978671303496043
Trained batch 559 in epoch 6, gen_loss = 1.021053640118667, disc_loss = 0.0003912802845336825
Trained batch 560 in epoch 6, gen_loss = 1.0208661264064265, disc_loss = 0.00039289861064172455
Trained batch 561 in epoch 6, gen_loss = 1.02099015226992, disc_loss = 0.0003939891524288826
Trained batch 562 in epoch 6, gen_loss = 1.020952761596727, disc_loss = 0.0003943401286921809
Trained batch 563 in epoch 6, gen_loss = 1.0210465707466112, disc_loss = 0.0003942866330833322
Trained batch 564 in epoch 6, gen_loss = 1.0210707811127722, disc_loss = 0.0003941140554274074
Trained batch 565 in epoch 6, gen_loss = 1.021078385965563, disc_loss = 0.00039393385891553116
Trained batch 566 in epoch 6, gen_loss = 1.021117281346094, disc_loss = 0.0003937290139749176
Trained batch 567 in epoch 6, gen_loss = 1.0213330462574959, disc_loss = 0.00039349751186434754
Trained batch 568 in epoch 6, gen_loss = 1.0213270211471195, disc_loss = 0.0003932936051313668
Trained batch 569 in epoch 6, gen_loss = 1.021375812041132, disc_loss = 0.0003931027271296204
Trained batch 570 in epoch 6, gen_loss = 1.0214336263945558, disc_loss = 0.0003929247648592108
Trained batch 571 in epoch 6, gen_loss = 1.0215467378184513, disc_loss = 0.0003927048780872235
Trained batch 572 in epoch 6, gen_loss = 1.021599226909158, disc_loss = 0.0003925096521896727
Trained batch 573 in epoch 6, gen_loss = 1.0215594028138948, disc_loss = 0.0003922129658935409
Trained batch 574 in epoch 6, gen_loss = 1.021442144020744, disc_loss = 0.0003919261592660484
Trained batch 575 in epoch 6, gen_loss = 1.0215252654420004, disc_loss = 0.0003916139364908607
Trained batch 576 in epoch 6, gen_loss = 1.021585597942359, disc_loss = 0.0003913472229660754
Trained batch 577 in epoch 6, gen_loss = 1.0214481261980988, disc_loss = 0.0003911110773965274
Trained batch 578 in epoch 6, gen_loss = 1.0213353815062265, disc_loss = 0.0003908683720447621
Trained batch 579 in epoch 6, gen_loss = 1.0213571301822004, disc_loss = 0.0003907240626584349
Trained batch 580 in epoch 6, gen_loss = 1.0215784994542292, disc_loss = 0.0003906826136159176
Trained batch 581 in epoch 6, gen_loss = 1.021662093519755, disc_loss = 0.00039048099601088224
Trained batch 582 in epoch 6, gen_loss = 1.0216424158466006, disc_loss = 0.0003903820248231141
Trained batch 583 in epoch 6, gen_loss = 1.0215733349323273, disc_loss = 0.0003904313080118748
Trained batch 584 in epoch 6, gen_loss = 1.0217489142703196, disc_loss = 0.000390379409086602
Trained batch 585 in epoch 6, gen_loss = 1.0217841975518054, disc_loss = 0.0003902283459843701
Trained batch 586 in epoch 6, gen_loss = 1.0217723858620482, disc_loss = 0.0003900643791251255
Trained batch 587 in epoch 6, gen_loss = 1.0217134403128203, disc_loss = 0.0003898078250972658
Trained batch 588 in epoch 6, gen_loss = 1.021835775853013, disc_loss = 0.00038949823332886237
Trained batch 589 in epoch 6, gen_loss = 1.0219293630729287, disc_loss = 0.000389218076729853
Trained batch 590 in epoch 6, gen_loss = 1.0220169504685248, disc_loss = 0.00038901856099545927
Trained batch 591 in epoch 6, gen_loss = 1.021944486913649, disc_loss = 0.00038877764818976546
Trained batch 592 in epoch 6, gen_loss = 1.0220844776795244, disc_loss = 0.00038847347950435426
Trained batch 593 in epoch 6, gen_loss = 1.0219903181899677, disc_loss = 0.0003883591378001345
Trained batch 594 in epoch 6, gen_loss = 1.0220664197657288, disc_loss = 0.0003887720786789804
Trained batch 595 in epoch 6, gen_loss = 1.0220004535161409, disc_loss = 0.0003897674299292434
Trained batch 596 in epoch 6, gen_loss = 1.022153284182301, disc_loss = 0.00039156430885947457
Trained batch 597 in epoch 6, gen_loss = 1.0221147531251047, disc_loss = 0.0003942066754504433
Trained batch 598 in epoch 6, gen_loss = 1.0221052975805853, disc_loss = 0.00039659705155179056
Trained batch 599 in epoch 6, gen_loss = 1.0220556647578876, disc_loss = 0.0003978193210969039
Trained batch 600 in epoch 6, gen_loss = 1.022111954090004, disc_loss = 0.00039812789163655855
Trained batch 601 in epoch 6, gen_loss = 1.0219831699350743, disc_loss = 0.00039803458000892003
Trained batch 602 in epoch 6, gen_loss = 1.0220891783881938, disc_loss = 0.00039784053197955123
Trained batch 603 in epoch 6, gen_loss = 1.0221696972649619, disc_loss = 0.0003975374392157753
Trained batch 604 in epoch 6, gen_loss = 1.0220695500531471, disc_loss = 0.0003972861314688382
Trained batch 605 in epoch 6, gen_loss = 1.022155664246468, disc_loss = 0.00039707851989294454
Trained batch 606 in epoch 6, gen_loss = 1.0221021210734886, disc_loss = 0.0003969323553713679
Trained batch 607 in epoch 6, gen_loss = 1.0221219923543303, disc_loss = 0.00039682850898483784
Trained batch 608 in epoch 6, gen_loss = 1.022128490978861, disc_loss = 0.00039668825682559835
Trained batch 609 in epoch 6, gen_loss = 1.0221098743501256, disc_loss = 0.0003964645822604519
Trained batch 610 in epoch 6, gen_loss = 1.0220390003168447, disc_loss = 0.0003962637070834971
Trained batch 611 in epoch 6, gen_loss = 1.022011469100036, disc_loss = 0.0003962013887775909
Trained batch 612 in epoch 6, gen_loss = 1.0220414352455887, disc_loss = 0.00039609809054458117
Trained batch 613 in epoch 6, gen_loss = 1.0219360078390725, disc_loss = 0.00039596140877709075
Trained batch 614 in epoch 6, gen_loss = 1.0218581452602293, disc_loss = 0.0003958325209538547
Trained batch 615 in epoch 6, gen_loss = 1.0218110524795272, disc_loss = 0.00039576257330583
Trained batch 616 in epoch 6, gen_loss = 1.021905099843271, disc_loss = 0.00039576004851435697
Trained batch 617 in epoch 6, gen_loss = 1.021880056769331, disc_loss = 0.0003956741336902169
Trained batch 618 in epoch 6, gen_loss = 1.0218906478658438, disc_loss = 0.0003955046015404453
Trained batch 619 in epoch 6, gen_loss = 1.0218872553879215, disc_loss = 0.00039534292846515347
Trained batch 620 in epoch 6, gen_loss = 1.0219690405228288, disc_loss = 0.0003951956984393832
Trained batch 621 in epoch 6, gen_loss = 1.021908861360366, disc_loss = 0.00039515213740736333
Trained batch 622 in epoch 6, gen_loss = 1.022151407900821, disc_loss = 0.00039527477291116474
Trained batch 623 in epoch 6, gen_loss = 1.0221588780673652, disc_loss = 0.00039547642291509896
Trained batch 624 in epoch 6, gen_loss = 1.0223124886512756, disc_loss = 0.0003955689708411228
Trained batch 625 in epoch 6, gen_loss = 1.0224509826673867, disc_loss = 0.0003955494246739703
Trained batch 626 in epoch 6, gen_loss = 1.022354947037674, disc_loss = 0.00039557427364772676
Trained batch 627 in epoch 6, gen_loss = 1.0224762582665037, disc_loss = 0.00039593888381506267
Trained batch 628 in epoch 6, gen_loss = 1.022398199584033, disc_loss = 0.0003965863236270098
Trained batch 629 in epoch 6, gen_loss = 1.0224623342355093, disc_loss = 0.00039712554672506584
Trained batch 630 in epoch 6, gen_loss = 1.0224131390145388, disc_loss = 0.0003975624207778713
Trained batch 631 in epoch 6, gen_loss = 1.0223261368802832, disc_loss = 0.0003979765105029827
Trained batch 632 in epoch 6, gen_loss = 1.0223067622237485, disc_loss = 0.00039830733099535784
Trained batch 633 in epoch 6, gen_loss = 1.022234717096064, disc_loss = 0.00039837798280769053
Trained batch 634 in epoch 6, gen_loss = 1.0221195970933268, disc_loss = 0.00039826223777866495
Trained batch 635 in epoch 6, gen_loss = 1.0221499990929597, disc_loss = 0.0003981444778099035
Trained batch 636 in epoch 6, gen_loss = 1.0221008834322356, disc_loss = 0.0003980653980838517
Trained batch 637 in epoch 6, gen_loss = 1.0219952081064445, disc_loss = 0.00039796999750981295
Trained batch 638 in epoch 6, gen_loss = 1.02199159970679, disc_loss = 0.0003977658189271583
Trained batch 639 in epoch 6, gen_loss = 1.0219256254844367, disc_loss = 0.00039746855633779885
Trained batch 640 in epoch 6, gen_loss = 1.021917832158099, disc_loss = 0.00039710322879856874
Trained batch 641 in epoch 6, gen_loss = 1.021840709763524, disc_loss = 0.00039662449640996
Trained batch 642 in epoch 6, gen_loss = 1.021942996311336, disc_loss = 0.0003961750195148668
Trained batch 643 in epoch 6, gen_loss = 1.0218717172649336, disc_loss = 0.0003956948873638562
Trained batch 644 in epoch 6, gen_loss = 1.0217510038568067, disc_loss = 0.00039520250532849215
Trained batch 645 in epoch 6, gen_loss = 1.0217112245574456, disc_loss = 0.00039472616481925067
Trained batch 646 in epoch 6, gen_loss = 1.0217440275725846, disc_loss = 0.00039434447848505966
Trained batch 647 in epoch 6, gen_loss = 1.021853611977012, disc_loss = 0.00039405595002172945
Trained batch 648 in epoch 6, gen_loss = 1.021802439711678, disc_loss = 0.0003937625250082125
Trained batch 649 in epoch 6, gen_loss = 1.0218364801773658, disc_loss = 0.00039344325583862464
Trained batch 650 in epoch 6, gen_loss = 1.0216536017423767, disc_loss = 0.00039313897921045856
Trained batch 651 in epoch 6, gen_loss = 1.0216409727656768, disc_loss = 0.00039285302075327613
Trained batch 652 in epoch 6, gen_loss = 1.0216375323751254, disc_loss = 0.00039265871074470153
Trained batch 653 in epoch 6, gen_loss = 1.0215566859150516, disc_loss = 0.00039250285561316303
Trained batch 654 in epoch 6, gen_loss = 1.0216330858587308, disc_loss = 0.0003924129751898821
Trained batch 655 in epoch 6, gen_loss = 1.021617729216814, disc_loss = 0.00039220922592060717
Trained batch 656 in epoch 6, gen_loss = 1.0216113650998386, disc_loss = 0.00039198037486526404
Trained batch 657 in epoch 6, gen_loss = 1.0215383528032564, disc_loss = 0.00039173067533956895
Trained batch 658 in epoch 6, gen_loss = 1.0216059365475123, disc_loss = 0.00039142352307367434
Trained batch 659 in epoch 6, gen_loss = 1.0216703376083662, disc_loss = 0.00039109054580352897
Trained batch 660 in epoch 6, gen_loss = 1.0216374146595666, disc_loss = 0.00039076012159200527
Trained batch 661 in epoch 6, gen_loss = 1.0217190431684167, disc_loss = 0.00039043075206807886
Trained batch 662 in epoch 6, gen_loss = 1.0216413606885333, disc_loss = 0.00039003304122364377
Trained batch 663 in epoch 6, gen_loss = 1.021638244929084, disc_loss = 0.00038960203108173854
Trained batch 664 in epoch 6, gen_loss = 1.021630731202606, disc_loss = 0.00038918912108428254
Trained batch 665 in epoch 6, gen_loss = 1.0216932661898501, disc_loss = 0.00038874521896877786
Trained batch 666 in epoch 6, gen_loss = 1.0217711273161905, disc_loss = 0.00038827430142865187
Trained batch 667 in epoch 6, gen_loss = 1.0216925585876682, disc_loss = 0.0003877882137873282
Trained batch 668 in epoch 6, gen_loss = 1.021816293844015, disc_loss = 0.0003873967722676307
Trained batch 669 in epoch 6, gen_loss = 1.022000134258128, disc_loss = 0.0003869755447326565
Trained batch 670 in epoch 6, gen_loss = 1.0221017703036437, disc_loss = 0.0003865734584870781
Trained batch 671 in epoch 6, gen_loss = 1.0221616387189854, disc_loss = 0.0003863243769100812
Trained batch 672 in epoch 6, gen_loss = 1.022040557099664, disc_loss = 0.0003862333636313423
Trained batch 673 in epoch 6, gen_loss = 1.022017324802076, disc_loss = 0.00038622664041663984
Trained batch 674 in epoch 6, gen_loss = 1.0219221444483158, disc_loss = 0.0003861575623105401
Trained batch 675 in epoch 6, gen_loss = 1.0219793708543101, disc_loss = 0.0003860210850291087
Trained batch 676 in epoch 6, gen_loss = 1.022055804025123, disc_loss = 0.00038583738227520844
Trained batch 677 in epoch 6, gen_loss = 1.0220195338965166, disc_loss = 0.00038570545265828994
Trained batch 678 in epoch 6, gen_loss = 1.022015333965706, disc_loss = 0.0003855985410255431
Trained batch 679 in epoch 6, gen_loss = 1.0219142333549611, disc_loss = 0.0003854096498049758
Trained batch 680 in epoch 6, gen_loss = 1.021907398704215, disc_loss = 0.00038519954323846736
Trained batch 681 in epoch 6, gen_loss = 1.0218392671727714, disc_loss = 0.0003850337694620709
Trained batch 682 in epoch 6, gen_loss = 1.0218260216678043, disc_loss = 0.00038487389838936777
Trained batch 683 in epoch 6, gen_loss = 1.0217739636437935, disc_loss = 0.000384609915458603
Trained batch 684 in epoch 6, gen_loss = 1.0218078082495363, disc_loss = 0.0003842281058091198
Trained batch 685 in epoch 6, gen_loss = 1.0217840852264761, disc_loss = 0.0003838292244724972
Trained batch 686 in epoch 6, gen_loss = 1.0217530456692892, disc_loss = 0.0003834550044240665
Trained batch 687 in epoch 6, gen_loss = 1.0216720928979475, disc_loss = 0.00038311822794280173
Trained batch 688 in epoch 6, gen_loss = 1.0216044467834673, disc_loss = 0.0003827479047815573
Trained batch 689 in epoch 6, gen_loss = 1.0215686117393383, disc_loss = 0.0003823614216937289
Trained batch 690 in epoch 6, gen_loss = 1.0215901003560177, disc_loss = 0.00038207953680028186
Trained batch 691 in epoch 6, gen_loss = 1.0216690823866452, disc_loss = 0.0003819514311628596
Trained batch 692 in epoch 6, gen_loss = 1.0215880180162096, disc_loss = 0.00038195660814869186
Trained batch 693 in epoch 6, gen_loss = 1.0216871919996113, disc_loss = 0.00038191982337604284
Trained batch 694 in epoch 6, gen_loss = 1.0216996670626908, disc_loss = 0.0003818160709755398
Trained batch 695 in epoch 6, gen_loss = 1.0218670660223084, disc_loss = 0.0003817166858143223
Trained batch 696 in epoch 6, gen_loss = 1.021771772092521, disc_loss = 0.00038164782934765185
Trained batch 697 in epoch 6, gen_loss = 1.0217858743360186, disc_loss = 0.0003815694122218222
Trained batch 698 in epoch 6, gen_loss = 1.0216973908298859, disc_loss = 0.0003813314770547142
Trained batch 699 in epoch 6, gen_loss = 1.0217512886013302, disc_loss = 0.00038097841198967737
Trained batch 700 in epoch 6, gen_loss = 1.0217658790644157, disc_loss = 0.00038064979380786324
Trained batch 701 in epoch 6, gen_loss = 1.0218034993719172, disc_loss = 0.00038051818449034763
Trained batch 702 in epoch 6, gen_loss = 1.0216011486385828, disc_loss = 0.00038055388341176095
Trained batch 703 in epoch 6, gen_loss = 1.0216481981121681, disc_loss = 0.00038067055252936785
Trained batch 704 in epoch 6, gen_loss = 1.0216201881144908, disc_loss = 0.0003808097784596921
Trained batch 705 in epoch 6, gen_loss = 1.0217016108819512, disc_loss = 0.0003810276175654482
Trained batch 706 in epoch 6, gen_loss = 1.0217742005197128, disc_loss = 0.00038123792220450263
Trained batch 707 in epoch 6, gen_loss = 1.0216811670590256, disc_loss = 0.0003813146715021431
Trained batch 708 in epoch 6, gen_loss = 1.021552340688423, disc_loss = 0.0003811798380388256
Trained batch 709 in epoch 6, gen_loss = 1.021646583164242, disc_loss = 0.00038094992911206187
Trained batch 710 in epoch 6, gen_loss = 1.0216757702089732, disc_loss = 0.0003807193102819289
Trained batch 711 in epoch 6, gen_loss = 1.0216362531600374, disc_loss = 0.0003805308824820294
Trained batch 712 in epoch 6, gen_loss = 1.021676117541245, disc_loss = 0.0003803807005710651
Trained batch 713 in epoch 6, gen_loss = 1.0216001609460312, disc_loss = 0.0003801502568144022
Trained batch 714 in epoch 6, gen_loss = 1.021703936170031, disc_loss = 0.0003798750578374944
Trained batch 715 in epoch 6, gen_loss = 1.0217192356146914, disc_loss = 0.00037963124378625785
Trained batch 716 in epoch 6, gen_loss = 1.0216405833947941, disc_loss = 0.0003794419838209663
Trained batch 717 in epoch 6, gen_loss = 1.0215811980135925, disc_loss = 0.00037924625327343523
Trained batch 718 in epoch 6, gen_loss = 1.0215989847010798, disc_loss = 0.00037920237926766115
Trained batch 719 in epoch 6, gen_loss = 1.021549554831452, disc_loss = 0.00037939677246059646
Trained batch 720 in epoch 6, gen_loss = 1.0215048062487218, disc_loss = 0.00037965325293987416
Trained batch 721 in epoch 6, gen_loss = 1.0214596759744627, disc_loss = 0.00037995873228933015
Trained batch 722 in epoch 6, gen_loss = 1.0214727636359704, disc_loss = 0.00038036944785403806
Trained batch 723 in epoch 6, gen_loss = 1.0214643627405167, disc_loss = 0.0003808940766087475
Trained batch 724 in epoch 6, gen_loss = 1.0214081802861443, disc_loss = 0.00038141706606658205
Trained batch 725 in epoch 6, gen_loss = 1.02135289290063, disc_loss = 0.0003819226265166801
Trained batch 726 in epoch 6, gen_loss = 1.0213004531033922, disc_loss = 0.0003822910501240151
Trained batch 727 in epoch 6, gen_loss = 1.0213253088704832, disc_loss = 0.00038242135982787597
Trained batch 728 in epoch 6, gen_loss = 1.0212901824132241, disc_loss = 0.0003823720612179533
Trained batch 729 in epoch 6, gen_loss = 1.0214195627055755, disc_loss = 0.00038221393911106583
Trained batch 730 in epoch 6, gen_loss = 1.021394510601842, disc_loss = 0.00038201246691115865
Trained batch 731 in epoch 6, gen_loss = 1.0213217082245103, disc_loss = 0.0003817984190560121
Trained batch 732 in epoch 6, gen_loss = 1.0214138009863694, disc_loss = 0.0003816613781398609
Trained batch 733 in epoch 6, gen_loss = 1.021413342017244, disc_loss = 0.0003815989428066521
Trained batch 734 in epoch 6, gen_loss = 1.0214060097324604, disc_loss = 0.0003815144951386792
Trained batch 735 in epoch 6, gen_loss = 1.0214272593350515, disc_loss = 0.00038138264821317654
Trained batch 736 in epoch 6, gen_loss = 1.0213505387144464, disc_loss = 0.0003811826561673578
Trained batch 737 in epoch 6, gen_loss = 1.021318794912116, disc_loss = 0.0003809662641662657
Trained batch 738 in epoch 6, gen_loss = 1.0212828015280997, disc_loss = 0.00038069617157484247
Trained batch 739 in epoch 6, gen_loss = 1.0212102657234348, disc_loss = 0.0003803554180145462
Trained batch 740 in epoch 6, gen_loss = 1.0211947024592505, disc_loss = 0.00038002077189528484
Trained batch 741 in epoch 6, gen_loss = 1.021156928690296, disc_loss = 0.00037974397500115104
Trained batch 742 in epoch 6, gen_loss = 1.0211962016241707, disc_loss = 0.0003796004487120018
Trained batch 743 in epoch 6, gen_loss = 1.0211887841102898, disc_loss = 0.0003795337753139373
Trained batch 744 in epoch 6, gen_loss = 1.021323758083702, disc_loss = 0.00037946586684935613
Trained batch 745 in epoch 6, gen_loss = 1.0212188394235862, disc_loss = 0.00037939751865297784
Trained batch 746 in epoch 6, gen_loss = 1.02104257180828, disc_loss = 0.00037930474127218135
Trained batch 747 in epoch 6, gen_loss = 1.0210188501340183, disc_loss = 0.00037922701600391666
Trained batch 748 in epoch 6, gen_loss = 1.0210260942240106, disc_loss = 0.00037909971526462567
Trained batch 749 in epoch 6, gen_loss = 1.0210117236773173, disc_loss = 0.0003789192658102062
Trained batch 750 in epoch 6, gen_loss = 1.020909860988114, disc_loss = 0.00037871571556402563
Trained batch 751 in epoch 6, gen_loss = 1.0208408568609268, disc_loss = 0.00037858729031037735
Trained batch 752 in epoch 6, gen_loss = 1.0209525846548448, disc_loss = 0.0003784387231311482
Trained batch 753 in epoch 6, gen_loss = 1.0209818241292665, disc_loss = 0.000378505350309614
Trained batch 754 in epoch 6, gen_loss = 1.0207952811228518, disc_loss = 0.0003786470624955528
Trained batch 755 in epoch 6, gen_loss = 1.020949131676129, disc_loss = 0.0003789957266153627
Trained batch 756 in epoch 6, gen_loss = 1.0209212882673095, disc_loss = 0.0003792384502542457
Trained batch 757 in epoch 6, gen_loss = 1.0208871020176165, disc_loss = 0.00037944230308434784
Trained batch 758 in epoch 6, gen_loss = 1.0209435398870776, disc_loss = 0.00037962340405596603
Trained batch 759 in epoch 6, gen_loss = 1.0209908225034412, disc_loss = 0.00037965627672364413
Trained batch 760 in epoch 6, gen_loss = 1.0209957738743505, disc_loss = 0.00037959117855540595
Trained batch 761 in epoch 6, gen_loss = 1.0210568204013695, disc_loss = 0.00037947684680880934
Trained batch 762 in epoch 6, gen_loss = 1.021099606160255, disc_loss = 0.00037932364492527474
Trained batch 763 in epoch 6, gen_loss = 1.0210694668336688, disc_loss = 0.00037915701478400787
Trained batch 764 in epoch 6, gen_loss = 1.021090607004228, disc_loss = 0.0003789699126559605
Trained batch 765 in epoch 6, gen_loss = 1.0209912114604023, disc_loss = 0.0003787589327750382
Trained batch 766 in epoch 6, gen_loss = 1.0209358597205858, disc_loss = 0.0003784742639657712
Trained batch 767 in epoch 6, gen_loss = 1.020967731019482, disc_loss = 0.00037815607744562385
Trained batch 768 in epoch 6, gen_loss = 1.0210295939631517, disc_loss = 0.0003777751131726157
Trained batch 769 in epoch 6, gen_loss = 1.0209502371100636, disc_loss = 0.00037739369521683306
Trained batch 770 in epoch 6, gen_loss = 1.0209726000110464, disc_loss = 0.0003770778381157967
Trained batch 771 in epoch 6, gen_loss = 1.02107625080205, disc_loss = 0.0003767541080152382
Trained batch 772 in epoch 6, gen_loss = 1.0211745905382668, disc_loss = 0.0003764899853291427
Trained batch 773 in epoch 6, gen_loss = 1.021190950189758, disc_loss = 0.00037621475569155576
Trained batch 774 in epoch 6, gen_loss = 1.021129101245634, disc_loss = 0.00037589877241595287
Trained batch 775 in epoch 6, gen_loss = 1.0211343956515961, disc_loss = 0.0003755984300941114
Trained batch 776 in epoch 6, gen_loss = 1.0211279672238511, disc_loss = 0.00037531993888200024
Trained batch 777 in epoch 6, gen_loss = 1.0211145071106889, disc_loss = 0.0003750723462778453
Trained batch 778 in epoch 6, gen_loss = 1.021165717933542, disc_loss = 0.00037478320604786953
Trained batch 779 in epoch 6, gen_loss = 1.02104096527283, disc_loss = 0.0003745856624962658
Trained batch 780 in epoch 6, gen_loss = 1.0208561294515368, disc_loss = 0.00037458507626985375
Trained batch 781 in epoch 6, gen_loss = 1.02091143556568, disc_loss = 0.00037449780675137323
Trained batch 782 in epoch 6, gen_loss = 1.020955510447004, disc_loss = 0.0003742596981240009
Trained batch 783 in epoch 6, gen_loss = 1.0210883613599806, disc_loss = 0.0003739391427328029
Trained batch 784 in epoch 6, gen_loss = 1.0211386066333503, disc_loss = 0.00037362312807298897
Trained batch 785 in epoch 6, gen_loss = 1.0211261420607871, disc_loss = 0.00037335245097376693
Trained batch 786 in epoch 6, gen_loss = 1.021087785688107, disc_loss = 0.0003733489946984752
Trained batch 787 in epoch 6, gen_loss = 1.0211054852166153, disc_loss = 0.00037368183719192375
Trained batch 788 in epoch 6, gen_loss = 1.0212097914348839, disc_loss = 0.0003738843525569318
Trained batch 789 in epoch 6, gen_loss = 1.0211062172545662, disc_loss = 0.0003738840223008935
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.0853374004364014, disc_loss = 0.00017811401630751789
Trained batch 1 in epoch 7, gen_loss = 1.0674170851707458, disc_loss = 0.0002152117231162265
Trained batch 2 in epoch 7, gen_loss = 1.0287960569063823, disc_loss = 0.0002650439952655385
Trained batch 3 in epoch 7, gen_loss = 1.0525686889886856, disc_loss = 0.00027242211217526346
Trained batch 4 in epoch 7, gen_loss = 1.0482102036476135, disc_loss = 0.00026142227288801224
Trained batch 5 in epoch 7, gen_loss = 1.0496282279491425, disc_loss = 0.00025730809769205126
Trained batch 6 in epoch 7, gen_loss = 1.0416091169629778, disc_loss = 0.0002666711828039427
Trained batch 7 in epoch 7, gen_loss = 1.0444395840168, disc_loss = 0.00028857011966465507
Trained batch 8 in epoch 7, gen_loss = 1.0278438594606187, disc_loss = 0.0003618859676256155
Trained batch 9 in epoch 7, gen_loss = 1.029391610622406, disc_loss = 0.0005336040529073216
Trained batch 10 in epoch 7, gen_loss = 1.025377468629317, disc_loss = 0.0007188452569111673
Trained batch 11 in epoch 7, gen_loss = 1.023191198706627, disc_loss = 0.0008763341381078741
Trained batch 12 in epoch 7, gen_loss = 1.0222701980517461, disc_loss = 0.0009825059241848066
Trained batch 13 in epoch 7, gen_loss = 1.028016597032547, disc_loss = 0.0010492047055907147
Trained batch 14 in epoch 7, gen_loss = 1.0305058757464092, disc_loss = 0.0010831889007628585
Trained batch 15 in epoch 7, gen_loss = 1.0328548960387707, disc_loss = 0.0010989096854245872
Trained batch 16 in epoch 7, gen_loss = 1.0309578776359558, disc_loss = 0.001090480200432734
Trained batch 17 in epoch 7, gen_loss = 1.0300357970926497, disc_loss = 0.0010720690972650321
Trained batch 18 in epoch 7, gen_loss = 1.0307911665816056, disc_loss = 0.0010476208599835733
Trained batch 19 in epoch 7, gen_loss = 1.0327389150857926, disc_loss = 0.0010230348714685533
Trained batch 20 in epoch 7, gen_loss = 1.0294659279641651, disc_loss = 0.001000521771770547
Trained batch 21 in epoch 7, gen_loss = 1.0270322371612897, disc_loss = 0.000979170867966869
Trained batch 22 in epoch 7, gen_loss = 1.0256165084631548, disc_loss = 0.0009530447556323412
Trained batch 23 in epoch 7, gen_loss = 1.028211382528146, disc_loss = 0.0009259500081194952
Trained batch 24 in epoch 7, gen_loss = 1.0295800375938415, disc_loss = 0.0008985671581467614
Trained batch 25 in epoch 7, gen_loss = 1.0314903740699475, disc_loss = 0.0008695487547531509
Trained batch 26 in epoch 7, gen_loss = 1.0278653193403173, disc_loss = 0.0008447894495610079
Trained batch 27 in epoch 7, gen_loss = 1.0299660414457321, disc_loss = 0.0008279062931251246
Trained batch 28 in epoch 7, gen_loss = 1.030139435981882, disc_loss = 0.0008097791011597769
Trained batch 29 in epoch 7, gen_loss = 1.029979298512141, disc_loss = 0.0007946815201042531
Trained batch 30 in epoch 7, gen_loss = 1.0271303173034423, disc_loss = 0.0007774517003018709
Trained batch 31 in epoch 7, gen_loss = 1.0257574636489153, disc_loss = 0.0007582754042232409
Trained batch 32 in epoch 7, gen_loss = 1.0286059831127976, disc_loss = 0.0007395040090407499
Trained batch 33 in epoch 7, gen_loss = 1.0284378896741306, disc_loss = 0.0007203024164054488
Trained batch 34 in epoch 7, gen_loss = 1.0331549389021737, disc_loss = 0.0007036218403040298
Trained batch 35 in epoch 7, gen_loss = 1.0322753869824939, disc_loss = 0.0006894546564176886
Trained batch 36 in epoch 7, gen_loss = 1.032849590520601, disc_loss = 0.0006789218231632903
Trained batch 37 in epoch 7, gen_loss = 1.0324590221831673, disc_loss = 0.0006703565289315424
Trained batch 38 in epoch 7, gen_loss = 1.0310770869255066, disc_loss = 0.0006625563986838246
Trained batch 39 in epoch 7, gen_loss = 1.0311719313263894, disc_loss = 0.0006518914524349384
Trained batch 40 in epoch 7, gen_loss = 1.0330541729927063, disc_loss = 0.0006397070630067369
Trained batch 41 in epoch 7, gen_loss = 1.0341897990022386, disc_loss = 0.000626896983227371
Trained batch 42 in epoch 7, gen_loss = 1.0321833435879197, disc_loss = 0.000614300885624902
Trained batch 43 in epoch 7, gen_loss = 1.0327705944126302, disc_loss = 0.0006023654090809446
Trained batch 44 in epoch 7, gen_loss = 1.0302526341544258, disc_loss = 0.0005911932292898807
Trained batch 45 in epoch 7, gen_loss = 1.031772678313048, disc_loss = 0.0005808310659473216
Trained batch 46 in epoch 7, gen_loss = 1.030055653541646, disc_loss = 0.0005704421936125653
Trained batch 47 in epoch 7, gen_loss = 1.0293223038315773, disc_loss = 0.0005601036280798629
Trained batch 48 in epoch 7, gen_loss = 1.029629330245816, disc_loss = 0.0005501740891545802
Trained batch 49 in epoch 7, gen_loss = 1.0299235463142395, disc_loss = 0.000540562192472862
Trained batch 50 in epoch 7, gen_loss = 1.0284522573153179, disc_loss = 0.0005311156661157249
Trained batch 51 in epoch 7, gen_loss = 1.0290457480228865, disc_loss = 0.0005224313941093547
Trained batch 52 in epoch 7, gen_loss = 1.0298055399138972, disc_loss = 0.0005137279663616044
Trained batch 53 in epoch 7, gen_loss = 1.0283149237985965, disc_loss = 0.0005056972309426379
Trained batch 54 in epoch 7, gen_loss = 1.0286573128266767, disc_loss = 0.0004986679094806525
Trained batch 55 in epoch 7, gen_loss = 1.0292451062372752, disc_loss = 0.000491942113317886
Trained batch 56 in epoch 7, gen_loss = 1.029657334612127, disc_loss = 0.00048502292727853433
Trained batch 57 in epoch 7, gen_loss = 1.0301685045505393, disc_loss = 0.00047811492518592095
Trained batch 58 in epoch 7, gen_loss = 1.0317698333222987, disc_loss = 0.0004722173882513189
Trained batch 59 in epoch 7, gen_loss = 1.0309694538513818, disc_loss = 0.0004677687977164169
Trained batch 60 in epoch 7, gen_loss = 1.0302484006178183, disc_loss = 0.00046467949791580485
Trained batch 61 in epoch 7, gen_loss = 1.0309592687314557, disc_loss = 0.00046232071227061695
Trained batch 62 in epoch 7, gen_loss = 1.0326581010742792, disc_loss = 0.0004597439188468603
Trained batch 63 in epoch 7, gen_loss = 1.0329840974882245, disc_loss = 0.00045748154269631414
Trained batch 64 in epoch 7, gen_loss = 1.032145187487969, disc_loss = 0.0004558331652683242
Trained batch 65 in epoch 7, gen_loss = 1.0319874584674835, disc_loss = 0.00045397406007175573
Trained batch 66 in epoch 7, gen_loss = 1.0319234622058584, disc_loss = 0.0004509268812344361
Trained batch 67 in epoch 7, gen_loss = 1.0317901556982714, disc_loss = 0.0004472013128821238
Trained batch 68 in epoch 7, gen_loss = 1.0323640237683835, disc_loss = 0.00044338266778377937
Trained batch 69 in epoch 7, gen_loss = 1.0326017899172646, disc_loss = 0.00043983300560544844
Trained batch 70 in epoch 7, gen_loss = 1.0328444553093172, disc_loss = 0.00043654587695950603
Trained batch 71 in epoch 7, gen_loss = 1.0324192634887166, disc_loss = 0.000433029450252636
Trained batch 72 in epoch 7, gen_loss = 1.0311079882595637, disc_loss = 0.0004297592475342928
Trained batch 73 in epoch 7, gen_loss = 1.0300327523334607, disc_loss = 0.0004276981310524846
Trained batch 74 in epoch 7, gen_loss = 1.0299671506881714, disc_loss = 0.0004255476428564483
Trained batch 75 in epoch 7, gen_loss = 1.0287348753527592, disc_loss = 0.00042236890423833086
Trained batch 76 in epoch 7, gen_loss = 1.0301377184979328, disc_loss = 0.0004190103550703876
Trained batch 77 in epoch 7, gen_loss = 1.0288371596580896, disc_loss = 0.000416999614641939
Trained batch 78 in epoch 7, gen_loss = 1.0284331267393088, disc_loss = 0.00041741292784248387
Trained batch 79 in epoch 7, gen_loss = 1.02803173661232, disc_loss = 0.0004192066962332319
Trained batch 80 in epoch 7, gen_loss = 1.0277415057759227, disc_loss = 0.00042080790260598283
Trained batch 81 in epoch 7, gen_loss = 1.0285346813318206, disc_loss = 0.0004212676169739031
Trained batch 82 in epoch 7, gen_loss = 1.028496228068708, disc_loss = 0.0004211697803795512
Trained batch 83 in epoch 7, gen_loss = 1.028434497969491, disc_loss = 0.0004207628452648004
Trained batch 84 in epoch 7, gen_loss = 1.0288404969608083, disc_loss = 0.0004199351065514801
Trained batch 85 in epoch 7, gen_loss = 1.0285752762195677, disc_loss = 0.0004190378075754568
Trained batch 86 in epoch 7, gen_loss = 1.0284253153307685, disc_loss = 0.0004173430221355333
Trained batch 87 in epoch 7, gen_loss = 1.0296741900118915, disc_loss = 0.000415618701853501
Trained batch 88 in epoch 7, gen_loss = 1.0293450221586764, disc_loss = 0.0004144055041496961
Trained batch 89 in epoch 7, gen_loss = 1.0292146682739258, disc_loss = 0.000413251436475548
Trained batch 90 in epoch 7, gen_loss = 1.0286768491451557, disc_loss = 0.00041161564089694304
Trained batch 91 in epoch 7, gen_loss = 1.0286493534627168, disc_loss = 0.00041001941229731767
Trained batch 92 in epoch 7, gen_loss = 1.0284000699238112, disc_loss = 0.00040821540425249917
Trained batch 93 in epoch 7, gen_loss = 1.0294000087900366, disc_loss = 0.0004068019264176404
Trained batch 94 in epoch 7, gen_loss = 1.0286865522986963, disc_loss = 0.00040631139153878107
Trained batch 95 in epoch 7, gen_loss = 1.029032037903865, disc_loss = 0.0004065960703201199
Trained batch 96 in epoch 7, gen_loss = 1.0285673233651624, disc_loss = 0.0004073091949976515
Trained batch 97 in epoch 7, gen_loss = 1.0286088762234669, disc_loss = 0.0004079792220831483
Trained batch 98 in epoch 7, gen_loss = 1.0280158628116955, disc_loss = 0.0004076698291596999
Trained batch 99 in epoch 7, gen_loss = 1.0290712583065034, disc_loss = 0.0004057911058407626
Trained batch 100 in epoch 7, gen_loss = 1.02964717680865, disc_loss = 0.00040341464085544754
Trained batch 101 in epoch 7, gen_loss = 1.0297291711264966, disc_loss = 0.0004013080652286732
Trained batch 102 in epoch 7, gen_loss = 1.0295139342835806, disc_loss = 0.00039901299052730484
Trained batch 103 in epoch 7, gen_loss = 1.0296109662606165, disc_loss = 0.00039700551941188256
Trained batch 104 in epoch 7, gen_loss = 1.0299143041883196, disc_loss = 0.00039552615389333194
Trained batch 105 in epoch 7, gen_loss = 1.0290255411615912, disc_loss = 0.0003955936107610436
Trained batch 106 in epoch 7, gen_loss = 1.0292855634867588, disc_loss = 0.0003977627489021131
Trained batch 107 in epoch 7, gen_loss = 1.0280874172846477, disc_loss = 0.00039867113658450154
Trained batch 108 in epoch 7, gen_loss = 1.0282060925019991, disc_loss = 0.0003992499773422098
Trained batch 109 in epoch 7, gen_loss = 1.0278374747796493, disc_loss = 0.0003982932649126848
Trained batch 110 in epoch 7, gen_loss = 1.0275143594355196, disc_loss = 0.00039710742242499
Trained batch 111 in epoch 7, gen_loss = 1.027210901358298, disc_loss = 0.00039693576409912827
Trained batch 112 in epoch 7, gen_loss = 1.02717493223933, disc_loss = 0.00039673712633450235
Trained batch 113 in epoch 7, gen_loss = 1.02718077782999, disc_loss = 0.00039676780742363345
Trained batch 114 in epoch 7, gen_loss = 1.0274174996044325, disc_loss = 0.0003961662433816262
Trained batch 115 in epoch 7, gen_loss = 1.0276699307663688, disc_loss = 0.00039489872026400726
Trained batch 116 in epoch 7, gen_loss = 1.028070612340911, disc_loss = 0.000393545067848978
Trained batch 117 in epoch 7, gen_loss = 1.0278799023668646, disc_loss = 0.00039126517894747865
Trained batch 118 in epoch 7, gen_loss = 1.0278226332504208, disc_loss = 0.0003887117992166504
Trained batch 119 in epoch 7, gen_loss = 1.0278226589163144, disc_loss = 0.00038596898075411447
Trained batch 120 in epoch 7, gen_loss = 1.0279591049044585, disc_loss = 0.0003831760880808165
Trained batch 121 in epoch 7, gen_loss = 1.027442079587061, disc_loss = 0.00038074313044012713
Trained batch 122 in epoch 7, gen_loss = 1.0277894885559393, disc_loss = 0.0003792864632945625
Trained batch 123 in epoch 7, gen_loss = 1.0281076484149503, disc_loss = 0.0003781439296114014
Trained batch 124 in epoch 7, gen_loss = 1.0282464289665223, disc_loss = 0.00037666091774008235
Trained batch 125 in epoch 7, gen_loss = 1.0277005732059479, disc_loss = 0.0003755691400689853
Trained batch 126 in epoch 7, gen_loss = 1.027468831989709, disc_loss = 0.00037552283578492726
Trained batch 127 in epoch 7, gen_loss = 1.0273092878051102, disc_loss = 0.0003760563657522198
Trained batch 128 in epoch 7, gen_loss = 1.027316063411476, disc_loss = 0.0003765294418971202
Trained batch 129 in epoch 7, gen_loss = 1.0274169862270355, disc_loss = 0.00037709341298838037
Trained batch 130 in epoch 7, gen_loss = 1.0276713730724714, disc_loss = 0.00037787521229892476
Trained batch 131 in epoch 7, gen_loss = 1.0274216943618022, disc_loss = 0.000378162435701983
Trained batch 132 in epoch 7, gen_loss = 1.0268058911302036, disc_loss = 0.0003783845333012672
Trained batch 133 in epoch 7, gen_loss = 1.026867451062843, disc_loss = 0.00037846397621007187
Trained batch 134 in epoch 7, gen_loss = 1.026275047549495, disc_loss = 0.0003779064325768828
Trained batch 135 in epoch 7, gen_loss = 1.0261455642826416, disc_loss = 0.0003776484474174675
Trained batch 136 in epoch 7, gen_loss = 1.0263695447114263, disc_loss = 0.00037793936126633465
Trained batch 137 in epoch 7, gen_loss = 1.026524491932081, disc_loss = 0.00037842346097497045
Trained batch 138 in epoch 7, gen_loss = 1.02653514567039, disc_loss = 0.000378951293255308
Trained batch 139 in epoch 7, gen_loss = 1.026335763505527, disc_loss = 0.00037870407049922505
Trained batch 140 in epoch 7, gen_loss = 1.0259218177896865, disc_loss = 0.00037765759825173943
Trained batch 141 in epoch 7, gen_loss = 1.0268008604016103, disc_loss = 0.00037689869614169623
Trained batch 142 in epoch 7, gen_loss = 1.0262763204274479, disc_loss = 0.00037749839611933567
Trained batch 143 in epoch 7, gen_loss = 1.0267644363145034, disc_loss = 0.00038006361134850723
Trained batch 144 in epoch 7, gen_loss = 1.0261037978632697, disc_loss = 0.0003852223375047445
Trained batch 145 in epoch 7, gen_loss = 1.025976193686054, disc_loss = 0.00039355861648900456
Trained batch 146 in epoch 7, gen_loss = 1.0259400569662755, disc_loss = 0.00040374282225519005
Trained batch 147 in epoch 7, gen_loss = 1.026293489175874, disc_loss = 0.0004150859344303466
Trained batch 148 in epoch 7, gen_loss = 1.0268304367993502, disc_loss = 0.0004256008842703339
Trained batch 149 in epoch 7, gen_loss = 1.026997809012731, disc_loss = 0.0004352100488176802
Trained batch 150 in epoch 7, gen_loss = 1.0275230909025432, disc_loss = 0.0004422091716807567
Trained batch 151 in epoch 7, gen_loss = 1.0271973229552571, disc_loss = 0.0004456424457394429
Trained batch 152 in epoch 7, gen_loss = 1.0272987983585182, disc_loss = 0.00044633126381561736
Trained batch 153 in epoch 7, gen_loss = 1.0269347626667518, disc_loss = 0.0004460442052802975
Trained batch 154 in epoch 7, gen_loss = 1.0264002657705737, disc_loss = 0.0004452868569182277
Trained batch 155 in epoch 7, gen_loss = 1.0263275026510923, disc_loss = 0.0004443407317058956
Trained batch 156 in epoch 7, gen_loss = 1.0268461837130747, disc_loss = 0.0004428396079825329
Trained batch 157 in epoch 7, gen_loss = 1.0271633520156522, disc_loss = 0.00044143997096214176
Trained batch 158 in epoch 7, gen_loss = 1.0268605373940378, disc_loss = 0.0004412014656376208
Trained batch 159 in epoch 7, gen_loss = 1.027225187793374, disc_loss = 0.0004424903609788089
Trained batch 160 in epoch 7, gen_loss = 1.0272503998709022, disc_loss = 0.0004439122365635418
Trained batch 161 in epoch 7, gen_loss = 1.027271740598443, disc_loss = 0.0004436655317813684
Trained batch 162 in epoch 7, gen_loss = 1.0267168513836304, disc_loss = 0.0004425749043743712
Trained batch 163 in epoch 7, gen_loss = 1.0267111989783078, disc_loss = 0.00044133993729124864
Trained batch 164 in epoch 7, gen_loss = 1.0269341544671493, disc_loss = 0.00043983368040327066
Trained batch 165 in epoch 7, gen_loss = 1.0267307237688317, disc_loss = 0.0004378368420179594
Trained batch 166 in epoch 7, gen_loss = 1.026655059731649, disc_loss = 0.0004357657770472537
Trained batch 167 in epoch 7, gen_loss = 1.02615563642411, disc_loss = 0.0004337370830528796
Trained batch 168 in epoch 7, gen_loss = 1.0261943001718916, disc_loss = 0.0004317358409951113
Trained batch 169 in epoch 7, gen_loss = 1.0260399776346543, disc_loss = 0.0004300615713231416
Trained batch 170 in epoch 7, gen_loss = 1.025475147174813, disc_loss = 0.00042860700764774334
Trained batch 171 in epoch 7, gen_loss = 1.0257805163084075, disc_loss = 0.0004272682921679049
Trained batch 172 in epoch 7, gen_loss = 1.0258111802139722, disc_loss = 0.0004258613230455653
Trained batch 173 in epoch 7, gen_loss = 1.0253656595602803, disc_loss = 0.00042428465369983773
Trained batch 174 in epoch 7, gen_loss = 1.0251512776102338, disc_loss = 0.0004224054116431424
Trained batch 175 in epoch 7, gen_loss = 1.0252073464745826, disc_loss = 0.0004208674103913588
Trained batch 176 in epoch 7, gen_loss = 1.0251735768749215, disc_loss = 0.0004203763726835947
Trained batch 177 in epoch 7, gen_loss = 1.0250941504923146, disc_loss = 0.00042014210415023686
Trained batch 178 in epoch 7, gen_loss = 1.0251946918791233, disc_loss = 0.00041906342225220164
Trained batch 179 in epoch 7, gen_loss = 1.0253927909665637, disc_loss = 0.00041765902878978525
Trained batch 180 in epoch 7, gen_loss = 1.0256090740472572, disc_loss = 0.00041625815426730756
Trained batch 181 in epoch 7, gen_loss = 1.0257887673246993, disc_loss = 0.000414971671449206
Trained batch 182 in epoch 7, gen_loss = 1.0255551693218001, disc_loss = 0.0004137120947130139
Trained batch 183 in epoch 7, gen_loss = 1.0255934547470964, disc_loss = 0.0004125745581602488
Trained batch 184 in epoch 7, gen_loss = 1.025578753690462, disc_loss = 0.00041175152214851255
Trained batch 185 in epoch 7, gen_loss = 1.0261802823953732, disc_loss = 0.0004120937208289854
Trained batch 186 in epoch 7, gen_loss = 1.0259333845765832, disc_loss = 0.0004146647036524133
Trained batch 187 in epoch 7, gen_loss = 1.0260651209887037, disc_loss = 0.00041847602630909063
Trained batch 188 in epoch 7, gen_loss = 1.02608701760176, disc_loss = 0.0004213514245830035
Trained batch 189 in epoch 7, gen_loss = 1.0258625058751358, disc_loss = 0.0004221897857381631
Trained batch 190 in epoch 7, gen_loss = 1.0258729997729756, disc_loss = 0.0004214021322295784
Trained batch 191 in epoch 7, gen_loss = 1.0253318731362622, disc_loss = 0.00041994581694856
Trained batch 192 in epoch 7, gen_loss = 1.0252129583778777, disc_loss = 0.00041834467350112614
Trained batch 193 in epoch 7, gen_loss = 1.0248192957381612, disc_loss = 0.0004169833789570269
Trained batch 194 in epoch 7, gen_loss = 1.0251974928073393, disc_loss = 0.0004159593716068253
Trained batch 195 in epoch 7, gen_loss = 1.0255573753799712, disc_loss = 0.0004149526965156095
Trained batch 196 in epoch 7, gen_loss = 1.0255495288650396, disc_loss = 0.0004136342592255229
Trained batch 197 in epoch 7, gen_loss = 1.0253399201113769, disc_loss = 0.0004123193452364325
Trained batch 198 in epoch 7, gen_loss = 1.0253083394400437, disc_loss = 0.00041105628640513195
Trained batch 199 in epoch 7, gen_loss = 1.0252825975418092, disc_loss = 0.0004097701658065489
Trained batch 200 in epoch 7, gen_loss = 1.0253435960456507, disc_loss = 0.0004084515017006993
Trained batch 201 in epoch 7, gen_loss = 1.0253183605647322, disc_loss = 0.000407192891534668
Trained batch 202 in epoch 7, gen_loss = 1.0253336635129204, disc_loss = 0.00040614040703022407
Trained batch 203 in epoch 7, gen_loss = 1.0251430676263922, disc_loss = 0.00040524935743365754
Trained batch 204 in epoch 7, gen_loss = 1.0246844637684707, disc_loss = 0.0004041868585151927
Trained batch 205 in epoch 7, gen_loss = 1.0250689743213284, disc_loss = 0.0004029145981706464
Trained batch 206 in epoch 7, gen_loss = 1.0253967095688346, disc_loss = 0.0004017005258827225
Trained batch 207 in epoch 7, gen_loss = 1.0256262791271393, disc_loss = 0.0004003503157281767
Trained batch 208 in epoch 7, gen_loss = 1.0258452518704975, disc_loss = 0.00039890342449190645
Trained batch 209 in epoch 7, gen_loss = 1.0257577331293197, disc_loss = 0.00039746746667896374
Trained batch 210 in epoch 7, gen_loss = 1.0259850463031028, disc_loss = 0.0003961836525562641
Trained batch 211 in epoch 7, gen_loss = 1.0257232588417124, disc_loss = 0.000395314782388527
Trained batch 212 in epoch 7, gen_loss = 1.025949199994405, disc_loss = 0.00039586317281748665
Trained batch 213 in epoch 7, gen_loss = 1.02597089070026, disc_loss = 0.00039843394230710123
Trained batch 214 in epoch 7, gen_loss = 1.0260537496832913, disc_loss = 0.00040281567667397065
Trained batch 215 in epoch 7, gen_loss = 1.0260530472905547, disc_loss = 0.00040928141635487446
Trained batch 216 in epoch 7, gen_loss = 1.02583066439299, disc_loss = 0.0004165847747044022
Trained batch 217 in epoch 7, gen_loss = 1.0253554511507716, disc_loss = 0.0004220814256051207
Trained batch 218 in epoch 7, gen_loss = 1.0256425942460152, disc_loss = 0.00042560825710247067
Trained batch 219 in epoch 7, gen_loss = 1.0256880657239393, disc_loss = 0.0004267732997918343
Trained batch 220 in epoch 7, gen_loss = 1.02596119787898, disc_loss = 0.00042645167007926974
Trained batch 221 in epoch 7, gen_loss = 1.0262365244530343, disc_loss = 0.0004256219351707448
Trained batch 222 in epoch 7, gen_loss = 1.0264175013041816, disc_loss = 0.0004246390006284912
Trained batch 223 in epoch 7, gen_loss = 1.0263421684503555, disc_loss = 0.00042343858832997024
Trained batch 224 in epoch 7, gen_loss = 1.026627221107483, disc_loss = 0.0004221452113738956
Trained batch 225 in epoch 7, gen_loss = 1.0267826018080246, disc_loss = 0.0004211845252858897
Trained batch 226 in epoch 7, gen_loss = 1.0269889794782394, disc_loss = 0.0004201294275700465
Trained batch 227 in epoch 7, gen_loss = 1.0265972339793255, disc_loss = 0.00041912597042251595
Trained batch 228 in epoch 7, gen_loss = 1.0266835353780521, disc_loss = 0.00041833357724646315
Trained batch 229 in epoch 7, gen_loss = 1.0261252468046935, disc_loss = 0.0004186789409805383
Trained batch 230 in epoch 7, gen_loss = 1.0259148478507996, disc_loss = 0.0004199028909953515
Trained batch 231 in epoch 7, gen_loss = 1.0253442083967144, disc_loss = 0.0004204518033538048
Trained batch 232 in epoch 7, gen_loss = 1.0254826387110698, disc_loss = 0.0004214829965395895
Trained batch 233 in epoch 7, gen_loss = 1.025563354166145, disc_loss = 0.00042277635913752677
Trained batch 234 in epoch 7, gen_loss = 1.0259100011054505, disc_loss = 0.00042372716008995143
Trained batch 235 in epoch 7, gen_loss = 1.0258429020138111, disc_loss = 0.00042327524575523704
Trained batch 236 in epoch 7, gen_loss = 1.0257209474024391, disc_loss = 0.0004223811411219482
Trained batch 237 in epoch 7, gen_loss = 1.025731651722884, disc_loss = 0.00042136543926681654
Trained batch 238 in epoch 7, gen_loss = 1.0255195520911755, disc_loss = 0.0004203973962126785
Trained batch 239 in epoch 7, gen_loss = 1.0256486400961875, disc_loss = 0.0004195435392981987
Trained batch 240 in epoch 7, gen_loss = 1.0256959803371508, disc_loss = 0.00041863734942159997
Trained batch 241 in epoch 7, gen_loss = 1.0258303181199002, disc_loss = 0.00041765071690567934
Trained batch 242 in epoch 7, gen_loss = 1.0254779970694963, disc_loss = 0.00041677629383323514
Trained batch 243 in epoch 7, gen_loss = 1.0252718639666918, disc_loss = 0.0004158085431135689
Trained batch 244 in epoch 7, gen_loss = 1.024826728324501, disc_loss = 0.00041479993902909454
Trained batch 245 in epoch 7, gen_loss = 1.024784748389469, disc_loss = 0.00041421876814298243
Trained batch 246 in epoch 7, gen_loss = 1.024471330739226, disc_loss = 0.0004140051700056272
Trained batch 247 in epoch 7, gen_loss = 1.0245358246949412, disc_loss = 0.00041404660760235856
Trained batch 248 in epoch 7, gen_loss = 1.0246061067504577, disc_loss = 0.0004143010115352166
Trained batch 249 in epoch 7, gen_loss = 1.024481740951538, disc_loss = 0.0004146243231516564
Trained batch 250 in epoch 7, gen_loss = 1.0245326847669138, disc_loss = 0.00041443766518257116
Trained batch 251 in epoch 7, gen_loss = 1.0245517416605874, disc_loss = 0.0004138007207219498
Trained batch 252 in epoch 7, gen_loss = 1.0247685720798054, disc_loss = 0.0004132125696371882
Trained batch 253 in epoch 7, gen_loss = 1.0245632956347128, disc_loss = 0.0004130235590746738
Trained batch 254 in epoch 7, gen_loss = 1.02450279675278, disc_loss = 0.0004128440343871868
Trained batch 255 in epoch 7, gen_loss = 1.0245906137861311, disc_loss = 0.0004124721077829463
Trained batch 256 in epoch 7, gen_loss = 1.0242518975113153, disc_loss = 0.0004122859266490797
Trained batch 257 in epoch 7, gen_loss = 1.0241774547007656, disc_loss = 0.00041257411000635133
Trained batch 258 in epoch 7, gen_loss = 1.0246191673757488, disc_loss = 0.00041333683414987476
Trained batch 259 in epoch 7, gen_loss = 1.024534593637173, disc_loss = 0.00041406392557781567
Trained batch 260 in epoch 7, gen_loss = 1.0246741515923277, disc_loss = 0.00041399090014760726
Trained batch 261 in epoch 7, gen_loss = 1.0247356104486771, disc_loss = 0.00041325207336066836
Trained batch 262 in epoch 7, gen_loss = 1.0247006031043628, disc_loss = 0.00041282133389002745
Trained batch 263 in epoch 7, gen_loss = 1.0245057096083958, disc_loss = 0.0004127104530336069
Trained batch 264 in epoch 7, gen_loss = 1.02451022930865, disc_loss = 0.0004124953982201712
Trained batch 265 in epoch 7, gen_loss = 1.0241723132312746, disc_loss = 0.00041183206311891406
Trained batch 266 in epoch 7, gen_loss = 1.0240316279372026, disc_loss = 0.00041100365191330514
Trained batch 267 in epoch 7, gen_loss = 1.0241593193652025, disc_loss = 0.0004103022724101815
Trained batch 268 in epoch 7, gen_loss = 1.0241250220727742, disc_loss = 0.00040942696483858143
Trained batch 269 in epoch 7, gen_loss = 1.024356723714758, disc_loss = 0.0004084723149086737
Trained batch 270 in epoch 7, gen_loss = 1.0244657755777844, disc_loss = 0.0004078859342757236
Trained batch 271 in epoch 7, gen_loss = 1.0247972682118416, disc_loss = 0.00040761026579115
Trained batch 272 in epoch 7, gen_loss = 1.0249689743195698, disc_loss = 0.0004072917470647297
Trained batch 273 in epoch 7, gen_loss = 1.0249090973478163, disc_loss = 0.0004067576747948693
Trained batch 274 in epoch 7, gen_loss = 1.0248919335278597, disc_loss = 0.0004060092271141581
Trained batch 275 in epoch 7, gen_loss = 1.0248014903154925, disc_loss = 0.0004052219002941443
Trained batch 276 in epoch 7, gen_loss = 1.0247482782236506, disc_loss = 0.000404339148127663
Trained batch 277 in epoch 7, gen_loss = 1.0244298856035412, disc_loss = 0.00040342279090581666
Trained batch 278 in epoch 7, gen_loss = 1.0243172778023615, disc_loss = 0.0004023745800411257
Trained batch 279 in epoch 7, gen_loss = 1.024541967681476, disc_loss = 0.00040124850364528747
Trained batch 280 in epoch 7, gen_loss = 1.024384957615591, disc_loss = 0.00040027364183292273
Trained batch 281 in epoch 7, gen_loss = 1.0242121477499075, disc_loss = 0.000399681420411922
Trained batch 282 in epoch 7, gen_loss = 1.0239492244097033, disc_loss = 0.0003994819782342138
Trained batch 283 in epoch 7, gen_loss = 1.0240328099945901, disc_loss = 0.00039951963415814145
Trained batch 284 in epoch 7, gen_loss = 1.0239277237340023, disc_loss = 0.0003996307581888814
Trained batch 285 in epoch 7, gen_loss = 1.0240999260148802, disc_loss = 0.00039990144881545613
Trained batch 286 in epoch 7, gen_loss = 1.0243346026550186, disc_loss = 0.00040035515814787996
Trained batch 287 in epoch 7, gen_loss = 1.0246068313717842, disc_loss = 0.00040051185686075367
Trained batch 288 in epoch 7, gen_loss = 1.0245639073394988, disc_loss = 0.00040025085787690455
Trained batch 289 in epoch 7, gen_loss = 1.0246417625197048, disc_loss = 0.0003996835173642592
Trained batch 290 in epoch 7, gen_loss = 1.0246777042900164, disc_loss = 0.0003988550095127846
Trained batch 291 in epoch 7, gen_loss = 1.02465874242456, disc_loss = 0.00039807460646829583
Trained batch 292 in epoch 7, gen_loss = 1.0245240365279005, disc_loss = 0.0003974586306681178
Trained batch 293 in epoch 7, gen_loss = 1.0247375733998356, disc_loss = 0.00039704946837347196
Trained batch 294 in epoch 7, gen_loss = 1.024618384999744, disc_loss = 0.0003967175548881395
Trained batch 295 in epoch 7, gen_loss = 1.0246096819236472, disc_loss = 0.00039613116920205556
Trained batch 296 in epoch 7, gen_loss = 1.0247583419385582, disc_loss = 0.0003954285027006342
Trained batch 297 in epoch 7, gen_loss = 1.0245677114733114, disc_loss = 0.0003946226724348658
Trained batch 298 in epoch 7, gen_loss = 1.024660254202559, disc_loss = 0.0003937526222538977
Trained batch 299 in epoch 7, gen_loss = 1.0246807346741358, disc_loss = 0.0003928762624006292
Trained batch 300 in epoch 7, gen_loss = 1.024536719155866, disc_loss = 0.00039197696099280957
Trained batch 301 in epoch 7, gen_loss = 1.0244193475767476, disc_loss = 0.0003911018281981745
Trained batch 302 in epoch 7, gen_loss = 1.0245079746340762, disc_loss = 0.00039032217620254536
Trained batch 303 in epoch 7, gen_loss = 1.0241946560379707, disc_loss = 0.00038949810671415195
Trained batch 304 in epoch 7, gen_loss = 1.0239595493332285, disc_loss = 0.0003885762868701961
Trained batch 305 in epoch 7, gen_loss = 1.0241791023538003, disc_loss = 0.0003875886552979115
Trained batch 306 in epoch 7, gen_loss = 1.0240954197579175, disc_loss = 0.0003868194833125408
Trained batch 307 in epoch 7, gen_loss = 1.0238884956418695, disc_loss = 0.0003862850804556752
Trained batch 308 in epoch 7, gen_loss = 1.0237012387865183, disc_loss = 0.0003860432115845152
Trained batch 309 in epoch 7, gen_loss = 1.0235212597154801, disc_loss = 0.00038611467728426964
Trained batch 310 in epoch 7, gen_loss = 1.0233649473481623, disc_loss = 0.0003861732308885159
Trained batch 311 in epoch 7, gen_loss = 1.023466818034649, disc_loss = 0.0003861693155671767
Trained batch 312 in epoch 7, gen_loss = 1.023119824382063, disc_loss = 0.000386121914572415
Trained batch 313 in epoch 7, gen_loss = 1.0231949622464027, disc_loss = 0.0003858027912602741
Trained batch 314 in epoch 7, gen_loss = 1.0231290049023098, disc_loss = 0.0003853888132970684
Trained batch 315 in epoch 7, gen_loss = 1.0230329772339593, disc_loss = 0.00038497187313025073
Trained batch 316 in epoch 7, gen_loss = 1.022878300880408, disc_loss = 0.0003846108774030809
Trained batch 317 in epoch 7, gen_loss = 1.0230121923692572, disc_loss = 0.0003841534544564249
Trained batch 318 in epoch 7, gen_loss = 1.0228354968247368, disc_loss = 0.0003835321340517785
Trained batch 319 in epoch 7, gen_loss = 1.022932568565011, disc_loss = 0.0003828364908599724
Trained batch 320 in epoch 7, gen_loss = 1.0229632561080553, disc_loss = 0.00038216636091428286
Trained batch 321 in epoch 7, gen_loss = 1.0230602777522544, disc_loss = 0.0003814686010825782
Trained batch 322 in epoch 7, gen_loss = 1.0231872675219555, disc_loss = 0.00038072330281907913
Trained batch 323 in epoch 7, gen_loss = 1.0231532564869634, disc_loss = 0.00037988689649707483
Trained batch 324 in epoch 7, gen_loss = 1.0229967638162467, disc_loss = 0.00037897718075188233
Trained batch 325 in epoch 7, gen_loss = 1.0231417859990173, disc_loss = 0.0003781622607971397
Trained batch 326 in epoch 7, gen_loss = 1.023143922517059, disc_loss = 0.00037746862512584193
Trained batch 327 in epoch 7, gen_loss = 1.0230995354855932, disc_loss = 0.000376915612311522
Trained batch 328 in epoch 7, gen_loss = 1.0228858510411618, disc_loss = 0.00037625959336728997
Trained batch 329 in epoch 7, gen_loss = 1.0230104729984746, disc_loss = 0.0003753332296279647
Trained batch 330 in epoch 7, gen_loss = 1.0229178324927015, disc_loss = 0.00037447932780833895
Trained batch 331 in epoch 7, gen_loss = 1.0226243465061646, disc_loss = 0.00037364217777975276
Trained batch 332 in epoch 7, gen_loss = 1.0225672052429244, disc_loss = 0.0003728659673713325
Trained batch 333 in epoch 7, gen_loss = 1.0226916606554728, disc_loss = 0.00037222698156909756
Trained batch 334 in epoch 7, gen_loss = 1.0229052479587384, disc_loss = 0.0003716852195250781
Trained batch 335 in epoch 7, gen_loss = 1.0230325648472423, disc_loss = 0.00037119580337102454
Trained batch 336 in epoch 7, gen_loss = 1.022695249372137, disc_loss = 0.00037070642222983014
Trained batch 337 in epoch 7, gen_loss = 1.0227923349163237, disc_loss = 0.0003704691506103721
Trained batch 338 in epoch 7, gen_loss = 1.0227395653021372, disc_loss = 0.0003704613604774983
Trained batch 339 in epoch 7, gen_loss = 1.022531019764788, disc_loss = 0.0003702399070842897
Trained batch 340 in epoch 7, gen_loss = 1.0226840635548589, disc_loss = 0.00036979630156384327
Trained batch 341 in epoch 7, gen_loss = 1.022658278893309, disc_loss = 0.00036923754553312954
Trained batch 342 in epoch 7, gen_loss = 1.0228923724274595, disc_loss = 0.0003686357278755422
Trained batch 343 in epoch 7, gen_loss = 1.0230892378576966, disc_loss = 0.0003679585122691331
Trained batch 344 in epoch 7, gen_loss = 1.0231544195741846, disc_loss = 0.00036725965141870445
Trained batch 345 in epoch 7, gen_loss = 1.0230088611214148, disc_loss = 0.0003665977212979096
Trained batch 346 in epoch 7, gen_loss = 1.0230722652388582, disc_loss = 0.0003660850674067443
Trained batch 347 in epoch 7, gen_loss = 1.0230175871616123, disc_loss = 0.0003656736807793147
Trained batch 348 in epoch 7, gen_loss = 1.0230240768894425, disc_loss = 0.00036527683012036377
Trained batch 349 in epoch 7, gen_loss = 1.0229164263180324, disc_loss = 0.000364890013661352
Trained batch 350 in epoch 7, gen_loss = 1.0229873653830286, disc_loss = 0.00036468156080046585
Trained batch 351 in epoch 7, gen_loss = 1.0229592170904984, disc_loss = 0.00036458133324272654
Trained batch 352 in epoch 7, gen_loss = 1.0231309251136889, disc_loss = 0.0003647407169301932
Trained batch 353 in epoch 7, gen_loss = 1.0230110974635107, disc_loss = 0.0003653009458030489
Trained batch 354 in epoch 7, gen_loss = 1.0227492785789598, disc_loss = 0.00036595669421523116
Trained batch 355 in epoch 7, gen_loss = 1.022734695940875, disc_loss = 0.00036655941784466563
Trained batch 356 in epoch 7, gen_loss = 1.0228329866874117, disc_loss = 0.0003672227114487109
Trained batch 357 in epoch 7, gen_loss = 1.0228544723388202, disc_loss = 0.00036804340074745115
Trained batch 358 in epoch 7, gen_loss = 1.0226393529631632, disc_loss = 0.000368803406748671
Trained batch 359 in epoch 7, gen_loss = 1.0224668948186768, disc_loss = 0.0003691730654483965
Trained batch 360 in epoch 7, gen_loss = 1.0225780252934824, disc_loss = 0.00036930343577948815
Trained batch 361 in epoch 7, gen_loss = 1.0228082506366856, disc_loss = 0.00036925819938774386
Trained batch 362 in epoch 7, gen_loss = 1.0227581119734395, disc_loss = 0.0003691347382834262
Trained batch 363 in epoch 7, gen_loss = 1.0229645913446344, disc_loss = 0.00036909331849308946
Trained batch 364 in epoch 7, gen_loss = 1.0228028509714833, disc_loss = 0.00036930420206921904
Trained batch 365 in epoch 7, gen_loss = 1.022846830672905, disc_loss = 0.000369683719536177
Trained batch 366 in epoch 7, gen_loss = 1.0231724954755819, disc_loss = 0.00037015487455751184
Trained batch 367 in epoch 7, gen_loss = 1.0231566157030023, disc_loss = 0.0003706977830540342
Trained batch 368 in epoch 7, gen_loss = 1.0231280578830377, disc_loss = 0.00037133514409754513
Trained batch 369 in epoch 7, gen_loss = 1.023215068353189, disc_loss = 0.0003719317441160407
Trained batch 370 in epoch 7, gen_loss = 1.0231369971586366, disc_loss = 0.0003723548484317089
Trained batch 371 in epoch 7, gen_loss = 1.0234573364898722, disc_loss = 0.00037258275613332386
Trained batch 372 in epoch 7, gen_loss = 1.0233209270574453, disc_loss = 0.0003723505173959481
Trained batch 373 in epoch 7, gen_loss = 1.0234487161916845, disc_loss = 0.00037185895188179623
Trained batch 374 in epoch 7, gen_loss = 1.0235376694997151, disc_loss = 0.0003713682782351195
Trained batch 375 in epoch 7, gen_loss = 1.0234626247844798, disc_loss = 0.00037100037122806323
Trained batch 376 in epoch 7, gen_loss = 1.0235377580164597, disc_loss = 0.0003707703446890802
Trained batch 377 in epoch 7, gen_loss = 1.0237218928400171, disc_loss = 0.0003705460176735879
Trained batch 378 in epoch 7, gen_loss = 1.0238357236643265, disc_loss = 0.0003705331821762987
Trained batch 379 in epoch 7, gen_loss = 1.0237937392372833, disc_loss = 0.0003709847450169802
Trained batch 380 in epoch 7, gen_loss = 1.0237859138666487, disc_loss = 0.00037179829937879796
Trained batch 381 in epoch 7, gen_loss = 1.0239486742706199, disc_loss = 0.00037289291118137253
Trained batch 382 in epoch 7, gen_loss = 1.0239584600022817, disc_loss = 0.00037407108265339695
Trained batch 383 in epoch 7, gen_loss = 1.023789409858485, disc_loss = 0.00037507254814765173
Trained batch 384 in epoch 7, gen_loss = 1.0238571541649955, disc_loss = 0.00037592101547157984
Trained batch 385 in epoch 7, gen_loss = 1.0241466887256643, disc_loss = 0.00037681814000953577
Trained batch 386 in epoch 7, gen_loss = 1.0243086041714178, disc_loss = 0.00037761749869484146
Trained batch 387 in epoch 7, gen_loss = 1.0241427206501519, disc_loss = 0.00037814296156846974
Trained batch 388 in epoch 7, gen_loss = 1.0238325837951698, disc_loss = 0.0003784691506246635
Trained batch 389 in epoch 7, gen_loss = 1.0239288430947524, disc_loss = 0.0003788345389927063
Trained batch 390 in epoch 7, gen_loss = 1.023871879138605, disc_loss = 0.0003792971391194349
Trained batch 391 in epoch 7, gen_loss = 1.0237806138335441, disc_loss = 0.000379552882090398
Trained batch 392 in epoch 7, gen_loss = 1.0239398804026403, disc_loss = 0.0003794397127916936
Trained batch 393 in epoch 7, gen_loss = 1.023947840112115, disc_loss = 0.00037908589174410475
Trained batch 394 in epoch 7, gen_loss = 1.023649206644372, disc_loss = 0.0003786427665430363
Trained batch 395 in epoch 7, gen_loss = 1.0237034342505715, disc_loss = 0.00037840397083463624
Trained batch 396 in epoch 7, gen_loss = 1.0236048229995842, disc_loss = 0.00037822363958381745
Trained batch 397 in epoch 7, gen_loss = 1.023637343591182, disc_loss = 0.00037813545327366566
Trained batch 398 in epoch 7, gen_loss = 1.0233949969585676, disc_loss = 0.0003781716502515948
Trained batch 399 in epoch 7, gen_loss = 1.0232214385271072, disc_loss = 0.00037820379361619416
Trained batch 400 in epoch 7, gen_loss = 1.0234571002665303, disc_loss = 0.00037818052801424045
Trained batch 401 in epoch 7, gen_loss = 1.0235200023176658, disc_loss = 0.000378124053262111
Trained batch 402 in epoch 7, gen_loss = 1.0233620908065115, disc_loss = 0.0003782750774768127
Trained batch 403 in epoch 7, gen_loss = 1.0234104061480795, disc_loss = 0.0003786255097336402
Trained batch 404 in epoch 7, gen_loss = 1.0234948914728046, disc_loss = 0.0003787453954210821
Trained batch 405 in epoch 7, gen_loss = 1.0232776547300404, disc_loss = 0.0003784558713261074
Trained batch 406 in epoch 7, gen_loss = 1.0233878442051956, disc_loss = 0.0003781311374559686
Trained batch 407 in epoch 7, gen_loss = 1.0233314005183238, disc_loss = 0.00037794155082783795
Trained batch 408 in epoch 7, gen_loss = 1.0234116825905872, disc_loss = 0.00037773918906221915
Trained batch 409 in epoch 7, gen_loss = 1.0234524354702088, disc_loss = 0.00037769856723415856
Trained batch 410 in epoch 7, gen_loss = 1.0235318357346992, disc_loss = 0.00037758194330286344
Trained batch 411 in epoch 7, gen_loss = 1.0235707866914063, disc_loss = 0.00037727878927257426
Trained batch 412 in epoch 7, gen_loss = 1.0235918803596036, disc_loss = 0.00037694689817550437
Trained batch 413 in epoch 7, gen_loss = 1.023684311028264, disc_loss = 0.0003764513276549307
Trained batch 414 in epoch 7, gen_loss = 1.0236518130244978, disc_loss = 0.00037579333611465263
Trained batch 415 in epoch 7, gen_loss = 1.0235831276155436, disc_loss = 0.0003751768968396181
Trained batch 416 in epoch 7, gen_loss = 1.0236211311902932, disc_loss = 0.0003745976034488347
Trained batch 417 in epoch 7, gen_loss = 1.0234126432945854, disc_loss = 0.00037409299144357873
Trained batch 418 in epoch 7, gen_loss = 1.0234706801560158, disc_loss = 0.00037365533368055473
Trained batch 419 in epoch 7, gen_loss = 1.0235554932128816, disc_loss = 0.0003730976992994242
Trained batch 420 in epoch 7, gen_loss = 1.023471188233754, disc_loss = 0.00037263301237976576
Trained batch 421 in epoch 7, gen_loss = 1.0234576490535556, disc_loss = 0.00037248045383761935
Trained batch 422 in epoch 7, gen_loss = 1.0234122212896957, disc_loss = 0.0003726995861448538
Trained batch 423 in epoch 7, gen_loss = 1.023476039604196, disc_loss = 0.0003729621562171197
Trained batch 424 in epoch 7, gen_loss = 1.0234118970702677, disc_loss = 0.0003731982972941991
Trained batch 425 in epoch 7, gen_loss = 1.0234802976740358, disc_loss = 0.0003737510168931623
Trained batch 426 in epoch 7, gen_loss = 1.023418244070415, disc_loss = 0.0003749805542756122
Trained batch 427 in epoch 7, gen_loss = 1.023246698151125, disc_loss = 0.0003766811763785184
Trained batch 428 in epoch 7, gen_loss = 1.0232332346044777, disc_loss = 0.0003781924207480044
Trained batch 429 in epoch 7, gen_loss = 1.02326013390408, disc_loss = 0.00037903774511590223
Trained batch 430 in epoch 7, gen_loss = 1.023228538700157, disc_loss = 0.0003792347230983216
Trained batch 431 in epoch 7, gen_loss = 1.02323827933934, disc_loss = 0.00037921440337885105
Trained batch 432 in epoch 7, gen_loss = 1.0229846356096775, disc_loss = 0.0003790772787871847
Trained batch 433 in epoch 7, gen_loss = 1.0229099037185791, disc_loss = 0.0003787682277517536
Trained batch 434 in epoch 7, gen_loss = 1.0229902838838512, disc_loss = 0.0003783319622559885
Trained batch 435 in epoch 7, gen_loss = 1.0228299304432826, disc_loss = 0.0003777704831993623
Trained batch 436 in epoch 7, gen_loss = 1.0227693949465892, disc_loss = 0.0003771842567991914
Trained batch 437 in epoch 7, gen_loss = 1.0227943865675904, disc_loss = 0.00037658136130780243
Trained batch 438 in epoch 7, gen_loss = 1.0229517949197722, disc_loss = 0.00037603608370462386
Trained batch 439 in epoch 7, gen_loss = 1.022973462397402, disc_loss = 0.0003755198912916636
Trained batch 440 in epoch 7, gen_loss = 1.0231102299528056, disc_loss = 0.0003749896035816224
Trained batch 441 in epoch 7, gen_loss = 1.0232651230976053, disc_loss = 0.00037442454733569504
Trained batch 442 in epoch 7, gen_loss = 1.023115447358676, disc_loss = 0.00037377916473907663
Trained batch 443 in epoch 7, gen_loss = 1.0232337004429586, disc_loss = 0.0003731139880540935
Trained batch 444 in epoch 7, gen_loss = 1.023154768783055, disc_loss = 0.000372525163884654
Trained batch 445 in epoch 7, gen_loss = 1.0230467217920072, disc_loss = 0.0003720205243679642
Trained batch 446 in epoch 7, gen_loss = 1.0228756063469837, disc_loss = 0.00037169401550081336
Trained batch 447 in epoch 7, gen_loss = 1.0229725055396557, disc_loss = 0.0003716440355755627
Trained batch 448 in epoch 7, gen_loss = 1.022906282298549, disc_loss = 0.0003716528214432454
Trained batch 449 in epoch 7, gen_loss = 1.0228848090436724, disc_loss = 0.0003715643385092133
Trained batch 450 in epoch 7, gen_loss = 1.022763524377954, disc_loss = 0.0003712989562664087
Trained batch 451 in epoch 7, gen_loss = 1.0227949011378583, disc_loss = 0.00037094901000651523
Trained batch 452 in epoch 7, gen_loss = 1.0229263878026544, disc_loss = 0.00037084794532134767
Trained batch 453 in epoch 7, gen_loss = 1.0228243182671752, disc_loss = 0.00037135752964958943
Trained batch 454 in epoch 7, gen_loss = 1.0228645071878537, disc_loss = 0.00037255989782452063
Trained batch 455 in epoch 7, gen_loss = 1.022845190737331, disc_loss = 0.0003739816022875618
Trained batch 456 in epoch 7, gen_loss = 1.0228778826851292, disc_loss = 0.00037502414543627197
Trained batch 457 in epoch 7, gen_loss = 1.0228401907927085, disc_loss = 0.0003758519473687088
Trained batch 458 in epoch 7, gen_loss = 1.0229007905604792, disc_loss = 0.00037646103597354914
Trained batch 459 in epoch 7, gen_loss = 1.022796042976172, disc_loss = 0.0003767756204979378
Trained batch 460 in epoch 7, gen_loss = 1.0226395084904487, disc_loss = 0.0003768361862797473
Trained batch 461 in epoch 7, gen_loss = 1.0228549945148038, disc_loss = 0.0003770993730521109
Trained batch 462 in epoch 7, gen_loss = 1.0228251513600606, disc_loss = 0.00037753515835876823
Trained batch 463 in epoch 7, gen_loss = 1.0228977949711784, disc_loss = 0.0003776649687646066
Trained batch 464 in epoch 7, gen_loss = 1.0229975173550268, disc_loss = 0.0003775269924791314
Trained batch 465 in epoch 7, gen_loss = 1.0230547697503167, disc_loss = 0.0003771837587849174
Trained batch 466 in epoch 7, gen_loss = 1.0232112633594863, disc_loss = 0.0003766498791305792
Trained batch 467 in epoch 7, gen_loss = 1.0230033575979054, disc_loss = 0.00037616660279321583
Trained batch 468 in epoch 7, gen_loss = 1.0230504709011965, disc_loss = 0.0003758619209011914
Trained batch 469 in epoch 7, gen_loss = 1.022992084000973, disc_loss = 0.0003756955371964649
Trained batch 470 in epoch 7, gen_loss = 1.022884721209289, disc_loss = 0.0003755638333195806
Trained batch 471 in epoch 7, gen_loss = 1.0231868521136753, disc_loss = 0.00037553147263155306
Trained batch 472 in epoch 7, gen_loss = 1.0231917587445605, disc_loss = 0.00037570186767385766
Trained batch 473 in epoch 7, gen_loss = 1.0232964233507085, disc_loss = 0.00037606972143259577
Trained batch 474 in epoch 7, gen_loss = 1.0233468173679552, disc_loss = 0.0003763659945520646
Trained batch 475 in epoch 7, gen_loss = 1.0231848554450924, disc_loss = 0.00037656218499541253
Trained batch 476 in epoch 7, gen_loss = 1.0232620486673318, disc_loss = 0.00037679764009950894
Trained batch 477 in epoch 7, gen_loss = 1.0234175613734513, disc_loss = 0.00037695725297461074
Trained batch 478 in epoch 7, gen_loss = 1.023304190914417, disc_loss = 0.00037686567886039616
Trained batch 479 in epoch 7, gen_loss = 1.0233556523919105, disc_loss = 0.00037678756726412154
Trained batch 480 in epoch 7, gen_loss = 1.0233765696785306, disc_loss = 0.0003769396356113469
Trained batch 481 in epoch 7, gen_loss = 1.0236088272446913, disc_loss = 0.00037728445735622123
Trained batch 482 in epoch 7, gen_loss = 1.0237130578260245, disc_loss = 0.00037763001832815307
Trained batch 483 in epoch 7, gen_loss = 1.0236274590176984, disc_loss = 0.00037801201231875084
Trained batch 484 in epoch 7, gen_loss = 1.0237898054811143, disc_loss = 0.00037838001700253804
Trained batch 485 in epoch 7, gen_loss = 1.0236644334017986, disc_loss = 0.00037865310133447527
Trained batch 486 in epoch 7, gen_loss = 1.0236008627458764, disc_loss = 0.00037872456501361634
Trained batch 487 in epoch 7, gen_loss = 1.023496366426593, disc_loss = 0.0003786706503485563
Trained batch 488 in epoch 7, gen_loss = 1.02337987023141, disc_loss = 0.00037862666014845935
Trained batch 489 in epoch 7, gen_loss = 1.023218116589955, disc_loss = 0.00037855542638625387
Trained batch 490 in epoch 7, gen_loss = 1.02321541345775, disc_loss = 0.0003784932246597796
Trained batch 491 in epoch 7, gen_loss = 1.0230920458954524, disc_loss = 0.0003784383562390765
Trained batch 492 in epoch 7, gen_loss = 1.0230288912993657, disc_loss = 0.00037843482936790327
Trained batch 493 in epoch 7, gen_loss = 1.0229021717420956, disc_loss = 0.0003785741984373951
Trained batch 494 in epoch 7, gen_loss = 1.0230504513991, disc_loss = 0.0003789245594963737
Trained batch 495 in epoch 7, gen_loss = 1.0230518686434915, disc_loss = 0.00037937661071033116
Trained batch 496 in epoch 7, gen_loss = 1.023129338109997, disc_loss = 0.0003798849158970123
Trained batch 497 in epoch 7, gen_loss = 1.0230581971057449, disc_loss = 0.0003804028648268885
Trained batch 498 in epoch 7, gen_loss = 1.0232494940499743, disc_loss = 0.0003810357487388258
Trained batch 499 in epoch 7, gen_loss = 1.0230326062440873, disc_loss = 0.00038145604666351573
Trained batch 500 in epoch 7, gen_loss = 1.0230571437262728, disc_loss = 0.000381427550181654
Trained batch 501 in epoch 7, gen_loss = 1.0229976470489426, disc_loss = 0.0003810438158100613
Trained batch 502 in epoch 7, gen_loss = 1.0229007111155015, disc_loss = 0.0003806207129546274
Trained batch 503 in epoch 7, gen_loss = 1.0227314177013578, disc_loss = 0.00038020257971722806
Trained batch 504 in epoch 7, gen_loss = 1.0227547364659828, disc_loss = 0.0003798339339068256
Trained batch 505 in epoch 7, gen_loss = 1.0228388594544453, disc_loss = 0.00037948141631463466
Trained batch 506 in epoch 7, gen_loss = 1.0229340857537776, disc_loss = 0.0003793355341290865
Trained batch 507 in epoch 7, gen_loss = 1.022756322162358, disc_loss = 0.00037952331240376225
Trained batch 508 in epoch 7, gen_loss = 1.022942607669793, disc_loss = 0.0003800256735801789
Trained batch 509 in epoch 7, gen_loss = 1.0230715001330657, disc_loss = 0.00038040668342528437
Trained batch 510 in epoch 7, gen_loss = 1.023207529883562, disc_loss = 0.00038040878179916197
Trained batch 511 in epoch 7, gen_loss = 1.0232481295242906, disc_loss = 0.0003801038994097894
Trained batch 512 in epoch 7, gen_loss = 1.023327535820751, disc_loss = 0.00037964249468327055
Trained batch 513 in epoch 7, gen_loss = 1.0232723842335119, disc_loss = 0.00037915294015389853
Trained batch 514 in epoch 7, gen_loss = 1.0231441280216846, disc_loss = 0.0003786629506737758
Trained batch 515 in epoch 7, gen_loss = 1.0231943091218785, disc_loss = 0.0003782221377453728
Trained batch 516 in epoch 7, gen_loss = 1.0231718694218352, disc_loss = 0.0003778505353827315
Trained batch 517 in epoch 7, gen_loss = 1.0232705080371105, disc_loss = 0.0003774219662228956
Trained batch 518 in epoch 7, gen_loss = 1.023290882220847, disc_loss = 0.0003769489890225218
Trained batch 519 in epoch 7, gen_loss = 1.0234457827531374, disc_loss = 0.0003766051512964343
Trained batch 520 in epoch 7, gen_loss = 1.0233865500411694, disc_loss = 0.00037621096005282747
Trained batch 521 in epoch 7, gen_loss = 1.0233240486104827, disc_loss = 0.0003757555134484827
Trained batch 522 in epoch 7, gen_loss = 1.0232830651631546, disc_loss = 0.00037529521393635305
Trained batch 523 in epoch 7, gen_loss = 1.023372150331963, disc_loss = 0.00037483329024950784
Trained batch 524 in epoch 7, gen_loss = 1.0233237727483113, disc_loss = 0.00037431867849331216
Trained batch 525 in epoch 7, gen_loss = 1.0233477320054638, disc_loss = 0.0003737667209813269
Trained batch 526 in epoch 7, gen_loss = 1.0232314641606877, disc_loss = 0.0003732281314872141
Trained batch 527 in epoch 7, gen_loss = 1.0231939437940265, disc_loss = 0.00037266111421145484
Trained batch 528 in epoch 7, gen_loss = 1.023014779014263, disc_loss = 0.0003721037831955518
Trained batch 529 in epoch 7, gen_loss = 1.023134784316117, disc_loss = 0.0003717407456037417
Trained batch 530 in epoch 7, gen_loss = 1.0231188543547793, disc_loss = 0.00037145632448749356
Trained batch 531 in epoch 7, gen_loss = 1.0230144025911962, disc_loss = 0.00037134875677801934
Trained batch 532 in epoch 7, gen_loss = 1.0231843134475693, disc_loss = 0.00037114664994375245
Trained batch 533 in epoch 7, gen_loss = 1.0233169574192846, disc_loss = 0.00037079491272372714
Trained batch 534 in epoch 7, gen_loss = 1.0233624368070442, disc_loss = 0.00037041993591543855
Trained batch 535 in epoch 7, gen_loss = 1.0233887263865613, disc_loss = 0.00036999535709651016
Trained batch 536 in epoch 7, gen_loss = 1.0235861179104953, disc_loss = 0.00036952954849248424
Trained batch 537 in epoch 7, gen_loss = 1.023448702460328, disc_loss = 0.000369048752774864
Trained batch 538 in epoch 7, gen_loss = 1.0235653028638554, disc_loss = 0.0003685514938481198
Trained batch 539 in epoch 7, gen_loss = 1.0235392569391817, disc_loss = 0.00036801212324833073
Trained batch 540 in epoch 7, gen_loss = 1.0233241137867715, disc_loss = 0.0003675114863509439
Trained batch 541 in epoch 7, gen_loss = 1.02324523488094, disc_loss = 0.00036713229332155096
Trained batch 542 in epoch 7, gen_loss = 1.0233015093136009, disc_loss = 0.0003667603682607741
Trained batch 543 in epoch 7, gen_loss = 1.0233054880929344, disc_loss = 0.0003663305060065207
Trained batch 544 in epoch 7, gen_loss = 1.0232411423954395, disc_loss = 0.0003659871956021119
Trained batch 545 in epoch 7, gen_loss = 1.0231189959215157, disc_loss = 0.0003656660714107305
Trained batch 546 in epoch 7, gen_loss = 1.0231400625797251, disc_loss = 0.00036528472647183045
Trained batch 547 in epoch 7, gen_loss = 1.02300562638871, disc_loss = 0.0003648916930694751
Trained batch 548 in epoch 7, gen_loss = 1.0230286995352726, disc_loss = 0.0003645547887128341
Trained batch 549 in epoch 7, gen_loss = 1.0229965020309795, disc_loss = 0.0003642453775484517
Trained batch 550 in epoch 7, gen_loss = 1.0228044723858634, disc_loss = 0.00036397637478527005
Trained batch 551 in epoch 7, gen_loss = 1.0227840863492177, disc_loss = 0.0003637807981512974
Trained batch 552 in epoch 7, gen_loss = 1.022722273041068, disc_loss = 0.00036364430670998444
Trained batch 553 in epoch 7, gen_loss = 1.0225811422086364, disc_loss = 0.00036341983063934693
Trained batch 554 in epoch 7, gen_loss = 1.022514490393905, disc_loss = 0.00036314220677275707
Trained batch 555 in epoch 7, gen_loss = 1.0226928501678028, disc_loss = 0.00036295235006965945
Trained batch 556 in epoch 7, gen_loss = 1.0226299225534956, disc_loss = 0.00036298929344852457
Trained batch 557 in epoch 7, gen_loss = 1.0225904237839483, disc_loss = 0.0003629566033714093
Trained batch 558 in epoch 7, gen_loss = 1.0225413529092382, disc_loss = 0.00036290724156044335
Trained batch 559 in epoch 7, gen_loss = 1.022423421059336, disc_loss = 0.0003630688877754957
Trained batch 560 in epoch 7, gen_loss = 1.0223725740922327, disc_loss = 0.00036327869822340685
Trained batch 561 in epoch 7, gen_loss = 1.0225841996932794, disc_loss = 0.00036357103941502884
Trained batch 562 in epoch 7, gen_loss = 1.0225932449896424, disc_loss = 0.000363894162247928
Trained batch 563 in epoch 7, gen_loss = 1.0224374377347054, disc_loss = 0.00036401587698466423
Trained batch 564 in epoch 7, gen_loss = 1.0224805375116062, disc_loss = 0.0003638504357558811
Trained batch 565 in epoch 7, gen_loss = 1.0225121240944408, disc_loss = 0.0003634578807568141
Trained batch 566 in epoch 7, gen_loss = 1.0225446223161418, disc_loss = 0.0003629666461754156
Trained batch 567 in epoch 7, gen_loss = 1.0224548948692604, disc_loss = 0.00036251529222617663
Trained batch 568 in epoch 7, gen_loss = 1.022524095901496, disc_loss = 0.0003622293206685618
Trained batch 569 in epoch 7, gen_loss = 1.0226757753313633, disc_loss = 0.00036203773241523827
Trained batch 570 in epoch 7, gen_loss = 1.0226545806732779, disc_loss = 0.0003617943935677831
Trained batch 571 in epoch 7, gen_loss = 1.0228265633324642, disc_loss = 0.00036146590195563046
Trained batch 572 in epoch 7, gen_loss = 1.0228012075182864, disc_loss = 0.00036101868216979017
Trained batch 573 in epoch 7, gen_loss = 1.0227526348434675, disc_loss = 0.00036055519168013875
Trained batch 574 in epoch 7, gen_loss = 1.0226866141609523, disc_loss = 0.0003601335475421207
Trained batch 575 in epoch 7, gen_loss = 1.022705092198319, disc_loss = 0.0003597466110313184
Trained batch 576 in epoch 7, gen_loss = 1.022680747447022, disc_loss = 0.00035931673624854015
Trained batch 577 in epoch 7, gen_loss = 1.022505697185193, disc_loss = 0.000358863218292861
Trained batch 578 in epoch 7, gen_loss = 1.0224955043850372, disc_loss = 0.0003585237913620952
Trained batch 579 in epoch 7, gen_loss = 1.0225092262029647, disc_loss = 0.00035837273401833453
Trained batch 580 in epoch 7, gen_loss = 1.022509375353073, disc_loss = 0.0003584352354520572
Trained batch 581 in epoch 7, gen_loss = 1.0226121320552433, disc_loss = 0.00035866900377352185
Trained batch 582 in epoch 7, gen_loss = 1.022570781805912, disc_loss = 0.0003588445767926313
Trained batch 583 in epoch 7, gen_loss = 1.022414265736325, disc_loss = 0.00035892303734203466
Trained batch 584 in epoch 7, gen_loss = 1.0223788749458445, disc_loss = 0.0003590261680011848
Trained batch 585 in epoch 7, gen_loss = 1.0225129633023065, disc_loss = 0.00035906597383656265
Trained batch 586 in epoch 7, gen_loss = 1.0224817163696485, disc_loss = 0.00035904545147538947
Trained batch 587 in epoch 7, gen_loss = 1.022544787753196, disc_loss = 0.0003590950803479499
Trained batch 588 in epoch 7, gen_loss = 1.0225814889566198, disc_loss = 0.0003591584425487461
Trained batch 589 in epoch 7, gen_loss = 1.0225298789598174, disc_loss = 0.0003591888673912825
Trained batch 590 in epoch 7, gen_loss = 1.0224299965372747, disc_loss = 0.0003592970222724714
Trained batch 591 in epoch 7, gen_loss = 1.022362262715359, disc_loss = 0.0003595351638892139
Trained batch 592 in epoch 7, gen_loss = 1.0223861471396474, disc_loss = 0.0003599114612925819
Trained batch 593 in epoch 7, gen_loss = 1.022505494380238, disc_loss = 0.00036036184465414444
Trained batch 594 in epoch 7, gen_loss = 1.0225196897482671, disc_loss = 0.00036075537644122225
Trained batch 595 in epoch 7, gen_loss = 1.0223787703970135, disc_loss = 0.00036095241834142915
Trained batch 596 in epoch 7, gen_loss = 1.0224669529764696, disc_loss = 0.000361087503226564
Trained batch 597 in epoch 7, gen_loss = 1.0222968091334785, disc_loss = 0.00036127177514438556
Trained batch 598 in epoch 7, gen_loss = 1.0221438526311184, disc_loss = 0.00036138663063336356
Trained batch 599 in epoch 7, gen_loss = 1.0222183778882026, disc_loss = 0.00036139678466497573
Trained batch 600 in epoch 7, gen_loss = 1.022036039293705, disc_loss = 0.0003612378396412196
Trained batch 601 in epoch 7, gen_loss = 1.0219935675792124, disc_loss = 0.00036101326710509524
Trained batch 602 in epoch 7, gen_loss = 1.0220250891611153, disc_loss = 0.00036078873470171344
Trained batch 603 in epoch 7, gen_loss = 1.0219365839926613, disc_loss = 0.00036054915184746244
Trained batch 604 in epoch 7, gen_loss = 1.0220224524332473, disc_loss = 0.00036041044970095917
Trained batch 605 in epoch 7, gen_loss = 1.022259804085143, disc_loss = 0.00036021082958919435
Trained batch 606 in epoch 7, gen_loss = 1.022065598253756, disc_loss = 0.0003599091778386862
Trained batch 607 in epoch 7, gen_loss = 1.022185123280475, disc_loss = 0.0003596579871208106
Trained batch 608 in epoch 7, gen_loss = 1.022185406269894, disc_loss = 0.00035939726770345284
Trained batch 609 in epoch 7, gen_loss = 1.0221769696376364, disc_loss = 0.00035912974402532705
Trained batch 610 in epoch 7, gen_loss = 1.022250324146252, disc_loss = 0.0003586644099039005
Trained batch 611 in epoch 7, gen_loss = 1.0223945829213834, disc_loss = 0.0003582422108462387
Trained batch 612 in epoch 7, gen_loss = 1.0224435358607555, disc_loss = 0.00035789596845602295
Trained batch 613 in epoch 7, gen_loss = 1.0223672092931666, disc_loss = 0.0003575737433665313
Trained batch 614 in epoch 7, gen_loss = 1.0224574079358482, disc_loss = 0.0003573453775216632
Trained batch 615 in epoch 7, gen_loss = 1.022513774501813, disc_loss = 0.00035711578743462567
Trained batch 616 in epoch 7, gen_loss = 1.0223944762923922, disc_loss = 0.0003568290975100962
Trained batch 617 in epoch 7, gen_loss = 1.0223218120610444, disc_loss = 0.0003566189651965886
Trained batch 618 in epoch 7, gen_loss = 1.0224178471935008, disc_loss = 0.0003564421463396565
Trained batch 619 in epoch 7, gen_loss = 1.0222800753770336, disc_loss = 0.00035625910965585893
Trained batch 620 in epoch 7, gen_loss = 1.0221903726290582, disc_loss = 0.0003560696198507426
Trained batch 621 in epoch 7, gen_loss = 1.0221965289000914, disc_loss = 0.00035583539849417276
Trained batch 622 in epoch 7, gen_loss = 1.0221491530657196, disc_loss = 0.00035554158076471845
Trained batch 623 in epoch 7, gen_loss = 1.0222322460359488, disc_loss = 0.00035525563706729514
Trained batch 624 in epoch 7, gen_loss = 1.0222162472724914, disc_loss = 0.00035500071765272876
Trained batch 625 in epoch 7, gen_loss = 1.022139136688397, disc_loss = 0.0003548657758469294
Trained batch 626 in epoch 7, gen_loss = 1.0221678447305111, disc_loss = 0.00035484411321078915
Trained batch 627 in epoch 7, gen_loss = 1.0221876275197717, disc_loss = 0.00035487670677165895
Trained batch 628 in epoch 7, gen_loss = 1.022242971653021, disc_loss = 0.0003549497449488415
Trained batch 629 in epoch 7, gen_loss = 1.0220856068626283, disc_loss = 0.000354990832888039
Trained batch 630 in epoch 7, gen_loss = 1.0221362472902953, disc_loss = 0.00035512591169189724
Trained batch 631 in epoch 7, gen_loss = 1.0221143874186505, disc_loss = 0.00035527655480316615
Trained batch 632 in epoch 7, gen_loss = 1.02204688126442, disc_loss = 0.0003552969373020253
Trained batch 633 in epoch 7, gen_loss = 1.0222743031354358, disc_loss = 0.0003551327816079123
Trained batch 634 in epoch 7, gen_loss = 1.022273445692588, disc_loss = 0.000354848059684205
Trained batch 635 in epoch 7, gen_loss = 1.022274376648777, disc_loss = 0.0003546871436679199
Trained batch 636 in epoch 7, gen_loss = 1.0221681353435785, disc_loss = 0.0003545647466884106
Trained batch 637 in epoch 7, gen_loss = 1.022261545015353, disc_loss = 0.0003545241959322865
Trained batch 638 in epoch 7, gen_loss = 1.0222830651138497, disc_loss = 0.00035447770155577687
Trained batch 639 in epoch 7, gen_loss = 1.0221047585830092, disc_loss = 0.00035438240083180973
Trained batch 640 in epoch 7, gen_loss = 1.0220873551138105, disc_loss = 0.00035460596153883637
Trained batch 641 in epoch 7, gen_loss = 1.0219572123337386, disc_loss = 0.00035522157672843993
Trained batch 642 in epoch 7, gen_loss = 1.0217782414719625, disc_loss = 0.0003557393219935998
Trained batch 643 in epoch 7, gen_loss = 1.0216845662697502, disc_loss = 0.00035599688673405497
Trained batch 644 in epoch 7, gen_loss = 1.0216788779857546, disc_loss = 0.00035600716291810385
Trained batch 645 in epoch 7, gen_loss = 1.0218141256102098, disc_loss = 0.0003558590574005396
Trained batch 646 in epoch 7, gen_loss = 1.0217088656226487, disc_loss = 0.00035566381581099394
Trained batch 647 in epoch 7, gen_loss = 1.0217035782557946, disc_loss = 0.00035567484492051414
Trained batch 648 in epoch 7, gen_loss = 1.0215723823141794, disc_loss = 0.0003559064955085294
Trained batch 649 in epoch 7, gen_loss = 1.0216135813639715, disc_loss = 0.00035629717448990467
Trained batch 650 in epoch 7, gen_loss = 1.021576698108386, disc_loss = 0.00035672865644899
Trained batch 651 in epoch 7, gen_loss = 1.0216186726751504, disc_loss = 0.0003569568863973372
Trained batch 652 in epoch 7, gen_loss = 1.0215691532511806, disc_loss = 0.0003569922210670673
Trained batch 653 in epoch 7, gen_loss = 1.0214923450706201, disc_loss = 0.0003569106651778993
Trained batch 654 in epoch 7, gen_loss = 1.021493574317175, disc_loss = 0.00035670800767159124
Trained batch 655 in epoch 7, gen_loss = 1.0214968527235635, disc_loss = 0.0003564355669002508
Trained batch 656 in epoch 7, gen_loss = 1.0215967523452898, disc_loss = 0.00035616263167331417
Trained batch 657 in epoch 7, gen_loss = 1.021678766762232, disc_loss = 0.00035593895255484493
Trained batch 658 in epoch 7, gen_loss = 1.0216603874255745, disc_loss = 0.0003556356514336902
Trained batch 659 in epoch 7, gen_loss = 1.0215361496715836, disc_loss = 0.00035531044519082183
Trained batch 660 in epoch 7, gen_loss = 1.0216322144473735, disc_loss = 0.00035505955335563477
Trained batch 661 in epoch 7, gen_loss = 1.0215111499106415, disc_loss = 0.0003549863206726211
Trained batch 662 in epoch 7, gen_loss = 1.021565974927416, disc_loss = 0.0003551792504869842
Trained batch 663 in epoch 7, gen_loss = 1.0215659128973282, disc_loss = 0.00035546713391351704
Trained batch 664 in epoch 7, gen_loss = 1.0215863756667403, disc_loss = 0.00035573331020659544
Trained batch 665 in epoch 7, gen_loss = 1.0213808134511426, disc_loss = 0.0003560081071986564
Trained batch 666 in epoch 7, gen_loss = 1.0212819983755452, disc_loss = 0.00035636269180061374
Trained batch 667 in epoch 7, gen_loss = 1.0211879028353148, disc_loss = 0.0003567633863301403
Trained batch 668 in epoch 7, gen_loss = 1.0211462833778029, disc_loss = 0.0003569372734682678
Trained batch 669 in epoch 7, gen_loss = 1.0210812601580548, disc_loss = 0.0003568685360271536
Trained batch 670 in epoch 7, gen_loss = 1.0210175206870862, disc_loss = 0.00035668254773709026
Trained batch 671 in epoch 7, gen_loss = 1.020938111380452, disc_loss = 0.00035646287076793843
Trained batch 672 in epoch 7, gen_loss = 1.0208833321242594, disc_loss = 0.0003562481407834031
Trained batch 673 in epoch 7, gen_loss = 1.021011136140597, disc_loss = 0.0003560435361740057
Trained batch 674 in epoch 7, gen_loss = 1.0210336551842867, disc_loss = 0.00035587944201931045
Trained batch 675 in epoch 7, gen_loss = 1.0209500875169708, disc_loss = 0.00035586740334390645
Trained batch 676 in epoch 7, gen_loss = 1.0208842864416903, disc_loss = 0.0003560886442630935
Trained batch 677 in epoch 7, gen_loss = 1.020856981871754, disc_loss = 0.00035655729471757193
Trained batch 678 in epoch 7, gen_loss = 1.020775005638336, disc_loss = 0.00035731039223423544
Trained batch 679 in epoch 7, gen_loss = 1.0206607706406536, disc_loss = 0.0003582772565952088
Trained batch 680 in epoch 7, gen_loss = 1.0205253985834892, disc_loss = 0.000359124487271543
Trained batch 681 in epoch 7, gen_loss = 1.0205006001631884, disc_loss = 0.000359940410195773
Trained batch 682 in epoch 7, gen_loss = 1.020531068783728, disc_loss = 0.0003605981570060278
Trained batch 683 in epoch 7, gen_loss = 1.0205362005191936, disc_loss = 0.00036101334602503093
Trained batch 684 in epoch 7, gen_loss = 1.0207220869342777, disc_loss = 0.00036126911150181944
Trained batch 685 in epoch 7, gen_loss = 1.0207907091771895, disc_loss = 0.00036157405735807237
Trained batch 686 in epoch 7, gen_loss = 1.0207198186732795, disc_loss = 0.00036190834048039245
Trained batch 687 in epoch 7, gen_loss = 1.0208321298624194, disc_loss = 0.00036205119595992034
Trained batch 688 in epoch 7, gen_loss = 1.0208016532771993, disc_loss = 0.0003619456846323672
Trained batch 689 in epoch 7, gen_loss = 1.0207807216955267, disc_loss = 0.0003616630892635009
Trained batch 690 in epoch 7, gen_loss = 1.0207562461258188, disc_loss = 0.0003612789646579595
Trained batch 691 in epoch 7, gen_loss = 1.020742101907041, disc_loss = 0.00036090932263962614
Trained batch 692 in epoch 7, gen_loss = 1.020728130275209, disc_loss = 0.00036059614157386984
Trained batch 693 in epoch 7, gen_loss = 1.0207671712901476, disc_loss = 0.00036038488858639934
Trained batch 694 in epoch 7, gen_loss = 1.0208339937299276, disc_loss = 0.00036026184016728954
Trained batch 695 in epoch 7, gen_loss = 1.0208705337396984, disc_loss = 0.00036023710974885704
Trained batch 696 in epoch 7, gen_loss = 1.0208605535574247, disc_loss = 0.00036026362864801845
Trained batch 697 in epoch 7, gen_loss = 1.0207205880166466, disc_loss = 0.0003604567220547042
Trained batch 698 in epoch 7, gen_loss = 1.020627570169337, disc_loss = 0.00036075175734099767
Trained batch 699 in epoch 7, gen_loss = 1.0206008113282068, disc_loss = 0.00036092061668439006
Trained batch 700 in epoch 7, gen_loss = 1.020507720329622, disc_loss = 0.00036099356662030476
Trained batch 701 in epoch 7, gen_loss = 1.0205281179854673, disc_loss = 0.0003608967459497677
Trained batch 702 in epoch 7, gen_loss = 1.0205788498752317, disc_loss = 0.00036065133229736137
Trained batch 703 in epoch 7, gen_loss = 1.020669014108452, disc_loss = 0.0003603922432427515
Trained batch 704 in epoch 7, gen_loss = 1.0206083071992753, disc_loss = 0.00036021576287057286
Trained batch 705 in epoch 7, gen_loss = 1.0205660971467285, disc_loss = 0.00036009787020499246
Trained batch 706 in epoch 7, gen_loss = 1.0205292936936126, disc_loss = 0.0003600187830112317
Trained batch 707 in epoch 7, gen_loss = 1.0205126693524884, disc_loss = 0.0003599332475855616
Trained batch 708 in epoch 7, gen_loss = 1.0204902087851875, disc_loss = 0.0003597374088456411
Trained batch 709 in epoch 7, gen_loss = 1.020405514727176, disc_loss = 0.00035937712294673447
Trained batch 710 in epoch 7, gen_loss = 1.0203428683401663, disc_loss = 0.000358961616608921
Trained batch 711 in epoch 7, gen_loss = 1.0203505972965379, disc_loss = 0.00035858859091399863
Trained batch 712 in epoch 7, gen_loss = 1.0203299588441515, disc_loss = 0.00035822895811938454
Trained batch 713 in epoch 7, gen_loss = 1.0203512896175813, disc_loss = 0.0003578652465402221
Trained batch 714 in epoch 7, gen_loss = 1.0202404039723056, disc_loss = 0.0003575133759895962
Trained batch 715 in epoch 7, gen_loss = 1.02025038295285, disc_loss = 0.000357195516226463
Trained batch 716 in epoch 7, gen_loss = 1.0201846473386598, disc_loss = 0.00035688789093111465
Trained batch 717 in epoch 7, gen_loss = 1.0202516605429, disc_loss = 0.00035658833442344545
Trained batch 718 in epoch 7, gen_loss = 1.0202282938240963, disc_loss = 0.00035627412362575824
Trained batch 719 in epoch 7, gen_loss = 1.0201126173966462, disc_loss = 0.000355986721393088
Trained batch 720 in epoch 7, gen_loss = 1.0200624425434373, disc_loss = 0.00035574597313068647
Trained batch 721 in epoch 7, gen_loss = 1.0199864396923466, disc_loss = 0.0003555389619154654
Trained batch 722 in epoch 7, gen_loss = 1.0199571672316903, disc_loss = 0.0003552778175434875
Trained batch 723 in epoch 7, gen_loss = 1.020028020548557, disc_loss = 0.00035505640581751064
Trained batch 724 in epoch 7, gen_loss = 1.0200763275705536, disc_loss = 0.0003549535082731444
Trained batch 725 in epoch 7, gen_loss = 1.0201039385697073, disc_loss = 0.00035495874481082456
Trained batch 726 in epoch 7, gen_loss = 1.0201554231991303, disc_loss = 0.00035508595554790127
Trained batch 727 in epoch 7, gen_loss = 1.0201097041532234, disc_loss = 0.00035515333437225697
Trained batch 728 in epoch 7, gen_loss = 1.020082946912742, disc_loss = 0.0003550696879015218
Trained batch 729 in epoch 7, gen_loss = 1.0201444634836014, disc_loss = 0.0003548768220964918
Trained batch 730 in epoch 7, gen_loss = 1.0201589900556896, disc_loss = 0.0003546684573526082
Trained batch 731 in epoch 7, gen_loss = 1.0201984618693754, disc_loss = 0.00035445367389076607
Trained batch 732 in epoch 7, gen_loss = 1.020231346235106, disc_loss = 0.00035423365296264074
Trained batch 733 in epoch 7, gen_loss = 1.0202885168612166, disc_loss = 0.00035400245880925547
Trained batch 734 in epoch 7, gen_loss = 1.0202044307780103, disc_loss = 0.00035379718912216567
Trained batch 735 in epoch 7, gen_loss = 1.020252574964062, disc_loss = 0.0003536995601309726
Trained batch 736 in epoch 7, gen_loss = 1.0201541458735472, disc_loss = 0.0003537872441929561
Trained batch 737 in epoch 7, gen_loss = 1.0201152811851606, disc_loss = 0.0003540400635229211
Trained batch 738 in epoch 7, gen_loss = 1.0199395135065215, disc_loss = 0.0003543660480863272
Trained batch 739 in epoch 7, gen_loss = 1.0198895830560375, disc_loss = 0.00035469125874393234
Trained batch 740 in epoch 7, gen_loss = 1.019914588384461, disc_loss = 0.0003550573292822032
Trained batch 741 in epoch 7, gen_loss = 1.0200605590870437, disc_loss = 0.0003555080878025161
Trained batch 742 in epoch 7, gen_loss = 1.0199842742602887, disc_loss = 0.0003558979691046589
Trained batch 743 in epoch 7, gen_loss = 1.0198348714138872, disc_loss = 0.00035616242555460624
Trained batch 744 in epoch 7, gen_loss = 1.0196912556686657, disc_loss = 0.0003562794809357416
Trained batch 745 in epoch 7, gen_loss = 1.019607625202583, disc_loss = 0.00035618844478800435
Trained batch 746 in epoch 7, gen_loss = 1.01962303548772, disc_loss = 0.00035602016208553593
Trained batch 747 in epoch 7, gen_loss = 1.0196133924518678, disc_loss = 0.00035584315563825847
Trained batch 748 in epoch 7, gen_loss = 1.0195796995042004, disc_loss = 0.00035566604660057836
Trained batch 749 in epoch 7, gen_loss = 1.0195342466831208, disc_loss = 0.0003555412880135312
Trained batch 750 in epoch 7, gen_loss = 1.0194503873705705, disc_loss = 0.00035551042079961343
Trained batch 751 in epoch 7, gen_loss = 1.0194811998529638, disc_loss = 0.00035554417822242343
Trained batch 752 in epoch 7, gen_loss = 1.0194232045891751, disc_loss = 0.00035554491165665334
Trained batch 753 in epoch 7, gen_loss = 1.0193006769415554, disc_loss = 0.0003554713612922825
Trained batch 754 in epoch 7, gen_loss = 1.0192515766383796, disc_loss = 0.00035530265775992573
Trained batch 755 in epoch 7, gen_loss = 1.019144565103546, disc_loss = 0.0003550616545658038
Trained batch 756 in epoch 7, gen_loss = 1.019226239962181, disc_loss = 0.0003548106860245724
Trained batch 757 in epoch 7, gen_loss = 1.0192807863287057, disc_loss = 0.00035454343720860653
Trained batch 758 in epoch 7, gen_loss = 1.0193156059708677, disc_loss = 0.0003542586325786131
Trained batch 759 in epoch 7, gen_loss = 1.0191396996378899, disc_loss = 0.00035394879188109036
Trained batch 760 in epoch 7, gen_loss = 1.0190225643021362, disc_loss = 0.00035363618393287734
Trained batch 761 in epoch 7, gen_loss = 1.019002393709393, disc_loss = 0.00035334020039262074
Trained batch 762 in epoch 7, gen_loss = 1.0189811393599053, disc_loss = 0.00035297643659961515
Trained batch 763 in epoch 7, gen_loss = 1.0188704116650278, disc_loss = 0.0003526186881629498
Trained batch 764 in epoch 7, gen_loss = 1.0188978435946445, disc_loss = 0.00035230735063593186
Trained batch 765 in epoch 7, gen_loss = 1.0188536532709556, disc_loss = 0.0003520157332413945
Trained batch 766 in epoch 7, gen_loss = 1.0187356502322826, disc_loss = 0.0003517446596903749
Trained batch 767 in epoch 7, gen_loss = 1.0186710169073194, disc_loss = 0.0003514586470079924
Trained batch 768 in epoch 7, gen_loss = 1.0186756194335431, disc_loss = 0.0003511479820430376
Trained batch 769 in epoch 7, gen_loss = 1.0185809216716073, disc_loss = 0.0003507762841811153
Trained batch 770 in epoch 7, gen_loss = 1.0186243020916108, disc_loss = 0.0003503961763694253
Trained batch 771 in epoch 7, gen_loss = 1.0186526397812552, disc_loss = 0.0003500560253341785
Trained batch 772 in epoch 7, gen_loss = 1.0185066269563672, disc_loss = 0.0003497337734464973
Trained batch 773 in epoch 7, gen_loss = 1.0183803089521344, disc_loss = 0.000349432875252842
Trained batch 774 in epoch 7, gen_loss = 1.0183630974062028, disc_loss = 0.00034917523991504325
Trained batch 775 in epoch 7, gen_loss = 1.0183973180264543, disc_loss = 0.00034895026423440605
Trained batch 776 in epoch 7, gen_loss = 1.0184595934672704, disc_loss = 0.00034874298095625517
Trained batch 777 in epoch 7, gen_loss = 1.0185270838075555, disc_loss = 0.00034858877413912443
Trained batch 778 in epoch 7, gen_loss = 1.0185399427340487, disc_loss = 0.0003484553238081827
Trained batch 779 in epoch 7, gen_loss = 1.0185470976890663, disc_loss = 0.0003482974959460523
Trained batch 780 in epoch 7, gen_loss = 1.018508916627735, disc_loss = 0.00034811307263652114
Trained batch 781 in epoch 7, gen_loss = 1.0185008417919774, disc_loss = 0.0003479369955006814
Trained batch 782 in epoch 7, gen_loss = 1.0186336404366816, disc_loss = 0.00034773619473255557
Trained batch 783 in epoch 7, gen_loss = 1.0186221625427812, disc_loss = 0.00034753490346553674
Trained batch 784 in epoch 7, gen_loss = 1.0186182350110096, disc_loss = 0.00034728783495526963
Trained batch 785 in epoch 7, gen_loss = 1.0186112269797094, disc_loss = 0.00034699196715894896
Trained batch 786 in epoch 7, gen_loss = 1.0186317756185084, disc_loss = 0.00034668838897876185
Trained batch 787 in epoch 7, gen_loss = 1.0187516164053516, disc_loss = 0.00034641849343102957
Trained batch 788 in epoch 7, gen_loss = 1.018817165807475, disc_loss = 0.0003461182649077373
Trained batch 789 in epoch 7, gen_loss = 1.0189138768594477, disc_loss = 0.00034577743394544964
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 1.013240933418274, disc_loss = 5.00891255796887e-05
Trained batch 1 in epoch 8, gen_loss = 0.9855691194534302, disc_loss = 4.978373181074858e-05
Trained batch 2 in epoch 8, gen_loss = 0.99238387743632, disc_loss = 5.410784554745381e-05
Trained batch 3 in epoch 8, gen_loss = 0.9853954315185547, disc_loss = 6.685793960059527e-05
Trained batch 4 in epoch 8, gen_loss = 0.9887282133102417, disc_loss = 8.567428594687953e-05
Trained batch 5 in epoch 8, gen_loss = 0.9904310206572214, disc_loss = 0.00010919382596815315
Trained batch 6 in epoch 8, gen_loss = 0.9967242053576878, disc_loss = 0.00013208088577292592
Trained batch 7 in epoch 8, gen_loss = 0.9959980770945549, disc_loss = 0.00015009770049800863
Trained batch 8 in epoch 8, gen_loss = 0.9963330295350816, disc_loss = 0.00016500671740181537
Trained batch 9 in epoch 8, gen_loss = 0.9984607338905335, disc_loss = 0.0001768870417436119
Trained batch 10 in epoch 8, gen_loss = 1.0009770718487827, disc_loss = 0.00018683707391822034
Trained batch 11 in epoch 8, gen_loss = 1.0028821229934692, disc_loss = 0.0001936982510718129
Trained batch 12 in epoch 8, gen_loss = 1.0070470754916852, disc_loss = 0.0001987502635949148
Trained batch 13 in epoch 8, gen_loss = 1.0033552220889501, disc_loss = 0.00020327685290664834
Trained batch 14 in epoch 8, gen_loss = 1.007879360516866, disc_loss = 0.00020734842158465956
Trained batch 15 in epoch 8, gen_loss = 1.0039239898324013, disc_loss = 0.00021164645613680477
Trained batch 16 in epoch 8, gen_loss = 0.9977994876749375, disc_loss = 0.00021757051367518108
Trained batch 17 in epoch 8, gen_loss = 0.9906977812449137, disc_loss = 0.00022275518171631524
Trained batch 18 in epoch 8, gen_loss = 0.9917423725128174, disc_loss = 0.00022798332678288907
Trained batch 19 in epoch 8, gen_loss = 0.9913645923137665, disc_loss = 0.00023307105839194265
Trained batch 20 in epoch 8, gen_loss = 0.991207670597803, disc_loss = 0.0002379540871645856
Trained batch 21 in epoch 8, gen_loss = 0.9914200549775903, disc_loss = 0.00023966454814812593
Trained batch 22 in epoch 8, gen_loss = 0.9925759175549382, disc_loss = 0.00023918097323748162
Trained batch 23 in epoch 8, gen_loss = 0.9920802488923073, disc_loss = 0.00023602960118296323
Trained batch 24 in epoch 8, gen_loss = 0.9931884837150574, disc_loss = 0.0002312941473792307
Trained batch 25 in epoch 8, gen_loss = 0.9929417211275834, disc_loss = 0.00022599688264353273
Trained batch 26 in epoch 8, gen_loss = 0.9951678492404796, disc_loss = 0.00022116772689278824
Trained batch 27 in epoch 8, gen_loss = 0.9937750420400074, disc_loss = 0.0002170308871427551
Trained batch 28 in epoch 8, gen_loss = 0.9926048208927286, disc_loss = 0.00021303640798954614
Trained batch 29 in epoch 8, gen_loss = 0.9937785685062408, disc_loss = 0.00020938672581299517
Trained batch 30 in epoch 8, gen_loss = 0.9932096062167999, disc_loss = 0.00020630043863709415
Trained batch 31 in epoch 8, gen_loss = 0.9937033671885729, disc_loss = 0.0002040456693066517
Trained batch 32 in epoch 8, gen_loss = 0.994365469975905, disc_loss = 0.00020207057373640552
Trained batch 33 in epoch 8, gen_loss = 0.9957958196892458, disc_loss = 0.000199923876874998
Trained batch 34 in epoch 8, gen_loss = 0.9973931533949716, disc_loss = 0.00019704694464702958
Trained batch 35 in epoch 8, gen_loss = 0.9951089637147056, disc_loss = 0.0001940834044944495
Trained batch 36 in epoch 8, gen_loss = 0.9948142460874609, disc_loss = 0.00019412320004964903
Trained batch 37 in epoch 8, gen_loss = 0.9958143500905288, disc_loss = 0.00020045378685034322
Trained batch 38 in epoch 8, gen_loss = 0.994117021560669, disc_loss = 0.00021070153683794136
Trained batch 39 in epoch 8, gen_loss = 0.994127145409584, disc_loss = 0.00022151113334984985
Trained batch 40 in epoch 8, gen_loss = 0.9961113958823972, disc_loss = 0.00023320595351922349
Trained batch 41 in epoch 8, gen_loss = 0.9955978535470509, disc_loss = 0.00024564743667031594
Trained batch 42 in epoch 8, gen_loss = 0.9969316388285437, disc_loss = 0.00025899420989146675
Trained batch 43 in epoch 8, gen_loss = 0.9982797476378354, disc_loss = 0.0002697185498784
Trained batch 44 in epoch 8, gen_loss = 1.000320922003852, disc_loss = 0.0002762774131648863
Trained batch 45 in epoch 8, gen_loss = 1.000444163446841, disc_loss = 0.00027777963544434425
Trained batch 46 in epoch 8, gen_loss = 0.9988993076567955, disc_loss = 0.0002800401772664701
Trained batch 47 in epoch 8, gen_loss = 0.9983156162003676, disc_loss = 0.0002869307145374478
Trained batch 48 in epoch 8, gen_loss = 0.9995485167114102, disc_loss = 0.0003013953062282799
Trained batch 49 in epoch 8, gen_loss = 0.9996608912944793, disc_loss = 0.0003244962365715764
Trained batch 50 in epoch 8, gen_loss = 1.0011226090730405, disc_loss = 0.00034797520407557706
Trained batch 51 in epoch 8, gen_loss = 1.000557121175986, disc_loss = 0.00036934165305305773
Trained batch 52 in epoch 8, gen_loss = 1.0014864419991116, disc_loss = 0.00038023274430328593
Trained batch 53 in epoch 8, gen_loss = 1.0010986107367057, disc_loss = 0.00038439543520022806
Trained batch 54 in epoch 8, gen_loss = 1.0003046946092085, disc_loss = 0.00038534598716069015
Trained batch 55 in epoch 8, gen_loss = 1.0005270029817308, disc_loss = 0.0003859239147589376
Trained batch 56 in epoch 8, gen_loss = 1.0016830636743914, disc_loss = 0.0003868569137442759
Trained batch 57 in epoch 8, gen_loss = 1.0020326088214744, disc_loss = 0.0003896848253949931
Trained batch 58 in epoch 8, gen_loss = 1.0033660238072024, disc_loss = 0.0003948599695508226
Trained batch 59 in epoch 8, gen_loss = 1.005297742287318, disc_loss = 0.0003995512357505504
Trained batch 60 in epoch 8, gen_loss = 1.0039842451205019, disc_loss = 0.00040407140417688634
Trained batch 61 in epoch 8, gen_loss = 1.0042343014670956, disc_loss = 0.00041239515802214645
Trained batch 62 in epoch 8, gen_loss = 1.004470339843205, disc_loss = 0.00041930513647717556
Trained batch 63 in epoch 8, gen_loss = 1.0030271438881755, disc_loss = 0.00042516834923844726
Trained batch 64 in epoch 8, gen_loss = 1.0027254031254695, disc_loss = 0.00042905232918341287
Trained batch 65 in epoch 8, gen_loss = 1.0033986694885022, disc_loss = 0.0004310082610269698
Trained batch 66 in epoch 8, gen_loss = 1.0039802754103249, disc_loss = 0.0004311246715343571
Trained batch 67 in epoch 8, gen_loss = 1.0033843762734358, disc_loss = 0.0004306142190591131
Trained batch 68 in epoch 8, gen_loss = 1.0028624240902886, disc_loss = 0.00043063182227711695
Trained batch 69 in epoch 8, gen_loss = 1.0044390763555253, disc_loss = 0.0004286841162995968
Trained batch 70 in epoch 8, gen_loss = 1.0047001083132248, disc_loss = 0.00042527054070042524
Trained batch 71 in epoch 8, gen_loss = 1.0056655059258144, disc_loss = 0.0004228297230939562
Trained batch 72 in epoch 8, gen_loss = 1.0062433415896272, disc_loss = 0.00042299343745881205
Trained batch 73 in epoch 8, gen_loss = 1.0065708498697024, disc_loss = 0.00042680520001905844
Trained batch 74 in epoch 8, gen_loss = 1.0066294956207276, disc_loss = 0.0004313610317573572
Trained batch 75 in epoch 8, gen_loss = 1.006297247974496, disc_loss = 0.0004358606041167054
Trained batch 76 in epoch 8, gen_loss = 1.0068748446253988, disc_loss = 0.0004437067850217731
Trained batch 77 in epoch 8, gen_loss = 1.0074355159050379, disc_loss = 0.00045592147720386635
Trained batch 78 in epoch 8, gen_loss = 1.007314747647394, disc_loss = 0.0004679167960384342
Trained batch 79 in epoch 8, gen_loss = 1.0085021339356899, disc_loss = 0.00047791717242944286
Trained batch 80 in epoch 8, gen_loss = 1.0084172406314331, disc_loss = 0.0004865334020355532
Trained batch 81 in epoch 8, gen_loss = 1.007184327375598, disc_loss = 0.0004920807339481032
Trained batch 82 in epoch 8, gen_loss = 1.0064539464123279, disc_loss = 0.0004931855226196461
Trained batch 83 in epoch 8, gen_loss = 1.0068087847459883, disc_loss = 0.0004905178445499457
Trained batch 84 in epoch 8, gen_loss = 1.0063938421361587, disc_loss = 0.0004860896027393584
Trained batch 85 in epoch 8, gen_loss = 1.0078633649404658, disc_loss = 0.0004816530460185848
Trained batch 86 in epoch 8, gen_loss = 1.0091296297380294, disc_loss = 0.00047736739369789034
Trained batch 87 in epoch 8, gen_loss = 1.0097769729115746, disc_loss = 0.00047295578927084784
Trained batch 88 in epoch 8, gen_loss = 1.0096130464853865, disc_loss = 0.0004692912876594215
Trained batch 89 in epoch 8, gen_loss = 1.009711007277171, disc_loss = 0.00046655446341093115
Trained batch 90 in epoch 8, gen_loss = 1.010396434710576, disc_loss = 0.00046359120228821614
Trained batch 91 in epoch 8, gen_loss = 1.0102998692056406, disc_loss = 0.00046001688212487824
Trained batch 92 in epoch 8, gen_loss = 1.0106338659922283, disc_loss = 0.0004571152165480789
Trained batch 93 in epoch 8, gen_loss = 1.0111817831688739, disc_loss = 0.00045501729502885085
Trained batch 94 in epoch 8, gen_loss = 1.0109375094112596, disc_loss = 0.00045261633587008536
Trained batch 95 in epoch 8, gen_loss = 1.0099034861971934, disc_loss = 0.0004502774644758271
Trained batch 96 in epoch 8, gen_loss = 1.0093619018485867, disc_loss = 0.0004487750239726684
Trained batch 97 in epoch 8, gen_loss = 1.008704597852668, disc_loss = 0.0004474052485067882
Trained batch 98 in epoch 8, gen_loss = 1.0089747508366902, disc_loss = 0.00044716047550812647
Trained batch 99 in epoch 8, gen_loss = 1.0088467049598693, disc_loss = 0.00044814861139457206
Trained batch 100 in epoch 8, gen_loss = 1.00943660854113, disc_loss = 0.0004493320662047631
Trained batch 101 in epoch 8, gen_loss = 1.010100031600279, disc_loss = 0.0004503019592769252
Trained batch 102 in epoch 8, gen_loss = 1.0097685936585212, disc_loss = 0.0004508708624448401
Trained batch 103 in epoch 8, gen_loss = 1.008877161030586, disc_loss = 0.0004512624240165818
Trained batch 104 in epoch 8, gen_loss = 1.0084178896177383, disc_loss = 0.0004528650198370174
Trained batch 105 in epoch 8, gen_loss = 1.0082934138909825, disc_loss = 0.00045403532725308567
Trained batch 106 in epoch 8, gen_loss = 1.0085887140202745, disc_loss = 0.0004553228385379825
Trained batch 107 in epoch 8, gen_loss = 1.0084840280038339, disc_loss = 0.000456544144779198
Trained batch 108 in epoch 8, gen_loss = 1.0088244523477117, disc_loss = 0.00045746215932880775
Trained batch 109 in epoch 8, gen_loss = 1.0088343533602628, disc_loss = 0.00045791680134822275
Trained batch 110 in epoch 8, gen_loss = 1.0086923080521661, disc_loss = 0.0004580768452813589
Trained batch 111 in epoch 8, gen_loss = 1.009123281176601, disc_loss = 0.00045762434969479467
Trained batch 112 in epoch 8, gen_loss = 1.0101424661357845, disc_loss = 0.00045644578237274036
Trained batch 113 in epoch 8, gen_loss = 1.0105359371294056, disc_loss = 0.0004548630171037777
Trained batch 114 in epoch 8, gen_loss = 1.010299637524978, disc_loss = 0.0004525465940747855
Trained batch 115 in epoch 8, gen_loss = 1.009914862184689, disc_loss = 0.00044978763686105656
Trained batch 116 in epoch 8, gen_loss = 1.010130583221077, disc_loss = 0.000447130378404867
Trained batch 117 in epoch 8, gen_loss = 1.0110323696823444, disc_loss = 0.00044461447007853493
Trained batch 118 in epoch 8, gen_loss = 1.0109507742048311, disc_loss = 0.00044186850426427063
Trained batch 119 in epoch 8, gen_loss = 1.0110284611582756, disc_loss = 0.00043942665403543896
Trained batch 120 in epoch 8, gen_loss = 1.0102210478349165, disc_loss = 0.0004373210809296497
Trained batch 121 in epoch 8, gen_loss = 1.0108705202087027, disc_loss = 0.0004358236077618518
Trained batch 122 in epoch 8, gen_loss = 1.0120411684842614, disc_loss = 0.00043430775743521127
Trained batch 123 in epoch 8, gen_loss = 1.0120899331185125, disc_loss = 0.00043270123246803713
Trained batch 124 in epoch 8, gen_loss = 1.0119806632995605, disc_loss = 0.00043049393530236556
Trained batch 125 in epoch 8, gen_loss = 1.0119623825663613, disc_loss = 0.0004279416829203477
Trained batch 126 in epoch 8, gen_loss = 1.012842935839976, disc_loss = 0.0004257399414200336
Trained batch 127 in epoch 8, gen_loss = 1.0126345017924905, disc_loss = 0.00042419182886987983
Trained batch 128 in epoch 8, gen_loss = 1.0124165295630463, disc_loss = 0.0004230023841391671
Trained batch 129 in epoch 8, gen_loss = 1.0118823821728047, disc_loss = 0.00042156736196305314
Trained batch 130 in epoch 8, gen_loss = 1.0122550607637595, disc_loss = 0.00042012865059273244
Trained batch 131 in epoch 8, gen_loss = 1.0122060911221937, disc_loss = 0.0004190588199090791
Trained batch 132 in epoch 8, gen_loss = 1.0124811982749997, disc_loss = 0.00041820872581609407
Trained batch 133 in epoch 8, gen_loss = 1.0121467255834322, disc_loss = 0.0004173532086415842
Trained batch 134 in epoch 8, gen_loss = 1.012547328737047, disc_loss = 0.0004164383760696553
Trained batch 135 in epoch 8, gen_loss = 1.0125162022955276, disc_loss = 0.0004152047383874614
Trained batch 136 in epoch 8, gen_loss = 1.0121192823361307, disc_loss = 0.0004136390258799423
Trained batch 137 in epoch 8, gen_loss = 1.011851609185122, disc_loss = 0.00041163622127909997
Trained batch 138 in epoch 8, gen_loss = 1.0123817127385586, disc_loss = 0.0004097605472733769
Trained batch 139 in epoch 8, gen_loss = 1.0124548873731067, disc_loss = 0.0004079966748707063
Trained batch 140 in epoch 8, gen_loss = 1.012843908570337, disc_loss = 0.0004061783315301774
Trained batch 141 in epoch 8, gen_loss = 1.0126912283225797, disc_loss = 0.0004040980117717712
Trained batch 142 in epoch 8, gen_loss = 1.0129762496147956, disc_loss = 0.0004019731834512106
Trained batch 143 in epoch 8, gen_loss = 1.0127706420090463, disc_loss = 0.0003998509059278553
Trained batch 144 in epoch 8, gen_loss = 1.0127318686452405, disc_loss = 0.0003978278186846653
Trained batch 145 in epoch 8, gen_loss = 1.0126945996937686, disc_loss = 0.0003957129989081694
Trained batch 146 in epoch 8, gen_loss = 1.0124977758141602, disc_loss = 0.0003933911125170111
Trained batch 147 in epoch 8, gen_loss = 1.0128802202037863, disc_loss = 0.0003910432990508255
Trained batch 148 in epoch 8, gen_loss = 1.0126418547342289, disc_loss = 0.00038875372870004853
Trained batch 149 in epoch 8, gen_loss = 1.012329805692037, disc_loss = 0.0003866167223410836
Trained batch 150 in epoch 8, gen_loss = 1.0127802716185714, disc_loss = 0.0003845604641662929
Trained batch 151 in epoch 8, gen_loss = 1.012749847612883, disc_loss = 0.00038272908123441373
Trained batch 152 in epoch 8, gen_loss = 1.0126156382311404, disc_loss = 0.0003809241868165212
Trained batch 153 in epoch 8, gen_loss = 1.0123699485481559, disc_loss = 0.0003788691317751798
Trained batch 154 in epoch 8, gen_loss = 1.0122244227317072, disc_loss = 0.0003766370132882824
Trained batch 155 in epoch 8, gen_loss = 1.0124873824608631, disc_loss = 0.00037451843437361857
Trained batch 156 in epoch 8, gen_loss = 1.0127201216995336, disc_loss = 0.0003724871719108485
Trained batch 157 in epoch 8, gen_loss = 1.0126741332343863, disc_loss = 0.00037080951005918905
Trained batch 158 in epoch 8, gen_loss = 1.0125687583437506, disc_loss = 0.00036946765356550706
Trained batch 159 in epoch 8, gen_loss = 1.0124902289360762, disc_loss = 0.00036847392766503617
Trained batch 160 in epoch 8, gen_loss = 1.0124806872806194, disc_loss = 0.00036750147021549133
Trained batch 161 in epoch 8, gen_loss = 1.0127584761307564, disc_loss = 0.0003662520797167226
Trained batch 162 in epoch 8, gen_loss = 1.0124842071094395, disc_loss = 0.0003647435577214907
Trained batch 163 in epoch 8, gen_loss = 1.0119313877530214, disc_loss = 0.0003631107113217628
Trained batch 164 in epoch 8, gen_loss = 1.0119065216093353, disc_loss = 0.0003615364542576682
Trained batch 165 in epoch 8, gen_loss = 1.0118306361767182, disc_loss = 0.00036008046667865783
Trained batch 166 in epoch 8, gen_loss = 1.0112434743407244, disc_loss = 0.00035893876800204846
Trained batch 167 in epoch 8, gen_loss = 1.0116466656327248, disc_loss = 0.00035827787126306376
Trained batch 168 in epoch 8, gen_loss = 1.0115528110216354, disc_loss = 0.00035836726739470843
Trained batch 169 in epoch 8, gen_loss = 1.0117877073147719, disc_loss = 0.0003587164216750192
Trained batch 170 in epoch 8, gen_loss = 1.011626262413828, disc_loss = 0.0003591276112465972
Trained batch 171 in epoch 8, gen_loss = 1.0115872462128483, disc_loss = 0.000359220305633011
Trained batch 172 in epoch 8, gen_loss = 1.0117849263152636, disc_loss = 0.0003589591080547617
Trained batch 173 in epoch 8, gen_loss = 1.0111892374082543, disc_loss = 0.0003587402102782327
Trained batch 174 in epoch 8, gen_loss = 1.0110986798150199, disc_loss = 0.0003591236348230658
Trained batch 175 in epoch 8, gen_loss = 1.0112276503985578, disc_loss = 0.0003595404252998626
Trained batch 176 in epoch 8, gen_loss = 1.0110198481608246, disc_loss = 0.0003599396057191468
Trained batch 177 in epoch 8, gen_loss = 1.011369550496005, disc_loss = 0.00036034040165125924
Trained batch 178 in epoch 8, gen_loss = 1.0114245967492046, disc_loss = 0.0003602999681509334
Trained batch 179 in epoch 8, gen_loss = 1.011839606364568, disc_loss = 0.0003597681434055428
Trained batch 180 in epoch 8, gen_loss = 1.011839124379237, disc_loss = 0.00035880318962137897
Trained batch 181 in epoch 8, gen_loss = 1.0117826258743203, disc_loss = 0.0003576325809942548
Trained batch 182 in epoch 8, gen_loss = 1.0116930688665213, disc_loss = 0.00035645129660696624
Trained batch 183 in epoch 8, gen_loss = 1.0114738601057425, disc_loss = 0.00035535063002696364
Trained batch 184 in epoch 8, gen_loss = 1.0117355691420065, disc_loss = 0.0003542500510308388
Trained batch 185 in epoch 8, gen_loss = 1.011738896690389, disc_loss = 0.00035305077041704607
Trained batch 186 in epoch 8, gen_loss = 1.0117235250651517, disc_loss = 0.00035170811136784827
Trained batch 187 in epoch 8, gen_loss = 1.0118717389537932, disc_loss = 0.0003503512673481229
Trained batch 188 in epoch 8, gen_loss = 1.0110962889181874, disc_loss = 0.00034929035621369996
Trained batch 189 in epoch 8, gen_loss = 1.011047941760013, disc_loss = 0.00034843121232513925
Trained batch 190 in epoch 8, gen_loss = 1.0112637524829484, disc_loss = 0.00034770235728292056
Trained batch 191 in epoch 8, gen_loss = 1.0111417844891548, disc_loss = 0.00034702976639285527
Trained batch 192 in epoch 8, gen_loss = 1.0113520517250416, disc_loss = 0.0003465834161787839
Trained batch 193 in epoch 8, gen_loss = 1.0116530232822771, disc_loss = 0.00034597104135660703
Trained batch 194 in epoch 8, gen_loss = 1.0119969667532505, disc_loss = 0.00034516961194383793
Trained batch 195 in epoch 8, gen_loss = 1.0116309614814059, disc_loss = 0.00034442946477555576
Trained batch 196 in epoch 8, gen_loss = 1.0118121774063498, disc_loss = 0.0003438273754720174
Trained batch 197 in epoch 8, gen_loss = 1.011629995673594, disc_loss = 0.00034348886607642843
Trained batch 198 in epoch 8, gen_loss = 1.0115850403081232, disc_loss = 0.0003432614335979817
Trained batch 199 in epoch 8, gen_loss = 1.0118673318624496, disc_loss = 0.000342979302367894
Trained batch 200 in epoch 8, gen_loss = 1.0117382196644646, disc_loss = 0.0003422800092714658
Trained batch 201 in epoch 8, gen_loss = 1.0115800724171176, disc_loss = 0.0003412089534340159
Trained batch 202 in epoch 8, gen_loss = 1.011246729366885, disc_loss = 0.0003400893359768475
Trained batch 203 in epoch 8, gen_loss = 1.011204222838084, disc_loss = 0.0003390021904801959
Trained batch 204 in epoch 8, gen_loss = 1.0112017375666922, disc_loss = 0.0003379779451146222
Trained batch 205 in epoch 8, gen_loss = 1.0107641321362801, disc_loss = 0.00033706578038106175
Trained batch 206 in epoch 8, gen_loss = 1.0111342394985439, disc_loss = 0.0003365962804775406
Trained batch 207 in epoch 8, gen_loss = 1.0106966177431436, disc_loss = 0.0003364867602263425
Trained batch 208 in epoch 8, gen_loss = 1.0108757997243598, disc_loss = 0.00033646905297607307
Trained batch 209 in epoch 8, gen_loss = 1.0107407958734602, disc_loss = 0.0003362931934091085
Trained batch 210 in epoch 8, gen_loss = 1.0109068497097322, disc_loss = 0.0003356297946092562
Trained batch 211 in epoch 8, gen_loss = 1.0105692561504975, disc_loss = 0.000334727631267907
Trained batch 212 in epoch 8, gen_loss = 1.0104209165058227, disc_loss = 0.00033373009804811137
Trained batch 213 in epoch 8, gen_loss = 1.01012062274407, disc_loss = 0.0003328130685340256
Trained batch 214 in epoch 8, gen_loss = 1.010755296363387, disc_loss = 0.0003320297612781571
Trained batch 215 in epoch 8, gen_loss = 1.0111013565350462, disc_loss = 0.0003312731666179995
Trained batch 216 in epoch 8, gen_loss = 1.0110211114180252, disc_loss = 0.00033051270413779
Trained batch 217 in epoch 8, gen_loss = 1.0111705217886409, disc_loss = 0.00032980090400755164
Trained batch 218 in epoch 8, gen_loss = 1.0113841921227162, disc_loss = 0.0003290183642973749
Trained batch 219 in epoch 8, gen_loss = 1.011443444815549, disc_loss = 0.00032813674221291545
Trained batch 220 in epoch 8, gen_loss = 1.0113436393608335, disc_loss = 0.00032726296625886013
Trained batch 221 in epoch 8, gen_loss = 1.011866692487184, disc_loss = 0.00032647921539096344
Trained batch 222 in epoch 8, gen_loss = 1.0118541295218362, disc_loss = 0.00032579555278518675
Trained batch 223 in epoch 8, gen_loss = 1.0115989691444807, disc_loss = 0.0003249832964554246
Trained batch 224 in epoch 8, gen_loss = 1.0114917016029359, disc_loss = 0.0003240584609577329
Trained batch 225 in epoch 8, gen_loss = 1.011785868258603, disc_loss = 0.00032319435716500564
Trained batch 226 in epoch 8, gen_loss = 1.011460995096467, disc_loss = 0.0003224303166698439
Trained batch 227 in epoch 8, gen_loss = 1.0112670921442801, disc_loss = 0.0003217782380951368
Trained batch 228 in epoch 8, gen_loss = 1.0109596921366895, disc_loss = 0.0003211490348767892
Trained batch 229 in epoch 8, gen_loss = 1.0110159669233405, disc_loss = 0.0003205088364231177
Trained batch 230 in epoch 8, gen_loss = 1.0113503455599666, disc_loss = 0.0003196936492489155
Trained batch 231 in epoch 8, gen_loss = 1.0112974846671368, disc_loss = 0.0003188281659182896
Trained batch 232 in epoch 8, gen_loss = 1.0115965320828646, disc_loss = 0.0003179864392527419
Trained batch 233 in epoch 8, gen_loss = 1.0115467852506883, disc_loss = 0.0003173105484538843
Trained batch 234 in epoch 8, gen_loss = 1.0120649593941708, disc_loss = 0.0003168696150904462
Trained batch 235 in epoch 8, gen_loss = 1.0122089327897055, disc_loss = 0.0003165552919862251
Trained batch 236 in epoch 8, gen_loss = 1.0121107483714944, disc_loss = 0.00031618555280883926
Trained batch 237 in epoch 8, gen_loss = 1.012249555407452, disc_loss = 0.000315670338597495
Trained batch 238 in epoch 8, gen_loss = 1.012679575876212, disc_loss = 0.00031538638089628594
Trained batch 239 in epoch 8, gen_loss = 1.0129071722428005, disc_loss = 0.0003157953482210966
Trained batch 240 in epoch 8, gen_loss = 1.0131571945807747, disc_loss = 0.00031678623805924885
Trained batch 241 in epoch 8, gen_loss = 1.0131810548876927, disc_loss = 0.00031799597506077524
Trained batch 242 in epoch 8, gen_loss = 1.0136626330913339, disc_loss = 0.00031944314704047624
Trained batch 243 in epoch 8, gen_loss = 1.0130692957366099, disc_loss = 0.0003207987091195346
Trained batch 244 in epoch 8, gen_loss = 1.0129327693764045, disc_loss = 0.000322177700908636
Trained batch 245 in epoch 8, gen_loss = 1.0131860901185168, disc_loss = 0.0003234253310689767
Trained batch 246 in epoch 8, gen_loss = 1.013093495899849, disc_loss = 0.00032417112794683054
Trained batch 247 in epoch 8, gen_loss = 1.0132818368654097, disc_loss = 0.00032420293524820966
Trained batch 248 in epoch 8, gen_loss = 1.013225122867339, disc_loss = 0.0003237609371244178
Trained batch 249 in epoch 8, gen_loss = 1.0134454300403595, disc_loss = 0.0003230597248475533
Trained batch 250 in epoch 8, gen_loss = 1.0136517953587718, disc_loss = 0.00032217531363304473
Trained batch 251 in epoch 8, gen_loss = 1.013491525063439, disc_loss = 0.0003212541159305219
Trained batch 252 in epoch 8, gen_loss = 1.0133624965023147, disc_loss = 0.00032063109076419926
Trained batch 253 in epoch 8, gen_loss = 1.0133013394404584, disc_loss = 0.0003203489269060266
Trained batch 254 in epoch 8, gen_loss = 1.0132641140152425, disc_loss = 0.0003200962593979841
Trained batch 255 in epoch 8, gen_loss = 1.0138594678137451, disc_loss = 0.0003196443664137405
Trained batch 256 in epoch 8, gen_loss = 1.013339665381361, disc_loss = 0.0003188045681042031
Trained batch 257 in epoch 8, gen_loss = 1.0129736183687699, disc_loss = 0.0003180695981258353
Trained batch 258 in epoch 8, gen_loss = 1.0130864397899524, disc_loss = 0.00031735987513070805
Trained batch 259 in epoch 8, gen_loss = 1.0132646530866622, disc_loss = 0.00031651655523231827
Trained batch 260 in epoch 8, gen_loss = 1.0133796457586617, disc_loss = 0.0003157889446372102
Trained batch 261 in epoch 8, gen_loss = 1.0130170226552104, disc_loss = 0.0003151893298024354
Trained batch 262 in epoch 8, gen_loss = 1.0134839401952214, disc_loss = 0.0003144994670013497
Trained batch 263 in epoch 8, gen_loss = 1.0132411420345306, disc_loss = 0.0003140094529292335
Trained batch 264 in epoch 8, gen_loss = 1.0132262049980882, disc_loss = 0.000313926939325372
Trained batch 265 in epoch 8, gen_loss = 1.0132924896433837, disc_loss = 0.0003139901365971025
Trained batch 266 in epoch 8, gen_loss = 1.012793667753984, disc_loss = 0.000313939368949631
Trained batch 267 in epoch 8, gen_loss = 1.012902347899195, disc_loss = 0.00031338635739329993
Trained batch 268 in epoch 8, gen_loss = 1.0131706726152214, disc_loss = 0.00031260313937045826
Trained batch 269 in epoch 8, gen_loss = 1.0131633431823166, disc_loss = 0.0003117210964706761
Trained batch 270 in epoch 8, gen_loss = 1.0133018212124871, disc_loss = 0.0003107688526377663
Trained batch 271 in epoch 8, gen_loss = 1.013184480369091, disc_loss = 0.00030983921455759523
Trained batch 272 in epoch 8, gen_loss = 1.013495405951699, disc_loss = 0.0003091997940904775
Trained batch 273 in epoch 8, gen_loss = 1.0135129350815377, disc_loss = 0.0003088927026304848
Trained batch 274 in epoch 8, gen_loss = 1.0133529632741756, disc_loss = 0.0003088736438076012
Trained batch 275 in epoch 8, gen_loss = 1.0134248254091844, disc_loss = 0.0003089943277344624
Trained batch 276 in epoch 8, gen_loss = 1.0133330081774439, disc_loss = 0.000309193691677735
Trained batch 277 in epoch 8, gen_loss = 1.0133948900716767, disc_loss = 0.00030941374528430327
Trained batch 278 in epoch 8, gen_loss = 1.0133508341286772, disc_loss = 0.0003096586232097389
Trained batch 279 in epoch 8, gen_loss = 1.013299463050706, disc_loss = 0.00030989366873005305
Trained batch 280 in epoch 8, gen_loss = 1.0133218650716056, disc_loss = 0.0003099267943391454
Trained batch 281 in epoch 8, gen_loss = 1.0134224722571408, disc_loss = 0.00030988350852515634
Trained batch 282 in epoch 8, gen_loss = 1.0133918178376375, disc_loss = 0.00030965962640668824
Trained batch 283 in epoch 8, gen_loss = 1.0135802496486985, disc_loss = 0.0003091513305444608
Trained batch 284 in epoch 8, gen_loss = 1.0135343078981367, disc_loss = 0.0003084377448989503
Trained batch 285 in epoch 8, gen_loss = 1.0138419570622745, disc_loss = 0.00030776140131699443
Trained batch 286 in epoch 8, gen_loss = 1.0138726238589668, disc_loss = 0.00030721435869941716
Trained batch 287 in epoch 8, gen_loss = 1.0137370663384597, disc_loss = 0.0003066531805112997
Trained batch 288 in epoch 8, gen_loss = 1.0139007395114041, disc_loss = 0.0003061703716245219
Trained batch 289 in epoch 8, gen_loss = 1.0139668481103306, disc_loss = 0.0003057655748401383
Trained batch 290 in epoch 8, gen_loss = 1.0137409426502346, disc_loss = 0.0003055114146238801
Trained batch 291 in epoch 8, gen_loss = 1.0136951587788046, disc_loss = 0.00030569847388518335
Trained batch 292 in epoch 8, gen_loss = 1.0135845751485726, disc_loss = 0.00030663388693044055
Trained batch 293 in epoch 8, gen_loss = 1.0135236435196027, disc_loss = 0.0003084930118892443
Trained batch 294 in epoch 8, gen_loss = 1.0135111073316154, disc_loss = 0.00031135724600941196
Trained batch 295 in epoch 8, gen_loss = 1.0134607889765017, disc_loss = 0.00031503207247697974
Trained batch 296 in epoch 8, gen_loss = 1.0136265652348297, disc_loss = 0.00031790440303966505
Trained batch 297 in epoch 8, gen_loss = 1.0135953852394284, disc_loss = 0.0003188171347012531
Trained batch 298 in epoch 8, gen_loss = 1.0132972749579312, disc_loss = 0.0003188325221265626
Trained batch 299 in epoch 8, gen_loss = 1.0132508252064387, disc_loss = 0.0003186398563169253
Trained batch 300 in epoch 8, gen_loss = 1.0134335017679537, disc_loss = 0.0003184954158341407
Trained batch 301 in epoch 8, gen_loss = 1.0132008356763826, disc_loss = 0.00031849964425840495
Trained batch 302 in epoch 8, gen_loss = 1.0130847995430723, disc_loss = 0.00031874600823633616
Trained batch 303 in epoch 8, gen_loss = 1.0132296567684727, disc_loss = 0.0003191516561376997
Trained batch 304 in epoch 8, gen_loss = 1.013253827564052, disc_loss = 0.0003195225286915837
Trained batch 305 in epoch 8, gen_loss = 1.013357270387263, disc_loss = 0.00031992487797324903
Trained batch 306 in epoch 8, gen_loss = 1.0135105269739604, disc_loss = 0.0003202299224152093
Trained batch 307 in epoch 8, gen_loss = 1.013388743841803, disc_loss = 0.00032032245423118646
Trained batch 308 in epoch 8, gen_loss = 1.0132318764056973, disc_loss = 0.0003202972903698502
Trained batch 309 in epoch 8, gen_loss = 1.0133822043095866, disc_loss = 0.00032034989544040254
Trained batch 310 in epoch 8, gen_loss = 1.0135279995452169, disc_loss = 0.0003204892347926136
Trained batch 311 in epoch 8, gen_loss = 1.013713542658549, disc_loss = 0.0003206895756496427
Trained batch 312 in epoch 8, gen_loss = 1.0138136893034744, disc_loss = 0.00032089266664952565
Trained batch 313 in epoch 8, gen_loss = 1.0139719735664927, disc_loss = 0.00032104646388862496
Trained batch 314 in epoch 8, gen_loss = 1.013840253012521, disc_loss = 0.00032094236101127334
Trained batch 315 in epoch 8, gen_loss = 1.0139733356765555, disc_loss = 0.00032052829136992395
Trained batch 316 in epoch 8, gen_loss = 1.0140617781257029, disc_loss = 0.00031999006691316807
Trained batch 317 in epoch 8, gen_loss = 1.014139990761595, disc_loss = 0.00031938683905136485
Trained batch 318 in epoch 8, gen_loss = 1.0144247272545268, disc_loss = 0.00031875466861649705
Trained batch 319 in epoch 8, gen_loss = 1.0144995022565126, disc_loss = 0.00031808502553758443
Trained batch 320 in epoch 8, gen_loss = 1.0144546410747777, disc_loss = 0.00031747471256837295
Trained batch 321 in epoch 8, gen_loss = 1.014381274303294, disc_loss = 0.00031682684281313073
Trained batch 322 in epoch 8, gen_loss = 1.0143641211300074, disc_loss = 0.0003161583878663974
Trained batch 323 in epoch 8, gen_loss = 1.0144095453951094, disc_loss = 0.00031560835560850574
Trained batch 324 in epoch 8, gen_loss = 1.0145732655892006, disc_loss = 0.0003152542377490765
Trained batch 325 in epoch 8, gen_loss = 1.0149164737367922, disc_loss = 0.00031511376033293545
Trained batch 326 in epoch 8, gen_loss = 1.0148046470563346, disc_loss = 0.0003152431624281841
Trained batch 327 in epoch 8, gen_loss = 1.0147050911696947, disc_loss = 0.0003156848453904897
Trained batch 328 in epoch 8, gen_loss = 1.0146847030312094, disc_loss = 0.00031622153836267784
Trained batch 329 in epoch 8, gen_loss = 1.0145139999461896, disc_loss = 0.00031663015902405747
Trained batch 330 in epoch 8, gen_loss = 1.0145006981140898, disc_loss = 0.00031686868932111515
Trained batch 331 in epoch 8, gen_loss = 1.0147456413651088, disc_loss = 0.0003170233111993721
Trained batch 332 in epoch 8, gen_loss = 1.01474859209748, disc_loss = 0.00031710789007447274
Trained batch 333 in epoch 8, gen_loss = 1.014625986357649, disc_loss = 0.0003172233426923554
Trained batch 334 in epoch 8, gen_loss = 1.0145390062189814, disc_loss = 0.0003174377906565388
Trained batch 335 in epoch 8, gen_loss = 1.0144956883575236, disc_loss = 0.0003175689601102065
Trained batch 336 in epoch 8, gen_loss = 1.0144068945409281, disc_loss = 0.00031776954574929826
Trained batch 337 in epoch 8, gen_loss = 1.0143795173901777, disc_loss = 0.00031803668115943116
Trained batch 338 in epoch 8, gen_loss = 1.0145876462129013, disc_loss = 0.0003183458697668601
Trained batch 339 in epoch 8, gen_loss = 1.014240318010835, disc_loss = 0.00031874840195301015
Trained batch 340 in epoch 8, gen_loss = 1.0142324510907148, disc_loss = 0.00031918862984700765
Trained batch 341 in epoch 8, gen_loss = 1.0144351206676305, disc_loss = 0.0003195065621493251
Trained batch 342 in epoch 8, gen_loss = 1.0143130039334645, disc_loss = 0.00031948482897998116
Trained batch 343 in epoch 8, gen_loss = 1.014459501692029, disc_loss = 0.0003192513322785597
Trained batch 344 in epoch 8, gen_loss = 1.0141079486280247, disc_loss = 0.00031888553962546766
Trained batch 345 in epoch 8, gen_loss = 1.013846308854274, disc_loss = 0.0003185626707550184
Trained batch 346 in epoch 8, gen_loss = 1.014020197673215, disc_loss = 0.0003182233860140857
Trained batch 347 in epoch 8, gen_loss = 1.014189449535019, disc_loss = 0.00031767738575330564
Trained batch 348 in epoch 8, gen_loss = 1.014249452547221, disc_loss = 0.0003171300509569961
Trained batch 349 in epoch 8, gen_loss = 1.014265720163073, disc_loss = 0.00031665784013707056
Trained batch 350 in epoch 8, gen_loss = 1.0143966977073255, disc_loss = 0.00031608882287359317
Trained batch 351 in epoch 8, gen_loss = 1.0144944309510968, disc_loss = 0.0003154293585587518
Trained batch 352 in epoch 8, gen_loss = 1.0145429116132914, disc_loss = 0.0003148073395201343
Trained batch 353 in epoch 8, gen_loss = 1.014333681871662, disc_loss = 0.0003144220179737753
Trained batch 354 in epoch 8, gen_loss = 1.0143212419160654, disc_loss = 0.00031446274822909045
Trained batch 355 in epoch 8, gen_loss = 1.0143473057934407, disc_loss = 0.0003146342772330233
Trained batch 356 in epoch 8, gen_loss = 1.0145631147032024, disc_loss = 0.0003147113217206878
Trained batch 357 in epoch 8, gen_loss = 1.0146990458392564, disc_loss = 0.00031476357775592694
Trained batch 358 in epoch 8, gen_loss = 1.0149055447086983, disc_loss = 0.00031440191660066653
Trained batch 359 in epoch 8, gen_loss = 1.0150006771087647, disc_loss = 0.00031398356200548327
Trained batch 360 in epoch 8, gen_loss = 1.0151975379426064, disc_loss = 0.00031367747629157443
Trained batch 361 in epoch 8, gen_loss = 1.0148314853399498, disc_loss = 0.00031360005672448007
Trained batch 362 in epoch 8, gen_loss = 1.014841480360215, disc_loss = 0.0003135539488887771
Trained batch 363 in epoch 8, gen_loss = 1.0148264464441237, disc_loss = 0.0003135715530563855
Trained batch 364 in epoch 8, gen_loss = 1.014784334457084, disc_loss = 0.00031362717681363456
Trained batch 365 in epoch 8, gen_loss = 1.0147605248487712, disc_loss = 0.00031375181104601716
Trained batch 366 in epoch 8, gen_loss = 1.0150326656060908, disc_loss = 0.0003139636477454545
Trained batch 367 in epoch 8, gen_loss = 1.0148740093345228, disc_loss = 0.00031422533872856826
Trained batch 368 in epoch 8, gen_loss = 1.0145641392485558, disc_loss = 0.0003147887905876955
Trained batch 369 in epoch 8, gen_loss = 1.0145510833005646, disc_loss = 0.00031564685563648093
Trained batch 370 in epoch 8, gen_loss = 1.0145358896319756, disc_loss = 0.0003167774586982566
Trained batch 371 in epoch 8, gen_loss = 1.0146666276519016, disc_loss = 0.0003179583988336769
Trained batch 372 in epoch 8, gen_loss = 1.0148977960082866, disc_loss = 0.00031909842198061064
Trained batch 373 in epoch 8, gen_loss = 1.0148803376577755, disc_loss = 0.00032026615837121375
Trained batch 374 in epoch 8, gen_loss = 1.0149705227216084, disc_loss = 0.00032095096564929313
Trained batch 375 in epoch 8, gen_loss = 1.0149454041681392, disc_loss = 0.00032113800023851467
Trained batch 376 in epoch 8, gen_loss = 1.0151957901150226, disc_loss = 0.00032108280913418266
Trained batch 377 in epoch 8, gen_loss = 1.014851978373906, disc_loss = 0.000320985763157113
Trained batch 378 in epoch 8, gen_loss = 1.0150355526828514, disc_loss = 0.0003209382384571021
Trained batch 379 in epoch 8, gen_loss = 1.0148490871253766, disc_loss = 0.0003211707992082474
Trained batch 380 in epoch 8, gen_loss = 1.014773238675175, disc_loss = 0.0003215393266804685
Trained batch 381 in epoch 8, gen_loss = 1.0147994900249062, disc_loss = 0.000321571104090901
Trained batch 382 in epoch 8, gen_loss = 1.0150950235112841, disc_loss = 0.00032154989089374855
Trained batch 383 in epoch 8, gen_loss = 1.0150246378034353, disc_loss = 0.000321469377562759
Trained batch 384 in epoch 8, gen_loss = 1.014989490013618, disc_loss = 0.0003211978414925964
Trained batch 385 in epoch 8, gen_loss = 1.015187454655998, disc_loss = 0.00032090883131046693
Trained batch 386 in epoch 8, gen_loss = 1.0152045386706212, disc_loss = 0.00032078194180705033
Trained batch 387 in epoch 8, gen_loss = 1.0154448799865763, disc_loss = 0.0003207878917706206
Trained batch 388 in epoch 8, gen_loss = 1.0155649016632826, disc_loss = 0.00032094096205515096
Trained batch 389 in epoch 8, gen_loss = 1.015624558008634, disc_loss = 0.00032101868678299257
Trained batch 390 in epoch 8, gen_loss = 1.0158066761768079, disc_loss = 0.00032112287149256655
Trained batch 391 in epoch 8, gen_loss = 1.015825509720919, disc_loss = 0.00032128493254573667
Trained batch 392 in epoch 8, gen_loss = 1.0157710331996888, disc_loss = 0.0003215337127384033
Trained batch 393 in epoch 8, gen_loss = 1.0158662508586942, disc_loss = 0.00032182596444768646
Trained batch 394 in epoch 8, gen_loss = 1.0156725714478312, disc_loss = 0.00032205623837963004
Trained batch 395 in epoch 8, gen_loss = 1.015688290198644, disc_loss = 0.00032224492688420476
Trained batch 396 in epoch 8, gen_loss = 1.0155894068686728, disc_loss = 0.0003225734719344748
Trained batch 397 in epoch 8, gen_loss = 1.01559715744239, disc_loss = 0.0003230780399170173
Trained batch 398 in epoch 8, gen_loss = 1.0155917585344243, disc_loss = 0.0003234182600535039
Trained batch 399 in epoch 8, gen_loss = 1.0153862756490708, disc_loss = 0.00032357093505197554
Trained batch 400 in epoch 8, gen_loss = 1.0153066104189714, disc_loss = 0.0003236279613098903
Trained batch 401 in epoch 8, gen_loss = 1.0153061634865566, disc_loss = 0.0003236023453723081
Trained batch 402 in epoch 8, gen_loss = 1.0152555233787366, disc_loss = 0.0003234651593094814
Trained batch 403 in epoch 8, gen_loss = 1.0153355279771408, disc_loss = 0.00032323070902721425
Trained batch 404 in epoch 8, gen_loss = 1.015289627475503, disc_loss = 0.00032289869816367294
Trained batch 405 in epoch 8, gen_loss = 1.0152463626685402, disc_loss = 0.00032246517691101185
Trained batch 406 in epoch 8, gen_loss = 1.0151939481423586, disc_loss = 0.00032193831097536565
Trained batch 407 in epoch 8, gen_loss = 1.0151852277271889, disc_loss = 0.00032131748160763355
Trained batch 408 in epoch 8, gen_loss = 1.0149606566848848, disc_loss = 0.0003207044058895219
Trained batch 409 in epoch 8, gen_loss = 1.0149496347438998, disc_loss = 0.00032013618976811924
Trained batch 410 in epoch 8, gen_loss = 1.0148361589206687, disc_loss = 0.0003196141216302021
Trained batch 411 in epoch 8, gen_loss = 1.015015403188548, disc_loss = 0.00031908549462262545
Trained batch 412 in epoch 8, gen_loss = 1.0150078764550623, disc_loss = 0.0003185057984945504
Trained batch 413 in epoch 8, gen_loss = 1.0151403729178479, disc_loss = 0.0003180147943154128
Trained batch 414 in epoch 8, gen_loss = 1.0150831120559969, disc_loss = 0.0003176515417542387
Trained batch 415 in epoch 8, gen_loss = 1.0151412345182438, disc_loss = 0.0003173290622971063
Trained batch 416 in epoch 8, gen_loss = 1.0150574371397352, disc_loss = 0.00031694318336416237
Trained batch 417 in epoch 8, gen_loss = 1.0151144117829902, disc_loss = 0.0003164537305060527
Trained batch 418 in epoch 8, gen_loss = 1.015139250880494, disc_loss = 0.0003158588679461531
Trained batch 419 in epoch 8, gen_loss = 1.0151196088109697, disc_loss = 0.00031526381739933553
Trained batch 420 in epoch 8, gen_loss = 1.0151465126001353, disc_loss = 0.00031469032887204587
Trained batch 421 in epoch 8, gen_loss = 1.015041072221729, disc_loss = 0.00031408078091996184
Trained batch 422 in epoch 8, gen_loss = 1.0147612234379382, disc_loss = 0.0003134634021585549
Trained batch 423 in epoch 8, gen_loss = 1.0146630066183377, disc_loss = 0.0003128825727421741
Trained batch 424 in epoch 8, gen_loss = 1.0147315140331492, disc_loss = 0.00031246024388511775
Trained batch 425 in epoch 8, gen_loss = 1.0147452474759777, disc_loss = 0.00031221487398384775
Trained batch 426 in epoch 8, gen_loss = 1.0146603330236967, disc_loss = 0.00031213249246429256
Trained batch 427 in epoch 8, gen_loss = 1.0148044983360256, disc_loss = 0.0003121380061593215
Trained batch 428 in epoch 8, gen_loss = 1.0149965967053856, disc_loss = 0.0003121602673857339
Trained batch 429 in epoch 8, gen_loss = 1.014793223142624, disc_loss = 0.00031215822571031696
Trained batch 430 in epoch 8, gen_loss = 1.0147737163678676, disc_loss = 0.0003122645425455609
Trained batch 431 in epoch 8, gen_loss = 1.0147813107404444, disc_loss = 0.00031254956572276433
Trained batch 432 in epoch 8, gen_loss = 1.0146177802019802, disc_loss = 0.0003130186465215965
Trained batch 433 in epoch 8, gen_loss = 1.0145201494891523, disc_loss = 0.0003136461053371793
Trained batch 434 in epoch 8, gen_loss = 1.0144831532719492, disc_loss = 0.00031444895503227597
Trained batch 435 in epoch 8, gen_loss = 1.014367815141284, disc_loss = 0.00031518961682320526
Trained batch 436 in epoch 8, gen_loss = 1.01442974996785, disc_loss = 0.00031577038164409056
Trained batch 437 in epoch 8, gen_loss = 1.014240137382185, disc_loss = 0.00031607713258194526
Trained batch 438 in epoch 8, gen_loss = 1.0141123047179132, disc_loss = 0.00031614828756383243
Trained batch 439 in epoch 8, gen_loss = 1.0143547440117056, disc_loss = 0.00031602009521520814
Trained batch 440 in epoch 8, gen_loss = 1.014318470511577, disc_loss = 0.00031572822495747743
Trained batch 441 in epoch 8, gen_loss = 1.014331517446095, disc_loss = 0.0003153428629685875
Trained batch 442 in epoch 8, gen_loss = 1.014226462179059, disc_loss = 0.00031482540867095615
Trained batch 443 in epoch 8, gen_loss = 1.0141490354194298, disc_loss = 0.00031425265944300655
Trained batch 444 in epoch 8, gen_loss = 1.0141425304198532, disc_loss = 0.0003136913866011342
Trained batch 445 in epoch 8, gen_loss = 1.0141334255714587, disc_loss = 0.00031318179742305754
Trained batch 446 in epoch 8, gen_loss = 1.014156896529315, disc_loss = 0.0003127175354882158
Trained batch 447 in epoch 8, gen_loss = 1.0141478199511766, disc_loss = 0.0003122490230842751
Trained batch 448 in epoch 8, gen_loss = 1.013997923425152, disc_loss = 0.00031179413836597694
Trained batch 449 in epoch 8, gen_loss = 1.0140376439359453, disc_loss = 0.0003114674232589702
Trained batch 450 in epoch 8, gen_loss = 1.014076461680977, disc_loss = 0.00031133023495403866
Trained batch 451 in epoch 8, gen_loss = 1.014165022072539, disc_loss = 0.0003115681599644301
Trained batch 452 in epoch 8, gen_loss = 1.01403330875022, disc_loss = 0.00031207516562259424
Trained batch 453 in epoch 8, gen_loss = 1.0140741303366185, disc_loss = 0.00031265981740519276
Trained batch 454 in epoch 8, gen_loss = 1.0139116124792413, disc_loss = 0.0003128583289703334
Trained batch 455 in epoch 8, gen_loss = 1.0138830819673705, disc_loss = 0.0003126249359187919
Trained batch 456 in epoch 8, gen_loss = 1.0139365410126533, disc_loss = 0.00031221803106164817
Trained batch 457 in epoch 8, gen_loss = 1.0141725477693382, disc_loss = 0.00031177794672820745
Trained batch 458 in epoch 8, gen_loss = 1.0142426527143824, disc_loss = 0.00031141530325641846
Trained batch 459 in epoch 8, gen_loss = 1.0143142153387483, disc_loss = 0.00031122746277896626
Trained batch 460 in epoch 8, gen_loss = 1.014260570940899, disc_loss = 0.0003113530656817034
Trained batch 461 in epoch 8, gen_loss = 1.0142411178066617, disc_loss = 0.0003115486814162958
Trained batch 462 in epoch 8, gen_loss = 1.0143092094435806, disc_loss = 0.00031149981280481523
Trained batch 463 in epoch 8, gen_loss = 1.0142240077257156, disc_loss = 0.00031121815700003183
Trained batch 464 in epoch 8, gen_loss = 1.014020614470205, disc_loss = 0.0003107923128227803
Trained batch 465 in epoch 8, gen_loss = 1.0138549866082842, disc_loss = 0.0003103875528273818
Trained batch 466 in epoch 8, gen_loss = 1.0138703643382234, disc_loss = 0.0003099492488067988
Trained batch 467 in epoch 8, gen_loss = 1.0139848666313367, disc_loss = 0.00030946290352069336
Trained batch 468 in epoch 8, gen_loss = 1.0139274574291985, disc_loss = 0.0003089406728947551
Trained batch 469 in epoch 8, gen_loss = 1.0138654670816787, disc_loss = 0.00030847407208366736
Trained batch 470 in epoch 8, gen_loss = 1.0139649002921556, disc_loss = 0.0003079779116096244
Trained batch 471 in epoch 8, gen_loss = 1.0141514607910382, disc_loss = 0.0003074825888041356
Trained batch 472 in epoch 8, gen_loss = 1.0141480465520007, disc_loss = 0.000307019916886068
Trained batch 473 in epoch 8, gen_loss = 1.014274948759924, disc_loss = 0.000306664075954662
Trained batch 474 in epoch 8, gen_loss = 1.0143204867212396, disc_loss = 0.00030636433557925844
Trained batch 475 in epoch 8, gen_loss = 1.0144885420298375, disc_loss = 0.0003061273340133367
Trained batch 476 in epoch 8, gen_loss = 1.0145383478460572, disc_loss = 0.00030596085198187473
Trained batch 477 in epoch 8, gen_loss = 1.0146267346757227, disc_loss = 0.00030597615183967214
Trained batch 478 in epoch 8, gen_loss = 1.014478784513374, disc_loss = 0.0003063018756200674
Trained batch 479 in epoch 8, gen_loss = 1.0145627041657765, disc_loss = 0.0003068537360074212
Trained batch 480 in epoch 8, gen_loss = 1.0147176398556843, disc_loss = 0.00030732183632360514
Trained batch 481 in epoch 8, gen_loss = 1.014778669197035, disc_loss = 0.0003076203805850954
Trained batch 482 in epoch 8, gen_loss = 1.0148955336762264, disc_loss = 0.0003079626085026976
Trained batch 483 in epoch 8, gen_loss = 1.014920438863029, disc_loss = 0.00030828433801984793
Trained batch 484 in epoch 8, gen_loss = 1.0148998088443402, disc_loss = 0.00030865481512779464
Trained batch 485 in epoch 8, gen_loss = 1.014918648166421, disc_loss = 0.00030900159081920345
Trained batch 486 in epoch 8, gen_loss = 1.0148812388002995, disc_loss = 0.00030918106979004907
Trained batch 487 in epoch 8, gen_loss = 1.0148339164061624, disc_loss = 0.00030920457073557
Trained batch 488 in epoch 8, gen_loss = 1.0152834254052254, disc_loss = 0.00030933279071668836
Trained batch 489 in epoch 8, gen_loss = 1.0153540735342064, disc_loss = 0.0003096094225207819
Trained batch 490 in epoch 8, gen_loss = 1.015358288516338, disc_loss = 0.00030987296643351106
Trained batch 491 in epoch 8, gen_loss = 1.0152479728789834, disc_loss = 0.00031002278100037605
Trained batch 492 in epoch 8, gen_loss = 1.0151653113278123, disc_loss = 0.0003100070099331699
Trained batch 493 in epoch 8, gen_loss = 1.0152195052579347, disc_loss = 0.00030989199714770026
Trained batch 494 in epoch 8, gen_loss = 1.0153856482168642, disc_loss = 0.00030971354081159026
Trained batch 495 in epoch 8, gen_loss = 1.0152948499927599, disc_loss = 0.0003095630574182818
Trained batch 496 in epoch 8, gen_loss = 1.0152747569909277, disc_loss = 0.00030952846088917025
Trained batch 497 in epoch 8, gen_loss = 1.0154019949665989, disc_loss = 0.00030962883240691043
Trained batch 498 in epoch 8, gen_loss = 1.0152753592731958, disc_loss = 0.0003097207906151112
Trained batch 499 in epoch 8, gen_loss = 1.0154899734258651, disc_loss = 0.0003098401830648072
Trained batch 500 in epoch 8, gen_loss = 1.0154297570744437, disc_loss = 0.0003096084221974461
Trained batch 501 in epoch 8, gen_loss = 1.015295351169024, disc_loss = 0.00030937561530163476
Trained batch 502 in epoch 8, gen_loss = 1.0151246783747587, disc_loss = 0.0003091405505658392
Trained batch 503 in epoch 8, gen_loss = 1.0149204593802255, disc_loss = 0.00030897245703691
Trained batch 504 in epoch 8, gen_loss = 1.0147367057233754, disc_loss = 0.0003087993529406238
Trained batch 505 in epoch 8, gen_loss = 1.0146589997728823, disc_loss = 0.00030859588875353387
Trained batch 506 in epoch 8, gen_loss = 1.0146903744816074, disc_loss = 0.000308353394404039
Trained batch 507 in epoch 8, gen_loss = 1.0147388363917043, disc_loss = 0.00030804912918444365
Trained batch 508 in epoch 8, gen_loss = 1.0147000050029493, disc_loss = 0.00030767902730923413
Trained batch 509 in epoch 8, gen_loss = 1.0148492399383993, disc_loss = 0.0003073079220627608
Trained batch 510 in epoch 8, gen_loss = 1.0149298633381345, disc_loss = 0.00030692124493757753
Trained batch 511 in epoch 8, gen_loss = 1.0149752565193921, disc_loss = 0.00030657927429444953
Trained batch 512 in epoch 8, gen_loss = 1.0148970398754171, disc_loss = 0.00030625741925128223
Trained batch 513 in epoch 8, gen_loss = 1.0149643181131043, disc_loss = 0.0003058706316066424
Trained batch 514 in epoch 8, gen_loss = 1.0148690852146705, disc_loss = 0.00030546368244420554
Trained batch 515 in epoch 8, gen_loss = 1.0149719961160837, disc_loss = 0.0003050637287390057
Trained batch 516 in epoch 8, gen_loss = 1.0150408079591895, disc_loss = 0.00030475431156787856
Trained batch 517 in epoch 8, gen_loss = 1.0149326854921217, disc_loss = 0.0003046066132010029
Trained batch 518 in epoch 8, gen_loss = 1.0148522966399587, disc_loss = 0.000304690333900198
Trained batch 519 in epoch 8, gen_loss = 1.0147572563244747, disc_loss = 0.000304972701717186
Trained batch 520 in epoch 8, gen_loss = 1.014685403591383, disc_loss = 0.00030531836611052504
Trained batch 521 in epoch 8, gen_loss = 1.0146418081389532, disc_loss = 0.00030568125200550644
Trained batch 522 in epoch 8, gen_loss = 1.0146329731148014, disc_loss = 0.00030600905724904404
Trained batch 523 in epoch 8, gen_loss = 1.0146469660387694, disc_loss = 0.00030628351985880365
Trained batch 524 in epoch 8, gen_loss = 1.0146276655651274, disc_loss = 0.0003065094195439347
Trained batch 525 in epoch 8, gen_loss = 1.014630421486191, disc_loss = 0.00030668225604598147
Trained batch 526 in epoch 8, gen_loss = 1.014587958352163, disc_loss = 0.0003067879757333186
Trained batch 527 in epoch 8, gen_loss = 1.0146591462420695, disc_loss = 0.0003068503712270423
Trained batch 528 in epoch 8, gen_loss = 1.0145661646116433, disc_loss = 0.0003068431780985178
Trained batch 529 in epoch 8, gen_loss = 1.0145347210596192, disc_loss = 0.00030681293222719345
Trained batch 530 in epoch 8, gen_loss = 1.0145278809883276, disc_loss = 0.0003067616393251201
Trained batch 532 in epoch 8, gen_loss = 1.0145895431905034, disc_loss = 0.00030661531616793855
Trained batch 533 in epoch 8, gen_loss = 1.0145960215772136, disc_loss = 0.0003065481131319968
Trained batch 534 in epoch 8, gen_loss = 1.0145555206548387, disc_loss = 0.0003065261644393937
Trained batch 535 in epoch 8, gen_loss = 1.014502161251965, disc_loss = 0.00030656462271807285
Trained batch 536 in epoch 8, gen_loss = 1.0144978468644552, disc_loss = 0.0003066228199065134
Trained batch 537 in epoch 8, gen_loss = 1.0146911177493383, disc_loss = 0.000306655944887199
Trained batch 538 in epoch 8, gen_loss = 1.0147480732434755, disc_loss = 0.00030663913475040256
Trained batch 539 in epoch 8, gen_loss = 1.0148046204337366, disc_loss = 0.00030664196103181757
Trained batch 540 in epoch 8, gen_loss = 1.0147837614175792, disc_loss = 0.00030671959006323954
Trained batch 541 in epoch 8, gen_loss = 1.014650024831075, disc_loss = 0.0003067674208196169
Trained batch 542 in epoch 8, gen_loss = 1.01453029406883, disc_loss = 0.00030677847270073425
Trained batch 543 in epoch 8, gen_loss = 1.0145193401943235, disc_loss = 0.000306636355296231
Trained batch 544 in epoch 8, gen_loss = 1.0147800898333208, disc_loss = 0.0003063756811545752
Trained batch 545 in epoch 8, gen_loss = 1.0149097927324064, disc_loss = 0.0003061067457835364
Trained batch 546 in epoch 8, gen_loss = 1.014838512353531, disc_loss = 0.00030576688289311177
Trained batch 547 in epoch 8, gen_loss = 1.0147352846216982, disc_loss = 0.00030544496645486447
Trained batch 548 in epoch 8, gen_loss = 1.0148260190621534, disc_loss = 0.0003051418564681011
Trained batch 549 in epoch 8, gen_loss = 1.0147997480089015, disc_loss = 0.00030476279510449703
Trained batch 550 in epoch 8, gen_loss = 1.0149435201920096, disc_loss = 0.00030439062262804984
Trained batch 551 in epoch 8, gen_loss = 1.0150336175077204, disc_loss = 0.0003040124327763687
Trained batch 552 in epoch 8, gen_loss = 1.014967643977505, disc_loss = 0.0003036357832572147
Trained batch 553 in epoch 8, gen_loss = 1.0150163612641152, disc_loss = 0.00030328108194830076
Trained batch 554 in epoch 8, gen_loss = 1.0149047355394105, disc_loss = 0.000302887069132716
Trained batch 555 in epoch 8, gen_loss = 1.0148321379431717, disc_loss = 0.00030260368702257314
Trained batch 556 in epoch 8, gen_loss = 1.0147322675270067, disc_loss = 0.0003025225157854925
Trained batch 557 in epoch 8, gen_loss = 1.014741580546116, disc_loss = 0.0003025641350197025
Trained batch 558 in epoch 8, gen_loss = 1.0148430115848193, disc_loss = 0.0003025583368224177
Trained batch 559 in epoch 8, gen_loss = 1.0151087477803231, disc_loss = 0.0003024088490877018
Trained batch 560 in epoch 8, gen_loss = 1.015192556508722, disc_loss = 0.00030218132203689704
Trained batch 561 in epoch 8, gen_loss = 1.0150719367736598, disc_loss = 0.0003019104593587141
Trained batch 562 in epoch 8, gen_loss = 1.015042719049098, disc_loss = 0.000301671940007257
Trained batch 563 in epoch 8, gen_loss = 1.0150487829818793, disc_loss = 0.00030146299267219917
Trained batch 564 in epoch 8, gen_loss = 1.0152339754906377, disc_loss = 0.00030134168826455695
Trained batch 565 in epoch 8, gen_loss = 1.0151679286265962, disc_loss = 0.0003012063750919438
Trained batch 566 in epoch 8, gen_loss = 1.0151301616083377, disc_loss = 0.0003010363518108484
Trained batch 567 in epoch 8, gen_loss = 1.0151935156802057, disc_loss = 0.0003009068730560256
Trained batch 568 in epoch 8, gen_loss = 1.0152537881385253, disc_loss = 0.0003008311226172618
Trained batch 569 in epoch 8, gen_loss = 1.0152768170624449, disc_loss = 0.00030084299898845257
Trained batch 570 in epoch 8, gen_loss = 1.015211932191498, disc_loss = 0.0003008898636615703
Trained batch 571 in epoch 8, gen_loss = 1.015091420157806, disc_loss = 0.000300975637738365
Trained batch 572 in epoch 8, gen_loss = 1.015069988281523, disc_loss = 0.0003009396363931495
Trained batch 573 in epoch 8, gen_loss = 1.015331243492585, disc_loss = 0.00030082374827803245
Trained batch 574 in epoch 8, gen_loss = 1.0154837478762087, disc_loss = 0.0003006921151055671
Trained batch 575 in epoch 8, gen_loss = 1.0156812710273597, disc_loss = 0.000300433016213396
Trained batch 576 in epoch 8, gen_loss = 1.015814159627184, disc_loss = 0.0003000944461919645
Trained batch 577 in epoch 8, gen_loss = 1.015846271312773, disc_loss = 0.00029982232687987586
Trained batch 578 in epoch 8, gen_loss = 1.0158822792799362, disc_loss = 0.000299599856284603
Trained batch 579 in epoch 8, gen_loss = 1.0160838165159882, disc_loss = 0.00029932109941126266
Trained batch 580 in epoch 8, gen_loss = 1.0162408318043576, disc_loss = 0.0002990306633624381
Trained batch 581 in epoch 8, gen_loss = 1.0161450805328147, disc_loss = 0.00029876874977321913
Trained batch 582 in epoch 8, gen_loss = 1.0162859280972292, disc_loss = 0.0002985101909403438
Trained batch 583 in epoch 8, gen_loss = 1.0161192393670344, disc_loss = 0.0002982301583907516
Trained batch 584 in epoch 8, gen_loss = 1.0160583443111844, disc_loss = 0.00029790071912585465
Trained batch 585 in epoch 8, gen_loss = 1.0161279976978237, disc_loss = 0.00029765278132107514
Trained batch 586 in epoch 8, gen_loss = 1.016036914195072, disc_loss = 0.00029757739740788377
Trained batch 587 in epoch 8, gen_loss = 1.0161643401295148, disc_loss = 0.0002977692610187239
Trained batch 588 in epoch 8, gen_loss = 1.0162111988294307, disc_loss = 0.000298126812006686
Trained batch 589 in epoch 8, gen_loss = 1.0161148673397, disc_loss = 0.0002984930108418743
Trained batch 590 in epoch 8, gen_loss = 1.0158826151071667, disc_loss = 0.00029908984138143
Trained batch 591 in epoch 8, gen_loss = 1.016003779664233, disc_loss = 0.0003002106358557334
Trained batch 592 in epoch 8, gen_loss = 1.0160240308832358, disc_loss = 0.00030138959213107757
Trained batch 593 in epoch 8, gen_loss = 1.0159120607857752, disc_loss = 0.0003022874690378077
Trained batch 594 in epoch 8, gen_loss = 1.0159755927174032, disc_loss = 0.00030280415993721906
Trained batch 595 in epoch 8, gen_loss = 1.0160251717839466, disc_loss = 0.0003030380714408727
Trained batch 596 in epoch 8, gen_loss = 1.0160500867482605, disc_loss = 0.0003030536013398549
Trained batch 597 in epoch 8, gen_loss = 1.0159181824894654, disc_loss = 0.00030293512512354667
Trained batch 598 in epoch 8, gen_loss = 1.0159916623008869, disc_loss = 0.0003028770487630959
Trained batch 599 in epoch 8, gen_loss = 1.0157935168345769, disc_loss = 0.00030300511492290145
Trained batch 600 in epoch 8, gen_loss = 1.015771796223328, disc_loss = 0.00030348017057448473
Trained batch 601 in epoch 8, gen_loss = 1.0156977051912353, disc_loss = 0.00030402791784932
Trained batch 602 in epoch 8, gen_loss = 1.0157418116605894, disc_loss = 0.0003043786264529527
Trained batch 603 in epoch 8, gen_loss = 1.015749102396681, disc_loss = 0.0003044385579872425
Trained batch 604 in epoch 8, gen_loss = 1.0156852578328661, disc_loss = 0.00030427919319505643
Trained batch 605 in epoch 8, gen_loss = 1.0157059958272248, disc_loss = 0.00030404076263492564
Trained batch 606 in epoch 8, gen_loss = 1.0156556597651525, disc_loss = 0.00030379620117902114
Trained batch 607 in epoch 8, gen_loss = 1.015648231302437, disc_loss = 0.0003036219944581382
Trained batch 608 in epoch 8, gen_loss = 1.015581239424707, disc_loss = 0.0003035317914466196
Trained batch 609 in epoch 8, gen_loss = 1.0154126417441447, disc_loss = 0.00030348143328246506
Trained batch 610 in epoch 8, gen_loss = 1.0155197887295786, disc_loss = 0.00030332138035615977
Trained batch 611 in epoch 8, gen_loss = 1.0155595924729615, disc_loss = 0.00030326659376156634
Trained batch 612 in epoch 8, gen_loss = 1.0155894017336224, disc_loss = 0.0003035293521248845
Trained batch 613 in epoch 8, gen_loss = 1.0154868793409888, disc_loss = 0.0003041381296912756
Trained batch 614 in epoch 8, gen_loss = 1.0153801510973675, disc_loss = 0.00030476453372635083
Trained batch 615 in epoch 8, gen_loss = 1.01550826585138, disc_loss = 0.00030525391304598253
Trained batch 616 in epoch 8, gen_loss = 1.0155029084346283, disc_loss = 0.00030565337172335443
Trained batch 617 in epoch 8, gen_loss = 1.0155176327452304, disc_loss = 0.0003062087934676891
Trained batch 618 in epoch 8, gen_loss = 1.0155757567416486, disc_loss = 0.00030688069766112385
Trained batch 619 in epoch 8, gen_loss = 1.0154823091722305, disc_loss = 0.0003076782649229919
Trained batch 620 in epoch 8, gen_loss = 1.015502503912614, disc_loss = 0.0003085654385013156
Trained batch 621 in epoch 8, gen_loss = 1.0156493769581294, disc_loss = 0.00030939913813784266
Trained batch 622 in epoch 8, gen_loss = 1.0156204964529072, disc_loss = 0.0003101597144983202
Trained batch 623 in epoch 8, gen_loss = 1.015616387510911, disc_loss = 0.00031058679415088054
Trained batch 624 in epoch 8, gen_loss = 1.0155459005355836, disc_loss = 0.00031079103025840596
Trained batch 625 in epoch 8, gen_loss = 1.0155626095521946, disc_loss = 0.0003109041237226388
Trained batch 626 in epoch 8, gen_loss = 1.015656842569415, disc_loss = 0.00031104728670174736
Trained batch 627 in epoch 8, gen_loss = 1.0157465577884843, disc_loss = 0.00031133072198323005
Trained batch 628 in epoch 8, gen_loss = 1.0157816040496948, disc_loss = 0.00031168613267889607
Trained batch 629 in epoch 8, gen_loss = 1.0158162417865935, disc_loss = 0.00031203777532302034
Trained batch 630 in epoch 8, gen_loss = 1.0158311880522788, disc_loss = 0.00031208658174003905
Trained batch 631 in epoch 8, gen_loss = 1.0159328900560547, disc_loss = 0.0003119502873831359
Trained batch 632 in epoch 8, gen_loss = 1.0158868809635229, disc_loss = 0.0003117465363048704
Trained batch 633 in epoch 8, gen_loss = 1.0160717616321913, disc_loss = 0.00031151909852642433
Trained batch 634 in epoch 8, gen_loss = 1.0161109473761611, disc_loss = 0.00031143293158457375
Trained batch 635 in epoch 8, gen_loss = 1.0160527177764185, disc_loss = 0.00031139483196840627
Trained batch 636 in epoch 8, gen_loss = 1.0160490591634574, disc_loss = 0.0003112989259854338
Trained batch 637 in epoch 8, gen_loss = 1.0159881335440848, disc_loss = 0.0003111854393094841
Trained batch 638 in epoch 8, gen_loss = 1.0158827854247534, disc_loss = 0.0003111176061474409
Trained batch 639 in epoch 8, gen_loss = 1.015793491061777, disc_loss = 0.00031116363701357843
Trained batch 640 in epoch 8, gen_loss = 1.0158010701679403, disc_loss = 0.00031120574275747613
Trained batch 641 in epoch 8, gen_loss = 1.0157561793319905, disc_loss = 0.0003111706242306017
Trained batch 642 in epoch 8, gen_loss = 1.0157053691232185, disc_loss = 0.00031101759605304863
Trained batch 643 in epoch 8, gen_loss = 1.0155922225358323, disc_loss = 0.0003107815385344749
Trained batch 644 in epoch 8, gen_loss = 1.0155229044515033, disc_loss = 0.00031049964662285725
Trained batch 645 in epoch 8, gen_loss = 1.0155052777967954, disc_loss = 0.00031021824767267053
Trained batch 646 in epoch 8, gen_loss = 1.0157028828190504, disc_loss = 0.0003100494056540812
Trained batch 647 in epoch 8, gen_loss = 1.0158418519077477, disc_loss = 0.000310095616587654
Trained batch 648 in epoch 8, gen_loss = 1.015872679340821, disc_loss = 0.000310272711725315
Trained batch 649 in epoch 8, gen_loss = 1.0158636768964622, disc_loss = 0.00031043907865890873
Trained batch 650 in epoch 8, gen_loss = 1.015823715385021, disc_loss = 0.00031054080989021885
Trained batch 651 in epoch 8, gen_loss = 1.0159412650791413, disc_loss = 0.00031046931816172495
Trained batch 652 in epoch 8, gen_loss = 1.0160511229158726, disc_loss = 0.0003102635769202919
Trained batch 653 in epoch 8, gen_loss = 1.0160321885839514, disc_loss = 0.00031002585154511986
Trained batch 654 in epoch 8, gen_loss = 1.0160000174100163, disc_loss = 0.0003097739248276148
Trained batch 655 in epoch 8, gen_loss = 1.0158245425398758, disc_loss = 0.0003095440857777714
Trained batch 656 in epoch 8, gen_loss = 1.0157311312865631, disc_loss = 0.0003093668122068324
Trained batch 657 in epoch 8, gen_loss = 1.0157140835802605, disc_loss = 0.00030914651168098794
Trained batch 658 in epoch 8, gen_loss = 1.0156748161873073, disc_loss = 0.00030887018950267065
Trained batch 659 in epoch 8, gen_loss = 1.0154449041142608, disc_loss = 0.0003086157380025587
Trained batch 660 in epoch 8, gen_loss = 1.0152649844287924, disc_loss = 0.0003084020348711879
Trained batch 661 in epoch 8, gen_loss = 1.0152382012400383, disc_loss = 0.0003081293009094763
Trained batch 662 in epoch 8, gen_loss = 1.0151620143139524, disc_loss = 0.00030776393320358766
Trained batch 663 in epoch 8, gen_loss = 1.0151220845529831, disc_loss = 0.00030743735481677045
Trained batch 664 in epoch 8, gen_loss = 1.0150540403853683, disc_loss = 0.0003071252188358204
Trained batch 665 in epoch 8, gen_loss = 1.015064992525198, disc_loss = 0.00030680176088891995
Trained batch 666 in epoch 8, gen_loss = 1.0150521017800922, disc_loss = 0.00030645258158582895
Trained batch 667 in epoch 8, gen_loss = 1.0151215457987643, disc_loss = 0.000306101651953932
Trained batch 668 in epoch 8, gen_loss = 1.0150727789141851, disc_loss = 0.0003057577829352602
Trained batch 669 in epoch 8, gen_loss = 1.0150029773142801, disc_loss = 0.00030545549088856205
Trained batch 670 in epoch 8, gen_loss = 1.0149492329172511, disc_loss = 0.00030518822576163613
Trained batch 671 in epoch 8, gen_loss = 1.0150064551049756, disc_loss = 0.00030496084604064456
Trained batch 672 in epoch 8, gen_loss = 1.0148665327551107, disc_loss = 0.0003048029769446222
Trained batch 673 in epoch 8, gen_loss = 1.0148437111597033, disc_loss = 0.0003046842611661507
Trained batch 674 in epoch 8, gen_loss = 1.0148057658584029, disc_loss = 0.0003046132040348042
Trained batch 675 in epoch 8, gen_loss = 1.01471826557577, disc_loss = 0.00030454323902938336
Trained batch 676 in epoch 8, gen_loss = 1.014750093970024, disc_loss = 0.00030453280597186454
Trained batch 677 in epoch 8, gen_loss = 1.0147213202662173, disc_loss = 0.0003045633807246076
Trained batch 678 in epoch 8, gen_loss = 1.014789698752458, disc_loss = 0.0003045145915999504
Trained batch 679 in epoch 8, gen_loss = 1.0147808995317011, disc_loss = 0.00030433952103040235
Trained batch 680 in epoch 8, gen_loss = 1.0148208720743568, disc_loss = 0.00030416243296956284
Trained batch 681 in epoch 8, gen_loss = 1.0147052666833323, disc_loss = 0.0003038872141707511
Trained batch 682 in epoch 8, gen_loss = 1.0146618809218289, disc_loss = 0.00030354773651724643
Trained batch 683 in epoch 8, gen_loss = 1.0146802677745708, disc_loss = 0.00030321968386073293
Trained batch 684 in epoch 8, gen_loss = 1.014651101175016, disc_loss = 0.0003029482939130164
Trained batch 685 in epoch 8, gen_loss = 1.0148015939807058, disc_loss = 0.0003028157644189179
Trained batch 686 in epoch 8, gen_loss = 1.0147724830948108, disc_loss = 0.0003027680676703794
Trained batch 687 in epoch 8, gen_loss = 1.0146840958921022, disc_loss = 0.00030268865522123443
Trained batch 688 in epoch 8, gen_loss = 1.0146834953256891, disc_loss = 0.0003024507758866743
Trained batch 689 in epoch 8, gen_loss = 1.014792154578195, disc_loss = 0.00030213495526855904
Trained batch 690 in epoch 8, gen_loss = 1.0146469097751611, disc_loss = 0.00030180207700608434
Trained batch 691 in epoch 8, gen_loss = 1.014450206835835, disc_loss = 0.00030152049364420825
Trained batch 692 in epoch 8, gen_loss = 1.0144416311430553, disc_loss = 0.00030129061415104443
Trained batch 693 in epoch 8, gen_loss = 1.014309565856065, disc_loss = 0.00030100386152495174
Trained batch 694 in epoch 8, gen_loss = 1.0142723302189394, disc_loss = 0.00030087615770962856
Trained batch 695 in epoch 8, gen_loss = 1.0143538704034927, disc_loss = 0.0003008548496052691
Trained batch 696 in epoch 8, gen_loss = 1.014418305676842, disc_loss = 0.0003008571290189749
Trained batch 697 in epoch 8, gen_loss = 1.0143190701745644, disc_loss = 0.00030079106064531674
Trained batch 698 in epoch 8, gen_loss = 1.0144377523055232, disc_loss = 0.0003007698973246253
Trained batch 699 in epoch 8, gen_loss = 1.0144250225169318, disc_loss = 0.0003008735129073362
Trained batch 700 in epoch 8, gen_loss = 1.0144144885890325, disc_loss = 0.0003010042368851372
Trained batch 701 in epoch 8, gen_loss = 1.0143506701855238, disc_loss = 0.0003012282331138312
Trained batch 702 in epoch 8, gen_loss = 1.014186050440814, disc_loss = 0.0003014964987566081
Trained batch 703 in epoch 8, gen_loss = 1.0141865053976125, disc_loss = 0.00030180163237632354
Trained batch 704 in epoch 8, gen_loss = 1.0141154060127042, disc_loss = 0.000302074272224782
Trained batch 705 in epoch 8, gen_loss = 1.0141088348779057, disc_loss = 0.0003022866906553194
Trained batch 706 in epoch 8, gen_loss = 1.0141829760610805, disc_loss = 0.0003024912362204782
Trained batch 707 in epoch 8, gen_loss = 1.0140093941304644, disc_loss = 0.00030271307031331667
Trained batch 708 in epoch 8, gen_loss = 1.0140079822291441, disc_loss = 0.00030293851318578363
Trained batch 709 in epoch 8, gen_loss = 1.0139860792059294, disc_loss = 0.0003031164005502868
Trained batch 710 in epoch 8, gen_loss = 1.0141041321593498, disc_loss = 0.0003032200369893366
Trained batch 711 in epoch 8, gen_loss = 1.0139769313208173, disc_loss = 0.00030333118422604046
Trained batch 712 in epoch 8, gen_loss = 1.0138802574359684, disc_loss = 0.00030345521601095603
Trained batch 713 in epoch 8, gen_loss = 1.013940305185585, disc_loss = 0.0003034664849884885
Trained batch 714 in epoch 8, gen_loss = 1.013948896464768, disc_loss = 0.0003033638785782895
Trained batch 715 in epoch 8, gen_loss = 1.0139885866941687, disc_loss = 0.00030324267277010526
Trained batch 716 in epoch 8, gen_loss = 1.013968386660061, disc_loss = 0.00030317829380234354
Trained batch 717 in epoch 8, gen_loss = 1.0139361018922004, disc_loss = 0.00030318540422264345
Trained batch 718 in epoch 8, gen_loss = 1.0138966912851877, disc_loss = 0.00030321629030180845
Trained batch 719 in epoch 8, gen_loss = 1.013865004065964, disc_loss = 0.0003032479115972819
Trained batch 720 in epoch 8, gen_loss = 1.0138389930315057, disc_loss = 0.0003032529566149762
Trained batch 721 in epoch 8, gen_loss = 1.013745314609311, disc_loss = 0.00030315293264509196
Trained batch 722 in epoch 8, gen_loss = 1.013768620428373, disc_loss = 0.00030299497136572777
Trained batch 723 in epoch 8, gen_loss = 1.0137135435039826, disc_loss = 0.00030285307749176784
Trained batch 724 in epoch 8, gen_loss = 1.0137484391804399, disc_loss = 0.00030281190759430093
Trained batch 725 in epoch 8, gen_loss = 1.0138012376862782, disc_loss = 0.00030284629032564526
Trained batch 726 in epoch 8, gen_loss = 1.0137868943371833, disc_loss = 0.00030280768858616984
Trained batch 727 in epoch 8, gen_loss = 1.0138270310484445, disc_loss = 0.0003026543762054324
Trained batch 728 in epoch 8, gen_loss = 1.0138683870986656, disc_loss = 0.0003024442064596132
Trained batch 729 in epoch 8, gen_loss = 1.0138398571373666, disc_loss = 0.00030222971903117157
Trained batch 730 in epoch 8, gen_loss = 1.0139167503684392, disc_loss = 0.0003020730992132083
Trained batch 731 in epoch 8, gen_loss = 1.0137665235116833, disc_loss = 0.000302128392966134
Trained batch 732 in epoch 8, gen_loss = 1.0137304966153746, disc_loss = 0.00030255713080201176
Trained batch 733 in epoch 8, gen_loss = 1.0137002501403278, disc_loss = 0.00030312528571455576
Trained batch 734 in epoch 8, gen_loss = 1.01367036525895, disc_loss = 0.0003035623960448017
Trained batch 735 in epoch 8, gen_loss = 1.013676331014089, disc_loss = 0.0003037850502135805
Trained batch 736 in epoch 8, gen_loss = 1.0136510876981666, disc_loss = 0.00030377972935235727
Trained batch 737 in epoch 8, gen_loss = 1.0136329874921297, disc_loss = 0.00030358572674719274
Trained batch 738 in epoch 8, gen_loss = 1.0136822048317595, disc_loss = 0.00030329354722419857
Trained batch 739 in epoch 8, gen_loss = 1.0137087734164418, disc_loss = 0.0003029821582655328
Trained batch 740 in epoch 8, gen_loss = 1.0137430591139234, disc_loss = 0.00030265568258366817
Trained batch 741 in epoch 8, gen_loss = 1.0137655403254167, disc_loss = 0.0003023318866698631
Trained batch 742 in epoch 8, gen_loss = 1.0137448403106883, disc_loss = 0.0003020108887617236
Trained batch 743 in epoch 8, gen_loss = 1.0137048771464696, disc_loss = 0.0003016803207907698
Trained batch 744 in epoch 8, gen_loss = 1.0136665973087284, disc_loss = 0.0003013561105694709
Trained batch 745 in epoch 8, gen_loss = 1.0137555731844965, disc_loss = 0.0003010861562202459
Trained batch 746 in epoch 8, gen_loss = 1.0137670873159386, disc_loss = 0.0003008134718332159
Trained batch 747 in epoch 8, gen_loss = 1.0137398101110509, disc_loss = 0.000300503153147946
Trained batch 748 in epoch 8, gen_loss = 1.0137050376237633, disc_loss = 0.0003001984205111415
Trained batch 749 in epoch 8, gen_loss = 1.0136557421684265, disc_loss = 0.0002999164662420905
Trained batch 750 in epoch 8, gen_loss = 1.0136360003056126, disc_loss = 0.00029965647531819955
Trained batch 751 in epoch 8, gen_loss = 1.013716183127241, disc_loss = 0.00029941767315130104
Trained batch 752 in epoch 8, gen_loss = 1.0138768071672355, disc_loss = 0.0002991732775455076
Trained batch 753 in epoch 8, gen_loss = 1.013921087079086, disc_loss = 0.00029891726662561086
Trained batch 754 in epoch 8, gen_loss = 1.0138690339018968, disc_loss = 0.0002986525817017151
Trained batch 755 in epoch 8, gen_loss = 1.013893389512622, disc_loss = 0.00029842721000908156
Trained batch 756 in epoch 8, gen_loss = 1.0138519802370662, disc_loss = 0.0002982780042873656
Trained batch 757 in epoch 8, gen_loss = 1.0138235953206438, disc_loss = 0.00029812981993882084
Trained batch 758 in epoch 8, gen_loss = 1.0137960438828852, disc_loss = 0.000297967582510518
Trained batch 759 in epoch 8, gen_loss = 1.0138808205723762, disc_loss = 0.0002978679188680345
Trained batch 760 in epoch 8, gen_loss = 1.0138052536686208, disc_loss = 0.0002977168516972764
Trained batch 761 in epoch 8, gen_loss = 1.0138045351492764, disc_loss = 0.00029747997796507623
Trained batch 762 in epoch 8, gen_loss = 1.013757386807533, disc_loss = 0.0002971712092880122
Trained batch 763 in epoch 8, gen_loss = 1.0138303227137522, disc_loss = 0.00029685437521372016
Trained batch 764 in epoch 8, gen_loss = 1.0138632180644016, disc_loss = 0.0002965407590452183
Trained batch 765 in epoch 8, gen_loss = 1.0139075235971895, disc_loss = 0.0002962448728766202
Trained batch 766 in epoch 8, gen_loss = 1.0138987518817848, disc_loss = 0.00029597908382119904
Trained batch 767 in epoch 8, gen_loss = 1.0138881181677182, disc_loss = 0.0002957255408517767
Trained batch 768 in epoch 8, gen_loss = 1.0139141640830567, disc_loss = 0.00029548672480244215
Trained batch 769 in epoch 8, gen_loss = 1.0139077031767214, disc_loss = 0.0002952650199652205
Trained batch 770 in epoch 8, gen_loss = 1.013916760103248, disc_loss = 0.0002950262346501017
Trained batch 771 in epoch 8, gen_loss = 1.013788205508741, disc_loss = 0.000294762117068856
Trained batch 772 in epoch 8, gen_loss = 1.0137467159953493, disc_loss = 0.0002944712110032357
Trained batch 773 in epoch 8, gen_loss = 1.0137551327546437, disc_loss = 0.00029419253948525896
Trained batch 774 in epoch 8, gen_loss = 1.0138939581378814, disc_loss = 0.0002939667459999797
Trained batch 775 in epoch 8, gen_loss = 1.01404900487858, disc_loss = 0.000293752255889633
Trained batch 776 in epoch 8, gen_loss = 1.0140607080097517, disc_loss = 0.00029352109087252796
Trained batch 777 in epoch 8, gen_loss = 1.0140154744021996, disc_loss = 0.00029329585857732924
Trained batch 778 in epoch 8, gen_loss = 1.0139371177351368, disc_loss = 0.00029309301844221035
Trained batch 779 in epoch 8, gen_loss = 1.013911530146232, disc_loss = 0.00029294398146027025
Trained batch 780 in epoch 8, gen_loss = 1.0139197512564373, disc_loss = 0.0002928302579983236
Trained batch 781 in epoch 8, gen_loss = 1.0137936161149799, disc_loss = 0.0002927988665006847
Trained batch 782 in epoch 8, gen_loss = 1.0138178583458162, disc_loss = 0.00029295470887279326
Trained batch 783 in epoch 8, gen_loss = 1.0137611380493154, disc_loss = 0.0002932722904219821
Trained batch 784 in epoch 8, gen_loss = 1.0137515635247443, disc_loss = 0.0002936393036208617
Trained batch 785 in epoch 8, gen_loss = 1.0137327967860923, disc_loss = 0.00029407143804911046
Trained batch 786 in epoch 8, gen_loss = 1.0136982000313386, disc_loss = 0.00029449055296749206
Trained batch 787 in epoch 8, gen_loss = 1.0137493732163143, disc_loss = 0.00029486979329810083
Trained batch 788 in epoch 8, gen_loss = 1.0136546052151911, disc_loss = 0.0002951903106124717
Trained batch 789 in epoch 8, gen_loss = 1.0137253302562086, disc_loss = 0.00029542559784630023
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8999758362770081, disc_loss = 0.00034832468372769654
Trained batch 1 in epoch 9, gen_loss = 0.9840308725833893, disc_loss = 0.0002823578397510573
Trained batch 2 in epoch 9, gen_loss = 0.9681500792503357, disc_loss = 0.0002504589598781119
Trained batch 3 in epoch 9, gen_loss = 0.9893112331628799, disc_loss = 0.0002530305864638649
Trained batch 4 in epoch 9, gen_loss = 1.0077553153038026, disc_loss = 0.0002669846115168184
Trained batch 5 in epoch 9, gen_loss = 1.0014782845973969, disc_loss = 0.0002722328887709106
Trained batch 6 in epoch 9, gen_loss = 1.0024801237242562, disc_loss = 0.00026712926254341643
Trained batch 7 in epoch 9, gen_loss = 1.0040960237383842, disc_loss = 0.0002552897603891324
Trained batch 8 in epoch 9, gen_loss = 1.0016346441374884, disc_loss = 0.00024567964040519047
Trained batch 9 in epoch 9, gen_loss = 1.0035185515880585, disc_loss = 0.00024396169901592658
Trained batch 10 in epoch 9, gen_loss = 1.000204698605971, disc_loss = 0.0002444386786506088
Trained batch 11 in epoch 9, gen_loss = 1.0001440693934758, disc_loss = 0.00024370315926110683
Trained batch 12 in epoch 9, gen_loss = 0.9943865262545072, disc_loss = 0.0002458677392076844
Trained batch 13 in epoch 9, gen_loss = 0.9988046543938773, disc_loss = 0.0002540374210054454
Trained batch 14 in epoch 9, gen_loss = 1.0001951217651368, disc_loss = 0.0002640472307878857
Trained batch 15 in epoch 9, gen_loss = 0.9984158426523209, disc_loss = 0.0002736516662480426
Trained batch 16 in epoch 9, gen_loss = 1.0032885565477259, disc_loss = 0.0002822196838678792
Trained batch 17 in epoch 9, gen_loss = 1.0042470229996576, disc_loss = 0.00028732142931807577
Trained batch 18 in epoch 9, gen_loss = 1.0104663685748452, disc_loss = 0.0002931168932455445
Trained batch 19 in epoch 9, gen_loss = 1.013969177007675, disc_loss = 0.00029484204496839085
Trained batch 20 in epoch 9, gen_loss = 1.0156334297997611, disc_loss = 0.00030035622919621387
Trained batch 21 in epoch 9, gen_loss = 1.013118944384835, disc_loss = 0.0003053358304896392
Trained batch 22 in epoch 9, gen_loss = 1.0071911500847859, disc_loss = 0.00030997767981202543
Trained batch 23 in epoch 9, gen_loss = 1.006102239092191, disc_loss = 0.000315183718460806
Trained batch 24 in epoch 9, gen_loss = 1.011273708343506, disc_loss = 0.0003184082644293085
Trained batch 25 in epoch 9, gen_loss = 1.010730239061209, disc_loss = 0.00031699783833643707
Trained batch 26 in epoch 9, gen_loss = 1.012287519596241, disc_loss = 0.00031586882013706836
Trained batch 27 in epoch 9, gen_loss = 1.0138578159468514, disc_loss = 0.0003144228503515478
Trained batch 28 in epoch 9, gen_loss = 1.013910408677726, disc_loss = 0.00031137720737927434
Trained batch 29 in epoch 9, gen_loss = 1.0123728036880493, disc_loss = 0.0003091701587739711
Trained batch 30 in epoch 9, gen_loss = 1.0089424464010424, disc_loss = 0.00030778103504299875
Trained batch 31 in epoch 9, gen_loss = 1.0101614631712437, disc_loss = 0.0003059365953959059
Trained batch 32 in epoch 9, gen_loss = 1.00897216796875, disc_loss = 0.00030404736268489313
Trained batch 33 in epoch 9, gen_loss = 1.0072777253739975, disc_loss = 0.0003030995520769947
Trained batch 34 in epoch 9, gen_loss = 1.0060931529317583, disc_loss = 0.000302416060003452
Trained batch 35 in epoch 9, gen_loss = 1.009742460317082, disc_loss = 0.0003011026359066212
Trained batch 36 in epoch 9, gen_loss = 1.008984834761233, disc_loss = 0.00029933321678293615
Trained batch 37 in epoch 9, gen_loss = 1.0132534801959991, disc_loss = 0.000299257096469917
Trained batch 38 in epoch 9, gen_loss = 1.0111349805807457, disc_loss = 0.000300361779712451
Trained batch 39 in epoch 9, gen_loss = 1.0107574746012689, disc_loss = 0.00030550414412573447
Trained batch 40 in epoch 9, gen_loss = 1.010495951989802, disc_loss = 0.0003137716632364772
Trained batch 41 in epoch 9, gen_loss = 1.0111945001851945, disc_loss = 0.00032412827775780376
Trained batch 42 in epoch 9, gen_loss = 1.0099487457164498, disc_loss = 0.00033796050478866713
Trained batch 43 in epoch 9, gen_loss = 1.0107939663258465, disc_loss = 0.0003532862204089972
Trained batch 44 in epoch 9, gen_loss = 1.0126500540309482, disc_loss = 0.0003672043097645251
Trained batch 45 in epoch 9, gen_loss = 1.0104327733102052, disc_loss = 0.0003755858155984796
Trained batch 46 in epoch 9, gen_loss = 1.0092058422717642, disc_loss = 0.0003775688773144948
Trained batch 47 in epoch 9, gen_loss = 1.0096728193263214, disc_loss = 0.0003776866472738523
Trained batch 48 in epoch 9, gen_loss = 1.0082326361111231, disc_loss = 0.00037634153868195276
Trained batch 49 in epoch 9, gen_loss = 1.0067904770374299, disc_loss = 0.00037322096206480635
Trained batch 50 in epoch 9, gen_loss = 1.008219484020682, disc_loss = 0.0003696317826146625
Trained batch 51 in epoch 9, gen_loss = 1.0086445521849852, disc_loss = 0.0003682353442575102
Trained batch 52 in epoch 9, gen_loss = 1.0080004401926725, disc_loss = 0.00036953107584575365
Trained batch 53 in epoch 9, gen_loss = 1.0085664490858715, disc_loss = 0.00037237247360516685
Trained batch 54 in epoch 9, gen_loss = 1.0090804609385404, disc_loss = 0.0003752457747892053
Trained batch 55 in epoch 9, gen_loss = 1.0090166489992822, disc_loss = 0.0003766800829388168
Trained batch 56 in epoch 9, gen_loss = 1.0079451182432342, disc_loss = 0.000375741481803472
Trained batch 57 in epoch 9, gen_loss = 1.0079210678051258, disc_loss = 0.00037388788593395065
Trained batch 58 in epoch 9, gen_loss = 1.0072400074894146, disc_loss = 0.00037191192924352837
Trained batch 59 in epoch 9, gen_loss = 1.0070554862419765, disc_loss = 0.00036980745620288265
Trained batch 60 in epoch 9, gen_loss = 1.0089206040882674, disc_loss = 0.0003681132566569312
Trained batch 61 in epoch 9, gen_loss = 1.0097186305830557, disc_loss = 0.00036833147333386625
Trained batch 62 in epoch 9, gen_loss = 1.0107631276524256, disc_loss = 0.00037000423998549757
Trained batch 63 in epoch 9, gen_loss = 1.0100339306518435, disc_loss = 0.0003724240129940881
Trained batch 64 in epoch 9, gen_loss = 1.0109758147826562, disc_loss = 0.0003737545346106904
Trained batch 65 in epoch 9, gen_loss = 1.01107827370817, disc_loss = 0.0003742139535571561
Trained batch 66 in epoch 9, gen_loss = 1.012119488040013, disc_loss = 0.0003743155052756835
Trained batch 67 in epoch 9, gen_loss = 1.0121686116737478, disc_loss = 0.0003737826223454356
Trained batch 68 in epoch 9, gen_loss = 1.0119722779246345, disc_loss = 0.00037206882383991575
Trained batch 69 in epoch 9, gen_loss = 1.0117865485804423, disc_loss = 0.00036898864304280975
Trained batch 70 in epoch 9, gen_loss = 1.0113810930453555, disc_loss = 0.00036546373682450767
Trained batch 71 in epoch 9, gen_loss = 1.012859192987283, disc_loss = 0.0003632918992985247
Trained batch 72 in epoch 9, gen_loss = 1.0126468678043312, disc_loss = 0.0003637986860480415
Trained batch 73 in epoch 9, gen_loss = 1.0121938956750405, disc_loss = 0.00036717423259884725
Trained batch 74 in epoch 9, gen_loss = 1.012882580757141, disc_loss = 0.0003708793168577055
Trained batch 75 in epoch 9, gen_loss = 1.0135926102337085, disc_loss = 0.0003727819735343617
Trained batch 76 in epoch 9, gen_loss = 1.013351015456311, disc_loss = 0.0003724280595870132
Trained batch 77 in epoch 9, gen_loss = 1.0139976059779143, disc_loss = 0.00037196393196399394
Trained batch 78 in epoch 9, gen_loss = 1.0141235657885104, disc_loss = 0.0003709102722173675
Trained batch 79 in epoch 9, gen_loss = 1.0138408340513707, disc_loss = 0.00036868320894427596
Trained batch 80 in epoch 9, gen_loss = 1.0141206942958596, disc_loss = 0.0003661999182867599
Trained batch 81 in epoch 9, gen_loss = 1.0144873472248637, disc_loss = 0.0003636556644867197
Trained batch 82 in epoch 9, gen_loss = 1.0148082404251557, disc_loss = 0.0003611195183089788
Trained batch 83 in epoch 9, gen_loss = 1.0148122218393145, disc_loss = 0.0003582785235873113
Trained batch 84 in epoch 9, gen_loss = 1.0135664827683393, disc_loss = 0.0003557035257793306
Trained batch 85 in epoch 9, gen_loss = 1.0125467084174933, disc_loss = 0.0003531922408255077
Trained batch 86 in epoch 9, gen_loss = 1.011526380462208, disc_loss = 0.0003503967786071308
Trained batch 87 in epoch 9, gen_loss = 1.0120795572345906, disc_loss = 0.0003478724538581446
Trained batch 88 in epoch 9, gen_loss = 1.0118401706888434, disc_loss = 0.00034600571765867845
Trained batch 89 in epoch 9, gen_loss = 1.0117645727263556, disc_loss = 0.0003447534760602543
Trained batch 90 in epoch 9, gen_loss = 1.0116166243186364, disc_loss = 0.0003433719788777775
Trained batch 91 in epoch 9, gen_loss = 1.011772201113079, disc_loss = 0.0003412858443524506
Trained batch 92 in epoch 9, gen_loss = 1.0124581924048803, disc_loss = 0.0003386849758274082
Trained batch 93 in epoch 9, gen_loss = 1.0131235528499523, disc_loss = 0.00033585153567478396
Trained batch 94 in epoch 9, gen_loss = 1.0128551696476182, disc_loss = 0.00033338147508115264
Trained batch 95 in epoch 9, gen_loss = 1.0126174601415794, disc_loss = 0.0003314502183305497
Trained batch 96 in epoch 9, gen_loss = 1.0124041026400536, disc_loss = 0.00032956041577188107
Trained batch 97 in epoch 9, gen_loss = 1.0119183264216598, disc_loss = 0.000327648238230815
Trained batch 98 in epoch 9, gen_loss = 1.0111136394317704, disc_loss = 0.00032552994092140873
Trained batch 99 in epoch 9, gen_loss = 1.0115012317895888, disc_loss = 0.000323027393387747
Trained batch 100 in epoch 9, gen_loss = 1.0122657607097436, disc_loss = 0.00032061949352985063
Trained batch 101 in epoch 9, gen_loss = 1.0120794323145175, disc_loss = 0.0003181872466395326
Trained batch 102 in epoch 9, gen_loss = 1.0119858395706103, disc_loss = 0.00031637359862340145
Trained batch 103 in epoch 9, gen_loss = 1.0120036859924977, disc_loss = 0.0003149712582363953
Trained batch 104 in epoch 9, gen_loss = 1.0123801361946834, disc_loss = 0.00031369440278337734
Trained batch 105 in epoch 9, gen_loss = 1.013177730564801, disc_loss = 0.00031255934636475395
Trained batch 106 in epoch 9, gen_loss = 1.0130266981704212, disc_loss = 0.00031161597905687063
Trained batch 107 in epoch 9, gen_loss = 1.012313562962744, disc_loss = 0.0003107526500335317
Trained batch 108 in epoch 9, gen_loss = 1.0127955538417222, disc_loss = 0.00031088377487121594
Trained batch 109 in epoch 9, gen_loss = 1.012768032875928, disc_loss = 0.00031097508148046805
Trained batch 110 in epoch 9, gen_loss = 1.0135222721744228, disc_loss = 0.00031079892295901454
Trained batch 111 in epoch 9, gen_loss = 1.0138457837913717, disc_loss = 0.0003109875870645088
Trained batch 112 in epoch 9, gen_loss = 1.0156117471973454, disc_loss = 0.00031162950163140515
Trained batch 113 in epoch 9, gen_loss = 1.0162135535164882, disc_loss = 0.00031240460348750564
Trained batch 114 in epoch 9, gen_loss = 1.0161436220873956, disc_loss = 0.0003133054544931561
Trained batch 115 in epoch 9, gen_loss = 1.0164858878686511, disc_loss = 0.00031512643162668924
Trained batch 116 in epoch 9, gen_loss = 1.0163584810036879, disc_loss = 0.00031752998570754373
Trained batch 117 in epoch 9, gen_loss = 1.0165546339447216, disc_loss = 0.00031988754710902744
Trained batch 118 in epoch 9, gen_loss = 1.0174779686607232, disc_loss = 0.00032179492889921094
Trained batch 119 in epoch 9, gen_loss = 1.0171916499733924, disc_loss = 0.00032335989775068207
Trained batch 120 in epoch 9, gen_loss = 1.0173762943133835, disc_loss = 0.000324515395709756
Trained batch 121 in epoch 9, gen_loss = 1.0173468868263433, disc_loss = 0.0003254290598708961
Trained batch 122 in epoch 9, gen_loss = 1.0182193590373527, disc_loss = 0.00032615926897776033
Trained batch 123 in epoch 9, gen_loss = 1.018285997932957, disc_loss = 0.0003267172332632453
Trained batch 124 in epoch 9, gen_loss = 1.019052746295929, disc_loss = 0.0003272129216347821
Trained batch 125 in epoch 9, gen_loss = 1.0187190837330289, disc_loss = 0.00032739906664429574
Trained batch 126 in epoch 9, gen_loss = 1.01950366853729, disc_loss = 0.0003274335062674863
Trained batch 127 in epoch 9, gen_loss = 1.0191986411809921, disc_loss = 0.00032724648741577766
Trained batch 128 in epoch 9, gen_loss = 1.0192212892133137, disc_loss = 0.00032711463765820574
Trained batch 129 in epoch 9, gen_loss = 1.0200337575032161, disc_loss = 0.0003272495611431973
Trained batch 130 in epoch 9, gen_loss = 1.0200607858541357, disc_loss = 0.0003278886663077847
Trained batch 131 in epoch 9, gen_loss = 1.0204088552431627, disc_loss = 0.00032840219682839233
Trained batch 132 in epoch 9, gen_loss = 1.0201057034327572, disc_loss = 0.0003282405741629191
Trained batch 133 in epoch 9, gen_loss = 1.0201268543058366, disc_loss = 0.00032761854684517245
Trained batch 134 in epoch 9, gen_loss = 1.020092150900099, disc_loss = 0.0003268087791015946
Trained batch 135 in epoch 9, gen_loss = 1.0198330248103422, disc_loss = 0.00032592421736326823
Trained batch 136 in epoch 9, gen_loss = 1.0200814017414177, disc_loss = 0.000325128985609244
Trained batch 137 in epoch 9, gen_loss = 1.0198590699313343, disc_loss = 0.00032405057029699083
Trained batch 138 in epoch 9, gen_loss = 1.019589467871961, disc_loss = 0.0003225533973229647
Trained batch 139 in epoch 9, gen_loss = 1.019577248607363, disc_loss = 0.00032089601653361956
Trained batch 140 in epoch 9, gen_loss = 1.019689977591765, disc_loss = 0.0003191602347395548
Trained batch 141 in epoch 9, gen_loss = 1.0193089607735755, disc_loss = 0.0003173788742495957
Trained batch 142 in epoch 9, gen_loss = 1.019243903927036, disc_loss = 0.000315678782779007
Trained batch 143 in epoch 9, gen_loss = 1.019513464636273, disc_loss = 0.0003141542548392964
Trained batch 144 in epoch 9, gen_loss = 1.0199140729575322, disc_loss = 0.00031273798828398617
Trained batch 145 in epoch 9, gen_loss = 1.019711336044416, disc_loss = 0.0003113316012026538
Trained batch 146 in epoch 9, gen_loss = 1.0197226052381554, disc_loss = 0.00030994075317795824
Trained batch 147 in epoch 9, gen_loss = 1.0195862280355918, disc_loss = 0.00030847199751234084
Trained batch 148 in epoch 9, gen_loss = 1.0194372894779948, disc_loss = 0.00030686991063068504
Trained batch 149 in epoch 9, gen_loss = 1.0191940224170686, disc_loss = 0.0003052332508377731
Trained batch 150 in epoch 9, gen_loss = 1.0198547038810932, disc_loss = 0.0003036032326747694
Trained batch 151 in epoch 9, gen_loss = 1.0203178881814605, disc_loss = 0.00030189906587302655
Trained batch 152 in epoch 9, gen_loss = 1.0202011832224778, disc_loss = 0.0003001903776725027
Trained batch 153 in epoch 9, gen_loss = 1.0200847081549755, disc_loss = 0.00029846668661917503
Trained batch 154 in epoch 9, gen_loss = 1.0205200768286182, disc_loss = 0.0002967761859772802
Trained batch 155 in epoch 9, gen_loss = 1.0210027973621318, disc_loss = 0.00029519210266488907
Trained batch 156 in epoch 9, gen_loss = 1.021013806200331, disc_loss = 0.0002936509442122677
Trained batch 157 in epoch 9, gen_loss = 1.0205847172042992, disc_loss = 0.0002922929472126409
Trained batch 158 in epoch 9, gen_loss = 1.020669068555412, disc_loss = 0.0002910419908237245
Trained batch 159 in epoch 9, gen_loss = 1.0209604103118182, disc_loss = 0.0002899787893966277
Trained batch 160 in epoch 9, gen_loss = 1.0207622077154077, disc_loss = 0.00028890081084230685
Trained batch 161 in epoch 9, gen_loss = 1.0208968862339303, disc_loss = 0.0002879595827655493
Trained batch 162 in epoch 9, gen_loss = 1.0207346399868924, disc_loss = 0.0002871454024078193
Trained batch 163 in epoch 9, gen_loss = 1.0209886809674704, disc_loss = 0.00028638547550277816
Trained batch 164 in epoch 9, gen_loss = 1.0205918113390604, disc_loss = 0.000285573388673859
Trained batch 165 in epoch 9, gen_loss = 1.0207202912095081, disc_loss = 0.00028491075022155923
Trained batch 166 in epoch 9, gen_loss = 1.0206008567781506, disc_loss = 0.00028458140529225115
Trained batch 167 in epoch 9, gen_loss = 1.0202663977231299, disc_loss = 0.0002847507586401272
Trained batch 168 in epoch 9, gen_loss = 1.0202618368278593, disc_loss = 0.0002853144103604005
Trained batch 169 in epoch 9, gen_loss = 1.020234048015931, disc_loss = 0.00028624696377151207
Trained batch 170 in epoch 9, gen_loss = 1.0207457260081643, disc_loss = 0.0002867808272842214
Trained batch 171 in epoch 9, gen_loss = 1.02068983850091, disc_loss = 0.0002868313399948272
Trained batch 172 in epoch 9, gen_loss = 1.0207671412842811, disc_loss = 0.00028695895511023106
Trained batch 173 in epoch 9, gen_loss = 1.0206981222519929, disc_loss = 0.0002874096606047851
Trained batch 174 in epoch 9, gen_loss = 1.0202781864574977, disc_loss = 0.000288325716017945
Trained batch 175 in epoch 9, gen_loss = 1.0208073783327232, disc_loss = 0.0002890957897844518
Trained batch 176 in epoch 9, gen_loss = 1.0206407773292672, disc_loss = 0.0002889739092400608
Trained batch 177 in epoch 9, gen_loss = 1.0204066285926305, disc_loss = 0.00028830191537932744
Trained batch 178 in epoch 9, gen_loss = 1.0202586294552467, disc_loss = 0.000287363912844211
Trained batch 179 in epoch 9, gen_loss = 1.020793119735188, disc_loss = 0.00028639460603396095
Trained batch 180 in epoch 9, gen_loss = 1.0210695520290354, disc_loss = 0.0002855396836298873
Trained batch 181 in epoch 9, gen_loss = 1.021282081093107, disc_loss = 0.0002847655157713414
Trained batch 182 in epoch 9, gen_loss = 1.0209333645841463, disc_loss = 0.0002839039239677463
Trained batch 183 in epoch 9, gen_loss = 1.0215780252347821, disc_loss = 0.00028294758846206366
Trained batch 184 in epoch 9, gen_loss = 1.0215164039586042, disc_loss = 0.0002820438281412715
Trained batch 185 in epoch 9, gen_loss = 1.0213261647250063, disc_loss = 0.0002809481039519362
Trained batch 186 in epoch 9, gen_loss = 1.0209628079026778, disc_loss = 0.00027973217329223276
Trained batch 187 in epoch 9, gen_loss = 1.0212673579758786, disc_loss = 0.00027852338781543794
Trained batch 188 in epoch 9, gen_loss = 1.0213506117699638, disc_loss = 0.00027730284007644975
Trained batch 189 in epoch 9, gen_loss = 1.0209371739312223, disc_loss = 0.00027607018038045347
Trained batch 190 in epoch 9, gen_loss = 1.020894766165948, disc_loss = 0.0002748221506970186
Trained batch 191 in epoch 9, gen_loss = 1.020705856072406, disc_loss = 0.0002736097989289495
Trained batch 192 in epoch 9, gen_loss = 1.0205654332057181, disc_loss = 0.00027244368674676295
Trained batch 193 in epoch 9, gen_loss = 1.0207724927626933, disc_loss = 0.0002714436781126406
Trained batch 194 in epoch 9, gen_loss = 1.0203567639375344, disc_loss = 0.00027051271183434157
Trained batch 195 in epoch 9, gen_loss = 1.0206007659435272, disc_loss = 0.000269668193957804
Trained batch 196 in epoch 9, gen_loss = 1.020414747865067, disc_loss = 0.0002688240800005606
Trained batch 197 in epoch 9, gen_loss = 1.020285287589738, disc_loss = 0.0002678288109371241
Trained batch 198 in epoch 9, gen_loss = 1.0204347464906511, disc_loss = 0.00026680925229491766
Trained batch 199 in epoch 9, gen_loss = 1.0205495008826255, disc_loss = 0.0002658079752291087
Trained batch 200 in epoch 9, gen_loss = 1.0202019425173896, disc_loss = 0.00026479860125121137
Trained batch 201 in epoch 9, gen_loss = 1.0204727422482898, disc_loss = 0.00026374388637285135
Trained batch 202 in epoch 9, gen_loss = 1.0203654519442855, disc_loss = 0.0002626960814971789
Trained batch 203 in epoch 9, gen_loss = 1.0201023074926114, disc_loss = 0.00026168726435571443
Trained batch 204 in epoch 9, gen_loss = 1.020406980630828, disc_loss = 0.00026082681309539687
Trained batch 205 in epoch 9, gen_loss = 1.0201700286379138, disc_loss = 0.0002600138723209966
Trained batch 206 in epoch 9, gen_loss = 1.0203773442673798, disc_loss = 0.00025924808880148885
Trained batch 207 in epoch 9, gen_loss = 1.0199171972389405, disc_loss = 0.00025861337791446625
Trained batch 208 in epoch 9, gen_loss = 1.0199073133856487, disc_loss = 0.0002582932584771427
Trained batch 209 in epoch 9, gen_loss = 1.0195698434398288, disc_loss = 0.0002583527025264976
Trained batch 210 in epoch 9, gen_loss = 1.0193554391793165, disc_loss = 0.00025860292770678035
Trained batch 211 in epoch 9, gen_loss = 1.0194723682021194, disc_loss = 0.0002588423216846697
Trained batch 212 in epoch 9, gen_loss = 1.0191643674608688, disc_loss = 0.0002591002452339728
Trained batch 213 in epoch 9, gen_loss = 1.0190776241159885, disc_loss = 0.0002595794579396612
Trained batch 214 in epoch 9, gen_loss = 1.01908492986546, disc_loss = 0.0002600530554678529
Trained batch 215 in epoch 9, gen_loss = 1.019531422743091, disc_loss = 0.0002604116075249126
Trained batch 216 in epoch 9, gen_loss = 1.0192532547607949, disc_loss = 0.00026052868369111603
Trained batch 217 in epoch 9, gen_loss = 1.0189722128417513, disc_loss = 0.0002603770765102652
Trained batch 218 in epoch 9, gen_loss = 1.01888030849091, disc_loss = 0.00026013221093756467
Trained batch 219 in epoch 9, gen_loss = 1.0186561904170297, disc_loss = 0.00025999182474730663
Trained batch 220 in epoch 9, gen_loss = 1.0184082882436691, disc_loss = 0.00026002715573392225
Trained batch 221 in epoch 9, gen_loss = 1.0183414806116808, disc_loss = 0.00026034362252192313
Trained batch 222 in epoch 9, gen_loss = 1.0184640830942333, disc_loss = 0.00026111852887557454
Trained batch 223 in epoch 9, gen_loss = 1.018462406737464, disc_loss = 0.00026220190151044723
Trained batch 224 in epoch 9, gen_loss = 1.018603844642639, disc_loss = 0.000263426464872383
Trained batch 225 in epoch 9, gen_loss = 1.0184815246446999, disc_loss = 0.0002649826234537774
Trained batch 226 in epoch 9, gen_loss = 1.018591120904763, disc_loss = 0.0002669302105535917
Trained batch 227 in epoch 9, gen_loss = 1.0181093764932532, disc_loss = 0.0002697903718510867
Trained batch 228 in epoch 9, gen_loss = 1.0180935198563155, disc_loss = 0.00027453106625069656
Trained batch 229 in epoch 9, gen_loss = 1.017689420606779, disc_loss = 0.00028058267435762506
Trained batch 230 in epoch 9, gen_loss = 1.017506631679865, disc_loss = 0.0002869754515069706
Trained batch 231 in epoch 9, gen_loss = 1.0173779898162545, disc_loss = 0.0002919857259194973
Trained batch 232 in epoch 9, gen_loss = 1.01757142548909, disc_loss = 0.00029516362123837886
Trained batch 233 in epoch 9, gen_loss = 1.0178533463906019, disc_loss = 0.0002973861557978273
Trained batch 234 in epoch 9, gen_loss = 1.0173936483707833, disc_loss = 0.0003002307301899914
Trained batch 235 in epoch 9, gen_loss = 1.0173149454896733, disc_loss = 0.0003043357794352124
Trained batch 236 in epoch 9, gen_loss = 1.017306746561316, disc_loss = 0.0003075020018813224
Trained batch 237 in epoch 9, gen_loss = 1.017015210971111, disc_loss = 0.00030916037820959505
Trained batch 238 in epoch 9, gen_loss = 1.0173600126509885, disc_loss = 0.0003098507064906588
Trained batch 239 in epoch 9, gen_loss = 1.0172834786276022, disc_loss = 0.0003108792507494703
Trained batch 240 in epoch 9, gen_loss = 1.0168389450465, disc_loss = 0.00031184373505938127
Trained batch 241 in epoch 9, gen_loss = 1.0172189515976866, disc_loss = 0.00031194264994148155
Trained batch 242 in epoch 9, gen_loss = 1.0174713927041357, disc_loss = 0.0003115041799751808
Trained batch 243 in epoch 9, gen_loss = 1.0172334408662358, disc_loss = 0.0003107319636135381
Trained batch 244 in epoch 9, gen_loss = 1.016996023606281, disc_loss = 0.0003099032333809692
Trained batch 245 in epoch 9, gen_loss = 1.0170836148223257, disc_loss = 0.0003092203664780799
Trained batch 246 in epoch 9, gen_loss = 1.016902390279268, disc_loss = 0.00030892697207230004
Trained batch 247 in epoch 9, gen_loss = 1.016883206944312, disc_loss = 0.00030860979982648017
Trained batch 248 in epoch 9, gen_loss = 1.016976056328739, disc_loss = 0.00030815977641534674
Trained batch 249 in epoch 9, gen_loss = 1.0166962914466857, disc_loss = 0.0003077085129334591
Trained batch 250 in epoch 9, gen_loss = 1.016694502051608, disc_loss = 0.000307328568746436
Trained batch 251 in epoch 9, gen_loss = 1.0165088980916948, disc_loss = 0.0003071727814607411
Trained batch 252 in epoch 9, gen_loss = 1.016467431788388, disc_loss = 0.00030755908460827476
Trained batch 253 in epoch 9, gen_loss = 1.0168185909902017, disc_loss = 0.0003082096057863334
Trained batch 254 in epoch 9, gen_loss = 1.0168202919118545, disc_loss = 0.0003088803108160694
Trained batch 255 in epoch 9, gen_loss = 1.0167538849636912, disc_loss = 0.0003096905438724207
Trained batch 256 in epoch 9, gen_loss = 1.0168741264231937, disc_loss = 0.0003103309925663709
Trained batch 257 in epoch 9, gen_loss = 1.0169233735217604, disc_loss = 0.00031103081247668224
Trained batch 258 in epoch 9, gen_loss = 1.0164094592613604, disc_loss = 0.00031219377532119516
Trained batch 259 in epoch 9, gen_loss = 1.0168665221104256, disc_loss = 0.0003143289849574033
Trained batch 260 in epoch 9, gen_loss = 1.0166145106385038, disc_loss = 0.00031788912989820045
Trained batch 261 in epoch 9, gen_loss = 1.0168153452509232, disc_loss = 0.00032254781965912813
Trained batch 262 in epoch 9, gen_loss = 1.0169366602661944, disc_loss = 0.00032644110183787495
Trained batch 263 in epoch 9, gen_loss = 1.0173566305276118, disc_loss = 0.0003292881414050829
Trained batch 264 in epoch 9, gen_loss = 1.017730065111844, disc_loss = 0.0003312935685861926
Trained batch 265 in epoch 9, gen_loss = 1.0176467299461365, disc_loss = 0.0003327949644815653
Trained batch 266 in epoch 9, gen_loss = 1.0174836000699676, disc_loss = 0.0003332134341901301
Trained batch 267 in epoch 9, gen_loss = 1.0174384788790745, disc_loss = 0.00033282053281349797
Trained batch 268 in epoch 9, gen_loss = 1.0172698134383305, disc_loss = 0.00033211417008904555
Trained batch 269 in epoch 9, gen_loss = 1.0171338337439078, disc_loss = 0.0003313370092116572
Trained batch 270 in epoch 9, gen_loss = 1.0170978606846939, disc_loss = 0.00033053775238817406
Trained batch 271 in epoch 9, gen_loss = 1.0173289959921556, disc_loss = 0.0003296799926133912
Trained batch 272 in epoch 9, gen_loss = 1.017351793282198, disc_loss = 0.000328911321694816
Trained batch 273 in epoch 9, gen_loss = 1.0175368820663786, disc_loss = 0.000328253074789192
Trained batch 274 in epoch 9, gen_loss = 1.0172961287064985, disc_loss = 0.000327903220101937
Trained batch 275 in epoch 9, gen_loss = 1.017290258753127, disc_loss = 0.00032771608723281963
Trained batch 276 in epoch 9, gen_loss = 1.017366910238989, disc_loss = 0.00032726361686094844
Trained batch 277 in epoch 9, gen_loss = 1.0177966956612017, disc_loss = 0.0003266171383689888
Trained batch 278 in epoch 9, gen_loss = 1.017820659504142, disc_loss = 0.00032605100352163546
Trained batch 279 in epoch 9, gen_loss = 1.0178969923939023, disc_loss = 0.0003253880276003786
Trained batch 280 in epoch 9, gen_loss = 1.0179157036479258, disc_loss = 0.00032469248276923075
Trained batch 281 in epoch 9, gen_loss = 1.0182640155156453, disc_loss = 0.0003238631609921403
Trained batch 282 in epoch 9, gen_loss = 1.0184210842152788, disc_loss = 0.00032300954407871646
Trained batch 283 in epoch 9, gen_loss = 1.0188004546602007, disc_loss = 0.00032221094097365774
Trained batch 284 in epoch 9, gen_loss = 1.0186640072287174, disc_loss = 0.000321468174495334
Trained batch 285 in epoch 9, gen_loss = 1.018757303903153, disc_loss = 0.0003208288046687278
Trained batch 286 in epoch 9, gen_loss = 1.018821187758695, disc_loss = 0.00032031885021222586
Trained batch 287 in epoch 9, gen_loss = 1.0185556927074988, disc_loss = 0.0003197702448889888
Trained batch 288 in epoch 9, gen_loss = 1.0186405555187212, disc_loss = 0.0003191878559975401
Trained batch 289 in epoch 9, gen_loss = 1.0181200892760836, disc_loss = 0.00031874014838931855
Trained batch 290 in epoch 9, gen_loss = 1.0178263144394786, disc_loss = 0.0003185015203720487
Trained batch 291 in epoch 9, gen_loss = 1.017601459197802, disc_loss = 0.0003183567851384359
Trained batch 292 in epoch 9, gen_loss = 1.0175968772722186, disc_loss = 0.00031804985834310253
Trained batch 293 in epoch 9, gen_loss = 1.0178507641464674, disc_loss = 0.0003176684367150103
Trained batch 294 in epoch 9, gen_loss = 1.0177626787605931, disc_loss = 0.00031716690940873193
Trained batch 295 in epoch 9, gen_loss = 1.0177773889657613, disc_loss = 0.0003164287855552912
Trained batch 296 in epoch 9, gen_loss = 1.0178008910381433, disc_loss = 0.0003156314533625601
Trained batch 297 in epoch 9, gen_loss = 1.0177101424876476, disc_loss = 0.00031481161926995695
Trained batch 298 in epoch 9, gen_loss = 1.017623503471298, disc_loss = 0.0003139262222357867
Trained batch 299 in epoch 9, gen_loss = 1.0172702316443125, disc_loss = 0.0003130609468644252
Trained batch 300 in epoch 9, gen_loss = 1.0174782157340319, disc_loss = 0.0003122214733944367
Trained batch 301 in epoch 9, gen_loss = 1.017615770267335, disc_loss = 0.00031140361208948985
Trained batch 302 in epoch 9, gen_loss = 1.01781162373697, disc_loss = 0.0003106218673895488
Trained batch 303 in epoch 9, gen_loss = 1.0180542723912942, disc_loss = 0.00030985386846575576
Trained batch 304 in epoch 9, gen_loss = 1.0179854326560849, disc_loss = 0.00030910554022306854
Trained batch 305 in epoch 9, gen_loss = 1.0179541387589148, disc_loss = 0.0003083016621340766
Trained batch 306 in epoch 9, gen_loss = 1.0179745075368727, disc_loss = 0.0003074076828123632
Trained batch 307 in epoch 9, gen_loss = 1.0177448511897744, disc_loss = 0.00030653170566650957
Trained batch 308 in epoch 9, gen_loss = 1.0175991457642861, disc_loss = 0.00030568426997761743
Trained batch 309 in epoch 9, gen_loss = 1.0173568333348921, disc_loss = 0.0003049131052619252
Trained batch 310 in epoch 9, gen_loss = 1.0173414895772168, disc_loss = 0.0003042421482664
Trained batch 311 in epoch 9, gen_loss = 1.0177649412399683, disc_loss = 0.0003036374728953188
Trained batch 312 in epoch 9, gen_loss = 1.0177208882170363, disc_loss = 0.0003030026180120319
Trained batch 313 in epoch 9, gen_loss = 1.017927387717423, disc_loss = 0.00030232333069964563
Trained batch 314 in epoch 9, gen_loss = 1.0179145264247107, disc_loss = 0.0003015535702283997
Trained batch 315 in epoch 9, gen_loss = 1.0178497358213496, disc_loss = 0.000300794429573285
Trained batch 316 in epoch 9, gen_loss = 1.017962230868896, disc_loss = 0.00030003700488493394
Trained batch 317 in epoch 9, gen_loss = 1.0179560503119942, disc_loss = 0.00029937089725850374
Trained batch 318 in epoch 9, gen_loss = 1.0181633334922193, disc_loss = 0.0002987533017320939
Trained batch 319 in epoch 9, gen_loss = 1.0181188754737378, disc_loss = 0.00029809239712221827
Trained batch 320 in epoch 9, gen_loss = 1.017883071275515, disc_loss = 0.0002973754546978414
Trained batch 321 in epoch 9, gen_loss = 1.017741481895032, disc_loss = 0.00029664403123404003
Trained batch 322 in epoch 9, gen_loss = 1.0176743715540175, disc_loss = 0.00029591395133665124
Trained batch 323 in epoch 9, gen_loss = 1.0178548730449912, disc_loss = 0.0002951910826169173
Trained batch 324 in epoch 9, gen_loss = 1.017780594092149, disc_loss = 0.00029449707756821927
Trained batch 325 in epoch 9, gen_loss = 1.017645428882786, disc_loss = 0.00029383619818365076
Trained batch 326 in epoch 9, gen_loss = 1.0175117824784843, disc_loss = 0.0002932111602362006
Trained batch 327 in epoch 9, gen_loss = 1.0172925862233813, disc_loss = 0.0002925863466261057
Trained batch 328 in epoch 9, gen_loss = 1.017497544049492, disc_loss = 0.00029197140780541517
Trained batch 329 in epoch 9, gen_loss = 1.017426245320927, disc_loss = 0.0002913936692383493
Trained batch 330 in epoch 9, gen_loss = 1.0174361703258987, disc_loss = 0.0002908684096381411
Trained batch 331 in epoch 9, gen_loss = 1.0172362016985215, disc_loss = 0.00029042833255034454
Trained batch 332 in epoch 9, gen_loss = 1.0171348033724605, disc_loss = 0.0002899903972044464
Trained batch 333 in epoch 9, gen_loss = 1.0168622211067977, disc_loss = 0.0002895507124645781
Trained batch 334 in epoch 9, gen_loss = 1.016775404873179, disc_loss = 0.0002890846891843005
Trained batch 335 in epoch 9, gen_loss = 1.0166225326912743, disc_loss = 0.0002886615984607488
Trained batch 336 in epoch 9, gen_loss = 1.0165415981049353, disc_loss = 0.0002884925590090188
Trained batch 337 in epoch 9, gen_loss = 1.0165608020929189, disc_loss = 0.0002886655115482491
Trained batch 338 in epoch 9, gen_loss = 1.0165671032790238, disc_loss = 0.0002889174732426319
Trained batch 339 in epoch 9, gen_loss = 1.016705044928719, disc_loss = 0.0002891144166556735
Trained batch 340 in epoch 9, gen_loss = 1.016600309578904, disc_loss = 0.00028907294218534946
Trained batch 341 in epoch 9, gen_loss = 1.0164584304854187, disc_loss = 0.0002889838338589938
Trained batch 342 in epoch 9, gen_loss = 1.0162541654297632, disc_loss = 0.0002891790741544119
Trained batch 343 in epoch 9, gen_loss = 1.0161969945874325, disc_loss = 0.0002893939094657219
Trained batch 344 in epoch 9, gen_loss = 1.0161607908165973, disc_loss = 0.00028922453909046084
Trained batch 345 in epoch 9, gen_loss = 1.0163266107526128, disc_loss = 0.0002888344401797156
Trained batch 346 in epoch 9, gen_loss = 1.0166730210829193, disc_loss = 0.0002883862881764893
Trained batch 347 in epoch 9, gen_loss = 1.0168737436848125, disc_loss = 0.0002879837452017183
Trained batch 348 in epoch 9, gen_loss = 1.0168573712892723, disc_loss = 0.00028753762291364084
Trained batch 349 in epoch 9, gen_loss = 1.0168099607740129, disc_loss = 0.00028698161901307426
Trained batch 350 in epoch 9, gen_loss = 1.0170017558964568, disc_loss = 0.000286433876106022
Trained batch 351 in epoch 9, gen_loss = 1.0168986862356013, disc_loss = 0.00028592178442853435
Trained batch 352 in epoch 9, gen_loss = 1.016934316489244, disc_loss = 0.0002854167754462097
Trained batch 353 in epoch 9, gen_loss = 1.0170216075444625, disc_loss = 0.0002848597650676321
Trained batch 354 in epoch 9, gen_loss = 1.0170690442474795, disc_loss = 0.00028427261885822895
Trained batch 355 in epoch 9, gen_loss = 1.0171152376726773, disc_loss = 0.0002837317301118367
Trained batch 356 in epoch 9, gen_loss = 1.0168751638476587, disc_loss = 0.0002833350716820391
Trained batch 357 in epoch 9, gen_loss = 1.0169582363613492, disc_loss = 0.0002831193966950048
Trained batch 358 in epoch 9, gen_loss = 1.016916785731621, disc_loss = 0.00028293424230902315
Trained batch 359 in epoch 9, gen_loss = 1.0169680270883772, disc_loss = 0.0002827813488895319
Trained batch 360 in epoch 9, gen_loss = 1.0168590793319026, disc_loss = 0.0002826904606774199
Trained batch 361 in epoch 9, gen_loss = 1.0166752950921243, disc_loss = 0.0002825828654830182
Trained batch 362 in epoch 9, gen_loss = 1.0167412899085642, disc_loss = 0.00028259411484908093
Trained batch 363 in epoch 9, gen_loss = 1.016704139801172, disc_loss = 0.0002824755708018899
Trained batch 364 in epoch 9, gen_loss = 1.016513244093281, disc_loss = 0.000282295303294046
Trained batch 365 in epoch 9, gen_loss = 1.016611535366767, disc_loss = 0.00028213091533617725
Trained batch 366 in epoch 9, gen_loss = 1.016602779279288, disc_loss = 0.00028192353397509467
Trained batch 367 in epoch 9, gen_loss = 1.0167211060938628, disc_loss = 0.0002816709964502914
Trained batch 368 in epoch 9, gen_loss = 1.0166346080257964, disc_loss = 0.00028139888863019306
Trained batch 369 in epoch 9, gen_loss = 1.0166469718958882, disc_loss = 0.0002811164112810385
Trained batch 370 in epoch 9, gen_loss = 1.0165317823302071, disc_loss = 0.00028078226982368
Trained batch 371 in epoch 9, gen_loss = 1.0167482940740482, disc_loss = 0.00028043843115982224
Trained batch 372 in epoch 9, gen_loss = 1.0165167318272528, disc_loss = 0.0002800131648091971
Trained batch 373 in epoch 9, gen_loss = 1.0161226882654077, disc_loss = 0.0002796163316621547
Trained batch 374 in epoch 9, gen_loss = 1.0157919843991599, disc_loss = 0.00027938741707475855
Trained batch 375 in epoch 9, gen_loss = 1.015603577044416, disc_loss = 0.00027946494537900435
Trained batch 376 in epoch 9, gen_loss = 1.015472974479989, disc_loss = 0.00027981411565860376
Trained batch 377 in epoch 9, gen_loss = 1.0153479404235013, disc_loss = 0.00028020374050900397
Trained batch 378 in epoch 9, gen_loss = 1.0151908690193399, disc_loss = 0.00028059837338253535
Trained batch 379 in epoch 9, gen_loss = 1.01535343966986, disc_loss = 0.00028103186377848033
Trained batch 380 in epoch 9, gen_loss = 1.0154259198606796, disc_loss = 0.000281558359075268
Trained batch 381 in epoch 9, gen_loss = 1.0154630036254204, disc_loss = 0.00028189194789970007
Trained batch 382 in epoch 9, gen_loss = 1.0154062372586123, disc_loss = 0.00028197117076196414
Trained batch 383 in epoch 9, gen_loss = 1.0154083377371232, disc_loss = 0.00028190737973924723
Trained batch 384 in epoch 9, gen_loss = 1.0154872646579494, disc_loss = 0.00028193781223048324
Trained batch 385 in epoch 9, gen_loss = 1.0156797047106096, disc_loss = 0.0002819119452990753
Trained batch 386 in epoch 9, gen_loss = 1.015995078616672, disc_loss = 0.0002818782330099289
Trained batch 387 in epoch 9, gen_loss = 1.0158909467077746, disc_loss = 0.0002821389705261645
Trained batch 388 in epoch 9, gen_loss = 1.015886198585628, disc_loss = 0.00028248247262171246
Trained batch 389 in epoch 9, gen_loss = 1.0159207796439147, disc_loss = 0.0002830184326553419
Trained batch 390 in epoch 9, gen_loss = 1.015835211405059, disc_loss = 0.00028364365369833584
Trained batch 391 in epoch 9, gen_loss = 1.0158636697701044, disc_loss = 0.00028401998354508706
Trained batch 392 in epoch 9, gen_loss = 1.016106257911857, disc_loss = 0.0002841318891561145
Trained batch 393 in epoch 9, gen_loss = 1.0158187362748354, disc_loss = 0.00028437561871348595
Trained batch 394 in epoch 9, gen_loss = 1.0154855876029292, disc_loss = 0.0002850102481566358
Trained batch 395 in epoch 9, gen_loss = 1.0154546550428025, disc_loss = 0.00028574002526786927
Trained batch 396 in epoch 9, gen_loss = 1.015598961628354, disc_loss = 0.00028653169853623924
Trained batch 397 in epoch 9, gen_loss = 1.015410255247624, disc_loss = 0.0002873790625419325
Trained batch 398 in epoch 9, gen_loss = 1.0152917478915144, disc_loss = 0.00028827340462239795
Trained batch 399 in epoch 9, gen_loss = 1.0152063816785812, disc_loss = 0.0002890519054017204
Trained batch 400 in epoch 9, gen_loss = 1.0153096979692986, disc_loss = 0.0002896161089316556
Trained batch 401 in epoch 9, gen_loss = 1.0155274337203941, disc_loss = 0.0002899850208527439
Trained batch 402 in epoch 9, gen_loss = 1.0155324305849098, disc_loss = 0.0002902411525107391
Trained batch 403 in epoch 9, gen_loss = 1.015471995171934, disc_loss = 0.00029041315419907744
Trained batch 404 in epoch 9, gen_loss = 1.015421286335698, disc_loss = 0.0002906085562390666
Trained batch 405 in epoch 9, gen_loss = 1.0154342472259634, disc_loss = 0.00029087931046699946
Trained batch 406 in epoch 9, gen_loss = 1.0157090762323477, disc_loss = 0.0002910642685986202
Trained batch 407 in epoch 9, gen_loss = 1.015566580435809, disc_loss = 0.00029109785070128663
Trained batch 408 in epoch 9, gen_loss = 1.0155978864445954, disc_loss = 0.00029095089984052956
Trained batch 409 in epoch 9, gen_loss = 1.0156443933161294, disc_loss = 0.00029070760368684695
Trained batch 410 in epoch 9, gen_loss = 1.0158989127825067, disc_loss = 0.0002905165528873754
Trained batch 411 in epoch 9, gen_loss = 1.0158660463916445, disc_loss = 0.00029033806370455407
Trained batch 412 in epoch 9, gen_loss = 1.0156879865228408, disc_loss = 0.00029017419188064086
Trained batch 413 in epoch 9, gen_loss = 1.0159011271552763, disc_loss = 0.00028992483593342973
Trained batch 414 in epoch 9, gen_loss = 1.0159620214657612, disc_loss = 0.00028956948948886626
Trained batch 415 in epoch 9, gen_loss = 1.01601698435843, disc_loss = 0.0002891567666420787
Trained batch 416 in epoch 9, gen_loss = 1.0160909186450127, disc_loss = 0.0002887724823971967
Trained batch 417 in epoch 9, gen_loss = 1.0161277964069513, disc_loss = 0.00028846342342949706
Trained batch 418 in epoch 9, gen_loss = 1.0161840626903251, disc_loss = 0.0002881353911864549
Trained batch 419 in epoch 9, gen_loss = 1.016271737217903, disc_loss = 0.0002877108332800812
Trained batch 420 in epoch 9, gen_loss = 1.0165429685857688, disc_loss = 0.0002871936799227227
Trained batch 421 in epoch 9, gen_loss = 1.0165824916972934, disc_loss = 0.00028670145297945494
Trained batch 422 in epoch 9, gen_loss = 1.0165337133914867, disc_loss = 0.0002861190764622897
Trained batch 423 in epoch 9, gen_loss = 1.0166812540506416, disc_loss = 0.0002856243729080954
Trained batch 424 in epoch 9, gen_loss = 1.0166725625711328, disc_loss = 0.00028510286210803315
Trained batch 425 in epoch 9, gen_loss = 1.0166748503284275, disc_loss = 0.00028460398643289064
Trained batch 426 in epoch 9, gen_loss = 1.0165930380586718, disc_loss = 0.00028413743018491667
Trained batch 427 in epoch 9, gen_loss = 1.0165807752408713, disc_loss = 0.00028371402228666716
Trained batch 428 in epoch 9, gen_loss = 1.0165049346176895, disc_loss = 0.00028325005944686375
Trained batch 429 in epoch 9, gen_loss = 1.0162914698900178, disc_loss = 0.00028283746822041375
Trained batch 430 in epoch 9, gen_loss = 1.016299232391083, disc_loss = 0.0002825234098387763
Trained batch 431 in epoch 9, gen_loss = 1.0162330774797335, disc_loss = 0.00028212856383376037
Trained batch 432 in epoch 9, gen_loss = 1.0162381118219388, disc_loss = 0.0002817021857851129
Trained batch 433 in epoch 9, gen_loss = 1.0163719220095515, disc_loss = 0.0002812970453498548
Trained batch 434 in epoch 9, gen_loss = 1.0163732027185375, disc_loss = 0.00028086114782189696
Trained batch 435 in epoch 9, gen_loss = 1.0165192077466108, disc_loss = 0.00028033006706084404
Trained batch 436 in epoch 9, gen_loss = 1.0164593894639877, disc_loss = 0.00027977007018517835
Trained batch 437 in epoch 9, gen_loss = 1.0162784794694213, disc_loss = 0.00027928658284060337
Trained batch 438 in epoch 9, gen_loss = 1.0162039916444747, disc_loss = 0.00027891086843853885
Trained batch 439 in epoch 9, gen_loss = 1.0161961056969382, disc_loss = 0.0002786403932821651
Trained batch 440 in epoch 9, gen_loss = 1.0161703235708397, disc_loss = 0.00027840427773259685
Trained batch 441 in epoch 9, gen_loss = 1.016057006643908, disc_loss = 0.00027822217340984096
Trained batch 442 in epoch 9, gen_loss = 1.0158292040329755, disc_loss = 0.0002780198593749812
Trained batch 443 in epoch 9, gen_loss = 1.0157592324791729, disc_loss = 0.00027782573612909745
Trained batch 444 in epoch 9, gen_loss = 1.015947455368685, disc_loss = 0.0002775850022189434
Trained batch 445 in epoch 9, gen_loss = 1.015946791711944, disc_loss = 0.0002773597197091121
Trained batch 446 in epoch 9, gen_loss = 1.0158974600318293, disc_loss = 0.00027708082893950305
Trained batch 447 in epoch 9, gen_loss = 1.015847853384912, disc_loss = 0.000276750738505273
Trained batch 448 in epoch 9, gen_loss = 1.0157153639602237, disc_loss = 0.00027648591089209144
Trained batch 449 in epoch 9, gen_loss = 1.0155064972241719, disc_loss = 0.0002763634682600645
Trained batch 450 in epoch 9, gen_loss = 1.0152620074489958, disc_loss = 0.0002763499848965603
Trained batch 451 in epoch 9, gen_loss = 1.015050068365789, disc_loss = 0.0002762938764988624
Trained batch 452 in epoch 9, gen_loss = 1.0153119240375543, disc_loss = 0.0002762822348825689
Trained batch 453 in epoch 9, gen_loss = 1.01535145406681, disc_loss = 0.0002764298668635613
Trained batch 454 in epoch 9, gen_loss = 1.0154443195887974, disc_loss = 0.0002767257027649116
Trained batch 455 in epoch 9, gen_loss = 1.015605659338466, disc_loss = 0.00027699406224488294
Trained batch 456 in epoch 9, gen_loss = 1.0157740152638641, disc_loss = 0.0002771747476441421
Trained batch 457 in epoch 9, gen_loss = 1.0156260931856247, disc_loss = 0.0002773764932483148
Trained batch 458 in epoch 9, gen_loss = 1.0157203173066016, disc_loss = 0.00027763522581046666
Trained batch 459 in epoch 9, gen_loss = 1.0155266724202945, disc_loss = 0.00027787712421306187
Trained batch 460 in epoch 9, gen_loss = 1.0155413113292024, disc_loss = 0.00027802952851808715
Trained batch 461 in epoch 9, gen_loss = 1.015394008262849, disc_loss = 0.00027813161733079985
Trained batch 462 in epoch 9, gen_loss = 1.0154312668814773, disc_loss = 0.0002782010803416273
Trained batch 463 in epoch 9, gen_loss = 1.0152230383507137, disc_loss = 0.0002782619776396665
Trained batch 464 in epoch 9, gen_loss = 1.0150151914165866, disc_loss = 0.0002784210832893438
Trained batch 465 in epoch 9, gen_loss = 1.014913773459938, disc_loss = 0.00027873345641426785
Trained batch 466 in epoch 9, gen_loss = 1.0149809406707322, disc_loss = 0.0002789993353836922
Trained batch 467 in epoch 9, gen_loss = 1.0149914450370348, disc_loss = 0.00027916423450500215
Trained batch 468 in epoch 9, gen_loss = 1.0149720931358175, disc_loss = 0.0002793706151618829
Trained batch 469 in epoch 9, gen_loss = 1.0150358107495816, disc_loss = 0.0002799246360967679
Trained batch 470 in epoch 9, gen_loss = 1.0149372347853998, disc_loss = 0.00028070695254288813
Trained batch 471 in epoch 9, gen_loss = 1.0147978283338628, disc_loss = 0.00028149375773833617
Trained batch 472 in epoch 9, gen_loss = 1.014693963729302, disc_loss = 0.0002820216448691843
Trained batch 473 in epoch 9, gen_loss = 1.01467398689266, disc_loss = 0.0002823383553352213
Trained batch 474 in epoch 9, gen_loss = 1.0146669622471458, disc_loss = 0.0002823083101324492
Trained batch 475 in epoch 9, gen_loss = 1.0147894043631915, disc_loss = 0.00028202303079876
Trained batch 476 in epoch 9, gen_loss = 1.0149790704625208, disc_loss = 0.0002816948504205471
Trained batch 477 in epoch 9, gen_loss = 1.015057157397769, disc_loss = 0.0002813916640456281
Trained batch 478 in epoch 9, gen_loss = 1.0151252339677672, disc_loss = 0.0002810081780339117
Trained batch 479 in epoch 9, gen_loss = 1.014984540020426, disc_loss = 0.0002805292743839042
Trained batch 480 in epoch 9, gen_loss = 1.0149120180373876, disc_loss = 0.00028005469448355233
Trained batch 481 in epoch 9, gen_loss = 1.0150933712102566, disc_loss = 0.00027967104365246337
Trained batch 482 in epoch 9, gen_loss = 1.0151533694247528, disc_loss = 0.000279351360677726
Trained batch 483 in epoch 9, gen_loss = 1.0152095407247543, disc_loss = 0.00027906659619294854
Trained batch 484 in epoch 9, gen_loss = 1.0152068107398515, disc_loss = 0.0002788125770466556
Trained batch 485 in epoch 9, gen_loss = 1.015016647645966, disc_loss = 0.0002786434324587113
Trained batch 486 in epoch 9, gen_loss = 1.01501227685803, disc_loss = 0.00027871693681578443
Trained batch 487 in epoch 9, gen_loss = 1.0150819959454849, disc_loss = 0.0002791162383860477
Trained batch 488 in epoch 9, gen_loss = 1.0152163358066224, disc_loss = 0.0002795028678988581
Trained batch 489 in epoch 9, gen_loss = 1.0151666671645885, disc_loss = 0.00027989519772485694
Trained batch 490 in epoch 9, gen_loss = 1.0150823645339235, disc_loss = 0.00028015220945709537
Trained batch 491 in epoch 9, gen_loss = 1.0150553595002105, disc_loss = 0.00028020848924832653
Trained batch 492 in epoch 9, gen_loss = 1.0150293030796864, disc_loss = 0.00028016068934275
Trained batch 493 in epoch 9, gen_loss = 1.014997005824618, disc_loss = 0.000280051200409318
Trained batch 494 in epoch 9, gen_loss = 1.0150200746276161, disc_loss = 0.0002799231068976694
Trained batch 495 in epoch 9, gen_loss = 1.0149298095174375, disc_loss = 0.00027978524095458615
Trained batch 496 in epoch 9, gen_loss = 1.014828154858449, disc_loss = 0.00027956444338752027
Trained batch 497 in epoch 9, gen_loss = 1.014738873664634, disc_loss = 0.00027920201694406756
Trained batch 498 in epoch 9, gen_loss = 1.014628669661367, disc_loss = 0.00027876774531874045
Trained batch 499 in epoch 9, gen_loss = 1.0145733203887939, disc_loss = 0.00027833093208028
Trained batch 500 in epoch 9, gen_loss = 1.0142890776464801, disc_loss = 0.0002779193857055949
Trained batch 501 in epoch 9, gen_loss = 1.0143210372601847, disc_loss = 0.0002775615814671364
Trained batch 502 in epoch 9, gen_loss = 1.014506051601994, disc_loss = 0.0002772600665461933
Trained batch 503 in epoch 9, gen_loss = 1.014574413734769, disc_loss = 0.00027696303369873296
Trained batch 504 in epoch 9, gen_loss = 1.0145482374890016, disc_loss = 0.00027671444143622764
Trained batch 505 in epoch 9, gen_loss = 1.0145187101109696, disc_loss = 0.00027650918009708886
Trained batch 506 in epoch 9, gen_loss = 1.0144732603895124, disc_loss = 0.00027647142358391987
Trained batch 507 in epoch 9, gen_loss = 1.014402767218004, disc_loss = 0.0002767181403766062
Trained batch 508 in epoch 9, gen_loss = 1.014302384759682, disc_loss = 0.00027718626817609213
Trained batch 509 in epoch 9, gen_loss = 1.01436328923001, disc_loss = 0.0002777531314909449
Trained batch 510 in epoch 9, gen_loss = 1.0143768758223248, disc_loss = 0.00027816371102086057
Trained batch 511 in epoch 9, gen_loss = 1.0143945639720187, disc_loss = 0.0002784420749861738
Trained batch 512 in epoch 9, gen_loss = 1.0143734805765208, disc_loss = 0.00027860838489107275
Trained batch 513 in epoch 9, gen_loss = 1.0143842554509872, disc_loss = 0.00027861320597954466
Trained batch 514 in epoch 9, gen_loss = 1.0143394827842713, disc_loss = 0.00027844629583041665
Trained batch 515 in epoch 9, gen_loss = 1.014200285077095, disc_loss = 0.00027816502967984287
Trained batch 516 in epoch 9, gen_loss = 1.014245556793545, disc_loss = 0.00027783623854825597
Trained batch 517 in epoch 9, gen_loss = 1.014275635646577, disc_loss = 0.0002774845562906959
Trained batch 518 in epoch 9, gen_loss = 1.014394223690033, disc_loss = 0.0002771181768606738
Trained batch 519 in epoch 9, gen_loss = 1.0142757717233437, disc_loss = 0.0002767702494216232
Trained batch 520 in epoch 9, gen_loss = 1.0142228787553973, disc_loss = 0.00027640211662825466
Trained batch 521 in epoch 9, gen_loss = 1.0140018973542355, disc_loss = 0.0002761638712831969
Trained batch 522 in epoch 9, gen_loss = 1.0140357495038048, disc_loss = 0.00027600025027936027
Trained batch 523 in epoch 9, gen_loss = 1.0141534908809735, disc_loss = 0.0002758463983566639
Trained batch 524 in epoch 9, gen_loss = 1.014121572290148, disc_loss = 0.00027579550234977865
Trained batch 525 in epoch 9, gen_loss = 1.0141283993258676, disc_loss = 0.00027601049647833835
Trained batch 526 in epoch 9, gen_loss = 1.0142001588837697, disc_loss = 0.00027643446250004867
Trained batch 527 in epoch 9, gen_loss = 1.0142288498128906, disc_loss = 0.00027702519287920563
Trained batch 528 in epoch 9, gen_loss = 1.0142636336315782, disc_loss = 0.0002775311059662227
Trained batch 529 in epoch 9, gen_loss = 1.0142776985213442, disc_loss = 0.00027785225134927184
Trained batch 530 in epoch 9, gen_loss = 1.0145113473782656, disc_loss = 0.00027798630180220576
Trained batch 531 in epoch 9, gen_loss = 1.0145535902645355, disc_loss = 0.0002780015741685437
Trained batch 532 in epoch 9, gen_loss = 1.0144387847039757, disc_loss = 0.0002779712249696566
Trained batch 533 in epoch 9, gen_loss = 1.0144352867138966, disc_loss = 0.0002778931960979327
Trained batch 534 in epoch 9, gen_loss = 1.0142809501318173, disc_loss = 0.0002778765277351714
Trained batch 535 in epoch 9, gen_loss = 1.0143763181656154, disc_loss = 0.00027791772910533646
Trained batch 536 in epoch 9, gen_loss = 1.0143795993519007, disc_loss = 0.00027793120301577474
Trained batch 537 in epoch 9, gen_loss = 1.0146531858187182, disc_loss = 0.0002779645369949467
Trained batch 538 in epoch 9, gen_loss = 1.0147670893368341, disc_loss = 0.00027796392247935234
Trained batch 539 in epoch 9, gen_loss = 1.0148122110852489, disc_loss = 0.0002780666368144685
Trained batch 540 in epoch 9, gen_loss = 1.0150870929804394, disc_loss = 0.0002785179204388837
Trained batch 541 in epoch 9, gen_loss = 1.0151185049122111, disc_loss = 0.0002797384802700962
Trained batch 542 in epoch 9, gen_loss = 1.0149349258529987, disc_loss = 0.0002852141957965458
Trained batch 543 in epoch 9, gen_loss = 1.0151834081420128, disc_loss = 0.0003184084696252231
Trained batch 544 in epoch 9, gen_loss = 1.0150357877442595, disc_loss = 0.0004021724619007661
Trained batch 545 in epoch 9, gen_loss = 1.0150456700351211, disc_loss = 0.0005012278057493682
Trained batch 546 in epoch 9, gen_loss = 1.0151043342497927, disc_loss = 0.0005767797759720899
Trained batch 547 in epoch 9, gen_loss = 1.0152804498037282, disc_loss = 0.0006387563420251015
Trained batch 548 in epoch 9, gen_loss = 1.0153565605481465, disc_loss = 0.0006862579980232788
Trained batch 549 in epoch 9, gen_loss = 1.015199786533009, disc_loss = 0.0007275907849014567
Trained batch 550 in epoch 9, gen_loss = 1.0152515281133774, disc_loss = 0.000776864380493106
Trained batch 551 in epoch 9, gen_loss = 1.0152446353349134, disc_loss = 0.0008080301392602859
Trained batch 552 in epoch 9, gen_loss = 1.0151538594506317, disc_loss = 0.0008161323328233437
Trained batch 553 in epoch 9, gen_loss = 1.0150657434971324, disc_loss = 0.0008184465308665695
Trained batch 554 in epoch 9, gen_loss = 1.0151907165845235, disc_loss = 0.0008220755743955656
Trained batch 555 in epoch 9, gen_loss = 1.0154067274692247, disc_loss = 0.000822142514794028
Trained batch 556 in epoch 9, gen_loss = 1.0153989424825356, disc_loss = 0.0008216700207576225
Trained batch 557 in epoch 9, gen_loss = 1.0153721475900288, disc_loss = 0.000821221204384649
Trained batch 558 in epoch 9, gen_loss = 1.0154532694219476, disc_loss = 0.0008206180926449414
Trained batch 559 in epoch 9, gen_loss = 1.015612617880106, disc_loss = 0.0008196821259844001
Trained batch 560 in epoch 9, gen_loss = 1.0156955467188422, disc_loss = 0.0008188506936496323
Trained batch 561 in epoch 9, gen_loss = 1.0159157324728167, disc_loss = 0.0008179338886769193
Trained batch 562 in epoch 9, gen_loss = 1.015875441460584, disc_loss = 0.0008169882854049344
Trained batch 563 in epoch 9, gen_loss = 1.0159471792743562, disc_loss = 0.0008160619842867343
Trained batch 564 in epoch 9, gen_loss = 1.015948965380677, disc_loss = 0.0008149554124936478
Trained batch 565 in epoch 9, gen_loss = 1.0159294077659242, disc_loss = 0.0008138736579910681
Trained batch 566 in epoch 9, gen_loss = 1.0159390253364724, disc_loss = 0.000812904293991985
Trained batch 567 in epoch 9, gen_loss = 1.0160724101981646, disc_loss = 0.0008117506265630831
Trained batch 568 in epoch 9, gen_loss = 1.016090446595358, disc_loss = 0.0008105697918553167
Trained batch 569 in epoch 9, gen_loss = 1.016074276911585, disc_loss = 0.0008094282203768543
Trained batch 570 in epoch 9, gen_loss = 1.0162725896426132, disc_loss = 0.0008084743818414566
Trained batch 571 in epoch 9, gen_loss = 1.016480531830054, disc_loss = 0.000807494727052688
Trained batch 572 in epoch 9, gen_loss = 1.016753769357791, disc_loss = 0.0008063925988433791
Trained batch 573 in epoch 9, gen_loss = 1.016736923921399, disc_loss = 0.0008052103283021271
Trained batch 574 in epoch 9, gen_loss = 1.0168669081770856, disc_loss = 0.000804152451227824
Trained batch 575 in epoch 9, gen_loss = 1.016767672677007, disc_loss = 0.0008032058988192148
Trained batch 576 in epoch 9, gen_loss = 1.016823736489129, disc_loss = 0.000802166858073437
Trained batch 577 in epoch 9, gen_loss = 1.0167583385965815, disc_loss = 0.0008011144581325368
Trained batch 578 in epoch 9, gen_loss = 1.0166944449635573, disc_loss = 0.0007999579906787334
Trained batch 579 in epoch 9, gen_loss = 1.016614582106985, disc_loss = 0.0007988536977791228
Trained batch 580 in epoch 9, gen_loss = 1.01644959640585, disc_loss = 0.0007977799096977476
Trained batch 581 in epoch 9, gen_loss = 1.0165204275719488, disc_loss = 0.0007966782870107167
Trained batch 582 in epoch 9, gen_loss = 1.0167681775207584, disc_loss = 0.0007955664125585443
Trained batch 583 in epoch 9, gen_loss = 1.0168966356001488, disc_loss = 0.0007943841816111123
Trained batch 584 in epoch 9, gen_loss = 1.0168480541970994, disc_loss = 0.0007932095836179378
Trained batch 585 in epoch 9, gen_loss = 1.0168664273345023, disc_loss = 0.0007920477964509868
Trained batch 586 in epoch 9, gen_loss = 1.0168335243831095, disc_loss = 0.0007910047760989883
Trained batch 587 in epoch 9, gen_loss = 1.0167358855203705, disc_loss = 0.0007899515369274854
Trained batch 588 in epoch 9, gen_loss = 1.0168356528104059, disc_loss = 0.0007888088374875379
Trained batch 589 in epoch 9, gen_loss = 1.0168180781905933, disc_loss = 0.0007876240096959656
Trained batch 590 in epoch 9, gen_loss = 1.016931329382656, disc_loss = 0.0007864386497128262
Trained batch 591 in epoch 9, gen_loss = 1.0168515942185312, disc_loss = 0.0007852702042942543
Trained batch 592 in epoch 9, gen_loss = 1.016882369027773, disc_loss = 0.0007841445497619177
Trained batch 593 in epoch 9, gen_loss = 1.016733283647383, disc_loss = 0.0007829832428236694
Trained batch 594 in epoch 9, gen_loss = 1.0167117971332134, disc_loss = 0.0007818345951910342
Trained batch 595 in epoch 9, gen_loss = 1.0166978113003224, disc_loss = 0.0007806666307681632
Trained batch 596 in epoch 9, gen_loss = 1.0169856912726334, disc_loss = 0.0007798198137643522
Trained batch 597 in epoch 9, gen_loss = 1.017315208413529, disc_loss = 0.0007788338431134395
Trained batch 598 in epoch 9, gen_loss = 1.0175130547386577, disc_loss = 0.0007778126491210967
Trained batch 599 in epoch 9, gen_loss = 1.017656956811746, disc_loss = 0.0007768578699445546
Trained batch 600 in epoch 9, gen_loss = 1.0177978591593648, disc_loss = 0.0007759268751555624
Trained batch 601 in epoch 9, gen_loss = 1.0178517244780974, disc_loss = 0.0007749246781342083
Trained batch 602 in epoch 9, gen_loss = 1.0178782911245305, disc_loss = 0.0007738478097555562
Trained batch 603 in epoch 9, gen_loss = 1.0177743697403283, disc_loss = 0.0007727379665722752
Trained batch 604 in epoch 9, gen_loss = 1.0177641019348271, disc_loss = 0.0007716089861096107
Trained batch 605 in epoch 9, gen_loss = 1.0177860917037864, disc_loss = 0.0007704401518867149
Trained batch 606 in epoch 9, gen_loss = 1.0179359775398669, disc_loss = 0.0007692886016556389
Trained batch 607 in epoch 9, gen_loss = 1.01801737319482, disc_loss = 0.0007682042374701842
Trained batch 608 in epoch 9, gen_loss = 1.0180223915964512, disc_loss = 0.0007672288141760834
Trained batch 609 in epoch 9, gen_loss = 1.0181227551131953, disc_loss = 0.0007661486368127297
Trained batch 610 in epoch 9, gen_loss = 1.0182336414699273, disc_loss = 0.0007650472146045278
Trained batch 611 in epoch 9, gen_loss = 1.018227623179068, disc_loss = 0.0007639482028620109
Trained batch 612 in epoch 9, gen_loss = 1.0182200300751854, disc_loss = 0.0007628383943823403
Trained batch 613 in epoch 9, gen_loss = 1.018135787803886, disc_loss = 0.0007617209842669359
Trained batch 614 in epoch 9, gen_loss = 1.0181541811159955, disc_loss = 0.0007605898712323486
Trained batch 615 in epoch 9, gen_loss = 1.0183533344949995, disc_loss = 0.0007594992797418275
Trained batch 616 in epoch 9, gen_loss = 1.0183978942456855, disc_loss = 0.0007584393690601543
Trained batch 617 in epoch 9, gen_loss = 1.018579471458509, disc_loss = 0.0007573726567477221
Trained batch 618 in epoch 9, gen_loss = 1.0185391647750226, disc_loss = 0.0007562788196846727
Trained batch 619 in epoch 9, gen_loss = 1.0185279672184298, disc_loss = 0.0007552218899593665
Trained batch 620 in epoch 9, gen_loss = 1.018630251120446, disc_loss = 0.000754184524401019
Trained batch 621 in epoch 9, gen_loss = 1.0187553990500533, disc_loss = 0.0007531457165873032
Trained batch 622 in epoch 9, gen_loss = 1.0186554169578308, disc_loss = 0.000752035168570991
Trained batch 623 in epoch 9, gen_loss = 1.0187829739581316, disc_loss = 0.0007509436889636279
Trained batch 624 in epoch 9, gen_loss = 1.0188522009849548, disc_loss = 0.0007498209460056387
Trained batch 625 in epoch 9, gen_loss = 1.0189373147563812, disc_loss = 0.0007487038795060974
Trained batch 626 in epoch 9, gen_loss = 1.0189100801469417, disc_loss = 0.0007476043793023007
Trained batch 627 in epoch 9, gen_loss = 1.018983542254776, disc_loss = 0.0007465127293042917
Trained batch 628 in epoch 9, gen_loss = 1.0190836789119035, disc_loss = 0.0007454875955493812
Trained batch 629 in epoch 9, gen_loss = 1.0191890622888293, disc_loss = 0.0007444267900219919
Trained batch 630 in epoch 9, gen_loss = 1.019409956248173, disc_loss = 0.0007433705971980867
Trained batch 631 in epoch 9, gen_loss = 1.019282811333107, disc_loss = 0.0007422988360591676
Trained batch 632 in epoch 9, gen_loss = 1.0193717844113355, disc_loss = 0.0007412849310760704
Trained batch 633 in epoch 9, gen_loss = 1.0192129726665629, disc_loss = 0.0007402703794747134
Trained batch 634 in epoch 9, gen_loss = 1.019346628038902, disc_loss = 0.0007392629574847731
Trained batch 635 in epoch 9, gen_loss = 1.0192046078308574, disc_loss = 0.0007382261773953749
Trained batch 636 in epoch 9, gen_loss = 1.019122949106914, disc_loss = 0.0007371677629934921
Trained batch 637 in epoch 9, gen_loss = 1.0190743399451145, disc_loss = 0.0007361700055786105
Trained batch 638 in epoch 9, gen_loss = 1.0190235300802848, disc_loss = 0.000735209985817083
Trained batch 639 in epoch 9, gen_loss = 1.0191153933294117, disc_loss = 0.0007342106655869429
Trained batch 640 in epoch 9, gen_loss = 1.0190833707495524, disc_loss = 0.0007332352311911596
Trained batch 641 in epoch 9, gen_loss = 1.0190200299674477, disc_loss = 0.0007322945784722278
Trained batch 642 in epoch 9, gen_loss = 1.0189842678154608, disc_loss = 0.0007313680356869208
Trained batch 643 in epoch 9, gen_loss = 1.0189408197166017, disc_loss = 0.0007304231409496492
Trained batch 644 in epoch 9, gen_loss = 1.0187174996664359, disc_loss = 0.0007294075656501764
Trained batch 645 in epoch 9, gen_loss = 1.0187289993460333, disc_loss = 0.0007284817122250591
Trained batch 646 in epoch 9, gen_loss = 1.0187163585120411, disc_loss = 0.0007275089645294769
Trained batch 647 in epoch 9, gen_loss = 1.0186109964126422, disc_loss = 0.0007264958877037574
Trained batch 648 in epoch 9, gen_loss = 1.0186324793678954, disc_loss = 0.0007255356343688539
Trained batch 649 in epoch 9, gen_loss = 1.0186693400603075, disc_loss = 0.000724551582881339
Trained batch 650 in epoch 9, gen_loss = 1.0188343356465048, disc_loss = 0.0007235611347542767
Trained batch 651 in epoch 9, gen_loss = 1.0188436213812213, disc_loss = 0.0007225629936780872
Trained batch 652 in epoch 9, gen_loss = 1.0188318779421073, disc_loss = 0.0007215591439159707
Trained batch 653 in epoch 9, gen_loss = 1.018801556814701, disc_loss = 0.000720574394589723
Trained batch 654 in epoch 9, gen_loss = 1.0188276760450756, disc_loss = 0.0007195759155407179
Trained batch 655 in epoch 9, gen_loss = 1.0187785790824309, disc_loss = 0.0007185637197236668
Trained batch 656 in epoch 9, gen_loss = 1.0188081709035819, disc_loss = 0.0007175757724281806
Trained batch 657 in epoch 9, gen_loss = 1.018806033764929, disc_loss = 0.0007165989395547524
Trained batch 658 in epoch 9, gen_loss = 1.01875615373186, disc_loss = 0.0007156164436652332
Trained batch 659 in epoch 9, gen_loss = 1.0187814546353888, disc_loss = 0.0007146302343630161
Trained batch 660 in epoch 9, gen_loss = 1.0186636092623136, disc_loss = 0.0007137018141411414
Trained batch 661 in epoch 9, gen_loss = 1.018489163897909, disc_loss = 0.000712721616492587
Trained batch 662 in epoch 9, gen_loss = 1.0185107689457602, disc_loss = 0.0007118821249413339
Trained batch 663 in epoch 9, gen_loss = 1.0185086532350045, disc_loss = 0.0007110347015846658
Trained batch 664 in epoch 9, gen_loss = 1.0185176163687741, disc_loss = 0.0007101423995957983
Trained batch 665 in epoch 9, gen_loss = 1.0184670623179313, disc_loss = 0.0007092543898768061
Trained batch 666 in epoch 9, gen_loss = 1.0185228285045995, disc_loss = 0.0007083470963203101
Trained batch 667 in epoch 9, gen_loss = 1.0184028720605873, disc_loss = 0.0007073896743235538
Trained batch 668 in epoch 9, gen_loss = 1.0182635263833586, disc_loss = 0.0007064117305607205
Trained batch 669 in epoch 9, gen_loss = 1.0181570175868362, disc_loss = 0.0007054465168745191
Trained batch 670 in epoch 9, gen_loss = 1.0180959347108083, disc_loss = 0.0007045162347617373
Trained batch 671 in epoch 9, gen_loss = 1.0180416656214566, disc_loss = 0.0007035682122401946
Trained batch 672 in epoch 9, gen_loss = 1.0179518066224869, disc_loss = 0.000702605271015659
Trained batch 673 in epoch 9, gen_loss = 1.0178925026241326, disc_loss = 0.0007016377449259753
Trained batch 674 in epoch 9, gen_loss = 1.0178854537010193, disc_loss = 0.0007006812491723664
Trained batch 675 in epoch 9, gen_loss = 1.0179404860593864, disc_loss = 0.0006997227844762886
Trained batch 676 in epoch 9, gen_loss = 1.0178741346081743, disc_loss = 0.0006987727933397009
Trained batch 677 in epoch 9, gen_loss = 1.0178767598308294, disc_loss = 0.0006979008137605085
Trained batch 678 in epoch 9, gen_loss = 1.0178238033194957, disc_loss = 0.0006971556883476248
Trained batch 679 in epoch 9, gen_loss = 1.0178501733085688, disc_loss = 0.0006964379437597338
Trained batch 680 in epoch 9, gen_loss = 1.0178628395832583, disc_loss = 0.0006957472167163301
Trained batch 681 in epoch 9, gen_loss = 1.0180779754066747, disc_loss = 0.0006950250813226957
Trained batch 682 in epoch 9, gen_loss = 1.0181247391253927, disc_loss = 0.0006942473606709807
Trained batch 683 in epoch 9, gen_loss = 1.0182710733504323, disc_loss = 0.0006934581309459437
Trained batch 684 in epoch 9, gen_loss = 1.0183624644349092, disc_loss = 0.0006926305435812882
Trained batch 685 in epoch 9, gen_loss = 1.0183591021566976, disc_loss = 0.0006917843950311443
Trained batch 686 in epoch 9, gen_loss = 1.0183672116312918, disc_loss = 0.0006908904002660654
Trained batch 687 in epoch 9, gen_loss = 1.0184862073944059, disc_loss = 0.0006899730544509386
Trained batch 688 in epoch 9, gen_loss = 1.0184301166472138, disc_loss = 0.0006891064657277194
Trained batch 689 in epoch 9, gen_loss = 1.0183910635070523, disc_loss = 0.0006883219480042117
Trained batch 690 in epoch 9, gen_loss = 1.0184321804605587, disc_loss = 0.0006874471736647992
Trained batch 691 in epoch 9, gen_loss = 1.0183243276066862, disc_loss = 0.0006865525947590331
Trained batch 692 in epoch 9, gen_loss = 1.0183163652516374, disc_loss = 0.0006856629449205909
Trained batch 693 in epoch 9, gen_loss = 1.0183317925813218, disc_loss = 0.0006847855152740239
Trained batch 694 in epoch 9, gen_loss = 1.0182359860097763, disc_loss = 0.0006839518236074254
Trained batch 695 in epoch 9, gen_loss = 1.0183838198239776, disc_loss = 0.0006830710886453911
Trained batch 696 in epoch 9, gen_loss = 1.0183984391829546, disc_loss = 0.0006821678597167725
Trained batch 697 in epoch 9, gen_loss = 1.0184997371411255, disc_loss = 0.0006812978801285824
Trained batch 698 in epoch 9, gen_loss = 1.0184011318652926, disc_loss = 0.0006804200522300157
Trained batch 699 in epoch 9, gen_loss = 1.0183319732972553, disc_loss = 0.0006795361387880153
Trained batch 700 in epoch 9, gen_loss = 1.0183038163117097, disc_loss = 0.00067865373913211
Trained batch 701 in epoch 9, gen_loss = 1.0182601723745677, disc_loss = 0.0006777662754788423
Trained batch 702 in epoch 9, gen_loss = 1.0182868924792088, disc_loss = 0.000676982957767884
Trained batch 703 in epoch 9, gen_loss = 1.0181676358492537, disc_loss = 0.0006762264215002357
Trained batch 704 in epoch 9, gen_loss = 1.018142551310519, disc_loss = 0.0006753510904002188
Trained batch 705 in epoch 9, gen_loss = 1.0181939452464452, disc_loss = 0.0006744965952073281
Trained batch 706 in epoch 9, gen_loss = 1.0182431817391975, disc_loss = 0.0006736103967976966
Trained batch 707 in epoch 9, gen_loss = 1.0182594299148031, disc_loss = 0.0006727176985003683
Trained batch 708 in epoch 9, gen_loss = 1.0182342938711009, disc_loss = 0.0006718295941958765
Trained batch 709 in epoch 9, gen_loss = 1.018161889448972, disc_loss = 0.0006709391642007304
Trained batch 710 in epoch 9, gen_loss = 1.0181030399688689, disc_loss = 0.0006700740481374223
Trained batch 711 in epoch 9, gen_loss = 1.0181556763441375, disc_loss = 0.0006692690475717703
Trained batch 712 in epoch 9, gen_loss = 1.0180877312537162, disc_loss = 0.0006684718563319442
Trained batch 713 in epoch 9, gen_loss = 1.0181900928167402, disc_loss = 0.000667663341279395
Trained batch 714 in epoch 9, gen_loss = 1.0181853777045136, disc_loss = 0.0006668608068088411
Trained batch 715 in epoch 9, gen_loss = 1.0182211060264257, disc_loss = 0.0006660172326143394
Trained batch 716 in epoch 9, gen_loss = 1.0181842673273764, disc_loss = 0.0006651359703487179
Trained batch 717 in epoch 9, gen_loss = 1.0181526561633458, disc_loss = 0.0006642800671517286
Trained batch 718 in epoch 9, gen_loss = 1.0182116638470093, disc_loss = 0.0006634607912961802
Trained batch 719 in epoch 9, gen_loss = 1.0182027763790555, disc_loss = 0.0006626403520133156
Trained batch 720 in epoch 9, gen_loss = 1.018146323430224, disc_loss = 0.0006617909898920419
Trained batch 721 in epoch 9, gen_loss = 1.0181255310856405, disc_loss = 0.0006609334506916699
Trained batch 722 in epoch 9, gen_loss = 1.0181879878538773, disc_loss = 0.0006600673573258601
Trained batch 723 in epoch 9, gen_loss = 1.0181579369207772, disc_loss = 0.000659204852770183
Trained batch 724 in epoch 9, gen_loss = 1.0181638918251827, disc_loss = 0.0006584135630039562
Trained batch 725 in epoch 9, gen_loss = 1.0182163675954519, disc_loss = 0.0006575670817125455
Trained batch 726 in epoch 9, gen_loss = 1.018262026234539, disc_loss = 0.0006567233528048658
Trained batch 727 in epoch 9, gen_loss = 1.0184230784793475, disc_loss = 0.0006558822550597232
Trained batch 728 in epoch 9, gen_loss = 1.0184147848513883, disc_loss = 0.000655053267958269
Trained batch 729 in epoch 9, gen_loss = 1.0183608277203287, disc_loss = 0.000654242525896024
Trained batch 730 in epoch 9, gen_loss = 1.0184094429668422, disc_loss = 0.0006534148278673165
Trained batch 731 in epoch 9, gen_loss = 1.0184516125038021, disc_loss = 0.0006525790965840359
Trained batch 732 in epoch 9, gen_loss = 1.0184883072789337, disc_loss = 0.0006517901088622584
Trained batch 733 in epoch 9, gen_loss = 1.0183811056191654, disc_loss = 0.0006510395159355599
Trained batch 734 in epoch 9, gen_loss = 1.018360769667593, disc_loss = 0.0006502474609437339
Trained batch 735 in epoch 9, gen_loss = 1.0183747992243455, disc_loss = 0.0006494656809922083
Trained batch 736 in epoch 9, gen_loss = 1.0183825995899445, disc_loss = 0.0006486803017620404
Trained batch 737 in epoch 9, gen_loss = 1.0184852564884073, disc_loss = 0.0006478942180890259
Trained batch 738 in epoch 9, gen_loss = 1.0184829652874008, disc_loss = 0.0006470882551414474
Trained batch 739 in epoch 9, gen_loss = 1.0184793750982026, disc_loss = 0.0006462840299816988
Trained batch 740 in epoch 9, gen_loss = 1.0184224483616118, disc_loss = 0.0006454792750637831
Trained batch 741 in epoch 9, gen_loss = 1.0184939892465534, disc_loss = 0.0006447219360598446
Trained batch 742 in epoch 9, gen_loss = 1.0184639937784599, disc_loss = 0.0006439448257404177
Trained batch 743 in epoch 9, gen_loss = 1.018387996060874, disc_loss = 0.0006431566700034979
Trained batch 744 in epoch 9, gen_loss = 1.018376745633631, disc_loss = 0.0006423810495363686
Trained batch 745 in epoch 9, gen_loss = 1.018336322288411, disc_loss = 0.0006416059213368367
Trained batch 746 in epoch 9, gen_loss = 1.0183160504503264, disc_loss = 0.0006408088536716987
Trained batch 747 in epoch 9, gen_loss = 1.0182888135712413, disc_loss = 0.0006400377778359362
Trained batch 748 in epoch 9, gen_loss = 1.0182009449151552, disc_loss = 0.0006392751607886694
Trained batch 749 in epoch 9, gen_loss = 1.018217919588089, disc_loss = 0.0006385234888536312
Trained batch 750 in epoch 9, gen_loss = 1.0183263106765188, disc_loss = 0.0006378127512043127
Trained batch 751 in epoch 9, gen_loss = 1.018315561829095, disc_loss = 0.0006371067880352596
Trained batch 752 in epoch 9, gen_loss = 1.0182778722103216, disc_loss = 0.0006364479924709914
Trained batch 753 in epoch 9, gen_loss = 1.0183115146994908, disc_loss = 0.0006357649042921012
Trained batch 754 in epoch 9, gen_loss = 1.018363749349354, disc_loss = 0.0006351051179201431
Trained batch 755 in epoch 9, gen_loss = 1.0182476302303334, disc_loss = 0.0006344104214717628
Trained batch 756 in epoch 9, gen_loss = 1.0182772189811797, disc_loss = 0.0006336900425145309
Trained batch 757 in epoch 9, gen_loss = 1.0182380038547012, disc_loss = 0.0006329621376279213
Trained batch 758 in epoch 9, gen_loss = 1.0183286791733601, disc_loss = 0.0006322468432026246
Trained batch 759 in epoch 9, gen_loss = 1.0183663626250468, disc_loss = 0.0006315435404614714
Trained batch 760 in epoch 9, gen_loss = 1.0183599572457402, disc_loss = 0.0006308905038827435
Trained batch 761 in epoch 9, gen_loss = 1.0182710440922285, disc_loss = 0.0006302822414018917
Trained batch 762 in epoch 9, gen_loss = 1.0181644282366002, disc_loss = 0.0006296792150350201
Trained batch 763 in epoch 9, gen_loss = 1.0182562220002969, disc_loss = 0.0006290699371789427
Trained batch 764 in epoch 9, gen_loss = 1.018199595049316, disc_loss = 0.0006284731958170643
Trained batch 765 in epoch 9, gen_loss = 1.0181960475195793, disc_loss = 0.0006278420781297472
Trained batch 766 in epoch 9, gen_loss = 1.018322151129995, disc_loss = 0.0006271727623129515
Trained batch 767 in epoch 9, gen_loss = 1.0184028143218409, disc_loss = 0.0006264867261667936
Trained batch 768 in epoch 9, gen_loss = 1.0186025638264085, disc_loss = 0.0006257942915792739
Trained batch 769 in epoch 9, gen_loss = 1.0186255576548637, disc_loss = 0.0006251830611290643
Trained batch 770 in epoch 9, gen_loss = 1.0187572176663637, disc_loss = 0.0006245829743293073
Trained batch 771 in epoch 9, gen_loss = 1.0188049929592893, disc_loss = 0.0006239233865822835
Trained batch 772 in epoch 9, gen_loss = 1.0188020749203137, disc_loss = 0.0006232319155334538
Trained batch 773 in epoch 9, gen_loss = 1.0187748150770055, disc_loss = 0.0006225055063477879
Trained batch 774 in epoch 9, gen_loss = 1.0186731992229339, disc_loss = 0.0006217746293329964
Trained batch 775 in epoch 9, gen_loss = 1.0186797861278671, disc_loss = 0.000621051103125771
Trained batch 776 in epoch 9, gen_loss = 1.0185794712954046, disc_loss = 0.0006203214880785464
Trained batch 777 in epoch 9, gen_loss = 1.0184755395801024, disc_loss = 0.0006195981017659403
Trained batch 778 in epoch 9, gen_loss = 1.0184713808654668, disc_loss = 0.0006188654063504643
Trained batch 779 in epoch 9, gen_loss = 1.0183934612151904, disc_loss = 0.0006181531632720203
Trained batch 780 in epoch 9, gen_loss = 1.0184154684503923, disc_loss = 0.0006174387956781103
Trained batch 781 in epoch 9, gen_loss = 1.0183462823748284, disc_loss = 0.0006167056758607001
Trained batch 782 in epoch 9, gen_loss = 1.0184102312662897, disc_loss = 0.0006159823575660873
Trained batch 783 in epoch 9, gen_loss = 1.0186274775436945, disc_loss = 0.0006152706747547644
Trained batch 784 in epoch 9, gen_loss = 1.018595186919923, disc_loss = 0.0006145545937140194
Trained batch 785 in epoch 9, gen_loss = 1.0186378569093368, disc_loss = 0.0006138219871208262
Trained batch 786 in epoch 9, gen_loss = 1.0186540227681589, disc_loss = 0.0006130791154075542
Trained batch 787 in epoch 9, gen_loss = 1.0184356783549797, disc_loss = 0.0006123506212544977
Trained batch 788 in epoch 9, gen_loss = 1.0183980415831348, disc_loss = 0.000611620340913309
Trained batch 789 in epoch 9, gen_loss = 1.0184452187411392, disc_loss = 0.0006109019431266772
Testing Epoch 9
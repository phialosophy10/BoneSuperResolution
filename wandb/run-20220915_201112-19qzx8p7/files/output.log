/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 1.0208473205566406, disc_loss = 0.6097512245178223
Trained batch 1 in epoch 0, gen_loss = 1.0203884840011597, disc_loss = 0.6409119367599487
Trained batch 2 in epoch 0, gen_loss = 0.9676556388537089, disc_loss = 0.6305062572161356
Trained batch 3 in epoch 0, gen_loss = 0.9669437855482101, disc_loss = 0.5993560254573822
Trained batch 4 in epoch 0, gen_loss = 0.9267016530036927, disc_loss = 0.5314452707767486
Trained batch 5 in epoch 0, gen_loss = 0.8808770477771759, disc_loss = 0.4789870431025823
Trained batch 6 in epoch 0, gen_loss = 0.8439692343984332, disc_loss = 0.44103847656931194
Trained batch 7 in epoch 0, gen_loss = 0.8243052735924721, disc_loss = 0.4089526906609535
Trained batch 8 in epoch 0, gen_loss = 0.8171252873208787, disc_loss = 0.38651936915185714
Trained batch 9 in epoch 0, gen_loss = 0.8103687345981598, disc_loss = 0.3667342633008957
Trained batch 10 in epoch 0, gen_loss = 0.8035243099386041, disc_loss = 0.3511902242898941
Trained batch 11 in epoch 0, gen_loss = 0.799623022476832, disc_loss = 0.3396081825097402
Trained batch 12 in epoch 0, gen_loss = 0.7990918617982131, disc_loss = 0.3297539743093344
Trained batch 13 in epoch 0, gen_loss = 0.8053298209394727, disc_loss = 0.3206050566264561
Trained batch 14 in epoch 0, gen_loss = 0.8048385461171468, disc_loss = 0.3094869832197825
Trained batch 15 in epoch 0, gen_loss = 0.8086866848170757, disc_loss = 0.2991247158497572
Trained batch 16 in epoch 0, gen_loss = 0.8090780377388, disc_loss = 0.2883590968216167
Trained batch 17 in epoch 0, gen_loss = 0.8092078301641676, disc_loss = 0.2782541571391953
Trained batch 18 in epoch 0, gen_loss = 0.8112213548861051, disc_loss = 0.26805365634591954
Trained batch 19 in epoch 0, gen_loss = 0.8103384345769882, disc_loss = 0.2610759325325489
Trained batch 20 in epoch 0, gen_loss = 0.8156856411979312, disc_loss = 0.25505839855897994
Trained batch 21 in epoch 0, gen_loss = 0.817870706319809, disc_loss = 0.25075414167209104
Trained batch 22 in epoch 0, gen_loss = 0.8218366918356522, disc_loss = 0.24732866948065552
Trained batch 23 in epoch 0, gen_loss = 0.8302311524748802, disc_loss = 0.24448840506374836
Trained batch 24 in epoch 0, gen_loss = 0.8315847706794739, disc_loss = 0.23988645195960998
Trained batch 25 in epoch 0, gen_loss = 0.8323992101045755, disc_loss = 0.23366439199218383
Trained batch 26 in epoch 0, gen_loss = 0.8330735431777107, disc_loss = 0.22790143887201944
Trained batch 27 in epoch 0, gen_loss = 0.8351788499525615, disc_loss = 0.22307937645486423
Trained batch 28 in epoch 0, gen_loss = 0.8399876417784855, disc_loss = 0.21857301839466753
Trained batch 29 in epoch 0, gen_loss = 0.8460876961549123, disc_loss = 0.21401131798823675
Trained batch 30 in epoch 0, gen_loss = 0.8546223736578419, disc_loss = 0.20977470374876453
Trained batch 31 in epoch 0, gen_loss = 0.863060848787427, disc_loss = 0.2053877036087215
Trained batch 32 in epoch 0, gen_loss = 0.8735056989120714, disc_loss = 0.20111821388656442
Trained batch 33 in epoch 0, gen_loss = 0.8832476752645829, disc_loss = 0.1968991795883459
Trained batch 34 in epoch 0, gen_loss = 0.8908492343766349, disc_loss = 0.19281898822103227
Trained batch 35 in epoch 0, gen_loss = 0.8984068019522561, disc_loss = 0.1892688185390499
Trained batch 36 in epoch 0, gen_loss = 0.9065350374659976, disc_loss = 0.1865352124378488
Trained batch 37 in epoch 0, gen_loss = 0.9125162786559055, disc_loss = 0.18284169525692337
Trained batch 38 in epoch 0, gen_loss = 0.9182904087580167, disc_loss = 0.17902750292649636
Trained batch 39 in epoch 0, gen_loss = 0.9226486667990684, disc_loss = 0.1753623285330832
Trained batch 40 in epoch 0, gen_loss = 0.9269230874573312, disc_loss = 0.17214262658139554
Trained batch 41 in epoch 0, gen_loss = 0.9320011011191777, disc_loss = 0.16905236669949122
Trained batch 42 in epoch 0, gen_loss = 0.9367201037185137, disc_loss = 0.1658644167663053
Trained batch 43 in epoch 0, gen_loss = 0.941315611655062, disc_loss = 0.16275545133447106
Trained batch 44 in epoch 0, gen_loss = 0.9467539191246033, disc_loss = 0.159845622546143
Trained batch 45 in epoch 0, gen_loss = 0.9512776227101035, disc_loss = 0.15691241613872672
Trained batch 46 in epoch 0, gen_loss = 0.9538750382179909, disc_loss = 0.15405189681877482
Trained batch 47 in epoch 0, gen_loss = 0.9567369557917118, disc_loss = 0.1513426648840929
Trained batch 48 in epoch 0, gen_loss = 0.958960507597242, disc_loss = 0.14867580853098508
Trained batch 49 in epoch 0, gen_loss = 0.9620991742610931, disc_loss = 0.14626266065984964
Trained batch 50 in epoch 0, gen_loss = 0.9658547604785246, disc_loss = 0.14391802919699864
Trained batch 51 in epoch 0, gen_loss = 0.9691432496676078, disc_loss = 0.14163223693433863
Trained batch 52 in epoch 0, gen_loss = 0.9720386187985258, disc_loss = 0.13934951152582215
Trained batch 53 in epoch 0, gen_loss = 0.9742181113472691, disc_loss = 0.13712493795901537
Trained batch 54 in epoch 0, gen_loss = 0.9767300031401894, disc_loss = 0.1350165518508716
Trained batch 55 in epoch 0, gen_loss = 0.9792843407818249, disc_loss = 0.13295179612136312
Trained batch 56 in epoch 0, gen_loss = 0.9815958455989235, disc_loss = 0.13095988610988124
Trained batch 57 in epoch 0, gen_loss = 0.9837818752075064, disc_loss = 0.12901909646160645
Trained batch 58 in epoch 0, gen_loss = 0.9853483004085088, disc_loss = 0.1271747454243191
Trained batch 59 in epoch 0, gen_loss = 0.9867473632097244, disc_loss = 0.1253862178574006
Trained batch 60 in epoch 0, gen_loss = 0.987951539578985, disc_loss = 0.12364178044019175
Trained batch 61 in epoch 0, gen_loss = 0.9893598123904197, disc_loss = 0.1219994965039434
Trained batch 62 in epoch 0, gen_loss = 0.9914802076324584, disc_loss = 0.12057625795049327
Trained batch 63 in epoch 0, gen_loss = 0.9944441607221961, disc_loss = 0.11944787026732229
Trained batch 64 in epoch 0, gen_loss = 0.9964294937940744, disc_loss = 0.11863105810032441
Trained batch 65 in epoch 0, gen_loss = 0.9986458791024757, disc_loss = 0.11803325149936206
Trained batch 66 in epoch 0, gen_loss = 1.000333747757015, disc_loss = 0.11696984643922813
Trained batch 67 in epoch 0, gen_loss = 1.0028442293405533, disc_loss = 0.11559878336265683
Trained batch 68 in epoch 0, gen_loss = 1.003934892191403, disc_loss = 0.11423431571734988
Trained batch 69 in epoch 0, gen_loss = 1.004391780069896, disc_loss = 0.11287948731333017
Trained batch 70 in epoch 0, gen_loss = 1.0052900557786646, disc_loss = 0.11152776739966701
Trained batch 71 in epoch 0, gen_loss = 1.0061810488502185, disc_loss = 0.11020207335241139
Trained batch 72 in epoch 0, gen_loss = 1.00643117868737, disc_loss = 0.1089265762943111
Trained batch 73 in epoch 0, gen_loss = 1.0065531400409904, disc_loss = 0.10770196684107587
Trained batch 74 in epoch 0, gen_loss = 1.0071469298998514, disc_loss = 0.10645450133830309
Trained batch 75 in epoch 0, gen_loss = 1.0079980610232604, disc_loss = 0.10523726593850083
Trained batch 76 in epoch 0, gen_loss = 1.0089232666151864, disc_loss = 0.10406659622132391
Trained batch 77 in epoch 0, gen_loss = 1.0089580286771824, disc_loss = 0.10291873144272429
Trained batch 78 in epoch 0, gen_loss = 1.0090493137323404, disc_loss = 0.10176815470987105
Trained batch 79 in epoch 0, gen_loss = 1.0100342832505702, disc_loss = 0.10064434969099238
Trained batch 80 in epoch 0, gen_loss = 1.0110209128003063, disc_loss = 0.09955572588714184
Trained batch 81 in epoch 0, gen_loss = 1.011638780192631, disc_loss = 0.09849679412138534
Trained batch 82 in epoch 0, gen_loss = 1.0126494406217552, disc_loss = 0.09755901988954788
Trained batch 83 in epoch 0, gen_loss = 1.0134246186131524, disc_loss = 0.09677429972881717
Trained batch 84 in epoch 0, gen_loss = 1.0140758086653316, disc_loss = 0.09601644291816389
Trained batch 85 in epoch 0, gen_loss = 1.0146251521831335, disc_loss = 0.0951076592751887
Trained batch 86 in epoch 0, gen_loss = 1.0147911837731285, disc_loss = 0.0941554623945006
Trained batch 87 in epoch 0, gen_loss = 1.0149888741699131, disc_loss = 0.09320925423790785
Trained batch 88 in epoch 0, gen_loss = 1.0157324390464955, disc_loss = 0.0922906839320164
Trained batch 89 in epoch 0, gen_loss = 1.0160774873362648, disc_loss = 0.09138762120985322
Trained batch 90 in epoch 0, gen_loss = 1.0163750969446623, disc_loss = 0.09049758659982747
Trained batch 91 in epoch 0, gen_loss = 1.0168387870425764, disc_loss = 0.08963049667806405
Trained batch 92 in epoch 0, gen_loss = 1.0175727958320289, disc_loss = 0.08878764816589894
Trained batch 93 in epoch 0, gen_loss = 1.0183925203820492, disc_loss = 0.08795384318627258
Trained batch 94 in epoch 0, gen_loss = 1.0182467517099882, disc_loss = 0.08712231484486868
Trained batch 95 in epoch 0, gen_loss = 1.0186044306804736, disc_loss = 0.08632204063663569
Trained batch 96 in epoch 0, gen_loss = 1.0191617116485674, disc_loss = 0.08552891635287975
Trained batch 97 in epoch 0, gen_loss = 1.0198662834508079, disc_loss = 0.08475045606075805
Trained batch 98 in epoch 0, gen_loss = 1.0207565739901379, disc_loss = 0.08399643348247716
Trained batch 99 in epoch 0, gen_loss = 1.0212458294630051, disc_loss = 0.08325469342060388
Trained batch 100 in epoch 0, gen_loss = 1.0213299122187172, disc_loss = 0.08251408446985896
Trained batch 101 in epoch 0, gen_loss = 1.0217612040977853, disc_loss = 0.08179485759533503
Trained batch 102 in epoch 0, gen_loss = 1.0222139514765693, disc_loss = 0.08108912165122993
Trained batch 103 in epoch 0, gen_loss = 1.0229210618596811, disc_loss = 0.08039933465457019
Trained batch 104 in epoch 0, gen_loss = 1.0232807312692915, disc_loss = 0.07971744008717083
Trained batch 105 in epoch 0, gen_loss = 1.0239043769971379, disc_loss = 0.0790491492030615
Trained batch 106 in epoch 0, gen_loss = 1.0248790026825165, disc_loss = 0.07839647928583567
Trained batch 107 in epoch 0, gen_loss = 1.0250939191491515, disc_loss = 0.07775466729610882
Trained batch 108 in epoch 0, gen_loss = 1.0257099095834505, disc_loss = 0.07712718246316691
Trained batch 109 in epoch 0, gen_loss = 1.0261908341537822, disc_loss = 0.07650929523462599
Trained batch 110 in epoch 0, gen_loss = 1.0269099296750248, disc_loss = 0.075909473832596
Trained batch 111 in epoch 0, gen_loss = 1.0269322911543506, disc_loss = 0.07530985708581284
Trained batch 112 in epoch 0, gen_loss = 1.027186535628496, disc_loss = 0.07471517775933036
Trained batch 113 in epoch 0, gen_loss = 1.027110416115376, disc_loss = 0.07412444935752112
Trained batch 114 in epoch 0, gen_loss = 1.027476824366528, disc_loss = 0.07354991576917794
Trained batch 115 in epoch 0, gen_loss = 1.0279161020599563, disc_loss = 0.0729854609174975
Trained batch 116 in epoch 0, gen_loss = 1.0280423026818495, disc_loss = 0.07243218865946062
Trained batch 117 in epoch 0, gen_loss = 1.0285260258084636, disc_loss = 0.07188454721028269
Trained batch 118 in epoch 0, gen_loss = 1.0288599594300534, disc_loss = 0.07134457756647793
Trained batch 119 in epoch 0, gen_loss = 1.0290259872873624, disc_loss = 0.07081106139036517
Trained batch 120 in epoch 0, gen_loss = 1.029267128341454, disc_loss = 0.07028960187203628
Trained batch 121 in epoch 0, gen_loss = 1.0297102659452158, disc_loss = 0.06977748427326318
Trained batch 122 in epoch 0, gen_loss = 1.0299491528573075, disc_loss = 0.06926782464426828
Trained batch 123 in epoch 0, gen_loss = 1.0303982645273209, disc_loss = 0.06878059263145851
Trained batch 124 in epoch 0, gen_loss = 1.0308565764427184, disc_loss = 0.06830985921993851
Trained batch 125 in epoch 0, gen_loss = 1.0305029082865942, disc_loss = 0.06783252206837966
Trained batch 126 in epoch 0, gen_loss = 1.0301804997789579, disc_loss = 0.067362165896178
Trained batch 127 in epoch 0, gen_loss = 1.0307156243361533, disc_loss = 0.06691056349882274
Trained batch 128 in epoch 0, gen_loss = 1.0307535926500957, disc_loss = 0.06648286437442483
Trained batch 129 in epoch 0, gen_loss = 1.0309705995596372, disc_loss = 0.06609236064653556
Trained batch 130 in epoch 0, gen_loss = 1.0312009917870733, disc_loss = 0.06571032564361928
Trained batch 131 in epoch 0, gen_loss = 1.031374888438167, disc_loss = 0.06531038254880431
Trained batch 132 in epoch 0, gen_loss = 1.0315964495329033, disc_loss = 0.06489913068585713
Trained batch 133 in epoch 0, gen_loss = 1.0316760188608027, disc_loss = 0.06447770822890547
Trained batch 134 in epoch 0, gen_loss = 1.0320204333022789, disc_loss = 0.06406462984159589
Trained batch 135 in epoch 0, gen_loss = 1.032088918282705, disc_loss = 0.06365419603432254
Trained batch 136 in epoch 0, gen_loss = 1.0325170846751137, disc_loss = 0.06324792198197794
Trained batch 137 in epoch 0, gen_loss = 1.0323801666930101, disc_loss = 0.06283694913651308
Trained batch 138 in epoch 0, gen_loss = 1.032334009949252, disc_loss = 0.062433377966927966
Trained batch 139 in epoch 0, gen_loss = 1.0326661139726638, disc_loss = 0.06203497219830752
Trained batch 140 in epoch 0, gen_loss = 1.0328316988674462, disc_loss = 0.061646633329041675
Trained batch 141 in epoch 0, gen_loss = 1.032590708262484, disc_loss = 0.061263006839665096
Trained batch 142 in epoch 0, gen_loss = 1.033099375404678, disc_loss = 0.060900513431174565
Trained batch 143 in epoch 0, gen_loss = 1.033562263680829, disc_loss = 0.060532410231341295
Trained batch 144 in epoch 0, gen_loss = 1.0337909377854446, disc_loss = 0.0601674472463542
Trained batch 145 in epoch 0, gen_loss = 1.0342732488292536, disc_loss = 0.05982550172364875
Trained batch 146 in epoch 0, gen_loss = 1.0343388700160852, disc_loss = 0.059480514326671355
Trained batch 147 in epoch 0, gen_loss = 1.0345899068020485, disc_loss = 0.059133752790355196
Trained batch 148 in epoch 0, gen_loss = 1.034581223590262, disc_loss = 0.058780942605995895
Trained batch 149 in epoch 0, gen_loss = 1.0344138487180075, disc_loss = 0.058437284532313546
Trained batch 150 in epoch 0, gen_loss = 1.0347675140330335, disc_loss = 0.058107930405176436
Trained batch 151 in epoch 0, gen_loss = 1.0350705416578996, disc_loss = 0.057784998847637326
Trained batch 152 in epoch 0, gen_loss = 1.034956654692008, disc_loss = 0.05745746947983219
Trained batch 153 in epoch 0, gen_loss = 1.0346907981030353, disc_loss = 0.05714262113301688
Trained batch 154 in epoch 0, gen_loss = 1.0347784949887184, disc_loss = 0.056834040855568264
Trained batch 155 in epoch 0, gen_loss = 1.0351644158363342, disc_loss = 0.056539921200452134
Trained batch 156 in epoch 0, gen_loss = 1.0352597821290326, disc_loss = 0.05625484808152364
Trained batch 157 in epoch 0, gen_loss = 1.0352969750573364, disc_loss = 0.05595258781038036
Trained batch 158 in epoch 0, gen_loss = 1.0358696441230535, disc_loss = 0.05564598761698079
Trained batch 159 in epoch 0, gen_loss = 1.0359676375985145, disc_loss = 0.05533336879161652
Trained batch 160 in epoch 0, gen_loss = 1.0363284564166335, disc_loss = 0.05502768378612233
Trained batch 161 in epoch 0, gen_loss = 1.0365528883757416, disc_loss = 0.05472725321090332
Trained batch 162 in epoch 0, gen_loss = 1.0365596271000026, disc_loss = 0.05442483940281751
Trained batch 163 in epoch 0, gen_loss = 1.0364635615814022, disc_loss = 0.05412492389427271
Trained batch 164 in epoch 0, gen_loss = 1.0362055442549967, disc_loss = 0.05382948693339572
Trained batch 165 in epoch 0, gen_loss = 1.036197964326445, disc_loss = 0.05354134837748954
Trained batch 166 in epoch 0, gen_loss = 1.036540862685906, disc_loss = 0.05325786528473129
Trained batch 167 in epoch 0, gen_loss = 1.036714654238451, disc_loss = 0.05296970765838133
Trained batch 168 in epoch 0, gen_loss = 1.0365102217042235, disc_loss = 0.05268740697526896
Trained batch 169 in epoch 0, gen_loss = 1.0366027968771316, disc_loss = 0.05241101586862522
Trained batch 170 in epoch 0, gen_loss = 1.0365085333411457, disc_loss = 0.05213264487847163
Trained batch 171 in epoch 0, gen_loss = 1.0366357228783674, disc_loss = 0.05186002337926089
Trained batch 172 in epoch 0, gen_loss = 1.0365830408355403, disc_loss = 0.05159082673920717
Trained batch 173 in epoch 0, gen_loss = 1.0367765087505867, disc_loss = 0.051322981728583406
Trained batch 174 in epoch 0, gen_loss = 1.0371623138019017, disc_loss = 0.05106285456301911
Trained batch 175 in epoch 0, gen_loss = 1.0371688689020546, disc_loss = 0.050804522007555614
Trained batch 176 in epoch 0, gen_loss = 1.0371276621764662, disc_loss = 0.0505548458530615
Trained batch 177 in epoch 0, gen_loss = 1.0371593454580628, disc_loss = 0.05031804776792362
Trained batch 178 in epoch 0, gen_loss = 1.036842697492525, disc_loss = 0.05007560815214695
Trained batch 179 in epoch 0, gen_loss = 1.0367746998866398, disc_loss = 0.049824233697209924
Trained batch 180 in epoch 0, gen_loss = 1.0368152069782026, disc_loss = 0.04957806892456353
Trained batch 181 in epoch 0, gen_loss = 1.0369107110814735, disc_loss = 0.04933758170835183
Trained batch 182 in epoch 0, gen_loss = 1.0369667280567147, disc_loss = 0.049098472355208436
Trained batch 183 in epoch 0, gen_loss = 1.036828730741273, disc_loss = 0.048856537439860404
Trained batch 184 in epoch 0, gen_loss = 1.0365052819252014, disc_loss = 0.04862037916994981
Trained batch 185 in epoch 0, gen_loss = 1.0368718399155525, disc_loss = 0.04838737089096779
Trained batch 186 in epoch 0, gen_loss = 1.0368993126134822, disc_loss = 0.048158481834147546
Trained batch 187 in epoch 0, gen_loss = 1.0370601729509679, disc_loss = 0.04792947446223982
Trained batch 188 in epoch 0, gen_loss = 1.0368770099190807, disc_loss = 0.04770279258598017
Trained batch 189 in epoch 0, gen_loss = 1.0368784449602428, disc_loss = 0.04749181680381298
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 1.0389842987060547, disc_loss = 0.010725182481110096
Trained batch 1 in epoch 1, gen_loss = 1.0419466495513916, disc_loss = 0.011320312973111868
Trained batch 2 in epoch 1, gen_loss = 1.0207983652750652, disc_loss = 0.011515820709367594
Trained batch 3 in epoch 1, gen_loss = 1.0261772274971008, disc_loss = 0.011741338297724724
Trained batch 4 in epoch 1, gen_loss = 1.0263637542724608, disc_loss = 0.01153678186237812
Trained batch 5 in epoch 1, gen_loss = 1.0355663299560547, disc_loss = 0.011038971443970999
Trained batch 6 in epoch 1, gen_loss = 1.039033191544669, disc_loss = 0.010457010274486882
Trained batch 7 in epoch 1, gen_loss = 1.0438465029001236, disc_loss = 0.010138622368685901
Trained batch 8 in epoch 1, gen_loss = 1.0391328864627414, disc_loss = 0.010049611226552062
Trained batch 9 in epoch 1, gen_loss = 1.0419113755226135, disc_loss = 0.010070783458650112
Trained batch 10 in epoch 1, gen_loss = 1.0456326441331343, disc_loss = 0.009911667470904913
Trained batch 11 in epoch 1, gen_loss = 1.0472095012664795, disc_loss = 0.009553310849393407
Trained batch 12 in epoch 1, gen_loss = 1.0507001693432148, disc_loss = 0.009233505465090275
Trained batch 13 in epoch 1, gen_loss = 1.0468746679169791, disc_loss = 0.009083721686952881
Trained batch 14 in epoch 1, gen_loss = 1.0477801005045573, disc_loss = 0.009078133509804805
Trained batch 15 in epoch 1, gen_loss = 1.0478264689445496, disc_loss = 0.009100688359467313
Trained batch 16 in epoch 1, gen_loss = 1.0484139779034782, disc_loss = 0.009090350529945949
Trained batch 17 in epoch 1, gen_loss = 1.0465439094437494, disc_loss = 0.008969644369143579
Trained batch 18 in epoch 1, gen_loss = 1.0482806092814396, disc_loss = 0.008794528897851706
Trained batch 19 in epoch 1, gen_loss = 1.0478671133518218, disc_loss = 0.008658759575337172
Trained batch 20 in epoch 1, gen_loss = 1.0474375599906558, disc_loss = 0.008581544627391156
Trained batch 21 in epoch 1, gen_loss = 1.0500198548490352, disc_loss = 0.008499844359572638
Trained batch 22 in epoch 1, gen_loss = 1.0475275412849758, disc_loss = 0.008358342917231113
Trained batch 23 in epoch 1, gen_loss = 1.0461587806542714, disc_loss = 0.008179604250472039
Trained batch 24 in epoch 1, gen_loss = 1.0463456201553345, disc_loss = 0.008011652901768685
Trained batch 25 in epoch 1, gen_loss = 1.0461481763766363, disc_loss = 0.007850695168599486
Trained batch 26 in epoch 1, gen_loss = 1.0450787279340956, disc_loss = 0.007744037442737156
Trained batch 27 in epoch 1, gen_loss = 1.0435550340584345, disc_loss = 0.00763035354404045
Trained batch 28 in epoch 1, gen_loss = 1.0447333393425777, disc_loss = 0.0075390808894459545
Trained batch 29 in epoch 1, gen_loss = 1.0461613257726035, disc_loss = 0.0074506490336110195
Trained batch 30 in epoch 1, gen_loss = 1.0478390801337458, disc_loss = 0.0073463211226607525
Trained batch 31 in epoch 1, gen_loss = 1.0490141957998276, disc_loss = 0.007232186020701192
Trained batch 32 in epoch 1, gen_loss = 1.047803394722216, disc_loss = 0.007124164423933535
Trained batch 33 in epoch 1, gen_loss = 1.0488322447328007, disc_loss = 0.007048820802832351
Trained batch 34 in epoch 1, gen_loss = 1.0487912893295288, disc_loss = 0.006973670981824398
Trained batch 35 in epoch 1, gen_loss = 1.048090633418825, disc_loss = 0.006873942562378943
Trained batch 36 in epoch 1, gen_loss = 1.047024891183183, disc_loss = 0.006784301377027421
Trained batch 37 in epoch 1, gen_loss = 1.0470513199505054, disc_loss = 0.006729210972001678
Trained batch 38 in epoch 1, gen_loss = 1.046304491850046, disc_loss = 0.006668434358942203
Trained batch 39 in epoch 1, gen_loss = 1.0461517035961152, disc_loss = 0.006596408371115104
Trained batch 40 in epoch 1, gen_loss = 1.046004618086466, disc_loss = 0.006536937733294397
Trained batch 41 in epoch 1, gen_loss = 1.0449575583140056, disc_loss = 0.006475327187217772
Trained batch 42 in epoch 1, gen_loss = 1.0443753558535909, disc_loss = 0.00641637408651065
Trained batch 43 in epoch 1, gen_loss = 1.0464967489242554, disc_loss = 0.00638455071550032
Trained batch 44 in epoch 1, gen_loss = 1.0463474724027846, disc_loss = 0.0063480775751587415
Trained batch 45 in epoch 1, gen_loss = 1.0456004272336545, disc_loss = 0.006357375122404293
Trained batch 46 in epoch 1, gen_loss = 1.0455652120265555, disc_loss = 0.006360490801446932
Trained batch 47 in epoch 1, gen_loss = 1.0462694490949314, disc_loss = 0.006374835497505653
Trained batch 48 in epoch 1, gen_loss = 1.045975137730034, disc_loss = 0.006363723574358286
Trained batch 49 in epoch 1, gen_loss = 1.0463070201873779, disc_loss = 0.006331371641717851
Trained batch 50 in epoch 1, gen_loss = 1.04710741370332, disc_loss = 0.006300674673790733
Trained batch 51 in epoch 1, gen_loss = 1.047174939742455, disc_loss = 0.006258623481978877
Trained batch 52 in epoch 1, gen_loss = 1.0475827365551356, disc_loss = 0.006213352308204433
Trained batch 53 in epoch 1, gen_loss = 1.0471785929467943, disc_loss = 0.006168255931697786
Trained batch 54 in epoch 1, gen_loss = 1.0472700314088301, disc_loss = 0.006115783044052395
Trained batch 55 in epoch 1, gen_loss = 1.0475073839936937, disc_loss = 0.006059006072713861
Trained batch 56 in epoch 1, gen_loss = 1.0466506690309758, disc_loss = 0.006000658660604243
Trained batch 57 in epoch 1, gen_loss = 1.0465100572027008, disc_loss = 0.00595142755352346
Trained batch 58 in epoch 1, gen_loss = 1.0472860154459032, disc_loss = 0.005913943723159827
Trained batch 59 in epoch 1, gen_loss = 1.0483870128790538, disc_loss = 0.005885962451187273
Trained batch 60 in epoch 1, gen_loss = 1.0479286850475875, disc_loss = 0.005842915323914074
Trained batch 61 in epoch 1, gen_loss = 1.0475080705458117, disc_loss = 0.005792628958701126
Trained batch 62 in epoch 1, gen_loss = 1.0480436938149589, disc_loss = 0.005751959147996136
Trained batch 63 in epoch 1, gen_loss = 1.0488559193909168, disc_loss = 0.005710105444450164
Trained batch 64 in epoch 1, gen_loss = 1.0477391325510466, disc_loss = 0.00566610016215306
Trained batch 65 in epoch 1, gen_loss = 1.0484617668570895, disc_loss = 0.005655296767751376
Trained batch 66 in epoch 1, gen_loss = 1.0481875094015207, disc_loss = 0.005636490714638981
Trained batch 67 in epoch 1, gen_loss = 1.048335824819172, disc_loss = 0.005625739926472306
Trained batch 68 in epoch 1, gen_loss = 1.0482114976730899, disc_loss = 0.0056075930757367096
Trained batch 69 in epoch 1, gen_loss = 1.047960021666118, disc_loss = 0.005577302830559867
Trained batch 70 in epoch 1, gen_loss = 1.0469142240537723, disc_loss = 0.005547912014176098
Trained batch 71 in epoch 1, gen_loss = 1.0469046326147184, disc_loss = 0.0055116146395448595
Trained batch 72 in epoch 1, gen_loss = 1.046845755348467, disc_loss = 0.005476992701703351
Trained batch 73 in epoch 1, gen_loss = 1.0460181340977952, disc_loss = 0.005434747039642487
Trained batch 74 in epoch 1, gen_loss = 1.0462346466382344, disc_loss = 0.005404263880724708
Trained batch 75 in epoch 1, gen_loss = 1.0458400069098723, disc_loss = 0.005375008055891253
Trained batch 76 in epoch 1, gen_loss = 1.0457634283350659, disc_loss = 0.005347922008920026
Trained batch 77 in epoch 1, gen_loss = 1.0461507737636566, disc_loss = 0.005328328056165423
Trained batch 78 in epoch 1, gen_loss = 1.0463394567936282, disc_loss = 0.005317323882415702
Trained batch 79 in epoch 1, gen_loss = 1.0459129236638547, disc_loss = 0.005304500058991834
Trained batch 80 in epoch 1, gen_loss = 1.0464246810218434, disc_loss = 0.00528990966555329
Trained batch 81 in epoch 1, gen_loss = 1.046160043012805, disc_loss = 0.005269828300764103
Trained batch 82 in epoch 1, gen_loss = 1.0461906776370773, disc_loss = 0.005248939966311656
Trained batch 83 in epoch 1, gen_loss = 1.0462521080459868, disc_loss = 0.0052359374018297305
Trained batch 84 in epoch 1, gen_loss = 1.0457809048540452, disc_loss = 0.005219685806728461
Trained batch 85 in epoch 1, gen_loss = 1.0458431070627168, disc_loss = 0.005197488648686991
Trained batch 86 in epoch 1, gen_loss = 1.0453091387091011, disc_loss = 0.005171819761309816
Trained batch 87 in epoch 1, gen_loss = 1.0452979958870194, disc_loss = 0.00516477217156948
Trained batch 88 in epoch 1, gen_loss = 1.045187703009402, disc_loss = 0.00516456455578295
Trained batch 89 in epoch 1, gen_loss = 1.0458759407202403, disc_loss = 0.005172442158477174
Trained batch 90 in epoch 1, gen_loss = 1.0480597733141301, disc_loss = 0.005220501519903377
Trained batch 91 in epoch 1, gen_loss = 1.0503326712743095, disc_loss = 0.005240542267489693
Trained batch 92 in epoch 1, gen_loss = 1.0510336231159907, disc_loss = 0.00524811434148941
Trained batch 93 in epoch 1, gen_loss = 1.0511275206474548, disc_loss = 0.0052530275796480634
Trained batch 94 in epoch 1, gen_loss = 1.0510101174053392, disc_loss = 0.005261067889238659
Trained batch 95 in epoch 1, gen_loss = 1.0512509550899267, disc_loss = 0.005272761186157974
Trained batch 96 in epoch 1, gen_loss = 1.0513799417879164, disc_loss = 0.005278777364718238
Trained batch 97 in epoch 1, gen_loss = 1.0512392405344515, disc_loss = 0.005279062786234581
Trained batch 98 in epoch 1, gen_loss = 1.0511634331760984, disc_loss = 0.005275242966646799
Trained batch 99 in epoch 1, gen_loss = 1.050720403790474, disc_loss = 0.005267307213507592
Trained batch 100 in epoch 1, gen_loss = 1.0510895092888635, disc_loss = 0.0052724906778202785
Trained batch 101 in epoch 1, gen_loss = 1.050534130895839, disc_loss = 0.005280814722509068
Trained batch 102 in epoch 1, gen_loss = 1.0506960147792854, disc_loss = 0.005281926218637274
Trained batch 103 in epoch 1, gen_loss = 1.0508184415789752, disc_loss = 0.005279550418400994
Trained batch 104 in epoch 1, gen_loss = 1.0511690803936549, disc_loss = 0.005283124443321001
Trained batch 105 in epoch 1, gen_loss = 1.051094629292218, disc_loss = 0.005288296756949628
Trained batch 106 in epoch 1, gen_loss = 1.0510970838716096, disc_loss = 0.0052980837307731125
Trained batch 107 in epoch 1, gen_loss = 1.0511335140025173, disc_loss = 0.005302309908007306
Trained batch 108 in epoch 1, gen_loss = 1.052086102306296, disc_loss = 0.005322437216485038
Trained batch 109 in epoch 1, gen_loss = 1.052197671478445, disc_loss = 0.005347912906753746
Trained batch 110 in epoch 1, gen_loss = 1.0523145408243746, disc_loss = 0.005386079078422742
Trained batch 111 in epoch 1, gen_loss = 1.0524916260370187, disc_loss = 0.005444378022470379
Trained batch 112 in epoch 1, gen_loss = 1.0528980604315226, disc_loss = 0.005521086930602262
Trained batch 113 in epoch 1, gen_loss = 1.0531570916635948, disc_loss = 0.005616190896385856
Trained batch 114 in epoch 1, gen_loss = 1.053205957101739, disc_loss = 0.00576153754297158
Trained batch 115 in epoch 1, gen_loss = 1.053534156803427, disc_loss = 0.006070931092835963
Trained batch 116 in epoch 1, gen_loss = 1.0535540626599238, disc_loss = 0.006750218956293459
Trained batch 117 in epoch 1, gen_loss = 1.0542118140196397, disc_loss = 0.007689432639597079
Trained batch 118 in epoch 1, gen_loss = 1.054427304688622, disc_loss = 0.008051966234822483
Trained batch 119 in epoch 1, gen_loss = 1.0546096806724867, disc_loss = 0.008095717325340956
Trained batch 120 in epoch 1, gen_loss = 1.0546200171975064, disc_loss = 0.00813442158074049
Trained batch 121 in epoch 1, gen_loss = 1.0545538952116107, disc_loss = 0.00812850566199202
Trained batch 122 in epoch 1, gen_loss = 1.0545548360522201, disc_loss = 0.008104019181242561
Trained batch 123 in epoch 1, gen_loss = 1.0545462922703834, disc_loss = 0.008086711232129845
Trained batch 124 in epoch 1, gen_loss = 1.054672471523285, disc_loss = 0.008063577644526958
Trained batch 125 in epoch 1, gen_loss = 1.0546504140846313, disc_loss = 0.008039133043013631
Trained batch 126 in epoch 1, gen_loss = 1.054572869942883, disc_loss = 0.008001506559580094
Trained batch 127 in epoch 1, gen_loss = 1.0546887847594917, disc_loss = 0.00796743415776291
Trained batch 128 in epoch 1, gen_loss = 1.0548826285110888, disc_loss = 0.007937464834183686
Trained batch 129 in epoch 1, gen_loss = 1.0551461792909183, disc_loss = 0.007911256858362602
Trained batch 130 in epoch 1, gen_loss = 1.0552139286776536, disc_loss = 0.007876678668531298
Trained batch 131 in epoch 1, gen_loss = 1.055217190673857, disc_loss = 0.007843254622650531
Trained batch 132 in epoch 1, gen_loss = 1.0552591269177602, disc_loss = 0.007812207790539789
Trained batch 133 in epoch 1, gen_loss = 1.0550947594108866, disc_loss = 0.007789390795836364
Trained batch 134 in epoch 1, gen_loss = 1.0553198633370575, disc_loss = 0.007760473783990299
Trained batch 135 in epoch 1, gen_loss = 1.0550893540768063, disc_loss = 0.007732058873550747
Trained batch 136 in epoch 1, gen_loss = 1.0548069820786914, disc_loss = 0.007700996757247044
Trained batch 137 in epoch 1, gen_loss = 1.0546597514463507, disc_loss = 0.007669473242392574
Trained batch 138 in epoch 1, gen_loss = 1.0547930992764534, disc_loss = 0.007642013781281898
Trained batch 139 in epoch 1, gen_loss = 1.0547902554273605, disc_loss = 0.007611953004795525
Trained batch 140 in epoch 1, gen_loss = 1.0547883464089522, disc_loss = 0.007576222077395159
Trained batch 141 in epoch 1, gen_loss = 1.0549172620538254, disc_loss = 0.007544273545007995
Trained batch 142 in epoch 1, gen_loss = 1.0552452590082075, disc_loss = 0.007519375111165268
Trained batch 143 in epoch 1, gen_loss = 1.055139219181405, disc_loss = 0.007496791136670961
Trained batch 144 in epoch 1, gen_loss = 1.0553309050099604, disc_loss = 0.0074699907643913195
Trained batch 145 in epoch 1, gen_loss = 1.055346623267213, disc_loss = 0.007449771451432104
Trained batch 146 in epoch 1, gen_loss = 1.0553586576260676, disc_loss = 0.007433794430919549
Trained batch 147 in epoch 1, gen_loss = 1.055426103440491, disc_loss = 0.007417885641680678
Trained batch 148 in epoch 1, gen_loss = 1.0555383507037324, disc_loss = 0.007398011858243771
Trained batch 149 in epoch 1, gen_loss = 1.0554442139466604, disc_loss = 0.007371385248067478
Trained batch 150 in epoch 1, gen_loss = 1.055353690851603, disc_loss = 0.007342919821400714
Trained batch 151 in epoch 1, gen_loss = 1.0553244560172683, disc_loss = 0.0073109508942396035
Trained batch 152 in epoch 1, gen_loss = 1.0554481990197127, disc_loss = 0.007278644755251365
Trained batch 153 in epoch 1, gen_loss = 1.0554316543139421, disc_loss = 0.00724515372240166
Trained batch 154 in epoch 1, gen_loss = 1.055554106543141, disc_loss = 0.00721233471356813
Trained batch 155 in epoch 1, gen_loss = 1.05556365274466, disc_loss = 0.007180241255973203
Trained batch 156 in epoch 1, gen_loss = 1.0556183707941869, disc_loss = 0.007147914988054022
Trained batch 157 in epoch 1, gen_loss = 1.0556877100769477, disc_loss = 0.007119593332828128
Trained batch 158 in epoch 1, gen_loss = 1.0558085760230538, disc_loss = 0.0070903222501254495
Trained batch 159 in epoch 1, gen_loss = 1.0558694820851087, disc_loss = 0.007058911432977766
Trained batch 160 in epoch 1, gen_loss = 1.0559658378547763, disc_loss = 0.007027814034603953
Trained batch 161 in epoch 1, gen_loss = 1.055933216103801, disc_loss = 0.00699622932114397
Trained batch 162 in epoch 1, gen_loss = 1.0557406325281764, disc_loss = 0.00696718440379696
Trained batch 163 in epoch 1, gen_loss = 1.0556504722775482, disc_loss = 0.006938875131820124
Trained batch 164 in epoch 1, gen_loss = 1.0555827881350661, disc_loss = 0.00690937633343944
Trained batch 165 in epoch 1, gen_loss = 1.0555440277220256, disc_loss = 0.006880366155058594
Trained batch 166 in epoch 1, gen_loss = 1.055574197612123, disc_loss = 0.006853512531525628
Trained batch 167 in epoch 1, gen_loss = 1.0556426924609004, disc_loss = 0.006825810007285327
Trained batch 168 in epoch 1, gen_loss = 1.0558385323490618, disc_loss = 0.006799470164851677
Trained batch 169 in epoch 1, gen_loss = 1.0557334391509785, disc_loss = 0.006772367302876185
Trained batch 170 in epoch 1, gen_loss = 1.0556222984665318, disc_loss = 0.006745409032558663
Trained batch 171 in epoch 1, gen_loss = 1.055511373766633, disc_loss = 0.006718064127706511
Trained batch 172 in epoch 1, gen_loss = 1.0553421770906173, disc_loss = 0.006690938421390477
Trained batch 173 in epoch 1, gen_loss = 1.0553085971837757, disc_loss = 0.006665760736869669
Trained batch 174 in epoch 1, gen_loss = 1.0553370002337865, disc_loss = 0.0066402821748384406
Trained batch 175 in epoch 1, gen_loss = 1.0554986802691764, disc_loss = 0.006618908925288865
Trained batch 176 in epoch 1, gen_loss = 1.0555955498232006, disc_loss = 0.006600174601689654
Trained batch 177 in epoch 1, gen_loss = 1.0554196482963776, disc_loss = 0.006579269729606974
Trained batch 178 in epoch 1, gen_loss = 1.0553672603388737, disc_loss = 0.00655749000416413
Trained batch 179 in epoch 1, gen_loss = 1.0555285649167168, disc_loss = 0.006538040042182224
Trained batch 180 in epoch 1, gen_loss = 1.05539922918404, disc_loss = 0.006514628951628152
Trained batch 181 in epoch 1, gen_loss = 1.0553349161541068, disc_loss = 0.006488503510219424
Trained batch 182 in epoch 1, gen_loss = 1.0555172862250948, disc_loss = 0.006465108582337738
Trained batch 183 in epoch 1, gen_loss = 1.0555081364253294, disc_loss = 0.006442317876423223
Trained batch 184 in epoch 1, gen_loss = 1.0556470229819015, disc_loss = 0.006421924063407287
Trained batch 185 in epoch 1, gen_loss = 1.0557697732602396, disc_loss = 0.006402063892618503
Trained batch 186 in epoch 1, gen_loss = 1.0558158041321657, disc_loss = 0.006383440954695371
Trained batch 187 in epoch 1, gen_loss = 1.0559381706283448, disc_loss = 0.006366775716045633
Trained batch 188 in epoch 1, gen_loss = 1.055866227894233, disc_loss = 0.006347890510273083
Trained batch 189 in epoch 1, gen_loss = 1.0558284988528803, disc_loss = 0.006326381235358942
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 1.0422279834747314, disc_loss = 0.001808548578992486
Trained batch 1 in epoch 2, gen_loss = 1.0629624724388123, disc_loss = 0.0020256167044863105
Trained batch 2 in epoch 2, gen_loss = 1.0550294319788616, disc_loss = 0.0019465313913921516
Trained batch 3 in epoch 2, gen_loss = 1.058900237083435, disc_loss = 0.0019119163625873625
Trained batch 4 in epoch 2, gen_loss = 1.0592308044433594, disc_loss = 0.0018853412242606283
Trained batch 5 in epoch 2, gen_loss = 1.0636239449183147, disc_loss = 0.0018422855258298416
Trained batch 6 in epoch 2, gen_loss = 1.062390957559858, disc_loss = 0.0018131215557722108
Trained batch 7 in epoch 2, gen_loss = 1.0608379691839218, disc_loss = 0.0017913995106937364
Trained batch 8 in epoch 2, gen_loss = 1.0589307281706068, disc_loss = 0.0017777864122763276
Trained batch 9 in epoch 2, gen_loss = 1.0558964133262634, disc_loss = 0.0017696538940072059
Trained batch 10 in epoch 2, gen_loss = 1.0572543035853992, disc_loss = 0.0017743758666752415
Trained batch 11 in epoch 2, gen_loss = 1.0557118554910023, disc_loss = 0.0017724558031962563
Trained batch 12 in epoch 2, gen_loss = 1.054296695269071, disc_loss = 0.001742812366081545
Trained batch 13 in epoch 2, gen_loss = 1.0575421452522278, disc_loss = 0.0017836681716809316
Trained batch 14 in epoch 2, gen_loss = 1.0519177953402201, disc_loss = 0.0018179537495598198
Trained batch 15 in epoch 2, gen_loss = 1.0521542318165302, disc_loss = 0.0018731719974312
Trained batch 16 in epoch 2, gen_loss = 1.0535766832968767, disc_loss = 0.0019049461150322767
Trained batch 17 in epoch 2, gen_loss = 1.0529017945130665, disc_loss = 0.0019034158968780604
Trained batch 18 in epoch 2, gen_loss = 1.0530547876107066, disc_loss = 0.0018844734264635726
Trained batch 19 in epoch 2, gen_loss = 1.051998308300972, disc_loss = 0.0018615610199049116
Trained batch 20 in epoch 2, gen_loss = 1.0512009717169262, disc_loss = 0.001845426247676923
Trained batch 21 in epoch 2, gen_loss = 1.0514572777531364, disc_loss = 0.0018402252727272835
Trained batch 22 in epoch 2, gen_loss = 1.0526043306226316, disc_loss = 0.0018424239343680117
Trained batch 23 in epoch 2, gen_loss = 1.0534468318025272, disc_loss = 0.0018508042218551661
Trained batch 24 in epoch 2, gen_loss = 1.052634165287018, disc_loss = 0.0018442017352208494
Trained batch 25 in epoch 2, gen_loss = 1.0536692899007063, disc_loss = 0.0018496872060215818
Trained batch 26 in epoch 2, gen_loss = 1.0532460764602378, disc_loss = 0.001858049525051481
Trained batch 27 in epoch 2, gen_loss = 1.054772668651172, disc_loss = 0.001903592438403783
Trained batch 28 in epoch 2, gen_loss = 1.0543973548658963, disc_loss = 0.0019983491852301463
Trained batch 29 in epoch 2, gen_loss = 1.0567833046118418, disc_loss = 0.0021496189098494747
Trained batch 30 in epoch 2, gen_loss = 1.0572991044290605, disc_loss = 0.0022606986927829922
Trained batch 31 in epoch 2, gen_loss = 1.0569454487413168, disc_loss = 0.0023424965438607614
Trained batch 32 in epoch 2, gen_loss = 1.0564530419580864, disc_loss = 0.002376127003861422
Trained batch 33 in epoch 2, gen_loss = 1.0568976349690382, disc_loss = 0.0024008968372500558
Trained batch 34 in epoch 2, gen_loss = 1.0567760280200413, disc_loss = 0.0024077764346397347
Trained batch 35 in epoch 2, gen_loss = 1.0568662302361593, disc_loss = 0.0023905305424705148
Trained batch 36 in epoch 2, gen_loss = 1.056312163133879, disc_loss = 0.0023808255665809723
Trained batch 37 in epoch 2, gen_loss = 1.0565526752095473, disc_loss = 0.0023643485435872877
Trained batch 38 in epoch 2, gen_loss = 1.0564664923227751, disc_loss = 0.0023412781301885843
Trained batch 39 in epoch 2, gen_loss = 1.0564863190054894, disc_loss = 0.0023207892692880703
Trained batch 40 in epoch 2, gen_loss = 1.0563349011467724, disc_loss = 0.002299878206785496
Trained batch 41 in epoch 2, gen_loss = 1.0553650614761172, disc_loss = 0.0022815452982848953
Trained batch 42 in epoch 2, gen_loss = 1.0551973151606182, disc_loss = 0.0022824956131232686
Trained batch 43 in epoch 2, gen_loss = 1.0548247247934341, disc_loss = 0.002272958295758475
Trained batch 44 in epoch 2, gen_loss = 1.0546242939101325, disc_loss = 0.0022596884803432558
Trained batch 45 in epoch 2, gen_loss = 1.0550209270871205, disc_loss = 0.002248519335610225
Trained batch 46 in epoch 2, gen_loss = 1.0554946369313178, disc_loss = 0.0022380203925112777
Trained batch 47 in epoch 2, gen_loss = 1.0550706821183364, disc_loss = 0.002228173424858445
Trained batch 48 in epoch 2, gen_loss = 1.0546254272363624, disc_loss = 0.002215792401218597
Trained batch 49 in epoch 2, gen_loss = 1.0548690783977508, disc_loss = 0.0022021475760266186
Trained batch 50 in epoch 2, gen_loss = 1.0547659198443096, disc_loss = 0.002188870156019488
Trained batch 51 in epoch 2, gen_loss = 1.053780829677215, disc_loss = 0.002171087497397541
Trained batch 52 in epoch 2, gen_loss = 1.0535062855144717, disc_loss = 0.0021570148803117984
Trained batch 53 in epoch 2, gen_loss = 1.0531090376553711, disc_loss = 0.0021482663923288107
Trained batch 54 in epoch 2, gen_loss = 1.0519848465919495, disc_loss = 0.002139536949636584
Trained batch 55 in epoch 2, gen_loss = 1.0518974012562208, disc_loss = 0.0021227999386610463
Trained batch 56 in epoch 2, gen_loss = 1.051530947810725, disc_loss = 0.002107130765931256
Trained batch 57 in epoch 2, gen_loss = 1.0514453680350864, disc_loss = 0.002091409548201823
Trained batch 58 in epoch 2, gen_loss = 1.0513077539912725, disc_loss = 0.00207809629352858
Trained batch 59 in epoch 2, gen_loss = 1.05080746114254, disc_loss = 0.0020642113930080088
Trained batch 60 in epoch 2, gen_loss = 1.0499922887223665, disc_loss = 0.002054917610815314
Trained batch 61 in epoch 2, gen_loss = 1.0495377442529124, disc_loss = 0.0020404713220834253
Trained batch 62 in epoch 2, gen_loss = 1.0488820766645766, disc_loss = 0.002028178650930169
Trained batch 63 in epoch 2, gen_loss = 1.0489260600879788, disc_loss = 0.0020388709508551983
Trained batch 64 in epoch 2, gen_loss = 1.0491037708062392, disc_loss = 0.0020456183361462674
Trained batch 65 in epoch 2, gen_loss = 1.0489511047348832, disc_loss = 0.002037409701822043
Trained batch 66 in epoch 2, gen_loss = 1.0492957874910156, disc_loss = 0.002032330035537815
Trained batch 67 in epoch 2, gen_loss = 1.0496675486073774, disc_loss = 0.002032539202927557
Trained batch 68 in epoch 2, gen_loss = 1.0491387109825576, disc_loss = 0.0020248579499109283
Trained batch 69 in epoch 2, gen_loss = 1.0486825389521464, disc_loss = 0.00201562203832769
Trained batch 70 in epoch 2, gen_loss = 1.0485413720909977, disc_loss = 0.0020112419241881917
Trained batch 71 in epoch 2, gen_loss = 1.0483270924952295, disc_loss = 0.0020049346219618907
Trained batch 72 in epoch 2, gen_loss = 1.0482275232876817, disc_loss = 0.001996805714379537
Trained batch 73 in epoch 2, gen_loss = 1.0482119684283797, disc_loss = 0.001991429116035736
Trained batch 74 in epoch 2, gen_loss = 1.0479801456133524, disc_loss = 0.0019855170091614125
Trained batch 75 in epoch 2, gen_loss = 1.0475577782643468, disc_loss = 0.0019789002912339606
Trained batch 76 in epoch 2, gen_loss = 1.0471912521820563, disc_loss = 0.001969823887414456
Trained batch 77 in epoch 2, gen_loss = 1.0462989264573805, disc_loss = 0.0019658376829913603
Trained batch 78 in epoch 2, gen_loss = 1.0465171752096731, disc_loss = 0.001962345868608431
Trained batch 79 in epoch 2, gen_loss = 1.0464960761368274, disc_loss = 0.001963115012040362
Trained batch 80 in epoch 2, gen_loss = 1.0465269419882033, disc_loss = 0.001969897283103179
Trained batch 81 in epoch 2, gen_loss = 1.0465717613697052, disc_loss = 0.001980244698820681
Trained batch 82 in epoch 2, gen_loss = 1.0461523712399494, disc_loss = 0.00198475100346897
Trained batch 83 in epoch 2, gen_loss = 1.0461028594346273, disc_loss = 0.0019837208369392016
Trained batch 84 in epoch 2, gen_loss = 1.0455663744141073, disc_loss = 0.001982475432348164
Trained batch 85 in epoch 2, gen_loss = 1.0456282711306284, disc_loss = 0.001984058818400859
Trained batch 86 in epoch 2, gen_loss = 1.0450992426653019, disc_loss = 0.0019838185030859948
Trained batch 87 in epoch 2, gen_loss = 1.0446472052823415, disc_loss = 0.001983922695878639
Trained batch 88 in epoch 2, gen_loss = 1.044329741697633, disc_loss = 0.0019822588538374293
Trained batch 89 in epoch 2, gen_loss = 1.043879007630878, disc_loss = 0.0019781249536511797
Trained batch 90 in epoch 2, gen_loss = 1.0432966469408391, disc_loss = 0.001974164068207636
Trained batch 91 in epoch 2, gen_loss = 1.0435138558563979, disc_loss = 0.001968673720156126
Trained batch 92 in epoch 2, gen_loss = 1.0428998374169873, disc_loss = 0.001965153084877598
Trained batch 93 in epoch 2, gen_loss = 1.0423272372560297, disc_loss = 0.001964110307682781
Trained batch 94 in epoch 2, gen_loss = 1.0419532907636542, disc_loss = 0.0019624960523000673
Trained batch 95 in epoch 2, gen_loss = 1.0418598620841901, disc_loss = 0.0019610709459811915
Trained batch 96 in epoch 2, gen_loss = 1.0420748443947625, disc_loss = 0.0019563244230872425
Trained batch 97 in epoch 2, gen_loss = 1.0417200673599631, disc_loss = 0.0019494680561866536
Trained batch 98 in epoch 2, gen_loss = 1.041493453762748, disc_loss = 0.0019487447018330596
Trained batch 99 in epoch 2, gen_loss = 1.0407961428165435, disc_loss = 0.0019508695031981915
Trained batch 100 in epoch 2, gen_loss = 1.0407057587463078, disc_loss = 0.0019581385203498868
Trained batch 101 in epoch 2, gen_loss = 1.040455051496917, disc_loss = 0.0019628058824523844
Trained batch 102 in epoch 2, gen_loss = 1.0403810380731973, disc_loss = 0.001960801728096908
Trained batch 103 in epoch 2, gen_loss = 1.0401919828011439, disc_loss = 0.00195551300734783
Trained batch 104 in epoch 2, gen_loss = 1.0400319337844848, disc_loss = 0.0019505509951462348
Trained batch 105 in epoch 2, gen_loss = 1.039863018494732, disc_loss = 0.0019465049922044546
Trained batch 106 in epoch 2, gen_loss = 1.040022782076185, disc_loss = 0.0019435152307013485
Trained batch 107 in epoch 2, gen_loss = 1.0397926690401855, disc_loss = 0.0019382029012949378
Trained batch 108 in epoch 2, gen_loss = 1.0395718659829656, disc_loss = 0.0019304327070798486
Trained batch 109 in epoch 2, gen_loss = 1.0392799810929731, disc_loss = 0.0019241277033209124
Trained batch 110 in epoch 2, gen_loss = 1.0392350312825795, disc_loss = 0.0019183662103338015
Trained batch 111 in epoch 2, gen_loss = 1.0390952208212443, disc_loss = 0.0019120200366679846
Trained batch 112 in epoch 2, gen_loss = 1.03893889157118, disc_loss = 0.0019057040459237399
Trained batch 113 in epoch 2, gen_loss = 1.038779602761854, disc_loss = 0.0018996332778203253
Trained batch 114 in epoch 2, gen_loss = 1.0386838094047879, disc_loss = 0.0018944542024932477
Trained batch 115 in epoch 2, gen_loss = 1.0380371326002582, disc_loss = 0.0018889477269740068
Trained batch 116 in epoch 2, gen_loss = 1.0382207265267005, disc_loss = 0.0018900174410759001
Trained batch 117 in epoch 2, gen_loss = 1.0381084306765411, disc_loss = 0.0018875817501901697
Trained batch 118 in epoch 2, gen_loss = 1.0377331781788033, disc_loss = 0.0018826882079040178
Trained batch 119 in epoch 2, gen_loss = 1.0372129514813424, disc_loss = 0.0018777680010922874
Trained batch 120 in epoch 2, gen_loss = 1.0368019633056704, disc_loss = 0.0018763164114130061
Trained batch 121 in epoch 2, gen_loss = 1.0367728066248971, disc_loss = 0.001888209802182544
Trained batch 122 in epoch 2, gen_loss = 1.0367761535373161, disc_loss = 0.0019110024620862147
Trained batch 123 in epoch 2, gen_loss = 1.0366269470222536, disc_loss = 0.001932081819940058
Trained batch 124 in epoch 2, gen_loss = 1.0368655877113342, disc_loss = 0.0019428106369450688
Trained batch 125 in epoch 2, gen_loss = 1.0365925615742093, disc_loss = 0.0019437815367598973
Trained batch 126 in epoch 2, gen_loss = 1.0365754098404112, disc_loss = 0.00194205226207988
Trained batch 127 in epoch 2, gen_loss = 1.036470024380833, disc_loss = 0.001941866599736386
Trained batch 128 in epoch 2, gen_loss = 1.035884099413258, disc_loss = 0.001941980658705498
Trained batch 129 in epoch 2, gen_loss = 1.0356013050446145, disc_loss = 0.0019430031211903462
Trained batch 130 in epoch 2, gen_loss = 1.0353244388376484, disc_loss = 0.00195419670878874
Trained batch 131 in epoch 2, gen_loss = 1.0346945867393955, disc_loss = 0.001959523896926619
Trained batch 132 in epoch 2, gen_loss = 1.0343319061107206, disc_loss = 0.0019627174859712447
Trained batch 133 in epoch 2, gen_loss = 1.0341684907229978, disc_loss = 0.001966243091998483
Trained batch 134 in epoch 2, gen_loss = 1.0340278925719084, disc_loss = 0.0019656660552654004
Trained batch 135 in epoch 2, gen_loss = 1.033897967023008, disc_loss = 0.001962779920123627
Trained batch 136 in epoch 2, gen_loss = 1.0337969969658956, disc_loss = 0.0019596057237010367
Trained batch 137 in epoch 2, gen_loss = 1.0333669945813608, disc_loss = 0.0019559492163049677
Trained batch 138 in epoch 2, gen_loss = 1.0353737837976689, disc_loss = 0.0019794910712328424
Trained batch 139 in epoch 2, gen_loss = 1.0358196582112993, disc_loss = 0.001991448143131233
Trained batch 140 in epoch 2, gen_loss = 1.0362343619055783, disc_loss = 0.0020047152515646097
Trained batch 141 in epoch 2, gen_loss = 1.036228791089125, disc_loss = 0.002011074341053117
Trained batch 142 in epoch 2, gen_loss = 1.0359891169554705, disc_loss = 0.0020134514205848108
Trained batch 143 in epoch 2, gen_loss = 1.0362550525201693, disc_loss = 0.00201486963083476
Trained batch 144 in epoch 2, gen_loss = 1.0363285557977084, disc_loss = 0.002011931620955724
Trained batch 145 in epoch 2, gen_loss = 1.0364888775838565, disc_loss = 0.002007915907099282
Trained batch 146 in epoch 2, gen_loss = 1.0365128663121437, disc_loss = 0.002005737240831716
Trained batch 147 in epoch 2, gen_loss = 1.0364229646888938, disc_loss = 0.0020084998049660005
Trained batch 148 in epoch 2, gen_loss = 1.0365164279937744, disc_loss = 0.002011470331797914
Trained batch 149 in epoch 2, gen_loss = 1.0365118821461996, disc_loss = 0.0020097226928919554
Trained batch 150 in epoch 2, gen_loss = 1.0365997181822921, disc_loss = 0.0020052019078037795
Trained batch 151 in epoch 2, gen_loss = 1.0368877759105282, disc_loss = 0.002000796582586573
Trained batch 152 in epoch 2, gen_loss = 1.03690030138477, disc_loss = 0.0019982405512112807
Trained batch 153 in epoch 2, gen_loss = 1.036949184807864, disc_loss = 0.001994708787299112
Trained batch 154 in epoch 2, gen_loss = 1.0369568647876863, disc_loss = 0.0019910544510029497
Trained batch 155 in epoch 2, gen_loss = 1.0369187631668189, disc_loss = 0.0019898029232326034
Trained batch 156 in epoch 2, gen_loss = 1.0369357235112768, disc_loss = 0.001986927268314798
Trained batch 157 in epoch 2, gen_loss = 1.0367513517790203, disc_loss = 0.0019840244299590684
Trained batch 158 in epoch 2, gen_loss = 1.0368002683111706, disc_loss = 0.0019825948709797747
Trained batch 159 in epoch 2, gen_loss = 1.0370477467775345, disc_loss = 0.001980228698084829
Trained batch 160 in epoch 2, gen_loss = 1.0369281376370731, disc_loss = 0.001977955286900125
Trained batch 161 in epoch 2, gen_loss = 1.0368028349346585, disc_loss = 0.001974179408725719
Trained batch 162 in epoch 2, gen_loss = 1.036694121507048, disc_loss = 0.0019706754203874365
Trained batch 163 in epoch 2, gen_loss = 1.0365052208667849, disc_loss = 0.001965521653779078
Trained batch 164 in epoch 2, gen_loss = 1.0365644758397883, disc_loss = 0.001960930117462395
Trained batch 165 in epoch 2, gen_loss = 1.0365213371184936, disc_loss = 0.0019562269023799123
Trained batch 166 in epoch 2, gen_loss = 1.036155704252734, disc_loss = 0.001953556852744234
Trained batch 167 in epoch 2, gen_loss = 1.0360125665153777, disc_loss = 0.0019505883025149593
Trained batch 168 in epoch 2, gen_loss = 1.0361425192398432, disc_loss = 0.0019485472202763932
Trained batch 169 in epoch 2, gen_loss = 1.0361315551926107, disc_loss = 0.0019444701837047058
Trained batch 170 in epoch 2, gen_loss = 1.0362615843265377, disc_loss = 0.0019441235678444742
Trained batch 171 in epoch 2, gen_loss = 1.036491601273071, disc_loss = 0.001945906843269937
Trained batch 172 in epoch 2, gen_loss = 1.0364260921588522, disc_loss = 0.001948177655001381
Trained batch 173 in epoch 2, gen_loss = 1.0365796623558834, disc_loss = 0.0019492236408940248
Trained batch 174 in epoch 2, gen_loss = 1.036688961301531, disc_loss = 0.0019475335355049798
Trained batch 175 in epoch 2, gen_loss = 1.0367302921685306, disc_loss = 0.0019442459220458245
Trained batch 176 in epoch 2, gen_loss = 1.0367226425537281, disc_loss = 0.0019410114609083888
Trained batch 177 in epoch 2, gen_loss = 1.0368880060281647, disc_loss = 0.001937803546793424
Trained batch 178 in epoch 2, gen_loss = 1.0367982747168514, disc_loss = 0.0019334230927084495
Trained batch 179 in epoch 2, gen_loss = 1.0367550591627757, disc_loss = 0.001933036311270876
Trained batch 180 in epoch 2, gen_loss = 1.0368765276439942, disc_loss = 0.0019355391213948226
Trained batch 181 in epoch 2, gen_loss = 1.036877765760317, disc_loss = 0.0019358456567195909
Trained batch 182 in epoch 2, gen_loss = 1.0370171513062356, disc_loss = 0.0019331617214681347
Trained batch 183 in epoch 2, gen_loss = 1.0370215838370116, disc_loss = 0.0019311990909045562
Trained batch 184 in epoch 2, gen_loss = 1.0370544317606334, disc_loss = 0.0019316570285858737
Trained batch 185 in epoch 2, gen_loss = 1.0367738268067759, disc_loss = 0.0019321461409700894
Trained batch 186 in epoch 2, gen_loss = 1.036496253893337, disc_loss = 0.001932799496767634
Trained batch 187 in epoch 2, gen_loss = 1.0364893240497468, disc_loss = 0.001929734424846445
Trained batch 188 in epoch 2, gen_loss = 1.0368654800470545, disc_loss = 0.0019284795653124256
Trained batch 189 in epoch 2, gen_loss = 1.036831603238457, disc_loss = 0.00193390277349145
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 1.0506172180175781, disc_loss = 0.0053742416203022
Trained batch 1 in epoch 3, gen_loss = 1.0380097031593323, disc_loss = 0.005270752124488354
Trained batch 2 in epoch 3, gen_loss = 1.0455905596415203, disc_loss = 0.004976348020136356
Trained batch 3 in epoch 3, gen_loss = 1.0440998673439026, disc_loss = 0.004628536349628121
Trained batch 4 in epoch 3, gen_loss = 1.0313422918319701, disc_loss = 0.004184802249073982
Trained batch 5 in epoch 3, gen_loss = 1.0359951456387837, disc_loss = 0.003802016784902662
Trained batch 6 in epoch 3, gen_loss = 1.0353575944900513, disc_loss = 0.0035971040737682153
Trained batch 7 in epoch 3, gen_loss = 1.042972132563591, disc_loss = 0.0035473770840326324
Trained batch 8 in epoch 3, gen_loss = 1.0402309232287936, disc_loss = 0.003499734797514975
Trained batch 9 in epoch 3, gen_loss = 1.0462993264198304, disc_loss = 0.0034817220526747405
Trained batch 10 in epoch 3, gen_loss = 1.0458701090379194, disc_loss = 0.003453543399121951
Trained batch 11 in epoch 3, gen_loss = 1.0456127524375916, disc_loss = 0.0034266851434949785
Trained batch 12 in epoch 3, gen_loss = 1.042780903669504, disc_loss = 0.003346998378849373
Trained batch 13 in epoch 3, gen_loss = 1.0416791013308935, disc_loss = 0.0032374330247486277
Trained batch 14 in epoch 3, gen_loss = 1.0433887084325155, disc_loss = 0.0031378200200075906
Trained batch 15 in epoch 3, gen_loss = 1.0432889088988304, disc_loss = 0.0030537125130649656
Trained batch 16 in epoch 3, gen_loss = 1.0399714007097132, disc_loss = 0.0030079965260537233
Trained batch 17 in epoch 3, gen_loss = 1.0377862850824993, disc_loss = 0.0029823758846355807
Trained batch 18 in epoch 3, gen_loss = 1.036286241129825, disc_loss = 0.0029673332495516853
Trained batch 19 in epoch 3, gen_loss = 1.034435075521469, disc_loss = 0.002960044587962329
Trained batch 20 in epoch 3, gen_loss = 1.03283649399167, disc_loss = 0.0029723182808430422
Trained batch 21 in epoch 3, gen_loss = 1.033387541770935, disc_loss = 0.0029882537412711167
Trained batch 22 in epoch 3, gen_loss = 1.0313715260961782, disc_loss = 0.0029769291109202995
Trained batch 23 in epoch 3, gen_loss = 1.030868684252103, disc_loss = 0.0029831666712804386
Trained batch 24 in epoch 3, gen_loss = 1.030929684638977, disc_loss = 0.0030111356452107428
Trained batch 25 in epoch 3, gen_loss = 1.0296577581992516, disc_loss = 0.0030260015852176226
Trained batch 26 in epoch 3, gen_loss = 1.0283288801157917, disc_loss = 0.003007376721749703
Trained batch 27 in epoch 3, gen_loss = 1.0274187943765096, disc_loss = 0.0029748637628342423
Trained batch 28 in epoch 3, gen_loss = 1.027121550050275, disc_loss = 0.002946659633568649
Trained batch 29 in epoch 3, gen_loss = 1.0270671506722768, disc_loss = 0.002902895538136363
Trained batch 30 in epoch 3, gen_loss = 1.0277845532663408, disc_loss = 0.0028466343233782437
Trained batch 31 in epoch 3, gen_loss = 1.0266358386725187, disc_loss = 0.0028025585525028873
Trained batch 32 in epoch 3, gen_loss = 1.0257744536255344, disc_loss = 0.002763076434899686
Trained batch 33 in epoch 3, gen_loss = 1.025551305097692, disc_loss = 0.002714094750391429
Trained batch 34 in epoch 3, gen_loss = 1.0259258576801844, disc_loss = 0.00267139940323042
Trained batch 35 in epoch 3, gen_loss = 1.0252472195360396, disc_loss = 0.00263145115524013
Trained batch 36 in epoch 3, gen_loss = 1.024494375731494, disc_loss = 0.0025861054356839204
Trained batch 37 in epoch 3, gen_loss = 1.024972035696632, disc_loss = 0.002550978415743693
Trained batch 38 in epoch 3, gen_loss = 1.0253787636756897, disc_loss = 0.0025166133627629816
Trained batch 39 in epoch 3, gen_loss = 1.024251762032509, disc_loss = 0.002483867813134566
Trained batch 40 in epoch 3, gen_loss = 1.0244017054394978, disc_loss = 0.0024495775322997716
Trained batch 41 in epoch 3, gen_loss = 1.024350711277553, disc_loss = 0.0024169025682134644
Trained batch 42 in epoch 3, gen_loss = 1.0237263260885727, disc_loss = 0.0023901666281744838
Trained batch 43 in epoch 3, gen_loss = 1.0226433710618452, disc_loss = 0.002362225471932272
Trained batch 44 in epoch 3, gen_loss = 1.0227267344792683, disc_loss = 0.0023410581181653673
Trained batch 45 in epoch 3, gen_loss = 1.0227696714193926, disc_loss = 0.002321221326660041
Trained batch 46 in epoch 3, gen_loss = 1.0229812784397856, disc_loss = 0.0022969169448070386
Trained batch 47 in epoch 3, gen_loss = 1.02269846200943, disc_loss = 0.002274220113273865
Trained batch 48 in epoch 3, gen_loss = 1.0222957353202664, disc_loss = 0.002253186877113672
Trained batch 49 in epoch 3, gen_loss = 1.0212787580490112, disc_loss = 0.002244138824753463
Trained batch 50 in epoch 3, gen_loss = 1.020737815137003, disc_loss = 0.002253109164645567
Trained batch 51 in epoch 3, gen_loss = 1.0209033775788088, disc_loss = 0.0022480299678416206
Trained batch 52 in epoch 3, gen_loss = 1.0203031099067543, disc_loss = 0.002227080269839685
Trained batch 53 in epoch 3, gen_loss = 1.019519837918105, disc_loss = 0.002209420044285556
Trained batch 54 in epoch 3, gen_loss = 1.0195352066646923, disc_loss = 0.0021892121400345454
Trained batch 55 in epoch 3, gen_loss = 1.0196226782032423, disc_loss = 0.0021686041519777583
Trained batch 56 in epoch 3, gen_loss = 1.019567634975701, disc_loss = 0.0021460127665481545
Trained batch 57 in epoch 3, gen_loss = 1.0191701681449497, disc_loss = 0.002123343822514189
Trained batch 58 in epoch 3, gen_loss = 1.0187981552996879, disc_loss = 0.0021016842555412548
Trained batch 59 in epoch 3, gen_loss = 1.0178772280613582, disc_loss = 0.0020802311463436734
Trained batch 60 in epoch 3, gen_loss = 1.0175550325972136, disc_loss = 0.002062824226488344
Trained batch 61 in epoch 3, gen_loss = 1.0171315496967686, disc_loss = 0.002047103427861246
Trained batch 62 in epoch 3, gen_loss = 1.0178605336991569, disc_loss = 0.002036302330134998
Trained batch 63 in epoch 3, gen_loss = 1.0180120058357716, disc_loss = 0.0020242047121428186
Trained batch 64 in epoch 3, gen_loss = 1.0178381828161387, disc_loss = 0.002009888342581689
Trained batch 65 in epoch 3, gen_loss = 1.0177203796126626, disc_loss = 0.0019955118063301074
Trained batch 66 in epoch 3, gen_loss = 1.01785660323812, disc_loss = 0.0019858398304473776
Trained batch 67 in epoch 3, gen_loss = 1.017398268860929, disc_loss = 0.0019831801935866035
Trained batch 68 in epoch 3, gen_loss = 1.0166738335637078, disc_loss = 0.0019791809524800897
Trained batch 69 in epoch 3, gen_loss = 1.0165516197681428, disc_loss = 0.001967299643105694
Trained batch 70 in epoch 3, gen_loss = 1.0169121203288225, disc_loss = 0.00195364602251162
Trained batch 71 in epoch 3, gen_loss = 1.0166872797740831, disc_loss = 0.001940571775776334
Trained batch 72 in epoch 3, gen_loss = 1.0165951929680288, disc_loss = 0.0019282311287211024
Trained batch 73 in epoch 3, gen_loss = 1.0166460783094973, disc_loss = 0.0019187792865056042
Trained batch 74 in epoch 3, gen_loss = 1.0171726155281067, disc_loss = 0.0019109170014659563
Trained batch 75 in epoch 3, gen_loss = 1.0176229735738354, disc_loss = 0.0019098018743342866
Trained batch 76 in epoch 3, gen_loss = 1.0172988780133136, disc_loss = 0.001913399813551601
Trained batch 77 in epoch 3, gen_loss = 1.0169417965106475, disc_loss = 0.0019193790070951367
Trained batch 78 in epoch 3, gen_loss = 1.0166223215151438, disc_loss = 0.0019230288777594702
Trained batch 79 in epoch 3, gen_loss = 1.0166677206754684, disc_loss = 0.0019203142830519937
Trained batch 80 in epoch 3, gen_loss = 1.0169783654036346, disc_loss = 0.0019137413473799825
Trained batch 81 in epoch 3, gen_loss = 1.016968325870793, disc_loss = 0.0019056385896940966
Trained batch 82 in epoch 3, gen_loss = 1.016694018639714, disc_loss = 0.0018991428772436388
Trained batch 83 in epoch 3, gen_loss = 1.0171068097863878, disc_loss = 0.0018991254813348253
Trained batch 84 in epoch 3, gen_loss = 1.0167700746480157, disc_loss = 0.0018938936210949632
Trained batch 85 in epoch 3, gen_loss = 1.0167321403359257, disc_loss = 0.0018817911433532488
Trained batch 86 in epoch 3, gen_loss = 1.0166237484449627, disc_loss = 0.0018683682227956838
Trained batch 87 in epoch 3, gen_loss = 1.0167211775075307, disc_loss = 0.0018552306964093905
Trained batch 88 in epoch 3, gen_loss = 1.016715809870302, disc_loss = 0.0018431429850628202
Trained batch 89 in epoch 3, gen_loss = 1.0171580784850651, disc_loss = 0.0018347616255697276
Trained batch 90 in epoch 3, gen_loss = 1.0167865419125819, disc_loss = 0.0018311101651576523
Trained batch 91 in epoch 3, gen_loss = 1.0167849562738254, disc_loss = 0.0018237089300426937
Trained batch 92 in epoch 3, gen_loss = 1.0164863851762587, disc_loss = 0.001814069320267487
Trained batch 93 in epoch 3, gen_loss = 1.0169523618322738, disc_loss = 0.0018071161095112405
Trained batch 94 in epoch 3, gen_loss = 1.0172775964987906, disc_loss = 0.0018034221004008463
Trained batch 95 in epoch 3, gen_loss = 1.0173948016017675, disc_loss = 0.0017999680664312716
Trained batch 96 in epoch 3, gen_loss = 1.01778299107994, disc_loss = 0.001795509957333969
Trained batch 97 in epoch 3, gen_loss = 1.0178155905129957, disc_loss = 0.0017981710867500122
Trained batch 98 in epoch 3, gen_loss = 1.018305120444057, disc_loss = 0.0018042366730632506
Trained batch 99 in epoch 3, gen_loss = 1.0182499879598617, disc_loss = 0.0018035445013083518
Trained batch 100 in epoch 3, gen_loss = 1.019124469544628, disc_loss = 0.001806745208836723
Trained batch 101 in epoch 3, gen_loss = 1.0191860169756646, disc_loss = 0.0018050300274683418
Trained batch 102 in epoch 3, gen_loss = 1.0192787317396368, disc_loss = 0.0017987875283686716
Trained batch 103 in epoch 3, gen_loss = 1.0195726884099154, disc_loss = 0.0017916825835037832
Trained batch 104 in epoch 3, gen_loss = 1.0200342535972595, disc_loss = 0.0017861128330142015
Trained batch 105 in epoch 3, gen_loss = 1.0200065481212903, disc_loss = 0.0017798536881048865
Trained batch 106 in epoch 3, gen_loss = 1.0200046261894369, disc_loss = 0.0017720967820610539
Trained batch 107 in epoch 3, gen_loss = 1.020348235964775, disc_loss = 0.0017690481111424527
Trained batch 108 in epoch 3, gen_loss = 1.0205575714417554, disc_loss = 0.0017681023695531788
Trained batch 109 in epoch 3, gen_loss = 1.0208347510207783, disc_loss = 0.0017680522541261533
Trained batch 110 in epoch 3, gen_loss = 1.0210346074791643, disc_loss = 0.0017652992129762162
Trained batch 111 in epoch 3, gen_loss = 1.0213144065013953, disc_loss = 0.0017600129815816348
Trained batch 112 in epoch 3, gen_loss = 1.021438700435436, disc_loss = 0.0017528426385303316
Trained batch 113 in epoch 3, gen_loss = 1.021293285123089, disc_loss = 0.0017467227855313308
Trained batch 114 in epoch 3, gen_loss = 1.0213590129562047, disc_loss = 0.0017424478038700056
Trained batch 115 in epoch 3, gen_loss = 1.021430488804291, disc_loss = 0.0017420794550883423
Trained batch 116 in epoch 3, gen_loss = 1.021348124385899, disc_loss = 0.0017413283876366275
Trained batch 117 in epoch 3, gen_loss = 1.0216685619394659, disc_loss = 0.0017410899592381981
Trained batch 118 in epoch 3, gen_loss = 1.02185018172785, disc_loss = 0.0017442472045262885
Trained batch 119 in epoch 3, gen_loss = 1.0220631485184033, disc_loss = 0.0017514653120694371
Trained batch 120 in epoch 3, gen_loss = 1.021811397115061, disc_loss = 0.0017571194498599623
Trained batch 121 in epoch 3, gen_loss = 1.0219996781622778, disc_loss = 0.0017614581180377634
Trained batch 122 in epoch 3, gen_loss = 1.0224844503208874, disc_loss = 0.0017641950251981312
Trained batch 123 in epoch 3, gen_loss = 1.0229937314025817, disc_loss = 0.0017652672104304656
Trained batch 124 in epoch 3, gen_loss = 1.023156175136566, disc_loss = 0.001762996277306229
Trained batch 125 in epoch 3, gen_loss = 1.0230731240340643, disc_loss = 0.001760768947572196
Trained batch 126 in epoch 3, gen_loss = 1.0229431357909375, disc_loss = 0.0017593163941018871
Trained batch 127 in epoch 3, gen_loss = 1.0228528841398656, disc_loss = 0.0017568918415236112
Trained batch 128 in epoch 3, gen_loss = 1.0224965344103731, disc_loss = 0.0017566560580785017
Trained batch 129 in epoch 3, gen_loss = 1.0226137046630566, disc_loss = 0.0017568514113708471
Trained batch 130 in epoch 3, gen_loss = 1.0223433930455272, disc_loss = 0.0017578649047570204
Trained batch 131 in epoch 3, gen_loss = 1.0222139751369304, disc_loss = 0.001761717186044817
Trained batch 132 in epoch 3, gen_loss = 1.0218570120352553, disc_loss = 0.0017664762344246352
Trained batch 133 in epoch 3, gen_loss = 1.0218577291538467, disc_loss = 0.0017717247277171588
Trained batch 134 in epoch 3, gen_loss = 1.0218269343729371, disc_loss = 0.001772427920648759
Trained batch 135 in epoch 3, gen_loss = 1.0219871853204334, disc_loss = 0.0017705220435506337
Trained batch 136 in epoch 3, gen_loss = 1.0218728141192972, disc_loss = 0.0017660626700576258
Trained batch 137 in epoch 3, gen_loss = 1.0221377814161605, disc_loss = 0.0017613549898142346
Trained batch 138 in epoch 3, gen_loss = 1.0218077679332211, disc_loss = 0.0017552771484110798
Trained batch 139 in epoch 3, gen_loss = 1.021390431693622, disc_loss = 0.0017482864994755281
Trained batch 140 in epoch 3, gen_loss = 1.021732393308734, disc_loss = 0.0017466333534581757
Trained batch 141 in epoch 3, gen_loss = 1.0212535459390828, disc_loss = 0.0017453056496148274
Trained batch 142 in epoch 3, gen_loss = 1.0211928911976047, disc_loss = 0.0017436960414117138
Trained batch 143 in epoch 3, gen_loss = 1.0213399997187986, disc_loss = 0.0017450462287848091
Trained batch 144 in epoch 3, gen_loss = 1.0212763560229334, disc_loss = 0.0017460731147178289
Trained batch 145 in epoch 3, gen_loss = 1.0213234338858357, disc_loss = 0.0017448814134496226
Trained batch 146 in epoch 3, gen_loss = 1.021613237403688, disc_loss = 0.0017438073449318303
Trained batch 147 in epoch 3, gen_loss = 1.0212877851885718, disc_loss = 0.001743800428419097
Trained batch 148 in epoch 3, gen_loss = 1.021251461649901, disc_loss = 0.0017454696619170623
Trained batch 149 in epoch 3, gen_loss = 1.0212087837855022, disc_loss = 0.001748811515669028
Trained batch 150 in epoch 3, gen_loss = 1.0210662330223235, disc_loss = 0.0017531422793322447
Trained batch 151 in epoch 3, gen_loss = 1.0208581301726793, disc_loss = 0.0017583003316662814
Trained batch 152 in epoch 3, gen_loss = 1.021126748689639, disc_loss = 0.001763062505964555
Trained batch 153 in epoch 3, gen_loss = 1.0206704294526732, disc_loss = 0.001764120330713544
Trained batch 154 in epoch 3, gen_loss = 1.0205682485334335, disc_loss = 0.0017646153224632143
Trained batch 155 in epoch 3, gen_loss = 1.02039385224, disc_loss = 0.0017632216727062582
Trained batch 156 in epoch 3, gen_loss = 1.0202591935540462, disc_loss = 0.0017597585920968157
Trained batch 157 in epoch 3, gen_loss = 1.0199303955216952, disc_loss = 0.0017543207799508886
Trained batch 158 in epoch 3, gen_loss = 1.0200264217718593, disc_loss = 0.0017483311495890127
Trained batch 159 in epoch 3, gen_loss = 1.019917667284608, disc_loss = 0.0017415869959222618
Trained batch 160 in epoch 3, gen_loss = 1.0198434172950177, disc_loss = 0.0017350967431163289
Trained batch 161 in epoch 3, gen_loss = 1.0199118149869235, disc_loss = 0.0017294875363370887
Trained batch 162 in epoch 3, gen_loss = 1.0198232677816614, disc_loss = 0.0017252946929560483
Trained batch 163 in epoch 3, gen_loss = 1.019531002131904, disc_loss = 0.0017257615378717098
Trained batch 164 in epoch 3, gen_loss = 1.0195645924770471, disc_loss = 0.0017330607399344445
Trained batch 165 in epoch 3, gen_loss = 1.0193807816649059, disc_loss = 0.0017389720179566957
Trained batch 166 in epoch 3, gen_loss = 1.0193242494931478, disc_loss = 0.0017404159862815798
Trained batch 167 in epoch 3, gen_loss = 1.0192251797942888, disc_loss = 0.001736941453557284
Trained batch 168 in epoch 3, gen_loss = 1.019149846226506, disc_loss = 0.0017318909422263018
Trained batch 169 in epoch 3, gen_loss = 1.0191828612019034, disc_loss = 0.0017288670419742737
Trained batch 170 in epoch 3, gen_loss = 1.019302797247792, disc_loss = 0.0017285480872695253
Trained batch 171 in epoch 3, gen_loss = 1.0191954024309335, disc_loss = 0.0017257960703424286
Trained batch 172 in epoch 3, gen_loss = 1.0191241616458562, disc_loss = 0.001721346129412962
Trained batch 173 in epoch 3, gen_loss = 1.0189027700616025, disc_loss = 0.00171579507275902
Trained batch 174 in epoch 3, gen_loss = 1.018836989743369, disc_loss = 0.0017127746669575571
Trained batch 175 in epoch 3, gen_loss = 1.0188242911615155, disc_loss = 0.001712419833479957
Trained batch 176 in epoch 3, gen_loss = 1.0186278422673543, disc_loss = 0.0017094034688431496
Trained batch 177 in epoch 3, gen_loss = 1.0186580305688837, disc_loss = 0.0017041356722677775
Trained batch 178 in epoch 3, gen_loss = 1.0186187681539098, disc_loss = 0.001698436774183377
Trained batch 179 in epoch 3, gen_loss = 1.0185674051443736, disc_loss = 0.0016927441459200863
Trained batch 180 in epoch 3, gen_loss = 1.0187312318475208, disc_loss = 0.0016884134518939651
Trained batch 181 in epoch 3, gen_loss = 1.018819280378111, disc_loss = 0.001686333801474545
Trained batch 182 in epoch 3, gen_loss = 1.0186040183234084, disc_loss = 0.0016844638125828463
Trained batch 183 in epoch 3, gen_loss = 1.0182302130953125, disc_loss = 0.0016835712474699983
Trained batch 184 in epoch 3, gen_loss = 1.0181027067674173, disc_loss = 0.0016821800347266568
Trained batch 185 in epoch 3, gen_loss = 1.0177350835774535, disc_loss = 0.0016808688373965842
Trained batch 186 in epoch 3, gen_loss = 1.0175495737376699, disc_loss = 0.001680005384723651
Trained batch 187 in epoch 3, gen_loss = 1.017672357724068, disc_loss = 0.0016788609005124408
Trained batch 188 in epoch 3, gen_loss = 1.017513568439181, disc_loss = 0.0016793611357185654
Trained batch 189 in epoch 3, gen_loss = 1.0177349874847814, disc_loss = 0.001688488430073975
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 1.0392175912857056, disc_loss = 0.0061584338545799255
Trained batch 1 in epoch 4, gen_loss = 1.033170461654663, disc_loss = 0.00644902978092432
Trained batch 2 in epoch 4, gen_loss = 1.0287151734034221, disc_loss = 0.0055661427322775126
Trained batch 3 in epoch 4, gen_loss = 1.0196349620819092, disc_loss = 0.004692923568654805
Trained batch 4 in epoch 4, gen_loss = 1.0142622590065002, disc_loss = 0.004126080148853362
Trained batch 5 in epoch 4, gen_loss = 1.0194753110408783, disc_loss = 0.0037481923936866224
Trained batch 6 in epoch 4, gen_loss = 1.0175229225839888, disc_loss = 0.0034468617190473844
Trained batch 7 in epoch 4, gen_loss = 1.0161264017224312, disc_loss = 0.0032033554889494553
Trained batch 8 in epoch 4, gen_loss = 1.012744300895267, disc_loss = 0.003020713092862732
Trained batch 9 in epoch 4, gen_loss = 1.0168000757694244, disc_loss = 0.0029103443725034595
Trained batch 10 in epoch 4, gen_loss = 1.013670883395455, disc_loss = 0.0028385928281667557
Trained batch 11 in epoch 4, gen_loss = 1.0167886068423588, disc_loss = 0.0027850755917218826
Trained batch 12 in epoch 4, gen_loss = 1.0159884645388677, disc_loss = 0.00270606551426821
Trained batch 13 in epoch 4, gen_loss = 1.013635128736496, disc_loss = 0.002642015211417207
Trained batch 14 in epoch 4, gen_loss = 1.0100996057192484, disc_loss = 0.002589549939148128
Trained batch 15 in epoch 4, gen_loss = 1.0101800747215748, disc_loss = 0.002527581869799178
Trained batch 16 in epoch 4, gen_loss = 1.011799479232115, disc_loss = 0.0024755534798126012
Trained batch 17 in epoch 4, gen_loss = 1.010306755701701, disc_loss = 0.002414547282064127
Trained batch 18 in epoch 4, gen_loss = 1.009355764640005, disc_loss = 0.002344377436920216
Trained batch 19 in epoch 4, gen_loss = 1.0075283348560333, disc_loss = 0.002267362890415825
Trained batch 20 in epoch 4, gen_loss = 1.0054548439525424, disc_loss = 0.0021926735062152147
Trained batch 21 in epoch 4, gen_loss = 1.0061918199062347, disc_loss = 0.0021312867756932974
Trained batch 22 in epoch 4, gen_loss = 1.0063183281732642, disc_loss = 0.002071249852989517
Trained batch 23 in epoch 4, gen_loss = 1.0062090829014778, disc_loss = 0.0020165167394831465
Trained batch 24 in epoch 4, gen_loss = 1.0067529416084289, disc_loss = 0.001974737076088786
Trained batch 25 in epoch 4, gen_loss = 1.0063894093036652, disc_loss = 0.0019423305056989193
Trained batch 26 in epoch 4, gen_loss = 1.007389278323562, disc_loss = 0.0019195805458972852
Trained batch 27 in epoch 4, gen_loss = 1.0061865172215871, disc_loss = 0.001894649101554283
Trained batch 28 in epoch 4, gen_loss = 1.0058744446984653, disc_loss = 0.001864187515758235
Trained batch 29 in epoch 4, gen_loss = 1.0058845202128093, disc_loss = 0.0018360499447832505
Trained batch 30 in epoch 4, gen_loss = 1.0062313118288595, disc_loss = 0.001811901712039065
Trained batch 31 in epoch 4, gen_loss = 1.0064158402383327, disc_loss = 0.0017873936922114808
Trained batch 32 in epoch 4, gen_loss = 1.007179617881775, disc_loss = 0.0017611622972639673
Trained batch 33 in epoch 4, gen_loss = 1.0075140946051653, disc_loss = 0.0017375825589303585
Trained batch 34 in epoch 4, gen_loss = 1.0077906778880528, disc_loss = 0.0017115133398744678
Trained batch 35 in epoch 4, gen_loss = 1.0073783348004024, disc_loss = 0.0016870861161603695
Trained batch 36 in epoch 4, gen_loss = 1.0073861447540489, disc_loss = 0.0016629053500002704
Trained batch 37 in epoch 4, gen_loss = 1.0074670016765594, disc_loss = 0.001639632282986943
Trained batch 38 in epoch 4, gen_loss = 1.0074270459321828, disc_loss = 0.001614738812443251
Trained batch 39 in epoch 4, gen_loss = 1.0067358270287514, disc_loss = 0.0015890257142018526
Trained batch 40 in epoch 4, gen_loss = 1.0063166414819114, disc_loss = 0.0015635031428778681
Trained batch 41 in epoch 4, gen_loss = 1.0061018750781106, disc_loss = 0.001539297289647428
Trained batch 42 in epoch 4, gen_loss = 1.004749522652737, disc_loss = 0.0015170726787060672
Trained batch 43 in epoch 4, gen_loss = 1.0029484710910104, disc_loss = 0.0014971998051888395
Trained batch 44 in epoch 4, gen_loss = 1.0032989581425984, disc_loss = 0.0014796917223268086
Trained batch 45 in epoch 4, gen_loss = 1.002837061882019, disc_loss = 0.0014743115246781836
Trained batch 46 in epoch 4, gen_loss = 1.00251560261909, disc_loss = 0.001479796540150617
Trained batch 47 in epoch 4, gen_loss = 1.0023294351994991, disc_loss = 0.0014892033553527047
Trained batch 48 in epoch 4, gen_loss = 1.0017969985397495, disc_loss = 0.0014982559262033627
Trained batch 49 in epoch 4, gen_loss = 1.0013720738887786, disc_loss = 0.001500094924122095
Trained batch 50 in epoch 4, gen_loss = 1.0013947007702846, disc_loss = 0.0014996938247635377
Trained batch 51 in epoch 4, gen_loss = 1.0008084097733865, disc_loss = 0.0015006343377395892
Trained batch 52 in epoch 4, gen_loss = 1.0011459577758357, disc_loss = 0.0014994184020906687
Trained batch 53 in epoch 4, gen_loss = 1.0005775392055511, disc_loss = 0.0014921400946116558
Trained batch 54 in epoch 4, gen_loss = 1.000243149020455, disc_loss = 0.001482438811482015
Trained batch 55 in epoch 4, gen_loss = 0.9998592500175748, disc_loss = 0.0014740976403118111
Trained batch 56 in epoch 4, gen_loss = 0.999227716211687, disc_loss = 0.0014657541984904622
Trained batch 57 in epoch 4, gen_loss = 0.9992119567147617, disc_loss = 0.0014623571157150355
Trained batch 58 in epoch 4, gen_loss = 0.9993260512917729, disc_loss = 0.0014581663003270277
Trained batch 59 in epoch 4, gen_loss = 0.9983969847361247, disc_loss = 0.0014540285114586974
Trained batch 60 in epoch 4, gen_loss = 0.9978362263226118, disc_loss = 0.0014482126141837264
Trained batch 61 in epoch 4, gen_loss = 0.9980375612935712, disc_loss = 0.00144370915386976
Trained batch 62 in epoch 4, gen_loss = 0.9983387920591567, disc_loss = 0.001441825725441237
Trained batch 63 in epoch 4, gen_loss = 0.9975513871759176, disc_loss = 0.001438084959772823
Trained batch 64 in epoch 4, gen_loss = 0.9971820629560031, disc_loss = 0.00143168431867917
Trained batch 65 in epoch 4, gen_loss = 0.9973167524193273, disc_loss = 0.0014268238261469048
Trained batch 66 in epoch 4, gen_loss = 0.9979523153447393, disc_loss = 0.0014216218433871087
Trained batch 67 in epoch 4, gen_loss = 0.9983772986075458, disc_loss = 0.0014150654426296515
Trained batch 68 in epoch 4, gen_loss = 0.9978226647860762, disc_loss = 0.0014111112399985068
Trained batch 69 in epoch 4, gen_loss = 0.997577714920044, disc_loss = 0.001409966659100194
Trained batch 70 in epoch 4, gen_loss = 0.9978823174893017, disc_loss = 0.0014105303693418456
Trained batch 71 in epoch 4, gen_loss = 0.9981714967224333, disc_loss = 0.0014087524315174152
Trained batch 72 in epoch 4, gen_loss = 0.9983271931948727, disc_loss = 0.0014011393179989432
Trained batch 73 in epoch 4, gen_loss = 0.9983414701513342, disc_loss = 0.0013910022350279866
Trained batch 74 in epoch 4, gen_loss = 0.9982938639322917, disc_loss = 0.0013814166902254026
Trained batch 75 in epoch 4, gen_loss = 0.9981852064007207, disc_loss = 0.0013732377594447155
Trained batch 76 in epoch 4, gen_loss = 0.9981961126451369, disc_loss = 0.0013655395248554066
Trained batch 77 in epoch 4, gen_loss = 0.9990131106132116, disc_loss = 0.0013590228097596897
Trained batch 78 in epoch 4, gen_loss = 0.9995156828361221, disc_loss = 0.0013515096543875488
Trained batch 79 in epoch 4, gen_loss = 0.9998069152235984, disc_loss = 0.0013447279590764083
Trained batch 80 in epoch 4, gen_loss = 0.9997023535363468, disc_loss = 0.0013375910384189568
Trained batch 81 in epoch 4, gen_loss = 0.9997489205220851, disc_loss = 0.0013322431115694799
Trained batch 82 in epoch 4, gen_loss = 0.9997344361730369, disc_loss = 0.0013277159284250475
Trained batch 83 in epoch 4, gen_loss = 0.9997982652414412, disc_loss = 0.0013239379837787489
Trained batch 84 in epoch 4, gen_loss = 0.9996084886438706, disc_loss = 0.0013193427612457206
Trained batch 85 in epoch 4, gen_loss = 0.9996202075204184, disc_loss = 0.0013138052843630226
Trained batch 86 in epoch 4, gen_loss = 0.9997803945650999, disc_loss = 0.0013065803461526145
Trained batch 87 in epoch 4, gen_loss = 0.9996726892211221, disc_loss = 0.0012979802764179608
Trained batch 88 in epoch 4, gen_loss = 0.9997182481744317, disc_loss = 0.001290105824133779
Trained batch 89 in epoch 4, gen_loss = 0.9993507345517476, disc_loss = 0.0012815713559070395
Trained batch 90 in epoch 4, gen_loss = 0.9989588378549932, disc_loss = 0.0012739744903468577
Trained batch 91 in epoch 4, gen_loss = 0.9997406899929047, disc_loss = 0.001269867269160307
Trained batch 92 in epoch 4, gen_loss = 0.9996637157214585, disc_loss = 0.0012631098600855517
Trained batch 93 in epoch 4, gen_loss = 0.9998273786078108, disc_loss = 0.0012573358618921818
Trained batch 94 in epoch 4, gen_loss = 0.9997249176627712, disc_loss = 0.0012521740263573041
Trained batch 95 in epoch 4, gen_loss = 0.9993341645846764, disc_loss = 0.0012476041301852092
Trained batch 96 in epoch 4, gen_loss = 0.9992966953012132, disc_loss = 0.0012425270037168695
Trained batch 97 in epoch 4, gen_loss = 0.9991843822051067, disc_loss = 0.0012369075485942314
Trained batch 98 in epoch 4, gen_loss = 0.9990218504510745, disc_loss = 0.0012307155752705053
Trained batch 99 in epoch 4, gen_loss = 0.9990525269508361, disc_loss = 0.0012248514196835458
Trained batch 100 in epoch 4, gen_loss = 0.9991281540086954, disc_loss = 0.0012195042898131552
Trained batch 101 in epoch 4, gen_loss = 0.9991048562760446, disc_loss = 0.0012146299265498551
Trained batch 102 in epoch 4, gen_loss = 0.9988151476221178, disc_loss = 0.0012104046899481739
Trained batch 103 in epoch 4, gen_loss = 0.9989286764309957, disc_loss = 0.0012051755889283062
Trained batch 104 in epoch 4, gen_loss = 0.9988889864512852, disc_loss = 0.0012000498871895529
Trained batch 105 in epoch 4, gen_loss = 0.9987669429689083, disc_loss = 0.001196709338505313
Trained batch 106 in epoch 4, gen_loss = 0.9986494996837366, disc_loss = 0.0011929410485829288
Trained batch 107 in epoch 4, gen_loss = 0.9987539654528653, disc_loss = 0.0011886925322296858
Trained batch 108 in epoch 4, gen_loss = 0.9990586671260518, disc_loss = 0.0011884693148195608
Trained batch 109 in epoch 4, gen_loss = 0.9989165723323822, disc_loss = 0.0011928505200723355
Trained batch 110 in epoch 4, gen_loss = 0.9992616461203979, disc_loss = 0.0011994596822439013
Trained batch 111 in epoch 4, gen_loss = 0.999127880270992, disc_loss = 0.0012086562138782547
Trained batch 112 in epoch 4, gen_loss = 0.999282301527209, disc_loss = 0.0012223504285896773
Trained batch 113 in epoch 4, gen_loss = 0.9995429437411459, disc_loss = 0.0012421872601599286
Trained batch 114 in epoch 4, gen_loss = 0.9993619384972946, disc_loss = 0.0012679467119438492
Trained batch 115 in epoch 4, gen_loss = 0.9993201185917032, disc_loss = 0.0012977311512102083
Trained batch 116 in epoch 4, gen_loss = 0.9990249780508188, disc_loss = 0.0013278910679281012
Trained batch 117 in epoch 4, gen_loss = 0.9989357439138121, disc_loss = 0.001354669274020372
Trained batch 118 in epoch 4, gen_loss = 0.9992867537907192, disc_loss = 0.0013780064407360403
Trained batch 119 in epoch 4, gen_loss = 0.9991169144709905, disc_loss = 0.00139267107588239
Trained batch 120 in epoch 4, gen_loss = 0.9988690880704517, disc_loss = 0.001400586527441282
Trained batch 121 in epoch 4, gen_loss = 0.9987242896048749, disc_loss = 0.001404406676511662
Trained batch 122 in epoch 4, gen_loss = 0.9985238255524054, disc_loss = 0.0014054148847888399
Trained batch 123 in epoch 4, gen_loss = 0.998797050406856, disc_loss = 0.0014075054392789401
Trained batch 124 in epoch 4, gen_loss = 0.9984791336059571, disc_loss = 0.001413731701672077
Trained batch 125 in epoch 4, gen_loss = 0.9985380891769652, disc_loss = 0.0014232019006851174
Trained batch 126 in epoch 4, gen_loss = 0.9985480890499325, disc_loss = 0.0014289469791825596
Trained batch 127 in epoch 4, gen_loss = 0.9985398277640343, disc_loss = 0.0014302547415354638
Trained batch 128 in epoch 4, gen_loss = 0.9984321340109951, disc_loss = 0.0014314688245816401
Trained batch 129 in epoch 4, gen_loss = 0.9985496984078334, disc_loss = 0.0014313099699882934
Trained batch 130 in epoch 4, gen_loss = 0.9986115179899084, disc_loss = 0.0014280535126076513
Trained batch 131 in epoch 4, gen_loss = 0.998623424858758, disc_loss = 0.0014232392206781008
Trained batch 132 in epoch 4, gen_loss = 0.9985303730892956, disc_loss = 0.0014173944451832178
Trained batch 133 in epoch 4, gen_loss = 0.9983799341899245, disc_loss = 0.0014115086019928775
Trained batch 134 in epoch 4, gen_loss = 0.9983444416964495, disc_loss = 0.001405567046755028
Trained batch 135 in epoch 4, gen_loss = 0.9983557822073207, disc_loss = 0.0014004057516371284
Trained batch 136 in epoch 4, gen_loss = 0.9984653335418144, disc_loss = 0.0013952038623052682
Trained batch 137 in epoch 4, gen_loss = 0.9982264059177344, disc_loss = 0.001389089525943838
Trained batch 138 in epoch 4, gen_loss = 0.9982134601195082, disc_loss = 0.0013831597124728903
Trained batch 139 in epoch 4, gen_loss = 0.9979922941752842, disc_loss = 0.00137755596203663
Trained batch 140 in epoch 4, gen_loss = 0.997996062251693, disc_loss = 0.0013724695342090905
Trained batch 141 in epoch 4, gen_loss = 0.9979245830589617, disc_loss = 0.0013680737691072248
Trained batch 142 in epoch 4, gen_loss = 0.9980378117594686, disc_loss = 0.001362967591039133
Trained batch 143 in epoch 4, gen_loss = 0.9980841262473, disc_loss = 0.0013579843915876052
Trained batch 144 in epoch 4, gen_loss = 0.9979312049931494, disc_loss = 0.0013527720624677323
Trained batch 145 in epoch 4, gen_loss = 0.9976520150491636, disc_loss = 0.0013493658270693244
Trained batch 146 in epoch 4, gen_loss = 0.9974417236386514, disc_loss = 0.0013506950103348361
Trained batch 147 in epoch 4, gen_loss = 0.9973208288083205, disc_loss = 0.0013563102358996213
Trained batch 148 in epoch 4, gen_loss = 0.9970280000027394, disc_loss = 0.0013641355830344727
Trained batch 149 in epoch 4, gen_loss = 0.9971033291021982, disc_loss = 0.0013740780449006706
Trained batch 150 in epoch 4, gen_loss = 0.9970422841065767, disc_loss = 0.0013835254146113054
Trained batch 151 in epoch 4, gen_loss = 0.9969262857186166, disc_loss = 0.0013924699141123135
Trained batch 152 in epoch 4, gen_loss = 0.9968578721962723, disc_loss = 0.0014003130369150123
Trained batch 153 in epoch 4, gen_loss = 0.9967713162496492, disc_loss = 0.001408450276358053
Trained batch 154 in epoch 4, gen_loss = 0.9967797686976771, disc_loss = 0.00141777626291338
Trained batch 155 in epoch 4, gen_loss = 0.9965079594881107, disc_loss = 0.0014263383640448013
Trained batch 156 in epoch 4, gen_loss = 0.9964459686522271, disc_loss = 0.0014343147227617729
Trained batch 157 in epoch 4, gen_loss = 0.9966392396371576, disc_loss = 0.001437384889776453
Trained batch 158 in epoch 4, gen_loss = 0.9966526451350758, disc_loss = 0.0014342944062338357
Trained batch 159 in epoch 4, gen_loss = 0.9964530691504478, disc_loss = 0.001428845713599003
Trained batch 160 in epoch 4, gen_loss = 0.99660373104285, disc_loss = 0.001423164103426016
Trained batch 161 in epoch 4, gen_loss = 0.9969227689283865, disc_loss = 0.0014172939073084567
Trained batch 162 in epoch 4, gen_loss = 0.9969743592607463, disc_loss = 0.0014112063103635436
Trained batch 163 in epoch 4, gen_loss = 0.9968565884159832, disc_loss = 0.0014063466656896307
Trained batch 164 in epoch 4, gen_loss = 0.9968420285167117, disc_loss = 0.001401296750444806
Trained batch 165 in epoch 4, gen_loss = 0.9970503625381424, disc_loss = 0.0013967131941960789
Trained batch 166 in epoch 4, gen_loss = 0.9972205051404988, disc_loss = 0.00139229833413317
Trained batch 167 in epoch 4, gen_loss = 0.9973613609160695, disc_loss = 0.0013879004829851467
Trained batch 168 in epoch 4, gen_loss = 0.9972987287848659, disc_loss = 0.001385493928665769
Trained batch 169 in epoch 4, gen_loss = 0.9975666046142578, disc_loss = 0.00138641691301018
Trained batch 170 in epoch 4, gen_loss = 0.9975584041305453, disc_loss = 0.0013876078154739233
Trained batch 171 in epoch 4, gen_loss = 0.9976021564284037, disc_loss = 0.001386786425258791
Trained batch 172 in epoch 4, gen_loss = 0.9972787895643642, disc_loss = 0.001383784427267171
Trained batch 173 in epoch 4, gen_loss = 0.9972357349149112, disc_loss = 0.001385304832967512
Trained batch 174 in epoch 4, gen_loss = 0.9973699143954686, disc_loss = 0.0013878199687626745
Trained batch 175 in epoch 4, gen_loss = 0.9974415596913208, disc_loss = 0.0013889452387626409
Trained batch 176 in epoch 4, gen_loss = 0.997441065850231, disc_loss = 0.001389612829494211
Trained batch 177 in epoch 4, gen_loss = 0.9971651565492823, disc_loss = 0.0013868950069960459
Trained batch 178 in epoch 4, gen_loss = 0.9970445553017728, disc_loss = 0.001383368835417689
Trained batch 179 in epoch 4, gen_loss = 0.9967992222971387, disc_loss = 0.0013813697464583029
Trained batch 180 in epoch 4, gen_loss = 0.9967131077913948, disc_loss = 0.001382140852755337
Trained batch 181 in epoch 4, gen_loss = 0.996549632195588, disc_loss = 0.0013835866917001473
Trained batch 182 in epoch 4, gen_loss = 0.9963613543354097, disc_loss = 0.0013884405571779064
Trained batch 183 in epoch 4, gen_loss = 0.9967494247400243, disc_loss = 0.0013906586204741514
Trained batch 184 in epoch 4, gen_loss = 0.9968263648651742, disc_loss = 0.0013888171977816603
Trained batch 185 in epoch 4, gen_loss = 0.9969233335346304, disc_loss = 0.0013871334217143276
Trained batch 186 in epoch 4, gen_loss = 0.997049026629504, disc_loss = 0.0013858391676113049
Trained batch 187 in epoch 4, gen_loss = 0.9968772169123304, disc_loss = 0.0013850756993324079
Trained batch 188 in epoch 4, gen_loss = 0.9969849763093172, disc_loss = 0.0013824436390432455
Trained batch 189 in epoch 4, gen_loss = 0.9969614433614831, disc_loss = 0.00137860017712228
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0361379384994507, disc_loss = 0.0008519195253029466
Trained batch 1 in epoch 5, gen_loss = 1.021533191204071, disc_loss = 0.0009695951011963189
Trained batch 2 in epoch 5, gen_loss = 1.010093669096629, disc_loss = 0.0009117884910665452
Trained batch 3 in epoch 5, gen_loss = 1.0028805583715439, disc_loss = 0.0008643373876111582
Trained batch 4 in epoch 5, gen_loss = 1.0039726614952087, disc_loss = 0.0008407414192333817
Trained batch 5 in epoch 5, gen_loss = 1.0032118658224742, disc_loss = 0.0008251745312009007
Trained batch 6 in epoch 5, gen_loss = 1.0068268179893494, disc_loss = 0.000856073248931872
Trained batch 7 in epoch 5, gen_loss = 1.000179536640644, disc_loss = 0.0009460906221647747
Trained batch 8 in epoch 5, gen_loss = 0.9943688909212748, disc_loss = 0.0010345587312864761
Trained batch 9 in epoch 5, gen_loss = 0.993597286939621, disc_loss = 0.001095482549862936
Trained batch 10 in epoch 5, gen_loss = 0.9957124482501637, disc_loss = 0.0011437769439494746
Trained batch 11 in epoch 5, gen_loss = 0.9947280039389929, disc_loss = 0.0011600194120546803
Trained batch 12 in epoch 5, gen_loss = 0.9928210102594816, disc_loss = 0.0011590231039847892
Trained batch 13 in epoch 5, gen_loss = 0.990678391286305, disc_loss = 0.0011463691106265677
Trained batch 14 in epoch 5, gen_loss = 0.9906154712041219, disc_loss = 0.0011179982257696489
Trained batch 15 in epoch 5, gen_loss = 0.9875478930771351, disc_loss = 0.0010854564316105098
Trained batch 16 in epoch 5, gen_loss = 0.9869531638482038, disc_loss = 0.0010517533861703293
Trained batch 17 in epoch 5, gen_loss = 0.9867613779173957, disc_loss = 0.0010320550160637747
Trained batch 18 in epoch 5, gen_loss = 0.9887279523046393, disc_loss = 0.0010120753186607832
Trained batch 19 in epoch 5, gen_loss = 0.9896324813365937, disc_loss = 0.0009934360627084971
Trained batch 20 in epoch 5, gen_loss = 0.9883070417812893, disc_loss = 0.0009792801547085955
Trained batch 21 in epoch 5, gen_loss = 0.9908309931104834, disc_loss = 0.0009834428889338267
Trained batch 22 in epoch 5, gen_loss = 0.991721845191458, disc_loss = 0.001017641721536284
Trained batch 23 in epoch 5, gen_loss = 0.9912375758091608, disc_loss = 0.0010442921047797427
Trained batch 24 in epoch 5, gen_loss = 0.9928628969192504, disc_loss = 0.0010425997385755182
Trained batch 25 in epoch 5, gen_loss = 0.9918785553712112, disc_loss = 0.0010222412842827348
Trained batch 26 in epoch 5, gen_loss = 0.9913231001959907, disc_loss = 0.0010084197576226736
Trained batch 27 in epoch 5, gen_loss = 0.991780264036996, disc_loss = 0.0009958866430679336
Trained batch 28 in epoch 5, gen_loss = 0.9912107360774073, disc_loss = 0.0009836152372560624
Trained batch 29 in epoch 5, gen_loss = 0.9914781033992768, disc_loss = 0.0009901790452810624
Trained batch 30 in epoch 5, gen_loss = 0.9923478345717153, disc_loss = 0.0010245775300708989
Trained batch 31 in epoch 5, gen_loss = 0.9931530747562647, disc_loss = 0.001057361161656445
Trained batch 32 in epoch 5, gen_loss = 0.9917872439731251, disc_loss = 0.0010628522458401594
Trained batch 33 in epoch 5, gen_loss = 0.9924295492031995, disc_loss = 0.001102213076699306
Trained batch 34 in epoch 5, gen_loss = 0.9932792510305132, disc_loss = 0.0012119170145264693
Trained batch 35 in epoch 5, gen_loss = 0.992094475362036, disc_loss = 0.001305500860325992
Trained batch 36 in epoch 5, gen_loss = 0.9914821499102825, disc_loss = 0.0013625107869203832
Trained batch 37 in epoch 5, gen_loss = 0.9919653048640803, disc_loss = 0.0014179633305359044
Trained batch 38 in epoch 5, gen_loss = 0.9915324739920788, disc_loss = 0.001471183471715985
Trained batch 39 in epoch 5, gen_loss = 0.992710591852665, disc_loss = 0.0015132502245251088
Trained batch 40 in epoch 5, gen_loss = 0.9935512179281654, disc_loss = 0.0015326897420625135
Trained batch 41 in epoch 5, gen_loss = 0.9938338753722963, disc_loss = 0.0015397962498744683
Trained batch 42 in epoch 5, gen_loss = 0.9930980039197345, disc_loss = 0.0015436023132615658
Trained batch 43 in epoch 5, gen_loss = 0.9926521344618364, disc_loss = 0.0015538851968647743
Trained batch 44 in epoch 5, gen_loss = 0.9920537988344829, disc_loss = 0.0015661477344110608
Trained batch 45 in epoch 5, gen_loss = 0.9914715406687363, disc_loss = 0.0015760663436199336
Trained batch 46 in epoch 5, gen_loss = 0.9913028301076686, disc_loss = 0.0015793438540137512
Trained batch 47 in epoch 5, gen_loss = 0.9908161150912443, disc_loss = 0.0015779476355722484
Trained batch 48 in epoch 5, gen_loss = 0.9916895104914295, disc_loss = 0.0015701831066600826
Trained batch 49 in epoch 5, gen_loss = 0.991907662153244, disc_loss = 0.0015595264034345747
Trained batch 50 in epoch 5, gen_loss = 0.9925607758409837, disc_loss = 0.0015541252442726901
Trained batch 51 in epoch 5, gen_loss = 0.9927599074748846, disc_loss = 0.001550370354939682
Trained batch 52 in epoch 5, gen_loss = 0.9926407415911837, disc_loss = 0.0015470824151668909
Trained batch 53 in epoch 5, gen_loss = 0.9922894349804631, disc_loss = 0.0015396788992263653
Trained batch 54 in epoch 5, gen_loss = 0.9916882406581532, disc_loss = 0.0015224616149101746
Trained batch 55 in epoch 5, gen_loss = 0.992211075765746, disc_loss = 0.0015147368789517454
Trained batch 56 in epoch 5, gen_loss = 0.9931209526563946, disc_loss = 0.0015344176882583845
Trained batch 57 in epoch 5, gen_loss = 0.9929421153561823, disc_loss = 0.001561671077948192
Trained batch 58 in epoch 5, gen_loss = 0.9928886647951805, disc_loss = 0.0015857130194366989
Trained batch 59 in epoch 5, gen_loss = 0.9933155576388041, disc_loss = 0.0016096885548904539
Trained batch 60 in epoch 5, gen_loss = 0.9934317596623155, disc_loss = 0.0016331730265414617
Trained batch 61 in epoch 5, gen_loss = 0.9929582447774948, disc_loss = 0.0016385642511229362
Trained batch 62 in epoch 5, gen_loss = 0.9927138307737926, disc_loss = 0.00162965961776319
Trained batch 63 in epoch 5, gen_loss = 0.9926393823698163, disc_loss = 0.0016168322163139237
Trained batch 64 in epoch 5, gen_loss = 0.9927783149939317, disc_loss = 0.001605816318008762
Trained batch 65 in epoch 5, gen_loss = 0.9928107379060803, disc_loss = 0.0015973655549301343
Trained batch 66 in epoch 5, gen_loss = 0.9929176622362279, disc_loss = 0.0015880632520055592
Trained batch 67 in epoch 5, gen_loss = 0.9930015960160423, disc_loss = 0.0015753864341497641
Trained batch 68 in epoch 5, gen_loss = 0.9930325349171957, disc_loss = 0.0015599039616063237
Trained batch 69 in epoch 5, gen_loss = 0.9928895354270935, disc_loss = 0.0015464254987559148
Trained batch 70 in epoch 5, gen_loss = 0.9932320269060807, disc_loss = 0.0015355039471563635
Trained batch 71 in epoch 5, gen_loss = 0.9930253509018157, disc_loss = 0.0015250295473379083
Trained batch 72 in epoch 5, gen_loss = 0.9924670866090958, disc_loss = 0.0015171464725576137
Trained batch 73 in epoch 5, gen_loss = 0.992303696033117, disc_loss = 0.001511760281770163
Trained batch 74 in epoch 5, gen_loss = 0.9926349902153015, disc_loss = 0.001509968499497821
Trained batch 75 in epoch 5, gen_loss = 0.9928491468492308, disc_loss = 0.0015104328271454985
Trained batch 76 in epoch 5, gen_loss = 0.9925019888134746, disc_loss = 0.0015123441018611676
Trained batch 77 in epoch 5, gen_loss = 0.9926840853996766, disc_loss = 0.001516309236206162
Trained batch 78 in epoch 5, gen_loss = 0.9933173015147825, disc_loss = 0.0015145547509700342
Trained batch 79 in epoch 5, gen_loss = 0.993829321116209, disc_loss = 0.00150552390186931
Trained batch 80 in epoch 5, gen_loss = 0.9939047399862313, disc_loss = 0.0014938687802188927
Trained batch 81 in epoch 5, gen_loss = 0.9940601798092447, disc_loss = 0.0014847356083564369
Trained batch 82 in epoch 5, gen_loss = 0.9943077183631529, disc_loss = 0.0014762129222256053
Trained batch 83 in epoch 5, gen_loss = 0.9946226839508329, disc_loss = 0.001468821485537947
Trained batch 84 in epoch 5, gen_loss = 0.9943991219296174, disc_loss = 0.001466142658746856
Trained batch 85 in epoch 5, gen_loss = 0.9940509421880855, disc_loss = 0.001462368865843949
Trained batch 86 in epoch 5, gen_loss = 0.9940471101081234, disc_loss = 0.0014562312836073682
Trained batch 87 in epoch 5, gen_loss = 0.9938902976838025, disc_loss = 0.001447450069297867
Trained batch 88 in epoch 5, gen_loss = 0.9940295688221964, disc_loss = 0.0014376249452111092
Trained batch 89 in epoch 5, gen_loss = 0.9940716220272912, disc_loss = 0.001428495028651216
Trained batch 90 in epoch 5, gen_loss = 0.9940082378439851, disc_loss = 0.001421549743819204
Trained batch 91 in epoch 5, gen_loss = 0.993853523031525, disc_loss = 0.0014138911634369795
Trained batch 92 in epoch 5, gen_loss = 0.9935950034408159, disc_loss = 0.0014031073172396469
Trained batch 93 in epoch 5, gen_loss = 0.9935659087718801, disc_loss = 0.001394574664795692
Trained batch 94 in epoch 5, gen_loss = 0.9933886270774038, disc_loss = 0.0013877380847636806
Trained batch 95 in epoch 5, gen_loss = 0.9932032978783051, disc_loss = 0.001381004614813719
Trained batch 96 in epoch 5, gen_loss = 0.9932843600351786, disc_loss = 0.0013732471252484342
Trained batch 97 in epoch 5, gen_loss = 0.9930749371343729, disc_loss = 0.0013636338464530868
Trained batch 98 in epoch 5, gen_loss = 0.9928662903381117, disc_loss = 0.0013537927700625263
Trained batch 99 in epoch 5, gen_loss = 0.9928182291984559, disc_loss = 0.0013441729263286106
Trained batch 100 in epoch 5, gen_loss = 0.993572997574759, disc_loss = 0.0013377372550635166
Trained batch 101 in epoch 5, gen_loss = 0.9935136016677407, disc_loss = 0.0013335616514429122
Trained batch 102 in epoch 5, gen_loss = 0.9937662106115841, disc_loss = 0.0013357641520679395
Trained batch 103 in epoch 5, gen_loss = 0.9939031555102422, disc_loss = 0.0013397814414369909
Trained batch 104 in epoch 5, gen_loss = 0.9939088185628255, disc_loss = 0.001340138063754975
Trained batch 105 in epoch 5, gen_loss = 0.9937339976148786, disc_loss = 0.0013383877546557243
Trained batch 106 in epoch 5, gen_loss = 0.9936224968633919, disc_loss = 0.0013345577479361896
Trained batch 107 in epoch 5, gen_loss = 0.9934858950199904, disc_loss = 0.0013289303436370876
Trained batch 108 in epoch 5, gen_loss = 0.9933852389318134, disc_loss = 0.001325542543247906
Trained batch 109 in epoch 5, gen_loss = 0.9932545385577461, disc_loss = 0.001325396617969752
Trained batch 110 in epoch 5, gen_loss = 0.993373369848406, disc_loss = 0.001326081980919667
Trained batch 111 in epoch 5, gen_loss = 0.9934317017240184, disc_loss = 0.00132731436341211
Trained batch 112 in epoch 5, gen_loss = 0.9933384662180875, disc_loss = 0.0013308249410361348
Trained batch 113 in epoch 5, gen_loss = 0.9928011235437895, disc_loss = 0.0013338673133260098
Trained batch 114 in epoch 5, gen_loss = 0.9931721635486769, disc_loss = 0.001335757864770763
Trained batch 115 in epoch 5, gen_loss = 0.9930551165136797, disc_loss = 0.0013388334284235466
Trained batch 116 in epoch 5, gen_loss = 0.9928157584280031, disc_loss = 0.0013392748448969875
Trained batch 117 in epoch 5, gen_loss = 0.992689708026789, disc_loss = 0.0013365997043457986
Trained batch 118 in epoch 5, gen_loss = 0.9924650177234361, disc_loss = 0.0013335746785864515
Trained batch 119 in epoch 5, gen_loss = 0.992546579738458, disc_loss = 0.0013311869399331045
Trained batch 120 in epoch 5, gen_loss = 0.9926754792859732, disc_loss = 0.0013281723423302944
Trained batch 121 in epoch 5, gen_loss = 0.9929926175563062, disc_loss = 0.0013241386157937622
Trained batch 122 in epoch 5, gen_loss = 0.9930094369058686, disc_loss = 0.0013211247664062322
Trained batch 123 in epoch 5, gen_loss = 0.9930579556572822, disc_loss = 0.0013177748081826366
Trained batch 124 in epoch 5, gen_loss = 0.9929097180366516, disc_loss = 0.001312436513369903
Trained batch 125 in epoch 5, gen_loss = 0.9926772032465253, disc_loss = 0.001306299219741338
Trained batch 126 in epoch 5, gen_loss = 0.9931736518078902, disc_loss = 0.0013009312461353985
Trained batch 127 in epoch 5, gen_loss = 0.9932126668281853, disc_loss = 0.001297245465366359
Trained batch 128 in epoch 5, gen_loss = 0.9932257690170939, disc_loss = 0.0012952234388903044
Trained batch 129 in epoch 5, gen_loss = 0.9933042246561784, disc_loss = 0.001291544713267985
Trained batch 130 in epoch 5, gen_loss = 0.9929051972527541, disc_loss = 0.0012867117510799262
Trained batch 131 in epoch 5, gen_loss = 0.9929165546641205, disc_loss = 0.0012966950865423617
Trained batch 132 in epoch 5, gen_loss = 0.9930260409986166, disc_loss = 0.0013249622759867908
Trained batch 133 in epoch 5, gen_loss = 0.9929131816572218, disc_loss = 0.001353193836594209
Trained batch 134 in epoch 5, gen_loss = 0.9932400213347541, disc_loss = 0.0013768033549206814
Trained batch 135 in epoch 5, gen_loss = 0.9934808782794896, disc_loss = 0.001400806678515544
Trained batch 136 in epoch 5, gen_loss = 0.9935384331828486, disc_loss = 0.0014167281751857432
Trained batch 137 in epoch 5, gen_loss = 0.9937487741311392, disc_loss = 0.0014207373768432012
Trained batch 138 in epoch 5, gen_loss = 0.9940329734370005, disc_loss = 0.0014186038850495096
Trained batch 139 in epoch 5, gen_loss = 0.9941085223640714, disc_loss = 0.0014161160575375626
Trained batch 140 in epoch 5, gen_loss = 0.9937675882738533, disc_loss = 0.0014132246730522192
Trained batch 141 in epoch 5, gen_loss = 0.9939329578003413, disc_loss = 0.0014081235975436997
Trained batch 142 in epoch 5, gen_loss = 0.9941544278518303, disc_loss = 0.001404042276138622
Trained batch 143 in epoch 5, gen_loss = 0.9941794077555338, disc_loss = 0.001399193858257301
Trained batch 144 in epoch 5, gen_loss = 0.9943775703167094, disc_loss = 0.0013938474615409586
Trained batch 145 in epoch 5, gen_loss = 0.9944993020737007, disc_loss = 0.0013898252631132555
Trained batch 146 in epoch 5, gen_loss = 0.9944808872378602, disc_loss = 0.0013853781415089383
Trained batch 147 in epoch 5, gen_loss = 0.9943701214081532, disc_loss = 0.0013812847796912506
Trained batch 148 in epoch 5, gen_loss = 0.9944386962276177, disc_loss = 0.0013763394272001772
Trained batch 149 in epoch 5, gen_loss = 0.9943493843078614, disc_loss = 0.001372319333216486
Trained batch 150 in epoch 5, gen_loss = 0.9943984320621617, disc_loss = 0.0013692575051612683
Trained batch 151 in epoch 5, gen_loss = 0.994314410184559, disc_loss = 0.0013670091956507683
Trained batch 152 in epoch 5, gen_loss = 0.9943374870649351, disc_loss = 0.001364847531601531
Trained batch 153 in epoch 5, gen_loss = 0.9948499938110252, disc_loss = 0.001361035537571864
Trained batch 154 in epoch 5, gen_loss = 0.9950314621771535, disc_loss = 0.0013560705763783546
Trained batch 155 in epoch 5, gen_loss = 0.9950009718155249, disc_loss = 0.001351118281607528
Trained batch 156 in epoch 5, gen_loss = 0.994820476337603, disc_loss = 0.001346192144526311
Trained batch 157 in epoch 5, gen_loss = 0.9946418615836131, disc_loss = 0.0013410029006323224
Trained batch 158 in epoch 5, gen_loss = 0.9945190683850702, disc_loss = 0.001335184011314029
Trained batch 159 in epoch 5, gen_loss = 0.9945917975157499, disc_loss = 0.0013297679304741905
Trained batch 160 in epoch 5, gen_loss = 0.9945965164936847, disc_loss = 0.0013242992050063605
Trained batch 161 in epoch 5, gen_loss = 0.9948398231724163, disc_loss = 0.0013197321190720102
Trained batch 162 in epoch 5, gen_loss = 0.9950498631395446, disc_loss = 0.001315307938615203
Trained batch 163 in epoch 5, gen_loss = 0.9951381665177461, disc_loss = 0.0013106902133142462
Trained batch 164 in epoch 5, gen_loss = 0.9955089435432897, disc_loss = 0.0013093387088950047
Trained batch 165 in epoch 5, gen_loss = 0.9954242243106106, disc_loss = 0.0013114602660202052
Trained batch 166 in epoch 5, gen_loss = 0.9954475721199355, disc_loss = 0.0013133402076245893
Trained batch 167 in epoch 5, gen_loss = 0.9954729903311956, disc_loss = 0.0013118791638199972
Trained batch 168 in epoch 5, gen_loss = 0.9954234308745029, disc_loss = 0.001307681989036335
Trained batch 169 in epoch 5, gen_loss = 0.9953402116018183, disc_loss = 0.001302502107094316
Trained batch 170 in epoch 5, gen_loss = 0.9951577280697069, disc_loss = 0.0012973101322174246
Trained batch 171 in epoch 5, gen_loss = 0.9951471675967061, disc_loss = 0.0012927264554512708
Trained batch 172 in epoch 5, gen_loss = 0.995347378915445, disc_loss = 0.0012885214857800158
Trained batch 173 in epoch 5, gen_loss = 0.9954115484637776, disc_loss = 0.0012855305163799945
Trained batch 174 in epoch 5, gen_loss = 0.9956541357721601, disc_loss = 0.0012832387809508614
Trained batch 175 in epoch 5, gen_loss = 0.995606009255756, disc_loss = 0.001282253084355034
Trained batch 176 in epoch 5, gen_loss = 0.9956433355471509, disc_loss = 0.0012811841706266511
Trained batch 177 in epoch 5, gen_loss = 0.9958982882874735, disc_loss = 0.0012790498361671657
Trained batch 178 in epoch 5, gen_loss = 0.9960325363628025, disc_loss = 0.001275571556462693
Trained batch 179 in epoch 5, gen_loss = 0.9961821635564169, disc_loss = 0.0012713893931100351
Trained batch 180 in epoch 5, gen_loss = 0.9961272356259888, disc_loss = 0.0012676196423029907
Trained batch 181 in epoch 5, gen_loss = 0.9958923390278449, disc_loss = 0.001264754968060815
Trained batch 182 in epoch 5, gen_loss = 0.9956860353386467, disc_loss = 0.001262439915508317
Trained batch 183 in epoch 5, gen_loss = 0.9955661096002745, disc_loss = 0.001258444956835339
Trained batch 184 in epoch 5, gen_loss = 0.9955877716476853, disc_loss = 0.001253592938725912
Trained batch 185 in epoch 5, gen_loss = 0.9956159130219491, disc_loss = 0.0012490346687295103
Trained batch 186 in epoch 5, gen_loss = 0.9954938346689398, disc_loss = 0.001244580711830746
Trained batch 187 in epoch 5, gen_loss = 0.9955776428922694, disc_loss = 0.00124155971880487
Trained batch 188 in epoch 5, gen_loss = 0.9954190399280931, disc_loss = 0.0012427633141645442
Trained batch 189 in epoch 5, gen_loss = 0.9952387038030123, disc_loss = 0.0012461277968740384
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.9402461051940918, disc_loss = 0.0016929198754951358
Trained batch 1 in epoch 6, gen_loss = 0.9634412527084351, disc_loss = 0.0014693684643134475
Trained batch 2 in epoch 6, gen_loss = 0.9666752417882284, disc_loss = 0.001199734047986567
Trained batch 3 in epoch 6, gen_loss = 0.9688408672809601, disc_loss = 0.0010315991239622235
Trained batch 4 in epoch 6, gen_loss = 0.9794663667678833, disc_loss = 0.0009621632285416126
Trained batch 5 in epoch 6, gen_loss = 0.9721197485923767, disc_loss = 0.0009862094108636181
Trained batch 6 in epoch 6, gen_loss = 0.970953140939985, disc_loss = 0.001097074626678867
Trained batch 7 in epoch 6, gen_loss = 0.9788576811552048, disc_loss = 0.0012072198005625978
Trained batch 8 in epoch 6, gen_loss = 0.9800632463561164, disc_loss = 0.0012562007824372915
Trained batch 9 in epoch 6, gen_loss = 0.984284394979477, disc_loss = 0.001258909364696592
Trained batch 10 in epoch 6, gen_loss = 0.9824647090651772, disc_loss = 0.0012369504283097658
Trained batch 11 in epoch 6, gen_loss = 0.9781030565500259, disc_loss = 0.0012233843638872106
Trained batch 12 in epoch 6, gen_loss = 0.9796864940569951, disc_loss = 0.0011857167522136408
Trained batch 13 in epoch 6, gen_loss = 0.9824151609625135, disc_loss = 0.0011385432486089744
Trained batch 14 in epoch 6, gen_loss = 0.9846450765927632, disc_loss = 0.0010976780594016114
Trained batch 15 in epoch 6, gen_loss = 0.9829838015139103, disc_loss = 0.0010889178120123688
Trained batch 16 in epoch 6, gen_loss = 0.9840227540801553, disc_loss = 0.0011488764361916658
Trained batch 17 in epoch 6, gen_loss = 0.9849677450127072, disc_loss = 0.0012433383672032505
Trained batch 18 in epoch 6, gen_loss = 0.9850432433580097, disc_loss = 0.0013015648919941956
Trained batch 19 in epoch 6, gen_loss = 0.9853522062301636, disc_loss = 0.0013138518057530745
Trained batch 20 in epoch 6, gen_loss = 0.9853502966108776, disc_loss = 0.0013006642943115107
Trained batch 21 in epoch 6, gen_loss = 0.9866308786652305, disc_loss = 0.0012717749129726806
Trained batch 22 in epoch 6, gen_loss = 0.9867863940156024, disc_loss = 0.0012515731454502952
Trained batch 23 in epoch 6, gen_loss = 0.9866757839918137, disc_loss = 0.0012547140189174872
Trained batch 24 in epoch 6, gen_loss = 0.987160267829895, disc_loss = 0.001289521085564047
Trained batch 25 in epoch 6, gen_loss = 0.9868919459673074, disc_loss = 0.0013468683218189443
Trained batch 26 in epoch 6, gen_loss = 0.987860174090774, disc_loss = 0.0014007643179933507
Trained batch 27 in epoch 6, gen_loss = 0.9879579778228488, disc_loss = 0.0014341744099510834
Trained batch 28 in epoch 6, gen_loss = 0.9899178352849237, disc_loss = 0.0014437029423224259
Trained batch 29 in epoch 6, gen_loss = 0.9905659099419911, disc_loss = 0.001442077400861308
Trained batch 30 in epoch 6, gen_loss = 0.9904228583458932, disc_loss = 0.0014445792166365972
Trained batch 31 in epoch 6, gen_loss = 0.9898035693913698, disc_loss = 0.001456616906580166
Trained batch 32 in epoch 6, gen_loss = 0.9904598124099501, disc_loss = 0.0014627653290517628
Trained batch 33 in epoch 6, gen_loss = 0.9911215848782483, disc_loss = 0.001459223370629308
Trained batch 34 in epoch 6, gen_loss = 0.9910075783729553, disc_loss = 0.0014534889404395862
Trained batch 35 in epoch 6, gen_loss = 0.9902880390485128, disc_loss = 0.0014451203702871378
Trained batch 36 in epoch 6, gen_loss = 0.9897869003785623, disc_loss = 0.0014390064909978694
Trained batch 37 in epoch 6, gen_loss = 0.9909764198880446, disc_loss = 0.0014326922598564508
Trained batch 38 in epoch 6, gen_loss = 0.9910702353868729, disc_loss = 0.0014318923946493901
Trained batch 39 in epoch 6, gen_loss = 0.990640239417553, disc_loss = 0.0014312129278550856
Trained batch 40 in epoch 6, gen_loss = 0.9896932026235069, disc_loss = 0.0014277327814275717
Trained batch 41 in epoch 6, gen_loss = 0.9901579533304486, disc_loss = 0.0014270710013252461
Trained batch 42 in epoch 6, gen_loss = 0.9900310469228167, disc_loss = 0.0014358157668327696
Trained batch 43 in epoch 6, gen_loss = 0.9897018508477644, disc_loss = 0.001452855171836828
Trained batch 44 in epoch 6, gen_loss = 0.989498680167728, disc_loss = 0.0014718807651661336
Trained batch 45 in epoch 6, gen_loss = 0.9902705874132074, disc_loss = 0.001494804188437031
Trained batch 46 in epoch 6, gen_loss = 0.9899476322721927, disc_loss = 0.0015257499614195463
Trained batch 47 in epoch 6, gen_loss = 0.9901727326214314, disc_loss = 0.0015629443793538182
Trained batch 48 in epoch 6, gen_loss = 0.9899767625088595, disc_loss = 0.0015901189276055262
Trained batch 49 in epoch 6, gen_loss = 0.990253449678421, disc_loss = 0.0015988740825559943
Trained batch 50 in epoch 6, gen_loss = 0.989508190575768, disc_loss = 0.0015970117460443255
Trained batch 51 in epoch 6, gen_loss = 0.9895630031824112, disc_loss = 0.001596793117082248
Trained batch 52 in epoch 6, gen_loss = 0.9902906564046752, disc_loss = 0.0016094620948007225
Trained batch 53 in epoch 6, gen_loss = 0.9900608051706243, disc_loss = 0.0016383672212854166
Trained batch 54 in epoch 6, gen_loss = 0.9908342914147811, disc_loss = 0.001687553128100593
Trained batch 55 in epoch 6, gen_loss = 0.9907288455537387, disc_loss = 0.0017299488213861228
Trained batch 56 in epoch 6, gen_loss = 0.9914481692146837, disc_loss = 0.0017533688816209242
Trained batch 57 in epoch 6, gen_loss = 0.9917742969660923, disc_loss = 0.001762884959040595
Trained batch 58 in epoch 6, gen_loss = 0.9917464377516407, disc_loss = 0.0017664945157544719
Trained batch 59 in epoch 6, gen_loss = 0.9915530681610107, disc_loss = 0.0017608941309542085
Trained batch 60 in epoch 6, gen_loss = 0.9914026846651172, disc_loss = 0.0017469988069039022
Trained batch 61 in epoch 6, gen_loss = 0.9910988365450213, disc_loss = 0.0017299717395461254
Trained batch 62 in epoch 6, gen_loss = 0.9904773452925304, disc_loss = 0.0017127115547376137
Trained batch 63 in epoch 6, gen_loss = 0.9910710072144866, disc_loss = 0.0016959443191808532
Trained batch 64 in epoch 6, gen_loss = 0.9911336788764367, disc_loss = 0.0016814395203255117
Trained batch 65 in epoch 6, gen_loss = 0.991375820203261, disc_loss = 0.0016661835631539086
Trained batch 66 in epoch 6, gen_loss = 0.9920653567385318, disc_loss = 0.0016493682650529516
Trained batch 67 in epoch 6, gen_loss = 0.9924624790163601, disc_loss = 0.00163178590403678
Trained batch 68 in epoch 6, gen_loss = 0.9923934470052305, disc_loss = 0.0016143081272763295
Trained batch 69 in epoch 6, gen_loss = 0.9928298286029271, disc_loss = 0.001597261753964371
Trained batch 70 in epoch 6, gen_loss = 0.9924801823119043, disc_loss = 0.00158001600131786
Trained batch 71 in epoch 6, gen_loss = 0.9926507025957108, disc_loss = 0.0015658652466501938
Trained batch 72 in epoch 6, gen_loss = 0.9922304357567878, disc_loss = 0.001553790406196391
Trained batch 73 in epoch 6, gen_loss = 0.9928037451731192, disc_loss = 0.0015445914618180108
Trained batch 74 in epoch 6, gen_loss = 0.9929674601554871, disc_loss = 0.001532899223578473
Trained batch 75 in epoch 6, gen_loss = 0.9935173619734613, disc_loss = 0.0015206449047821622
Trained batch 76 in epoch 6, gen_loss = 0.9937844408022893, disc_loss = 0.0015075468388688448
Trained batch 77 in epoch 6, gen_loss = 0.9939575630884904, disc_loss = 0.001496668652786563
Trained batch 78 in epoch 6, gen_loss = 0.99384238523773, disc_loss = 0.0014895592164837672
Trained batch 79 in epoch 6, gen_loss = 0.9941751889884471, disc_loss = 0.0014869684862787835
Trained batch 80 in epoch 6, gen_loss = 0.9941591002323009, disc_loss = 0.0014878803516312697
Trained batch 81 in epoch 6, gen_loss = 0.9943463838681942, disc_loss = 0.0014874301935977688
Trained batch 82 in epoch 6, gen_loss = 0.9941814513091581, disc_loss = 0.0014836752130818296
Trained batch 83 in epoch 6, gen_loss = 0.9942259838183721, disc_loss = 0.001479037017339752
Trained batch 84 in epoch 6, gen_loss = 0.9940618024152867, disc_loss = 0.0014729457797811312
Trained batch 85 in epoch 6, gen_loss = 0.9942511805268222, disc_loss = 0.0014659964396932358
Trained batch 86 in epoch 6, gen_loss = 0.994156588768137, disc_loss = 0.0014586110596662794
Trained batch 87 in epoch 6, gen_loss = 0.9939613619988615, disc_loss = 0.001449155851415443
Trained batch 88 in epoch 6, gen_loss = 0.993956854504146, disc_loss = 0.001438963415331385
Trained batch 89 in epoch 6, gen_loss = 0.9940374235312144, disc_loss = 0.0014295555082046323
Trained batch 90 in epoch 6, gen_loss = 0.9944518025104816, disc_loss = 0.0014251029326140389
Trained batch 91 in epoch 6, gen_loss = 0.9941323444895123, disc_loss = 0.0014229774773728263
Trained batch 92 in epoch 6, gen_loss = 0.9938597493274237, disc_loss = 0.0014228530363329956
Trained batch 93 in epoch 6, gen_loss = 0.9935884913231464, disc_loss = 0.0014259740846489179
Trained batch 94 in epoch 6, gen_loss = 0.9935417520372491, disc_loss = 0.0014265940781976831
Trained batch 95 in epoch 6, gen_loss = 0.993444507320722, disc_loss = 0.001424413832864957
Trained batch 96 in epoch 6, gen_loss = 0.9935538928533337, disc_loss = 0.0014195277760064556
Trained batch 97 in epoch 6, gen_loss = 0.9930317414050199, disc_loss = 0.0014120209350355197
Trained batch 98 in epoch 6, gen_loss = 0.9932213804938577, disc_loss = 0.0014061687644712176
Trained batch 99 in epoch 6, gen_loss = 0.9932287287712097, disc_loss = 0.0014004552405094727
Trained batch 100 in epoch 6, gen_loss = 0.9936399979166465, disc_loss = 0.0013950355252997932
Trained batch 101 in epoch 6, gen_loss = 0.993781234703812, disc_loss = 0.0013884846320804938
Trained batch 102 in epoch 6, gen_loss = 0.993838744256103, disc_loss = 0.0013805012613109955
Trained batch 103 in epoch 6, gen_loss = 0.9938589684092082, disc_loss = 0.0013715710195426184
Trained batch 104 in epoch 6, gen_loss = 0.9940202559743608, disc_loss = 0.0013621767971753365
Trained batch 105 in epoch 6, gen_loss = 0.9938764420320403, disc_loss = 0.0013541771145098192
Trained batch 106 in epoch 6, gen_loss = 0.9937964616534866, disc_loss = 0.0013463426741475465
Trained batch 107 in epoch 6, gen_loss = 0.9938979364103742, disc_loss = 0.0013366055166072867
Trained batch 108 in epoch 6, gen_loss = 0.994372028276461, disc_loss = 0.0013291138232847967
Trained batch 109 in epoch 6, gen_loss = 0.994209520925175, disc_loss = 0.0013220559525176543
Trained batch 110 in epoch 6, gen_loss = 0.9944191446175447, disc_loss = 0.0013148252399185218
Trained batch 111 in epoch 6, gen_loss = 0.9944467922406537, disc_loss = 0.0013088267073076817
Trained batch 112 in epoch 6, gen_loss = 0.9942949150515868, disc_loss = 0.0013030062525417755
Trained batch 113 in epoch 6, gen_loss = 0.9941392357934985, disc_loss = 0.0012972418238253642
Trained batch 114 in epoch 6, gen_loss = 0.9940925878027211, disc_loss = 0.0012913425508684114
Trained batch 115 in epoch 6, gen_loss = 0.993882115544944, disc_loss = 0.0012840582986145504
Trained batch 116 in epoch 6, gen_loss = 0.9939748497090788, disc_loss = 0.0012761711677273687
Trained batch 117 in epoch 6, gen_loss = 0.9939687519760455, disc_loss = 0.0012681194136148098
Trained batch 118 in epoch 6, gen_loss = 0.9938625032160463, disc_loss = 0.0012610013373665699
Trained batch 119 in epoch 6, gen_loss = 0.9937960714101791, disc_loss = 0.0012550600746180861
Trained batch 120 in epoch 6, gen_loss = 0.9935509774310529, disc_loss = 0.0012495052665933845
Trained batch 121 in epoch 6, gen_loss = 0.9934351903493287, disc_loss = 0.001243528736312492
Trained batch 122 in epoch 6, gen_loss = 0.9937508522979612, disc_loss = 0.0012394427085234746
Trained batch 123 in epoch 6, gen_loss = 0.9940172328102973, disc_loss = 0.0012365218604944886
Trained batch 124 in epoch 6, gen_loss = 0.9940634489059448, disc_loss = 0.0012364924699068069
Trained batch 125 in epoch 6, gen_loss = 0.9941618565529112, disc_loss = 0.0012420980769786098
Trained batch 126 in epoch 6, gen_loss = 0.9938540374200175, disc_loss = 0.0012494436516536501
Trained batch 127 in epoch 6, gen_loss = 0.9938782416284084, disc_loss = 0.001255351440704544
Trained batch 128 in epoch 6, gen_loss = 0.9940537888874379, disc_loss = 0.0012599808306527115
Trained batch 129 in epoch 6, gen_loss = 0.9940182695021996, disc_loss = 0.0012642825801426974
Trained batch 130 in epoch 6, gen_loss = 0.9941935220747503, disc_loss = 0.0012698071548459299
Trained batch 131 in epoch 6, gen_loss = 0.9942964468941544, disc_loss = 0.0012732706037984992
Trained batch 132 in epoch 6, gen_loss = 0.9943612670539913, disc_loss = 0.0012756157718962968
Trained batch 133 in epoch 6, gen_loss = 0.9945611215349454, disc_loss = 0.0012743061794134886
Trained batch 134 in epoch 6, gen_loss = 0.9944230786076298, disc_loss = 0.001269569401456802
Trained batch 135 in epoch 6, gen_loss = 0.9942038567627177, disc_loss = 0.0012646744032869773
Trained batch 136 in epoch 6, gen_loss = 0.9941944349421202, disc_loss = 0.0012606715521754793
Trained batch 137 in epoch 6, gen_loss = 0.9940836567809617, disc_loss = 0.0012582034974331982
Trained batch 138 in epoch 6, gen_loss = 0.9940188188347028, disc_loss = 0.001257441864221645
Trained batch 139 in epoch 6, gen_loss = 0.9941029838153295, disc_loss = 0.0012592849088832736
Trained batch 140 in epoch 6, gen_loss = 0.9941765898508383, disc_loss = 0.0012614905127449662
Trained batch 141 in epoch 6, gen_loss = 0.9941670017343172, disc_loss = 0.0012592658085722318
Trained batch 142 in epoch 6, gen_loss = 0.9942001116859329, disc_loss = 0.001254765913167226
Trained batch 143 in epoch 6, gen_loss = 0.9944848455488682, disc_loss = 0.0012506849573886332
Trained batch 144 in epoch 6, gen_loss = 0.994364580203747, disc_loss = 0.0012470551071977565
Trained batch 145 in epoch 6, gen_loss = 0.9943088288993052, disc_loss = 0.00124300540782103
Trained batch 146 in epoch 6, gen_loss = 0.9942108660328145, disc_loss = 0.0012389640236704223
Trained batch 147 in epoch 6, gen_loss = 0.9946178036767084, disc_loss = 0.0012353464486738164
Trained batch 148 in epoch 6, gen_loss = 0.9943602113115707, disc_loss = 0.0012345846532218958
Trained batch 149 in epoch 6, gen_loss = 0.9941585993766785, disc_loss = 0.0012346028734464198
Trained batch 150 in epoch 6, gen_loss = 0.9940774172347113, disc_loss = 0.0012298952418052598
Trained batch 151 in epoch 6, gen_loss = 0.9941157345709047, disc_loss = 0.0012242355459372782
Trained batch 152 in epoch 6, gen_loss = 0.9941976327522128, disc_loss = 0.0012213821285876013
Trained batch 153 in epoch 6, gen_loss = 0.9943487605491241, disc_loss = 0.0012204271233595256
Trained batch 154 in epoch 6, gen_loss = 0.9941712879365491, disc_loss = 0.001216818617408975
Trained batch 155 in epoch 6, gen_loss = 0.9943845692353371, disc_loss = 0.0012126266517906259
Trained batch 156 in epoch 6, gen_loss = 0.9941544217668521, disc_loss = 0.001212215938072972
Trained batch 157 in epoch 6, gen_loss = 0.9941971532151669, disc_loss = 0.0012150139673509858
Trained batch 158 in epoch 6, gen_loss = 0.9944315102865111, disc_loss = 0.0012165088627162338
Trained batch 159 in epoch 6, gen_loss = 0.9943781960755587, disc_loss = 0.0012140816632381756
Trained batch 160 in epoch 6, gen_loss = 0.9943602533073899, disc_loss = 0.0012098053332507866
Trained batch 161 in epoch 6, gen_loss = 0.9942683934429546, disc_loss = 0.0012062838361066777
Trained batch 162 in epoch 6, gen_loss = 0.9943111897246238, disc_loss = 0.0012067905853950973
Trained batch 163 in epoch 6, gen_loss = 0.994255270536353, disc_loss = 0.0012136309039594447
Trained batch 164 in epoch 6, gen_loss = 0.9939946250482039, disc_loss = 0.0012199445273092186
Trained batch 165 in epoch 6, gen_loss = 0.9941301349415836, disc_loss = 0.001218160828792894
Trained batch 166 in epoch 6, gen_loss = 0.9940969519272536, disc_loss = 0.0012152035750970132
Trained batch 167 in epoch 6, gen_loss = 0.993753640069848, disc_loss = 0.001214818067680989
Trained batch 168 in epoch 6, gen_loss = 0.9936841507635173, disc_loss = 0.001210876846081197
Trained batch 169 in epoch 6, gen_loss = 0.9939558225519517, disc_loss = 0.001206955932909349
Trained batch 170 in epoch 6, gen_loss = 0.9938521325936791, disc_loss = 0.0012030606469539762
Trained batch 171 in epoch 6, gen_loss = 0.9938746943723323, disc_loss = 0.0011996432976745784
Trained batch 172 in epoch 6, gen_loss = 0.9940714460576889, disc_loss = 0.001196628855171242
Trained batch 173 in epoch 6, gen_loss = 0.9942809394721327, disc_loss = 0.001193485998357218
Trained batch 174 in epoch 6, gen_loss = 0.9941910924230303, disc_loss = 0.0011896127297742558
Trained batch 175 in epoch 6, gen_loss = 0.9940366690809076, disc_loss = 0.0011859431762621336
Trained batch 176 in epoch 6, gen_loss = 0.9937422083596051, disc_loss = 0.0011823789710192125
Trained batch 177 in epoch 6, gen_loss = 0.9939049432116948, disc_loss = 0.0011792469161805916
Trained batch 178 in epoch 6, gen_loss = 0.9937685045450093, disc_loss = 0.001182893893516274
Trained batch 179 in epoch 6, gen_loss = 0.9935822397470474, disc_loss = 0.0011873118723289937
Trained batch 180 in epoch 6, gen_loss = 0.9935071109408173, disc_loss = 0.0011858336676686529
Trained batch 181 in epoch 6, gen_loss = 0.9933121060277079, disc_loss = 0.0011826956180592098
Trained batch 182 in epoch 6, gen_loss = 0.9934292960036648, disc_loss = 0.001186806605677146
Trained batch 183 in epoch 6, gen_loss = 0.9934188487089198, disc_loss = 0.0011955567513169904
Trained batch 184 in epoch 6, gen_loss = 0.9934273246172313, disc_loss = 0.0011973476403934025
Trained batch 185 in epoch 6, gen_loss = 0.9934309903652437, disc_loss = 0.0011940126378347056
Trained batch 186 in epoch 6, gen_loss = 0.9936299492968595, disc_loss = 0.001192324741134659
Trained batch 187 in epoch 6, gen_loss = 0.9933046587604157, disc_loss = 0.0011902240616148041
Trained batch 188 in epoch 6, gen_loss = 0.9933548317384467, disc_loss = 0.0011891302270457523
Trained batch 189 in epoch 6, gen_loss = 0.9932439675456599, disc_loss = 0.0011924885107682233
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.0069712400436401, disc_loss = 0.002650158479809761
Trained batch 1 in epoch 7, gen_loss = 0.9801469147205353, disc_loss = 0.0030342356767505407
Trained batch 2 in epoch 7, gen_loss = 0.9839273492495219, disc_loss = 0.0034209773875772953
Trained batch 3 in epoch 7, gen_loss = 0.9796997308731079, disc_loss = 0.003572085755877197
Trained batch 4 in epoch 7, gen_loss = 0.9852956056594848, disc_loss = 0.0034781410358846188
Trained batch 5 in epoch 7, gen_loss = 0.9878650705019633, disc_loss = 0.0032417874317616224
Trained batch 6 in epoch 7, gen_loss = 0.9911925281797137, disc_loss = 0.003003753023222089
Trained batch 7 in epoch 7, gen_loss = 0.9907835125923157, disc_loss = 0.002793744206428528
Trained batch 8 in epoch 7, gen_loss = 0.9942113293541802, disc_loss = 0.002628475168926848
Trained batch 9 in epoch 7, gen_loss = 0.990017032623291, disc_loss = 0.0024707372765988113
Trained batch 10 in epoch 7, gen_loss = 0.9897630323063243, disc_loss = 0.002322946405249902
Trained batch 11 in epoch 7, gen_loss = 0.9905468126138052, disc_loss = 0.002183037892488452
Trained batch 12 in epoch 7, gen_loss = 0.9888251377986028, disc_loss = 0.0020862323178264955
Trained batch 13 in epoch 7, gen_loss = 0.9920102953910828, disc_loss = 0.002080314967315644
Trained batch 14 in epoch 7, gen_loss = 0.9925573507944743, disc_loss = 0.0020922923538212973
Trained batch 15 in epoch 7, gen_loss = 0.9914074204862118, disc_loss = 0.0020402210284373723
Trained batch 16 in epoch 7, gen_loss = 0.98989038958269, disc_loss = 0.0019733279135406893
Trained batch 17 in epoch 7, gen_loss = 0.9886876278453403, disc_loss = 0.0019081746221571746
Trained batch 18 in epoch 7, gen_loss = 0.9892613856415999, disc_loss = 0.0018478710798693722
Trained batch 19 in epoch 7, gen_loss = 0.9890143275260925, disc_loss = 0.0017921251361258327
Trained batch 20 in epoch 7, gen_loss = 0.9896017483302525, disc_loss = 0.0017439360103924714
Trained batch 21 in epoch 7, gen_loss = 0.9903884692625566, disc_loss = 0.0016948465146759356
Trained batch 22 in epoch 7, gen_loss = 0.9905698714048966, disc_loss = 0.0016426457441411912
Trained batch 23 in epoch 7, gen_loss = 0.9895590369900068, disc_loss = 0.0015929706205497496
Trained batch 24 in epoch 7, gen_loss = 0.9893473267555237, disc_loss = 0.0015526278200559318
Trained batch 25 in epoch 7, gen_loss = 0.989502109014071, disc_loss = 0.0015176761438711905
Trained batch 26 in epoch 7, gen_loss = 0.9900433973029807, disc_loss = 0.001481665468654009
Trained batch 27 in epoch 7, gen_loss = 0.988926329783031, disc_loss = 0.0014477807729105865
Trained batch 28 in epoch 7, gen_loss = 0.9880027770996094, disc_loss = 0.0014216089259897326
Trained batch 29 in epoch 7, gen_loss = 0.987463754415512, disc_loss = 0.0014124451166329284
Trained batch 30 in epoch 7, gen_loss = 0.986729496909726, disc_loss = 0.0014245596661743138
Trained batch 31 in epoch 7, gen_loss = 0.9860644601285458, disc_loss = 0.0014444326261582319
Trained batch 32 in epoch 7, gen_loss = 0.9878259427619703, disc_loss = 0.0014701907163147223
Trained batch 33 in epoch 7, gen_loss = 0.9873850661165574, disc_loss = 0.0014860073193524253
Trained batch 34 in epoch 7, gen_loss = 0.9867374045508248, disc_loss = 0.0014799955068156123
Trained batch 35 in epoch 7, gen_loss = 0.9871879782941606, disc_loss = 0.0014585761430983741
Trained batch 36 in epoch 7, gen_loss = 0.9871270914335508, disc_loss = 0.001435167741382847
Trained batch 37 in epoch 7, gen_loss = 0.9879302382469177, disc_loss = 0.0014142925256716186
Trained batch 38 in epoch 7, gen_loss = 0.9876375733277737, disc_loss = 0.001397390393182062
Trained batch 39 in epoch 7, gen_loss = 0.987959711253643, disc_loss = 0.001384325158142019
Trained batch 40 in epoch 7, gen_loss = 0.9872276870215811, disc_loss = 0.001368966420669472
Trained batch 41 in epoch 7, gen_loss = 0.9874299239544642, disc_loss = 0.0013506531928821157
Trained batch 42 in epoch 7, gen_loss = 0.9867082044135692, disc_loss = 0.0013323537450348742
Trained batch 43 in epoch 7, gen_loss = 0.986103122884577, disc_loss = 0.0013146218486574733
Trained batch 44 in epoch 7, gen_loss = 0.9867793983883328, disc_loss = 0.0013006371691719526
Trained batch 45 in epoch 7, gen_loss = 0.9874572131944739, disc_loss = 0.0012939975270495304
Trained batch 46 in epoch 7, gen_loss = 0.9872381496936717, disc_loss = 0.0012855594197506124
Trained batch 47 in epoch 7, gen_loss = 0.9870460058252016, disc_loss = 0.0012727562110133779
Trained batch 48 in epoch 7, gen_loss = 0.9873788551408418, disc_loss = 0.0012588621905947827
Trained batch 49 in epoch 7, gen_loss = 0.9872171711921692, disc_loss = 0.0012425351020647214
Trained batch 50 in epoch 7, gen_loss = 0.9871488692713719, disc_loss = 0.0012237570669693762
Trained batch 51 in epoch 7, gen_loss = 0.987263982112591, disc_loss = 0.0012086974277805823
Trained batch 52 in epoch 7, gen_loss = 0.9869560070757596, disc_loss = 0.0011937589206697666
Trained batch 53 in epoch 7, gen_loss = 0.9875330306865551, disc_loss = 0.001178739832809057
Trained batch 54 in epoch 7, gen_loss = 0.9874035770242865, disc_loss = 0.001170737377833575
Trained batch 55 in epoch 7, gen_loss = 0.9869864700095994, disc_loss = 0.0011662425063799933
Trained batch 56 in epoch 7, gen_loss = 0.9869360400919329, disc_loss = 0.0011576301787914545
Trained batch 57 in epoch 7, gen_loss = 0.9867021482566307, disc_loss = 0.0011468479431892649
Trained batch 58 in epoch 7, gen_loss = 0.986362370394044, disc_loss = 0.0011366648921127414
Trained batch 59 in epoch 7, gen_loss = 0.9862712909777959, disc_loss = 0.0011250146257225425
Trained batch 60 in epoch 7, gen_loss = 0.9861690734253555, disc_loss = 0.0011137507724209277
Trained batch 61 in epoch 7, gen_loss = 0.9860145324660886, disc_loss = 0.0011026121196224385
Trained batch 62 in epoch 7, gen_loss = 0.9858951871357267, disc_loss = 0.001092055937670733
Trained batch 63 in epoch 7, gen_loss = 0.9854761902242899, disc_loss = 0.001083572671177535
Trained batch 64 in epoch 7, gen_loss = 0.986464447241563, disc_loss = 0.0010799826628779276
Trained batch 65 in epoch 7, gen_loss = 0.9858908111398871, disc_loss = 0.0010788259577097822
Trained batch 66 in epoch 7, gen_loss = 0.9856779753272213, disc_loss = 0.001080336096547127
Trained batch 67 in epoch 7, gen_loss = 0.9866655398817623, disc_loss = 0.0010814302629168035
Trained batch 68 in epoch 7, gen_loss = 0.9867260300594828, disc_loss = 0.001080186381696494
Trained batch 69 in epoch 7, gen_loss = 0.9871454545429774, disc_loss = 0.0010766419519703569
Trained batch 70 in epoch 7, gen_loss = 0.9876123448492775, disc_loss = 0.0010749649024457003
Trained batch 71 in epoch 7, gen_loss = 0.9879324469301436, disc_loss = 0.001076907456687574
Trained batch 72 in epoch 7, gen_loss = 0.988261877673946, disc_loss = 0.0010842521509876449
Trained batch 73 in epoch 7, gen_loss = 0.9879085196031107, disc_loss = 0.001094004839762567
Trained batch 74 in epoch 7, gen_loss = 0.9887513319651285, disc_loss = 0.001105244771655028
Trained batch 75 in epoch 7, gen_loss = 0.988692719685404, disc_loss = 0.001111312837134679
Trained batch 76 in epoch 7, gen_loss = 0.9886799919140803, disc_loss = 0.0011126513690415576
Trained batch 77 in epoch 7, gen_loss = 0.9887463794304774, disc_loss = 0.0011098164500137314
Trained batch 78 in epoch 7, gen_loss = 0.989289584793622, disc_loss = 0.0011062807586969502
Trained batch 79 in epoch 7, gen_loss = 0.9889777198433876, disc_loss = 0.0011075425634771818
Trained batch 80 in epoch 7, gen_loss = 0.98910285587664, disc_loss = 0.0011124602669165872
Trained batch 81 in epoch 7, gen_loss = 0.9896678393933831, disc_loss = 0.0011166069168943866
Trained batch 82 in epoch 7, gen_loss = 0.9891624781022589, disc_loss = 0.0011192289793286025
Trained batch 83 in epoch 7, gen_loss = 0.989257602464585, disc_loss = 0.0011212932215476897
Trained batch 84 in epoch 7, gen_loss = 0.988865943516002, disc_loss = 0.0011226703964091619
Trained batch 85 in epoch 7, gen_loss = 0.9888383247131525, disc_loss = 0.0011230104952796125
Trained batch 86 in epoch 7, gen_loss = 0.9894778796996193, disc_loss = 0.001122760313801232
Trained batch 87 in epoch 7, gen_loss = 0.9895570549097928, disc_loss = 0.0011207839868968056
Trained batch 88 in epoch 7, gen_loss = 0.9893290634905354, disc_loss = 0.0011178355685597433
Trained batch 89 in epoch 7, gen_loss = 0.9891341679626041, disc_loss = 0.001113025327019083
Trained batch 90 in epoch 7, gen_loss = 0.9888864434682406, disc_loss = 0.0011068794612163822
Trained batch 91 in epoch 7, gen_loss = 0.9889558624962101, disc_loss = 0.0011020814731043924
Trained batch 92 in epoch 7, gen_loss = 0.9888296185001251, disc_loss = 0.0011002171339632401
Trained batch 93 in epoch 7, gen_loss = 0.9884808501030536, disc_loss = 0.0010997519591213897
Trained batch 94 in epoch 7, gen_loss = 0.9887008296815972, disc_loss = 0.001099559499600314
Trained batch 95 in epoch 7, gen_loss = 0.9889204086114963, disc_loss = 0.0010977210589165527
Trained batch 96 in epoch 7, gen_loss = 0.9888414556218177, disc_loss = 0.0010925770473796106
Trained batch 97 in epoch 7, gen_loss = 0.9888771291898222, disc_loss = 0.0010854453902705858
Trained batch 98 in epoch 7, gen_loss = 0.9889674433554062, disc_loss = 0.001081865067732511
Trained batch 99 in epoch 7, gen_loss = 0.9892704361677169, disc_loss = 0.0010851214834838175
Trained batch 100 in epoch 7, gen_loss = 0.9885728223489063, disc_loss = 0.0010889908964492121
Trained batch 101 in epoch 7, gen_loss = 0.9886200316980773, disc_loss = 0.0010909968710335555
Trained batch 102 in epoch 7, gen_loss = 0.9887221889588439, disc_loss = 0.001092676476527964
Trained batch 103 in epoch 7, gen_loss = 0.9893382042646408, disc_loss = 0.0010921679615701297
Trained batch 104 in epoch 7, gen_loss = 0.9890902700878325, disc_loss = 0.0010912736220884003
Trained batch 105 in epoch 7, gen_loss = 0.9890544453881821, disc_loss = 0.0010909574654915388
Trained batch 106 in epoch 7, gen_loss = 0.989039427766176, disc_loss = 0.0010894242922718871
Trained batch 107 in epoch 7, gen_loss = 0.9888878497812483, disc_loss = 0.001087467308227335
Trained batch 108 in epoch 7, gen_loss = 0.988943935534276, disc_loss = 0.0010866557278375595
Trained batch 109 in epoch 7, gen_loss = 0.9890109441497109, disc_loss = 0.0010877441596345637
Trained batch 110 in epoch 7, gen_loss = 0.988840280352412, disc_loss = 0.001086425831958836
Trained batch 111 in epoch 7, gen_loss = 0.9888479741556304, disc_loss = 0.0010845455666900047
Trained batch 112 in epoch 7, gen_loss = 0.9886380101727174, disc_loss = 0.0010831006418860032
Trained batch 113 in epoch 7, gen_loss = 0.9888700848085838, disc_loss = 0.001082980260610368
Trained batch 114 in epoch 7, gen_loss = 0.9889868171318718, disc_loss = 0.0010847993243141504
Trained batch 115 in epoch 7, gen_loss = 0.9888381325993044, disc_loss = 0.0010917523726800874
Trained batch 116 in epoch 7, gen_loss = 0.9889455386716076, disc_loss = 0.0010985239499953026
Trained batch 117 in epoch 7, gen_loss = 0.989277151176485, disc_loss = 0.0011029205306223987
Trained batch 118 in epoch 7, gen_loss = 0.9893682769366673, disc_loss = 0.0011049128475524642
Trained batch 119 in epoch 7, gen_loss = 0.9893610989054044, disc_loss = 0.0011025761862886914
Trained batch 120 in epoch 7, gen_loss = 0.9895267264902099, disc_loss = 0.0010978185784837524
Trained batch 121 in epoch 7, gen_loss = 0.989576872743544, disc_loss = 0.0010928349714004815
Trained batch 122 in epoch 7, gen_loss = 0.9896077300474896, disc_loss = 0.0010887004150649366
Trained batch 123 in epoch 7, gen_loss = 0.9896097337045977, disc_loss = 0.001084613384474294
Trained batch 124 in epoch 7, gen_loss = 0.9898449382781982, disc_loss = 0.0010809806783217937
Trained batch 125 in epoch 7, gen_loss = 0.9897251564358908, disc_loss = 0.0010778384437019537
Trained batch 126 in epoch 7, gen_loss = 0.9897390660338514, disc_loss = 0.0010742207612809323
Trained batch 127 in epoch 7, gen_loss = 0.989653174765408, disc_loss = 0.0010708892448292318
Trained batch 128 in epoch 7, gen_loss = 0.9895393256993257, disc_loss = 0.0010699231961341358
Trained batch 129 in epoch 7, gen_loss = 0.9898794577671931, disc_loss = 0.0010696573552335254
Trained batch 130 in epoch 7, gen_loss = 0.9897568467009159, disc_loss = 0.0010676756174612847
Trained batch 131 in epoch 7, gen_loss = 0.9900444714408932, disc_loss = 0.0010679749109179036
Trained batch 132 in epoch 7, gen_loss = 0.990176714900741, disc_loss = 0.0010717484053605958
Trained batch 133 in epoch 7, gen_loss = 0.9902793653865358, disc_loss = 0.001078146345845646
Trained batch 134 in epoch 7, gen_loss = 0.9903368300861782, disc_loss = 0.0010904849086525953
Trained batch 135 in epoch 7, gen_loss = 0.9905674172674909, disc_loss = 0.0011073010076977558
Trained batch 136 in epoch 7, gen_loss = 0.990419962545381, disc_loss = 0.0011214267721239913
Trained batch 137 in epoch 7, gen_loss = 0.9905996845252272, disc_loss = 0.0011324807843345259
Trained batch 138 in epoch 7, gen_loss = 0.9907119681509279, disc_loss = 0.0011393780890842163
Trained batch 139 in epoch 7, gen_loss = 0.9909972390958242, disc_loss = 0.0011416824137476006
Trained batch 140 in epoch 7, gen_loss = 0.9909735879999526, disc_loss = 0.0011410260408314223
Trained batch 141 in epoch 7, gen_loss = 0.9911360853994396, disc_loss = 0.001138420041993221
Trained batch 142 in epoch 7, gen_loss = 0.9909164163616154, disc_loss = 0.0011350564388769933
Trained batch 143 in epoch 7, gen_loss = 0.9907663779126273, disc_loss = 0.0011316234407180066
Trained batch 144 in epoch 7, gen_loss = 0.9909886031315245, disc_loss = 0.0011281585543625185
Trained batch 145 in epoch 7, gen_loss = 0.991340067288647, disc_loss = 0.0011252729907513864
Trained batch 146 in epoch 7, gen_loss = 0.9916380278918208, disc_loss = 0.0011228931520124708
Trained batch 147 in epoch 7, gen_loss = 0.9917680750022063, disc_loss = 0.0011203328980922674
Trained batch 148 in epoch 7, gen_loss = 0.9917402939508425, disc_loss = 0.0011186757538664536
Trained batch 149 in epoch 7, gen_loss = 0.9917777442932129, disc_loss = 0.00111721169455753
Trained batch 150 in epoch 7, gen_loss = 0.991600792534304, disc_loss = 0.0011148850453958927
Trained batch 151 in epoch 7, gen_loss = 0.9915757943925104, disc_loss = 0.0011110800277444803
Trained batch 152 in epoch 7, gen_loss = 0.9916928994889352, disc_loss = 0.0011062077092527248
Trained batch 153 in epoch 7, gen_loss = 0.9918206492801765, disc_loss = 0.0011011102892966433
Trained batch 154 in epoch 7, gen_loss = 0.9916808766703452, disc_loss = 0.0010960922752987713
Trained batch 155 in epoch 7, gen_loss = 0.9915880323984684, disc_loss = 0.001094877644880818
Trained batch 156 in epoch 7, gen_loss = 0.9913574567266331, disc_loss = 0.001100690253479347
Trained batch 157 in epoch 7, gen_loss = 0.9912742078304291, disc_loss = 0.0011161352427458227
Trained batch 158 in epoch 7, gen_loss = 0.9915134453173703, disc_loss = 0.0011354066023702657
Trained batch 159 in epoch 7, gen_loss = 0.9915603294968605, disc_loss = 0.0011517405942868208
Trained batch 160 in epoch 7, gen_loss = 0.9914993625249922, disc_loss = 0.0011613142719312994
Trained batch 161 in epoch 7, gen_loss = 0.9917311970098519, disc_loss = 0.0011649576635933538
Trained batch 162 in epoch 7, gen_loss = 0.9914907937400912, disc_loss = 0.001164815483966191
Trained batch 163 in epoch 7, gen_loss = 0.9915907931763951, disc_loss = 0.0011620849836617708
Trained batch 164 in epoch 7, gen_loss = 0.9917570211670615, disc_loss = 0.0011586112502934129
Trained batch 165 in epoch 7, gen_loss = 0.9914893928062485, disc_loss = 0.0011551222414709628
Trained batch 166 in epoch 7, gen_loss = 0.9918359849981205, disc_loss = 0.0011522901013722186
Trained batch 167 in epoch 7, gen_loss = 0.9917432672920681, disc_loss = 0.0011518962609919808
Trained batch 168 in epoch 7, gen_loss = 0.9918352887475279, disc_loss = 0.0011547602456167738
Trained batch 169 in epoch 7, gen_loss = 0.99172643142588, disc_loss = 0.00115828062304953
Trained batch 170 in epoch 7, gen_loss = 0.9916936187019125, disc_loss = 0.0011613437261198216
Trained batch 171 in epoch 7, gen_loss = 0.9917332294375397, disc_loss = 0.0011646011922113208
Trained batch 172 in epoch 7, gen_loss = 0.9916924141735011, disc_loss = 0.0011698982037060136
Trained batch 173 in epoch 7, gen_loss = 0.9912798586247982, disc_loss = 0.0011734440678532567
Trained batch 174 in epoch 7, gen_loss = 0.9913418030738831, disc_loss = 0.001176220504234412
Trained batch 175 in epoch 7, gen_loss = 0.9912230413068425, disc_loss = 0.0011775617521462582
Trained batch 176 in epoch 7, gen_loss = 0.9912472852205826, disc_loss = 0.0011778716152497056
Trained batch 177 in epoch 7, gen_loss = 0.9911646431081751, disc_loss = 0.0011759157589469314
Trained batch 178 in epoch 7, gen_loss = 0.9912879523618261, disc_loss = 0.0011721438898668526
Trained batch 179 in epoch 7, gen_loss = 0.9912237581279543, disc_loss = 0.0011675186303263115
Trained batch 180 in epoch 7, gen_loss = 0.9914597941367007, disc_loss = 0.001162862471428324
Trained batch 181 in epoch 7, gen_loss = 0.9913696132518433, disc_loss = 0.001158357415748709
Trained batch 182 in epoch 7, gen_loss = 0.9912347946662069, disc_loss = 0.0011536921509681525
Trained batch 183 in epoch 7, gen_loss = 0.9912334926750349, disc_loss = 0.0011489745895390945
Trained batch 184 in epoch 7, gen_loss = 0.9909621873417416, disc_loss = 0.0011463210318627692
Trained batch 185 in epoch 7, gen_loss = 0.990968838494311, disc_loss = 0.0011502984216153842
Trained batch 186 in epoch 7, gen_loss = 0.9909909150817178, disc_loss = 0.0011589369513430598
Trained batch 187 in epoch 7, gen_loss = 0.9910067284994937, disc_loss = 0.0011677932143743903
Trained batch 188 in epoch 7, gen_loss = 0.9908860713716537, disc_loss = 0.0011736307138880153
Trained batch 189 in epoch 7, gen_loss = 0.9905380926634136, disc_loss = 0.0011747976738996314
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.9764868021011353, disc_loss = 0.0014926057774573565
Trained batch 1 in epoch 8, gen_loss = 0.9977889657020569, disc_loss = 0.0017306728987023234
Trained batch 2 in epoch 8, gen_loss = 0.9889064828554789, disc_loss = 0.0017368190456181765
Trained batch 3 in epoch 8, gen_loss = 0.9801575392484665, disc_loss = 0.0017187881167046726
Trained batch 4 in epoch 8, gen_loss = 0.9789786696434021, disc_loss = 0.0016736939316615463
Trained batch 5 in epoch 8, gen_loss = 0.9902213911215464, disc_loss = 0.0015697224298492074
Trained batch 6 in epoch 8, gen_loss = 0.9958845802715847, disc_loss = 0.0014410252499926304
Trained batch 7 in epoch 8, gen_loss = 0.9930465891957283, disc_loss = 0.0013255443191155791
Trained batch 8 in epoch 8, gen_loss = 0.9973062210612826, disc_loss = 0.0012415420626186663
Trained batch 9 in epoch 8, gen_loss = 0.9946648299694061, disc_loss = 0.001177430694224313
Trained batch 10 in epoch 8, gen_loss = 0.9946646744554694, disc_loss = 0.0011252129651521418
Trained batch 11 in epoch 8, gen_loss = 0.9903423935174942, disc_loss = 0.0010846580989891663
Trained batch 12 in epoch 8, gen_loss = 0.990962775853964, disc_loss = 0.001072830175801825
Trained batch 13 in epoch 8, gen_loss = 0.9911742423261914, disc_loss = 0.0010904469402573471
Trained batch 14 in epoch 8, gen_loss = 0.9893585602442424, disc_loss = 0.0011106144830894968
Trained batch 15 in epoch 8, gen_loss = 0.9883882254362106, disc_loss = 0.0011019695666618645
Trained batch 16 in epoch 8, gen_loss = 0.9877006516737097, disc_loss = 0.001063223188633428
Trained batch 17 in epoch 8, gen_loss = 0.9868574672275119, disc_loss = 0.0010194853869810079
Trained batch 18 in epoch 8, gen_loss = 0.9863951770882857, disc_loss = 0.0009837014153354655
Trained batch 19 in epoch 8, gen_loss = 0.9855607569217681, disc_loss = 0.0009562000617734156
Trained batch 20 in epoch 8, gen_loss = 0.9843828621364775, disc_loss = 0.000943647732215357
Trained batch 21 in epoch 8, gen_loss = 0.9846480380405079, disc_loss = 0.0009626598290527578
Trained batch 22 in epoch 8, gen_loss = 0.9859862327575684, disc_loss = 0.0009841625034586405
Trained batch 23 in epoch 8, gen_loss = 0.9854291255275408, disc_loss = 0.0009727417285224268
Trained batch 24 in epoch 8, gen_loss = 0.9852243494987488, disc_loss = 0.0009501206327695399
Trained batch 25 in epoch 8, gen_loss = 0.9854354239427127, disc_loss = 0.0009385675691121903
Trained batch 26 in epoch 8, gen_loss = 0.9865492471942195, disc_loss = 0.0009398523327911755
Trained batch 27 in epoch 8, gen_loss = 0.9856640888111932, disc_loss = 0.0009379547315932411
Trained batch 28 in epoch 8, gen_loss = 0.98705105329382, disc_loss = 0.0009409379874404263
Trained batch 29 in epoch 8, gen_loss = 0.9876766463120779, disc_loss = 0.00094194993240914
Trained batch 30 in epoch 8, gen_loss = 0.9869215469206533, disc_loss = 0.0009291397882700567
Trained batch 31 in epoch 8, gen_loss = 0.9878559838980436, disc_loss = 0.0009117819772654912
Trained batch 32 in epoch 8, gen_loss = 0.9878750768574801, disc_loss = 0.0008926195256539028
Trained batch 33 in epoch 8, gen_loss = 0.9880451612612781, disc_loss = 0.0008724233540466658
Trained batch 34 in epoch 8, gen_loss = 0.9866902198110308, disc_loss = 0.0008538236953817042
Trained batch 35 in epoch 8, gen_loss = 0.9860112137264676, disc_loss = 0.0008368164215223967
Trained batch 36 in epoch 8, gen_loss = 0.9874332595515896, disc_loss = 0.0008304735112343789
Trained batch 37 in epoch 8, gen_loss = 0.986264191175762, disc_loss = 0.0008357343191930436
Trained batch 38 in epoch 8, gen_loss = 0.987371353002695, disc_loss = 0.0008330530560133645
Trained batch 39 in epoch 8, gen_loss = 0.9878830164670944, disc_loss = 0.0008294783729070332
Trained batch 40 in epoch 8, gen_loss = 0.9887916896401382, disc_loss = 0.0008260014349106336
Trained batch 41 in epoch 8, gen_loss = 0.9873319097927639, disc_loss = 0.0008241648798243009
Trained batch 42 in epoch 8, gen_loss = 0.9868063996004504, disc_loss = 0.0008424014146818758
Trained batch 43 in epoch 8, gen_loss = 0.9863725087859414, disc_loss = 0.0008738079162536782
Trained batch 44 in epoch 8, gen_loss = 0.9867091920640734, disc_loss = 0.0009081143918188496
Trained batch 45 in epoch 8, gen_loss = 0.9871977127116659, disc_loss = 0.0009310890891356394
Trained batch 46 in epoch 8, gen_loss = 0.9865776477976048, disc_loss = 0.0009376378339824286
Trained batch 47 in epoch 8, gen_loss = 0.9858004736403624, disc_loss = 0.0009461969608916357
Trained batch 48 in epoch 8, gen_loss = 0.9861667265697401, disc_loss = 0.0009521856928975987
Trained batch 49 in epoch 8, gen_loss = 0.9865201675891876, disc_loss = 0.0009559460525633768
Trained batch 50 in epoch 8, gen_loss = 0.98652342487784, disc_loss = 0.0009645929579467823
Trained batch 51 in epoch 8, gen_loss = 0.9868745459960058, disc_loss = 0.0009807859656015912
Trained batch 52 in epoch 8, gen_loss = 0.9866749947925784, disc_loss = 0.0009924949367557002
Trained batch 53 in epoch 8, gen_loss = 0.9862304903842785, disc_loss = 0.0009932252971878
Trained batch 54 in epoch 8, gen_loss = 0.9860080632296475, disc_loss = 0.0009865058051549238
Trained batch 55 in epoch 8, gen_loss = 0.985231526196003, disc_loss = 0.0009771532344789843
Trained batch 56 in epoch 8, gen_loss = 0.9849393294568647, disc_loss = 0.0009696771500003116
Trained batch 57 in epoch 8, gen_loss = 0.9845580510024367, disc_loss = 0.0009630908813239236
Trained batch 58 in epoch 8, gen_loss = 0.9844211976406938, disc_loss = 0.0009548718689830374
Trained batch 59 in epoch 8, gen_loss = 0.9852663626273473, disc_loss = 0.0009467689669691026
Trained batch 60 in epoch 8, gen_loss = 0.9854766325872453, disc_loss = 0.000939795768392257
Trained batch 61 in epoch 8, gen_loss = 0.985263757167324, disc_loss = 0.0009332142466108405
Trained batch 62 in epoch 8, gen_loss = 0.9848839328402564, disc_loss = 0.0009263299483185013
Trained batch 63 in epoch 8, gen_loss = 0.984746003523469, disc_loss = 0.0009197106555802748
Trained batch 64 in epoch 8, gen_loss = 0.9849157351713914, disc_loss = 0.0009132759591851097
Trained batch 65 in epoch 8, gen_loss = 0.9849345846609636, disc_loss = 0.0009075362723899271
Trained batch 66 in epoch 8, gen_loss = 0.9844905547241667, disc_loss = 0.0009014029377279108
Trained batch 67 in epoch 8, gen_loss = 0.9845666885375977, disc_loss = 0.0008956408770138617
Trained batch 68 in epoch 8, gen_loss = 0.9848729251087576, disc_loss = 0.0008892095036150051
Trained batch 69 in epoch 8, gen_loss = 0.9848577473844801, disc_loss = 0.0008807402669585177
Trained batch 70 in epoch 8, gen_loss = 0.9847944815393904, disc_loss = 0.0008713543943037659
Trained batch 71 in epoch 8, gen_loss = 0.9846841014093823, disc_loss = 0.0008620900635934151
Trained batch 72 in epoch 8, gen_loss = 0.9848738622992006, disc_loss = 0.0008534293409280658
Trained batch 73 in epoch 8, gen_loss = 0.9851079124051172, disc_loss = 0.0008452042681243698
Trained batch 74 in epoch 8, gen_loss = 0.985683467388153, disc_loss = 0.0008395276647449161
Trained batch 75 in epoch 8, gen_loss = 0.9857846255365171, disc_loss = 0.0008342219595138694
Trained batch 76 in epoch 8, gen_loss = 0.9860003280949283, disc_loss = 0.0008281585497724183
Trained batch 77 in epoch 8, gen_loss = 0.9862518776685764, disc_loss = 0.0008216145195034094
Trained batch 78 in epoch 8, gen_loss = 0.9860105522071259, disc_loss = 0.000814382889996212
Trained batch 79 in epoch 8, gen_loss = 0.9857206970453263, disc_loss = 0.0008082650490905507
Trained batch 80 in epoch 8, gen_loss = 0.985993766490324, disc_loss = 0.0008029446685269912
Trained batch 81 in epoch 8, gen_loss = 0.9863533944618411, disc_loss = 0.0007979730117523748
Trained batch 82 in epoch 8, gen_loss = 0.9865758677563036, disc_loss = 0.0007942837387034446
Trained batch 83 in epoch 8, gen_loss = 0.9863474709647042, disc_loss = 0.0007931727368919556
Trained batch 84 in epoch 8, gen_loss = 0.9858537645900951, disc_loss = 0.0007928352914271219
Trained batch 85 in epoch 8, gen_loss = 0.9856140551178955, disc_loss = 0.0007900630794316639
Trained batch 86 in epoch 8, gen_loss = 0.9857992707997904, disc_loss = 0.0007896297967567205
Trained batch 87 in epoch 8, gen_loss = 0.9858927340670065, disc_loss = 0.0007895784896060253
Trained batch 88 in epoch 8, gen_loss = 0.9859774869479491, disc_loss = 0.000790349830607779
Trained batch 89 in epoch 8, gen_loss = 0.9855880737304688, disc_loss = 0.0007910226641494471
Trained batch 90 in epoch 8, gen_loss = 0.985219521181924, disc_loss = 0.0007897587296371297
Trained batch 91 in epoch 8, gen_loss = 0.9850512956795485, disc_loss = 0.0007866262364942762
Trained batch 92 in epoch 8, gen_loss = 0.9854838290522175, disc_loss = 0.0007830430509119485
Trained batch 93 in epoch 8, gen_loss = 0.985321564243195, disc_loss = 0.0007789798959918775
Trained batch 94 in epoch 8, gen_loss = 0.9856500769916333, disc_loss = 0.0007754957062915262
Trained batch 95 in epoch 8, gen_loss = 0.9853418078273535, disc_loss = 0.0007746583522324121
Trained batch 96 in epoch 8, gen_loss = 0.9850352185288656, disc_loss = 0.000780437611368696
Trained batch 97 in epoch 8, gen_loss = 0.9852232184945321, disc_loss = 0.0007870703600335163
Trained batch 98 in epoch 8, gen_loss = 0.9856160921279831, disc_loss = 0.0007931880064654362
Trained batch 99 in epoch 8, gen_loss = 0.9859488517045975, disc_loss = 0.0007981440440926235
Trained batch 100 in epoch 8, gen_loss = 0.9856920915074868, disc_loss = 0.0007990283093652642
Trained batch 101 in epoch 8, gen_loss = 0.9854321397987067, disc_loss = 0.0007978168282801669
Trained batch 102 in epoch 8, gen_loss = 0.9852113272379903, disc_loss = 0.0007961533885410743
Trained batch 103 in epoch 8, gen_loss = 0.9855568305804179, disc_loss = 0.0007945783143860843
Trained batch 104 in epoch 8, gen_loss = 0.9854730299540928, disc_loss = 0.0007930167428206741
Trained batch 105 in epoch 8, gen_loss = 0.9857433213377899, disc_loss = 0.0007912966801361005
Trained batch 106 in epoch 8, gen_loss = 0.985969339575723, disc_loss = 0.0007897168793661137
Trained batch 107 in epoch 8, gen_loss = 0.9860273721041503, disc_loss = 0.000787369090243441
Trained batch 108 in epoch 8, gen_loss = 0.9860919763188843, disc_loss = 0.000784357776197844
Trained batch 109 in epoch 8, gen_loss = 0.9862039858644659, disc_loss = 0.000780069890871263
Trained batch 110 in epoch 8, gen_loss = 0.9861823438524125, disc_loss = 0.0007752290039862346
Trained batch 111 in epoch 8, gen_loss = 0.9859446021062988, disc_loss = 0.0007709173651164747
Trained batch 112 in epoch 8, gen_loss = 0.9860627914951966, disc_loss = 0.0007685145907427506
Trained batch 113 in epoch 8, gen_loss = 0.9863606680903518, disc_loss = 0.0007657419849062551
Trained batch 114 in epoch 8, gen_loss = 0.9866706713386204, disc_loss = 0.0007619969373437292
Trained batch 115 in epoch 8, gen_loss = 0.9868425264440733, disc_loss = 0.0007580658218949825
Trained batch 116 in epoch 8, gen_loss = 0.9867567842842168, disc_loss = 0.0007549693381849629
Trained batch 117 in epoch 8, gen_loss = 0.9871813796334348, disc_loss = 0.0007561567939681758
Trained batch 118 in epoch 8, gen_loss = 0.9873921340253172, disc_loss = 0.0007597229881515382
Trained batch 119 in epoch 8, gen_loss = 0.9874553248286247, disc_loss = 0.0007603376554470743
Trained batch 120 in epoch 8, gen_loss = 0.9872546161501861, disc_loss = 0.000759756088055755
Trained batch 121 in epoch 8, gen_loss = 0.9870726251211323, disc_loss = 0.0007612460747802034
Trained batch 122 in epoch 8, gen_loss = 0.9869826014448957, disc_loss = 0.0007701397113212407
Trained batch 123 in epoch 8, gen_loss = 0.9869038712593817, disc_loss = 0.0007881574780302828
Trained batch 124 in epoch 8, gen_loss = 0.9869713373184205, disc_loss = 0.000808733417536132
Trained batch 125 in epoch 8, gen_loss = 0.9869179176905799, disc_loss = 0.0008273075050849926
Trained batch 126 in epoch 8, gen_loss = 0.9868305837075542, disc_loss = 0.0008413186891501271
Trained batch 127 in epoch 8, gen_loss = 0.9866841277107596, disc_loss = 0.0008549374041422197
Trained batch 128 in epoch 8, gen_loss = 0.9868297687796659, disc_loss = 0.0008717177393115234
Trained batch 129 in epoch 8, gen_loss = 0.9867816136433528, disc_loss = 0.0008907633930973064
Trained batch 130 in epoch 8, gen_loss = 0.9870365976377298, disc_loss = 0.0009094665833626241
Trained batch 131 in epoch 8, gen_loss = 0.9872897863388062, disc_loss = 0.0009224269807887277
Trained batch 132 in epoch 8, gen_loss = 0.987177968921518, disc_loss = 0.0009283801238533964
Trained batch 133 in epoch 8, gen_loss = 0.9872154611260143, disc_loss = 0.0009298041659892091
Trained batch 134 in epoch 8, gen_loss = 0.9875290967799999, disc_loss = 0.0009285336678321646
Trained batch 135 in epoch 8, gen_loss = 0.9874135562602211, disc_loss = 0.0009248095631097813
Trained batch 136 in epoch 8, gen_loss = 0.9875498453195948, disc_loss = 0.0009200631875169198
Trained batch 137 in epoch 8, gen_loss = 0.9876387369805488, disc_loss = 0.0009162791348121507
Trained batch 138 in epoch 8, gen_loss = 0.9877876317758354, disc_loss = 0.000914088027319777
Trained batch 139 in epoch 8, gen_loss = 0.9879851741450173, disc_loss = 0.0009134962538415234
Trained batch 140 in epoch 8, gen_loss = 0.9883438357224701, disc_loss = 0.0009148311420428031
Trained batch 141 in epoch 8, gen_loss = 0.9880382582335405, disc_loss = 0.0009201510413180919
Trained batch 142 in epoch 8, gen_loss = 0.9883724446896907, disc_loss = 0.0009315432092277463
Trained batch 143 in epoch 8, gen_loss = 0.9883210216131475, disc_loss = 0.0009470519781744871
Trained batch 144 in epoch 8, gen_loss = 0.9882614789337948, disc_loss = 0.0009615306348082257
Trained batch 145 in epoch 8, gen_loss = 0.9882152415301702, disc_loss = 0.0009738845735340226
Trained batch 146 in epoch 8, gen_loss = 0.988365135225309, disc_loss = 0.0009834434904219887
Trained batch 147 in epoch 8, gen_loss = 0.9880868558948105, disc_loss = 0.00098811037595796
Trained batch 148 in epoch 8, gen_loss = 0.9881540192853684, disc_loss = 0.0009886381174742413
Trained batch 149 in epoch 8, gen_loss = 0.9879488110542297, disc_loss = 0.0009871558568556793
Trained batch 150 in epoch 8, gen_loss = 0.9879786715602243, disc_loss = 0.0009865731814072856
Trained batch 151 in epoch 8, gen_loss = 0.9879653983210263, disc_loss = 0.0009876441969314136
Trained batch 152 in epoch 8, gen_loss = 0.9878547733126123, disc_loss = 0.00098921334227544
Trained batch 153 in epoch 8, gen_loss = 0.9881379507578812, disc_loss = 0.0009890098317319152
Trained batch 154 in epoch 8, gen_loss = 0.9880080150019738, disc_loss = 0.0009876794792944565
Trained batch 155 in epoch 8, gen_loss = 0.9880300882535104, disc_loss = 0.0009865562866392653
Trained batch 156 in epoch 8, gen_loss = 0.9881531493678973, disc_loss = 0.000985464507437335
Trained batch 157 in epoch 8, gen_loss = 0.9880182328103464, disc_loss = 0.0009842519993750862
Trained batch 158 in epoch 8, gen_loss = 0.9882116790087718, disc_loss = 0.0009834337451476193
Trained batch 159 in epoch 8, gen_loss = 0.9880628988146782, disc_loss = 0.0009836195712523478
Trained batch 160 in epoch 8, gen_loss = 0.9879639263478865, disc_loss = 0.0009850456417496286
Trained batch 161 in epoch 8, gen_loss = 0.9881689927460234, disc_loss = 0.0009845159221174666
Trained batch 162 in epoch 8, gen_loss = 0.9883710866325472, disc_loss = 0.0009825984150866915
Trained batch 163 in epoch 8, gen_loss = 0.9883389462058138, disc_loss = 0.0009809636031582712
Trained batch 164 in epoch 8, gen_loss = 0.9885496186487602, disc_loss = 0.0009830181239081095
Trained batch 165 in epoch 8, gen_loss = 0.9885096470993685, disc_loss = 0.0009890200284622464
Trained batch 166 in epoch 8, gen_loss = 0.9885487110314969, disc_loss = 0.0009953676545009587
Trained batch 167 in epoch 8, gen_loss = 0.9885614588856697, disc_loss = 0.000997926038464703
Trained batch 168 in epoch 8, gen_loss = 0.9887278104674887, disc_loss = 0.000997205441814197
Trained batch 169 in epoch 8, gen_loss = 0.9889518033055699, disc_loss = 0.0009947780272341333
Trained batch 170 in epoch 8, gen_loss = 0.9887750870303104, disc_loss = 0.0009932847847931947
Trained batch 171 in epoch 8, gen_loss = 0.9889175832964653, disc_loss = 0.0009973176854336365
Trained batch 172 in epoch 8, gen_loss = 0.9891489361751975, disc_loss = 0.0010024823524788658
Trained batch 173 in epoch 8, gen_loss = 0.9890332026728268, disc_loss = 0.0010012081380493287
Trained batch 174 in epoch 8, gen_loss = 0.9892376978056772, disc_loss = 0.0009980942858549367
Trained batch 175 in epoch 8, gen_loss = 0.9892767820168625, disc_loss = 0.0009969958724799324
Trained batch 176 in epoch 8, gen_loss = 0.9892515567062938, disc_loss = 0.0009955015421699005
Trained batch 177 in epoch 8, gen_loss = 0.9894250909264168, disc_loss = 0.0009918546738538609
Trained batch 178 in epoch 8, gen_loss = 0.9894677843461489, disc_loss = 0.0009882075146429876
Trained batch 179 in epoch 8, gen_loss = 0.989389885465304, disc_loss = 0.0009855709346690371
Trained batch 180 in epoch 8, gen_loss = 0.9893589046119985, disc_loss = 0.000982800707396619
Trained batch 181 in epoch 8, gen_loss = 0.9892945695709396, disc_loss = 0.0009792164943704207
Trained batch 182 in epoch 8, gen_loss = 0.9895354685236196, disc_loss = 0.0009755199350311059
Trained batch 183 in epoch 8, gen_loss = 0.9893568067447, disc_loss = 0.0009738798908865251
Trained batch 184 in epoch 8, gen_loss = 0.989373590172948, disc_loss = 0.0009752229067679445
Trained batch 185 in epoch 8, gen_loss = 0.9892065534668584, disc_loss = 0.0009809036158502191
Trained batch 186 in epoch 8, gen_loss = 0.989189848542851, disc_loss = 0.0009898634508089038
Trained batch 187 in epoch 8, gen_loss = 0.9893912387655136, disc_loss = 0.0009956950520102104
Trained batch 188 in epoch 8, gen_loss = 0.9893746423342872, disc_loss = 0.0009964010990058472
Trained batch 189 in epoch 8, gen_loss = 0.9893025225714633, disc_loss = 0.0009947437815227252
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9636538624763489, disc_loss = 0.0006012616213411093
Trained batch 1 in epoch 9, gen_loss = 0.997908741235733, disc_loss = 0.0007938703056424856
Trained batch 2 in epoch 9, gen_loss = 1.0079589088757832, disc_loss = 0.0008669688055912653
Trained batch 3 in epoch 9, gen_loss = 1.01348514854908, disc_loss = 0.0008193215762730688
Trained batch 4 in epoch 9, gen_loss = 1.0053330302238463, disc_loss = 0.0007718786597251892
Trained batch 5 in epoch 9, gen_loss = 1.0107714235782623, disc_loss = 0.0007414565770886838
Trained batch 6 in epoch 9, gen_loss = 1.007394083908626, disc_loss = 0.0007920298126659223
Trained batch 7 in epoch 9, gen_loss = 1.007009096443653, disc_loss = 0.0008843028481351212
Trained batch 8 in epoch 9, gen_loss = 1.0026680098639593, disc_loss = 0.0009966713453953464
Trained batch 9 in epoch 9, gen_loss = 0.9988748967647553, disc_loss = 0.0010988387861289085
Trained batch 10 in epoch 9, gen_loss = 0.9964917247945612, disc_loss = 0.0011234970615160737
Trained batch 11 in epoch 9, gen_loss = 0.9977815051873525, disc_loss = 0.0011022126418538392
Trained batch 12 in epoch 9, gen_loss = 0.9983634857031015, disc_loss = 0.0010556736065504642
Trained batch 13 in epoch 9, gen_loss = 0.9965160148484367, disc_loss = 0.0010043455237921859
Trained batch 14 in epoch 9, gen_loss = 0.9968308846155802, disc_loss = 0.0009623426652979105
Trained batch 15 in epoch 9, gen_loss = 0.9986550360918045, disc_loss = 0.0009266822689824039
Trained batch 16 in epoch 9, gen_loss = 0.9970178393756642, disc_loss = 0.00089338916415513
Trained batch 17 in epoch 9, gen_loss = 0.9957622720135583, disc_loss = 0.0008707684771959773
Trained batch 18 in epoch 9, gen_loss = 0.9942925886103982, disc_loss = 0.0008490536695860914
Trained batch 19 in epoch 9, gen_loss = 0.9936197727918625, disc_loss = 0.0008279410481918603
Trained batch 20 in epoch 9, gen_loss = 0.9918806921868097, disc_loss = 0.0008086087805817702
Trained batch 21 in epoch 9, gen_loss = 0.9927240420471538, disc_loss = 0.0007999483985424212
Trained batch 22 in epoch 9, gen_loss = 0.9936784790909808, disc_loss = 0.000804077435294976
Trained batch 23 in epoch 9, gen_loss = 0.992022305727005, disc_loss = 0.000802249988434293
Trained batch 24 in epoch 9, gen_loss = 0.992175178527832, disc_loss = 0.0007916439010296017
Trained batch 25 in epoch 9, gen_loss = 0.9920887373960935, disc_loss = 0.0007847651689259622
Trained batch 26 in epoch 9, gen_loss = 0.9907387936556781, disc_loss = 0.0007748963296223708
Trained batch 27 in epoch 9, gen_loss = 0.9916417981897082, disc_loss = 0.0007694240703131072
Trained batch 28 in epoch 9, gen_loss = 0.9904829880286907, disc_loss = 0.0008121813930458678
Trained batch 29 in epoch 9, gen_loss = 0.9892413318157196, disc_loss = 0.0008755682201202337
Trained batch 30 in epoch 9, gen_loss = 0.9884566549331911, disc_loss = 0.0009088624323222546
Trained batch 31 in epoch 9, gen_loss = 0.9899414535611868, disc_loss = 0.0009255704871975468
Trained batch 32 in epoch 9, gen_loss = 0.9897549549738566, disc_loss = 0.0009371954744865159
Trained batch 33 in epoch 9, gen_loss = 0.989826912389082, disc_loss = 0.0009446786211543333
Trained batch 34 in epoch 9, gen_loss = 0.9900762864521572, disc_loss = 0.0009433857439684548
Trained batch 35 in epoch 9, gen_loss = 0.9898836033211814, disc_loss = 0.0009342333643063386
Trained batch 36 in epoch 9, gen_loss = 0.9905798580195453, disc_loss = 0.0009190904840235473
Trained batch 37 in epoch 9, gen_loss = 0.990716112287421, disc_loss = 0.0009046994711848368
Trained batch 38 in epoch 9, gen_loss = 0.9907354758335993, disc_loss = 0.0008936371409501403
Trained batch 39 in epoch 9, gen_loss = 0.991328826546669, disc_loss = 0.0008822668482025619
Trained batch 40 in epoch 9, gen_loss = 0.9913255790384804, disc_loss = 0.0008673027815104167
Trained batch 41 in epoch 9, gen_loss = 0.9916994259470985, disc_loss = 0.0008530117387029653
Trained batch 42 in epoch 9, gen_loss = 0.9929724460424378, disc_loss = 0.0008419769529123293
Trained batch 43 in epoch 9, gen_loss = 0.993079047311436, disc_loss = 0.000831443623279814
Trained batch 44 in epoch 9, gen_loss = 0.9929048657417298, disc_loss = 0.0008200409602270359
Trained batch 45 in epoch 9, gen_loss = 0.992911555196928, disc_loss = 0.0008098077587024106
Trained batch 46 in epoch 9, gen_loss = 0.9914759029733374, disc_loss = 0.0008125582683900807
Trained batch 47 in epoch 9, gen_loss = 0.9921616427600384, disc_loss = 0.0008697728523353968
Trained batch 48 in epoch 9, gen_loss = 0.9922758304342931, disc_loss = 0.000981294311825376
Trained batch 49 in epoch 9, gen_loss = 0.9924568831920624, disc_loss = 0.0010797774320235477
Trained batch 50 in epoch 9, gen_loss = 0.9932021615551967, disc_loss = 0.0011360801056748732
Trained batch 51 in epoch 9, gen_loss = 0.9925612188302554, disc_loss = 0.0011471622985062334
Trained batch 52 in epoch 9, gen_loss = 0.9924308781353932, disc_loss = 0.0011415587675555627
Trained batch 53 in epoch 9, gen_loss = 0.9915912813610501, disc_loss = 0.001149306062466672
Trained batch 54 in epoch 9, gen_loss = 0.9913409764116461, disc_loss = 0.0011720727594696325
Trained batch 55 in epoch 9, gen_loss = 0.9908977193491799, disc_loss = 0.0011936349136314156
Trained batch 56 in epoch 9, gen_loss = 0.9906385405021801, disc_loss = 0.0012087610385813669
Trained batch 57 in epoch 9, gen_loss = 0.9902238424482017, disc_loss = 0.0012087952641665872
Trained batch 58 in epoch 9, gen_loss = 0.9899950047670785, disc_loss = 0.001195965670700327
Trained batch 59 in epoch 9, gen_loss = 0.990815116961797, disc_loss = 0.0011818129312208233
Trained batch 60 in epoch 9, gen_loss = 0.9909765349059808, disc_loss = 0.0011708431454474626
Trained batch 61 in epoch 9, gen_loss = 0.9914461489646665, disc_loss = 0.0011628607551815108
Trained batch 62 in epoch 9, gen_loss = 0.9909955499664186, disc_loss = 0.0011574207368077682
Trained batch 63 in epoch 9, gen_loss = 0.9905936345458031, disc_loss = 0.001157195506948483
Trained batch 64 in epoch 9, gen_loss = 0.9898510401065533, disc_loss = 0.0011592429359622586
Trained batch 65 in epoch 9, gen_loss = 0.9892385078198982, disc_loss = 0.0011561564932697256
Trained batch 66 in epoch 9, gen_loss = 0.989406902398636, disc_loss = 0.0011454627839605144
Trained batch 67 in epoch 9, gen_loss = 0.9892299604766509, disc_loss = 0.0011351316112696247
Trained batch 68 in epoch 9, gen_loss = 0.9894244195758433, disc_loss = 0.001124099663802949
Trained batch 69 in epoch 9, gen_loss = 0.9893120689051492, disc_loss = 0.001115216945098447
Trained batch 70 in epoch 9, gen_loss = 0.9893664432243562, disc_loss = 0.001108648205458016
Trained batch 71 in epoch 9, gen_loss = 0.9894243818190362, disc_loss = 0.0011036834338382403
Trained batch 72 in epoch 9, gen_loss = 0.9894470735772015, disc_loss = 0.0010980266020378124
Trained batch 73 in epoch 9, gen_loss = 0.9892559953638025, disc_loss = 0.0010908803189915882
Trained batch 74 in epoch 9, gen_loss = 0.9889709170659383, disc_loss = 0.0010821520649672797
Trained batch 75 in epoch 9, gen_loss = 0.989040132415922, disc_loss = 0.0010726227353045129
Trained batch 76 in epoch 9, gen_loss = 0.9890037674408454, disc_loss = 0.0010634227561335044
Trained batch 77 in epoch 9, gen_loss = 0.9889565538137387, disc_loss = 0.0010549173931418082
Trained batch 78 in epoch 9, gen_loss = 0.9890197062794166, disc_loss = 0.001048006172972743
Trained batch 79 in epoch 9, gen_loss = 0.9891950100660324, disc_loss = 0.001042652474643546
Trained batch 80 in epoch 9, gen_loss = 0.9895920047053585, disc_loss = 0.0010371739199287315
Trained batch 81 in epoch 9, gen_loss = 0.9893107835839434, disc_loss = 0.0010303561249179992
Trained batch 82 in epoch 9, gen_loss = 0.989317754665053, disc_loss = 0.0010232460679463953
Trained batch 83 in epoch 9, gen_loss = 0.989499990429197, disc_loss = 0.0010193426604105515
Trained batch 84 in epoch 9, gen_loss = 0.9896517683477962, disc_loss = 0.0010186885908136474
Trained batch 85 in epoch 9, gen_loss = 0.9897062528965085, disc_loss = 0.001018370937577687
Trained batch 86 in epoch 9, gen_loss = 0.9897540595339632, disc_loss = 0.001015597386365949
Trained batch 87 in epoch 9, gen_loss = 0.9893839088353243, disc_loss = 0.0010095284626665737
Trained batch 88 in epoch 9, gen_loss = 0.9888234788112427, disc_loss = 0.0010023254164091698
Trained batch 89 in epoch 9, gen_loss = 0.9885598811838362, disc_loss = 0.000994886187901203
Trained batch 90 in epoch 9, gen_loss = 0.988382794699826, disc_loss = 0.0009876884111320948
Trained batch 91 in epoch 9, gen_loss = 0.9888500189003737, disc_loss = 0.0009816373700311449
Trained batch 92 in epoch 9, gen_loss = 0.9890748371360123, disc_loss = 0.000978119205996414
Trained batch 93 in epoch 9, gen_loss = 0.9888489005413461, disc_loss = 0.0009772363877384627
Trained batch 94 in epoch 9, gen_loss = 0.9890403672268516, disc_loss = 0.0009841635654753956
Trained batch 95 in epoch 9, gen_loss = 0.9890281092375517, disc_loss = 0.0009975063491462304
Trained batch 96 in epoch 9, gen_loss = 0.9885126137241875, disc_loss = 0.0010048924305010587
Trained batch 97 in epoch 9, gen_loss = 0.9885788511256782, disc_loss = 0.0010072502158510936
Trained batch 98 in epoch 9, gen_loss = 0.988568157860727, disc_loss = 0.0010095931406749056
Trained batch 99 in epoch 9, gen_loss = 0.988214750289917, disc_loss = 0.0010099394715507514
Trained batch 100 in epoch 9, gen_loss = 0.9882698188913931, disc_loss = 0.0010063028977930287
Trained batch 101 in epoch 9, gen_loss = 0.9886581956171522, disc_loss = 0.001001354519508359
Trained batch 102 in epoch 9, gen_loss = 0.9889556042198996, disc_loss = 0.0009961400016604298
Trained batch 103 in epoch 9, gen_loss = 0.9889131337404251, disc_loss = 0.000993087170522463
Trained batch 104 in epoch 9, gen_loss = 0.9892314922241937, disc_loss = 0.0009926339458962458
Trained batch 105 in epoch 9, gen_loss = 0.9886730414516521, disc_loss = 0.000990154522851127
Trained batch 106 in epoch 9, gen_loss = 0.9890104721639758, disc_loss = 0.0009917865605768095
Trained batch 107 in epoch 9, gen_loss = 0.98895353741116, disc_loss = 0.0010013207709697006
Trained batch 108 in epoch 9, gen_loss = 0.9891794723108274, disc_loss = 0.001011406964624574
Trained batch 109 in epoch 9, gen_loss = 0.9886652848937295, disc_loss = 0.0010206267854135315
Trained batch 110 in epoch 9, gen_loss = 0.9887183238794138, disc_loss = 0.0010294417186266834
Trained batch 111 in epoch 9, gen_loss = 0.9884585945733956, disc_loss = 0.0010345553749045524
Trained batch 112 in epoch 9, gen_loss = 0.9882453221135434, disc_loss = 0.001035394931296546
Trained batch 113 in epoch 9, gen_loss = 0.9879736387938783, disc_loss = 0.0010333372366291944
Trained batch 114 in epoch 9, gen_loss = 0.9881030041238535, disc_loss = 0.001029064606257674
Trained batch 115 in epoch 9, gen_loss = 0.9882177731086468, disc_loss = 0.0010236192498143345
Trained batch 116 in epoch 9, gen_loss = 0.988281227584578, disc_loss = 0.0010173218187967585
Trained batch 117 in epoch 9, gen_loss = 0.987987280902216, disc_loss = 0.0010101606687570339
Trained batch 118 in epoch 9, gen_loss = 0.9873851667933103, disc_loss = 0.0010041103795162957
Trained batch 119 in epoch 9, gen_loss = 0.987041762471199, disc_loss = 0.0010016916368234283
Trained batch 120 in epoch 9, gen_loss = 0.9867866472764448, disc_loss = 0.0010032129400863875
Trained batch 121 in epoch 9, gen_loss = 0.98684396997827, disc_loss = 0.0010070531346575648
Trained batch 122 in epoch 9, gen_loss = 0.9871102358267559, disc_loss = 0.0010115062586993464
Trained batch 123 in epoch 9, gen_loss = 0.9871887905943778, disc_loss = 0.0010154525798204686
Trained batch 124 in epoch 9, gen_loss = 0.987629144191742, disc_loss = 0.001018541032448411
Trained batch 125 in epoch 9, gen_loss = 0.9876868105123914, disc_loss = 0.0010198069771470886
Trained batch 126 in epoch 9, gen_loss = 0.9876459954291816, disc_loss = 0.0010196104651229
Trained batch 127 in epoch 9, gen_loss = 0.9876827034167945, disc_loss = 0.0010184093471252709
Trained batch 128 in epoch 9, gen_loss = 0.9878111980682196, disc_loss = 0.0010159883906256206
Trained batch 129 in epoch 9, gen_loss = 0.9877204133914067, disc_loss = 0.001012585165265661
Trained batch 130 in epoch 9, gen_loss = 0.987734095285867, disc_loss = 0.0010093593688233833
Trained batch 131 in epoch 9, gen_loss = 0.9879014072093096, disc_loss = 0.001005473267110629
Trained batch 132 in epoch 9, gen_loss = 0.9878872834650197, disc_loss = 0.0010003468820026942
Trained batch 133 in epoch 9, gen_loss = 0.9877623448620981, disc_loss = 0.0009948032273504354
Trained batch 134 in epoch 9, gen_loss = 0.9877574059698316, disc_loss = 0.0009890792378293419
Trained batch 135 in epoch 9, gen_loss = 0.9879971860962755, disc_loss = 0.0009838473730162472
Trained batch 136 in epoch 9, gen_loss = 0.9882212081094728, disc_loss = 0.0009790924819607805
Trained batch 137 in epoch 9, gen_loss = 0.9883441195107888, disc_loss = 0.0009759449601625565
Trained batch 138 in epoch 9, gen_loss = 0.9881064643105157, disc_loss = 0.0009742816993899697
Trained batch 139 in epoch 9, gen_loss = 0.9879306171621595, disc_loss = 0.0009707088434619696
Trained batch 140 in epoch 9, gen_loss = 0.988032859267918, disc_loss = 0.0009668562961709257
Trained batch 141 in epoch 9, gen_loss = 0.9876054634510631, disc_loss = 0.0009666986195337762
Trained batch 142 in epoch 9, gen_loss = 0.9878376322192746, disc_loss = 0.0009754105431184016
Trained batch 143 in epoch 9, gen_loss = 0.9880377658539348, disc_loss = 0.0009881298509652778
Trained batch 144 in epoch 9, gen_loss = 0.9879906543369951, disc_loss = 0.0009967766136155817
Trained batch 145 in epoch 9, gen_loss = 0.9884845708331017, disc_loss = 0.0009988249141614476
Trained batch 146 in epoch 9, gen_loss = 0.9887917272898615, disc_loss = 0.0009968825817887423
Trained batch 147 in epoch 9, gen_loss = 0.9888732405127706, disc_loss = 0.0009957807287227715
Trained batch 148 in epoch 9, gen_loss = 0.9891770258045837, disc_loss = 0.0009935231732467076
Trained batch 149 in epoch 9, gen_loss = 0.9888611590862274, disc_loss = 0.00099265311146155
Trained batch 150 in epoch 9, gen_loss = 0.9888782299907002, disc_loss = 0.0010014324416622322
Trained batch 151 in epoch 9, gen_loss = 0.9891827651544621, disc_loss = 0.0010144347271355066
Trained batch 152 in epoch 9, gen_loss = 0.9891978810036105, disc_loss = 0.0010255893876508267
Trained batch 153 in epoch 9, gen_loss = 0.9890689923391713, disc_loss = 0.001035089420862254
Trained batch 154 in epoch 9, gen_loss = 0.9888451618532981, disc_loss = 0.0010416949535870263
Trained batch 155 in epoch 9, gen_loss = 0.989052530664664, disc_loss = 0.0010464715484816295
Trained batch 156 in epoch 9, gen_loss = 0.9890298277709135, disc_loss = 0.0010510557761214151
Trained batch 157 in epoch 9, gen_loss = 0.9891318969334228, disc_loss = 0.001052868824387323
Trained batch 158 in epoch 9, gen_loss = 0.9886791391192742, disc_loss = 0.001052640169806216
Trained batch 159 in epoch 9, gen_loss = 0.9886461652815342, disc_loss = 0.0010542394455114845
Trained batch 160 in epoch 9, gen_loss = 0.9886598786952333, disc_loss = 0.0010575169338757947
Trained batch 161 in epoch 9, gen_loss = 0.988819420337677, disc_loss = 0.001056816112710002
Trained batch 162 in epoch 9, gen_loss = 0.9888994174500916, disc_loss = 0.0010533180052808777
Trained batch 163 in epoch 9, gen_loss = 0.9888133748275477, disc_loss = 0.0010496495574110801
Trained batch 164 in epoch 9, gen_loss = 0.9891485207008593, disc_loss = 0.0010474528556435622
Trained batch 165 in epoch 9, gen_loss = 0.9891789785350662, disc_loss = 0.001044767107870654
Trained batch 166 in epoch 9, gen_loss = 0.9893235781949438, disc_loss = 0.0010418562514116307
Trained batch 167 in epoch 9, gen_loss = 0.9894023097696758, disc_loss = 0.0010385131075357397
Trained batch 168 in epoch 9, gen_loss = 0.9895798553376508, disc_loss = 0.0010351216502848615
Trained batch 169 in epoch 9, gen_loss = 0.9897722763173721, disc_loss = 0.001031874112873886
Trained batch 170 in epoch 9, gen_loss = 0.9897003902329339, disc_loss = 0.0010282664673133312
Trained batch 171 in epoch 9, gen_loss = 0.9895750807468281, disc_loss = 0.0010257940395900353
Trained batch 172 in epoch 9, gen_loss = 0.9896387085749235, disc_loss = 0.0010247194833011835
Trained batch 173 in epoch 9, gen_loss = 0.9894421038956478, disc_loss = 0.0010231770924627032
Trained batch 174 in epoch 9, gen_loss = 0.989222822529929, disc_loss = 0.0010208228175594871
Trained batch 175 in epoch 9, gen_loss = 0.9891584200615232, disc_loss = 0.0010202821148678513
Trained batch 176 in epoch 9, gen_loss = 0.989115641615485, disc_loss = 0.0010216784596740463
Trained batch 177 in epoch 9, gen_loss = 0.9889735050415724, disc_loss = 0.0010222207057993503
Trained batch 178 in epoch 9, gen_loss = 0.9891551120321178, disc_loss = 0.0010208589336691768
Trained batch 179 in epoch 9, gen_loss = 0.9889982985125647, disc_loss = 0.0010179294979833584
Trained batch 180 in epoch 9, gen_loss = 0.9890136857059121, disc_loss = 0.0010141716874140258
Trained batch 181 in epoch 9, gen_loss = 0.9890781614806626, disc_loss = 0.0010113013794090455
Trained batch 182 in epoch 9, gen_loss = 0.9888981580734253, disc_loss = 0.0010097445256924103
Trained batch 183 in epoch 9, gen_loss = 0.9888347374356311, disc_loss = 0.0010068611075479091
Trained batch 184 in epoch 9, gen_loss = 0.9885114012537776, disc_loss = 0.001005721158297682
Trained batch 185 in epoch 9, gen_loss = 0.9887010025721724, disc_loss = 0.0010150677833696126
Trained batch 186 in epoch 9, gen_loss = 0.9889871825508892, disc_loss = 0.0010323895727916755
Trained batch 187 in epoch 9, gen_loss = 0.9890480631209434, disc_loss = 0.0010451110980245581
Trained batch 188 in epoch 9, gen_loss = 0.9891693175785126, disc_loss = 0.0010525358504512245
Trained batch 189 in epoch 9, gen_loss = 0.9891140890748877, disc_loss = 0.0010553969554358016
Testing Epoch 9
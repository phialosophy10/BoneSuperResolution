/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.9808969497680664, disc_loss = 0.6594236493110657
Trained batch 1 in epoch 0, gen_loss = 1.0256893038749695, disc_loss = 0.9525688588619232
Trained batch 2 in epoch 0, gen_loss = 0.9822966655095419, disc_loss = 0.7744307021299998
Trained batch 3 in epoch 0, gen_loss = 0.9663752317428589, disc_loss = 0.6874512583017349
Trained batch 4 in epoch 0, gen_loss = 0.9474970817565918, disc_loss = 0.6126466870307923
Trained batch 5 in epoch 0, gen_loss = 0.9391349852085114, disc_loss = 0.5527060925960541
Trained batch 6 in epoch 0, gen_loss = 0.9090947508811951, disc_loss = 0.5062856844493321
Trained batch 7 in epoch 0, gen_loss = 0.889874555170536, disc_loss = 0.4680168479681015
Trained batch 8 in epoch 0, gen_loss = 0.8864956895510355, disc_loss = 0.4358638922373454
Trained batch 9 in epoch 0, gen_loss = 0.882745486497879, disc_loss = 0.4078944161534309
Trained batch 10 in epoch 0, gen_loss = 0.882688744501634, disc_loss = 0.38391595401547174
Trained batch 11 in epoch 0, gen_loss = 0.8823460588852564, disc_loss = 0.36824116110801697
Trained batch 12 in epoch 0, gen_loss = 0.8865945889399602, disc_loss = 0.35654187202453613
Trained batch 13 in epoch 0, gen_loss = 0.875202110835484, disc_loss = 0.34556091257504057
Trained batch 14 in epoch 0, gen_loss = 0.8671499808629354, disc_loss = 0.3370356102784475
Trained batch 15 in epoch 0, gen_loss = 0.8700523003935814, disc_loss = 0.3277096478268504
Trained batch 16 in epoch 0, gen_loss = 0.8692162527757532, disc_loss = 0.3215035945177078
Trained batch 17 in epoch 0, gen_loss = 0.8617769380410513, disc_loss = 0.32155250757932663
Trained batch 18 in epoch 0, gen_loss = 0.8656233015813326, disc_loss = 0.316067489354234
Trained batch 19 in epoch 0, gen_loss = 0.8672680079936981, disc_loss = 0.30929836481809614
Trained batch 20 in epoch 0, gen_loss = 0.8679702168419248, disc_loss = 0.3005097409089406
Trained batch 21 in epoch 0, gen_loss = 0.8726160472089594, disc_loss = 0.2927638685161417
Trained batch 22 in epoch 0, gen_loss = 0.8721897265185481, disc_loss = 0.28489848647428595
Trained batch 23 in epoch 0, gen_loss = 0.8749182000756264, disc_loss = 0.2771686837077141
Trained batch 24 in epoch 0, gen_loss = 0.8749571514129638, disc_loss = 0.2704980832338333
Trained batch 25 in epoch 0, gen_loss = 0.8772158668591425, disc_loss = 0.2641453745846565
Trained batch 26 in epoch 0, gen_loss = 0.8782048909752457, disc_loss = 0.2577851301542035
Trained batch 27 in epoch 0, gen_loss = 0.8835755267313549, disc_loss = 0.2516009360551834
Trained batch 28 in epoch 0, gen_loss = 0.8889488372309454, disc_loss = 0.24542825052450443
Trained batch 29 in epoch 0, gen_loss = 0.8944027761618296, disc_loss = 0.2396392787496249
Trained batch 30 in epoch 0, gen_loss = 0.8966991343805867, disc_loss = 0.23409092282095262
Trained batch 31 in epoch 0, gen_loss = 0.8980796299874783, disc_loss = 0.22932191845029593
Trained batch 32 in epoch 0, gen_loss = 0.9046658638751868, disc_loss = 0.22433076844070898
Trained batch 33 in epoch 0, gen_loss = 0.911971951232237, disc_loss = 0.21997844866093466
Trained batch 34 in epoch 0, gen_loss = 0.9139852830341884, disc_loss = 0.2158796991620745
Trained batch 35 in epoch 0, gen_loss = 0.9120365646150377, disc_loss = 0.21267660727931392
Trained batch 36 in epoch 0, gen_loss = 0.9132181985958202, disc_loss = 0.20879251429358045
Trained batch 37 in epoch 0, gen_loss = 0.9181831133993048, disc_loss = 0.20517533409752345
Trained batch 38 in epoch 0, gen_loss = 0.9222563138374915, disc_loss = 0.20189767617445725
Trained batch 39 in epoch 0, gen_loss = 0.9280417531728744, disc_loss = 0.19850889015942813
Trained batch 40 in epoch 0, gen_loss = 0.9266769377196707, disc_loss = 0.19534263141998431
Trained batch 41 in epoch 0, gen_loss = 0.9321950376033783, disc_loss = 0.1925733701458999
Trained batch 42 in epoch 0, gen_loss = 0.9365539703258249, disc_loss = 0.1892573554501977
Trained batch 43 in epoch 0, gen_loss = 0.9352047348564322, disc_loss = 0.18676387806507674
Trained batch 44 in epoch 0, gen_loss = 0.9450292494561937, disc_loss = 0.18468135131729974
Trained batch 45 in epoch 0, gen_loss = 0.9487531664578811, disc_loss = 0.18231790448012558
Trained batch 46 in epoch 0, gen_loss = 0.9537801983508658, disc_loss = 0.18226569510520774
Trained batch 47 in epoch 0, gen_loss = 0.9631668118139108, disc_loss = 0.1830427274107933
Trained batch 48 in epoch 0, gen_loss = 0.9687155400003705, disc_loss = 0.18058847483931756
Trained batch 49 in epoch 0, gen_loss = 0.9709622395038605, disc_loss = 0.17861772939562798
Trained batch 50 in epoch 0, gen_loss = 0.9730427884588054, disc_loss = 0.17617937601080128
Trained batch 51 in epoch 0, gen_loss = 0.9755631284071848, disc_loss = 0.17398235688988978
Trained batch 52 in epoch 0, gen_loss = 0.9815102939335805, disc_loss = 0.17199063989913688
Trained batch 53 in epoch 0, gen_loss = 0.9817151835671177, disc_loss = 0.16980576418616153
Trained batch 54 in epoch 0, gen_loss = 0.9829319878058, disc_loss = 0.16778566031293435
Trained batch 55 in epoch 0, gen_loss = 0.9890454720173564, disc_loss = 0.16916276467964053
Trained batch 56 in epoch 0, gen_loss = 0.9832394489070826, disc_loss = 0.17532342731168396
Trained batch 57 in epoch 0, gen_loss = 0.981206576372015, disc_loss = 0.1743504462185605
Trained batch 58 in epoch 0, gen_loss = 0.9842657628705946, disc_loss = 0.173386917086476
Trained batch 59 in epoch 0, gen_loss = 0.9858025699853897, disc_loss = 0.1715896362438798
Trained batch 60 in epoch 0, gen_loss = 0.9829937952463744, disc_loss = 0.17026835967038498
Trained batch 61 in epoch 0, gen_loss = 0.9833712895070353, disc_loss = 0.16877722505840562
Trained batch 62 in epoch 0, gen_loss = 0.983868210088639, disc_loss = 0.16858886353789815
Trained batch 63 in epoch 0, gen_loss = 0.9828573800623417, disc_loss = 0.16939119953894988
Trained batch 64 in epoch 0, gen_loss = 0.9842318901648888, disc_loss = 0.16898511722683907
Trained batch 65 in epoch 0, gen_loss = 0.9819053899158131, disc_loss = 0.16777726640981255
Trained batch 66 in epoch 0, gen_loss = 0.9825742031211284, disc_loss = 0.1661993858418358
Trained batch 67 in epoch 0, gen_loss = 0.9850416954825906, disc_loss = 0.16452243798138463
Trained batch 68 in epoch 0, gen_loss = 0.9834377117778944, disc_loss = 0.16326301993019338
Trained batch 69 in epoch 0, gen_loss = 0.9850671589374542, disc_loss = 0.16293902870799815
Trained batch 70 in epoch 0, gen_loss = 0.9815160447443035, disc_loss = 0.16624978231922002
Trained batch 71 in epoch 0, gen_loss = 0.980591244995594, disc_loss = 0.16530074080866244
Trained batch 72 in epoch 0, gen_loss = 0.9859371569058667, disc_loss = 0.16577807910842438
Trained batch 73 in epoch 0, gen_loss = 0.9844532383454813, disc_loss = 0.16584352831784133
Trained batch 74 in epoch 0, gen_loss = 0.9839466174443563, disc_loss = 0.1649024084707101
Trained batch 75 in epoch 0, gen_loss = 0.9851442324487787, disc_loss = 0.1643679680694875
Trained batch 76 in epoch 0, gen_loss = 0.9834266297228924, disc_loss = 0.1635161293307682
Trained batch 77 in epoch 0, gen_loss = 0.9799520304569831, disc_loss = 0.163065558203902
Trained batch 78 in epoch 0, gen_loss = 0.9815544335148002, disc_loss = 0.16254601585148257
Trained batch 79 in epoch 0, gen_loss = 0.9796420790255069, disc_loss = 0.16202260726131498
Trained batch 80 in epoch 0, gen_loss = 0.9789513224436913, disc_loss = 0.16074634628531373
Trained batch 81 in epoch 0, gen_loss = 0.9809677375525963, disc_loss = 0.16077940529439508
Trained batch 82 in epoch 0, gen_loss = 0.9784099409379154, disc_loss = 0.16409385958349848
Trained batch 83 in epoch 0, gen_loss = 0.9756066089584714, disc_loss = 0.16408463993242808
Trained batch 84 in epoch 0, gen_loss = 0.9778654379003188, disc_loss = 0.16447430428336648
Trained batch 85 in epoch 0, gen_loss = 0.9761884080809217, disc_loss = 0.16422499023204626
Trained batch 86 in epoch 0, gen_loss = 0.9734797724362078, disc_loss = 0.16391474830693212
Trained batch 87 in epoch 0, gen_loss = 0.9739841751076959, disc_loss = 0.16335494824769822
Trained batch 88 in epoch 0, gen_loss = 0.9731346060720723, disc_loss = 0.16320915109990689
Trained batch 89 in epoch 0, gen_loss = 0.9717513865894741, disc_loss = 0.16262154769566323
Trained batch 90 in epoch 0, gen_loss = 0.9703016254928086, disc_loss = 0.16231784494696083
Trained batch 91 in epoch 0, gen_loss = 0.9732892694680587, disc_loss = 0.1628337615048108
Trained batch 92 in epoch 0, gen_loss = 0.9716287101468732, disc_loss = 0.16317790386176878
Trained batch 93 in epoch 0, gen_loss = 0.9700659500791672, disc_loss = 0.16273981459597323
Trained batch 94 in epoch 0, gen_loss = 0.9701689939749868, disc_loss = 0.16247684798742595
Trained batch 95 in epoch 0, gen_loss = 0.9684373730172714, disc_loss = 0.1625246892993649
Trained batch 96 in epoch 0, gen_loss = 0.968970434567363, disc_loss = 0.16374861886820843
Trained batch 97 in epoch 0, gen_loss = 0.9669764850820813, disc_loss = 0.1656936534813472
Trained batch 98 in epoch 0, gen_loss = 0.9665885326838253, disc_loss = 0.1659040863465781
Trained batch 99 in epoch 0, gen_loss = 0.9651423561573028, disc_loss = 0.16698924690485
Trained batch 100 in epoch 0, gen_loss = 0.9633031097969206, disc_loss = 0.16775885784980094
Trained batch 101 in epoch 0, gen_loss = 0.9614701265213537, disc_loss = 0.1678913806875547
Trained batch 102 in epoch 0, gen_loss = 0.9613380842995876, disc_loss = 0.16770500769314256
Trained batch 103 in epoch 0, gen_loss = 0.9589484970156963, disc_loss = 0.16778102244895238
Trained batch 104 in epoch 0, gen_loss = 0.9573093488102867, disc_loss = 0.16757381969974156
Trained batch 105 in epoch 0, gen_loss = 0.9552300791695433, disc_loss = 0.1674546924120975
Trained batch 106 in epoch 0, gen_loss = 0.9538584034019542, disc_loss = 0.16733383784227282
Trained batch 107 in epoch 0, gen_loss = 0.9550043774975671, disc_loss = 0.16708585440560622
Trained batch 108 in epoch 0, gen_loss = 0.9537168177989644, disc_loss = 0.16680989968120505
Trained batch 109 in epoch 0, gen_loss = 0.9532446677034552, disc_loss = 0.1663233433934775
Trained batch 110 in epoch 0, gen_loss = 0.9557389966002455, disc_loss = 0.166765026479691
Trained batch 111 in epoch 0, gen_loss = 0.9529927250530038, disc_loss = 0.16923802964655416
Trained batch 112 in epoch 0, gen_loss = 0.9517733270088128, disc_loss = 0.1689847547527963
Trained batch 113 in epoch 0, gen_loss = 0.9518290867930964, disc_loss = 0.1693248553364946
Trained batch 114 in epoch 0, gen_loss = 0.9521624414817147, disc_loss = 0.16955836292194285
Trained batch 115 in epoch 0, gen_loss = 0.9494560905571642, disc_loss = 0.17026463953842377
Trained batch 116 in epoch 0, gen_loss = 0.9478201382180564, disc_loss = 0.17063650533429578
Trained batch 117 in epoch 0, gen_loss = 0.9493190105688774, disc_loss = 0.17113577012540931
Trained batch 118 in epoch 0, gen_loss = 0.9482356570348018, disc_loss = 0.17143599745355734
Trained batch 119 in epoch 0, gen_loss = 0.9467163234949112, disc_loss = 0.17159244151165087
Trained batch 120 in epoch 0, gen_loss = 0.9443138226989872, disc_loss = 0.17197558277648342
Trained batch 121 in epoch 0, gen_loss = 0.9429858048431209, disc_loss = 0.1717902738906321
Trained batch 122 in epoch 0, gen_loss = 0.9425591109244804, disc_loss = 0.1725688270800482
Trained batch 123 in epoch 0, gen_loss = 0.9415139541510613, disc_loss = 0.17314999736845493
Trained batch 124 in epoch 0, gen_loss = 0.9396493344306945, disc_loss = 0.17330873817205428
Trained batch 125 in epoch 0, gen_loss = 0.9383857463087354, disc_loss = 0.1734170267387988
Trained batch 126 in epoch 0, gen_loss = 0.9375500148675573, disc_loss = 0.17325111220436773
Trained batch 127 in epoch 0, gen_loss = 0.9360091746784747, disc_loss = 0.17351038864580914
Trained batch 128 in epoch 0, gen_loss = 0.9358994946923367, disc_loss = 0.1738108574997547
Trained batch 129 in epoch 0, gen_loss = 0.9349108705153832, disc_loss = 0.1738061965084993
Trained batch 130 in epoch 0, gen_loss = 0.9350747325038182, disc_loss = 0.17363902113137356
Trained batch 131 in epoch 0, gen_loss = 0.9363682766755422, disc_loss = 0.1739889614171151
Trained batch 132 in epoch 0, gen_loss = 0.9340282898200186, disc_loss = 0.175395828944848
Trained batch 133 in epoch 0, gen_loss = 0.9333043449850225, disc_loss = 0.1751149187225904
Trained batch 134 in epoch 0, gen_loss = 0.9350121078667817, disc_loss = 0.17504693253172768
Trained batch 135 in epoch 0, gen_loss = 0.9345149866798345, disc_loss = 0.17473751980373087
Trained batch 136 in epoch 0, gen_loss = 0.9330941677963647, disc_loss = 0.17465905328519152
Trained batch 137 in epoch 0, gen_loss = 0.9329378134098606, disc_loss = 0.17423264871256938
Trained batch 138 in epoch 0, gen_loss = 0.9321894478454864, disc_loss = 0.17364318877887383
Trained batch 139 in epoch 0, gen_loss = 0.9322818751846041, disc_loss = 0.1734283247696502
Trained batch 140 in epoch 0, gen_loss = 0.931897113509212, disc_loss = 0.17330610292389037
Trained batch 141 in epoch 0, gen_loss = 0.9308367795507673, disc_loss = 0.1732577795398907
Trained batch 142 in epoch 0, gen_loss = 0.9303845279700272, disc_loss = 0.17294900739318006
Trained batch 143 in epoch 0, gen_loss = 0.9286905845834149, disc_loss = 0.1731169758261078
Trained batch 144 in epoch 0, gen_loss = 0.9274371373242345, disc_loss = 0.17323640754510616
Trained batch 145 in epoch 0, gen_loss = 0.9276721930667146, disc_loss = 0.17305467803388425
Trained batch 146 in epoch 0, gen_loss = 0.9282487918730495, disc_loss = 0.1728553421744684
Trained batch 147 in epoch 0, gen_loss = 0.9269215875380749, disc_loss = 0.1739835165743087
Trained batch 148 in epoch 0, gen_loss = 0.9266607973399579, disc_loss = 0.17363723917495485
Trained batch 149 in epoch 0, gen_loss = 0.928296157916387, disc_loss = 0.1746003064016501
Trained batch 150 in epoch 0, gen_loss = 0.9276778670336236, disc_loss = 0.1743332649402271
Trained batch 151 in epoch 0, gen_loss = 0.9265238666220715, disc_loss = 0.17420026419782325
Trained batch 152 in epoch 0, gen_loss = 0.925196025106642, disc_loss = 0.1748767631018863
Trained batch 153 in epoch 0, gen_loss = 0.9250791576001551, disc_loss = 0.1752522832097171
Trained batch 154 in epoch 0, gen_loss = 0.9236800697542006, disc_loss = 0.1763304568586811
Trained batch 155 in epoch 0, gen_loss = 0.921974764802517, disc_loss = 0.17706910563776126
Trained batch 156 in epoch 0, gen_loss = 0.920335958717735, disc_loss = 0.17763217377245047
Trained batch 157 in epoch 0, gen_loss = 0.9198003245305412, disc_loss = 0.17758226003262062
Trained batch 158 in epoch 0, gen_loss = 0.9186763759679014, disc_loss = 0.1776328887673294
Trained batch 159 in epoch 0, gen_loss = 0.9169748608022928, disc_loss = 0.17778803878463806
Trained batch 160 in epoch 0, gen_loss = 0.9163393733664329, disc_loss = 0.17761360446673743
Trained batch 161 in epoch 0, gen_loss = 0.9157413321512716, disc_loss = 0.17748112594823778
Trained batch 162 in epoch 0, gen_loss = 0.9152226199401668, disc_loss = 0.1778909918263646
Trained batch 163 in epoch 0, gen_loss = 0.9139229102832515, disc_loss = 0.1793309113510498
Trained batch 164 in epoch 0, gen_loss = 0.9142947471503056, disc_loss = 0.17914864470561345
Trained batch 165 in epoch 0, gen_loss = 0.9136719567229948, disc_loss = 0.17880747018449278
Trained batch 166 in epoch 0, gen_loss = 0.9125426922015801, disc_loss = 0.17883425335327308
Trained batch 167 in epoch 0, gen_loss = 0.9123629157741865, disc_loss = 0.17874446724142348
Trained batch 168 in epoch 0, gen_loss = 0.9110900470490991, disc_loss = 0.1786646544933319
Trained batch 169 in epoch 0, gen_loss = 0.9104750643758213, disc_loss = 0.17850085496902465
Trained batch 170 in epoch 0, gen_loss = 0.9094181775349622, disc_loss = 0.17858030180833492
Trained batch 171 in epoch 0, gen_loss = 0.9107880588880805, disc_loss = 0.17988596622680508
Trained batch 172 in epoch 0, gen_loss = 0.9082675972425869, disc_loss = 0.18073030677489463
Trained batch 173 in epoch 0, gen_loss = 0.9065788377975595, disc_loss = 0.18096256521583973
Trained batch 174 in epoch 0, gen_loss = 0.9062817420278276, disc_loss = 0.1809700563124248
Trained batch 175 in epoch 0, gen_loss = 0.9060522944412448, disc_loss = 0.1809989342635328
Trained batch 176 in epoch 0, gen_loss = 0.9048511534087402, disc_loss = 0.18128882676868116
Trained batch 177 in epoch 0, gen_loss = 0.9036962101968486, disc_loss = 0.18135951241750395
Trained batch 178 in epoch 0, gen_loss = 0.9027864743211416, disc_loss = 0.18167505933585779
Trained batch 179 in epoch 0, gen_loss = 0.9021325578292211, disc_loss = 0.18166493872801462
Trained batch 180 in epoch 0, gen_loss = 0.9016454878432975, disc_loss = 0.18160490288260234
Trained batch 181 in epoch 0, gen_loss = 0.9020645729788057, disc_loss = 0.18177902616642333
Trained batch 182 in epoch 0, gen_loss = 0.9008141026470831, disc_loss = 0.18169373241278644
Trained batch 183 in epoch 0, gen_loss = 0.8994544533931691, disc_loss = 0.18207516407837038
Trained batch 184 in epoch 0, gen_loss = 0.8993237150681985, disc_loss = 0.18221318882864876
Trained batch 185 in epoch 0, gen_loss = 0.8985025789788974, disc_loss = 0.18222643274773834
Trained batch 186 in epoch 0, gen_loss = 0.8972205079813055, disc_loss = 0.1825683800613179
Trained batch 187 in epoch 0, gen_loss = 0.8967915643402871, disc_loss = 0.1825623817424825
Trained batch 188 in epoch 0, gen_loss = 0.8968814967801331, disc_loss = 0.18265397996498794
Trained batch 189 in epoch 0, gen_loss = 0.8955102914258053, disc_loss = 0.1829522840286556
Trained batch 190 in epoch 0, gen_loss = 0.894825399546099, disc_loss = 0.18288000029419105
Trained batch 191 in epoch 0, gen_loss = 0.8947561917205652, disc_loss = 0.18297843829107782
Trained batch 192 in epoch 0, gen_loss = 0.8935101427562496, disc_loss = 0.18306225623182681
Trained batch 193 in epoch 0, gen_loss = 0.8920695428381261, disc_loss = 0.183441468658521
Trained batch 194 in epoch 0, gen_loss = 0.8914059911018762, disc_loss = 0.1833186034972851
Trained batch 195 in epoch 0, gen_loss = 0.8910959800895379, disc_loss = 0.1832538467584824
Trained batch 196 in epoch 0, gen_loss = 0.8896939857357045, disc_loss = 0.183715222753244
Trained batch 197 in epoch 0, gen_loss = 0.8890414647381715, disc_loss = 0.18369932653325977
Trained batch 198 in epoch 0, gen_loss = 0.8888115990701033, disc_loss = 0.1836793706494959
Trained batch 199 in epoch 0, gen_loss = 0.8881390070915223, disc_loss = 0.18366908118128777
Trained batch 200 in epoch 0, gen_loss = 0.8872020007365972, disc_loss = 0.18362142360625575
Trained batch 201 in epoch 0, gen_loss = 0.8864905072910951, disc_loss = 0.18352706258249754
Trained batch 202 in epoch 0, gen_loss = 0.8863067459590329, disc_loss = 0.18344892238454866
Trained batch 203 in epoch 0, gen_loss = 0.8852155494923685, disc_loss = 0.1835059780700534
Trained batch 204 in epoch 0, gen_loss = 0.8851616461102555, disc_loss = 0.18341786999528
Trained batch 205 in epoch 0, gen_loss = 0.8865915996935761, disc_loss = 0.18385571349882385
Trained batch 206 in epoch 0, gen_loss = 0.8851638617722885, disc_loss = 0.18452556013773028
Trained batch 207 in epoch 0, gen_loss = 0.8839246152112117, disc_loss = 0.18471300078985783
Trained batch 208 in epoch 0, gen_loss = 0.8837670892049251, disc_loss = 0.1847242221735311
Trained batch 209 in epoch 0, gen_loss = 0.8840893833410173, disc_loss = 0.18510358553557169
Trained batch 210 in epoch 0, gen_loss = 0.883826950432565, disc_loss = 0.1850366660910195
Trained batch 211 in epoch 0, gen_loss = 0.8831110456079807, disc_loss = 0.18484385163997705
Trained batch 212 in epoch 0, gen_loss = 0.8821560155617799, disc_loss = 0.1847964500037717
Trained batch 213 in epoch 0, gen_loss = 0.8812132402558193, disc_loss = 0.1850739564294013
Trained batch 214 in epoch 0, gen_loss = 0.8799374455629393, disc_loss = 0.18531596515067789
Trained batch 215 in epoch 0, gen_loss = 0.8789969889654053, disc_loss = 0.18548938238786328
Trained batch 216 in epoch 0, gen_loss = 0.8792175974714042, disc_loss = 0.1860233643499937
Trained batch 217 in epoch 0, gen_loss = 0.8784071360159358, disc_loss = 0.18588990854834198
Trained batch 218 in epoch 0, gen_loss = 0.8777140202043263, disc_loss = 0.1859915852546692
Trained batch 219 in epoch 0, gen_loss = 0.8772862710736015, disc_loss = 0.1861664965748787
Trained batch 220 in epoch 0, gen_loss = 0.8765398954374218, disc_loss = 0.1861401937261426
Trained batch 221 in epoch 0, gen_loss = 0.875575835640366, disc_loss = 0.1861632013240376
Trained batch 222 in epoch 0, gen_loss = 0.875224397321453, disc_loss = 0.18617683588923895
Trained batch 223 in epoch 0, gen_loss = 0.8745261678206069, disc_loss = 0.18611000617966056
Trained batch 224 in epoch 0, gen_loss = 0.8733201991187202, disc_loss = 0.18614392989211612
Trained batch 225 in epoch 0, gen_loss = 0.8732390725507145, disc_loss = 0.18608736372099513
Trained batch 226 in epoch 0, gen_loss = 0.8725864341080452, disc_loss = 0.18596442339178748
Trained batch 227 in epoch 0, gen_loss = 0.8725895416318324, disc_loss = 0.1857647708241354
Trained batch 228 in epoch 0, gen_loss = 0.8725398950701718, disc_loss = 0.1853427406091357
Trained batch 229 in epoch 0, gen_loss = 0.8719748367433963, disc_loss = 0.18502806664808938
Trained batch 230 in epoch 0, gen_loss = 0.8719374065275316, disc_loss = 0.18474278402276886
Trained batch 231 in epoch 0, gen_loss = 0.8717843985249256, disc_loss = 0.1845390188411392
Trained batch 232 in epoch 0, gen_loss = 0.872283254058576, disc_loss = 0.18442972273018227
Trained batch 233 in epoch 0, gen_loss = 0.8718948359163399, disc_loss = 0.18433951815733543
Trained batch 234 in epoch 0, gen_loss = 0.8717868941895506, disc_loss = 0.1840656028148976
Trained batch 235 in epoch 0, gen_loss = 0.8732404375480394, disc_loss = 0.18453040769544699
Trained batch 236 in epoch 0, gen_loss = 0.8719342011439649, disc_loss = 0.1857832143326852
Trained batch 237 in epoch 0, gen_loss = 0.8707578099575364, disc_loss = 0.1859833493578334
Trained batch 238 in epoch 0, gen_loss = 0.8701127912210121, disc_loss = 0.1861641852800816
Trained batch 239 in epoch 0, gen_loss = 0.8696087757746379, disc_loss = 0.18647176443288724
Trained batch 240 in epoch 0, gen_loss = 0.8684624515133774, disc_loss = 0.1867588233527306
Trained batch 241 in epoch 0, gen_loss = 0.8677352733355909, disc_loss = 0.18697748936651168
Trained batch 242 in epoch 0, gen_loss = 0.8673368120880284, disc_loss = 0.18700938687157728
Trained batch 243 in epoch 0, gen_loss = 0.8673443723408902, disc_loss = 0.18697505774068052
Trained batch 244 in epoch 0, gen_loss = 0.8666649713808177, disc_loss = 0.18689814538371807
Trained batch 245 in epoch 0, gen_loss = 0.8659382770216562, disc_loss = 0.18680852336612175
Trained batch 246 in epoch 0, gen_loss = 0.8656325318552704, disc_loss = 0.18682032901989787
Trained batch 247 in epoch 0, gen_loss = 0.8657224911355204, disc_loss = 0.18704429376990564
Trained batch 248 in epoch 0, gen_loss = 0.8647992290167444, disc_loss = 0.1869587681619039
Trained batch 249 in epoch 0, gen_loss = 0.8641650733947754, disc_loss = 0.18677878606319429
Trained batch 250 in epoch 0, gen_loss = 0.8641718977476022, disc_loss = 0.1868100731496317
Trained batch 251 in epoch 0, gen_loss = 0.8637362023194631, disc_loss = 0.18684925889921566
Trained batch 252 in epoch 0, gen_loss = 0.8634289512521194, disc_loss = 0.18676138424826233
Trained batch 253 in epoch 0, gen_loss = 0.8632140401310808, disc_loss = 0.1866277744920235
Trained batch 254 in epoch 0, gen_loss = 0.8629539407935797, disc_loss = 0.1865551389315549
Trained batch 255 in epoch 0, gen_loss = 0.8617987339384854, disc_loss = 0.18666634295368567
Trained batch 256 in epoch 0, gen_loss = 0.8612855749371451, disc_loss = 0.18650197646497288
Trained batch 257 in epoch 0, gen_loss = 0.8613745295262152, disc_loss = 0.1865931526981583
Trained batch 258 in epoch 0, gen_loss = 0.8603461679344472, disc_loss = 0.18708738897527968
Trained batch 259 in epoch 0, gen_loss = 0.860334911254736, disc_loss = 0.18687867768681965
Trained batch 260 in epoch 0, gen_loss = 0.8599337051654684, disc_loss = 0.1869667121619557
Trained batch 261 in epoch 0, gen_loss = 0.8598378912638162, disc_loss = 0.18678039602423444
Trained batch 262 in epoch 0, gen_loss = 0.8590980049775128, disc_loss = 0.18667056284023328
Trained batch 263 in epoch 0, gen_loss = 0.8596758835695006, disc_loss = 0.1865965494829597
Trained batch 264 in epoch 0, gen_loss = 0.8594511904806461, disc_loss = 0.18639404441950455
Trained batch 265 in epoch 0, gen_loss = 0.8587836616469505, disc_loss = 0.18643202038859963
Trained batch 266 in epoch 0, gen_loss = 0.8600037506457126, disc_loss = 0.1870305799924479
Trained batch 267 in epoch 0, gen_loss = 0.8589611173565708, disc_loss = 0.18767838074422594
Trained batch 268 in epoch 0, gen_loss = 0.857904467662471, disc_loss = 0.18763172748363594
Trained batch 269 in epoch 0, gen_loss = 0.857015824759448, disc_loss = 0.18782418348171093
Trained batch 270 in epoch 0, gen_loss = 0.8566167754880617, disc_loss = 0.18803055622920778
Trained batch 271 in epoch 0, gen_loss = 0.8562502394265988, disc_loss = 0.18806370862704866
Trained batch 272 in epoch 0, gen_loss = 0.8554368182853028, disc_loss = 0.18817597398391137
Trained batch 273 in epoch 0, gen_loss = 0.8547893712555406, disc_loss = 0.18817468699965165
Trained batch 274 in epoch 0, gen_loss = 0.8545349766991355, disc_loss = 0.18815650902011177
Trained batch 275 in epoch 0, gen_loss = 0.8540417029373888, disc_loss = 0.18825149924858756
Trained batch 276 in epoch 0, gen_loss = 0.8534503342442564, disc_loss = 0.1882324078345557
Trained batch 277 in epoch 0, gen_loss = 0.8528416639180492, disc_loss = 0.18812388637297445
Trained batch 278 in epoch 0, gen_loss = 0.8525035045907489, disc_loss = 0.18814944921855858
Trained batch 279 in epoch 0, gen_loss = 0.8526110985449382, disc_loss = 0.18821124343999796
Trained batch 280 in epoch 0, gen_loss = 0.8517566191768307, disc_loss = 0.18824967153343866
Trained batch 281 in epoch 0, gen_loss = 0.8512016543259857, disc_loss = 0.18819616639867742
Trained batch 282 in epoch 0, gen_loss = 0.8509691414479232, disc_loss = 0.18845878220278467
Trained batch 283 in epoch 0, gen_loss = 0.8501898390306554, disc_loss = 0.18877101647602001
Trained batch 284 in epoch 0, gen_loss = 0.8497507283562108, disc_loss = 0.18868887481982247
Trained batch 285 in epoch 0, gen_loss = 0.8496562846890696, disc_loss = 0.18868650053139333
Trained batch 286 in epoch 0, gen_loss = 0.8494315487997872, disc_loss = 0.18864171113494382
Trained batch 287 in epoch 0, gen_loss = 0.8488911303381125, disc_loss = 0.18855237743506828
Trained batch 288 in epoch 0, gen_loss = 0.8480945050097667, disc_loss = 0.18842848717753863
Trained batch 289 in epoch 0, gen_loss = 0.8477268214883475, disc_loss = 0.1883513580108511
Trained batch 290 in epoch 0, gen_loss = 0.8477230635295618, disc_loss = 0.18822452978989512
Trained batch 291 in epoch 0, gen_loss = 0.8472363389518163, disc_loss = 0.18804123334280431
Trained batch 292 in epoch 0, gen_loss = 0.8471638993598495, disc_loss = 0.187808169312648
Trained batch 293 in epoch 0, gen_loss = 0.8467437284333366, disc_loss = 0.18765181381584836
Trained batch 294 in epoch 0, gen_loss = 0.8468556583937952, disc_loss = 0.1874702788763127
Trained batch 295 in epoch 0, gen_loss = 0.8469550486754727, disc_loss = 0.18714609432562784
Trained batch 296 in epoch 0, gen_loss = 0.8460891822773198, disc_loss = 0.18723408699738056
Trained batch 297 in epoch 0, gen_loss = 0.8457987194493313, disc_loss = 0.18689872411973524
Trained batch 298 in epoch 0, gen_loss = 0.8464068128512456, disc_loss = 0.18678390503826747
Trained batch 299 in epoch 0, gen_loss = 0.8452112850546837, disc_loss = 0.18705961239834626
Trained batch 300 in epoch 0, gen_loss = 0.8458137053785926, disc_loss = 0.18714883529961704
Trained batch 301 in epoch 0, gen_loss = 0.8464015817997471, disc_loss = 0.18694912610168488
Trained batch 302 in epoch 0, gen_loss = 0.8462900333475358, disc_loss = 0.18661904725993034
Trained batch 303 in epoch 0, gen_loss = 0.8460766019201592, disc_loss = 0.18630400292673394
Trained batch 304 in epoch 0, gen_loss = 0.8468352791715841, disc_loss = 0.18622039436805443
Trained batch 305 in epoch 0, gen_loss = 0.8457183373325011, disc_loss = 0.18669556575565557
Trained batch 306 in epoch 0, gen_loss = 0.84550093934668, disc_loss = 0.1865227036299457
Trained batch 307 in epoch 0, gen_loss = 0.847627608323252, disc_loss = 0.186970209654469
Trained batch 308 in epoch 0, gen_loss = 0.8472247514331225, disc_loss = 0.1868060200586674
Trained batch 309 in epoch 0, gen_loss = 0.8463389878311465, disc_loss = 0.18711308608612706
Trained batch 310 in epoch 0, gen_loss = 0.8455333202789834, disc_loss = 0.187115942574199
Trained batch 311 in epoch 0, gen_loss = 0.8450584632272904, disc_loss = 0.1872343799481407
Trained batch 312 in epoch 0, gen_loss = 0.8447882829192347, disc_loss = 0.18725933827245578
Trained batch 313 in epoch 0, gen_loss = 0.8446922434173572, disc_loss = 0.18752169269759944
Trained batch 314 in epoch 0, gen_loss = 0.8440183788064927, disc_loss = 0.18778745468173708
Trained batch 315 in epoch 0, gen_loss = 0.8431755822104744, disc_loss = 0.18786106609939773
Trained batch 316 in epoch 0, gen_loss = 0.8428697304958801, disc_loss = 0.18774210938989927
Trained batch 317 in epoch 0, gen_loss = 0.8424674119776899, disc_loss = 0.18788809701800346
Trained batch 318 in epoch 0, gen_loss = 0.8416318526275479, disc_loss = 0.18796427153214393
Trained batch 319 in epoch 0, gen_loss = 0.8410955674014986, disc_loss = 0.18806084648240357
Trained batch 320 in epoch 0, gen_loss = 0.8408276272525669, disc_loss = 0.18811161117483152
Trained batch 321 in epoch 0, gen_loss = 0.8403085613657969, disc_loss = 0.18798713767843217
Trained batch 322 in epoch 0, gen_loss = 0.8398004712150562, disc_loss = 0.18785958063583993
Trained batch 323 in epoch 0, gen_loss = 0.8396584219586702, disc_loss = 0.18773117843141526
Trained batch 324 in epoch 0, gen_loss = 0.839338425397873, disc_loss = 0.18768133610486984
Trained batch 325 in epoch 0, gen_loss = 0.8385143542399436, disc_loss = 0.18780179785713097
Trained batch 326 in epoch 0, gen_loss = 0.8383282934306958, disc_loss = 0.1876519300294214
Trained batch 327 in epoch 0, gen_loss = 0.83846317586012, disc_loss = 0.18774360307015298
Trained batch 328 in epoch 0, gen_loss = 0.8376041162521282, disc_loss = 0.18782755793680897
Trained batch 329 in epoch 0, gen_loss = 0.8372545853708729, disc_loss = 0.18773613578893922
Trained batch 330 in epoch 0, gen_loss = 0.8371776735854654, disc_loss = 0.18744701725568655
Trained batch 331 in epoch 0, gen_loss = 0.8365347874631365, disc_loss = 0.18758584444512086
Trained batch 332 in epoch 0, gen_loss = 0.8366324854147685, disc_loss = 0.18736439918702072
Trained batch 333 in epoch 0, gen_loss = 0.8365738467720454, disc_loss = 0.18719999695163286
Trained batch 334 in epoch 0, gen_loss = 0.836366860635245, disc_loss = 0.18702801797372193
Trained batch 335 in epoch 0, gen_loss = 0.8361123691179922, disc_loss = 0.18679278184260642
Trained batch 336 in epoch 0, gen_loss = 0.8359181238034359, disc_loss = 0.18654352959344933
Trained batch 337 in epoch 0, gen_loss = 0.8354029825629568, disc_loss = 0.18644533374693972
Trained batch 338 in epoch 0, gen_loss = 0.8356728361243695, disc_loss = 0.1867181265116793
Trained batch 339 in epoch 0, gen_loss = 0.8346471753190545, disc_loss = 0.18723097603548974
Trained batch 340 in epoch 0, gen_loss = 0.8344312257780707, disc_loss = 0.18719508363441986
Trained batch 341 in epoch 0, gen_loss = 0.8341657102805132, disc_loss = 0.1871165737553298
Trained batch 342 in epoch 0, gen_loss = 0.8336812158715273, disc_loss = 0.18709393495112744
Trained batch 343 in epoch 0, gen_loss = 0.8335891891010972, disc_loss = 0.18709016095327083
Trained batch 344 in epoch 0, gen_loss = 0.8332073745520219, disc_loss = 0.1870717691986457
Trained batch 345 in epoch 0, gen_loss = 0.832981713073102, disc_loss = 0.18703156199327783
Trained batch 346 in epoch 0, gen_loss = 0.8329963527770139, disc_loss = 0.18711579968932726
Trained batch 347 in epoch 0, gen_loss = 0.8322661154229065, disc_loss = 0.18711859465244857
Trained batch 348 in epoch 0, gen_loss = 0.8319522598411428, disc_loss = 0.1871422827884256
Trained batch 349 in epoch 0, gen_loss = 0.831848486661911, disc_loss = 0.1869874739434038
Trained batch 350 in epoch 0, gen_loss = 0.8315647504268548, disc_loss = 0.1867640500097533
Trained batch 351 in epoch 0, gen_loss = 0.8307585529983044, disc_loss = 0.18673620972020383
Trained batch 352 in epoch 0, gen_loss = 0.8308729784346842, disc_loss = 0.1867590155505256
Trained batch 353 in epoch 0, gen_loss = 0.8304501994181488, disc_loss = 0.18667469024237265
Trained batch 354 in epoch 0, gen_loss = 0.8304563534091896, disc_loss = 0.18642266961470455
Trained batch 355 in epoch 0, gen_loss = 0.8300194649883871, disc_loss = 0.18626264480643728
Trained batch 356 in epoch 0, gen_loss = 0.8294819299580336, disc_loss = 0.18627571381357202
Trained batch 357 in epoch 0, gen_loss = 0.8295488497398419, disc_loss = 0.18608441557631147
Trained batch 358 in epoch 0, gen_loss = 0.8295035476804111, disc_loss = 0.1857576478366068
Trained batch 359 in epoch 0, gen_loss = 0.8290453587969144, disc_loss = 0.1857857681189974
Trained batch 360 in epoch 0, gen_loss = 0.8301936541567879, disc_loss = 0.18694388901510398
Trained batch 361 in epoch 0, gen_loss = 0.8294365215038068, disc_loss = 0.18787846827457622
Trained batch 362 in epoch 0, gen_loss = 0.8293155407117418, disc_loss = 0.1877823615492868
Trained batch 363 in epoch 0, gen_loss = 0.8293720606591676, disc_loss = 0.18782262669896688
Trained batch 364 in epoch 0, gen_loss = 0.8287310613344794, disc_loss = 0.1878353881713462
Trained batch 365 in epoch 0, gen_loss = 0.8285860298761253, disc_loss = 0.1877307723902288
Trained batch 366 in epoch 0, gen_loss = 0.8281075923579265, disc_loss = 0.1877736568410325
Trained batch 367 in epoch 0, gen_loss = 0.827579343934422, disc_loss = 0.18777794696633582
Trained batch 368 in epoch 0, gen_loss = 0.8275139763103267, disc_loss = 0.1877260042763338
Trained batch 369 in epoch 0, gen_loss = 0.8268716776693189, disc_loss = 0.18781837585407335
Trained batch 370 in epoch 0, gen_loss = 0.8266877887062628, disc_loss = 0.18782303542541365
Trained batch 371 in epoch 0, gen_loss = 0.8265860487696945, disc_loss = 0.18774190747369363
Trained batch 372 in epoch 0, gen_loss = 0.8266144035329128, disc_loss = 0.1877321200819821
Trained batch 373 in epoch 0, gen_loss = 0.826311788297592, disc_loss = 0.18776207574628254
Trained batch 374 in epoch 0, gen_loss = 0.8261239565213522, disc_loss = 0.18784363907575607
Trained batch 375 in epoch 0, gen_loss = 0.8258121205454177, disc_loss = 0.18773406571609544
Trained batch 376 in epoch 0, gen_loss = 0.8255254069753287, disc_loss = 0.18765424944914938
Trained batch 377 in epoch 0, gen_loss = 0.8254366405111141, disc_loss = 0.1876111141548901
Trained batch 378 in epoch 0, gen_loss = 0.8248454022533346, disc_loss = 0.18770623106833811
Trained batch 379 in epoch 0, gen_loss = 0.8248348615671459, disc_loss = 0.1875746088004426
Trained batch 380 in epoch 0, gen_loss = 0.8252382800960791, disc_loss = 0.18786196721585716
Trained batch 381 in epoch 0, gen_loss = 0.8248031499810243, disc_loss = 0.18798621687355466
Trained batch 382 in epoch 0, gen_loss = 0.8243145650111664, disc_loss = 0.18806531435904864
Trained batch 383 in epoch 0, gen_loss = 0.8239947999827564, disc_loss = 0.18802043238732344
Trained batch 384 in epoch 0, gen_loss = 0.8238067515484698, disc_loss = 0.1881274853627403
Trained batch 385 in epoch 0, gen_loss = 0.8234045780384479, disc_loss = 0.18813922945313502
Trained batch 386 in epoch 0, gen_loss = 0.8231113419052243, disc_loss = 0.1881252835078757
Trained batch 387 in epoch 0, gen_loss = 0.8231942775015978, disc_loss = 0.18808005717534995
Trained batch 388 in epoch 0, gen_loss = 0.8230515336929066, disc_loss = 0.1880313521753853
Trained batch 389 in epoch 0, gen_loss = 0.82251473512405, disc_loss = 0.1881467094597144
Trained batch 390 in epoch 0, gen_loss = 0.8223102202500834, disc_loss = 0.1880362732979038
Trained batch 391 in epoch 0, gen_loss = 0.822510729030687, disc_loss = 0.18786573453749322
Trained batch 392 in epoch 0, gen_loss = 0.8221737919872953, disc_loss = 0.18763954747875836
Trained batch 393 in epoch 0, gen_loss = 0.8219945827111375, disc_loss = 0.18736721711412904
Trained batch 394 in epoch 0, gen_loss = 0.8220373108417173, disc_loss = 0.18728601758993124
Trained batch 395 in epoch 0, gen_loss = 0.8228814312905977, disc_loss = 0.18732451335197747
Trained batch 396 in epoch 0, gen_loss = 0.8226304982110896, disc_loss = 0.187229665122945
Trained batch 397 in epoch 0, gen_loss = 0.8222844364056036, disc_loss = 0.1872973532308286
Trained batch 398 in epoch 0, gen_loss = 0.8216646192665387, disc_loss = 0.18744507069725141
Trained batch 399 in epoch 0, gen_loss = 0.821666090041399, disc_loss = 0.1872728476114571
Trained batch 400 in epoch 0, gen_loss = 0.8220877901574323, disc_loss = 0.18738967449662097
Trained batch 401 in epoch 0, gen_loss = 0.8215346990236595, disc_loss = 0.18734461997649562
Trained batch 402 in epoch 0, gen_loss = 0.8216557842921974, disc_loss = 0.18717092451253542
Trained batch 403 in epoch 0, gen_loss = 0.8218198057153437, disc_loss = 0.18719980919198825
Trained batch 404 in epoch 0, gen_loss = 0.8213387599697819, disc_loss = 0.18718190382660171
Trained batch 405 in epoch 0, gen_loss = 0.8214050763346291, disc_loss = 0.18706438229809252
Trained batch 406 in epoch 0, gen_loss = 0.8211284500960929, disc_loss = 0.18688199491553575
Trained batch 407 in epoch 0, gen_loss = 0.8204357860719457, disc_loss = 0.18695818771626435
Trained batch 408 in epoch 0, gen_loss = 0.8207866599040976, disc_loss = 0.18704195739587537
Trained batch 409 in epoch 0, gen_loss = 0.820173165710961, disc_loss = 0.18727155742121906
Trained batch 410 in epoch 0, gen_loss = 0.8199110754795028, disc_loss = 0.1871963038931798
Trained batch 411 in epoch 0, gen_loss = 0.8197095048369714, disc_loss = 0.18730056090551672
Trained batch 412 in epoch 0, gen_loss = 0.8193546335864587, disc_loss = 0.18726526651775
Trained batch 413 in epoch 0, gen_loss = 0.8195156116704434, disc_loss = 0.18713346148890572
Trained batch 414 in epoch 0, gen_loss = 0.8194758237126362, disc_loss = 0.18690977575908224
Trained batch 415 in epoch 0, gen_loss = 0.8194368240924982, disc_loss = 0.186627718888653
Trained batch 416 in epoch 0, gen_loss = 0.8194117621838046, disc_loss = 0.18641558839834566
Trained batch 417 in epoch 0, gen_loss = 0.8192936116428466, disc_loss = 0.18643422360625564
Trained batch 418 in epoch 0, gen_loss = 0.8188651093150665, disc_loss = 0.18631185416959067
Trained batch 419 in epoch 0, gen_loss = 0.8188507935830525, disc_loss = 0.18603920211039837
Trained batch 420 in epoch 0, gen_loss = 0.8190276222104415, disc_loss = 0.18589406961358357
Trained batch 421 in epoch 0, gen_loss = 0.8185077157065767, disc_loss = 0.18587881489105135
Trained batch 422 in epoch 0, gen_loss = 0.8186998797083014, disc_loss = 0.18582315330809734
Trained batch 423 in epoch 0, gen_loss = 0.8191645219922066, disc_loss = 0.18544986825612075
Trained batch 424 in epoch 0, gen_loss = 0.8190464533076567, disc_loss = 0.1852037322433556
Trained batch 425 in epoch 0, gen_loss = 0.8189803335308469, disc_loss = 0.18493100903718404
Trained batch 426 in epoch 0, gen_loss = 0.8202009247114285, disc_loss = 0.18500927698730865
Trained batch 427 in epoch 0, gen_loss = 0.8198109535134841, disc_loss = 0.18486131474410541
Trained batch 428 in epoch 0, gen_loss = 0.8195836416213385, disc_loss = 0.1845952361596353
Trained batch 429 in epoch 0, gen_loss = 0.8197788856750311, disc_loss = 0.1843296491042819
Trained batch 430 in epoch 0, gen_loss = 0.819354391983103, disc_loss = 0.1842570944393179
Trained batch 431 in epoch 0, gen_loss = 0.8191424249498932, disc_loss = 0.18409682040240755
Trained batch 432 in epoch 0, gen_loss = 0.8196729143552361, disc_loss = 0.1840439743983966
Trained batch 433 in epoch 0, gen_loss = 0.8198235091251163, disc_loss = 0.18381065749112638
Trained batch 434 in epoch 0, gen_loss = 0.8193298708433392, disc_loss = 0.18462882303129668
Trained batch 435 in epoch 0, gen_loss = 0.8196213506503937, disc_loss = 0.18459205501157483
Trained batch 436 in epoch 0, gen_loss = 0.8194401467419326, disc_loss = 0.18457918630346007
Trained batch 437 in epoch 0, gen_loss = 0.8190777194282236, disc_loss = 0.18459509065604374
Trained batch 438 in epoch 0, gen_loss = 0.8190704827156589, disc_loss = 0.18461927147857965
Trained batch 439 in epoch 0, gen_loss = 0.8184146856719797, disc_loss = 0.18467736715789546
Trained batch 440 in epoch 0, gen_loss = 0.8185286519208462, disc_loss = 0.18453191545984102
Trained batch 441 in epoch 0, gen_loss = 0.8185896386657905, disc_loss = 0.18439449822504866
Trained batch 442 in epoch 0, gen_loss = 0.8188610187233436, disc_loss = 0.18409820638479282
Trained batch 443 in epoch 0, gen_loss = 0.8186054028369285, disc_loss = 0.18400288038459178
Trained batch 444 in epoch 0, gen_loss = 0.8187599053543605, disc_loss = 0.18375753421294555
Trained batch 445 in epoch 0, gen_loss = 0.81958166820586, disc_loss = 0.18349899409230247
Trained batch 446 in epoch 0, gen_loss = 0.8194352636401285, disc_loss = 0.1832801858067379
Trained batch 447 in epoch 0, gen_loss = 0.8191040820841279, disc_loss = 0.1832220156627175
Trained batch 448 in epoch 0, gen_loss = 0.8194362623388889, disc_loss = 0.18317325659643835
Trained batch 449 in epoch 0, gen_loss = 0.8197863176133897, disc_loss = 0.182904930661122
Trained batch 450 in epoch 0, gen_loss = 0.8193995812515462, disc_loss = 0.18272847875523196
Trained batch 451 in epoch 0, gen_loss = 0.8190978712740198, disc_loss = 0.18255204735406205
Trained batch 452 in epoch 0, gen_loss = 0.8188918126339944, disc_loss = 0.1824535856611418
Trained batch 453 in epoch 0, gen_loss = 0.8192293766049037, disc_loss = 0.18246154410001464
Trained batch 454 in epoch 0, gen_loss = 0.8199419387094267, disc_loss = 0.1822099526013647
Trained batch 455 in epoch 0, gen_loss = 0.8193062317737362, disc_loss = 0.1827361602826338
Trained batch 456 in epoch 0, gen_loss = 0.8200750884394156, disc_loss = 0.18265785421988637
Trained batch 457 in epoch 0, gen_loss = 0.820225448717717, disc_loss = 0.182363105506746
Trained batch 458 in epoch 0, gen_loss = 0.8200613427785487, disc_loss = 0.18213152515342812
Trained batch 459 in epoch 0, gen_loss = 0.8199965798336527, disc_loss = 0.1820036744941836
Trained batch 460 in epoch 0, gen_loss = 0.8198609686983899, disc_loss = 0.18205996203577698
Trained batch 461 in epoch 0, gen_loss = 0.8195944263305499, disc_loss = 0.1819766235751507
Trained batch 462 in epoch 0, gen_loss = 0.8192443142184428, disc_loss = 0.18198877286576298
Trained batch 463 in epoch 0, gen_loss = 0.8187374549693075, disc_loss = 0.18198266985087558
Trained batch 464 in epoch 0, gen_loss = 0.8187800151045604, disc_loss = 0.18187764863814077
Trained batch 465 in epoch 0, gen_loss = 0.8185605051179812, disc_loss = 0.18172022762664397
Trained batch 466 in epoch 0, gen_loss = 0.8183297260925653, disc_loss = 0.18157101282151913
Trained batch 467 in epoch 0, gen_loss = 0.8181031010089777, disc_loss = 0.18160450335942271
Trained batch 468 in epoch 0, gen_loss = 0.8185498302679326, disc_loss = 0.18175922037124126
Trained batch 469 in epoch 0, gen_loss = 0.817953504907324, disc_loss = 0.18184783628329318
Trained batch 470 in epoch 0, gen_loss = 0.8183078897480246, disc_loss = 0.18164333323068174
Trained batch 471 in epoch 0, gen_loss = 0.8183612809595415, disc_loss = 0.1813484373960202
Trained batch 472 in epoch 0, gen_loss = 0.8184950951541957, disc_loss = 0.1810913579440016
Trained batch 473 in epoch 0, gen_loss = 0.8180987668942802, disc_loss = 0.18108160873945756
Trained batch 474 in epoch 0, gen_loss = 0.8190084984428004, disc_loss = 0.1813642935219564
Trained batch 475 in epoch 0, gen_loss = 0.8185660146615085, disc_loss = 0.18132506512856783
Trained batch 476 in epoch 0, gen_loss = 0.8183745301994387, disc_loss = 0.18116587697210051
Trained batch 477 in epoch 0, gen_loss = 0.8182881846088744, disc_loss = 0.18100632666356892
Trained batch 478 in epoch 0, gen_loss = 0.8177597567532406, disc_loss = 0.1809797843680999
Trained batch 479 in epoch 0, gen_loss = 0.8176657857994238, disc_loss = 0.18091546786017715
Trained batch 480 in epoch 0, gen_loss = 0.817863003627674, disc_loss = 0.18110918873251103
Trained batch 481 in epoch 0, gen_loss = 0.817344482014288, disc_loss = 0.18106219832518783
Trained batch 482 in epoch 0, gen_loss = 0.8168667776984457, disc_loss = 0.18112135456400627
Trained batch 483 in epoch 0, gen_loss = 0.8168821029426637, disc_loss = 0.18115917286904884
Trained batch 484 in epoch 0, gen_loss = 0.8166467862030895, disc_loss = 0.18108638489676504
Trained batch 485 in epoch 0, gen_loss = 0.816452388778145, disc_loss = 0.1810364532955144
Trained batch 486 in epoch 0, gen_loss = 0.8162646968017124, disc_loss = 0.18106801965459415
Trained batch 487 in epoch 0, gen_loss = 0.8163388966292632, disc_loss = 0.18121755552157515
Trained batch 488 in epoch 0, gen_loss = 0.8160597972099523, disc_loss = 0.18110835255106533
Trained batch 489 in epoch 0, gen_loss = 0.8156967253101115, disc_loss = 0.18108181328493722
Trained batch 490 in epoch 0, gen_loss = 0.8154600483579694, disc_loss = 0.18103068279455248
Trained batch 491 in epoch 0, gen_loss = 0.815539357502286, disc_loss = 0.1808800730793699
Trained batch 492 in epoch 0, gen_loss = 0.8152773998088334, disc_loss = 0.18081246172861928
Trained batch 493 in epoch 0, gen_loss = 0.8150907787475509, disc_loss = 0.1806622089946318
Trained batch 494 in epoch 0, gen_loss = 0.8153701045296409, disc_loss = 0.18080152243074746
Trained batch 495 in epoch 0, gen_loss = 0.8154647391169302, disc_loss = 0.18052463507610222
Trained batch 496 in epoch 0, gen_loss = 0.8150060964781993, disc_loss = 0.18041289992765402
Trained batch 497 in epoch 0, gen_loss = 0.8144850040295996, disc_loss = 0.1804510840704762
Trained batch 498 in epoch 0, gen_loss = 0.8144525123502544, disc_loss = 0.18049911940414345
Trained batch 499 in epoch 0, gen_loss = 0.8142579780817032, disc_loss = 0.1803874159678817
Trained batch 500 in epoch 0, gen_loss = 0.8141122776829078, disc_loss = 0.18024258769885032
Trained batch 501 in epoch 0, gen_loss = 0.8135886256438327, disc_loss = 0.18018031778533858
Trained batch 502 in epoch 0, gen_loss = 0.8133636376492783, disc_loss = 0.1800844452416091
Trained batch 503 in epoch 0, gen_loss = 0.8131683861452436, disc_loss = 0.179948496698801
Trained batch 504 in epoch 0, gen_loss = 0.8128866142565662, disc_loss = 0.17976040225660447
Trained batch 505 in epoch 0, gen_loss = 0.8125309789840411, disc_loss = 0.17974105400029614
Trained batch 506 in epoch 0, gen_loss = 0.812792124362622, disc_loss = 0.1797752536069124
Trained batch 507 in epoch 0, gen_loss = 0.812400811183171, disc_loss = 0.17969387918564045
Trained batch 508 in epoch 0, gen_loss = 0.8122649354410078, disc_loss = 0.1796464151199651
Trained batch 509 in epoch 0, gen_loss = 0.812393669754851, disc_loss = 0.17975535383265392
Trained batch 510 in epoch 0, gen_loss = 0.8128192198486477, disc_loss = 0.17946255341201378
Trained batch 511 in epoch 0, gen_loss = 0.813033728627488, disc_loss = 0.1792219345952617
Trained batch 512 in epoch 0, gen_loss = 0.8130712589325263, disc_loss = 0.17895650252206052
Trained batch 513 in epoch 0, gen_loss = 0.813365123035379, disc_loss = 0.17864839411576203
Trained batch 514 in epoch 0, gen_loss = 0.8133467700874921, disc_loss = 0.1784028202656982
Trained batch 515 in epoch 0, gen_loss = 0.8134039916502412, disc_loss = 0.17820256412058144
Trained batch 516 in epoch 0, gen_loss = 0.8131468915155363, disc_loss = 0.1780456304622227
Trained batch 517 in epoch 0, gen_loss = 0.8131908363587147, disc_loss = 0.17786679896579977
Trained batch 518 in epoch 0, gen_loss = 0.814227724465791, disc_loss = 0.1778400257473851
Trained batch 519 in epoch 0, gen_loss = 0.8139090456641638, disc_loss = 0.17784539936110377
Trained batch 520 in epoch 0, gen_loss = 0.8137841761226617, disc_loss = 0.1778252943563713
Trained batch 521 in epoch 0, gen_loss = 0.8142171592319606, disc_loss = 0.178123672253727
Trained batch 522 in epoch 0, gen_loss = 0.8138099590861319, disc_loss = 0.1780518016085228
Trained batch 523 in epoch 0, gen_loss = 0.8132500954484212, disc_loss = 0.17805744442406274
Trained batch 524 in epoch 0, gen_loss = 0.8131791281700135, disc_loss = 0.17794929390152295
Trained batch 525 in epoch 0, gen_loss = 0.8128667048854973, disc_loss = 0.17788108740667652
Trained batch 526 in epoch 0, gen_loss = 0.8123401594569154, disc_loss = 0.17781427705508482
Trained batch 527 in epoch 0, gen_loss = 0.8117916896713503, disc_loss = 0.17785574052003073
Trained batch 528 in epoch 0, gen_loss = 0.8117917889908717, disc_loss = 0.17781175830047613
Trained batch 529 in epoch 0, gen_loss = 0.8122910017112516, disc_loss = 0.17756735049188138
Trained batch 530 in epoch 0, gen_loss = 0.8116874887893878, disc_loss = 0.17761710473457298
Trained batch 531 in epoch 0, gen_loss = 0.8116847648656458, disc_loss = 0.177416441156844
Trained batch 532 in epoch 0, gen_loss = 0.8122501104902371, disc_loss = 0.17739669346088094
Trained batch 533 in epoch 0, gen_loss = 0.8119363118423505, disc_loss = 0.17731185276270583
Trained batch 534 in epoch 0, gen_loss = 0.8114820064785324, disc_loss = 0.17737550748703637
Trained batch 535 in epoch 0, gen_loss = 0.8121380635829114, disc_loss = 0.17827723666664158
Trained batch 536 in epoch 0, gen_loss = 0.8116518264598243, disc_loss = 0.17847181822639827
Trained batch 537 in epoch 0, gen_loss = 0.8111581771347159, disc_loss = 0.1786257172813535
Trained batch 538 in epoch 0, gen_loss = 0.8107597659824067, disc_loss = 0.1787544515930766
Trained batch 539 in epoch 0, gen_loss = 0.810358813294658, disc_loss = 0.17890474933579012
Trained batch 540 in epoch 0, gen_loss = 0.8099092664868466, disc_loss = 0.1790143846019469
Trained batch 541 in epoch 0, gen_loss = 0.8094615845002812, disc_loss = 0.1791294244258936
Trained batch 542 in epoch 0, gen_loss = 0.8091293882928501, disc_loss = 0.17919469315345996
Trained batch 543 in epoch 0, gen_loss = 0.8087733510662528, disc_loss = 0.17930395070545593
Trained batch 544 in epoch 0, gen_loss = 0.8082774811928425, disc_loss = 0.17936089554921203
Trained batch 545 in epoch 0, gen_loss = 0.8078854897301713, disc_loss = 0.17939482200140264
Trained batch 546 in epoch 0, gen_loss = 0.8074169820361861, disc_loss = 0.179585272061487
Trained batch 547 in epoch 0, gen_loss = 0.8071875453647905, disc_loss = 0.17967702371550956
Trained batch 548 in epoch 0, gen_loss = 0.8070210929559662, disc_loss = 0.17970464786409462
Trained batch 549 in epoch 0, gen_loss = 0.8066909367387946, disc_loss = 0.17974161897870627
Trained batch 550 in epoch 0, gen_loss = 0.8062540076389071, disc_loss = 0.17985504213213488
Trained batch 551 in epoch 0, gen_loss = 0.8057142255314882, disc_loss = 0.17992680427361873
Trained batch 552 in epoch 0, gen_loss = 0.8054435616375956, disc_loss = 0.17994695796107513
Trained batch 553 in epoch 0, gen_loss = 0.8054632569263128, disc_loss = 0.1801137808737234
Trained batch 554 in epoch 0, gen_loss = 0.8052447940852191, disc_loss = 0.1801226074295538
Trained batch 555 in epoch 0, gen_loss = 0.8050842579963396, disc_loss = 0.18009042543553405
Trained batch 556 in epoch 0, gen_loss = 0.804723237960514, disc_loss = 0.18012225667359158
Trained batch 557 in epoch 0, gen_loss = 0.8042855850257327, disc_loss = 0.18019877595152692
Trained batch 558 in epoch 0, gen_loss = 0.8038777905201443, disc_loss = 0.18027542962664356
Trained batch 559 in epoch 0, gen_loss = 0.8034880483789103, disc_loss = 0.18027447985618242
Trained batch 560 in epoch 0, gen_loss = 0.80325304813776, disc_loss = 0.18026923306565235
Trained batch 561 in epoch 0, gen_loss = 0.8030219522447348, disc_loss = 0.18024000779351093
Trained batch 562 in epoch 0, gen_loss = 0.8025729372488669, disc_loss = 0.18019153793767545
Trained batch 563 in epoch 0, gen_loss = 0.8021123997919949, disc_loss = 0.1801874258667759
Trained batch 564 in epoch 0, gen_loss = 0.8018568544261223, disc_loss = 0.1801327056259708
Trained batch 565 in epoch 0, gen_loss = 0.8015992241276448, disc_loss = 0.18007718218167973
Trained batch 566 in epoch 0, gen_loss = 0.8012952861331758, disc_loss = 0.18009061172499438
Trained batch 567 in epoch 0, gen_loss = 0.8009262519403243, disc_loss = 0.18006715461165762
Trained batch 568 in epoch 0, gen_loss = 0.8007931439025959, disc_loss = 0.17995901614663262
Trained batch 569 in epoch 0, gen_loss = 0.8004030298768429, disc_loss = 0.1799253777126994
Trained batch 570 in epoch 0, gen_loss = 0.8002685964003127, disc_loss = 0.17992672446182228
Trained batch 571 in epoch 0, gen_loss = 0.8002106397302, disc_loss = 0.17981002716204295
Trained batch 572 in epoch 0, gen_loss = 0.8000255547476897, disc_loss = 0.17970304702771064
Trained batch 573 in epoch 0, gen_loss = 0.7999431977911693, disc_loss = 0.1796396334658828
Trained batch 574 in epoch 0, gen_loss = 0.799710965467536, disc_loss = 0.17950699350756147
Trained batch 575 in epoch 0, gen_loss = 0.7995282071125176, disc_loss = 0.1794289658169469
Trained batch 576 in epoch 0, gen_loss = 0.7991936307019543, disc_loss = 0.17941016555994593
Trained batch 577 in epoch 0, gen_loss = 0.7992373411011944, disc_loss = 0.1792347052788755
Trained batch 578 in epoch 0, gen_loss = 0.7990103928124554, disc_loss = 0.17909809719893394
Trained batch 579 in epoch 0, gen_loss = 0.7989531983589304, disc_loss = 0.17898805192189998
Trained batch 580 in epoch 0, gen_loss = 0.7986072088477943, disc_loss = 0.17896690186940248
Trained batch 581 in epoch 0, gen_loss = 0.798810884305292, disc_loss = 0.17894209820866788
Trained batch 582 in epoch 0, gen_loss = 0.7985308661060104, disc_loss = 0.17902825214927234
Trained batch 583 in epoch 0, gen_loss = 0.7984440868643865, disc_loss = 0.17899882632039793
Trained batch 584 in epoch 0, gen_loss = 0.7987462900642656, disc_loss = 0.17884024677750393
Trained batch 585 in epoch 0, gen_loss = 0.7987419148150564, disc_loss = 0.17860667154498067
Trained batch 586 in epoch 0, gen_loss = 0.7988036537901506, disc_loss = 0.17839594514726373
Trained batch 587 in epoch 0, gen_loss = 0.7988100515133669, disc_loss = 0.1782660696237367
Trained batch 588 in epoch 0, gen_loss = 0.7993903501126883, disc_loss = 0.17824113030612773
Trained batch 589 in epoch 0, gen_loss = 0.7994015066300408, disc_loss = 0.17803582076804111
Trained batch 590 in epoch 0, gen_loss = 0.7992418410410937, disc_loss = 0.17783541338874403
Trained batch 591 in epoch 0, gen_loss = 0.7996389244657915, disc_loss = 0.17764179334925437
Trained batch 592 in epoch 0, gen_loss = 0.8003188304314123, disc_loss = 0.17738909898153044
Trained batch 593 in epoch 0, gen_loss = 0.7999424787884208, disc_loss = 0.17770063051144885
Trained batch 594 in epoch 0, gen_loss = 0.8008276710991098, disc_loss = 0.17802554691413872
Trained batch 595 in epoch 0, gen_loss = 0.8006747606016645, disc_loss = 0.17785891524872324
Trained batch 596 in epoch 0, gen_loss = 0.8004022645990253, disc_loss = 0.17791719921245247
Trained batch 597 in epoch 0, gen_loss = 0.8005815970658459, disc_loss = 0.17790990509092808
Trained batch 598 in epoch 0, gen_loss = 0.8002526537205819, disc_loss = 0.17777853400037563
Trained batch 599 in epoch 0, gen_loss = 0.7998205347855886, disc_loss = 0.17786669097219904
Trained batch 600 in epoch 0, gen_loss = 0.7995781524605838, disc_loss = 0.1778555995600295
Trained batch 601 in epoch 0, gen_loss = 0.7996594164260599, disc_loss = 0.17780122712279278
Trained batch 602 in epoch 0, gen_loss = 0.8000043706712042, disc_loss = 0.17759901978334977
Trained batch 603 in epoch 0, gen_loss = 0.7997633484223031, disc_loss = 0.177435092344288
Trained batch 604 in epoch 0, gen_loss = 0.7997680994104748, disc_loss = 0.17724171860897836
Trained batch 605 in epoch 0, gen_loss = 0.8001099473769122, disc_loss = 0.1770495189163256
Trained batch 606 in epoch 0, gen_loss = 0.7997321014152916, disc_loss = 0.17689450215885824
Trained batch 607 in epoch 0, gen_loss = 0.7992880148322958, disc_loss = 0.17690454352965676
Trained batch 608 in epoch 0, gen_loss = 0.799393477600392, disc_loss = 0.17683416150498077
Trained batch 609 in epoch 0, gen_loss = 0.7997744461552041, disc_loss = 0.17684500650426405
Trained batch 610 in epoch 0, gen_loss = 0.8004857903611641, disc_loss = 0.1766140854044066
Trained batch 611 in epoch 0, gen_loss = 0.8001192972745771, disc_loss = 0.1766567578100983
Trained batch 612 in epoch 0, gen_loss = 0.8000971440584391, disc_loss = 0.176480077103777
Trained batch 613 in epoch 0, gen_loss = 0.8004476583353471, disc_loss = 0.17639866151546615
Trained batch 614 in epoch 0, gen_loss = 0.8004085219972502, disc_loss = 0.17625682703484363
Trained batch 615 in epoch 0, gen_loss = 0.800069971518083, disc_loss = 0.17628560772214036
Trained batch 616 in epoch 0, gen_loss = 0.8003439384496, disc_loss = 0.1762775864325331
Trained batch 617 in epoch 0, gen_loss = 0.7999676422586719, disc_loss = 0.17629024302617052
Trained batch 618 in epoch 0, gen_loss = 0.7997831106185913, disc_loss = 0.17616822094519613
Trained batch 619 in epoch 0, gen_loss = 0.7994752941593047, disc_loss = 0.1761303205343504
Trained batch 620 in epoch 0, gen_loss = 0.7994715958209814, disc_loss = 0.176165034847511
Trained batch 621 in epoch 0, gen_loss = 0.7990465637571942, disc_loss = 0.176237303002998
Trained batch 622 in epoch 0, gen_loss = 0.7989018950760843, disc_loss = 0.17623236863298364
Trained batch 623 in epoch 0, gen_loss = 0.7989658145950391, disc_loss = 0.17618200585890847
Trained batch 624 in epoch 0, gen_loss = 0.7986465316772461, disc_loss = 0.1761095294177532
Trained batch 625 in epoch 0, gen_loss = 0.7985512766594323, disc_loss = 0.17598027104553512
Trained batch 626 in epoch 0, gen_loss = 0.798225636117196, disc_loss = 0.17591887723767397
Trained batch 627 in epoch 0, gen_loss = 0.7980230141217541, disc_loss = 0.17599310049087188
Trained batch 628 in epoch 0, gen_loss = 0.7977139780176463, disc_loss = 0.17591932832318194
Trained batch 629 in epoch 0, gen_loss = 0.79751699718218, disc_loss = 0.17591919635851233
Trained batch 630 in epoch 0, gen_loss = 0.7973655563337867, disc_loss = 0.17586298043088378
Trained batch 631 in epoch 0, gen_loss = 0.7974330494298211, disc_loss = 0.17590781022452667
Trained batch 632 in epoch 0, gen_loss = 0.7969562488050446, disc_loss = 0.1760815164901163
Trained batch 633 in epoch 0, gen_loss = 0.796920167863933, disc_loss = 0.1760792777776624
Trained batch 634 in epoch 0, gen_loss = 0.797214129731411, disc_loss = 0.1759811208532082
Trained batch 635 in epoch 0, gen_loss = 0.7970296980918579, disc_loss = 0.17585525842699803
Trained batch 636 in epoch 0, gen_loss = 0.7966878170401934, disc_loss = 0.17594449318582822
Trained batch 637 in epoch 0, gen_loss = 0.7965877048180768, disc_loss = 0.17589715600223937
Trained batch 638 in epoch 0, gen_loss = 0.7964504950203246, disc_loss = 0.1758442979148576
Trained batch 639 in epoch 0, gen_loss = 0.7963221110869199, disc_loss = 0.17583243679837324
Trained batch 640 in epoch 0, gen_loss = 0.7962631225678924, disc_loss = 0.17578541372965167
Trained batch 641 in epoch 0, gen_loss = 0.7963767158929432, disc_loss = 0.1756650202057536
Trained batch 642 in epoch 0, gen_loss = 0.7959633026022933, disc_loss = 0.1757875350977455
Trained batch 643 in epoch 0, gen_loss = 0.7961690936306989, disc_loss = 0.17569305202258484
Trained batch 644 in epoch 0, gen_loss = 0.7960892645425575, disc_loss = 0.1756109401641428
Trained batch 645 in epoch 0, gen_loss = 0.7958485640516222, disc_loss = 0.17546148050933985
Trained batch 646 in epoch 0, gen_loss = 0.7954967632267906, disc_loss = 0.17545697306623967
Trained batch 647 in epoch 0, gen_loss = 0.7955119269037688, disc_loss = 0.1755612452491474
Trained batch 648 in epoch 0, gen_loss = 0.7951436184679599, disc_loss = 0.17550849760143525
Trained batch 649 in epoch 0, gen_loss = 0.7949322942128548, disc_loss = 0.17541177445306227
Trained batch 650 in epoch 0, gen_loss = 0.7948989680926738, disc_loss = 0.17534002767569642
Trained batch 651 in epoch 0, gen_loss = 0.7948503196696562, disc_loss = 0.17528925685817662
Trained batch 652 in epoch 0, gen_loss = 0.7944596224959375, disc_loss = 0.1753255083963024
Trained batch 653 in epoch 0, gen_loss = 0.7944813619057337, disc_loss = 0.17525960275453348
Trained batch 654 in epoch 0, gen_loss = 0.794888331917406, disc_loss = 0.1753135932822719
Trained batch 655 in epoch 0, gen_loss = 0.7952246441074261, disc_loss = 0.17512065206836092
Trained batch 656 in epoch 0, gen_loss = 0.7949024948264547, disc_loss = 0.17511807595871537
Trained batch 657 in epoch 0, gen_loss = 0.7948765297700568, disc_loss = 0.1749541040985508
Trained batch 658 in epoch 0, gen_loss = 0.7949990652309383, disc_loss = 0.1749293669685156
Trained batch 659 in epoch 0, gen_loss = 0.794844463512753, disc_loss = 0.17488272007780545
Trained batch 660 in epoch 0, gen_loss = 0.7945450337409252, disc_loss = 0.17483379646188912
Trained batch 661 in epoch 0, gen_loss = 0.7946083795538121, disc_loss = 0.17484536558232097
Trained batch 662 in epoch 0, gen_loss = 0.7945474105273257, disc_loss = 0.17475058663731965
Trained batch 663 in epoch 0, gen_loss = 0.7944912170340498, disc_loss = 0.17457894049023828
Trained batch 664 in epoch 0, gen_loss = 0.7943114712274164, disc_loss = 0.17450805854864587
Trained batch 665 in epoch 0, gen_loss = 0.7953522425066601, disc_loss = 0.1746405577594722
Trained batch 666 in epoch 0, gen_loss = 0.7954166002984884, disc_loss = 0.17446938550275662
Trained batch 667 in epoch 0, gen_loss = 0.7953946719358781, disc_loss = 0.17429146055734443
Trained batch 668 in epoch 0, gen_loss = 0.7953485540477684, disc_loss = 0.17415362505189327
Trained batch 669 in epoch 0, gen_loss = 0.7952826684535439, disc_loss = 0.17407283380405228
Trained batch 670 in epoch 0, gen_loss = 0.7951581525642719, disc_loss = 0.173982479977359
Trained batch 671 in epoch 0, gen_loss = 0.7948325523397043, disc_loss = 0.17407169463556438
Trained batch 672 in epoch 0, gen_loss = 0.7950256725919902, disc_loss = 0.1740362313181649
Trained batch 673 in epoch 0, gen_loss = 0.7955173106770134, disc_loss = 0.17385414302437524
Trained batch 674 in epoch 0, gen_loss = 0.7952425794689744, disc_loss = 0.17391871567125675
Trained batch 675 in epoch 0, gen_loss = 0.7953546298061602, disc_loss = 0.1737623906765993
Trained batch 676 in epoch 0, gen_loss = 0.7953146400708744, disc_loss = 0.17364548170936336
Trained batch 677 in epoch 0, gen_loss = 0.7951717661984902, disc_loss = 0.1735181891329169
Trained batch 678 in epoch 0, gen_loss = 0.7952642485126304, disc_loss = 0.1734710944287029
Trained batch 679 in epoch 0, gen_loss = 0.7955240683082272, disc_loss = 0.1732951358125052
Trained batch 680 in epoch 0, gen_loss = 0.7951154100124707, disc_loss = 0.17364271999871503
Trained batch 681 in epoch 0, gen_loss = 0.795303359977311, disc_loss = 0.17359930053462555
Trained batch 682 in epoch 0, gen_loss = 0.7955014991463539, disc_loss = 0.17358857342539735
Trained batch 683 in epoch 0, gen_loss = 0.7953617181084309, disc_loss = 0.17348275996461424
Trained batch 684 in epoch 0, gen_loss = 0.7949178811842508, disc_loss = 0.17353484439697578
Trained batch 685 in epoch 0, gen_loss = 0.7950353739299858, disc_loss = 0.17346297826281268
Trained batch 686 in epoch 0, gen_loss = 0.7950498803126933, disc_loss = 0.173321527126618
Trained batch 687 in epoch 0, gen_loss = 0.7956246378896541, disc_loss = 0.1731659610441691
Trained batch 688 in epoch 0, gen_loss = 0.7953547236275776, disc_loss = 0.17307823072951314
Trained batch 689 in epoch 0, gen_loss = 0.7951952123555585, disc_loss = 0.1729157489872929
Trained batch 690 in epoch 0, gen_loss = 0.7953748688770272, disc_loss = 0.17279416466652053
Trained batch 691 in epoch 0, gen_loss = 0.7955201288437568, disc_loss = 0.17259233844913327
Trained batch 692 in epoch 0, gen_loss = 0.7955346681596913, disc_loss = 0.17247820074144551
Trained batch 693 in epoch 0, gen_loss = 0.7953238607054142, disc_loss = 0.1724463071437923
Trained batch 694 in epoch 0, gen_loss = 0.7959939757268206, disc_loss = 0.17274592601888472
Trained batch 695 in epoch 0, gen_loss = 0.7958770938560196, disc_loss = 0.17260413139994288
Trained batch 696 in epoch 0, gen_loss = 0.7954091710630414, disc_loss = 0.17265095665965394
Trained batch 697 in epoch 0, gen_loss = 0.7953558123128803, disc_loss = 0.17262341915216178
Trained batch 698 in epoch 0, gen_loss = 0.7955951640790112, disc_loss = 0.17260118652247053
Trained batch 699 in epoch 0, gen_loss = 0.795263548365661, disc_loss = 0.17258705088602644
Trained batch 700 in epoch 0, gen_loss = 0.7949460014892202, disc_loss = 0.17256065057896172
Trained batch 701 in epoch 0, gen_loss = 0.7947757303120404, disc_loss = 0.17256461574757032
Trained batch 702 in epoch 0, gen_loss = 0.7949401311057052, disc_loss = 0.17245214019675512
Trained batch 703 in epoch 0, gen_loss = 0.7947005121968687, disc_loss = 0.17253306132889437
Trained batch 704 in epoch 0, gen_loss = 0.794377867592142, disc_loss = 0.172519993015849
Trained batch 705 in epoch 0, gen_loss = 0.7943394778892608, disc_loss = 0.17250721253159196
Trained batch 706 in epoch 0, gen_loss = 0.7946057642956266, disc_loss = 0.17238239760087773
Trained batch 707 in epoch 0, gen_loss = 0.7943196722258956, disc_loss = 0.17254137508255446
Trained batch 708 in epoch 0, gen_loss = 0.7939199521528144, disc_loss = 0.172656867243297
Trained batch 709 in epoch 0, gen_loss = 0.7939523306950717, disc_loss = 0.17263624155500407
Trained batch 710 in epoch 0, gen_loss = 0.793865258557887, disc_loss = 0.17260577291271187
Trained batch 711 in epoch 0, gen_loss = 0.7937847446608409, disc_loss = 0.17250283804900024
Trained batch 712 in epoch 0, gen_loss = 0.7938967612565483, disc_loss = 0.17233990223720397
Trained batch 713 in epoch 0, gen_loss = 0.7938693657058293, disc_loss = 0.17215385806097203
Trained batch 714 in epoch 0, gen_loss = 0.7937675858294213, disc_loss = 0.17199764711248292
Trained batch 715 in epoch 0, gen_loss = 0.7940653937572207, disc_loss = 0.17181762727237612
Trained batch 716 in epoch 0, gen_loss = 0.7941007004372744, disc_loss = 0.17162508785599945
Trained batch 717 in epoch 0, gen_loss = 0.793830880506125, disc_loss = 0.17161187868887004
Trained batch 718 in epoch 0, gen_loss = 0.7937195336288139, disc_loss = 0.17154564932299587
Trained batch 719 in epoch 0, gen_loss = 0.7941047069513135, disc_loss = 0.17157452744949195
Trained batch 720 in epoch 0, gen_loss = 0.7939846731009331, disc_loss = 0.17145950864902315
Trained batch 721 in epoch 0, gen_loss = 0.7937158135248353, disc_loss = 0.17142275566044277
Trained batch 722 in epoch 0, gen_loss = 0.7937696361360378, disc_loss = 0.17139285225756107
Trained batch 723 in epoch 0, gen_loss = 0.7937151648474662, disc_loss = 0.17127236231996867
Trained batch 724 in epoch 0, gen_loss = 0.7938264339134611, disc_loss = 0.17108465552330018
Trained batch 725 in epoch 0, gen_loss = 0.7937633995756959, disc_loss = 0.17089993102327194
Trained batch 726 in epoch 0, gen_loss = 0.7933916725433512, disc_loss = 0.1709391650996149
Trained batch 727 in epoch 0, gen_loss = 0.7933549308269233, disc_loss = 0.17088331474543927
Trained batch 728 in epoch 0, gen_loss = 0.7933086783552366, disc_loss = 0.170939692213048
Trained batch 729 in epoch 0, gen_loss = 0.7930349173202906, disc_loss = 0.17102407010859005
Trained batch 730 in epoch 0, gen_loss = 0.7933658713273571, disc_loss = 0.17109001151677194
Trained batch 731 in epoch 0, gen_loss = 0.7937980028368085, disc_loss = 0.17089294690048434
Trained batch 732 in epoch 0, gen_loss = 0.7938823974392749, disc_loss = 0.1707324716141816
Trained batch 733 in epoch 0, gen_loss = 0.7939810344000279, disc_loss = 0.17055736465394822
Trained batch 734 in epoch 0, gen_loss = 0.7940701648086107, disc_loss = 0.17035232248152193
Trained batch 735 in epoch 0, gen_loss = 0.7941981726933433, disc_loss = 0.17020201575233723
Trained batch 736 in epoch 0, gen_loss = 0.7944097573511313, disc_loss = 0.17004629719390799
Trained batch 737 in epoch 0, gen_loss = 0.7942638274050018, disc_loss = 0.16991058158054745
Trained batch 738 in epoch 0, gen_loss = 0.7939523896038613, disc_loss = 0.1699719792622594
Trained batch 739 in epoch 0, gen_loss = 0.7939892060450605, disc_loss = 0.16999901797421074
Trained batch 740 in epoch 0, gen_loss = 0.7938526611820407, disc_loss = 0.17001042586931012
Trained batch 741 in epoch 0, gen_loss = 0.7937387339268733, disc_loss = 0.1699120017004543
Trained batch 742 in epoch 0, gen_loss = 0.7942087110006633, disc_loss = 0.16985960650191334
Trained batch 743 in epoch 0, gen_loss = 0.7937424614304497, disc_loss = 0.1698087793374334
Trained batch 744 in epoch 0, gen_loss = 0.7933589447664734, disc_loss = 0.16978945690613464
Trained batch 745 in epoch 0, gen_loss = 0.7934549900306134, disc_loss = 0.16976978700238482
Trained batch 746 in epoch 0, gen_loss = 0.7938541166354693, disc_loss = 0.16968624092828
Trained batch 747 in epoch 0, gen_loss = 0.7932976478720731, disc_loss = 0.1698735285062283
Trained batch 748 in epoch 0, gen_loss = 0.793124776736439, disc_loss = 0.16985057527634584
Trained batch 749 in epoch 0, gen_loss = 0.7935738573869069, disc_loss = 0.16999899562696616
Trained batch 750 in epoch 0, gen_loss = 0.793382377980076, disc_loss = 0.16995214884691487
Trained batch 751 in epoch 0, gen_loss = 0.7930025060443168, disc_loss = 0.17002188331606063
Trained batch 752 in epoch 0, gen_loss = 0.7927687543321891, disc_loss = 0.17000921979388234
Trained batch 753 in epoch 0, gen_loss = 0.7927902865789297, disc_loss = 0.1700086466009563
Trained batch 754 in epoch 0, gen_loss = 0.7926343272063906, disc_loss = 0.1699779428442977
Trained batch 755 in epoch 0, gen_loss = 0.7924430410540293, disc_loss = 0.16995934649769748
Trained batch 756 in epoch 0, gen_loss = 0.7922371332207633, disc_loss = 0.16996001280460363
Trained batch 757 in epoch 0, gen_loss = 0.7919067931521222, disc_loss = 0.16996612070044773
Trained batch 758 in epoch 0, gen_loss = 0.791666264512008, disc_loss = 0.1700173333159627
Trained batch 759 in epoch 0, gen_loss = 0.7915614448095623, disc_loss = 0.17000442930056076
Trained batch 760 in epoch 0, gen_loss = 0.7914352681727667, disc_loss = 0.17001490499065522
Trained batch 761 in epoch 0, gen_loss = 0.7910537237101026, disc_loss = 0.17033082503444097
Trained batch 762 in epoch 0, gen_loss = 0.7910155930494106, disc_loss = 0.17028873594939162
Trained batch 763 in epoch 0, gen_loss = 0.7908554970437943, disc_loss = 0.17033887380022186
Trained batch 764 in epoch 0, gen_loss = 0.7905064998888502, disc_loss = 0.1703184842527692
Trained batch 765 in epoch 0, gen_loss = 0.7902077795164392, disc_loss = 0.1703371399230574
Trained batch 766 in epoch 0, gen_loss = 0.7902154863424686, disc_loss = 0.1704494593594578
Trained batch 767 in epoch 0, gen_loss = 0.7901324009678016, disc_loss = 0.17050028001055276
Trained batch 768 in epoch 0, gen_loss = 0.7900221174963119, disc_loss = 0.17046072942014634
Trained batch 769 in epoch 0, gen_loss = 0.7897473949116546, disc_loss = 0.1704204080215135
Trained batch 770 in epoch 0, gen_loss = 0.7895635189403974, disc_loss = 0.17051507076961211
Trained batch 771 in epoch 0, gen_loss = 0.7892670353459571, disc_loss = 0.17051450883573974
Trained batch 772 in epoch 0, gen_loss = 0.7889505893878764, disc_loss = 0.17057532909173242
Trained batch 773 in epoch 0, gen_loss = 0.7887620973648642, disc_loss = 0.17060067025747255
Trained batch 774 in epoch 0, gen_loss = 0.7886194887468891, disc_loss = 0.1705566053861572
Trained batch 775 in epoch 0, gen_loss = 0.7883864759477144, disc_loss = 0.17066735127633534
Trained batch 776 in epoch 0, gen_loss = 0.7881597162366988, disc_loss = 0.1706689510499265
Trained batch 777 in epoch 0, gen_loss = 0.7879138280156339, disc_loss = 0.17064623671145704
Trained batch 778 in epoch 0, gen_loss = 0.787948051374286, disc_loss = 0.17057621246144003
Trained batch 779 in epoch 0, gen_loss = 0.7880381046197353, disc_loss = 0.17045194550106924
Trained batch 780 in epoch 0, gen_loss = 0.787951268704081, disc_loss = 0.17033764740473634
Trained batch 781 in epoch 0, gen_loss = 0.7880232671794989, disc_loss = 0.17020296508832203
Trained batch 782 in epoch 0, gen_loss = 0.7880107207012055, disc_loss = 0.17009119781288456
Trained batch 783 in epoch 0, gen_loss = 0.7881753987499646, disc_loss = 0.1699091450225714
Trained batch 784 in epoch 0, gen_loss = 0.7878239700748663, disc_loss = 0.16984310535014055
Trained batch 785 in epoch 0, gen_loss = 0.7876366990364841, disc_loss = 0.16983014325736892
Trained batch 786 in epoch 0, gen_loss = 0.7879497172568926, disc_loss = 0.1698924560132975
Trained batch 787 in epoch 0, gen_loss = 0.7879329976545373, disc_loss = 0.1697371269571524
Trained batch 788 in epoch 0, gen_loss = 0.7879223975391896, disc_loss = 0.1695735289258422
Trained batch 789 in epoch 0, gen_loss = 0.7878226037266888, disc_loss = 0.169507972683899
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6175355911254883, disc_loss = 0.08908811211585999
Trained batch 1 in epoch 1, gen_loss = 0.9054034948348999, disc_loss = 0.11291303485631943
Trained batch 2 in epoch 1, gen_loss = 0.8340538740158081, disc_loss = 0.11677166571219762
Trained batch 3 in epoch 1, gen_loss = 0.7710671722888947, disc_loss = 0.15545139275491238
Trained batch 4 in epoch 1, gen_loss = 0.8020376682281494, disc_loss = 0.14406723529100418
Trained batch 5 in epoch 1, gen_loss = 0.8389454285303751, disc_loss = 0.126388402034839
Trained batch 6 in epoch 1, gen_loss = 0.8173604352133614, disc_loss = 0.11659019493630954
Trained batch 7 in epoch 1, gen_loss = 0.7987069636583328, disc_loss = 0.11984297586604953
Trained batch 8 in epoch 1, gen_loss = 0.8364987240897285, disc_loss = 0.1277550487882561
Trained batch 9 in epoch 1, gen_loss = 0.807258939743042, disc_loss = 0.139089297875762
Trained batch 10 in epoch 1, gen_loss = 0.8082996552640741, disc_loss = 0.13656030425971205
Trained batch 11 in epoch 1, gen_loss = 0.8225997189680735, disc_loss = 0.13919308129698038
Trained batch 12 in epoch 1, gen_loss = 0.8022958773833054, disc_loss = 0.14189164655712935
Trained batch 13 in epoch 1, gen_loss = 0.7979280352592468, disc_loss = 0.1389188806393317
Trained batch 14 in epoch 1, gen_loss = 0.8020084818204244, disc_loss = 0.1389022149145603
Trained batch 15 in epoch 1, gen_loss = 0.7862251177430153, disc_loss = 0.14720236486755311
Trained batch 16 in epoch 1, gen_loss = 0.7993138046825633, disc_loss = 0.1543208761688541
Trained batch 17 in epoch 1, gen_loss = 0.7991795738538107, disc_loss = 0.15125144003993934
Trained batch 18 in epoch 1, gen_loss = 0.7858360252882305, disc_loss = 0.1572488622837945
Trained batch 19 in epoch 1, gen_loss = 0.7859513163566589, disc_loss = 0.15519377682358027
Trained batch 20 in epoch 1, gen_loss = 0.7974174476805187, disc_loss = 0.15431803908376468
Trained batch 21 in epoch 1, gen_loss = 0.8032958778468046, disc_loss = 0.14957563714547592
Trained batch 22 in epoch 1, gen_loss = 0.7945650634558304, disc_loss = 0.15006850011970685
Trained batch 23 in epoch 1, gen_loss = 0.7868449166417122, disc_loss = 0.1529351118952036
Trained batch 24 in epoch 1, gen_loss = 0.7991678833961486, disc_loss = 0.1554175114631653
Trained batch 25 in epoch 1, gen_loss = 0.7888138454694015, disc_loss = 0.1567884425704296
Trained batch 26 in epoch 1, gen_loss = 0.782731729525107, disc_loss = 0.15759677081196397
Trained batch 27 in epoch 1, gen_loss = 0.7882631016629082, disc_loss = 0.1620400148843016
Trained batch 28 in epoch 1, gen_loss = 0.7843567687889625, disc_loss = 0.16150114916521927
Trained batch 29 in epoch 1, gen_loss = 0.7769760906696319, disc_loss = 0.16404729435841242
Trained batch 30 in epoch 1, gen_loss = 0.7713616759546341, disc_loss = 0.16381247149359796
Trained batch 31 in epoch 1, gen_loss = 0.7666843831539154, disc_loss = 0.16318958485499024
Trained batch 32 in epoch 1, gen_loss = 0.764184321417953, disc_loss = 0.16555013755957285
Trained batch 33 in epoch 1, gen_loss = 0.7627134077689227, disc_loss = 0.16605063615476384
Trained batch 34 in epoch 1, gen_loss = 0.7596051863261631, disc_loss = 0.16581876192774092
Trained batch 35 in epoch 1, gen_loss = 0.7544550978475146, disc_loss = 0.16511931270360947
Trained batch 36 in epoch 1, gen_loss = 0.7508713570800988, disc_loss = 0.1649032460676657
Trained batch 37 in epoch 1, gen_loss = 0.7533688168776663, disc_loss = 0.1646752843731328
Trained batch 38 in epoch 1, gen_loss = 0.7522021776590592, disc_loss = 0.16334918924631217
Trained batch 39 in epoch 1, gen_loss = 0.7511677712202072, disc_loss = 0.16174107044935226
Trained batch 40 in epoch 1, gen_loss = 0.7520527432604533, disc_loss = 0.15994396787591098
Trained batch 41 in epoch 1, gen_loss = 0.7499568093390692, disc_loss = 0.1589209847152233
Trained batch 42 in epoch 1, gen_loss = 0.7526275806648787, disc_loss = 0.15934894927019297
Trained batch 43 in epoch 1, gen_loss = 0.7538096064871008, disc_loss = 0.15715931677682834
Trained batch 44 in epoch 1, gen_loss = 0.75055832862854, disc_loss = 0.15696545657184388
Trained batch 45 in epoch 1, gen_loss = 0.7554693014725394, disc_loss = 0.1565381999572982
Trained batch 46 in epoch 1, gen_loss = 0.7586173833684718, disc_loss = 0.1543319156353778
Trained batch 47 in epoch 1, gen_loss = 0.7535862252116203, disc_loss = 0.15610124675246576
Trained batch 48 in epoch 1, gen_loss = 0.7536136507987976, disc_loss = 0.155803348108822
Trained batch 49 in epoch 1, gen_loss = 0.7499080955982208, disc_loss = 0.15700403310358524
Trained batch 50 in epoch 1, gen_loss = 0.7492364107393751, disc_loss = 0.15686345020053433
Trained batch 51 in epoch 1, gen_loss = 0.7457279287851774, disc_loss = 0.15713601939093608
Trained batch 52 in epoch 1, gen_loss = 0.7436017112911872, disc_loss = 0.15733418887797393
Trained batch 53 in epoch 1, gen_loss = 0.7418209733786406, disc_loss = 0.15710114694579883
Trained batch 54 in epoch 1, gen_loss = 0.7431712627410889, disc_loss = 0.15799385234713553
Trained batch 55 in epoch 1, gen_loss = 0.7415888756513596, disc_loss = 0.15630608085276826
Trained batch 56 in epoch 1, gen_loss = 0.7381578213290164, disc_loss = 0.15756701932925926
Trained batch 57 in epoch 1, gen_loss = 0.7387050143603621, disc_loss = 0.15653786172383818
Trained batch 58 in epoch 1, gen_loss = 0.7489328303579557, disc_loss = 0.15745443162524095
Trained batch 59 in epoch 1, gen_loss = 0.7487760027249654, disc_loss = 0.15550107217083375
Trained batch 60 in epoch 1, gen_loss = 0.7440577442528772, disc_loss = 0.15682457564551322
Trained batch 61 in epoch 1, gen_loss = 0.7448779046535492, disc_loss = 0.15666653414166742
Trained batch 62 in epoch 1, gen_loss = 0.7477542086253091, disc_loss = 0.15754421368714364
Trained batch 63 in epoch 1, gen_loss = 0.7447996092960238, disc_loss = 0.15922645112732425
Trained batch 64 in epoch 1, gen_loss = 0.7451685089331407, disc_loss = 0.15876276773902087
Trained batch 65 in epoch 1, gen_loss = 0.7454291898192782, disc_loss = 0.15946238154940534
Trained batch 66 in epoch 1, gen_loss = 0.7435116509893047, disc_loss = 0.1602845067964561
Trained batch 67 in epoch 1, gen_loss = 0.7435121983289719, disc_loss = 0.16031907854930444
Trained batch 68 in epoch 1, gen_loss = 0.7411458198575006, disc_loss = 0.15993705138132192
Trained batch 69 in epoch 1, gen_loss = 0.7391375916344779, disc_loss = 0.15995463159467493
Trained batch 70 in epoch 1, gen_loss = 0.7387197370260534, disc_loss = 0.16050032059281644
Trained batch 71 in epoch 1, gen_loss = 0.7358729533023305, disc_loss = 0.16120089202498397
Trained batch 72 in epoch 1, gen_loss = 0.7350146615341918, disc_loss = 0.16045671941278733
Trained batch 73 in epoch 1, gen_loss = 0.7341276173656052, disc_loss = 0.16052540406786106
Trained batch 74 in epoch 1, gen_loss = 0.7332303619384766, disc_loss = 0.16027653947472573
Trained batch 75 in epoch 1, gen_loss = 0.7337011789020739, disc_loss = 0.1589405121477811
Trained batch 76 in epoch 1, gen_loss = 0.7323186281439545, disc_loss = 0.1583217191328476
Trained batch 77 in epoch 1, gen_loss = 0.7329350343117347, disc_loss = 0.1573422237371023
Trained batch 78 in epoch 1, gen_loss = 0.732725445228287, disc_loss = 0.15706229129735427
Trained batch 79 in epoch 1, gen_loss = 0.7324813053011894, disc_loss = 0.15705538741312922
Trained batch 80 in epoch 1, gen_loss = 0.7304091460910844, disc_loss = 0.15672215557208768
Trained batch 81 in epoch 1, gen_loss = 0.7283335357177548, disc_loss = 0.15703516430789377
Trained batch 82 in epoch 1, gen_loss = 0.7294285591826382, disc_loss = 0.15692044700305147
Trained batch 83 in epoch 1, gen_loss = 0.7305687516927719, disc_loss = 0.1563560108964642
Trained batch 84 in epoch 1, gen_loss = 0.7287331518004923, disc_loss = 0.15695226047845448
Trained batch 85 in epoch 1, gen_loss = 0.7303072103234225, disc_loss = 0.1559176293829846
Trained batch 86 in epoch 1, gen_loss = 0.7326121138430189, disc_loss = 0.15584086819455542
Trained batch 87 in epoch 1, gen_loss = 0.7321523482149298, disc_loss = 0.15553784416988492
Trained batch 88 in epoch 1, gen_loss = 0.730101026845782, disc_loss = 0.15596484531010135
Trained batch 89 in epoch 1, gen_loss = 0.7296525743272569, disc_loss = 0.15573986201650566
Trained batch 90 in epoch 1, gen_loss = 0.7296573329757858, disc_loss = 0.15536241998875533
Trained batch 91 in epoch 1, gen_loss = 0.7291672035403873, disc_loss = 0.15495681434707798
Trained batch 92 in epoch 1, gen_loss = 0.7279892813774848, disc_loss = 0.15455815696748354
Trained batch 93 in epoch 1, gen_loss = 0.7283578641871189, disc_loss = 0.15381611641892728
Trained batch 94 in epoch 1, gen_loss = 0.7292001159567582, disc_loss = 0.1528503884218241
Trained batch 95 in epoch 1, gen_loss = 0.7297152522951365, disc_loss = 0.1525151258877789
Trained batch 96 in epoch 1, gen_loss = 0.7292543016758162, disc_loss = 0.15210884252620727
Trained batch 97 in epoch 1, gen_loss = 0.7302164313744526, disc_loss = 0.15173406036076498
Trained batch 98 in epoch 1, gen_loss = 0.7315246938454985, disc_loss = 0.15084932943937754
Trained batch 99 in epoch 1, gen_loss = 0.7315859854221344, disc_loss = 0.14991636045277118
Trained batch 100 in epoch 1, gen_loss = 0.7309564405148572, disc_loss = 0.14997618586415112
Trained batch 101 in epoch 1, gen_loss = 0.7306162510432449, disc_loss = 0.1496720230024235
Trained batch 102 in epoch 1, gen_loss = 0.731328501863387, disc_loss = 0.14958557435899106
Trained batch 103 in epoch 1, gen_loss = 0.7311641155527189, disc_loss = 0.14916031915121353
Trained batch 104 in epoch 1, gen_loss = 0.7341948866844177, disc_loss = 0.14816907615888686
Trained batch 105 in epoch 1, gen_loss = 0.7346181391545061, disc_loss = 0.14716042472787624
Trained batch 106 in epoch 1, gen_loss = 0.7367223205967485, disc_loss = 0.14598080937132657
Trained batch 107 in epoch 1, gen_loss = 0.7391819672452079, disc_loss = 0.14485747025658688
Trained batch 108 in epoch 1, gen_loss = 0.7407386516212323, disc_loss = 0.14418109038144078
Trained batch 109 in epoch 1, gen_loss = 0.7437854718078266, disc_loss = 0.14315140608020804
Trained batch 110 in epoch 1, gen_loss = 0.7452411399231301, disc_loss = 0.14237318572227484
Trained batch 111 in epoch 1, gen_loss = 0.7481430540127414, disc_loss = 0.14132875648127602
Trained batch 112 in epoch 1, gen_loss = 0.7515723921556389, disc_loss = 0.14040852715549743
Trained batch 113 in epoch 1, gen_loss = 0.7549715444707034, disc_loss = 0.13953641695869073
Trained batch 114 in epoch 1, gen_loss = 0.7580135288445846, disc_loss = 0.1386288281530142
Trained batch 115 in epoch 1, gen_loss = 0.7608250651893944, disc_loss = 0.1376300060896781
Trained batch 116 in epoch 1, gen_loss = 0.7641333733868395, disc_loss = 0.13655555143188208
Trained batch 117 in epoch 1, gen_loss = 0.7667777654478105, disc_loss = 0.13568796308995304
Trained batch 118 in epoch 1, gen_loss = 0.7697412902567567, disc_loss = 0.1348785557353697
Trained batch 119 in epoch 1, gen_loss = 0.7733116880059242, disc_loss = 0.1339534523120771
Trained batch 120 in epoch 1, gen_loss = 0.7762924191380335, disc_loss = 0.13293541195871664
Trained batch 121 in epoch 1, gen_loss = 0.7788361159504437, disc_loss = 0.13197339988756376
Trained batch 122 in epoch 1, gen_loss = 0.7819131714541737, disc_loss = 0.13120795671290497
Trained batch 123 in epoch 1, gen_loss = 0.7843183870277097, disc_loss = 0.13034400249260567
Trained batch 124 in epoch 1, gen_loss = 0.7863058323860168, disc_loss = 0.12947947286069394
Trained batch 125 in epoch 1, gen_loss = 0.7886337169579097, disc_loss = 0.1286181335500072
Trained batch 126 in epoch 1, gen_loss = 0.7916602595584599, disc_loss = 0.12771646550849197
Trained batch 127 in epoch 1, gen_loss = 0.7952867806889117, disc_loss = 0.12683374974585604
Trained batch 128 in epoch 1, gen_loss = 0.7983493273572404, disc_loss = 0.12593227574356305
Trained batch 129 in epoch 1, gen_loss = 0.8011242889440977, disc_loss = 0.1250350633994318
Trained batch 130 in epoch 1, gen_loss = 0.8036156651627926, disc_loss = 0.12414526569706794
Trained batch 131 in epoch 1, gen_loss = 0.8059803884137761, disc_loss = 0.1232705128125169
Trained batch 132 in epoch 1, gen_loss = 0.8080605963118991, disc_loss = 0.12242347023036695
Trained batch 133 in epoch 1, gen_loss = 0.8093955450093568, disc_loss = 0.12158941627660794
Trained batch 134 in epoch 1, gen_loss = 0.8117251488897536, disc_loss = 0.1207836614438781
Trained batch 135 in epoch 1, gen_loss = 0.813862206743044, disc_loss = 0.11996710491503644
Trained batch 136 in epoch 1, gen_loss = 0.8157370495100091, disc_loss = 0.11915435632486848
Trained batch 137 in epoch 1, gen_loss = 0.8176542853099712, disc_loss = 0.11835699423850662
Trained batch 138 in epoch 1, gen_loss = 0.8194199907693932, disc_loss = 0.1175774353884643
Trained batch 139 in epoch 1, gen_loss = 0.820738461613655, disc_loss = 0.11680510822417481
Trained batch 140 in epoch 1, gen_loss = 0.822658637313978, disc_loss = 0.11603433432731222
Trained batch 141 in epoch 1, gen_loss = 0.8250935770256419, disc_loss = 0.11530848126202611
Trained batch 142 in epoch 1, gen_loss = 0.8270570460733, disc_loss = 0.11456302317002645
Trained batch 143 in epoch 1, gen_loss = 0.8285563426713148, disc_loss = 0.11381680328243722
Trained batch 144 in epoch 1, gen_loss = 0.8305448190919285, disc_loss = 0.11308536622673274
Trained batch 145 in epoch 1, gen_loss = 0.8327819472306395, disc_loss = 0.11236854581391975
Trained batch 146 in epoch 1, gen_loss = 0.8345335523287455, disc_loss = 0.11164646021717665
Trained batch 147 in epoch 1, gen_loss = 0.8369104672928114, disc_loss = 0.11096368269441095
Trained batch 148 in epoch 1, gen_loss = 0.8390305686317034, disc_loss = 0.11027207751227106
Trained batch 149 in epoch 1, gen_loss = 0.8403903790314993, disc_loss = 0.10961286942784985
Trained batch 150 in epoch 1, gen_loss = 0.8419956359642231, disc_loss = 0.10896225425951331
Trained batch 151 in epoch 1, gen_loss = 0.8438002369121501, disc_loss = 0.1083044707223675
Trained batch 152 in epoch 1, gen_loss = 0.8449322152761073, disc_loss = 0.10763813165363435
Trained batch 153 in epoch 1, gen_loss = 0.8468109976935696, disc_loss = 0.10699377454176255
Trained batch 154 in epoch 1, gen_loss = 0.847684258414853, disc_loss = 0.10634137474961819
Trained batch 155 in epoch 1, gen_loss = 0.8488477418820063, disc_loss = 0.10569475112387385
Trained batch 156 in epoch 1, gen_loss = 0.8503432695273381, disc_loss = 0.10506479051201396
Trained batch 157 in epoch 1, gen_loss = 0.851963401972493, disc_loss = 0.10445807298315288
Trained batch 158 in epoch 1, gen_loss = 0.8530780500585928, disc_loss = 0.10386353105002041
Trained batch 159 in epoch 1, gen_loss = 0.8547002714127302, disc_loss = 0.10329289094079286
Trained batch 160 in epoch 1, gen_loss = 0.8559705822364144, disc_loss = 0.10273939927588709
Trained batch 161 in epoch 1, gen_loss = 0.8573967935862364, disc_loss = 0.1021822141368448
Trained batch 162 in epoch 1, gen_loss = 0.8596536963263903, disc_loss = 0.10168646066878105
Trained batch 163 in epoch 1, gen_loss = 0.8611234524628011, disc_loss = 0.10113230245415031
Trained batch 164 in epoch 1, gen_loss = 0.8625329252445336, disc_loss = 0.10056484459588926
Trained batch 165 in epoch 1, gen_loss = 0.8634168401540044, disc_loss = 0.10003323004165866
Trained batch 166 in epoch 1, gen_loss = 0.8643616098843648, disc_loss = 0.09953928853156502
Trained batch 167 in epoch 1, gen_loss = 0.8660075277799651, disc_loss = 0.09902341768056863
Trained batch 168 in epoch 1, gen_loss = 0.8678174925273692, disc_loss = 0.09849838937836639
Trained batch 169 in epoch 1, gen_loss = 0.8689079947331373, disc_loss = 0.09797472849707393
Trained batch 170 in epoch 1, gen_loss = 0.8702125002069083, disc_loss = 0.09746355190328514
Trained batch 171 in epoch 1, gen_loss = 0.8714832999678546, disc_loss = 0.09694182632902507
Trained batch 172 in epoch 1, gen_loss = 0.8725478645694049, disc_loss = 0.0964650946340895
Trained batch 173 in epoch 1, gen_loss = 0.873223020084973, disc_loss = 0.0959620983500419
Trained batch 174 in epoch 1, gen_loss = 0.874442309311458, disc_loss = 0.09548921298235655
Trained batch 175 in epoch 1, gen_loss = 0.8759486312893304, disc_loss = 0.09502639223038303
Trained batch 176 in epoch 1, gen_loss = 0.8772045451368989, disc_loss = 0.09455169154341611
Trained batch 177 in epoch 1, gen_loss = 0.8784518740820081, disc_loss = 0.09406436895009841
Trained batch 178 in epoch 1, gen_loss = 0.8793981844486471, disc_loss = 0.09358352047063452
Trained batch 179 in epoch 1, gen_loss = 0.8803734087281757, disc_loss = 0.09310300734101071
Trained batch 180 in epoch 1, gen_loss = 0.8815814674888527, disc_loss = 0.09262366627872978
Trained batch 181 in epoch 1, gen_loss = 0.8827196015761449, disc_loss = 0.09214842033439449
Trained batch 182 in epoch 1, gen_loss = 0.883761504634482, disc_loss = 0.09170848474700431
Trained batch 183 in epoch 1, gen_loss = 0.8855551614061646, disc_loss = 0.09125533244451103
Trained batch 184 in epoch 1, gen_loss = 0.8870882488585807, disc_loss = 0.0908169010402383
Trained batch 185 in epoch 1, gen_loss = 0.8873703748949112, disc_loss = 0.09038030359673724
Trained batch 186 in epoch 1, gen_loss = 0.8882870329892572, disc_loss = 0.08992889254568096
Trained batch 187 in epoch 1, gen_loss = 0.8898046460557492, disc_loss = 0.08951185974094303
Trained batch 188 in epoch 1, gen_loss = 0.8916010982775814, disc_loss = 0.08915612488374035
Trained batch 189 in epoch 1, gen_loss = 0.8916335190597333, disc_loss = 0.08879393384742894
Trained batch 190 in epoch 1, gen_loss = 0.8921445043299211, disc_loss = 0.0884021621743578
Trained batch 191 in epoch 1, gen_loss = 0.8928000880405307, disc_loss = 0.08803967713417175
Trained batch 192 in epoch 1, gen_loss = 0.8935145111899302, disc_loss = 0.08766115048099213
Trained batch 193 in epoch 1, gen_loss = 0.8950414586927473, disc_loss = 0.08728680546040234
Trained batch 194 in epoch 1, gen_loss = 0.8961566108923692, disc_loss = 0.08688674473132078
Trained batch 195 in epoch 1, gen_loss = 0.8967385063974225, disc_loss = 0.08649207116104662
Trained batch 196 in epoch 1, gen_loss = 0.8969478876457602, disc_loss = 0.08617330437554473
Trained batch 197 in epoch 1, gen_loss = 0.8973834123274292, disc_loss = 0.08577672482910331
Trained batch 198 in epoch 1, gen_loss = 0.8999724112563396, disc_loss = 0.08551896416380926
Trained batch 199 in epoch 1, gen_loss = 0.901931414604187, disc_loss = 0.08534218442160636
Trained batch 200 in epoch 1, gen_loss = 0.9027459407920269, disc_loss = 0.08505213116550475
Trained batch 201 in epoch 1, gen_loss = 0.9014489461879919, disc_loss = 0.085206890649319
Trained batch 202 in epoch 1, gen_loss = 0.9024879533081807, disc_loss = 0.08502281123652981
Trained batch 203 in epoch 1, gen_loss = 0.9033186178581387, disc_loss = 0.08480679320956708
Trained batch 204 in epoch 1, gen_loss = 0.9031275452637091, disc_loss = 0.08446827171506678
Trained batch 205 in epoch 1, gen_loss = 0.9024900487325724, disc_loss = 0.08433707662885195
Trained batch 206 in epoch 1, gen_loss = 0.9018402681258566, disc_loss = 0.08408566984091548
Trained batch 207 in epoch 1, gen_loss = 0.9011780636814924, disc_loss = 0.08394788404872927
Trained batch 208 in epoch 1, gen_loss = 0.9041744288074913, disc_loss = 0.08408846437449803
Trained batch 209 in epoch 1, gen_loss = 0.9051562133289519, disc_loss = 0.08376033238268324
Trained batch 210 in epoch 1, gen_loss = 0.9046436661227619, disc_loss = 0.08359115847532077
Trained batch 211 in epoch 1, gen_loss = 0.9048646151457193, disc_loss = 0.08325564669322152
Trained batch 212 in epoch 1, gen_loss = 0.9051091528274644, disc_loss = 0.08290138418300891
Trained batch 213 in epoch 1, gen_loss = 0.9057778713302077, disc_loss = 0.08267932692455633
Trained batch 214 in epoch 1, gen_loss = 0.9055028014404829, disc_loss = 0.08244896816133067
Trained batch 215 in epoch 1, gen_loss = 0.9058443790784588, disc_loss = 0.08212736518449944
Trained batch 216 in epoch 1, gen_loss = 0.9060941149012833, disc_loss = 0.08178433282343749
Trained batch 217 in epoch 1, gen_loss = 0.90965665316363, disc_loss = 0.08217587322851114
Trained batch 218 in epoch 1, gen_loss = 0.911433312990894, disc_loss = 0.08192974472733121
Trained batch 219 in epoch 1, gen_loss = 0.9122751420194453, disc_loss = 0.08173706041310322
Trained batch 220 in epoch 1, gen_loss = 0.9126117507257073, disc_loss = 0.08144073821267121
Trained batch 221 in epoch 1, gen_loss = 0.9127567480276296, disc_loss = 0.08110818819579173
Trained batch 222 in epoch 1, gen_loss = 0.9128162556165003, disc_loss = 0.0807805779064283
Trained batch 223 in epoch 1, gen_loss = 0.9122298721756253, disc_loss = 0.08069942263578664
Trained batch 224 in epoch 1, gen_loss = 0.9130512136883205, disc_loss = 0.08041248513385653
Trained batch 225 in epoch 1, gen_loss = 0.9129024646450988, disc_loss = 0.0801957135554403
Trained batch 226 in epoch 1, gen_loss = 0.9125760517981609, disc_loss = 0.07991151220989845
Trained batch 227 in epoch 1, gen_loss = 0.9132442142356906, disc_loss = 0.07961036307990485
Trained batch 228 in epoch 1, gen_loss = 0.9137171629214391, disc_loss = 0.07930432534756293
Trained batch 229 in epoch 1, gen_loss = 0.9134695918663688, disc_loss = 0.07902259757215886
Trained batch 230 in epoch 1, gen_loss = 0.9134154531346771, disc_loss = 0.07876088825211704
Trained batch 231 in epoch 1, gen_loss = 0.9134993352766695, disc_loss = 0.07847997936187312
Trained batch 232 in epoch 1, gen_loss = 0.9144706500957964, disc_loss = 0.07836921770293505
Trained batch 233 in epoch 1, gen_loss = 0.9151268193864415, disc_loss = 0.0780733516977097
Trained batch 234 in epoch 1, gen_loss = 0.9151324348246798, disc_loss = 0.07782306078861051
Trained batch 235 in epoch 1, gen_loss = 0.9151000544681387, disc_loss = 0.07752336629753206
Trained batch 236 in epoch 1, gen_loss = 0.9149721875975404, disc_loss = 0.07723706408368447
Trained batch 237 in epoch 1, gen_loss = 0.915054923846942, disc_loss = 0.0769320452084937
Trained batch 238 in epoch 1, gen_loss = 0.9152198975056285, disc_loss = 0.07664947129131361
Trained batch 239 in epoch 1, gen_loss = 0.9151023114720981, disc_loss = 0.07635897297683793
Trained batch 240 in epoch 1, gen_loss = 0.9153683180630949, disc_loss = 0.07606784931356976
Trained batch 241 in epoch 1, gen_loss = 0.9152615319106204, disc_loss = 0.07578328922237
Trained batch 242 in epoch 1, gen_loss = 0.9141091714180055, disc_loss = 0.07617224488453364
Trained batch 243 in epoch 1, gen_loss = 0.9162734045845563, disc_loss = 0.07663199884939145
Trained batch 244 in epoch 1, gen_loss = 0.9171177302088056, disc_loss = 0.07666950006113978
Trained batch 245 in epoch 1, gen_loss = 0.9167935533252188, disc_loss = 0.07646249267234792
Trained batch 246 in epoch 1, gen_loss = 0.9166295900035967, disc_loss = 0.07628297515454804
Trained batch 247 in epoch 1, gen_loss = 0.9164679187440103, disc_loss = 0.0760628194247763
Trained batch 248 in epoch 1, gen_loss = 0.9165954482124512, disc_loss = 0.07582238302322995
Trained batch 249 in epoch 1, gen_loss = 0.9152069475650787, disc_loss = 0.07610730598121881
Trained batch 250 in epoch 1, gen_loss = 0.9157233620544829, disc_loss = 0.07615177399400934
Trained batch 251 in epoch 1, gen_loss = 0.9176741079205558, disc_loss = 0.07662457524104015
Trained batch 252 in epoch 1, gen_loss = 0.9174334416276382, disc_loss = 0.07636862002283688
Trained batch 253 in epoch 1, gen_loss = 0.9164364696956995, disc_loss = 0.07641229771194964
Trained batch 254 in epoch 1, gen_loss = 0.9163550250670489, disc_loss = 0.07616847429935839
Trained batch 255 in epoch 1, gen_loss = 0.9161628978326917, disc_loss = 0.07599667800968746
Trained batch 256 in epoch 1, gen_loss = 0.9159384395361875, disc_loss = 0.07583448187183545
Trained batch 257 in epoch 1, gen_loss = 0.9163654090822205, disc_loss = 0.07559070510197749
Trained batch 258 in epoch 1, gen_loss = 0.9167160564407879, disc_loss = 0.0753545815549417
Trained batch 259 in epoch 1, gen_loss = 0.9166663344089802, disc_loss = 0.07509642407799569
Trained batch 260 in epoch 1, gen_loss = 0.9163158330424078, disc_loss = 0.07496154970236094
Trained batch 261 in epoch 1, gen_loss = 0.9167782448175299, disc_loss = 0.07475297591997353
Trained batch 262 in epoch 1, gen_loss = 0.9158015729356628, disc_loss = 0.07485945722151958
Trained batch 263 in epoch 1, gen_loss = 0.916439065201716, disc_loss = 0.07500288577284664
Trained batch 264 in epoch 1, gen_loss = 0.9164495137502562, disc_loss = 0.07486618943863882
Trained batch 265 in epoch 1, gen_loss = 0.9163101505964322, disc_loss = 0.07464389046794154
Trained batch 266 in epoch 1, gen_loss = 0.9148808896318357, disc_loss = 0.0754024273984497
Trained batch 267 in epoch 1, gen_loss = 0.9155735724897527, disc_loss = 0.07582817252016445
Trained batch 268 in epoch 1, gen_loss = 0.915595332264457, disc_loss = 0.07588029525772458
Trained batch 269 in epoch 1, gen_loss = 0.9142407732981223, disc_loss = 0.07629500387788371
Trained batch 270 in epoch 1, gen_loss = 0.9130737363632315, disc_loss = 0.07669715294992462
Trained batch 271 in epoch 1, gen_loss = 0.9126219133682111, disc_loss = 0.07678306637235972
Trained batch 272 in epoch 1, gen_loss = 0.9120216900175744, disc_loss = 0.07716477820956773
Trained batch 273 in epoch 1, gen_loss = 0.9105037314830905, disc_loss = 0.07751394686268738
Trained batch 274 in epoch 1, gen_loss = 0.9097920559753071, disc_loss = 0.07749844386157664
Trained batch 275 in epoch 1, gen_loss = 0.9102063173617142, disc_loss = 0.07756908068203948
Trained batch 276 in epoch 1, gen_loss = 0.9110670402807449, disc_loss = 0.07739342690280736
Trained batch 277 in epoch 1, gen_loss = 0.9111181352850345, disc_loss = 0.07717174472850111
Trained batch 278 in epoch 1, gen_loss = 0.9104638130647734, disc_loss = 0.07703622490982108
Trained batch 279 in epoch 1, gen_loss = 0.9091239683330059, disc_loss = 0.07744508049384291
Trained batch 280 in epoch 1, gen_loss = 0.9095942270925461, disc_loss = 0.07805727670479605
Trained batch 281 in epoch 1, gen_loss = 0.9095224920950883, disc_loss = 0.07803090742676921
Trained batch 282 in epoch 1, gen_loss = 0.9080724252828861, disc_loss = 0.07852636400425919
Trained batch 283 in epoch 1, gen_loss = 0.9077393905797475, disc_loss = 0.0789040675629455
Trained batch 284 in epoch 1, gen_loss = 0.9071334807496322, disc_loss = 0.07934384661350857
Trained batch 285 in epoch 1, gen_loss = 0.905879769291911, disc_loss = 0.07957351381297816
Trained batch 286 in epoch 1, gen_loss = 0.9048581846084329, disc_loss = 0.07980060075386995
Trained batch 287 in epoch 1, gen_loss = 0.9040647209104564, disc_loss = 0.08002644551258224
Trained batch 288 in epoch 1, gen_loss = 0.9038972543185145, disc_loss = 0.0801151127660821
Trained batch 289 in epoch 1, gen_loss = 0.9024876598654122, disc_loss = 0.08067913563151298
Trained batch 290 in epoch 1, gen_loss = 0.901687527030604, disc_loss = 0.0810437873165888
Trained batch 291 in epoch 1, gen_loss = 0.9004474641525582, disc_loss = 0.08136126321536323
Trained batch 292 in epoch 1, gen_loss = 0.8999213621071174, disc_loss = 0.08166122415226983
Trained batch 293 in epoch 1, gen_loss = 0.898838229122616, disc_loss = 0.08196494225602673
Trained batch 294 in epoch 1, gen_loss = 0.8979152740058253, disc_loss = 0.08225319374478975
Trained batch 295 in epoch 1, gen_loss = 0.896977853533384, disc_loss = 0.08245136950328644
Trained batch 296 in epoch 1, gen_loss = 0.8958395615169897, disc_loss = 0.0826524975631223
Trained batch 297 in epoch 1, gen_loss = 0.895887593894997, disc_loss = 0.08291706466897322
Trained batch 298 in epoch 1, gen_loss = 0.8949778133810165, disc_loss = 0.08297043519536887
Trained batch 299 in epoch 1, gen_loss = 0.8937745622793833, disc_loss = 0.08326259140235683
Trained batch 300 in epoch 1, gen_loss = 0.892920753488509, disc_loss = 0.08348336498070495
Trained batch 301 in epoch 1, gen_loss = 0.8922321616813836, disc_loss = 0.08374278591822414
Trained batch 302 in epoch 1, gen_loss = 0.8915808930648829, disc_loss = 0.08366137213402554
Trained batch 303 in epoch 1, gen_loss = 0.8910316195535032, disc_loss = 0.08359081885397532
Trained batch 304 in epoch 1, gen_loss = 0.8899170627359484, disc_loss = 0.08374629107716142
Trained batch 305 in epoch 1, gen_loss = 0.8903744748604843, disc_loss = 0.08364700247515358
Trained batch 306 in epoch 1, gen_loss = 0.8893895370564165, disc_loss = 0.08380559493608603
Trained batch 307 in epoch 1, gen_loss = 0.8887704130891082, disc_loss = 0.08400089084775514
Trained batch 308 in epoch 1, gen_loss = 0.8886513004025209, disc_loss = 0.08398590472294772
Trained batch 309 in epoch 1, gen_loss = 0.8891152028114565, disc_loss = 0.08386027183563959
Trained batch 310 in epoch 1, gen_loss = 0.8888418444483227, disc_loss = 0.08375420228808735
Trained batch 311 in epoch 1, gen_loss = 0.888207448216585, disc_loss = 0.083606699305491
Trained batch 312 in epoch 1, gen_loss = 0.8874993990785398, disc_loss = 0.08349374077392939
Trained batch 313 in epoch 1, gen_loss = 0.8882058209674374, disc_loss = 0.08354186274075678
Trained batch 314 in epoch 1, gen_loss = 0.8874922937817044, disc_loss = 0.08374961300324353
Trained batch 315 in epoch 1, gen_loss = 0.8872841040167627, disc_loss = 0.08391256595348727
Trained batch 316 in epoch 1, gen_loss = 0.8887690597152108, disc_loss = 0.0839431425732816
Trained batch 317 in epoch 1, gen_loss = 0.8892441367578207, disc_loss = 0.08372669515006666
Trained batch 318 in epoch 1, gen_loss = 0.8890553266277134, disc_loss = 0.08360184070750556
Trained batch 319 in epoch 1, gen_loss = 0.889335953257978, disc_loss = 0.08336958288273308
Trained batch 320 in epoch 1, gen_loss = 0.8897871207968097, disc_loss = 0.0831346901632683
Trained batch 321 in epoch 1, gen_loss = 0.8900995245261222, disc_loss = 0.08290029835152607
Trained batch 322 in epoch 1, gen_loss = 0.8900413245608563, disc_loss = 0.08266549364839545
Trained batch 323 in epoch 1, gen_loss = 0.8901401425217405, disc_loss = 0.08244473033262716
Trained batch 324 in epoch 1, gen_loss = 0.890267757819249, disc_loss = 0.0823303028740562
Trained batch 325 in epoch 1, gen_loss = 0.8894432419282527, disc_loss = 0.08258999317621618
Trained batch 326 in epoch 1, gen_loss = 0.8894259047435329, disc_loss = 0.08276956193775668
Trained batch 327 in epoch 1, gen_loss = 0.8883287601354646, disc_loss = 0.08305771508333613
Trained batch 328 in epoch 1, gen_loss = 0.8874832792122676, disc_loss = 0.08308654272006004
Trained batch 329 in epoch 1, gen_loss = 0.8878293006709128, disc_loss = 0.08334059065320727
Trained batch 330 in epoch 1, gen_loss = 0.8884940354485527, disc_loss = 0.08322959661404981
Trained batch 331 in epoch 1, gen_loss = 0.8877958129328417, disc_loss = 0.08319127126821284
Trained batch 332 in epoch 1, gen_loss = 0.8868705417300846, disc_loss = 0.08362211638574933
Trained batch 333 in epoch 1, gen_loss = 0.8875870997320392, disc_loss = 0.08399108157376062
Trained batch 334 in epoch 1, gen_loss = 0.8868322952469783, disc_loss = 0.08428842472329513
Trained batch 335 in epoch 1, gen_loss = 0.8861969581672123, disc_loss = 0.08433153336435291
Trained batch 336 in epoch 1, gen_loss = 0.8869447559560442, disc_loss = 0.08465477035212322
Trained batch 337 in epoch 1, gen_loss = 0.8865342926696913, disc_loss = 0.084491743047628
Trained batch 338 in epoch 1, gen_loss = 0.8860912778384566, disc_loss = 0.08435392643223381
Trained batch 339 in epoch 1, gen_loss = 0.8858739986139186, disc_loss = 0.08421982202185865
Trained batch 340 in epoch 1, gen_loss = 0.885899328765981, disc_loss = 0.084025013380714
Trained batch 341 in epoch 1, gen_loss = 0.8862930477014062, disc_loss = 0.08381432414664859
Trained batch 342 in epoch 1, gen_loss = 0.8860258281057152, disc_loss = 0.08364942380968406
Trained batch 343 in epoch 1, gen_loss = 0.8864525050617927, disc_loss = 0.08343991703018112
Trained batch 344 in epoch 1, gen_loss = 0.8867912561997123, disc_loss = 0.08325134189934402
Trained batch 345 in epoch 1, gen_loss = 0.8866481574284548, disc_loss = 0.08317240690704801
Trained batch 346 in epoch 1, gen_loss = 0.887413053759924, disc_loss = 0.08300520839593682
Trained batch 347 in epoch 1, gen_loss = 0.8883093287204874, disc_loss = 0.0828592915371617
Trained batch 348 in epoch 1, gen_loss = 0.8876505635870904, disc_loss = 0.0829464272972207
Trained batch 349 in epoch 1, gen_loss = 0.8874437648909432, disc_loss = 0.08289138281185712
Trained batch 350 in epoch 1, gen_loss = 0.8883455071354184, disc_loss = 0.08299592973935044
Trained batch 351 in epoch 1, gen_loss = 0.888652828098698, disc_loss = 0.08280888542966833
Trained batch 352 in epoch 1, gen_loss = 0.8876383414349542, disc_loss = 0.08297246606181516
Trained batch 353 in epoch 1, gen_loss = 0.887782534131896, disc_loss = 0.0828639870840993
Trained batch 354 in epoch 1, gen_loss = 0.8871413279587115, disc_loss = 0.08285274306495845
Trained batch 355 in epoch 1, gen_loss = 0.8865983082672183, disc_loss = 0.08283045909137288
Trained batch 356 in epoch 1, gen_loss = 0.886241048324008, disc_loss = 0.08273121614676981
Trained batch 357 in epoch 1, gen_loss = 0.8861748769296615, disc_loss = 0.08263373545854867
Trained batch 358 in epoch 1, gen_loss = 0.8862638320763463, disc_loss = 0.08281468332571322
Trained batch 359 in epoch 1, gen_loss = 0.8855910327699449, disc_loss = 0.082822572442496
Trained batch 360 in epoch 1, gen_loss = 0.8859674362594732, disc_loss = 0.08273887427116117
Trained batch 361 in epoch 1, gen_loss = 0.886184104239743, disc_loss = 0.08253957539827701
Trained batch 362 in epoch 1, gen_loss = 0.8861466166730098, disc_loss = 0.08236194439694162
Trained batch 363 in epoch 1, gen_loss = 0.8856112275804792, disc_loss = 0.08221027510660281
Trained batch 364 in epoch 1, gen_loss = 0.8850079061233834, disc_loss = 0.08214767807711885
Trained batch 365 in epoch 1, gen_loss = 0.8850408465158744, disc_loss = 0.08230035702947303
Trained batch 366 in epoch 1, gen_loss = 0.885082876162568, disc_loss = 0.08213876483946714
Trained batch 367 in epoch 1, gen_loss = 0.8839113723648631, disc_loss = 0.08259819342461212
Trained batch 368 in epoch 1, gen_loss = 0.8836448462351874, disc_loss = 0.08251310482893776
Trained batch 369 in epoch 1, gen_loss = 0.8843315071350819, disc_loss = 0.08320716874976013
Trained batch 370 in epoch 1, gen_loss = 0.884647076823962, disc_loss = 0.08302550733019158
Trained batch 371 in epoch 1, gen_loss = 0.883992343980779, disc_loss = 0.08305575414460593
Trained batch 372 in epoch 1, gen_loss = 0.884363326725947, disc_loss = 0.08294197016373157
Trained batch 373 in epoch 1, gen_loss = 0.8830575259292827, disc_loss = 0.08316566390956548
Trained batch 374 in epoch 1, gen_loss = 0.8828515337308248, disc_loss = 0.08321977035452922
Trained batch 375 in epoch 1, gen_loss = 0.8820887215911074, disc_loss = 0.08349131170828689
Trained batch 376 in epoch 1, gen_loss = 0.8814150804866214, disc_loss = 0.0840418311527656
Trained batch 377 in epoch 1, gen_loss = 0.8807389166935411, disc_loss = 0.08408268921757264
Trained batch 378 in epoch 1, gen_loss = 0.8797819889629737, disc_loss = 0.08425647081527121
Trained batch 379 in epoch 1, gen_loss = 0.8792472295070949, disc_loss = 0.08437663267954792
Trained batch 380 in epoch 1, gen_loss = 0.878993182670413, disc_loss = 0.08451837796248554
Trained batch 381 in epoch 1, gen_loss = 0.8782914259046785, disc_loss = 0.08469492745346814
Trained batch 382 in epoch 1, gen_loss = 0.8774466830507582, disc_loss = 0.08484005689008195
Trained batch 383 in epoch 1, gen_loss = 0.8769905084433655, disc_loss = 0.08501481856850053
Trained batch 384 in epoch 1, gen_loss = 0.8762902540045899, disc_loss = 0.08521956865518511
Trained batch 385 in epoch 1, gen_loss = 0.8763974366101577, disc_loss = 0.08528569145996721
Trained batch 386 in epoch 1, gen_loss = 0.8759117057157118, disc_loss = 0.08523253580791158
Trained batch 387 in epoch 1, gen_loss = 0.8752841414864531, disc_loss = 0.08529884547004764
Trained batch 388 in epoch 1, gen_loss = 0.8746597175426533, disc_loss = 0.08541321051773881
Trained batch 389 in epoch 1, gen_loss = 0.874282852655802, disc_loss = 0.08562755816114637
Trained batch 390 in epoch 1, gen_loss = 0.8741875982955288, disc_loss = 0.08581203220607451
Trained batch 391 in epoch 1, gen_loss = 0.873758931549228, disc_loss = 0.08574469737489993
Trained batch 392 in epoch 1, gen_loss = 0.8731995919581891, disc_loss = 0.0858628048416957
Trained batch 393 in epoch 1, gen_loss = 0.8732292499336495, disc_loss = 0.08617793035168711
Trained batch 394 in epoch 1, gen_loss = 0.8733733889422839, disc_loss = 0.08608410451089657
Trained batch 395 in epoch 1, gen_loss = 0.8722908281617694, disc_loss = 0.08646528868973631
Trained batch 396 in epoch 1, gen_loss = 0.8716527963765622, disc_loss = 0.0868226274195824
Trained batch 397 in epoch 1, gen_loss = 0.8718745060002984, disc_loss = 0.08702357684556938
Trained batch 398 in epoch 1, gen_loss = 0.8718247025234059, disc_loss = 0.0869678288609499
Trained batch 399 in epoch 1, gen_loss = 0.8713136917352676, disc_loss = 0.08697525413939729
Trained batch 400 in epoch 1, gen_loss = 0.8705813654343089, disc_loss = 0.08728560889162996
Trained batch 401 in epoch 1, gen_loss = 0.8706856614618159, disc_loss = 0.0873338226900802
Trained batch 402 in epoch 1, gen_loss = 0.8705140327105747, disc_loss = 0.08724246083737973
Trained batch 403 in epoch 1, gen_loss = 0.8705953309441558, disc_loss = 0.0871047299322995
Trained batch 404 in epoch 1, gen_loss = 0.8707442857601024, disc_loss = 0.08691448436383112
Trained batch 405 in epoch 1, gen_loss = 0.8713132204680607, disc_loss = 0.08674572293963191
Trained batch 406 in epoch 1, gen_loss = 0.87112031477968, disc_loss = 0.08659650742806294
Trained batch 407 in epoch 1, gen_loss = 0.8710644427759975, disc_loss = 0.08646025126982554
Trained batch 408 in epoch 1, gen_loss = 0.8702271895478582, disc_loss = 0.08668846043150116
Trained batch 409 in epoch 1, gen_loss = 0.8705271651105183, disc_loss = 0.08693805135241368
Trained batch 410 in epoch 1, gen_loss = 0.8709676207707167, disc_loss = 0.08690399716442809
Trained batch 411 in epoch 1, gen_loss = 0.8701931682315845, disc_loss = 0.08719005527933246
Trained batch 412 in epoch 1, gen_loss = 0.8695818135293863, disc_loss = 0.0872451596629533
Trained batch 413 in epoch 1, gen_loss = 0.8697578847984185, disc_loss = 0.08758407338085958
Trained batch 414 in epoch 1, gen_loss = 0.8689153997294874, disc_loss = 0.08789622546678566
Trained batch 415 in epoch 1, gen_loss = 0.8683185340979924, disc_loss = 0.08811417562313952
Trained batch 416 in epoch 1, gen_loss = 0.8682125771074272, disc_loss = 0.08817942051007022
Trained batch 417 in epoch 1, gen_loss = 0.8678914868945711, disc_loss = 0.08831788225179654
Trained batch 418 in epoch 1, gen_loss = 0.8675463869634278, disc_loss = 0.08834082800405976
Trained batch 419 in epoch 1, gen_loss = 0.8671003763164793, disc_loss = 0.08828895689830893
Trained batch 420 in epoch 1, gen_loss = 0.8665143276903239, disc_loss = 0.0884143406627014
Trained batch 421 in epoch 1, gen_loss = 0.8668585834909954, disc_loss = 0.0887120044591585
Trained batch 422 in epoch 1, gen_loss = 0.8669006266492478, disc_loss = 0.08853265722161137
Trained batch 423 in epoch 1, gen_loss = 0.8668152175421985, disc_loss = 0.08840822586394355
Trained batch 424 in epoch 1, gen_loss = 0.8667688488960266, disc_loss = 0.08834550159599851
Trained batch 425 in epoch 1, gen_loss = 0.8665358049209129, disc_loss = 0.08839917917268027
Trained batch 426 in epoch 1, gen_loss = 0.8664521117121051, disc_loss = 0.08858952383168338
Trained batch 427 in epoch 1, gen_loss = 0.8660854450731634, disc_loss = 0.08853880120832995
Trained batch 428 in epoch 1, gen_loss = 0.8663326318447406, disc_loss = 0.08842471919927772
Trained batch 429 in epoch 1, gen_loss = 0.8658094619595728, disc_loss = 0.08859019730629962
Trained batch 430 in epoch 1, gen_loss = 0.8658266862694459, disc_loss = 0.08853006399865425
Trained batch 431 in epoch 1, gen_loss = 0.8658889130585723, disc_loss = 0.08836739605801457
Trained batch 432 in epoch 1, gen_loss = 0.8657798713404367, disc_loss = 0.08824382549233512
Trained batch 433 in epoch 1, gen_loss = 0.8655101350650259, disc_loss = 0.08814527334490885
Trained batch 434 in epoch 1, gen_loss = 0.8659665728437489, disc_loss = 0.08821948876112014
Trained batch 435 in epoch 1, gen_loss = 0.8661474439255689, disc_loss = 0.08810405767898699
Trained batch 436 in epoch 1, gen_loss = 0.8664151810672245, disc_loss = 0.08795262442462709
Trained batch 437 in epoch 1, gen_loss = 0.8663348412677033, disc_loss = 0.08783003067614757
Trained batch 438 in epoch 1, gen_loss = 0.8657484935736602, disc_loss = 0.08792290633548569
Trained batch 439 in epoch 1, gen_loss = 0.8653317222541029, disc_loss = 0.08812959748531946
Trained batch 440 in epoch 1, gen_loss = 0.8657833750015483, disc_loss = 0.08840267994396743
Trained batch 441 in epoch 1, gen_loss = 0.865921579065366, disc_loss = 0.08826192142863282
Trained batch 442 in epoch 1, gen_loss = 0.8652399213265619, disc_loss = 0.08833670328343897
Trained batch 443 in epoch 1, gen_loss = 0.8648732598568942, disc_loss = 0.08828556304168259
Trained batch 444 in epoch 1, gen_loss = 0.8648201634374897, disc_loss = 0.08841268883787849
Trained batch 445 in epoch 1, gen_loss = 0.8656023698002768, disc_loss = 0.08837589800082181
Trained batch 446 in epoch 1, gen_loss = 0.8657482817135668, disc_loss = 0.08820063634973511
Trained batch 447 in epoch 1, gen_loss = 0.8648776781213071, disc_loss = 0.0886394891006473
Trained batch 448 in epoch 1, gen_loss = 0.8643327005589194, disc_loss = 0.08872034904320947
Trained batch 449 in epoch 1, gen_loss = 0.8645960889259974, disc_loss = 0.08921402491629124
Trained batch 450 in epoch 1, gen_loss = 0.8642391120383057, disc_loss = 0.08924782428964807
Trained batch 451 in epoch 1, gen_loss = 0.8634294678284004, disc_loss = 0.08947901273624295
Trained batch 452 in epoch 1, gen_loss = 0.8630736497195878, disc_loss = 0.08967011565831849
Trained batch 453 in epoch 1, gen_loss = 0.8627087848695889, disc_loss = 0.08976503482113063
Trained batch 454 in epoch 1, gen_loss = 0.8620159236284403, disc_loss = 0.08994148400622409
Trained batch 455 in epoch 1, gen_loss = 0.8618906415476087, disc_loss = 0.08995593766469442
Trained batch 456 in epoch 1, gen_loss = 0.861403984170513, disc_loss = 0.0899781833282576
Trained batch 457 in epoch 1, gen_loss = 0.8609656641446868, disc_loss = 0.0900167219714957
Trained batch 458 in epoch 1, gen_loss = 0.860360704411089, disc_loss = 0.09011384456018737
Trained batch 459 in epoch 1, gen_loss = 0.8597292565133261, disc_loss = 0.09023554261125948
Trained batch 460 in epoch 1, gen_loss = 0.85925680108029, disc_loss = 0.09046840907727043
Trained batch 461 in epoch 1, gen_loss = 0.8588911667143627, disc_loss = 0.09060929926088104
Trained batch 462 in epoch 1, gen_loss = 0.8585275937491308, disc_loss = 0.09061501887234705
Trained batch 463 in epoch 1, gen_loss = 0.8584725350013067, disc_loss = 0.09054564756084361
Trained batch 464 in epoch 1, gen_loss = 0.8579220517348217, disc_loss = 0.09064376076222748
Trained batch 465 in epoch 1, gen_loss = 0.8576962173368797, disc_loss = 0.0907351290287506
Trained batch 466 in epoch 1, gen_loss = 0.8574060212493708, disc_loss = 0.09072265623245045
Trained batch 467 in epoch 1, gen_loss = 0.8572268461187681, disc_loss = 0.09073630191035505
Trained batch 468 in epoch 1, gen_loss = 0.8568124127413418, disc_loss = 0.09088537181967865
Trained batch 469 in epoch 1, gen_loss = 0.8565648966013117, disc_loss = 0.09095839067818003
Trained batch 470 in epoch 1, gen_loss = 0.8563478565646332, disc_loss = 0.0908916607704765
Trained batch 471 in epoch 1, gen_loss = 0.8561836464046422, disc_loss = 0.09089195484421768
Trained batch 472 in epoch 1, gen_loss = 0.8558661469571435, disc_loss = 0.09088084264707616
Trained batch 473 in epoch 1, gen_loss = 0.8564782022549633, disc_loss = 0.09078180362403644
Trained batch 474 in epoch 1, gen_loss = 0.8560600994135205, disc_loss = 0.09077559036643881
Trained batch 475 in epoch 1, gen_loss = 0.8554943424939108, disc_loss = 0.09085616621212299
Trained batch 476 in epoch 1, gen_loss = 0.8560311132631961, disc_loss = 0.0909278879031945
Trained batch 477 in epoch 1, gen_loss = 0.8559862895864822, disc_loss = 0.09093093532273959
Trained batch 478 in epoch 1, gen_loss = 0.8553672356371591, disc_loss = 0.09133488888655923
Trained batch 479 in epoch 1, gen_loss = 0.8554688602065047, disc_loss = 0.09143056608736515
Trained batch 480 in epoch 1, gen_loss = 0.8549421108066416, disc_loss = 0.09154599697451087
Trained batch 481 in epoch 1, gen_loss = 0.8546555321122601, disc_loss = 0.09160941836126613
Trained batch 482 in epoch 1, gen_loss = 0.8546300491561061, disc_loss = 0.09160121645986663
Trained batch 483 in epoch 1, gen_loss = 0.8545495731648335, disc_loss = 0.09152365443566121
Trained batch 484 in epoch 1, gen_loss = 0.8545246261296813, disc_loss = 0.09140702409228099
Trained batch 485 in epoch 1, gen_loss = 0.8538883744811816, disc_loss = 0.09152946449478958
Trained batch 486 in epoch 1, gen_loss = 0.8537974847782809, disc_loss = 0.09147845023527772
Trained batch 487 in epoch 1, gen_loss = 0.8543805910549203, disc_loss = 0.0914691513190504
Trained batch 488 in epoch 1, gen_loss = 0.8543605953759699, disc_loss = 0.0913639843220116
Trained batch 489 in epoch 1, gen_loss = 0.8543235901058936, disc_loss = 0.09125017271358139
Trained batch 490 in epoch 1, gen_loss = 0.853949159140985, disc_loss = 0.09130511306939446
Trained batch 491 in epoch 1, gen_loss = 0.8547209906505375, disc_loss = 0.09159694805862457
Trained batch 492 in epoch 1, gen_loss = 0.8543982022795183, disc_loss = 0.09156035130152113
Trained batch 493 in epoch 1, gen_loss = 0.8542726114090637, disc_loss = 0.0914747844627391
Trained batch 494 in epoch 1, gen_loss = 0.8538946514779872, disc_loss = 0.09146202606233683
Trained batch 495 in epoch 1, gen_loss = 0.8543620003207076, disc_loss = 0.09157304693343898
Trained batch 496 in epoch 1, gen_loss = 0.8539782176674972, disc_loss = 0.09156959624567503
Trained batch 497 in epoch 1, gen_loss = 0.8538576448897282, disc_loss = 0.09148421610544724
Trained batch 498 in epoch 1, gen_loss = 0.8541157681024624, disc_loss = 0.0914081210393705
Trained batch 499 in epoch 1, gen_loss = 0.8538953152298927, disc_loss = 0.09135557320713997
Trained batch 500 in epoch 1, gen_loss = 0.853708140447944, disc_loss = 0.09132401554467912
Trained batch 501 in epoch 1, gen_loss = 0.8534463873778682, disc_loss = 0.09131764310349032
Trained batch 502 in epoch 1, gen_loss = 0.8535879651902921, disc_loss = 0.09133583139887387
Trained batch 503 in epoch 1, gen_loss = 0.8538832965469549, disc_loss = 0.09119582702849238
Trained batch 504 in epoch 1, gen_loss = 0.8536888237636868, disc_loss = 0.09108681648895882
Trained batch 505 in epoch 1, gen_loss = 0.8536524850978211, disc_loss = 0.09096577515450155
Trained batch 506 in epoch 1, gen_loss = 0.853952435170405, disc_loss = 0.09083154486745772
Trained batch 507 in epoch 1, gen_loss = 0.8543593862981308, disc_loss = 0.09076067454760939
Trained batch 508 in epoch 1, gen_loss = 0.8538442568483896, disc_loss = 0.09072305147914848
Trained batch 509 in epoch 1, gen_loss = 0.8533127344706479, disc_loss = 0.09080064416516061
Trained batch 510 in epoch 1, gen_loss = 0.8528619893259731, disc_loss = 0.09088731304890023
Trained batch 511 in epoch 1, gen_loss = 0.8528099640388973, disc_loss = 0.09101327593089081
Trained batch 512 in epoch 1, gen_loss = 0.852717616927554, disc_loss = 0.09099599074201974
Trained batch 513 in epoch 1, gen_loss = 0.8528646359995645, disc_loss = 0.09087701422318178
Trained batch 514 in epoch 1, gen_loss = 0.8524134619143403, disc_loss = 0.09085729368826718
Trained batch 515 in epoch 1, gen_loss = 0.8521662606864937, disc_loss = 0.09079594967179289
Trained batch 516 in epoch 1, gen_loss = 0.852709410096045, disc_loss = 0.09122886359547508
Trained batch 517 in epoch 1, gen_loss = 0.8529954755743498, disc_loss = 0.09112218643707658
Trained batch 518 in epoch 1, gen_loss = 0.8530109388635337, disc_loss = 0.09114099477699497
Trained batch 519 in epoch 1, gen_loss = 0.8534343449542156, disc_loss = 0.09131079612729641
Trained batch 520 in epoch 1, gen_loss = 0.8533379929193837, disc_loss = 0.09139108367535981
Trained batch 521 in epoch 1, gen_loss = 0.8532658580733442, disc_loss = 0.09139510509611547
Trained batch 522 in epoch 1, gen_loss = 0.8528337883789726, disc_loss = 0.09157789052672413
Trained batch 523 in epoch 1, gen_loss = 0.8531192679327863, disc_loss = 0.09164765172901045
Trained batch 524 in epoch 1, gen_loss = 0.8528965556621552, disc_loss = 0.09158608796341079
Trained batch 525 in epoch 1, gen_loss = 0.8526087493384292, disc_loss = 0.09152982537652377
Trained batch 526 in epoch 1, gen_loss = 0.8523796902548882, disc_loss = 0.09156256250372648
Trained batch 527 in epoch 1, gen_loss = 0.8522711747862173, disc_loss = 0.09163095354046108
Trained batch 528 in epoch 1, gen_loss = 0.8526916625031, disc_loss = 0.09150669087140006
Trained batch 529 in epoch 1, gen_loss = 0.8523839925257665, disc_loss = 0.09147832127955724
Trained batch 530 in epoch 1, gen_loss = 0.8534006144704118, disc_loss = 0.09152895003108207
Trained batch 531 in epoch 1, gen_loss = 0.85373829490036, disc_loss = 0.09138356580546028
Trained batch 532 in epoch 1, gen_loss = 0.8533434943343193, disc_loss = 0.09131716250478662
Trained batch 533 in epoch 1, gen_loss = 0.8530376427963878, disc_loss = 0.09133046534791421
Trained batch 534 in epoch 1, gen_loss = 0.8532521513577933, disc_loss = 0.0914238461127905
Trained batch 535 in epoch 1, gen_loss = 0.8533185422976515, disc_loss = 0.09142545824731464
Trained batch 536 in epoch 1, gen_loss = 0.8526084955289155, disc_loss = 0.09181485670571887
Trained batch 537 in epoch 1, gen_loss = 0.8524883293640215, disc_loss = 0.09173176434846615
Trained batch 538 in epoch 1, gen_loss = 0.8521807697465115, disc_loss = 0.09195836720528541
Trained batch 539 in epoch 1, gen_loss = 0.8519776680403286, disc_loss = 0.09192851000913867
Trained batch 540 in epoch 1, gen_loss = 0.8512441802928276, disc_loss = 0.09211923432658649
Trained batch 541 in epoch 1, gen_loss = 0.851023372523899, disc_loss = 0.09211171727723741
Trained batch 542 in epoch 1, gen_loss = 0.8507241552376615, disc_loss = 0.09210445185776793
Trained batch 543 in epoch 1, gen_loss = 0.8509920167681926, disc_loss = 0.09216345470015179
Trained batch 544 in epoch 1, gen_loss = 0.8507248997141462, disc_loss = 0.09212258430795932
Trained batch 545 in epoch 1, gen_loss = 0.8505324811398328, disc_loss = 0.09206097197783736
Trained batch 546 in epoch 1, gen_loss = 0.8504720944264254, disc_loss = 0.09207123396764944
Trained batch 547 in epoch 1, gen_loss = 0.850517913427231, disc_loss = 0.09198021278274755
Trained batch 548 in epoch 1, gen_loss = 0.8501388996785239, disc_loss = 0.09200736813803623
Trained batch 549 in epoch 1, gen_loss = 0.8500279277563095, disc_loss = 0.09215350431474773
Trained batch 550 in epoch 1, gen_loss = 0.8500597133502337, disc_loss = 0.09211304017127966
Trained batch 551 in epoch 1, gen_loss = 0.8502056796805583, disc_loss = 0.09197775569771403
Trained batch 552 in epoch 1, gen_loss = 0.8505903242617361, disc_loss = 0.09184011834156557
Trained batch 553 in epoch 1, gen_loss = 0.8506228736053736, disc_loss = 0.09171282659059504
Trained batch 554 in epoch 1, gen_loss = 0.8508545396027264, disc_loss = 0.09159375928879321
Trained batch 555 in epoch 1, gen_loss = 0.8506427218052123, disc_loss = 0.09146879920601952
Trained batch 556 in epoch 1, gen_loss = 0.8502652334246644, disc_loss = 0.09144877632026506
Trained batch 557 in epoch 1, gen_loss = 0.8509261750726289, disc_loss = 0.09147826287441463
Trained batch 558 in epoch 1, gen_loss = 0.85047973903006, disc_loss = 0.09150140544929423
Trained batch 559 in epoch 1, gen_loss = 0.8502447151179825, disc_loss = 0.09148161603204374
Trained batch 560 in epoch 1, gen_loss = 0.8501566736137166, disc_loss = 0.09140918550949789
Trained batch 561 in epoch 1, gen_loss = 0.8496329133726949, disc_loss = 0.09151548194596246
Trained batch 562 in epoch 1, gen_loss = 0.8494603916023383, disc_loss = 0.09147828504721077
Trained batch 563 in epoch 1, gen_loss = 0.8496022062204408, disc_loss = 0.09147932349724021
Trained batch 564 in epoch 1, gen_loss = 0.8497303422045919, disc_loss = 0.09143790640596268
Trained batch 565 in epoch 1, gen_loss = 0.8491548193954326, disc_loss = 0.09162384783355486
Trained batch 566 in epoch 1, gen_loss = 0.8491885987434017, disc_loss = 0.09156001569798489
Trained batch 567 in epoch 1, gen_loss = 0.8498261765590016, disc_loss = 0.09155579546505821
Trained batch 568 in epoch 1, gen_loss = 0.8494712595675658, disc_loss = 0.0915378443864035
Trained batch 569 in epoch 1, gen_loss = 0.8490799594866602, disc_loss = 0.09153100281234897
Trained batch 570 in epoch 1, gen_loss = 0.8490426096210546, disc_loss = 0.09150758156334352
Trained batch 571 in epoch 1, gen_loss = 0.8491221952375833, disc_loss = 0.0914222502957222
Trained batch 572 in epoch 1, gen_loss = 0.8487868278334486, disc_loss = 0.0915287424099955
Trained batch 573 in epoch 1, gen_loss = 0.8484352289695773, disc_loss = 0.0915636043275223
Trained batch 574 in epoch 1, gen_loss = 0.8481234839169876, disc_loss = 0.09161017671551393
Trained batch 575 in epoch 1, gen_loss = 0.8479821314103901, disc_loss = 0.09155787694099773
Trained batch 576 in epoch 1, gen_loss = 0.8484211067702989, disc_loss = 0.09145391397694677
Trained batch 577 in epoch 1, gen_loss = 0.8483270656794413, disc_loss = 0.09132354182858266
Trained batch 578 in epoch 1, gen_loss = 0.8481136300506164, disc_loss = 0.09122326406159652
Trained batch 579 in epoch 1, gen_loss = 0.8478952847164253, disc_loss = 0.09114113417614637
Trained batch 580 in epoch 1, gen_loss = 0.8480500922043024, disc_loss = 0.0912441693457956
Trained batch 581 in epoch 1, gen_loss = 0.8474447515719535, disc_loss = 0.09140031719164238
Trained batch 582 in epoch 1, gen_loss = 0.8476184389296773, disc_loss = 0.09137832319386316
Trained batch 583 in epoch 1, gen_loss = 0.847328680682264, disc_loss = 0.09141692591588689
Trained batch 584 in epoch 1, gen_loss = 0.8467489465179606, disc_loss = 0.09154180151720842
Trained batch 585 in epoch 1, gen_loss = 0.846546191862012, disc_loss = 0.09147448776410606
Trained batch 586 in epoch 1, gen_loss = 0.8475882049008976, disc_loss = 0.09189126067802793
Trained batch 587 in epoch 1, gen_loss = 0.847499129166003, disc_loss = 0.09182254277917297
Trained batch 588 in epoch 1, gen_loss = 0.8471782144241301, disc_loss = 0.0917979821480545
Trained batch 589 in epoch 1, gen_loss = 0.8467189144785121, disc_loss = 0.0918743811768748
Trained batch 590 in epoch 1, gen_loss = 0.8466103810646812, disc_loss = 0.09232531579655742
Trained batch 591 in epoch 1, gen_loss = 0.8467611233024178, disc_loss = 0.09238974803844718
Trained batch 592 in epoch 1, gen_loss = 0.8462812167295517, disc_loss = 0.09255066824037249
Trained batch 593 in epoch 1, gen_loss = 0.8465392686401554, disc_loss = 0.09246156164931027
Trained batch 594 in epoch 1, gen_loss = 0.8461824226279219, disc_loss = 0.09243932848154497
Trained batch 595 in epoch 1, gen_loss = 0.8458966056272488, disc_loss = 0.09257850001859885
Trained batch 596 in epoch 1, gen_loss = 0.8454095458165685, disc_loss = 0.09280370438855197
Trained batch 597 in epoch 1, gen_loss = 0.8450764309502764, disc_loss = 0.09305175980334995
Trained batch 598 in epoch 1, gen_loss = 0.8449328188008578, disc_loss = 0.09315605372974092
Trained batch 599 in epoch 1, gen_loss = 0.8447839254637559, disc_loss = 0.09325007342733443
Trained batch 600 in epoch 1, gen_loss = 0.8447203039627107, disc_loss = 0.09321713556354236
Trained batch 601 in epoch 1, gen_loss = 0.8445528550104445, disc_loss = 0.09315578152806162
Trained batch 602 in epoch 1, gen_loss = 0.8442931610652266, disc_loss = 0.09311906079982545
Trained batch 603 in epoch 1, gen_loss = 0.8439046701552063, disc_loss = 0.09319566087550576
Trained batch 604 in epoch 1, gen_loss = 0.8437380757706224, disc_loss = 0.09336791645335264
Trained batch 605 in epoch 1, gen_loss = 0.8433852114594809, disc_loss = 0.09349677887231898
Trained batch 606 in epoch 1, gen_loss = 0.8429714087304802, disc_loss = 0.09356698728606866
Trained batch 607 in epoch 1, gen_loss = 0.8429448459003317, disc_loss = 0.09356956103951425
Trained batch 608 in epoch 1, gen_loss = 0.8424467954827451, disc_loss = 0.09379115733448018
Trained batch 609 in epoch 1, gen_loss = 0.8423984828053928, disc_loss = 0.09379749832766467
Trained batch 610 in epoch 1, gen_loss = 0.8426200876747137, disc_loss = 0.09376934817923559
Trained batch 611 in epoch 1, gen_loss = 0.8430541168922693, disc_loss = 0.09366601181453933
Trained batch 612 in epoch 1, gen_loss = 0.8425926772746916, disc_loss = 0.09378022742480477
Trained batch 613 in epoch 1, gen_loss = 0.842486833467934, disc_loss = 0.09373854743225761
Trained batch 614 in epoch 1, gen_loss = 0.8430203708691325, disc_loss = 0.09394709668387242
Trained batch 615 in epoch 1, gen_loss = 0.8426447285750469, disc_loss = 0.09395973230167837
Trained batch 616 in epoch 1, gen_loss = 0.842147561535843, disc_loss = 0.09404897023855771
Trained batch 617 in epoch 1, gen_loss = 0.8423087254986408, disc_loss = 0.09406370427881437
Trained batch 618 in epoch 1, gen_loss = 0.8427866084413883, disc_loss = 0.09396221524823656
Trained batch 619 in epoch 1, gen_loss = 0.8421947088453078, disc_loss = 0.09434867327011401
Trained batch 620 in epoch 1, gen_loss = 0.8427267045310538, disc_loss = 0.09442377125247473
Trained batch 621 in epoch 1, gen_loss = 0.8429265408941404, disc_loss = 0.09435012252624012
Trained batch 622 in epoch 1, gen_loss = 0.8428329100673884, disc_loss = 0.09426463092789412
Trained batch 623 in epoch 1, gen_loss = 0.8429000212882574, disc_loss = 0.0941399581437835
Trained batch 624 in epoch 1, gen_loss = 0.8426425284862519, disc_loss = 0.09406046926081181
Trained batch 625 in epoch 1, gen_loss = 0.8428485556818045, disc_loss = 0.09392758632769076
Trained batch 626 in epoch 1, gen_loss = 0.8424416486251107, disc_loss = 0.0941164439627262
Trained batch 627 in epoch 1, gen_loss = 0.8422218639474766, disc_loss = 0.0940432578019774
Trained batch 628 in epoch 1, gen_loss = 0.8419310760896043, disc_loss = 0.09404642755144967
Trained batch 629 in epoch 1, gen_loss = 0.842329866214404, disc_loss = 0.09394135999212426
Trained batch 630 in epoch 1, gen_loss = 0.8421088228985172, disc_loss = 0.09398132830816903
Trained batch 631 in epoch 1, gen_loss = 0.8415799232883544, disc_loss = 0.09426241508490536
Trained batch 632 in epoch 1, gen_loss = 0.8416442864031588, disc_loss = 0.09431650739245552
Trained batch 633 in epoch 1, gen_loss = 0.8415637599650994, disc_loss = 0.09424458729831814
Trained batch 634 in epoch 1, gen_loss = 0.841398666834268, disc_loss = 0.09422003990699222
Trained batch 635 in epoch 1, gen_loss = 0.8411749369412098, disc_loss = 0.09421130548723324
Trained batch 636 in epoch 1, gen_loss = 0.8413856853402016, disc_loss = 0.09412721770390096
Trained batch 637 in epoch 1, gen_loss = 0.8417519920018026, disc_loss = 0.09399824455047616
Trained batch 638 in epoch 1, gen_loss = 0.8417258430068295, disc_loss = 0.09393005012294077
Trained batch 639 in epoch 1, gen_loss = 0.8420814010780304, disc_loss = 0.09381413508526748
Trained batch 640 in epoch 1, gen_loss = 0.84192174947392, disc_loss = 0.09377711585776621
Trained batch 641 in epoch 1, gen_loss = 0.8421740729210904, disc_loss = 0.0936807241752117
Trained batch 642 in epoch 1, gen_loss = 0.8419137880275631, disc_loss = 0.0936526201569807
Trained batch 643 in epoch 1, gen_loss = 0.8421643610048738, disc_loss = 0.09364861224326797
Trained batch 644 in epoch 1, gen_loss = 0.8418672816235889, disc_loss = 0.09367809317457353
Trained batch 645 in epoch 1, gen_loss = 0.8417607964284649, disc_loss = 0.0936365520376885
Trained batch 646 in epoch 1, gen_loss = 0.842126283754337, disc_loss = 0.0938939131332858
Trained batch 647 in epoch 1, gen_loss = 0.8417884525785475, disc_loss = 0.09397758619233185
Trained batch 648 in epoch 1, gen_loss = 0.8414970054556666, disc_loss = 0.09397915619725393
Trained batch 649 in epoch 1, gen_loss = 0.8412537699937821, disc_loss = 0.09404491155050122
Trained batch 650 in epoch 1, gen_loss = 0.8412719001326876, disc_loss = 0.09409601609730454
Trained batch 651 in epoch 1, gen_loss = 0.8410377542208309, disc_loss = 0.09419479564923587
Trained batch 652 in epoch 1, gen_loss = 0.8408063727261279, disc_loss = 0.09425658561363474
Trained batch 653 in epoch 1, gen_loss = 0.8407124042602125, disc_loss = 0.09429608158829882
Trained batch 654 in epoch 1, gen_loss = 0.8405471506464572, disc_loss = 0.09431274117944577
Trained batch 655 in epoch 1, gen_loss = 0.8401772689256, disc_loss = 0.09445089900088156
Trained batch 656 in epoch 1, gen_loss = 0.8402390500454053, disc_loss = 0.09440572847735527
Trained batch 657 in epoch 1, gen_loss = 0.839881371989801, disc_loss = 0.09452516934197498
Trained batch 658 in epoch 1, gen_loss = 0.8395034874788003, disc_loss = 0.09467426647767085
Trained batch 659 in epoch 1, gen_loss = 0.8393214691317443, disc_loss = 0.09472336303866045
Trained batch 660 in epoch 1, gen_loss = 0.8390958565717025, disc_loss = 0.09486317956811677
Trained batch 661 in epoch 1, gen_loss = 0.8390218554756793, disc_loss = 0.09480054478310161
Trained batch 662 in epoch 1, gen_loss = 0.8396172901534027, disc_loss = 0.09485626090205587
Trained batch 663 in epoch 1, gen_loss = 0.839464049068201, disc_loss = 0.09477738479393567
Trained batch 664 in epoch 1, gen_loss = 0.8391072200205093, disc_loss = 0.0948002612666416
Trained batch 665 in epoch 1, gen_loss = 0.8388931203980345, disc_loss = 0.09472129805371524
Trained batch 666 in epoch 1, gen_loss = 0.8390768062675196, disc_loss = 0.0947796059018378
Trained batch 667 in epoch 1, gen_loss = 0.8386091515421867, disc_loss = 0.09489832785465716
Trained batch 668 in epoch 1, gen_loss = 0.8382585496378586, disc_loss = 0.09492844999565984
Trained batch 669 in epoch 1, gen_loss = 0.8384130721216771, disc_loss = 0.0951272445981071
Trained batch 670 in epoch 1, gen_loss = 0.8387568852851714, disc_loss = 0.09508371315813233
Trained batch 671 in epoch 1, gen_loss = 0.8383465628804905, disc_loss = 0.09512902909773402
Trained batch 672 in epoch 1, gen_loss = 0.8379169470045222, disc_loss = 0.09531160248484999
Trained batch 673 in epoch 1, gen_loss = 0.8382820601544677, disc_loss = 0.09535077984033025
Trained batch 674 in epoch 1, gen_loss = 0.8381661184187289, disc_loss = 0.09549149047859289
Trained batch 675 in epoch 1, gen_loss = 0.8379436308551117, disc_loss = 0.0955952703332826
Trained batch 676 in epoch 1, gen_loss = 0.8375663105370903, disc_loss = 0.09566395836944198
Trained batch 677 in epoch 1, gen_loss = 0.8374730480895282, disc_loss = 0.09564806101568989
Trained batch 678 in epoch 1, gen_loss = 0.8373310785844856, disc_loss = 0.09571872972396363
Trained batch 679 in epoch 1, gen_loss = 0.8370468971045578, disc_loss = 0.09570536484585747
Trained batch 680 in epoch 1, gen_loss = 0.8369811396504289, disc_loss = 0.09580096384037215
Trained batch 681 in epoch 1, gen_loss = 0.8370297558583821, disc_loss = 0.09569212032995485
Trained batch 682 in epoch 1, gen_loss = 0.8365245961950952, disc_loss = 0.09591260645265853
Trained batch 683 in epoch 1, gen_loss = 0.8364388186767785, disc_loss = 0.09593550316384879
Trained batch 684 in epoch 1, gen_loss = 0.8364566871284569, disc_loss = 0.09612729351586886
Trained batch 685 in epoch 1, gen_loss = 0.8366416644511347, disc_loss = 0.09601089174644722
Trained batch 686 in epoch 1, gen_loss = 0.8366151174863874, disc_loss = 0.09589675244410269
Trained batch 687 in epoch 1, gen_loss = 0.836189758249147, disc_loss = 0.09605646908667675
Trained batch 688 in epoch 1, gen_loss = 0.8362923562526703, disc_loss = 0.0959530023246982
Trained batch 689 in epoch 1, gen_loss = 0.8367291038882905, disc_loss = 0.09595508688952828
Trained batch 690 in epoch 1, gen_loss = 0.8362662948765044, disc_loss = 0.09601344283691751
Trained batch 691 in epoch 1, gen_loss = 0.8359017479368028, disc_loss = 0.09607446225053184
Trained batch 692 in epoch 1, gen_loss = 0.8359542661501044, disc_loss = 0.09603961636843146
Trained batch 693 in epoch 1, gen_loss = 0.8356775759534121, disc_loss = 0.09607828167060481
Trained batch 694 in epoch 1, gen_loss = 0.8356774019251625, disc_loss = 0.09607277257542172
Trained batch 695 in epoch 1, gen_loss = 0.835541919687356, disc_loss = 0.09604333135722226
Trained batch 696 in epoch 1, gen_loss = 0.8352672872019977, disc_loss = 0.09612085827502022
Trained batch 697 in epoch 1, gen_loss = 0.8352951231948967, disc_loss = 0.09634407430508289
Trained batch 698 in epoch 1, gen_loss = 0.8351195900992774, disc_loss = 0.09632389784759932
Trained batch 699 in epoch 1, gen_loss = 0.8346309967551913, disc_loss = 0.09653732327611318
Trained batch 700 in epoch 1, gen_loss = 0.8349852323021937, disc_loss = 0.09663205435592548
Trained batch 701 in epoch 1, gen_loss = 0.8346888638629533, disc_loss = 0.09667892541943325
Trained batch 702 in epoch 1, gen_loss = 0.8348178390418822, disc_loss = 0.09681258684588573
Trained batch 703 in epoch 1, gen_loss = 0.834488685158166, disc_loss = 0.09688399232717612
Trained batch 704 in epoch 1, gen_loss = 0.8341841537901695, disc_loss = 0.09700312961209961
Trained batch 705 in epoch 1, gen_loss = 0.8340597451577443, disc_loss = 0.09702189928501127
Trained batch 706 in epoch 1, gen_loss = 0.8339755444917855, disc_loss = 0.09723012696403636
Trained batch 707 in epoch 1, gen_loss = 0.8339278710595632, disc_loss = 0.09720746444743443
Trained batch 708 in epoch 1, gen_loss = 0.8333830392495197, disc_loss = 0.0974070037214666
Trained batch 709 in epoch 1, gen_loss = 0.8332023037571302, disc_loss = 0.09738908219216785
Trained batch 710 in epoch 1, gen_loss = 0.8332698170394334, disc_loss = 0.09754562065785989
Trained batch 711 in epoch 1, gen_loss = 0.8328945006798493, disc_loss = 0.09762326245107217
Trained batch 712 in epoch 1, gen_loss = 0.8325678474187517, disc_loss = 0.09773337502596798
Trained batch 713 in epoch 1, gen_loss = 0.8325613254175133, disc_loss = 0.09776360224488945
Trained batch 714 in epoch 1, gen_loss = 0.8328250591154699, disc_loss = 0.0977793745865876
Trained batch 715 in epoch 1, gen_loss = 0.8323548129400727, disc_loss = 0.09788783564877451
Trained batch 716 in epoch 1, gen_loss = 0.832322633125127, disc_loss = 0.09784692906316063
Trained batch 717 in epoch 1, gen_loss = 0.8320154450979074, disc_loss = 0.09798859008056084
Trained batch 718 in epoch 1, gen_loss = 0.8321450261893956, disc_loss = 0.09833738458717192
Trained batch 719 in epoch 1, gen_loss = 0.8316559967481427, disc_loss = 0.09861396876189651
Trained batch 720 in epoch 1, gen_loss = 0.8314645627252603, disc_loss = 0.09872236537996384
Trained batch 721 in epoch 1, gen_loss = 0.8311396277924984, disc_loss = 0.09876224303803822
Trained batch 722 in epoch 1, gen_loss = 0.8307474438168037, disc_loss = 0.09885783846081746
Trained batch 723 in epoch 1, gen_loss = 0.8306676414049132, disc_loss = 0.09897089070506723
Trained batch 724 in epoch 1, gen_loss = 0.8304410142323067, disc_loss = 0.09901875726236352
Trained batch 725 in epoch 1, gen_loss = 0.8301803823098663, disc_loss = 0.09902159820539112
Trained batch 726 in epoch 1, gen_loss = 0.8300206649336231, disc_loss = 0.09898303670647261
Trained batch 727 in epoch 1, gen_loss = 0.8298884260539825, disc_loss = 0.09896700948113474
Trained batch 728 in epoch 1, gen_loss = 0.8299380457859143, disc_loss = 0.09886133910089077
Trained batch 729 in epoch 1, gen_loss = 0.8296618573061407, disc_loss = 0.0988847754091943
Trained batch 730 in epoch 1, gen_loss = 0.829340038033745, disc_loss = 0.09893982372439063
Trained batch 731 in epoch 1, gen_loss = 0.8293519578263407, disc_loss = 0.09904076675171938
Trained batch 732 in epoch 1, gen_loss = 0.8291492989492611, disc_loss = 0.0991639002438477
Trained batch 733 in epoch 1, gen_loss = 0.8287756516514422, disc_loss = 0.09934721577643577
Trained batch 734 in epoch 1, gen_loss = 0.828789740314289, disc_loss = 0.0994617318126316
Trained batch 735 in epoch 1, gen_loss = 0.8285097832508062, disc_loss = 0.09956188110315808
Trained batch 736 in epoch 1, gen_loss = 0.8286122612180024, disc_loss = 0.09952378949451196
Trained batch 737 in epoch 1, gen_loss = 0.8281904041040234, disc_loss = 0.09959255184266504
Trained batch 738 in epoch 1, gen_loss = 0.8278439627690631, disc_loss = 0.09967291033644032
Trained batch 739 in epoch 1, gen_loss = 0.8280285150215433, disc_loss = 0.09979891961415273
Trained batch 740 in epoch 1, gen_loss = 0.8278038340461077, disc_loss = 0.09979553172910302
Trained batch 741 in epoch 1, gen_loss = 0.8274496545126496, disc_loss = 0.09984184757522696
Trained batch 742 in epoch 1, gen_loss = 0.827294721296947, disc_loss = 0.09997137691223966
Trained batch 743 in epoch 1, gen_loss = 0.8270659643395614, disc_loss = 0.1000097405418293
Trained batch 744 in epoch 1, gen_loss = 0.8268169403476203, disc_loss = 0.10005963566844295
Trained batch 745 in epoch 1, gen_loss = 0.8268096874051055, disc_loss = 0.10001022436708491
Trained batch 746 in epoch 1, gen_loss = 0.8265820881688452, disc_loss = 0.10002764046237052
Trained batch 747 in epoch 1, gen_loss = 0.8265798238111052, disc_loss = 0.10004399765785883
Trained batch 748 in epoch 1, gen_loss = 0.8264834338498211, disc_loss = 0.1000229070430624
Trained batch 749 in epoch 1, gen_loss = 0.8260539514621099, disc_loss = 0.10025385494157672
Trained batch 750 in epoch 1, gen_loss = 0.826130349570997, disc_loss = 0.10025864231527923
Trained batch 751 in epoch 1, gen_loss = 0.8262216914445162, disc_loss = 0.1002124458801576
Trained batch 752 in epoch 1, gen_loss = 0.8258691762943825, disc_loss = 0.10024586118198683
Trained batch 753 in epoch 1, gen_loss = 0.8256753774394407, disc_loss = 0.10027147363253748
Trained batch 754 in epoch 1, gen_loss = 0.8256316351180045, disc_loss = 0.1002758993230612
Trained batch 755 in epoch 1, gen_loss = 0.8254024631999157, disc_loss = 0.10030101103801772
Trained batch 756 in epoch 1, gen_loss = 0.8253044443921023, disc_loss = 0.1003609057552768
Trained batch 757 in epoch 1, gen_loss = 0.8251079169536958, disc_loss = 0.10032972630658887
Trained batch 758 in epoch 1, gen_loss = 0.8249837637183224, disc_loss = 0.10034019606156036
Trained batch 759 in epoch 1, gen_loss = 0.825040295759314, disc_loss = 0.10036202837884622
Trained batch 760 in epoch 1, gen_loss = 0.8253036657943049, disc_loss = 0.10027615957172605
Trained batch 761 in epoch 1, gen_loss = 0.8249006353103583, disc_loss = 0.10034814310868777
Trained batch 762 in epoch 1, gen_loss = 0.8247430615546976, disc_loss = 0.10031661529064687
Trained batch 763 in epoch 1, gen_loss = 0.824870772581762, disc_loss = 0.10049780205755217
Trained batch 764 in epoch 1, gen_loss = 0.8248475882352567, disc_loss = 0.1004301105023307
Trained batch 765 in epoch 1, gen_loss = 0.8249935670792279, disc_loss = 0.10033423353506947
Trained batch 766 in epoch 1, gen_loss = 0.8247108316095121, disc_loss = 0.10038340362845258
Trained batch 767 in epoch 1, gen_loss = 0.8247142619996642, disc_loss = 0.10040452420677563
Trained batch 768 in epoch 1, gen_loss = 0.8248779427633174, disc_loss = 0.10037090327174092
Trained batch 769 in epoch 1, gen_loss = 0.8244194589652024, disc_loss = 0.10047666599925656
Trained batch 770 in epoch 1, gen_loss = 0.8245297231253638, disc_loss = 0.10044286338353937
Trained batch 771 in epoch 1, gen_loss = 0.824472625792953, disc_loss = 0.10047500757283381
Trained batch 772 in epoch 1, gen_loss = 0.8246581187377772, disc_loss = 0.1004397704303361
Trained batch 773 in epoch 1, gen_loss = 0.8244677802080947, disc_loss = 0.10042793112289575
Trained batch 774 in epoch 1, gen_loss = 0.8248862117336643, disc_loss = 0.10035392252307745
Trained batch 775 in epoch 1, gen_loss = 0.824881675009875, disc_loss = 0.10030655933126385
Trained batch 776 in epoch 1, gen_loss = 0.8245721500045697, disc_loss = 0.1003680661994307
Trained batch 777 in epoch 1, gen_loss = 0.8245782447658039, disc_loss = 0.10052521344499332
Trained batch 778 in epoch 1, gen_loss = 0.8245001846926815, disc_loss = 0.10049902638767168
Trained batch 779 in epoch 1, gen_loss = 0.8245494522345371, disc_loss = 0.10045421255919605
Trained batch 780 in epoch 1, gen_loss = 0.8247813046665411, disc_loss = 0.10036436720809658
Trained batch 781 in epoch 1, gen_loss = 0.8244419304458687, disc_loss = 0.10038713822760584
Trained batch 782 in epoch 1, gen_loss = 0.8244723272658552, disc_loss = 0.10037227867154516
Trained batch 783 in epoch 1, gen_loss = 0.8244131662103594, disc_loss = 0.1003323076447301
Trained batch 784 in epoch 1, gen_loss = 0.8242039542289297, disc_loss = 0.1003022047803755
Trained batch 785 in epoch 1, gen_loss = 0.8238866506642057, disc_loss = 0.10036346043931657
Trained batch 786 in epoch 1, gen_loss = 0.824050481316398, disc_loss = 0.10054890776060171
Trained batch 787 in epoch 1, gen_loss = 0.8240356532298974, disc_loss = 0.1005117960408954
Trained batch 788 in epoch 1, gen_loss = 0.8241942655602034, disc_loss = 0.10040851596374589
Trained batch 789 in epoch 1, gen_loss = 0.8239742841901658, disc_loss = 0.10033508760713135
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6457695960998535, disc_loss = 0.09918588399887085
Trained batch 1 in epoch 2, gen_loss = 0.5899526476860046, disc_loss = 0.13777881115674973
Trained batch 2 in epoch 2, gen_loss = 0.6551724870999655, disc_loss = 0.1397735277811686
Trained batch 3 in epoch 2, gen_loss = 0.7699434608221054, disc_loss = 0.11922762729227543
Trained batch 4 in epoch 2, gen_loss = 0.7307812809944153, disc_loss = 0.11804280132055282
Trained batch 5 in epoch 2, gen_loss = 0.7277119557062784, disc_loss = 0.11672006423274676
Trained batch 6 in epoch 2, gen_loss = 0.7571038007736206, disc_loss = 0.12561597675085068
Trained batch 7 in epoch 2, gen_loss = 0.7429822534322739, disc_loss = 0.12229881063103676
Trained batch 8 in epoch 2, gen_loss = 0.7293232017093234, disc_loss = 0.11675110376543468
Trained batch 9 in epoch 2, gen_loss = 0.7369431495666504, disc_loss = 0.11510628685355187
Trained batch 10 in epoch 2, gen_loss = 0.7217977101152594, disc_loss = 0.11226226592605765
Trained batch 11 in epoch 2, gen_loss = 0.724300816655159, disc_loss = 0.11217304629584153
Trained batch 12 in epoch 2, gen_loss = 0.7232174827502325, disc_loss = 0.11316841554183227
Trained batch 13 in epoch 2, gen_loss = 0.732981128352029, disc_loss = 0.11643359331148011
Trained batch 14 in epoch 2, gen_loss = 0.734101661046346, disc_loss = 0.11191241691509883
Trained batch 15 in epoch 2, gen_loss = 0.7593527436256409, disc_loss = 0.1077589001506567
Trained batch 16 in epoch 2, gen_loss = 0.7447812311789569, disc_loss = 0.12186947640250712
Trained batch 17 in epoch 2, gen_loss = 0.7655198209815555, disc_loss = 0.12103163285387887
Trained batch 18 in epoch 2, gen_loss = 0.7668227176917227, disc_loss = 0.12011894309207012
Trained batch 19 in epoch 2, gen_loss = 0.7573170363903046, disc_loss = 0.12329821772873402
Trained batch 20 in epoch 2, gen_loss = 0.7532815791311718, disc_loss = 0.12186357059649058
Trained batch 21 in epoch 2, gen_loss = 0.7710629945451563, disc_loss = 0.1191404727710919
Trained batch 22 in epoch 2, gen_loss = 0.7770516328189684, disc_loss = 0.11580274075917575
Trained batch 23 in epoch 2, gen_loss = 0.7757092043757439, disc_loss = 0.11404737162714203
Trained batch 24 in epoch 2, gen_loss = 0.7797158789634705, disc_loss = 0.11319416835904121
Trained batch 25 in epoch 2, gen_loss = 0.779362868804198, disc_loss = 0.11136976930384453
Trained batch 26 in epoch 2, gen_loss = 0.7811499900288053, disc_loss = 0.10967582064094367
Trained batch 27 in epoch 2, gen_loss = 0.7961134676422391, disc_loss = 0.1071521859349949
Trained batch 28 in epoch 2, gen_loss = 0.8005374978328573, disc_loss = 0.10431135163224976
Trained batch 29 in epoch 2, gen_loss = 0.806244021654129, disc_loss = 0.10191164414087932
Trained batch 30 in epoch 2, gen_loss = 0.8089854082753581, disc_loss = 0.09947750825555093
Trained batch 31 in epoch 2, gen_loss = 0.8098054770380259, disc_loss = 0.09721795096993446
Trained batch 32 in epoch 2, gen_loss = 0.8096153862548597, disc_loss = 0.09537245694435004
Trained batch 33 in epoch 2, gen_loss = 0.8068579102263731, disc_loss = 0.09629928320646286
Trained batch 34 in epoch 2, gen_loss = 0.8132391537938799, disc_loss = 0.09613467987094607
Trained batch 35 in epoch 2, gen_loss = 0.8055055671268039, disc_loss = 0.09984844778147009
Trained batch 36 in epoch 2, gen_loss = 0.811905725582226, disc_loss = 0.10095295692617828
Trained batch 37 in epoch 2, gen_loss = 0.8108379025208322, disc_loss = 0.0989527260198405
Trained batch 38 in epoch 2, gen_loss = 0.8088582968100523, disc_loss = 0.09756460967354286
Trained batch 39 in epoch 2, gen_loss = 0.8053022444248199, disc_loss = 0.09700218746438623
Trained batch 40 in epoch 2, gen_loss = 0.8085139844475723, disc_loss = 0.0967270532940946
Trained batch 41 in epoch 2, gen_loss = 0.8053728015649886, disc_loss = 0.09731589106931574
Trained batch 42 in epoch 2, gen_loss = 0.7986807753873426, disc_loss = 0.09806999832738278
Trained batch 43 in epoch 2, gen_loss = 0.7961999110200189, disc_loss = 0.09881663076918233
Trained batch 44 in epoch 2, gen_loss = 0.7979104081789653, disc_loss = 0.10067405394381947
Trained batch 45 in epoch 2, gen_loss = 0.8007325918778129, disc_loss = 0.09885336078055527
Trained batch 46 in epoch 2, gen_loss = 0.8033302591202107, disc_loss = 0.09714010995911791
Trained batch 47 in epoch 2, gen_loss = 0.7997220245500406, disc_loss = 0.09701750772849967
Trained batch 48 in epoch 2, gen_loss = 0.7955833539670828, disc_loss = 0.09761064944370669
Trained batch 49 in epoch 2, gen_loss = 0.7987454378604889, disc_loss = 0.09937183741480111
Trained batch 50 in epoch 2, gen_loss = 0.7967762561405406, disc_loss = 0.09878771215238992
Trained batch 51 in epoch 2, gen_loss = 0.7963104878480618, disc_loss = 0.09800706857528824
Trained batch 52 in epoch 2, gen_loss = 0.7916342548604282, disc_loss = 0.09939638254636864
Trained batch 53 in epoch 2, gen_loss = 0.7961875829431746, disc_loss = 0.1010094880712805
Trained batch 54 in epoch 2, gen_loss = 0.7909548661925576, disc_loss = 0.10389786955307831
Trained batch 55 in epoch 2, gen_loss = 0.7894151615245002, disc_loss = 0.10420049337803253
Trained batch 56 in epoch 2, gen_loss = 0.7905806763130322, disc_loss = 0.1048780806166561
Trained batch 57 in epoch 2, gen_loss = 0.7885053424999632, disc_loss = 0.1049802453289258
Trained batch 58 in epoch 2, gen_loss = 0.7874572842808093, disc_loss = 0.10501645855858165
Trained batch 59 in epoch 2, gen_loss = 0.7879530688126882, disc_loss = 0.10383366455013553
Trained batch 60 in epoch 2, gen_loss = 0.7881082061861382, disc_loss = 0.10279182561474745
Trained batch 61 in epoch 2, gen_loss = 0.7853657487900026, disc_loss = 0.1037101229772933
Trained batch 62 in epoch 2, gen_loss = 0.7877048528383649, disc_loss = 0.10570221556912339
Trained batch 63 in epoch 2, gen_loss = 0.7882654406130314, disc_loss = 0.10606352085596882
Trained batch 64 in epoch 2, gen_loss = 0.7891077683522151, disc_loss = 0.10486687012016774
Trained batch 65 in epoch 2, gen_loss = 0.7857827345530192, disc_loss = 0.1061054454890616
Trained batch 66 in epoch 2, gen_loss = 0.7864501351740822, disc_loss = 0.10626474036765632
Trained batch 67 in epoch 2, gen_loss = 0.7839499887298135, disc_loss = 0.10707228271948065
Trained batch 68 in epoch 2, gen_loss = 0.7827491622040237, disc_loss = 0.10709233627911063
Trained batch 69 in epoch 2, gen_loss = 0.7853284886905125, disc_loss = 0.10575675180714045
Trained batch 70 in epoch 2, gen_loss = 0.788034157014229, disc_loss = 0.10568132517780636
Trained batch 71 in epoch 2, gen_loss = 0.7866054442193773, disc_loss = 0.10553855452841769
Trained batch 72 in epoch 2, gen_loss = 0.7860006583880071, disc_loss = 0.1050702219522775
Trained batch 73 in epoch 2, gen_loss = 0.785342187494845, disc_loss = 0.10553767012331534
Trained batch 74 in epoch 2, gen_loss = 0.7847150222460428, disc_loss = 0.10533050342152515
Trained batch 75 in epoch 2, gen_loss = 0.7841162940389231, disc_loss = 0.10523038616060819
Trained batch 76 in epoch 2, gen_loss = 0.7820504338710339, disc_loss = 0.10518023946213645
Trained batch 77 in epoch 2, gen_loss = 0.7805380263389685, disc_loss = 0.1052344384459922
Trained batch 78 in epoch 2, gen_loss = 0.7849344264102888, disc_loss = 0.10671173020772919
Trained batch 79 in epoch 2, gen_loss = 0.7854490004479885, disc_loss = 0.10586041141068563
Trained batch 80 in epoch 2, gen_loss = 0.7829684674003978, disc_loss = 0.10671801151086886
Trained batch 81 in epoch 2, gen_loss = 0.7806232927775965, disc_loss = 0.10670650244985776
Trained batch 82 in epoch 2, gen_loss = 0.7836002779294209, disc_loss = 0.1081628695646503
Trained batch 83 in epoch 2, gen_loss = 0.7822153156711942, disc_loss = 0.1081806877517097
Trained batch 84 in epoch 2, gen_loss = 0.7802409059861127, disc_loss = 0.10913970596430933
Trained batch 85 in epoch 2, gen_loss = 0.7811022705810015, disc_loss = 0.10966594607114445
Trained batch 86 in epoch 2, gen_loss = 0.7830948021220064, disc_loss = 0.10869878576533205
Trained batch 87 in epoch 2, gen_loss = 0.7830752486532385, disc_loss = 0.10773977587549863
Trained batch 88 in epoch 2, gen_loss = 0.7811493619104449, disc_loss = 0.10823329313124498
Trained batch 89 in epoch 2, gen_loss = 0.7802064683702257, disc_loss = 0.10826465538185504
Trained batch 90 in epoch 2, gen_loss = 0.7807195193164951, disc_loss = 0.10817469067994383
Trained batch 91 in epoch 2, gen_loss = 0.7805614432562953, disc_loss = 0.10757987522115202
Trained batch 92 in epoch 2, gen_loss = 0.7782605880050248, disc_loss = 0.10853349742910234
Trained batch 93 in epoch 2, gen_loss = 0.7774245954574422, disc_loss = 0.10847745056046133
Trained batch 94 in epoch 2, gen_loss = 0.776614068683825, disc_loss = 0.1090615201643423
Trained batch 95 in epoch 2, gen_loss = 0.7758833542466164, disc_loss = 0.1102303291069499
Trained batch 96 in epoch 2, gen_loss = 0.7762628431172715, disc_loss = 0.110373542298438
Trained batch 97 in epoch 2, gen_loss = 0.7761277361791961, disc_loss = 0.10974145799457115
Trained batch 98 in epoch 2, gen_loss = 0.7778018110930317, disc_loss = 0.10907087163679828
Trained batch 99 in epoch 2, gen_loss = 0.7766146934032441, disc_loss = 0.10882616852410137
Trained batch 100 in epoch 2, gen_loss = 0.7794438246453163, disc_loss = 0.10847958351605304
Trained batch 101 in epoch 2, gen_loss = 0.7791522963374269, disc_loss = 0.1080328579352913
Trained batch 102 in epoch 2, gen_loss = 0.7780943414539967, disc_loss = 0.10785155386202833
Trained batch 103 in epoch 2, gen_loss = 0.7781687252796613, disc_loss = 0.10761869524139911
Trained batch 104 in epoch 2, gen_loss = 0.778668943473271, disc_loss = 0.10793636977849971
Trained batch 105 in epoch 2, gen_loss = 0.7780495510911042, disc_loss = 0.10744258182404458
Trained batch 106 in epoch 2, gen_loss = 0.7803431203432172, disc_loss = 0.10662002277464788
Trained batch 107 in epoch 2, gen_loss = 0.7781897584597269, disc_loss = 0.10754002245246536
Trained batch 108 in epoch 2, gen_loss = 0.7768931498221301, disc_loss = 0.1076250525464842
Trained batch 109 in epoch 2, gen_loss = 0.7782876513221048, disc_loss = 0.10710168982940642
Trained batch 110 in epoch 2, gen_loss = 0.7775176323211945, disc_loss = 0.10702245065791381
Trained batch 111 in epoch 2, gen_loss = 0.7773404217192105, disc_loss = 0.1068958240378249
Trained batch 112 in epoch 2, gen_loss = 0.7757008202308047, disc_loss = 0.10753990321593211
Trained batch 113 in epoch 2, gen_loss = 0.7773141280600899, disc_loss = 0.10876851666947468
Trained batch 114 in epoch 2, gen_loss = 0.7761513373126154, disc_loss = 0.10920508420499771
Trained batch 115 in epoch 2, gen_loss = 0.7748106209368542, disc_loss = 0.11042086902909495
Trained batch 116 in epoch 2, gen_loss = 0.7744746299890372, disc_loss = 0.11029293458972476
Trained batch 117 in epoch 2, gen_loss = 0.7751516937199285, disc_loss = 0.11017830468619526
Trained batch 118 in epoch 2, gen_loss = 0.7744085297865027, disc_loss = 0.11004194668141984
Trained batch 119 in epoch 2, gen_loss = 0.774790495634079, disc_loss = 0.11033566706658651
Trained batch 120 in epoch 2, gen_loss = 0.7755421227660061, disc_loss = 0.11055458454830834
Trained batch 121 in epoch 2, gen_loss = 0.7739389504565567, disc_loss = 0.1117283179210957
Trained batch 122 in epoch 2, gen_loss = 0.7750574670186857, disc_loss = 0.11170199168921728
Trained batch 123 in epoch 2, gen_loss = 0.774574198069111, disc_loss = 0.11142999126816229
Trained batch 124 in epoch 2, gen_loss = 0.7748819131851197, disc_loss = 0.11119999981671572
Trained batch 125 in epoch 2, gen_loss = 0.7751852784837995, disc_loss = 0.11064006681627934
Trained batch 126 in epoch 2, gen_loss = 0.7757618004881491, disc_loss = 0.10989291432834282
Trained batch 127 in epoch 2, gen_loss = 0.7751678158529103, disc_loss = 0.1096850634276052
Trained batch 128 in epoch 2, gen_loss = 0.7771353892577711, disc_loss = 0.11124417377101589
Trained batch 129 in epoch 2, gen_loss = 0.7769479320599483, disc_loss = 0.1107389053544746
Trained batch 130 in epoch 2, gen_loss = 0.7753254293485452, disc_loss = 0.11100695038370731
Trained batch 131 in epoch 2, gen_loss = 0.7774314573316863, disc_loss = 0.11112593261835475
Trained batch 132 in epoch 2, gen_loss = 0.7759637877457124, disc_loss = 0.11197364375807513
Trained batch 133 in epoch 2, gen_loss = 0.7760064962194927, disc_loss = 0.11175456615998897
Trained batch 134 in epoch 2, gen_loss = 0.7755028631952073, disc_loss = 0.1120321660750994
Trained batch 135 in epoch 2, gen_loss = 0.775204033974339, disc_loss = 0.1120692831258673
Trained batch 136 in epoch 2, gen_loss = 0.7749307029438715, disc_loss = 0.11237775855935621
Trained batch 137 in epoch 2, gen_loss = 0.7736518879731497, disc_loss = 0.11336535961110739
Trained batch 138 in epoch 2, gen_loss = 0.7728438982003026, disc_loss = 0.11341002032080356
Trained batch 139 in epoch 2, gen_loss = 0.7724064141511917, disc_loss = 0.11368052177796406
Trained batch 140 in epoch 2, gen_loss = 0.7708393128205698, disc_loss = 0.11414482054161898
Trained batch 141 in epoch 2, gen_loss = 0.770758869362549, disc_loss = 0.11600900919530803
Trained batch 142 in epoch 2, gen_loss = 0.7690334757724842, disc_loss = 0.11678353906120661
Trained batch 143 in epoch 2, gen_loss = 0.7677089079386659, disc_loss = 0.11700802736838038
Trained batch 144 in epoch 2, gen_loss = 0.7673996506066157, disc_loss = 0.11760581490936978
Trained batch 145 in epoch 2, gen_loss = 0.7683474074487817, disc_loss = 0.1180098486030857
Trained batch 146 in epoch 2, gen_loss = 0.7676119208335876, disc_loss = 0.11858348219598434
Trained batch 147 in epoch 2, gen_loss = 0.767851537546596, disc_loss = 0.11856163741794189
Trained batch 148 in epoch 2, gen_loss = 0.767626883199551, disc_loss = 0.11838549006130271
Trained batch 149 in epoch 2, gen_loss = 0.7674522097905477, disc_loss = 0.11941955974325538
Trained batch 150 in epoch 2, gen_loss = 0.7664397418104261, disc_loss = 0.11992589636576294
Trained batch 151 in epoch 2, gen_loss = 0.7648452939955812, disc_loss = 0.11987222339590325
Trained batch 152 in epoch 2, gen_loss = 0.7645604337742126, disc_loss = 0.12004896755531139
Trained batch 153 in epoch 2, gen_loss = 0.7646064646058268, disc_loss = 0.12015670973976905
Trained batch 154 in epoch 2, gen_loss = 0.7624590537240429, disc_loss = 0.12099777604903905
Trained batch 155 in epoch 2, gen_loss = 0.7619095293757243, disc_loss = 0.12095914456921701
Trained batch 156 in epoch 2, gen_loss = 0.7625915364475008, disc_loss = 0.12078802767476648
Trained batch 157 in epoch 2, gen_loss = 0.7625800833294664, disc_loss = 0.12067321382015
Trained batch 158 in epoch 2, gen_loss = 0.7616714094794771, disc_loss = 0.12108682354314709
Trained batch 159 in epoch 2, gen_loss = 0.7605546126142144, disc_loss = 0.12140359734767117
Trained batch 160 in epoch 2, gen_loss = 0.7601626598686906, disc_loss = 0.12140727899852932
Trained batch 161 in epoch 2, gen_loss = 0.7599836306439506, disc_loss = 0.12179755673019423
Trained batch 162 in epoch 2, gen_loss = 0.75951324851235, disc_loss = 0.12159197549535636
Trained batch 163 in epoch 2, gen_loss = 0.7596955570142444, disc_loss = 0.1214438707329242
Trained batch 164 in epoch 2, gen_loss = 0.7598804320349838, disc_loss = 0.12126976274744128
Trained batch 165 in epoch 2, gen_loss = 0.7583825396127012, disc_loss = 0.12149810248492174
Trained batch 166 in epoch 2, gen_loss = 0.7587781728741652, disc_loss = 0.12152251365321304
Trained batch 167 in epoch 2, gen_loss = 0.7576463901925654, disc_loss = 0.12175566362150546
Trained batch 168 in epoch 2, gen_loss = 0.7578973676678697, disc_loss = 0.12181135990585272
Trained batch 169 in epoch 2, gen_loss = 0.7573390853755614, disc_loss = 0.12155416525133392
Trained batch 170 in epoch 2, gen_loss = 0.7572777541408762, disc_loss = 0.12134348536291492
Trained batch 171 in epoch 2, gen_loss = 0.756615313159865, disc_loss = 0.12140396489155326
Trained batch 172 in epoch 2, gen_loss = 0.7571492131390324, disc_loss = 0.12116698283874403
Trained batch 173 in epoch 2, gen_loss = 0.7581035195068381, disc_loss = 0.12104600086144504
Trained batch 174 in epoch 2, gen_loss = 0.7588957897254399, disc_loss = 0.120572385239814
Trained batch 175 in epoch 2, gen_loss = 0.7584410609508102, disc_loss = 0.12025871780298819
Trained batch 176 in epoch 2, gen_loss = 0.7591199297352699, disc_loss = 0.11997692670546851
Trained batch 177 in epoch 2, gen_loss = 0.7599244146199708, disc_loss = 0.11952008114960254
Trained batch 178 in epoch 2, gen_loss = 0.7605978428651501, disc_loss = 0.11895120945660262
Trained batch 179 in epoch 2, gen_loss = 0.7599891508618991, disc_loss = 0.11884663397342794
Trained batch 180 in epoch 2, gen_loss = 0.7616244131359606, disc_loss = 0.11833235172256416
Trained batch 181 in epoch 2, gen_loss = 0.7610307088592551, disc_loss = 0.11841742526023434
Trained batch 182 in epoch 2, gen_loss = 0.7603283373058819, disc_loss = 0.11839982659092856
Trained batch 183 in epoch 2, gen_loss = 0.7624902441773725, disc_loss = 0.11931042603480266
Trained batch 184 in epoch 2, gen_loss = 0.7620744413620717, disc_loss = 0.119013872173791
Trained batch 185 in epoch 2, gen_loss = 0.7617059168956613, disc_loss = 0.11866328175810556
Trained batch 186 in epoch 2, gen_loss = 0.7621113503361768, disc_loss = 0.11848806609265147
Trained batch 187 in epoch 2, gen_loss = 0.7632510016890283, disc_loss = 0.11897176432304402
Trained batch 188 in epoch 2, gen_loss = 0.7632189571226715, disc_loss = 0.118807990158164
Trained batch 189 in epoch 2, gen_loss = 0.763053160435275, disc_loss = 0.11862599978615579
Trained batch 190 in epoch 2, gen_loss = 0.7636472952615528, disc_loss = 0.11863727305396533
Trained batch 191 in epoch 2, gen_loss = 0.7641084819721679, disc_loss = 0.11823209103022236
Trained batch 192 in epoch 2, gen_loss = 0.7624790336492766, disc_loss = 0.11875183717709595
Trained batch 193 in epoch 2, gen_loss = 0.7624826282262802, disc_loss = 0.11879545672479824
Trained batch 194 in epoch 2, gen_loss = 0.7624215546326759, disc_loss = 0.11879950386878008
Trained batch 195 in epoch 2, gen_loss = 0.7619389354878542, disc_loss = 0.11853044346564126
Trained batch 196 in epoch 2, gen_loss = 0.7610240613446018, disc_loss = 0.11849608188636866
Trained batch 197 in epoch 2, gen_loss = 0.7614504798795237, disc_loss = 0.11851679108039749
Trained batch 198 in epoch 2, gen_loss = 0.7615524124560045, disc_loss = 0.11850571014155545
Trained batch 199 in epoch 2, gen_loss = 0.7606133918464184, disc_loss = 0.11865407671313732
Trained batch 200 in epoch 2, gen_loss = 0.7605830082549384, disc_loss = 0.11899580591038536
Trained batch 201 in epoch 2, gen_loss = 0.7600700012823143, disc_loss = 0.1189063433696064
Trained batch 202 in epoch 2, gen_loss = 0.7598885862991728, disc_loss = 0.11857779540139907
Trained batch 203 in epoch 2, gen_loss = 0.7594177069909432, disc_loss = 0.1188584272795375
Trained batch 204 in epoch 2, gen_loss = 0.7605535671478365, disc_loss = 0.11929592704173268
Trained batch 205 in epoch 2, gen_loss = 0.7617674645000291, disc_loss = 0.1188277844656078
Trained batch 206 in epoch 2, gen_loss = 0.7628877924548255, disc_loss = 0.1183385931648278
Trained batch 207 in epoch 2, gen_loss = 0.7640199997963814, disc_loss = 0.11786133842095016
Trained batch 208 in epoch 2, gen_loss = 0.764140415562397, disc_loss = 0.11792654807469918
Trained batch 209 in epoch 2, gen_loss = 0.7640074958403905, disc_loss = 0.11789430982566305
Trained batch 210 in epoch 2, gen_loss = 0.7647491274004299, disc_loss = 0.11799488481028243
Trained batch 211 in epoch 2, gen_loss = 0.7643291375265931, disc_loss = 0.1178645017108757
Trained batch 212 in epoch 2, gen_loss = 0.7653434801269585, disc_loss = 0.11820918691952324
Trained batch 213 in epoch 2, gen_loss = 0.7642619552734856, disc_loss = 0.11826643806873499
Trained batch 214 in epoch 2, gen_loss = 0.7642776562724003, disc_loss = 0.11844971948844749
Trained batch 215 in epoch 2, gen_loss = 0.7641766036826151, disc_loss = 0.11846622789744288
Trained batch 216 in epoch 2, gen_loss = 0.764138770405598, disc_loss = 0.1183805411406857
Trained batch 217 in epoch 2, gen_loss = 0.76433053681063, disc_loss = 0.11829142080654108
Trained batch 218 in epoch 2, gen_loss = 0.7637786872038558, disc_loss = 0.11817995802027313
Trained batch 219 in epoch 2, gen_loss = 0.7636106725443493, disc_loss = 0.11800508999943056
Trained batch 220 in epoch 2, gen_loss = 0.7638985610385826, disc_loss = 0.11817027783080329
Trained batch 221 in epoch 2, gen_loss = 0.76408121432807, disc_loss = 0.11806430590028565
Trained batch 222 in epoch 2, gen_loss = 0.7630849228044262, disc_loss = 0.11816878372494281
Trained batch 223 in epoch 2, gen_loss = 0.7629387566287603, disc_loss = 0.11826399204437621
Trained batch 224 in epoch 2, gen_loss = 0.7641416455639733, disc_loss = 0.11810736702134211
Trained batch 225 in epoch 2, gen_loss = 0.7630782075951584, disc_loss = 0.1184748222565163
Trained batch 226 in epoch 2, gen_loss = 0.76284605540368, disc_loss = 0.11843205019749603
Trained batch 227 in epoch 2, gen_loss = 0.7632219918202936, disc_loss = 0.11932293230487981
Trained batch 228 in epoch 2, gen_loss = 0.7625368184137553, disc_loss = 0.11933207924693302
Trained batch 229 in epoch 2, gen_loss = 0.7620585274437199, disc_loss = 0.11918408808743824
Trained batch 230 in epoch 2, gen_loss = 0.7622678428243249, disc_loss = 0.11921169324596594
Trained batch 231 in epoch 2, gen_loss = 0.7612515046935657, disc_loss = 0.11953001048271383
Trained batch 232 in epoch 2, gen_loss = 0.761293514219988, disc_loss = 0.11930033829574804
Trained batch 233 in epoch 2, gen_loss = 0.7625536675381864, disc_loss = 0.11958926517723335
Trained batch 234 in epoch 2, gen_loss = 0.761584393648391, disc_loss = 0.11957109991778085
Trained batch 235 in epoch 2, gen_loss = 0.761109676527775, disc_loss = 0.11963830070207053
Trained batch 236 in epoch 2, gen_loss = 0.7612449671397229, disc_loss = 0.1193567189006803
Trained batch 237 in epoch 2, gen_loss = 0.7611736967032697, disc_loss = 0.11951831280167739
Trained batch 238 in epoch 2, gen_loss = 0.7608881945639974, disc_loss = 0.11928912744346896
Trained batch 239 in epoch 2, gen_loss = 0.760252799714605, disc_loss = 0.11915802020812408
Trained batch 240 in epoch 2, gen_loss = 0.7602764322302649, disc_loss = 0.11902816939511611
Trained batch 241 in epoch 2, gen_loss = 0.760568884901764, disc_loss = 0.11901057255646784
Trained batch 242 in epoch 2, gen_loss = 0.7596718059400472, disc_loss = 0.11937355869085578
Trained batch 243 in epoch 2, gen_loss = 0.759407859723099, disc_loss = 0.11920034491121158
Trained batch 244 in epoch 2, gen_loss = 0.7597867526570145, disc_loss = 0.11948846666408437
Trained batch 245 in epoch 2, gen_loss = 0.7593022450441267, disc_loss = 0.11957464533350695
Trained batch 246 in epoch 2, gen_loss = 0.7590059617511656, disc_loss = 0.1194511064957933
Trained batch 247 in epoch 2, gen_loss = 0.7589823667320513, disc_loss = 0.11988722869089895
Trained batch 248 in epoch 2, gen_loss = 0.7586086056079252, disc_loss = 0.11985131355758054
Trained batch 249 in epoch 2, gen_loss = 0.7584171835184097, disc_loss = 0.11963541957363487
Trained batch 250 in epoch 2, gen_loss = 0.7578218288393135, disc_loss = 0.11966020506676806
Trained batch 251 in epoch 2, gen_loss = 0.7571487016384564, disc_loss = 0.11988376964637566
Trained batch 252 in epoch 2, gen_loss = 0.7579655839284889, disc_loss = 0.12018934578042138
Trained batch 253 in epoch 2, gen_loss = 0.7580907559535635, disc_loss = 0.11993360956104135
Trained batch 254 in epoch 2, gen_loss = 0.7571739249369678, disc_loss = 0.12023093328975579
Trained batch 255 in epoch 2, gen_loss = 0.7575194131350145, disc_loss = 0.12031937951906002
Trained batch 256 in epoch 2, gen_loss = 0.7585374273446748, disc_loss = 0.12108566223169
Trained batch 257 in epoch 2, gen_loss = 0.7585579206546148, disc_loss = 0.12104760805982374
Trained batch 258 in epoch 2, gen_loss = 0.7579277246385008, disc_loss = 0.12098059966858174
Trained batch 259 in epoch 2, gen_loss = 0.7581964221138221, disc_loss = 0.12122314801224722
Trained batch 260 in epoch 2, gen_loss = 0.7580909047318601, disc_loss = 0.12142386021613503
Trained batch 261 in epoch 2, gen_loss = 0.7582911472511655, disc_loss = 0.12170276864438907
Trained batch 262 in epoch 2, gen_loss = 0.7575906339480396, disc_loss = 0.12181188964670941
Trained batch 263 in epoch 2, gen_loss = 0.7571256642766071, disc_loss = 0.1219490404120844
Trained batch 264 in epoch 2, gen_loss = 0.7570354658477711, disc_loss = 0.12209047179950296
Trained batch 265 in epoch 2, gen_loss = 0.7572516378827561, disc_loss = 0.12214789757701128
Trained batch 266 in epoch 2, gen_loss = 0.7568712905328372, disc_loss = 0.1222012716028072
Trained batch 267 in epoch 2, gen_loss = 0.7571471597054111, disc_loss = 0.1220463354717384
Trained batch 268 in epoch 2, gen_loss = 0.7567530282146425, disc_loss = 0.12213175873649497
Trained batch 269 in epoch 2, gen_loss = 0.7563562531162191, disc_loss = 0.12233590759267962
Trained batch 270 in epoch 2, gen_loss = 0.7565405506269518, disc_loss = 0.12244406853531009
Trained batch 271 in epoch 2, gen_loss = 0.7568114317734452, disc_loss = 0.12214349631754243
Trained batch 272 in epoch 2, gen_loss = 0.7568060396573483, disc_loss = 0.12201262879161498
Trained batch 273 in epoch 2, gen_loss = 0.7563382945139042, disc_loss = 0.12211309846177915
Trained batch 274 in epoch 2, gen_loss = 0.756842839609493, disc_loss = 0.12203076137399131
Trained batch 275 in epoch 2, gen_loss = 0.756807253304599, disc_loss = 0.12183805171440801
Trained batch 276 in epoch 2, gen_loss = 0.7564616204384002, disc_loss = 0.12177742522425061
Trained batch 277 in epoch 2, gen_loss = 0.7569385853817137, disc_loss = 0.12178191628052498
Trained batch 278 in epoch 2, gen_loss = 0.7569327543499649, disc_loss = 0.1219080495330969
Trained batch 279 in epoch 2, gen_loss = 0.7560747160443237, disc_loss = 0.1221351129634838
Trained batch 280 in epoch 2, gen_loss = 0.7563407975795855, disc_loss = 0.12181305656958623
Trained batch 281 in epoch 2, gen_loss = 0.7562152302645623, disc_loss = 0.12161623554119298
Trained batch 282 in epoch 2, gen_loss = 0.7563330340511807, disc_loss = 0.12136769540568439
Trained batch 283 in epoch 2, gen_loss = 0.7567077141622423, disc_loss = 0.12109533632764409
Trained batch 284 in epoch 2, gen_loss = 0.7568716012594993, disc_loss = 0.12093686653268441
Trained batch 285 in epoch 2, gen_loss = 0.7564133298355382, disc_loss = 0.12098678679146863
Trained batch 286 in epoch 2, gen_loss = 0.756046164015029, disc_loss = 0.12093949591487854
Trained batch 287 in epoch 2, gen_loss = 0.7564507121634152, disc_loss = 0.12100589387571542
Trained batch 288 in epoch 2, gen_loss = 0.7578757938422959, disc_loss = 0.1208070438052286
Trained batch 289 in epoch 2, gen_loss = 0.7573147721331696, disc_loss = 0.12163541664786894
Trained batch 290 in epoch 2, gen_loss = 0.7578341908676108, disc_loss = 0.12151586470158957
Trained batch 291 in epoch 2, gen_loss = 0.7587560706146775, disc_loss = 0.12129747897884106
Trained batch 292 in epoch 2, gen_loss = 0.7589548955394954, disc_loss = 0.12105112171607925
Trained batch 293 in epoch 2, gen_loss = 0.7587190879648235, disc_loss = 0.12098130370572614
Trained batch 294 in epoch 2, gen_loss = 0.7585009971917686, disc_loss = 0.12083313596134974
Trained batch 295 in epoch 2, gen_loss = 0.7597604620496969, disc_loss = 0.12069876421230367
Trained batch 296 in epoch 2, gen_loss = 0.759390775703822, disc_loss = 0.12056289048495417
Trained batch 297 in epoch 2, gen_loss = 0.759344618692494, disc_loss = 0.12036839284740339
Trained batch 298 in epoch 2, gen_loss = 0.7590063336900246, disc_loss = 0.12027750866655822
Trained batch 299 in epoch 2, gen_loss = 0.7590832780798277, disc_loss = 0.12008155936685701
Trained batch 300 in epoch 2, gen_loss = 0.7601497964407519, disc_loss = 0.11990280204028683
Trained batch 301 in epoch 2, gen_loss = 0.7604257802892205, disc_loss = 0.11965770503530736
Trained batch 302 in epoch 2, gen_loss = 0.7597314909149712, disc_loss = 0.11960085948296015
Trained batch 303 in epoch 2, gen_loss = 0.7601948422624877, disc_loss = 0.11952194718239632
Trained batch 304 in epoch 2, gen_loss = 0.7612051442998354, disc_loss = 0.1191978260111369
Trained batch 305 in epoch 2, gen_loss = 0.7617790764258578, disc_loss = 0.11888772513705238
Trained batch 306 in epoch 2, gen_loss = 0.7614407536455396, disc_loss = 0.11864967015951096
Trained batch 307 in epoch 2, gen_loss = 0.7617107363683837, disc_loss = 0.1183922481692892
Trained batch 308 in epoch 2, gen_loss = 0.7625273359053343, disc_loss = 0.11841659332568302
Trained batch 309 in epoch 2, gen_loss = 0.7635837413610951, disc_loss = 0.11819903896520695
Trained batch 310 in epoch 2, gen_loss = 0.7631431477821141, disc_loss = 0.11830488654973519
Trained batch 311 in epoch 2, gen_loss = 0.7627092268413458, disc_loss = 0.11830394865813641
Trained batch 312 in epoch 2, gen_loss = 0.7623478392252145, disc_loss = 0.11817818794685145
Trained batch 313 in epoch 2, gen_loss = 0.762870290571717, disc_loss = 0.11820532628601998
Trained batch 314 in epoch 2, gen_loss = 0.7626020602763646, disc_loss = 0.11831777148126137
Trained batch 315 in epoch 2, gen_loss = 0.762371848372719, disc_loss = 0.11808678884165291
Trained batch 316 in epoch 2, gen_loss = 0.7630484003561905, disc_loss = 0.11784132432827156
Trained batch 317 in epoch 2, gen_loss = 0.7632238648410113, disc_loss = 0.11759654047412786
Trained batch 318 in epoch 2, gen_loss = 0.7633328543374531, disc_loss = 0.11744028567205123
Trained batch 319 in epoch 2, gen_loss = 0.7640208228491246, disc_loss = 0.11759630119486246
Trained batch 320 in epoch 2, gen_loss = 0.7636594825258879, disc_loss = 0.11757065600938979
Trained batch 321 in epoch 2, gen_loss = 0.7635639238616695, disc_loss = 0.11745514092758669
Trained batch 322 in epoch 2, gen_loss = 0.764212367243073, disc_loss = 0.1174637393322384
Trained batch 323 in epoch 2, gen_loss = 0.7636017853647102, disc_loss = 0.11761018472010798
Trained batch 324 in epoch 2, gen_loss = 0.7639687968217409, disc_loss = 0.11759233095611517
Trained batch 325 in epoch 2, gen_loss = 0.7638120966637792, disc_loss = 0.11741470103580619
Trained batch 326 in epoch 2, gen_loss = 0.7636882350167732, disc_loss = 0.11728375064727455
Trained batch 327 in epoch 2, gen_loss = 0.7640170105165098, disc_loss = 0.11718283951702732
Trained batch 328 in epoch 2, gen_loss = 0.7639927948318354, disc_loss = 0.1171046711849813
Trained batch 329 in epoch 2, gen_loss = 0.7636653489235675, disc_loss = 0.11707985687041372
Trained batch 330 in epoch 2, gen_loss = 0.7634500076943654, disc_loss = 0.11708032343469088
Trained batch 331 in epoch 2, gen_loss = 0.7641372496643698, disc_loss = 0.11724239158309457
Trained batch 332 in epoch 2, gen_loss = 0.7652169858908152, disc_loss = 0.11700736988872827
Trained batch 333 in epoch 2, gen_loss = 0.7646277720878224, disc_loss = 0.11716362499648672
Trained batch 334 in epoch 2, gen_loss = 0.7651374762627616, disc_loss = 0.11699090350085675
Trained batch 335 in epoch 2, gen_loss = 0.765305185867917, disc_loss = 0.11679533355969138
Trained batch 336 in epoch 2, gen_loss = 0.7647340144707824, disc_loss = 0.11672236190318443
Trained batch 337 in epoch 2, gen_loss = 0.7644146186183896, disc_loss = 0.11661933692304428
Trained batch 338 in epoch 2, gen_loss = 0.7645959120056974, disc_loss = 0.11657817973027275
Trained batch 339 in epoch 2, gen_loss = 0.7642089960329673, disc_loss = 0.11679810692337067
Trained batch 340 in epoch 2, gen_loss = 0.7649855649541201, disc_loss = 0.11680187187990572
Trained batch 341 in epoch 2, gen_loss = 0.7653088601883392, disc_loss = 0.11652525817997188
Trained batch 342 in epoch 2, gen_loss = 0.7655089830344342, disc_loss = 0.1162910451949642
Trained batch 343 in epoch 2, gen_loss = 0.7654529098681239, disc_loss = 0.11632209531908724
Trained batch 344 in epoch 2, gen_loss = 0.7655433799045673, disc_loss = 0.11617827934577413
Trained batch 345 in epoch 2, gen_loss = 0.7670008763240251, disc_loss = 0.1159744671050653
Trained batch 346 in epoch 2, gen_loss = 0.7670357157758059, disc_loss = 0.11575537950863327
Trained batch 347 in epoch 2, gen_loss = 0.767627918600351, disc_loss = 0.1154901331006924
Trained batch 348 in epoch 2, gen_loss = 0.7672358835836536, disc_loss = 0.11539588192675294
Trained batch 349 in epoch 2, gen_loss = 0.7670223247153418, disc_loss = 0.11534453580155969
Trained batch 350 in epoch 2, gen_loss = 0.7690319299188435, disc_loss = 0.11568686944244169
Trained batch 351 in epoch 2, gen_loss = 0.7689257844097235, disc_loss = 0.11562111542761241
Trained batch 352 in epoch 2, gen_loss = 0.7691285732616446, disc_loss = 0.11538234575474819
Trained batch 353 in epoch 2, gen_loss = 0.7689613407782916, disc_loss = 0.11525247512006406
Trained batch 354 in epoch 2, gen_loss = 0.7687411258757954, disc_loss = 0.11545448807710913
Trained batch 355 in epoch 2, gen_loss = 0.7694497336999754, disc_loss = 0.1153443888577978
Trained batch 356 in epoch 2, gen_loss = 0.7706410037536248, disc_loss = 0.11513342414865223
Trained batch 357 in epoch 2, gen_loss = 0.7706209878182279, disc_loss = 0.11499652962392852
Trained batch 358 in epoch 2, gen_loss = 0.7704631140803229, disc_loss = 0.1149336608168267
Trained batch 359 in epoch 2, gen_loss = 0.7707759851382838, disc_loss = 0.11471473540231171
Trained batch 360 in epoch 2, gen_loss = 0.7719568602761403, disc_loss = 0.11449283291005279
Trained batch 361 in epoch 2, gen_loss = 0.772906765177105, disc_loss = 0.1143327535243283
Trained batch 362 in epoch 2, gen_loss = 0.7730039063399816, disc_loss = 0.11410680845041167
Trained batch 363 in epoch 2, gen_loss = 0.7731570952704975, disc_loss = 0.11390471867551762
Trained batch 364 in epoch 2, gen_loss = 0.772569391907078, disc_loss = 0.11393645781105104
Trained batch 365 in epoch 2, gen_loss = 0.7737679039357138, disc_loss = 0.11375576191291702
Trained batch 366 in epoch 2, gen_loss = 0.7733272855710593, disc_loss = 0.11363896941486999
Trained batch 367 in epoch 2, gen_loss = 0.7728226222907719, disc_loss = 0.11365607991035137
Trained batch 368 in epoch 2, gen_loss = 0.7723728436926193, disc_loss = 0.1136937655765957
Trained batch 369 in epoch 2, gen_loss = 0.7723529993682294, disc_loss = 0.11382553121075034
Trained batch 370 in epoch 2, gen_loss = 0.7721225663497442, disc_loss = 0.11369739092053027
Trained batch 371 in epoch 2, gen_loss = 0.7715199314939079, disc_loss = 0.1137807489878508
Trained batch 372 in epoch 2, gen_loss = 0.7718480578536323, disc_loss = 0.1136200699940244
Trained batch 373 in epoch 2, gen_loss = 0.7717582443978059, disc_loss = 0.11363065592137808
Trained batch 374 in epoch 2, gen_loss = 0.7715581204891205, disc_loss = 0.11346005766342084
Trained batch 375 in epoch 2, gen_loss = 0.7719827238074009, disc_loss = 0.11324123445492079
Trained batch 376 in epoch 2, gen_loss = 0.7716175223693291, disc_loss = 0.11327338299469464
Trained batch 377 in epoch 2, gen_loss = 0.7712453405850779, disc_loss = 0.11335869943328872
Trained batch 378 in epoch 2, gen_loss = 0.7717445026444256, disc_loss = 0.11330098104184017
Trained batch 379 in epoch 2, gen_loss = 0.7732695840691265, disc_loss = 0.11318823673370246
Trained batch 380 in epoch 2, gen_loss = 0.7732102752826971, disc_loss = 0.11302319346753553
Trained batch 381 in epoch 2, gen_loss = 0.7723801522978937, disc_loss = 0.11400331687230948
Trained batch 382 in epoch 2, gen_loss = 0.7734181818700646, disc_loss = 0.11388501281516904
Trained batch 383 in epoch 2, gen_loss = 0.7737811527525386, disc_loss = 0.11407311398215825
Trained batch 384 in epoch 2, gen_loss = 0.7732521027713627, disc_loss = 0.11439979066467518
Trained batch 385 in epoch 2, gen_loss = 0.7727320961692791, disc_loss = 0.11447268467483357
Trained batch 386 in epoch 2, gen_loss = 0.7727128860254312, disc_loss = 0.11453410203133058
Trained batch 387 in epoch 2, gen_loss = 0.7725841785521851, disc_loss = 0.11446373344917503
Trained batch 388 in epoch 2, gen_loss = 0.7723593983061823, disc_loss = 0.11444080837195438
Trained batch 389 in epoch 2, gen_loss = 0.7721846552995535, disc_loss = 0.11439139823644207
Trained batch 390 in epoch 2, gen_loss = 0.7719852706355512, disc_loss = 0.11430181130109464
Trained batch 391 in epoch 2, gen_loss = 0.7720617241397196, disc_loss = 0.11421940074425799
Trained batch 392 in epoch 2, gen_loss = 0.7718232554637142, disc_loss = 0.11410672714075894
Trained batch 393 in epoch 2, gen_loss = 0.773000345919943, disc_loss = 0.11396001284790751
Trained batch 394 in epoch 2, gen_loss = 0.7729547227485271, disc_loss = 0.1138174661423398
Trained batch 395 in epoch 2, gen_loss = 0.7722051979766952, disc_loss = 0.11407345646964104
Trained batch 396 in epoch 2, gen_loss = 0.7720908451290515, disc_loss = 0.11413856489485322
Trained batch 397 in epoch 2, gen_loss = 0.7723888313800247, disc_loss = 0.11402336830722552
Trained batch 398 in epoch 2, gen_loss = 0.7727025683810538, disc_loss = 0.11391708117333196
Trained batch 399 in epoch 2, gen_loss = 0.7726758930832147, disc_loss = 0.113804953887593
Trained batch 400 in epoch 2, gen_loss = 0.7724322323638602, disc_loss = 0.11381756628345596
Trained batch 401 in epoch 2, gen_loss = 0.7731430331124595, disc_loss = 0.11362884814308873
Trained batch 402 in epoch 2, gen_loss = 0.7736308088817312, disc_loss = 0.11349940238746979
Trained batch 403 in epoch 2, gen_loss = 0.7734820971837139, disc_loss = 0.1133476871752761
Trained batch 404 in epoch 2, gen_loss = 0.7731543908148636, disc_loss = 0.11354882468549926
Trained batch 405 in epoch 2, gen_loss = 0.7740342519406614, disc_loss = 0.11343383631012931
Trained batch 406 in epoch 2, gen_loss = 0.7740666577066192, disc_loss = 0.11335437244870665
Trained batch 407 in epoch 2, gen_loss = 0.7740329767705179, disc_loss = 0.11320176230990053
Trained batch 408 in epoch 2, gen_loss = 0.7735458793879139, disc_loss = 0.1132796922980974
Trained batch 409 in epoch 2, gen_loss = 0.773683426510997, disc_loss = 0.11335411922006709
Trained batch 410 in epoch 2, gen_loss = 0.773606620348283, disc_loss = 0.11331376266368912
Trained batch 411 in epoch 2, gen_loss = 0.7731190153840676, disc_loss = 0.11333844987720758
Trained batch 412 in epoch 2, gen_loss = 0.7736364906838673, disc_loss = 0.11326476406378189
Trained batch 413 in epoch 2, gen_loss = 0.7744678513007464, disc_loss = 0.11319214607485467
Trained batch 414 in epoch 2, gen_loss = 0.7739077630531357, disc_loss = 0.11346591482814176
Trained batch 415 in epoch 2, gen_loss = 0.7741989446803927, disc_loss = 0.11325940473873813
Trained batch 416 in epoch 2, gen_loss = 0.7743754038850752, disc_loss = 0.11318605859725953
Trained batch 417 in epoch 2, gen_loss = 0.7748025455400704, disc_loss = 0.11296456634472503
Trained batch 418 in epoch 2, gen_loss = 0.7747349000062465, disc_loss = 0.1128004285882545
Trained batch 419 in epoch 2, gen_loss = 0.7743169175017448, disc_loss = 0.11291988085112756
Trained batch 420 in epoch 2, gen_loss = 0.7745507644785838, disc_loss = 0.1128889474411652
Trained batch 421 in epoch 2, gen_loss = 0.7745214897733164, disc_loss = 0.11280590819495055
Trained batch 422 in epoch 2, gen_loss = 0.7753053274419572, disc_loss = 0.11265205853700144
Trained batch 423 in epoch 2, gen_loss = 0.7747294739029318, disc_loss = 0.11275811777406214
Trained batch 424 in epoch 2, gen_loss = 0.7743490602689631, disc_loss = 0.11278288653010832
Trained batch 425 in epoch 2, gen_loss = 0.7752853628475341, disc_loss = 0.11284973039707177
Trained batch 426 in epoch 2, gen_loss = 0.7758979844125707, disc_loss = 0.11271041590912351
Trained batch 427 in epoch 2, gen_loss = 0.7754638016084644, disc_loss = 0.11288524465417821
Trained batch 428 in epoch 2, gen_loss = 0.7750733805286301, disc_loss = 0.11296209235543207
Trained batch 429 in epoch 2, gen_loss = 0.7751191124666569, disc_loss = 0.1133750072853683
Trained batch 430 in epoch 2, gen_loss = 0.7750297940385867, disc_loss = 0.11345841748782556
Trained batch 431 in epoch 2, gen_loss = 0.7744514390964199, disc_loss = 0.11367013127137734
Trained batch 432 in epoch 2, gen_loss = 0.7741793489759018, disc_loss = 0.11377178611960821
Trained batch 433 in epoch 2, gen_loss = 0.7742790775502333, disc_loss = 0.11380834384147541
Trained batch 434 in epoch 2, gen_loss = 0.773970387790395, disc_loss = 0.11399048307546597
Trained batch 435 in epoch 2, gen_loss = 0.7738231628996517, disc_loss = 0.11400621607600617
Trained batch 436 in epoch 2, gen_loss = 0.7733836392925315, disc_loss = 0.11409086252624506
Trained batch 437 in epoch 2, gen_loss = 0.7733015557538429, disc_loss = 0.11409343308960535
Trained batch 438 in epoch 2, gen_loss = 0.7733236136496203, disc_loss = 0.11424628232132669
Trained batch 439 in epoch 2, gen_loss = 0.7730597527867014, disc_loss = 0.11443318551279266
Trained batch 440 in epoch 2, gen_loss = 0.7728701394025971, disc_loss = 0.11446095955116746
Trained batch 441 in epoch 2, gen_loss = 0.773329976929259, disc_loss = 0.11453699346893041
Trained batch 442 in epoch 2, gen_loss = 0.7728572468321695, disc_loss = 0.11474874685676116
Trained batch 443 in epoch 2, gen_loss = 0.772855445138506, disc_loss = 0.1146649137613372
Trained batch 444 in epoch 2, gen_loss = 0.7727398350667418, disc_loss = 0.11500421426981018
Trained batch 445 in epoch 2, gen_loss = 0.7722536827283055, disc_loss = 0.11533427952826357
Trained batch 446 in epoch 2, gen_loss = 0.7717775527129503, disc_loss = 0.11553345376654826
Trained batch 447 in epoch 2, gen_loss = 0.7715929408025529, disc_loss = 0.11561144801297425
Trained batch 448 in epoch 2, gen_loss = 0.7712638552709252, disc_loss = 0.11564156638130645
Trained batch 449 in epoch 2, gen_loss = 0.7711624346176783, disc_loss = 0.11580093873250816
Trained batch 450 in epoch 2, gen_loss = 0.7709680933777879, disc_loss = 0.11583356277814792
Trained batch 451 in epoch 2, gen_loss = 0.7711614299796324, disc_loss = 0.11570540791896658
Trained batch 452 in epoch 2, gen_loss = 0.7715116103095461, disc_loss = 0.11555550290399105
Trained batch 453 in epoch 2, gen_loss = 0.7710207550404881, disc_loss = 0.11571092935000026
Trained batch 454 in epoch 2, gen_loss = 0.7708876047160599, disc_loss = 0.1157952228601981
Trained batch 455 in epoch 2, gen_loss = 0.7708777167687291, disc_loss = 0.11589116542886027
Trained batch 456 in epoch 2, gen_loss = 0.7704986824900629, disc_loss = 0.11587175899908697
Trained batch 457 in epoch 2, gen_loss = 0.7702020920129843, disc_loss = 0.11590412207248754
Trained batch 458 in epoch 2, gen_loss = 0.7708536168978365, disc_loss = 0.1159815235095898
Trained batch 459 in epoch 2, gen_loss = 0.771305937676326, disc_loss = 0.11586999245514365
Trained batch 460 in epoch 2, gen_loss = 0.7708178456719165, disc_loss = 0.11612933971302951
Trained batch 461 in epoch 2, gen_loss = 0.7705787103542517, disc_loss = 0.11627235092843573
Trained batch 462 in epoch 2, gen_loss = 0.7710055638724218, disc_loss = 0.1164931726398562
Trained batch 463 in epoch 2, gen_loss = 0.7707839205475717, disc_loss = 0.11644154003668769
Trained batch 464 in epoch 2, gen_loss = 0.7705686757000544, disc_loss = 0.11646378511582972
Trained batch 465 in epoch 2, gen_loss = 0.7705665011390596, disc_loss = 0.11637500561813748
Trained batch 466 in epoch 2, gen_loss = 0.770962666967441, disc_loss = 0.11642791761775408
Trained batch 467 in epoch 2, gen_loss = 0.7708057286775011, disc_loss = 0.11637575733554988
Trained batch 468 in epoch 2, gen_loss = 0.7704158983886369, disc_loss = 0.1163470757815407
Trained batch 469 in epoch 2, gen_loss = 0.7705391095673785, disc_loss = 0.11649012946266125
Trained batch 470 in epoch 2, gen_loss = 0.7700499628379847, disc_loss = 0.11652492591221432
Trained batch 471 in epoch 2, gen_loss = 0.7698114908979101, disc_loss = 0.11659951542969793
Trained batch 472 in epoch 2, gen_loss = 0.770306712036153, disc_loss = 0.11675978589204414
Trained batch 473 in epoch 2, gen_loss = 0.7700425291488945, disc_loss = 0.11688165008463751
Trained batch 474 in epoch 2, gen_loss = 0.7699541888111516, disc_loss = 0.117048875973805
Trained batch 475 in epoch 2, gen_loss = 0.7699169082676663, disc_loss = 0.11694480641745031
Trained batch 476 in epoch 2, gen_loss = 0.7699414211124245, disc_loss = 0.11683208062908997
Trained batch 477 in epoch 2, gen_loss = 0.7695420106958645, disc_loss = 0.11687421296999856
Trained batch 478 in epoch 2, gen_loss = 0.7698261978606341, disc_loss = 0.11706715912630078
Trained batch 479 in epoch 2, gen_loss = 0.7696215369428198, disc_loss = 0.11708529517248584
Trained batch 480 in epoch 2, gen_loss = 0.7694943908470336, disc_loss = 0.11707194036612453
Trained batch 481 in epoch 2, gen_loss = 0.7692750110542131, disc_loss = 0.11711539478230587
Trained batch 482 in epoch 2, gen_loss = 0.7693154184344393, disc_loss = 0.1170682600462196
Trained batch 483 in epoch 2, gen_loss = 0.7694797628551475, disc_loss = 0.11692020523531194
Trained batch 484 in epoch 2, gen_loss = 0.7691687583308859, disc_loss = 0.11701178561665655
Trained batch 485 in epoch 2, gen_loss = 0.7690580512393158, disc_loss = 0.11711967707546467
Trained batch 486 in epoch 2, gen_loss = 0.7692302554172656, disc_loss = 0.11708310711746404
Trained batch 487 in epoch 2, gen_loss = 0.7692800416443192, disc_loss = 0.11707009173754114
Trained batch 488 in epoch 2, gen_loss = 0.7690353527025211, disc_loss = 0.1170913948561303
Trained batch 489 in epoch 2, gen_loss = 0.7691102927436634, disc_loss = 0.1172519814318084
Trained batch 490 in epoch 2, gen_loss = 0.7685534907334205, disc_loss = 0.11734331127772081
Trained batch 491 in epoch 2, gen_loss = 0.76871677003498, disc_loss = 0.11738246939962775
Trained batch 492 in epoch 2, gen_loss = 0.7682920484586372, disc_loss = 0.11749021763560073
Trained batch 493 in epoch 2, gen_loss = 0.7678994378942227, disc_loss = 0.11745459954574825
Trained batch 494 in epoch 2, gen_loss = 0.7681343475375513, disc_loss = 0.11749921745310227
Trained batch 495 in epoch 2, gen_loss = 0.767904142518678, disc_loss = 0.11747302247339018
Trained batch 496 in epoch 2, gen_loss = 0.7678802642424102, disc_loss = 0.11743272865149877
Trained batch 497 in epoch 2, gen_loss = 0.7680759730947065, disc_loss = 0.11741052373652777
Trained batch 498 in epoch 2, gen_loss = 0.7679592069380269, disc_loss = 0.11729758413683974
Trained batch 499 in epoch 2, gen_loss = 0.7676168956160545, disc_loss = 0.117442851068452
Trained batch 500 in epoch 2, gen_loss = 0.7671405773557827, disc_loss = 0.11754769851414565
Trained batch 501 in epoch 2, gen_loss = 0.7670739955042463, disc_loss = 0.11752612032627026
Trained batch 502 in epoch 2, gen_loss = 0.766606047838393, disc_loss = 0.11751251623486252
Trained batch 503 in epoch 2, gen_loss = 0.7671802786016275, disc_loss = 0.11766696099140164
Trained batch 504 in epoch 2, gen_loss = 0.7668653707102974, disc_loss = 0.1177929912924324
Trained batch 505 in epoch 2, gen_loss = 0.7666303356998994, disc_loss = 0.11770175082476537
Trained batch 506 in epoch 2, gen_loss = 0.7668054244339584, disc_loss = 0.11765636446567976
Trained batch 507 in epoch 2, gen_loss = 0.7665549917366561, disc_loss = 0.11771262708618709
Trained batch 508 in epoch 2, gen_loss = 0.7664081259303103, disc_loss = 0.11761639464997882
Trained batch 509 in epoch 2, gen_loss = 0.7671559900045395, disc_loss = 0.11755939506030842
Trained batch 510 in epoch 2, gen_loss = 0.766853294552189, disc_loss = 0.11759830652799917
Trained batch 511 in epoch 2, gen_loss = 0.7671242039068602, disc_loss = 0.11754788135476701
Trained batch 512 in epoch 2, gen_loss = 0.7673224900317238, disc_loss = 0.11739718972307722
Trained batch 513 in epoch 2, gen_loss = 0.7676820589758543, disc_loss = 0.11723644759121862
Trained batch 514 in epoch 2, gen_loss = 0.7675056211578036, disc_loss = 0.117126569030716
Trained batch 515 in epoch 2, gen_loss = 0.7671623808122421, disc_loss = 0.11725071542751939
Trained batch 516 in epoch 2, gen_loss = 0.7676552204952019, disc_loss = 0.11722101550188989
Trained batch 517 in epoch 2, gen_loss = 0.7677425038515371, disc_loss = 0.1171002236633601
Trained batch 518 in epoch 2, gen_loss = 0.7679824900879796, disc_loss = 0.1170116910703753
Trained batch 519 in epoch 2, gen_loss = 0.7674905907076138, disc_loss = 0.11716460252646357
Trained batch 520 in epoch 2, gen_loss = 0.7671959971626523, disc_loss = 0.11724908231809421
Trained batch 521 in epoch 2, gen_loss = 0.7679853849826644, disc_loss = 0.11756362491447864
Trained batch 522 in epoch 2, gen_loss = 0.7677232195154886, disc_loss = 0.11752483456165852
Trained batch 523 in epoch 2, gen_loss = 0.7676238006421627, disc_loss = 0.1174372980132955
Trained batch 524 in epoch 2, gen_loss = 0.7671844506831397, disc_loss = 0.11746416405020725
Trained batch 525 in epoch 2, gen_loss = 0.7668934636129626, disc_loss = 0.11761997969636956
Trained batch 526 in epoch 2, gen_loss = 0.7674983777742006, disc_loss = 0.11786190142759619
Trained batch 527 in epoch 2, gen_loss = 0.7672523830763318, disc_loss = 0.11785285359170909
Trained batch 528 in epoch 2, gen_loss = 0.7670683790357442, disc_loss = 0.1179747922972746
Trained batch 529 in epoch 2, gen_loss = 0.767245987844917, disc_loss = 0.11801601227478317
Trained batch 530 in epoch 2, gen_loss = 0.7671519934906573, disc_loss = 0.11807574893886368
Trained batch 531 in epoch 2, gen_loss = 0.7666231830205236, disc_loss = 0.11820441743015851
Trained batch 532 in epoch 2, gen_loss = 0.7664888262413232, disc_loss = 0.1182541903789814
Trained batch 533 in epoch 2, gen_loss = 0.7665314836783356, disc_loss = 0.11837913113565983
Trained batch 534 in epoch 2, gen_loss = 0.7663663932653231, disc_loss = 0.11828943551735621
Trained batch 535 in epoch 2, gen_loss = 0.7662308477977319, disc_loss = 0.11830103474690008
Trained batch 536 in epoch 2, gen_loss = 0.7664122796258447, disc_loss = 0.11850034501889176
Trained batch 537 in epoch 2, gen_loss = 0.7659237654568094, disc_loss = 0.11865323651270408
Trained batch 538 in epoch 2, gen_loss = 0.7663581492396586, disc_loss = 0.11851342013606833
Trained batch 539 in epoch 2, gen_loss = 0.766602778269185, disc_loss = 0.11840600128699508
Trained batch 540 in epoch 2, gen_loss = 0.7667470377716692, disc_loss = 0.1182227902365728
Trained batch 541 in epoch 2, gen_loss = 0.766426453676171, disc_loss = 0.11821409062107825
Trained batch 542 in epoch 2, gen_loss = 0.7661964562387098, disc_loss = 0.11814934841458365
Trained batch 543 in epoch 2, gen_loss = 0.7660510615062188, disc_loss = 0.11813019021749771
Trained batch 544 in epoch 2, gen_loss = 0.7661499820171146, disc_loss = 0.11799149749920182
Trained batch 545 in epoch 2, gen_loss = 0.7660116628085301, disc_loss = 0.11791345504566263
Trained batch 546 in epoch 2, gen_loss = 0.7658092356142222, disc_loss = 0.11797387203477473
Trained batch 547 in epoch 2, gen_loss = 0.7661852447764717, disc_loss = 0.11798986180916592
Trained batch 548 in epoch 2, gen_loss = 0.7660187893769346, disc_loss = 0.11786785756555031
Trained batch 549 in epoch 2, gen_loss = 0.7654883270372044, disc_loss = 0.11805964737622575
Trained batch 550 in epoch 2, gen_loss = 0.7658082846612982, disc_loss = 0.11792815973755723
Trained batch 551 in epoch 2, gen_loss = 0.7664483304580917, disc_loss = 0.11800346867201607
Trained batch 552 in epoch 2, gen_loss = 0.7661522860229554, disc_loss = 0.11816634004177765
Trained batch 553 in epoch 2, gen_loss = 0.7660540473052311, disc_loss = 0.1180155415387172
Trained batch 554 in epoch 2, gen_loss = 0.7659570753574372, disc_loss = 0.11824682700103736
Trained batch 555 in epoch 2, gen_loss = 0.7658581456584896, disc_loss = 0.11818903905888953
Trained batch 556 in epoch 2, gen_loss = 0.7659637921053375, disc_loss = 0.1180581839327137
Trained batch 557 in epoch 2, gen_loss = 0.7657215616074942, disc_loss = 0.118006027662479
Trained batch 558 in epoch 2, gen_loss = 0.7658649134401345, disc_loss = 0.11794929675697907
Trained batch 559 in epoch 2, gen_loss = 0.7653943201793092, disc_loss = 0.11799412755728034
Trained batch 560 in epoch 2, gen_loss = 0.7652209705528729, disc_loss = 0.11795660440516186
Trained batch 561 in epoch 2, gen_loss = 0.7653556092247844, disc_loss = 0.11814756454316587
Trained batch 562 in epoch 2, gen_loss = 0.765055483812549, disc_loss = 0.118145567328598
Trained batch 563 in epoch 2, gen_loss = 0.764798288385496, disc_loss = 0.1181710843303974
Trained batch 564 in epoch 2, gen_loss = 0.7649283943450557, disc_loss = 0.11821559604455148
Trained batch 565 in epoch 2, gen_loss = 0.7646299229388523, disc_loss = 0.11825475657635201
Trained batch 566 in epoch 2, gen_loss = 0.7646676816532431, disc_loss = 0.11812633464057032
Trained batch 567 in epoch 2, gen_loss = 0.7643610449429129, disc_loss = 0.11805934553578969
Trained batch 568 in epoch 2, gen_loss = 0.7647314956297145, disc_loss = 0.11792769835793752
Trained batch 569 in epoch 2, gen_loss = 0.7646991504388944, disc_loss = 0.1178763898203901
Trained batch 570 in epoch 2, gen_loss = 0.7645547388418334, disc_loss = 0.1178388618040445
Trained batch 571 in epoch 2, gen_loss = 0.7644515178732939, disc_loss = 0.11777954949945263
Trained batch 572 in epoch 2, gen_loss = 0.7653594222472392, disc_loss = 0.11783206632058502
Trained batch 573 in epoch 2, gen_loss = 0.7655616057355229, disc_loss = 0.11766874000514478
Trained batch 574 in epoch 2, gen_loss = 0.7653746635499208, disc_loss = 0.11758033477255832
Trained batch 575 in epoch 2, gen_loss = 0.765701767626322, disc_loss = 0.11752240275220377
Trained batch 576 in epoch 2, gen_loss = 0.765682149852789, disc_loss = 0.11739678921232861
Trained batch 577 in epoch 2, gen_loss = 0.7654416898851989, disc_loss = 0.1172861399332055
Trained batch 578 in epoch 2, gen_loss = 0.7653603775616549, disc_loss = 0.11732079116514979
Trained batch 579 in epoch 2, gen_loss = 0.7652611143116294, disc_loss = 0.11728956930114534
Trained batch 580 in epoch 2, gen_loss = 0.7651807599654501, disc_loss = 0.1171957916835012
Trained batch 581 in epoch 2, gen_loss = 0.7662266057074275, disc_loss = 0.11720585515338582
Trained batch 582 in epoch 2, gen_loss = 0.766118122261548, disc_loss = 0.11719535171864219
Trained batch 583 in epoch 2, gen_loss = 0.7661822951105359, disc_loss = 0.1172058515279388
Trained batch 584 in epoch 2, gen_loss = 0.7665571882684007, disc_loss = 0.11718654127743763
Trained batch 585 in epoch 2, gen_loss = 0.7667141800345821, disc_loss = 0.1171075398684082
Trained batch 586 in epoch 2, gen_loss = 0.7669645779888309, disc_loss = 0.11697706226830638
Trained batch 587 in epoch 2, gen_loss = 0.7668924833945676, disc_loss = 0.11687724763166388
Trained batch 588 in epoch 2, gen_loss = 0.7670625382955288, disc_loss = 0.11677456917383523
Trained batch 589 in epoch 2, gen_loss = 0.7671624651904834, disc_loss = 0.11663401022206171
Trained batch 590 in epoch 2, gen_loss = 0.7670496653280081, disc_loss = 0.11658519187661648
Trained batch 591 in epoch 2, gen_loss = 0.7673496750460284, disc_loss = 0.11650645710383165
Trained batch 592 in epoch 2, gen_loss = 0.7680043839986167, disc_loss = 0.11639855783369901
Trained batch 593 in epoch 2, gen_loss = 0.7678434611470611, disc_loss = 0.11631161552894648
Trained batch 594 in epoch 2, gen_loss = 0.7675905847248911, disc_loss = 0.11640915055641858
Trained batch 595 in epoch 2, gen_loss = 0.7682878497562953, disc_loss = 0.11666327346297568
Trained batch 596 in epoch 2, gen_loss = 0.768626854597424, disc_loss = 0.1166639312543287
Trained batch 597 in epoch 2, gen_loss = 0.7688442374451901, disc_loss = 0.11650982599886116
Trained batch 598 in epoch 2, gen_loss = 0.76861663050763, disc_loss = 0.1165972009335391
Trained batch 599 in epoch 2, gen_loss = 0.7686958103875319, disc_loss = 0.11644166212063282
Trained batch 600 in epoch 2, gen_loss = 0.769038886228536, disc_loss = 0.11632110579667641
Trained batch 601 in epoch 2, gen_loss = 0.768686654015237, disc_loss = 0.11631006806426715
Trained batch 602 in epoch 2, gen_loss = 0.7686283603730684, disc_loss = 0.11628336366266012
Trained batch 603 in epoch 2, gen_loss = 0.7686589353822715, disc_loss = 0.11626591550229451
Trained batch 604 in epoch 2, gen_loss = 0.7689180511581011, disc_loss = 0.1161695982937601
Trained batch 605 in epoch 2, gen_loss = 0.768561126326177, disc_loss = 0.11615723047079672
Trained batch 606 in epoch 2, gen_loss = 0.7696791354572949, disc_loss = 0.1162449716555056
Trained batch 607 in epoch 2, gen_loss = 0.7694715839369517, disc_loss = 0.11626319776099224
Trained batch 608 in epoch 2, gen_loss = 0.7692065426379393, disc_loss = 0.11654089415852709
Trained batch 609 in epoch 2, gen_loss = 0.7687591176052563, disc_loss = 0.11662912600994355
Trained batch 610 in epoch 2, gen_loss = 0.7688486246840263, disc_loss = 0.11663463268026636
Trained batch 611 in epoch 2, gen_loss = 0.768943528675176, disc_loss = 0.11651006276000997
Trained batch 612 in epoch 2, gen_loss = 0.7687915292785763, disc_loss = 0.11660790123306762
Trained batch 613 in epoch 2, gen_loss = 0.7684868080511156, disc_loss = 0.11661972624404471
Trained batch 614 in epoch 2, gen_loss = 0.7683320592573988, disc_loss = 0.11657428324252851
Trained batch 615 in epoch 2, gen_loss = 0.768537477384527, disc_loss = 0.11649428001550546
Trained batch 616 in epoch 2, gen_loss = 0.7683344141880543, disc_loss = 0.11644930555070093
Trained batch 617 in epoch 2, gen_loss = 0.7684791917071759, disc_loss = 0.11641945152974485
Trained batch 618 in epoch 2, gen_loss = 0.768277015699516, disc_loss = 0.11637427664613155
Trained batch 619 in epoch 2, gen_loss = 0.7680011738211878, disc_loss = 0.11639601663506079
Trained batch 620 in epoch 2, gen_loss = 0.768237148170118, disc_loss = 0.11643831770951094
Trained batch 621 in epoch 2, gen_loss = 0.7682581334539549, disc_loss = 0.11633515235342061
Trained batch 622 in epoch 2, gen_loss = 0.7685277654787893, disc_loss = 0.11617676153880684
Trained batch 623 in epoch 2, gen_loss = 0.7685344516753386, disc_loss = 0.11606067716508196
Trained batch 624 in epoch 2, gen_loss = 0.7683882847309113, disc_loss = 0.11598221930414439
Trained batch 625 in epoch 2, gen_loss = 0.7687901754063159, disc_loss = 0.11587755292350539
Trained batch 626 in epoch 2, gen_loss = 0.7690324435869093, disc_loss = 0.11580523927703476
Trained batch 627 in epoch 2, gen_loss = 0.7689297629674529, disc_loss = 0.11587085943390277
Trained batch 628 in epoch 2, gen_loss = 0.768948508986229, disc_loss = 0.11579862323001809
Trained batch 629 in epoch 2, gen_loss = 0.769444985474859, disc_loss = 0.11580161249619864
Trained batch 630 in epoch 2, gen_loss = 0.7693074152416737, disc_loss = 0.11575584475647675
Trained batch 631 in epoch 2, gen_loss = 0.7693430331028714, disc_loss = 0.11563838321179198
Trained batch 632 in epoch 2, gen_loss = 0.7699732455126294, disc_loss = 0.11571998741936769
Trained batch 633 in epoch 2, gen_loss = 0.7698109976782783, disc_loss = 0.11583335413994145
Trained batch 634 in epoch 2, gen_loss = 0.7699143554751329, disc_loss = 0.11569775154770125
Trained batch 635 in epoch 2, gen_loss = 0.7697147133309137, disc_loss = 0.11571145453197448
Trained batch 636 in epoch 2, gen_loss = 0.7695839148207774, disc_loss = 0.11569587942037375
Trained batch 637 in epoch 2, gen_loss = 0.7699910855872504, disc_loss = 0.11561729680297189
Trained batch 638 in epoch 2, gen_loss = 0.7701349810162247, disc_loss = 0.11547028980653658
Trained batch 639 in epoch 2, gen_loss = 0.7701915218960493, disc_loss = 0.11542637389648007
Trained batch 640 in epoch 2, gen_loss = 0.770150525661043, disc_loss = 0.1153028557228154
Trained batch 641 in epoch 2, gen_loss = 0.7706149643362497, disc_loss = 0.11516974790230672
Trained batch 642 in epoch 2, gen_loss = 0.7708159696722104, disc_loss = 0.11504226342903835
Trained batch 643 in epoch 2, gen_loss = 0.7706415788820071, disc_loss = 0.11511908105273748
Trained batch 644 in epoch 2, gen_loss = 0.7712581984294478, disc_loss = 0.11517030265644308
Trained batch 645 in epoch 2, gen_loss = 0.7712115247275438, disc_loss = 0.11509399820009575
Trained batch 646 in epoch 2, gen_loss = 0.7712623644188346, disc_loss = 0.1151165175287649
Trained batch 647 in epoch 2, gen_loss = 0.7711355201900005, disc_loss = 0.11506767403535591
Trained batch 648 in epoch 2, gen_loss = 0.7713230654069199, disc_loss = 0.11504802482492521
Trained batch 649 in epoch 2, gen_loss = 0.7722055573188341, disc_loss = 0.11519702478526876
Trained batch 650 in epoch 2, gen_loss = 0.7717095474310551, disc_loss = 0.11555112898778942
Trained batch 651 in epoch 2, gen_loss = 0.771655978234999, disc_loss = 0.11552838938156475
Trained batch 652 in epoch 2, gen_loss = 0.7719520975765737, disc_loss = 0.11554014530306708
Trained batch 653 in epoch 2, gen_loss = 0.7717641520937648, disc_loss = 0.11553824198964859
Trained batch 654 in epoch 2, gen_loss = 0.7719232649293565, disc_loss = 0.1154094505102466
Trained batch 655 in epoch 2, gen_loss = 0.771896795165248, disc_loss = 0.11535534962710765
Trained batch 656 in epoch 2, gen_loss = 0.7718678943279853, disc_loss = 0.1152597572441855
Trained batch 657 in epoch 2, gen_loss = 0.7720173212351408, disc_loss = 0.11516915007400974
Trained batch 658 in epoch 2, gen_loss = 0.7723647302669531, disc_loss = 0.11503469093656096
Trained batch 659 in epoch 2, gen_loss = 0.7723555719310587, disc_loss = 0.11498568446206098
Trained batch 660 in epoch 2, gen_loss = 0.7723719742763421, disc_loss = 0.11485221615531757
Trained batch 661 in epoch 2, gen_loss = 0.7721568559411789, disc_loss = 0.11476990751488826
Trained batch 662 in epoch 2, gen_loss = 0.7722801873586836, disc_loss = 0.11472407759758636
Trained batch 663 in epoch 2, gen_loss = 0.7725100724632481, disc_loss = 0.11464826354100537
Trained batch 664 in epoch 2, gen_loss = 0.7728119458471026, disc_loss = 0.11451576824503061
Trained batch 665 in epoch 2, gen_loss = 0.772859463373104, disc_loss = 0.11443772106137765
Trained batch 666 in epoch 2, gen_loss = 0.7731566049348468, disc_loss = 0.11429398743270978
Trained batch 667 in epoch 2, gen_loss = 0.7731427414688522, disc_loss = 0.11418225349228227
Trained batch 668 in epoch 2, gen_loss = 0.7734868496166395, disc_loss = 0.11412690146248482
Trained batch 669 in epoch 2, gen_loss = 0.7737414633160207, disc_loss = 0.11398955891742858
Trained batch 670 in epoch 2, gen_loss = 0.773813690940243, disc_loss = 0.11385716337588478
Trained batch 671 in epoch 2, gen_loss = 0.7736402867982785, disc_loss = 0.11387753038295723
Trained batch 672 in epoch 2, gen_loss = 0.7743018306736429, disc_loss = 0.1138203665904734
Trained batch 673 in epoch 2, gen_loss = 0.7748485404765925, disc_loss = 0.11378329596136771
Trained batch 674 in epoch 2, gen_loss = 0.774922511930819, disc_loss = 0.1137015964159811
Trained batch 675 in epoch 2, gen_loss = 0.7747747292356378, disc_loss = 0.11365458330817345
Trained batch 676 in epoch 2, gen_loss = 0.7749525399292589, disc_loss = 0.11351445709194223
Trained batch 677 in epoch 2, gen_loss = 0.7752063957463323, disc_loss = 0.11347305358340827
Trained batch 678 in epoch 2, gen_loss = 0.7756012942373138, disc_loss = 0.11332144801517255
Trained batch 679 in epoch 2, gen_loss = 0.7754886058323524, disc_loss = 0.11321139797321794
Trained batch 680 in epoch 2, gen_loss = 0.7754613926932326, disc_loss = 0.1132192114264145
Trained batch 681 in epoch 2, gen_loss = 0.775064885878493, disc_loss = 0.11318286361249268
Trained batch 682 in epoch 2, gen_loss = 0.7752118661323368, disc_loss = 0.11313216601352523
Trained batch 683 in epoch 2, gen_loss = 0.7754791133236467, disc_loss = 0.11301603440974148
Trained batch 684 in epoch 2, gen_loss = 0.775383702159798, disc_loss = 0.11290574809468358
Trained batch 685 in epoch 2, gen_loss = 0.7753155660698782, disc_loss = 0.11283618946350654
Trained batch 686 in epoch 2, gen_loss = 0.7756721773869433, disc_loss = 0.11274710510555096
Trained batch 687 in epoch 2, gen_loss = 0.7760191034785536, disc_loss = 0.11274979725279737
Trained batch 688 in epoch 2, gen_loss = 0.7765817507258002, disc_loss = 0.11262985500703053
Trained batch 689 in epoch 2, gen_loss = 0.7766024174897567, disc_loss = 0.11254910585483995
Trained batch 690 in epoch 2, gen_loss = 0.7763741243247876, disc_loss = 0.11254994603151566
Trained batch 691 in epoch 2, gen_loss = 0.7768173947327399, disc_loss = 0.11268449548465022
Trained batch 692 in epoch 2, gen_loss = 0.7768375358368239, disc_loss = 0.11260772892240364
Trained batch 693 in epoch 2, gen_loss = 0.7768518600065357, disc_loss = 0.11256172907503821
Trained batch 694 in epoch 2, gen_loss = 0.7770137352909116, disc_loss = 0.11247563926141253
Trained batch 695 in epoch 2, gen_loss = 0.7769149490471544, disc_loss = 0.11237618419336391
Trained batch 696 in epoch 2, gen_loss = 0.7775400533224623, disc_loss = 0.11229757708196703
Trained batch 697 in epoch 2, gen_loss = 0.7778751616150056, disc_loss = 0.11215849928050849
Trained batch 698 in epoch 2, gen_loss = 0.7778193469722895, disc_loss = 0.11212686926408941
Trained batch 699 in epoch 2, gen_loss = 0.7777825385332108, disc_loss = 0.11205378304767821
Trained batch 700 in epoch 2, gen_loss = 0.7780830141651137, disc_loss = 0.11204310597057392
Trained batch 701 in epoch 2, gen_loss = 0.7782822450851103, disc_loss = 0.11191987614160631
Trained batch 702 in epoch 2, gen_loss = 0.7781656314943457, disc_loss = 0.111894486158037
Trained batch 703 in epoch 2, gen_loss = 0.7778581099754031, disc_loss = 0.11204422991960944
Trained batch 704 in epoch 2, gen_loss = 0.7777467144296525, disc_loss = 0.11203446163802494
Trained batch 705 in epoch 2, gen_loss = 0.7784333191917571, disc_loss = 0.11202379013873405
Trained batch 706 in epoch 2, gen_loss = 0.7783612597106707, disc_loss = 0.11200991792069508
Trained batch 707 in epoch 2, gen_loss = 0.7784521092297667, disc_loss = 0.1119386673060451
Trained batch 708 in epoch 2, gen_loss = 0.7784640487225671, disc_loss = 0.1119789422485762
Trained batch 709 in epoch 2, gen_loss = 0.7782357309905577, disc_loss = 0.11198412578316852
Trained batch 710 in epoch 2, gen_loss = 0.7783584654247375, disc_loss = 0.11188318989725597
Trained batch 711 in epoch 2, gen_loss = 0.7783622039335497, disc_loss = 0.11183913480725893
Trained batch 712 in epoch 2, gen_loss = 0.7782031815149005, disc_loss = 0.11180968061847113
Trained batch 713 in epoch 2, gen_loss = 0.7779942868637437, disc_loss = 0.11183107193136792
Trained batch 714 in epoch 2, gen_loss = 0.7780207657313847, disc_loss = 0.1117866143440971
Trained batch 715 in epoch 2, gen_loss = 0.7779067546628707, disc_loss = 0.11176779741998866
Trained batch 716 in epoch 2, gen_loss = 0.7781234949702498, disc_loss = 0.11166319355103635
Trained batch 717 in epoch 2, gen_loss = 0.777885189876583, disc_loss = 0.11167307764753533
Trained batch 718 in epoch 2, gen_loss = 0.7782590169568386, disc_loss = 0.11166758878967402
Trained batch 719 in epoch 2, gen_loss = 0.7779892564647728, disc_loss = 0.11178031377623686
Trained batch 720 in epoch 2, gen_loss = 0.7782900626054253, disc_loss = 0.11180452440430032
Trained batch 721 in epoch 2, gen_loss = 0.7783487650496147, disc_loss = 0.11174536566701498
Trained batch 722 in epoch 2, gen_loss = 0.7781180911703888, disc_loss = 0.11174081051709288
Trained batch 723 in epoch 2, gen_loss = 0.7782254750886675, disc_loss = 0.11164364769915891
Trained batch 724 in epoch 2, gen_loss = 0.7780598860773547, disc_loss = 0.11161579579757205
Trained batch 725 in epoch 2, gen_loss = 0.7781748964602625, disc_loss = 0.11162692115105914
Trained batch 726 in epoch 2, gen_loss = 0.7777789263810547, disc_loss = 0.11172584678588289
Trained batch 727 in epoch 2, gen_loss = 0.7779693182680633, disc_loss = 0.11180635529012511
Trained batch 728 in epoch 2, gen_loss = 0.7777750219010194, disc_loss = 0.11172144204526321
Trained batch 729 in epoch 2, gen_loss = 0.7776510766107743, disc_loss = 0.11169840996217442
Trained batch 730 in epoch 2, gen_loss = 0.777847406476043, disc_loss = 0.11162470205828405
Trained batch 731 in epoch 2, gen_loss = 0.7779521655515244, disc_loss = 0.11155815196701942
Trained batch 732 in epoch 2, gen_loss = 0.7778253587824261, disc_loss = 0.11151268362800755
Trained batch 733 in epoch 2, gen_loss = 0.7774648698863931, disc_loss = 0.11155529527440261
Trained batch 734 in epoch 2, gen_loss = 0.7777382994995636, disc_loss = 0.11155076239916946
Trained batch 735 in epoch 2, gen_loss = 0.7775005703063115, disc_loss = 0.11160232867848169
Trained batch 736 in epoch 2, gen_loss = 0.7774422473629262, disc_loss = 0.11153950810235302
Trained batch 737 in epoch 2, gen_loss = 0.7777762173152551, disc_loss = 0.11167409822349827
Trained batch 738 in epoch 2, gen_loss = 0.7775738681282177, disc_loss = 0.11169431057250749
Trained batch 739 in epoch 2, gen_loss = 0.7772378811965117, disc_loss = 0.1117724445837273
Trained batch 740 in epoch 2, gen_loss = 0.7772321512020229, disc_loss = 0.11181694842427567
Trained batch 741 in epoch 2, gen_loss = 0.7775031337037562, disc_loss = 0.11193220819549941
Trained batch 742 in epoch 2, gen_loss = 0.7773043912801576, disc_loss = 0.11200634615864319
Trained batch 743 in epoch 2, gen_loss = 0.7773826469176559, disc_loss = 0.11198636787437824
Trained batch 744 in epoch 2, gen_loss = 0.7772912999927598, disc_loss = 0.11195519240635554
Trained batch 745 in epoch 2, gen_loss = 0.7776656257882515, disc_loss = 0.11216703638679101
Trained batch 746 in epoch 2, gen_loss = 0.7777551407794876, disc_loss = 0.11211043604371577
Trained batch 747 in epoch 2, gen_loss = 0.7774303729202658, disc_loss = 0.1123209165790203
Trained batch 748 in epoch 2, gen_loss = 0.7773889720201174, disc_loss = 0.11227896210870572
Trained batch 749 in epoch 2, gen_loss = 0.7775036667188009, disc_loss = 0.11225637494648497
Trained batch 750 in epoch 2, gen_loss = 0.7771091044504697, disc_loss = 0.1123601295731059
Trained batch 751 in epoch 2, gen_loss = 0.7777136447740362, disc_loss = 0.11241766387482788
Trained batch 752 in epoch 2, gen_loss = 0.777372144687065, disc_loss = 0.1125512758250117
Trained batch 753 in epoch 2, gen_loss = 0.7774038916399372, disc_loss = 0.11253405447471244
Trained batch 754 in epoch 2, gen_loss = 0.7774694843008029, disc_loss = 0.11250716510123962
Trained batch 755 in epoch 2, gen_loss = 0.7771598579233916, disc_loss = 0.11257742596765556
Trained batch 756 in epoch 2, gen_loss = 0.7770151873875798, disc_loss = 0.11256244340776177
Trained batch 757 in epoch 2, gen_loss = 0.7776790337543689, disc_loss = 0.11261691470657498
Trained batch 758 in epoch 2, gen_loss = 0.7777409730221443, disc_loss = 0.11257224025545895
Trained batch 759 in epoch 2, gen_loss = 0.777775171163835, disc_loss = 0.1124650130991971
Trained batch 760 in epoch 2, gen_loss = 0.7778224137546825, disc_loss = 0.11237137420678146
Trained batch 761 in epoch 2, gen_loss = 0.7778565352513721, disc_loss = 0.11227475441723397
Trained batch 762 in epoch 2, gen_loss = 0.7779997400500046, disc_loss = 0.11231409121294986
Trained batch 763 in epoch 2, gen_loss = 0.777781845543397, disc_loss = 0.11242980877283706
Trained batch 764 in epoch 2, gen_loss = 0.7775259119233274, disc_loss = 0.11248072452624054
Trained batch 765 in epoch 2, gen_loss = 0.7775527434156084, disc_loss = 0.11239743578143165
Trained batch 766 in epoch 2, gen_loss = 0.777822132760263, disc_loss = 0.11243701535926687
Trained batch 767 in epoch 2, gen_loss = 0.7778823263167093, disc_loss = 0.11241406119976698
Trained batch 768 in epoch 2, gen_loss = 0.7777414392432869, disc_loss = 0.11239226192589583
Trained batch 769 in epoch 2, gen_loss = 0.7775190811652641, disc_loss = 0.11234415987409747
Trained batch 770 in epoch 2, gen_loss = 0.7771786064025493, disc_loss = 0.11244979756974872
Trained batch 771 in epoch 2, gen_loss = 0.7774987522647788, disc_loss = 0.11252187882607967
Trained batch 772 in epoch 2, gen_loss = 0.7776906583626859, disc_loss = 0.11242724207252804
Trained batch 773 in epoch 2, gen_loss = 0.7774453732240416, disc_loss = 0.1123858918219285
Trained batch 774 in epoch 2, gen_loss = 0.7772422089884358, disc_loss = 0.1123539333490114
Trained batch 775 in epoch 2, gen_loss = 0.7774211628381739, disc_loss = 0.11227622976377799
Trained batch 776 in epoch 2, gen_loss = 0.7777177220452552, disc_loss = 0.11226304398641047
Trained batch 777 in epoch 2, gen_loss = 0.7778035339475597, disc_loss = 0.11218129564914613
Trained batch 778 in epoch 2, gen_loss = 0.7779198303455259, disc_loss = 0.11206900415552327
Trained batch 779 in epoch 2, gen_loss = 0.7779556823846622, disc_loss = 0.11196365448502966
Trained batch 780 in epoch 2, gen_loss = 0.7781700097339254, disc_loss = 0.11188119535290286
Trained batch 781 in epoch 2, gen_loss = 0.7783652618717964, disc_loss = 0.11182009882134054
Trained batch 782 in epoch 2, gen_loss = 0.7789666471505683, disc_loss = 0.11176630981994429
Trained batch 783 in epoch 2, gen_loss = 0.7787383261079691, disc_loss = 0.11185977687674327
Trained batch 784 in epoch 2, gen_loss = 0.7787994147865636, disc_loss = 0.11181382285253068
Trained batch 785 in epoch 2, gen_loss = 0.7787601015798311, disc_loss = 0.11177869172264412
Trained batch 786 in epoch 2, gen_loss = 0.7788914906327273, disc_loss = 0.1118378429324514
Trained batch 787 in epoch 2, gen_loss = 0.7790092125459371, disc_loss = 0.11178816857672093
Trained batch 788 in epoch 2, gen_loss = 0.778705926373582, disc_loss = 0.11188576627211086
Trained batch 789 in epoch 2, gen_loss = 0.7787790305252317, disc_loss = 0.1119202463769743
Testing Epoch 2

Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.7787734866142273, disc_loss = 0.04799189046025276
Trained batch 1 in epoch 3, gen_loss = 0.7263126969337463, disc_loss = 0.07597834803164005
Trained batch 2 in epoch 3, gen_loss = 0.6903225183486938, disc_loss = 0.07600776727000873
Trained batch 3 in epoch 3, gen_loss = 0.7044965028762817, disc_loss = 0.06480667740106583
Trained batch 4 in epoch 3, gen_loss = 0.7205376148223877, disc_loss = 0.08045470416545868
Trained batch 5 in epoch 3, gen_loss = 0.7179449498653412, disc_loss = 0.08107704545060794
Trained batch 6 in epoch 3, gen_loss = 0.7041083829743522, disc_loss = 0.08723167330026627
Trained batch 7 in epoch 3, gen_loss = 0.7497582957148552, disc_loss = 0.12042366992682219
Trained batch 8 in epoch 3, gen_loss = 0.7394496401151022, disc_loss = 0.12761637485689586
Trained batch 9 in epoch 3, gen_loss = 0.7224497437477112, disc_loss = 0.13215465620160102
Trained batch 10 in epoch 3, gen_loss = 0.76390925320712, disc_loss = 0.1421955099160021
Trained batch 11 in epoch 3, gen_loss = 0.7725069473187128, disc_loss = 0.13387909904122353
Trained batch 12 in epoch 3, gen_loss = 0.7550374131936294, disc_loss = 0.1398980411199423
Trained batch 13 in epoch 3, gen_loss = 0.7705739097935813, disc_loss = 0.14193238637277059
Trained batch 14 in epoch 3, gen_loss = 0.7573468168576558, disc_loss = 0.1371161421140035
Trained batch 15 in epoch 3, gen_loss = 0.7661428414285183, disc_loss = 0.1328541487455368
Trained batch 16 in epoch 3, gen_loss = 0.7752919898313635, disc_loss = 0.12888496895046794
Trained batch 17 in epoch 3, gen_loss = 0.7707500722673204, disc_loss = 0.1262541583014859
Trained batch 18 in epoch 3, gen_loss = 0.7741912603378296, disc_loss = 0.12405293042722501
Trained batch 19 in epoch 3, gen_loss = 0.7702555030584335, disc_loss = 0.12151338905096054
Trained batch 20 in epoch 3, gen_loss = 0.7620089479855129, disc_loss = 0.12490327443395342
Trained batch 21 in epoch 3, gen_loss = 0.7598406672477722, disc_loss = 0.12392097271301529
Trained batch 22 in epoch 3, gen_loss = 0.7590560265209364, disc_loss = 0.12177929832883504
Trained batch 23 in epoch 3, gen_loss = 0.7565686851739883, disc_loss = 0.12241742790987094
Trained batch 24 in epoch 3, gen_loss = 0.7460897827148437, disc_loss = 0.12350644558668136
Trained batch 25 in epoch 3, gen_loss = 0.7472973465919495, disc_loss = 0.12541831370729667
Trained batch 26 in epoch 3, gen_loss = 0.7421434698281465, disc_loss = 0.12391277071502474
Trained batch 27 in epoch 3, gen_loss = 0.7483913323708943, disc_loss = 0.12169620022177696
Trained batch 28 in epoch 3, gen_loss = 0.747492253780365, disc_loss = 0.11890341251574714
Trained batch 29 in epoch 3, gen_loss = 0.7446524560451507, disc_loss = 0.11796849506596724
Trained batch 30 in epoch 3, gen_loss = 0.7493406207330765, disc_loss = 0.11826797634843857
Trained batch 31 in epoch 3, gen_loss = 0.7463066857308149, disc_loss = 0.11741455213632435
Trained batch 32 in epoch 3, gen_loss = 0.7418611031590086, disc_loss = 0.12089533099170888
Trained batch 33 in epoch 3, gen_loss = 0.7379698665703044, disc_loss = 0.12085523642599583
Trained batch 34 in epoch 3, gen_loss = 0.7348110846110752, disc_loss = 0.11964579788701875
Trained batch 35 in epoch 3, gen_loss = 0.7520119845867157, disc_loss = 0.12275511988749106
Trained batch 36 in epoch 3, gen_loss = 0.7483419115478928, disc_loss = 0.12278027439842353
Trained batch 37 in epoch 3, gen_loss = 0.7436972166362562, disc_loss = 0.12165897643487704
Trained batch 38 in epoch 3, gen_loss = 0.745808332394331, disc_loss = 0.12009365474566436
Trained batch 39 in epoch 3, gen_loss = 0.7501535728573799, disc_loss = 0.11887361370027065
Trained batch 40 in epoch 3, gen_loss = 0.7549311402367382, disc_loss = 0.11754002094995684
Trained batch 41 in epoch 3, gen_loss = 0.7503081205345336, disc_loss = 0.11967847691405387
Trained batch 42 in epoch 3, gen_loss = 0.7550721889318421, disc_loss = 0.11878184887558915
Trained batch 43 in epoch 3, gen_loss = 0.7554933157834139, disc_loss = 0.11835846237160942
Trained batch 44 in epoch 3, gen_loss = 0.7531810151206122, disc_loss = 0.11768613722589281
Trained batch 45 in epoch 3, gen_loss = 0.7564086512379025, disc_loss = 0.11723703097390092
Trained batch 46 in epoch 3, gen_loss = 0.7556263144980085, disc_loss = 0.11776312472338372
Trained batch 47 in epoch 3, gen_loss = 0.755643709252278, disc_loss = 0.1164286231311659
Trained batch 48 in epoch 3, gen_loss = 0.7541778416049724, disc_loss = 0.1160532039951305
Trained batch 49 in epoch 3, gen_loss = 0.7583846342563629, disc_loss = 0.11470467634499074
Trained batch 50 in epoch 3, gen_loss = 0.7611294213463279, disc_loss = 0.11323324021171122
Trained batch 51 in epoch 3, gen_loss = 0.7653398869129328, disc_loss = 0.11216045966228613
Trained batch 52 in epoch 3, gen_loss = 0.7603141822904911, disc_loss = 0.11337124900716655
Trained batch 53 in epoch 3, gen_loss = 0.7648056315051185, disc_loss = 0.11266730056592712
Trained batch 54 in epoch 3, gen_loss = 0.7662458777427673, disc_loss = 0.11149723184379665
Trained batch 55 in epoch 3, gen_loss = 0.765927115721362, disc_loss = 0.11045430434335556
Trained batch 56 in epoch 3, gen_loss = 0.7643708503037169, disc_loss = 0.10985792513217843
Trained batch 57 in epoch 3, gen_loss = 0.76376516551807, disc_loss = 0.10918418388685276
Trained batch 58 in epoch 3, gen_loss = 0.767612468388121, disc_loss = 0.10779166000626855
Trained batch 59 in epoch 3, gen_loss = 0.7677329709132512, disc_loss = 0.1065240440890193
Trained batch 60 in epoch 3, gen_loss = 0.768084032613723, disc_loss = 0.10545688965281502
Trained batch 61 in epoch 3, gen_loss = 0.7764358280166503, disc_loss = 0.10561834131517718
Trained batch 62 in epoch 3, gen_loss = 0.7754339651455955, disc_loss = 0.10625369728557647
Trained batch 63 in epoch 3, gen_loss = 0.778611640445888, disc_loss = 0.10520750668365508
Trained batch 64 in epoch 3, gen_loss = 0.7781660896081191, disc_loss = 0.10451029894443659
Trained batch 65 in epoch 3, gen_loss = 0.7830102145671844, disc_loss = 0.10448425635695457
Trained batch 66 in epoch 3, gen_loss = 0.7842545536027026, disc_loss = 0.10337104489887829
Trained batch 67 in epoch 3, gen_loss = 0.7813554257154465, disc_loss = 0.10312068766421255
Trained batch 68 in epoch 3, gen_loss = 0.7849657803341963, disc_loss = 0.1021540742367506
Trained batch 69 in epoch 3, gen_loss = 0.7849604325635092, disc_loss = 0.10188633509512458
Trained batch 70 in epoch 3, gen_loss = 0.7851222677969597, disc_loss = 0.10176691431289828
Trained batch 71 in epoch 3, gen_loss = 0.7832269113924768, disc_loss = 0.10198860850909518
Trained batch 72 in epoch 3, gen_loss = 0.7812933309437478, disc_loss = 0.10157105273069585
Trained batch 73 in epoch 3, gen_loss = 0.7839637406774469, disc_loss = 0.10226437859740611
Trained batch 74 in epoch 3, gen_loss = 0.7814074873924255, disc_loss = 0.10216882733007272
Trained batch 75 in epoch 3, gen_loss = 0.7824380389953914, disc_loss = 0.10259616245074492
Trained batch 76 in epoch 3, gen_loss = 0.7822565397658905, disc_loss = 0.10187916435881869
Trained batch 77 in epoch 3, gen_loss = 0.7828543308453683, disc_loss = 0.10123780300506414
Trained batch 78 in epoch 3, gen_loss = 0.7799817376498934, disc_loss = 0.10243334486797641
Trained batch 79 in epoch 3, gen_loss = 0.7809741131961345, disc_loss = 0.10201547571923583
Trained batch 80 in epoch 3, gen_loss = 0.7816138407330454, disc_loss = 0.10135528829270675
Trained batch 81 in epoch 3, gen_loss = 0.7832299398212899, disc_loss = 0.100744758868908
Trained batch 82 in epoch 3, gen_loss = 0.7816894750997244, disc_loss = 0.10080026366175657
Trained batch 83 in epoch 3, gen_loss = 0.7831542151314872, disc_loss = 0.10117087821431812
Trained batch 84 in epoch 3, gen_loss = 0.7825585204012254, disc_loss = 0.10082353710689966
Trained batch 85 in epoch 3, gen_loss = 0.7803517552309258, disc_loss = 0.10037418625988932
Trained batch 86 in epoch 3, gen_loss = 0.7835195174162415, disc_loss = 0.10015401627397401
Trained batch 87 in epoch 3, gen_loss = 0.7846737693656575, disc_loss = 0.09919291094411165
Trained batch 88 in epoch 3, gen_loss = 0.7869489775614792, disc_loss = 0.09832961600943563
Trained batch 89 in epoch 3, gen_loss = 0.7859607636928558, disc_loss = 0.09851870200493269
Trained batch 90 in epoch 3, gen_loss = 0.7874212153665312, disc_loss = 0.09807576987237393
Trained batch 91 in epoch 3, gen_loss = 0.7870595707841541, disc_loss = 0.09806736650795717
Trained batch 92 in epoch 3, gen_loss = 0.787824095577322, disc_loss = 0.09779674819199949
Trained batch 93 in epoch 3, gen_loss = 0.7871343911962306, disc_loss = 0.09795960572924703
Trained batch 94 in epoch 3, gen_loss = 0.7883730323691117, disc_loss = 0.09833633157571679
Trained batch 95 in epoch 3, gen_loss = 0.7884175485620896, disc_loss = 0.0978301533323247
Trained batch 96 in epoch 3, gen_loss = 0.7898599573017395, disc_loss = 0.09702499505593297
Trained batch 97 in epoch 3, gen_loss = 0.79069371126136, disc_loss = 0.096362853261205
Trained batch 98 in epoch 3, gen_loss = 0.7900737578218634, disc_loss = 0.09648016594689
Trained batch 99 in epoch 3, gen_loss = 0.7878387594223022, disc_loss = 0.0972907695453614
Trained batch 100 in epoch 3, gen_loss = 0.7935398569201478, disc_loss = 0.09852660841096451
Trained batch 101 in epoch 3, gen_loss = 0.7903845091076458, disc_loss = 0.09979811605686943
Trained batch 102 in epoch 3, gen_loss = 0.7894462980691669, disc_loss = 0.0996036293997782
Trained batch 103 in epoch 3, gen_loss = 0.7925516478717327, disc_loss = 0.10099777166480915
Trained batch 104 in epoch 3, gen_loss = 0.7895716670013609, disc_loss = 0.10219149606391079
Trained batch 105 in epoch 3, gen_loss = 0.7888085732482514, disc_loss = 0.10243768978617945
Trained batch 106 in epoch 3, gen_loss = 0.7887736895931101, disc_loss = 0.10237072912157974
Trained batch 107 in epoch 3, gen_loss = 0.7886996376845572, disc_loss = 0.1025264381379303
Trained batch 108 in epoch 3, gen_loss = 0.7856705976188729, disc_loss = 0.10351778248137017
Trained batch 109 in epoch 3, gen_loss = 0.7844460368156433, disc_loss = 0.10365231859243729
Trained batch 110 in epoch 3, gen_loss = 0.786356376098083, disc_loss = 0.1055892994123939
Trained batch 111 in epoch 3, gen_loss = 0.7843484186700412, disc_loss = 0.10616295288283643
Trained batch 112 in epoch 3, gen_loss = 0.7820912383298958, disc_loss = 0.10645310352432781
Trained batch 113 in epoch 3, gen_loss = 0.7806024075600139, disc_loss = 0.10665722553242456
Trained batch 114 in epoch 3, gen_loss = 0.7815924224646195, disc_loss = 0.10630098914160677
Trained batch 115 in epoch 3, gen_loss = 0.7834399280876949, disc_loss = 0.10595503933567169
Trained batch 116 in epoch 3, gen_loss = 0.7826863883906959, disc_loss = 0.10546229304506993
Trained batch 117 in epoch 3, gen_loss = 0.7817934650485798, disc_loss = 0.1051798711878137
Trained batch 118 in epoch 3, gen_loss = 0.7816675140076325, disc_loss = 0.10475074827764966
Trained batch 119 in epoch 3, gen_loss = 0.7840383857488632, disc_loss = 0.10455426718884459
Trained batch 120 in epoch 3, gen_loss = 0.7816727178648484, disc_loss = 0.10620838670783546
Trained batch 121 in epoch 3, gen_loss = 0.7819275208672539, disc_loss = 0.10618251698763399
Trained batch 122 in epoch 3, gen_loss = 0.7830018742782313, disc_loss = 0.10627529548284242
Trained batch 123 in epoch 3, gen_loss = 0.781783445467872, disc_loss = 0.10656967400873621
Trained batch 124 in epoch 3, gen_loss = 0.7811184494495392, disc_loss = 0.10628151728957891
Trained batch 125 in epoch 3, gen_loss = 0.7828812090650438, disc_loss = 0.10617617431229778
Trained batch 126 in epoch 3, gen_loss = 0.7810549339440864, disc_loss = 0.1061913441118645
Trained batch 127 in epoch 3, gen_loss = 0.7803695208858699, disc_loss = 0.10620067649142584
Trained batch 128 in epoch 3, gen_loss = 0.7824235708676568, disc_loss = 0.10645374513498342
Trained batch 129 in epoch 3, gen_loss = 0.7828142672777176, disc_loss = 0.10593127065982956
Trained batch 130 in epoch 3, gen_loss = 0.7813760726961471, disc_loss = 0.10690749108876663
Trained batch 131 in epoch 3, gen_loss = 0.7817729397705107, disc_loss = 0.10639370601821804
Trained batch 132 in epoch 3, gen_loss = 0.7833121367415091, disc_loss = 0.10617389778529567
Trained batch 133 in epoch 3, gen_loss = 0.7822404412636116, disc_loss = 0.10660626657946563
Trained batch 134 in epoch 3, gen_loss = 0.7803744172608411, disc_loss = 0.10717615702499945
Trained batch 135 in epoch 3, gen_loss = 0.7799812763491097, disc_loss = 0.10728756871814017
Trained batch 136 in epoch 3, gen_loss = 0.7827193969792693, disc_loss = 0.10729434604273878
Trained batch 137 in epoch 3, gen_loss = 0.7850054137516713, disc_loss = 0.10675786038104823
Trained batch 138 in epoch 3, gen_loss = 0.7849420487023085, disc_loss = 0.10677012931823517
Trained batch 139 in epoch 3, gen_loss = 0.7842877726469721, disc_loss = 0.10630206949343639
Trained batch 140 in epoch 3, gen_loss = 0.784403292211235, disc_loss = 0.1065031254584802
Trained batch 141 in epoch 3, gen_loss = 0.7843176623885061, disc_loss = 0.1067930255806677
Trained batch 142 in epoch 3, gen_loss = 0.7835122315616875, disc_loss = 0.10678554164128495
Trained batch 143 in epoch 3, gen_loss = 0.7834785611679157, disc_loss = 0.10640991475924642
Trained batch 144 in epoch 3, gen_loss = 0.7853176008010733, disc_loss = 0.10614103024247391
Trained batch 145 in epoch 3, gen_loss = 0.785445436835289, disc_loss = 0.1059163469145049
Trained batch 146 in epoch 3, gen_loss = 0.7862746681080384, disc_loss = 0.10567456946968018
Trained batch 147 in epoch 3, gen_loss = 0.7849817169276444, disc_loss = 0.1056216094026191
Trained batch 148 in epoch 3, gen_loss = 0.7843103714837324, disc_loss = 0.10534708173758031
Trained batch 149 in epoch 3, gen_loss = 0.7851045308510463, disc_loss = 0.10553992640847962
Trained batch 150 in epoch 3, gen_loss = 0.785890076136747, disc_loss = 0.10505653571781536
Trained batch 151 in epoch 3, gen_loss = 0.7846654337879858, disc_loss = 0.10545247410252494
Trained batch 152 in epoch 3, gen_loss = 0.7850548112704083, disc_loss = 0.10553240673190434
Trained batch 153 in epoch 3, gen_loss = 0.7847053793730674, disc_loss = 0.10536409091422116
Trained batch 154 in epoch 3, gen_loss = 0.783656059734283, disc_loss = 0.105216634171384
Trained batch 155 in epoch 3, gen_loss = 0.7848067751679665, disc_loss = 0.10594929400712061
Trained batch 156 in epoch 3, gen_loss = 0.7846848746393896, disc_loss = 0.10563010055049779
Trained batch 157 in epoch 3, gen_loss = 0.7845132130233547, disc_loss = 0.10524739836095066
Trained batch 158 in epoch 3, gen_loss = 0.7838602986350749, disc_loss = 0.10491819107471584
Trained batch 159 in epoch 3, gen_loss = 0.7844149773940444, disc_loss = 0.1064549354778137
Trained batch 160 in epoch 3, gen_loss = 0.7838247894130138, disc_loss = 0.10630267765372992
Trained batch 161 in epoch 3, gen_loss = 0.7822522081342744, disc_loss = 0.1071477699737398
Trained batch 162 in epoch 3, gen_loss = 0.7837123894618333, disc_loss = 0.10862892134217945
Trained batch 163 in epoch 3, gen_loss = 0.7837354433609218, disc_loss = 0.10905163098558239
Trained batch 164 in epoch 3, gen_loss = 0.7826659905188011, disc_loss = 0.10938902885060418
Trained batch 165 in epoch 3, gen_loss = 0.7825509383376822, disc_loss = 0.10918394305058811
Trained batch 166 in epoch 3, gen_loss = 0.7837711460219172, disc_loss = 0.1092425795316607
Trained batch 167 in epoch 3, gen_loss = 0.782715008549747, disc_loss = 0.10919812733551398
Trained batch 168 in epoch 3, gen_loss = 0.7822251011281324, disc_loss = 0.10934012708909942
Trained batch 169 in epoch 3, gen_loss = 0.7823609802652808, disc_loss = 0.10932995128609678
Trained batch 170 in epoch 3, gen_loss = 0.7814023273381573, disc_loss = 0.10891733370307419
Trained batch 171 in epoch 3, gen_loss = 0.7826288365000902, disc_loss = 0.10836426239612318
Trained batch 172 in epoch 3, gen_loss = 0.7827049275009619, disc_loss = 0.10805650914055591
Trained batch 173 in epoch 3, gen_loss = 0.7836401659524304, disc_loss = 0.10755007062642567
Trained batch 174 in epoch 3, gen_loss = 0.7821249769415174, disc_loss = 0.10775116247258017
Trained batch 175 in epoch 3, gen_loss = 0.782032533633438, disc_loss = 0.10765576527178795
Trained batch 176 in epoch 3, gen_loss = 0.7818832820081442, disc_loss = 0.10735644189125232
Trained batch 177 in epoch 3, gen_loss = 0.7825651083434566, disc_loss = 0.10769434306205491
Trained batch 178 in epoch 3, gen_loss = 0.7810903080015875, disc_loss = 0.10783815308468801
Trained batch 179 in epoch 3, gen_loss = 0.7803366762068537, disc_loss = 0.10792469054770966
Trained batch 180 in epoch 3, gen_loss = 0.7805878814742051, disc_loss = 0.10754218861687084
Trained batch 181 in epoch 3, gen_loss = 0.7812125438844765, disc_loss = 0.1075718911252097
Trained batch 182 in epoch 3, gen_loss = 0.7807285067487936, disc_loss = 0.10737613820129893
Trained batch 183 in epoch 3, gen_loss = 0.7800482581167117, disc_loss = 0.10754684131572266
Trained batch 184 in epoch 3, gen_loss = 0.7816182064043509, disc_loss = 0.10811242976200741
Trained batch 185 in epoch 3, gen_loss = 0.7822101252373829, disc_loss = 0.10782639155044191
Trained batch 186 in epoch 3, gen_loss = 0.7809712521851382, disc_loss = 0.10887603391519683
Trained batch 187 in epoch 3, gen_loss = 0.7818373053314838, disc_loss = 0.10850455391498164
Trained batch 188 in epoch 3, gen_loss = 0.7842180557036526, disc_loss = 0.10867187342847939
Trained batch 189 in epoch 3, gen_loss = 0.7826456589134116, disc_loss = 0.10885941897469915
Trained batch 190 in epoch 3, gen_loss = 0.7823946986210908, disc_loss = 0.10856197298021684
Trained batch 191 in epoch 3, gen_loss = 0.7817878463926414, disc_loss = 0.1084395834429112
Trained batch 192 in epoch 3, gen_loss = 0.7830556496746182, disc_loss = 0.10832657869133153
Trained batch 193 in epoch 3, gen_loss = 0.7836902819036209, disc_loss = 0.10857864215336356
Trained batch 194 in epoch 3, gen_loss = 0.7831463008354872, disc_loss = 0.10879242763591883
Trained batch 195 in epoch 3, gen_loss = 0.7831072413495609, disc_loss = 0.10851316909989989
Trained batch 196 in epoch 3, gen_loss = 0.7825157553108816, disc_loss = 0.10839462015059242
Trained batch 197 in epoch 3, gen_loss = 0.7830955158881466, disc_loss = 0.108578936916522
Trained batch 198 in epoch 3, gen_loss = 0.7823681398552267, disc_loss = 0.10867873492683448
Trained batch 199 in epoch 3, gen_loss = 0.7824527771770954, disc_loss = 0.10842565729748457
Trained batch 200 in epoch 3, gen_loss = 0.7817111414166825, disc_loss = 0.10857187789304192
Trained batch 201 in epoch 3, gen_loss = 0.7816770933937318, disc_loss = 0.10828718146087953
Trained batch 202 in epoch 3, gen_loss = 0.7818395720033223, disc_loss = 0.10807081720713764
Trained batch 203 in epoch 3, gen_loss = 0.7826676834739891, disc_loss = 0.10774029988119853
Trained batch 204 in epoch 3, gen_loss = 0.7818298873378009, disc_loss = 0.10779765069757292
Trained batch 205 in epoch 3, gen_loss = 0.7832258197578411, disc_loss = 0.10774020474060501
Trained batch 206 in epoch 3, gen_loss = 0.7835581329997611, disc_loss = 0.10752864908606966
Trained batch 207 in epoch 3, gen_loss = 0.7833079032313365, disc_loss = 0.10732402408477636
Trained batch 208 in epoch 3, gen_loss = 0.7828748780859714, disc_loss = 0.10720444416725322
Trained batch 209 in epoch 3, gen_loss = 0.7827941566705704, disc_loss = 0.10721305061929992
Trained batch 210 in epoch 3, gen_loss = 0.7834075761349846, disc_loss = 0.10845992681945528
Trained batch 211 in epoch 3, gen_loss = 0.7818560194013253, disc_loss = 0.11020624503616314
Trained batch 212 in epoch 3, gen_loss = 0.7824720210032844, disc_loss = 0.1103024423918184
Trained batch 213 in epoch 3, gen_loss = 0.7825299580799085, disc_loss = 0.11049858480256712
Trained batch 214 in epoch 3, gen_loss = 0.7816775736420654, disc_loss = 0.11067782494477754
Trained batch 215 in epoch 3, gen_loss = 0.7815633309936082, disc_loss = 0.1104886796006381
Trained batch 216 in epoch 3, gen_loss = 0.7820750154932523, disc_loss = 0.11029765119321198
Trained batch 217 in epoch 3, gen_loss = 0.7817247637094707, disc_loss = 0.11037943094814999
Trained batch 218 in epoch 3, gen_loss = 0.781408268431006, disc_loss = 0.1104685438915951
Trained batch 219 in epoch 3, gen_loss = 0.7817419614304196, disc_loss = 0.11020211175676774
Trained batch 220 in epoch 3, gen_loss = 0.781306165780417, disc_loss = 0.11031376983026439
Trained batch 221 in epoch 3, gen_loss = 0.7806481859973959, disc_loss = 0.11059491945061463
Trained batch 222 in epoch 3, gen_loss = 0.7815580612608135, disc_loss = 0.11029309378059857
Trained batch 223 in epoch 3, gen_loss = 0.7822456451665077, disc_loss = 0.1101597129392238
Trained batch 224 in epoch 3, gen_loss = 0.7819702168305714, disc_loss = 0.11030079778283834
Trained batch 225 in epoch 3, gen_loss = 0.7822507745133037, disc_loss = 0.11033978368839727
Trained batch 226 in epoch 3, gen_loss = 0.7828400496081633, disc_loss = 0.1099947560127283
Trained batch 227 in epoch 3, gen_loss = 0.7820643274146214, disc_loss = 0.10996647007158843
Trained batch 228 in epoch 3, gen_loss = 0.782052920504949, disc_loss = 0.11008536319073502
Trained batch 229 in epoch 3, gen_loss = 0.7816874710114106, disc_loss = 0.11011170490199457
Trained batch 230 in epoch 3, gen_loss = 0.7805894072695728, disc_loss = 0.11064222169177228
Trained batch 231 in epoch 3, gen_loss = 0.7811965342482616, disc_loss = 0.11060974028780414
Trained batch 232 in epoch 3, gen_loss = 0.7815324253534555, disc_loss = 0.11071715054258129
Trained batch 233 in epoch 3, gen_loss = 0.7812782654650191, disc_loss = 0.11051583673375157
Trained batch 234 in epoch 3, gen_loss = 0.7808789751631149, disc_loss = 0.11083946311648221
Trained batch 235 in epoch 3, gen_loss = 0.78012431135117, disc_loss = 0.11124679643139875
Trained batch 236 in epoch 3, gen_loss = 0.7804625322295644, disc_loss = 0.11124553919262901
Trained batch 237 in epoch 3, gen_loss = 0.7796479014038038, disc_loss = 0.11118347299120881
Trained batch 238 in epoch 3, gen_loss = 0.781783051695285, disc_loss = 0.11171141966288933
Trained batch 239 in epoch 3, gen_loss = 0.7808295986304681, disc_loss = 0.11191447192104534
Trained batch 240 in epoch 3, gen_loss = 0.7801477598698802, disc_loss = 0.1120595143165022
Trained batch 241 in epoch 3, gen_loss = 0.7797494975249629, disc_loss = 0.11256812624864218
Trained batch 242 in epoch 3, gen_loss = 0.7803536090585921, disc_loss = 0.11287104851593083
Trained batch 243 in epoch 3, gen_loss = 0.7808068146715399, disc_loss = 0.11262057168546637
Trained batch 244 in epoch 3, gen_loss = 0.7801935652080847, disc_loss = 0.11260765300949617
Trained batch 245 in epoch 3, gen_loss = 0.7805198778708776, disc_loss = 0.11259700954187571
Trained batch 246 in epoch 3, gen_loss = 0.7804236850033888, disc_loss = 0.11228069487717832
Trained batch 247 in epoch 3, gen_loss = 0.7799801435922423, disc_loss = 0.11212750307599743
Trained batch 248 in epoch 3, gen_loss = 0.7794010618843706, disc_loss = 0.1120763147534077
Trained batch 249 in epoch 3, gen_loss = 0.7797296577692032, disc_loss = 0.11249077492579818
Trained batch 250 in epoch 3, gen_loss = 0.7792590525283282, disc_loss = 0.11251601324123571
Trained batch 251 in epoch 3, gen_loss = 0.7798381467896794, disc_loss = 0.11244298821862136
Trained batch 252 in epoch 3, gen_loss = 0.7803460099244778, disc_loss = 0.11211351137019311
Trained batch 253 in epoch 3, gen_loss = 0.7804376425470892, disc_loss = 0.11198837805436704
Trained batch 254 in epoch 3, gen_loss = 0.7804737879949457, disc_loss = 0.11165821852125958
Trained batch 255 in epoch 3, gen_loss = 0.7806833718204871, disc_loss = 0.1113577744581562
Trained batch 256 in epoch 3, gen_loss = 0.7814098945619531, disc_loss = 0.111141549956039
Trained batch 257 in epoch 3, gen_loss = 0.7805440949146137, disc_loss = 0.11132164312844244
Trained batch 258 in epoch 3, gen_loss = 0.7810961430367356, disc_loss = 0.1112579232887239
Trained batch 259 in epoch 3, gen_loss = 0.7809385032607958, disc_loss = 0.11127391241562481
Trained batch 260 in epoch 3, gen_loss = 0.7801827921949583, disc_loss = 0.11163414782448404
Trained batch 261 in epoch 3, gen_loss = 0.7804810838162444, disc_loss = 0.11163195838639868
Trained batch 262 in epoch 3, gen_loss = 0.7797326734537408, disc_loss = 0.1117802046614738
Trained batch 263 in epoch 3, gen_loss = 0.7801681810030432, disc_loss = 0.1115114435334831
Trained batch 264 in epoch 3, gen_loss = 0.7802276520234234, disc_loss = 0.11138356380375489
Trained batch 265 in epoch 3, gen_loss = 0.7804310148147712, disc_loss = 0.11139656190543358
Trained batch 266 in epoch 3, gen_loss = 0.7794582831502407, disc_loss = 0.11167575515569485
Trained batch 267 in epoch 3, gen_loss = 0.7799546948786992, disc_loss = 0.11145413645070547
Trained batch 268 in epoch 3, gen_loss = 0.7803996357111239, disc_loss = 0.11127597512157987
Trained batch 269 in epoch 3, gen_loss = 0.7794946985112297, disc_loss = 0.11117013712517089
Trained batch 270 in epoch 3, gen_loss = 0.7796610089025814, disc_loss = 0.11112381925125954
Trained batch 271 in epoch 3, gen_loss = 0.7794784216538948, disc_loss = 0.11091794591629878
Trained batch 272 in epoch 3, gen_loss = 0.7800533643790654, disc_loss = 0.11091083444095466
Trained batch 273 in epoch 3, gen_loss = 0.7798796281979902, disc_loss = 0.11067397974390727
Trained batch 274 in epoch 3, gen_loss = 0.7802809744531458, disc_loss = 0.11063448773527687
Trained batch 275 in epoch 3, gen_loss = 0.780112138584904, disc_loss = 0.11048567897397214
Trained batch 276 in epoch 3, gen_loss = 0.7793648327946232, disc_loss = 0.11048626493904673
Trained batch 277 in epoch 3, gen_loss = 0.7801264699200074, disc_loss = 0.11088439878813333
Trained batch 278 in epoch 3, gen_loss = 0.7801614379156447, disc_loss = 0.11066245633815032
Trained batch 279 in epoch 3, gen_loss = 0.779227231762239, disc_loss = 0.11114665713227753
Trained batch 280 in epoch 3, gen_loss = 0.7794242994428954, disc_loss = 0.11125956254669886
Trained batch 281 in epoch 3, gen_loss = 0.7788865806151789, disc_loss = 0.11154273846219723
Trained batch 282 in epoch 3, gen_loss = 0.7784737221133161, disc_loss = 0.11153744507659977
Trained batch 283 in epoch 3, gen_loss = 0.7790608728225802, disc_loss = 0.1113299607974805
Trained batch 284 in epoch 3, gen_loss = 0.7792205349395149, disc_loss = 0.1110918803205877
Trained batch 285 in epoch 3, gen_loss = 0.7801800585918494, disc_loss = 0.11090340171256786
Trained batch 286 in epoch 3, gen_loss = 0.779801420114597, disc_loss = 0.11082550678531987
Trained batch 287 in epoch 3, gen_loss = 0.7793252719566226, disc_loss = 0.1108954141931867
Trained batch 288 in epoch 3, gen_loss = 0.7804602070044481, disc_loss = 0.11091097547740363
Trained batch 289 in epoch 3, gen_loss = 0.7797601852951379, disc_loss = 0.11094302024114235
Trained batch 290 in epoch 3, gen_loss = 0.7794296349241971, disc_loss = 0.11081556041638568
Trained batch 291 in epoch 3, gen_loss = 0.7798564047233699, disc_loss = 0.11129585615588888
Trained batch 292 in epoch 3, gen_loss = 0.7792415900645403, disc_loss = 0.1112537787616914
Trained batch 293 in epoch 3, gen_loss = 0.7796179979634122, disc_loss = 0.11109080736138889
Trained batch 294 in epoch 3, gen_loss = 0.7797355834710396, disc_loss = 0.11091333069854369
Trained batch 295 in epoch 3, gen_loss = 0.7792303132245669, disc_loss = 0.11096343939582742
Trained batch 296 in epoch 3, gen_loss = 0.7793435910936156, disc_loss = 0.1110798139846335
Trained batch 297 in epoch 3, gen_loss = 0.7802596773277193, disc_loss = 0.1108267760848089
Trained batch 298 in epoch 3, gen_loss = 0.7793851154903105, disc_loss = 0.11120331531895145
Trained batch 299 in epoch 3, gen_loss = 0.7802665973703067, disc_loss = 0.11118149253539741
Trained batch 300 in epoch 3, gen_loss = 0.7796326084588453, disc_loss = 0.11127342860774443
Trained batch 301 in epoch 3, gen_loss = 0.7792148739099503, disc_loss = 0.11118100041104172
Trained batch 302 in epoch 3, gen_loss = 0.780125757156819, disc_loss = 0.11112021045335153
Trained batch 303 in epoch 3, gen_loss = 0.7792601213839493, disc_loss = 0.11110744113408912
Trained batch 304 in epoch 3, gen_loss = 0.7791469027761553, disc_loss = 0.11090738479292295
Trained batch 305 in epoch 3, gen_loss = 0.7795712463801203, disc_loss = 0.11089178061818862
Trained batch 306 in epoch 3, gen_loss = 0.7790761507489394, disc_loss = 0.11093043522903216
Trained batch 307 in epoch 3, gen_loss = 0.7782904051921584, disc_loss = 0.1109150813003494
Trained batch 308 in epoch 3, gen_loss = 0.7785339254198722, disc_loss = 0.11083780044936922
Trained batch 309 in epoch 3, gen_loss = 0.7785085642530072, disc_loss = 0.11066803026403631
Trained batch 310 in epoch 3, gen_loss = 0.7784444018000575, disc_loss = 0.11067355829335965
Trained batch 311 in epoch 3, gen_loss = 0.7788583472944223, disc_loss = 0.1106704527971884
Trained batch 312 in epoch 3, gen_loss = 0.7791614455346483, disc_loss = 0.11067146727273734
Trained batch 313 in epoch 3, gen_loss = 0.7789511197501686, disc_loss = 0.11069715974828714
Trained batch 314 in epoch 3, gen_loss = 0.7796551578574711, disc_loss = 0.11089273987130986
Trained batch 315 in epoch 3, gen_loss = 0.7797766451405573, disc_loss = 0.11064993111782154
Trained batch 316 in epoch 3, gen_loss = 0.7794529044477722, disc_loss = 0.11051459420378369
Trained batch 317 in epoch 3, gen_loss = 0.780333899008403, disc_loss = 0.1103151018918732
Trained batch 318 in epoch 3, gen_loss = 0.7802499281388465, disc_loss = 0.11032965485310199
Trained batch 319 in epoch 3, gen_loss = 0.780799715500325, disc_loss = 0.11008023935428354
Trained batch 320 in epoch 3, gen_loss = 0.7809457690730645, disc_loss = 0.11020588692904354
Trained batch 321 in epoch 3, gen_loss = 0.7804059140985797, disc_loss = 0.11013140919566247
Trained batch 322 in epoch 3, gen_loss = 0.7804281618388444, disc_loss = 0.10994003013341512
Trained batch 323 in epoch 3, gen_loss = 0.7816759920966478, disc_loss = 0.10980936371215423
Trained batch 324 in epoch 3, gen_loss = 0.7813278718178089, disc_loss = 0.10978697608583249
Trained batch 325 in epoch 3, gen_loss = 0.7805031019668638, disc_loss = 0.10981881846188128
Trained batch 326 in epoch 3, gen_loss = 0.7812002912756135, disc_loss = 0.10974319528970605
Trained batch 327 in epoch 3, gen_loss = 0.7815664480553894, disc_loss = 0.10947936156866844
Trained batch 328 in epoch 3, gen_loss = 0.7808589207908665, disc_loss = 0.10966964162557774
Trained batch 329 in epoch 3, gen_loss = 0.780253438967647, disc_loss = 0.10962567184063973
Trained batch 330 in epoch 3, gen_loss = 0.7797678097677375, disc_loss = 0.1096969480426515
Trained batch 331 in epoch 3, gen_loss = 0.7800644780677485, disc_loss = 0.10969917659356024
Trained batch 332 in epoch 3, gen_loss = 0.7805807843759611, disc_loss = 0.10963106776556901
Trained batch 333 in epoch 3, gen_loss = 0.7808394702430257, disc_loss = 0.10936889975627292
Trained batch 334 in epoch 3, gen_loss = 0.7801059513839324, disc_loss = 0.10968590930048654
Trained batch 335 in epoch 3, gen_loss = 0.7813817969567719, disc_loss = 0.10993209019735721
Trained batch 336 in epoch 3, gen_loss = 0.7815770633319719, disc_loss = 0.10969396193929083
Trained batch 337 in epoch 3, gen_loss = 0.7812482533899284, disc_loss = 0.10993091706682503
Trained batch 338 in epoch 3, gen_loss = 0.78049776380041, disc_loss = 0.11003832767132372
Trained batch 339 in epoch 3, gen_loss = 0.7806078028152971, disc_loss = 0.10992189027533374
Trained batch 340 in epoch 3, gen_loss = 0.7809887569496009, disc_loss = 0.11065825684230961
Trained batch 341 in epoch 3, gen_loss = 0.7804171339287396, disc_loss = 0.11135518668241233
Trained batch 342 in epoch 3, gen_loss = 0.7811581734839403, disc_loss = 0.1114837837000934
Trained batch 343 in epoch 3, gen_loss = 0.7808972267044145, disc_loss = 0.11150493446553429
Trained batch 344 in epoch 3, gen_loss = 0.7806188661983048, disc_loss = 0.11152084614217714
Trained batch 345 in epoch 3, gen_loss = 0.7805744394918398, disc_loss = 0.11154089043067628
Trained batch 346 in epoch 3, gen_loss = 0.7811446530846423, disc_loss = 0.1114262602444985
Trained batch 347 in epoch 3, gen_loss = 0.7816882956473307, disc_loss = 0.11139423920152088
Trained batch 348 in epoch 3, gen_loss = 0.7815023654682247, disc_loss = 0.1113472278590146
Trained batch 349 in epoch 3, gen_loss = 0.7812727479423796, disc_loss = 0.11153979475743005
Trained batch 350 in epoch 3, gen_loss = 0.7813556162889866, disc_loss = 0.11155558621346356
Trained batch 351 in epoch 3, gen_loss = 0.7819657993756912, disc_loss = 0.11156313252286054
Trained batch 352 in epoch 3, gen_loss = 0.7823186181591185, disc_loss = 0.11131059092129171
Trained batch 353 in epoch 3, gen_loss = 0.7823078348643362, disc_loss = 0.11115869893139954
Trained batch 354 in epoch 3, gen_loss = 0.7821005487945718, disc_loss = 0.11096793601787845
Trained batch 355 in epoch 3, gen_loss = 0.7823305313339394, disc_loss = 0.11085893481373368
Trained batch 356 in epoch 3, gen_loss = 0.782264858651228, disc_loss = 0.11077268070773501
Trained batch 357 in epoch 3, gen_loss = 0.7823496220331618, disc_loss = 0.11063811155660443
Trained batch 358 in epoch 3, gen_loss = 0.7825069808528284, disc_loss = 0.11051242837739439
Trained batch 359 in epoch 3, gen_loss = 0.78221799954772, disc_loss = 0.11040857328464174
Trained batch 360 in epoch 3, gen_loss = 0.7829516695972295, disc_loss = 0.1102384607645572
Trained batch 361 in epoch 3, gen_loss = 0.7825192350544323, disc_loss = 0.11016733954449631
Trained batch 362 in epoch 3, gen_loss = 0.7825147970156237, disc_loss = 0.10999367855868966
Trained batch 363 in epoch 3, gen_loss = 0.7821338229945728, disc_loss = 0.11006643111142074
Trained batch 364 in epoch 3, gen_loss = 0.7830236628447493, disc_loss = 0.11014467163190042
Trained batch 365 in epoch 3, gen_loss = 0.7839437251696821, disc_loss = 0.10998069926271917
Trained batch 366 in epoch 3, gen_loss = 0.7834325068165886, disc_loss = 0.1099672723911723
Trained batch 367 in epoch 3, gen_loss = 0.7832345738197151, disc_loss = 0.10980442888862656
Trained batch 368 in epoch 3, gen_loss = 0.7833608310558609, disc_loss = 0.10963292421677168
Trained batch 369 in epoch 3, gen_loss = 0.7837071219811569, disc_loss = 0.10941633798836453
Trained batch 370 in epoch 3, gen_loss = 0.7840205494444968, disc_loss = 0.10917435080124281
Trained batch 371 in epoch 3, gen_loss = 0.7840607292068902, disc_loss = 0.1091094212681656
Trained batch 372 in epoch 3, gen_loss = 0.7833823696697685, disc_loss = 0.10933521551507008
Trained batch 373 in epoch 3, gen_loss = 0.783750600435517, disc_loss = 0.10947235974229196
Trained batch 374 in epoch 3, gen_loss = 0.7837519503434499, disc_loss = 0.10937316417445739
Trained batch 375 in epoch 3, gen_loss = 0.7845389808904617, disc_loss = 0.10926610048850403
Trained batch 376 in epoch 3, gen_loss = 0.7846274528484446, disc_loss = 0.10902783847031053
Trained batch 377 in epoch 3, gen_loss = 0.784777669127656, disc_loss = 0.10884843709775144
Trained batch 378 in epoch 3, gen_loss = 0.7848893887606648, disc_loss = 0.10881760612493847
Trained batch 379 in epoch 3, gen_loss = 0.785150563481607, disc_loss = 0.10875550230327798
Trained batch 380 in epoch 3, gen_loss = 0.7842969877982703, disc_loss = 0.10899834288161962
Trained batch 381 in epoch 3, gen_loss = 0.7842952655091959, disc_loss = 0.10898870387948387
Trained batch 382 in epoch 3, gen_loss = 0.7844983133105634, disc_loss = 0.10876201007845897
Trained batch 383 in epoch 3, gen_loss = 0.7842065382283181, disc_loss = 0.10869046640436864
Trained batch 384 in epoch 3, gen_loss = 0.7837805107816473, disc_loss = 0.10860652548394033
Trained batch 385 in epoch 3, gen_loss = 0.7840469305842651, disc_loss = 0.10855993669277414
Trained batch 386 in epoch 3, gen_loss = 0.7833669970355909, disc_loss = 0.10873095366083452
Trained batch 387 in epoch 3, gen_loss = 0.783072829937812, disc_loss = 0.10864634234122164
Trained batch 388 in epoch 3, gen_loss = 0.7833690863188864, disc_loss = 0.10856016884512414
Trained batch 389 in epoch 3, gen_loss = 0.7831909891122427, disc_loss = 0.10861384972022511
Trained batch 390 in epoch 3, gen_loss = 0.7829995002130719, disc_loss = 0.10858478319242863
Trained batch 391 in epoch 3, gen_loss = 0.7832154250722758, disc_loss = 0.10846011873990373
Trained batch 392 in epoch 3, gen_loss = 0.7829273606226341, disc_loss = 0.10845475510454738
Trained batch 393 in epoch 3, gen_loss = 0.7829698875622095, disc_loss = 0.10840505555621939
Trained batch 394 in epoch 3, gen_loss = 0.7828729461265516, disc_loss = 0.10857661386503827
Trained batch 395 in epoch 3, gen_loss = 0.7823363766074181, disc_loss = 0.10864151149959952
Trained batch 396 in epoch 3, gen_loss = 0.7831729152791146, disc_loss = 0.1086457453278698
Trained batch 397 in epoch 3, gen_loss = 0.7837927009741864, disc_loss = 0.10844363073991546
Trained batch 398 in epoch 3, gen_loss = 0.7830195544955126, disc_loss = 0.10866454523990403
Trained batch 399 in epoch 3, gen_loss = 0.7833083783090115, disc_loss = 0.1085716132284142
Trained batch 400 in epoch 3, gen_loss = 0.7838847112477272, disc_loss = 0.10854383734777161
Trained batch 401 in epoch 3, gen_loss = 0.7833827513070842, disc_loss = 0.10878473835584906
Trained batch 402 in epoch 3, gen_loss = 0.7839246880327797, disc_loss = 0.10857005999943532
Trained batch 403 in epoch 3, gen_loss = 0.7842429944194189, disc_loss = 0.10845432693535222
Trained batch 404 in epoch 3, gen_loss = 0.7836644393426401, disc_loss = 0.10847340056235776
Trained batch 405 in epoch 3, gen_loss = 0.7838074970127914, disc_loss = 0.10829572983572415
Trained batch 406 in epoch 3, gen_loss = 0.7836954517505093, disc_loss = 0.10825557521880771
Trained batch 407 in epoch 3, gen_loss = 0.7841115643580755, disc_loss = 0.10814222979459766
Trained batch 408 in epoch 3, gen_loss = 0.783350026694953, disc_loss = 0.10824505111525942
Trained batch 409 in epoch 3, gen_loss = 0.7832805518696948, disc_loss = 0.10809753796358297
Trained batch 410 in epoch 3, gen_loss = 0.7840932600399584, disc_loss = 0.10810894632616835
Trained batch 411 in epoch 3, gen_loss = 0.7841996329212652, disc_loss = 0.10793783760955106
Trained batch 412 in epoch 3, gen_loss = 0.7835687613949072, disc_loss = 0.10824193546805558
Trained batch 413 in epoch 3, gen_loss = 0.7844456141985557, disc_loss = 0.10828851061931627
Trained batch 414 in epoch 3, gen_loss = 0.784056783584227, disc_loss = 0.10823333014969726
Trained batch 415 in epoch 3, gen_loss = 0.7834091401444032, disc_loss = 0.10837338656375113
Trained batch 416 in epoch 3, gen_loss = 0.7836162975366167, disc_loss = 0.10828558817657707
Trained batch 417 in epoch 3, gen_loss = 0.7831389941096876, disc_loss = 0.10824573670322316
Trained batch 418 in epoch 3, gen_loss = 0.78270398403978, disc_loss = 0.10829682377231505
Trained batch 419 in epoch 3, gen_loss = 0.782348395954995, disc_loss = 0.10822549149438385
Trained batch 420 in epoch 3, gen_loss = 0.7825280367053886, disc_loss = 0.10813541683167077
Trained batch 421 in epoch 3, gen_loss = 0.7828372325659928, disc_loss = 0.10825149663083997
Trained batch 422 in epoch 3, gen_loss = 0.7828079705824526, disc_loss = 0.1081390229139662
Trained batch 423 in epoch 3, gen_loss = 0.7820618416903153, disc_loss = 0.1086117136489846
Trained batch 424 in epoch 3, gen_loss = 0.7820609936994665, disc_loss = 0.10855098096105982
Trained batch 425 in epoch 3, gen_loss = 0.7821967520624259, disc_loss = 0.10885246926393936
Trained batch 426 in epoch 3, gen_loss = 0.7819639165172533, disc_loss = 0.10895559651694267
Trained batch 427 in epoch 3, gen_loss = 0.7817764099791785, disc_loss = 0.10891262879899799
Trained batch 428 in epoch 3, gen_loss = 0.7819633149044775, disc_loss = 0.10872550540341017
Trained batch 429 in epoch 3, gen_loss = 0.7827234760273335, disc_loss = 0.10867564153835871
Trained batch 430 in epoch 3, gen_loss = 0.7827209885601655, disc_loss = 0.10851933138786432
Trained batch 431 in epoch 3, gen_loss = 0.7821736190881994, disc_loss = 0.10855572605807404
Trained batch 432 in epoch 3, gen_loss = 0.7822530364604801, disc_loss = 0.1084082456968088
Trained batch 433 in epoch 3, gen_loss = 0.7826322141330913, disc_loss = 0.10866084605378146
Trained batch 434 in epoch 3, gen_loss = 0.7820304053953324, disc_loss = 0.10870129726184853
Trained batch 435 in epoch 3, gen_loss = 0.7816646697871182, disc_loss = 0.10876745101568554
Trained batch 436 in epoch 3, gen_loss = 0.7824690481072433, disc_loss = 0.10887529242152957
Trained batch 437 in epoch 3, gen_loss = 0.7821873208703516, disc_loss = 0.10894133783153952
Trained batch 438 in epoch 3, gen_loss = 0.7827590714826128, disc_loss = 0.10888001628024907
Trained batch 439 in epoch 3, gen_loss = 0.7825223183090037, disc_loss = 0.10890602857001465
Trained batch 440 in epoch 3, gen_loss = 0.7831124091634944, disc_loss = 0.10869548359754877
Trained batch 441 in epoch 3, gen_loss = 0.7827856384251453, disc_loss = 0.10873927529774842
Trained batch 442 in epoch 3, gen_loss = 0.7830833110529467, disc_loss = 0.10878211431180045
Trained batch 443 in epoch 3, gen_loss = 0.7832468562834972, disc_loss = 0.1087016593476103
Trained batch 444 in epoch 3, gen_loss = 0.7830551486336783, disc_loss = 0.10868341279624219
Trained batch 445 in epoch 3, gen_loss = 0.782689110179653, disc_loss = 0.10865539689694485
Trained batch 446 in epoch 3, gen_loss = 0.7828983707182626, disc_loss = 0.10866094285401388
Trained batch 447 in epoch 3, gen_loss = 0.7826221615874341, disc_loss = 0.1085642454792313
Trained batch 448 in epoch 3, gen_loss = 0.7824153657214413, disc_loss = 0.10849939668156987
Trained batch 449 in epoch 3, gen_loss = 0.7822309396002027, disc_loss = 0.10841215095379286
Trained batch 450 in epoch 3, gen_loss = 0.781991910775855, disc_loss = 0.10830368487135468
Trained batch 451 in epoch 3, gen_loss = 0.7825705298280294, disc_loss = 0.108537369125432
Trained batch 452 in epoch 3, gen_loss = 0.7820763030062712, disc_loss = 0.10863536082117697
Trained batch 453 in epoch 3, gen_loss = 0.7820318836210057, disc_loss = 0.10860129467740917
Trained batch 454 in epoch 3, gen_loss = 0.7819902899501088, disc_loss = 0.10875878500045984
Trained batch 455 in epoch 3, gen_loss = 0.7814346230343768, disc_loss = 0.10902893650059572
Trained batch 456 in epoch 3, gen_loss = 0.7812689931439623, disc_loss = 0.10924441381041734
Trained batch 457 in epoch 3, gen_loss = 0.7809988340956675, disc_loss = 0.1093670802504052
Trained batch 458 in epoch 3, gen_loss = 0.7812383972221989, disc_loss = 0.10949265108543219
Trained batch 459 in epoch 3, gen_loss = 0.781444121832433, disc_loss = 0.10960472299636383
Trained batch 460 in epoch 3, gen_loss = 0.7812276966142551, disc_loss = 0.10967016745956691
Trained batch 461 in epoch 3, gen_loss = 0.7812486797958226, disc_loss = 0.10954282413240829
Trained batch 462 in epoch 3, gen_loss = 0.7814529153234758, disc_loss = 0.10943634324298757
Trained batch 463 in epoch 3, gen_loss = 0.7811047651901327, disc_loss = 0.10948778581925957
Trained batch 464 in epoch 3, gen_loss = 0.7808346357396854, disc_loss = 0.10946785353164198
Trained batch 465 in epoch 3, gen_loss = 0.7811675926134821, disc_loss = 0.10952776965241512
Trained batch 466 in epoch 3, gen_loss = 0.7813163427775626, disc_loss = 0.10939389904980933
Trained batch 467 in epoch 3, gen_loss = 0.7810800051332539, disc_loss = 0.10938354852832217
Trained batch 468 in epoch 3, gen_loss = 0.781168692020465, disc_loss = 0.10923187521053974
Trained batch 469 in epoch 3, gen_loss = 0.7812203748429075, disc_loss = 0.10929934994931868
Trained batch 470 in epoch 3, gen_loss = 0.7805964139363315, disc_loss = 0.10933141159427584
Trained batch 471 in epoch 3, gen_loss = 0.780177200749769, disc_loss = 0.10940400500568735
Trained batch 472 in epoch 3, gen_loss = 0.7805374853202707, disc_loss = 0.10967581905621492
Trained batch 473 in epoch 3, gen_loss = 0.7800344416109318, disc_loss = 0.10981618168759887
Trained batch 474 in epoch 3, gen_loss = 0.7798054016263861, disc_loss = 0.1097071112986458
Trained batch 475 in epoch 3, gen_loss = 0.7795699301387081, disc_loss = 0.10963151267995792
Trained batch 476 in epoch 3, gen_loss = 0.7794287405923728, disc_loss = 0.10966811298472764
Trained batch 477 in epoch 3, gen_loss = 0.780084368199983, disc_loss = 0.10971926641163404
Trained batch 478 in epoch 3, gen_loss = 0.7804315365182084, disc_loss = 0.10954363461941605
Trained batch 479 in epoch 3, gen_loss = 0.7799706511199475, disc_loss = 0.10959761712195662
Trained batch 480 in epoch 3, gen_loss = 0.7796013419692581, disc_loss = 0.10959098060381078
Trained batch 481 in epoch 3, gen_loss = 0.7799610023181963, disc_loss = 0.10988388443752134
Trained batch 482 in epoch 3, gen_loss = 0.7797134271813229, disc_loss = 0.10984539740196358
Trained batch 483 in epoch 3, gen_loss = 0.7795803040758638, disc_loss = 0.10977414384107144
Trained batch 484 in epoch 3, gen_loss = 0.7795411637148906, disc_loss = 0.10975873993959316
Trained batch 485 in epoch 3, gen_loss = 0.7796107551443233, disc_loss = 0.109655817961052
Trained batch 486 in epoch 3, gen_loss = 0.779386032288569, disc_loss = 0.10962182229663986
Trained batch 487 in epoch 3, gen_loss = 0.7794907554739812, disc_loss = 0.1094837524435773
Trained batch 488 in epoch 3, gen_loss = 0.7796079432306114, disc_loss = 0.10933519396854752
Trained batch 489 in epoch 3, gen_loss = 0.7795669687037565, disc_loss = 0.10933856933510729
Trained batch 490 in epoch 3, gen_loss = 0.779218616650692, disc_loss = 0.10941741313375608
Trained batch 491 in epoch 3, gen_loss = 0.779621725159932, disc_loss = 0.10944478372604079
Trained batch 492 in epoch 3, gen_loss = 0.7797346140501707, disc_loss = 0.10931121883441601
Trained batch 493 in epoch 3, gen_loss = 0.7798184470126504, disc_loss = 0.10917518829911767
Trained batch 494 in epoch 3, gen_loss = 0.7800375532622289, disc_loss = 0.10903828369660509
Trained batch 495 in epoch 3, gen_loss = 0.7798847869759605, disc_loss = 0.10901612035682305
Trained batch 496 in epoch 3, gen_loss = 0.7801895591334798, disc_loss = 0.1090399247371185
Trained batch 497 in epoch 3, gen_loss = 0.780188879334783, disc_loss = 0.1089021764512372
Trained batch 498 in epoch 3, gen_loss = 0.7801665968312052, disc_loss = 0.10887677134957187
Trained batch 499 in epoch 3, gen_loss = 0.7800289804935455, disc_loss = 0.10879393806122244
Trained batch 500 in epoch 3, gen_loss = 0.7804575749262126, disc_loss = 0.10870097059117047
Trained batch 501 in epoch 3, gen_loss = 0.7806344858678689, disc_loss = 0.10856791844487605
Trained batch 502 in epoch 3, gen_loss = 0.7803058570943343, disc_loss = 0.10859993632482902
Trained batch 503 in epoch 3, gen_loss = 0.7805364790653425, disc_loss = 0.10858753089061272
Trained batch 504 in epoch 3, gen_loss = 0.7807755332181949, disc_loss = 0.1086342948405902
Trained batch 505 in epoch 3, gen_loss = 0.7803784802025957, disc_loss = 0.10857955079798112
Trained batch 506 in epoch 3, gen_loss = 0.7804806386460449, disc_loss = 0.10841573054555076
Trained batch 507 in epoch 3, gen_loss = 0.7807810284255996, disc_loss = 0.10828664405161412
Trained batch 508 in epoch 3, gen_loss = 0.780785343150493, disc_loss = 0.10815072808165857
Trained batch 509 in epoch 3, gen_loss = 0.7809932543950923, disc_loss = 0.1079883954159039
Trained batch 510 in epoch 3, gen_loss = 0.7810700064535944, disc_loss = 0.10789453986040709
Trained batch 511 in epoch 3, gen_loss = 0.7807862007757649, disc_loss = 0.10797786517468921
Trained batch 512 in epoch 3, gen_loss = 0.7806141270763925, disc_loss = 0.10785760503756082
Trained batch 513 in epoch 3, gen_loss = 0.7809885539665297, disc_loss = 0.10782211183856608
Trained batch 514 in epoch 3, gen_loss = 0.780894874716268, disc_loss = 0.10768322478618148
Trained batch 515 in epoch 3, gen_loss = 0.7808289963376615, disc_loss = 0.10784821879198096
Trained batch 516 in epoch 3, gen_loss = 0.7803223895150412, disc_loss = 0.10786734486622034
Trained batch 517 in epoch 3, gen_loss = 0.7804307342726291, disc_loss = 0.10781016263887862
Trained batch 518 in epoch 3, gen_loss = 0.7800969664072026, disc_loss = 0.1078154398307836
Trained batch 519 in epoch 3, gen_loss = 0.779986723455099, disc_loss = 0.10768299046008346
Trained batch 520 in epoch 3, gen_loss = 0.7799374179739412, disc_loss = 0.10770791536465202
Trained batch 521 in epoch 3, gen_loss = 0.77951220785521, disc_loss = 0.10786408142247363
Trained batch 522 in epoch 3, gen_loss = 0.7801041423020809, disc_loss = 0.10782960678911972
Trained batch 523 in epoch 3, gen_loss = 0.7807363810885044, disc_loss = 0.1076941963281653
Trained batch 524 in epoch 3, gen_loss = 0.7805414215723674, disc_loss = 0.10768037437505665
Trained batch 525 in epoch 3, gen_loss = 0.7811744170043858, disc_loss = 0.10763202796552061
Trained batch 526 in epoch 3, gen_loss = 0.7812114404320039, disc_loss = 0.10750437490253284
Trained batch 527 in epoch 3, gen_loss = 0.7813243287982363, disc_loss = 0.10740232420203304
Trained batch 528 in epoch 3, gen_loss = 0.7813527269714947, disc_loss = 0.10729250340548209
Trained batch 529 in epoch 3, gen_loss = 0.7823322533436541, disc_loss = 0.10730703049075772
Trained batch 530 in epoch 3, gen_loss = 0.7821047220750942, disc_loss = 0.1072573752919468
Trained batch 531 in epoch 3, gen_loss = 0.7824806992272685, disc_loss = 0.10717226674647204
Trained batch 532 in epoch 3, gen_loss = 0.7820898070791649, disc_loss = 0.10722467862943268
Trained batch 533 in epoch 3, gen_loss = 0.7823055265994554, disc_loss = 0.1071981438923948
Trained batch 534 in epoch 3, gen_loss = 0.7822147663508621, disc_loss = 0.10715856872951594
Trained batch 535 in epoch 3, gen_loss = 0.7821258960375145, disc_loss = 0.10706214631608785
Trained batch 536 in epoch 3, gen_loss = 0.7817414442920152, disc_loss = 0.10704801259198168
Trained batch 537 in epoch 3, gen_loss = 0.7817294744975505, disc_loss = 0.10721839278707883
Trained batch 538 in epoch 3, gen_loss = 0.7815283873085631, disc_loss = 0.10715280240833594
Trained batch 539 in epoch 3, gen_loss = 0.7815348834903152, disc_loss = 0.10708652951202735
Trained batch 540 in epoch 3, gen_loss = 0.7822256429799163, disc_loss = 0.10724066110937246
Trained batch 541 in epoch 3, gen_loss = 0.7822065034475714, disc_loss = 0.10714390943156782
Trained batch 542 in epoch 3, gen_loss = 0.7820685478424718, disc_loss = 0.10703636900544111
Trained batch 543 in epoch 3, gen_loss = 0.7820143679923871, disc_loss = 0.1069096692286514
Trained batch 544 in epoch 3, gen_loss = 0.7821289270296009, disc_loss = 0.10700014160279561
Trained batch 545 in epoch 3, gen_loss = 0.7823686988362463, disc_loss = 0.1069169248549793
Trained batch 546 in epoch 3, gen_loss = 0.7821157804572823, disc_loss = 0.10693824857003456
Trained batch 547 in epoch 3, gen_loss = 0.7822013069895932, disc_loss = 0.10684606650959783
Trained batch 548 in epoch 3, gen_loss = 0.7827100296706667, disc_loss = 0.10698044827150245
Trained batch 549 in epoch 3, gen_loss = 0.7826558934558522, disc_loss = 0.10696518390524117
Trained batch 550 in epoch 3, gen_loss = 0.7824871290184409, disc_loss = 0.1069875303334717
Trained batch 551 in epoch 3, gen_loss = 0.7826973651198373, disc_loss = 0.10693675482584893
Trained batch 552 in epoch 3, gen_loss = 0.782752085335647, disc_loss = 0.10684692022132992
Trained batch 553 in epoch 3, gen_loss = 0.7833730520324156, disc_loss = 0.10671092182337323
Trained batch 554 in epoch 3, gen_loss = 0.7836693134393778, disc_loss = 0.10655642393305227
Trained batch 555 in epoch 3, gen_loss = 0.7834996250893572, disc_loss = 0.10654012831899491
Trained batch 556 in epoch 3, gen_loss = 0.783890389454429, disc_loss = 0.10642110368929121
Trained batch 557 in epoch 3, gen_loss = 0.7837429793291194, disc_loss = 0.10635251316699236
Trained batch 558 in epoch 3, gen_loss = 0.7836159353605963, disc_loss = 0.10636505100556211
Trained batch 559 in epoch 3, gen_loss = 0.783773261415107, disc_loss = 0.1062993815817338
Trained batch 560 in epoch 3, gen_loss = 0.7836715636406353, disc_loss = 0.10634991381675961
Trained batch 561 in epoch 3, gen_loss = 0.783327503666759, disc_loss = 0.10656464055969357
Trained batch 562 in epoch 3, gen_loss = 0.7835971217595874, disc_loss = 0.10644493185043281
Trained batch 563 in epoch 3, gen_loss = 0.7846268112143726, disc_loss = 0.10706622106459071
Trained batch 564 in epoch 3, gen_loss = 0.7840840136582873, disc_loss = 0.10747477766126394
Trained batch 565 in epoch 3, gen_loss = 0.7840806817102769, disc_loss = 0.10736364434726615
Trained batch 566 in epoch 3, gen_loss = 0.7847073907049035, disc_loss = 0.10738136213785283
Trained batch 567 in epoch 3, gen_loss = 0.7845289789559976, disc_loss = 0.10727752371802664
Trained batch 568 in epoch 3, gen_loss = 0.7843862729562816, disc_loss = 0.10720291533892048
Trained batch 569 in epoch 3, gen_loss = 0.7841922603678285, disc_loss = 0.10717550847319919
Trained batch 570 in epoch 3, gen_loss = 0.7846088662560892, disc_loss = 0.10723271607641528
Trained batch 571 in epoch 3, gen_loss = 0.7844462299367765, disc_loss = 0.10720495429456599
Trained batch 572 in epoch 3, gen_loss = 0.7842267880160979, disc_loss = 0.10725830755900286
Trained batch 573 in epoch 3, gen_loss = 0.7847220118349022, disc_loss = 0.10724367608092336
Trained batch 574 in epoch 3, gen_loss = 0.7844922697544098, disc_loss = 0.10729672524430181
Trained batch 575 in epoch 3, gen_loss = 0.7850155269002749, disc_loss = 0.1072143624041928
Trained batch 576 in epoch 3, gen_loss = 0.7849125869869152, disc_loss = 0.10717215031817995
Trained batch 577 in epoch 3, gen_loss = 0.7851562831537946, disc_loss = 0.10704868926689234
Trained batch 578 in epoch 3, gen_loss = 0.7853558634332218, disc_loss = 0.10694302920097669
Trained batch 579 in epoch 3, gen_loss = 0.7854200850786834, disc_loss = 0.10681723644475227
Trained batch 580 in epoch 3, gen_loss = 0.7858520354851183, disc_loss = 0.10666736357535994
Trained batch 581 in epoch 3, gen_loss = 0.7858209177288403, disc_loss = 0.10661709565778113
Trained batch 582 in epoch 3, gen_loss = 0.7860956322369813, disc_loss = 0.10651220326786334
Trained batch 583 in epoch 3, gen_loss = 0.7865768856279653, disc_loss = 0.10635973604185481
Trained batch 584 in epoch 3, gen_loss = 0.7861673892563225, disc_loss = 0.10640538117537895
Trained batch 585 in epoch 3, gen_loss = 0.7860381457280787, disc_loss = 0.10641176621477301
Trained batch 586 in epoch 3, gen_loss = 0.7864186693192341, disc_loss = 0.10631925916518171
Trained batch 587 in epoch 3, gen_loss = 0.7862242664508268, disc_loss = 0.10631091633437798
Trained batch 588 in epoch 3, gen_loss = 0.7864586907756753, disc_loss = 0.10617465959902986
Trained batch 589 in epoch 3, gen_loss = 0.7864147468643673, disc_loss = 0.10619785603988222
Trained batch 590 in epoch 3, gen_loss = 0.7863577252818041, disc_loss = 0.10616150445599494
Trained batch 591 in epoch 3, gen_loss = 0.7861265809451407, disc_loss = 0.10623445908218068
Trained batch 592 in epoch 3, gen_loss = 0.7862262182553341, disc_loss = 0.1061897284883698
Trained batch 593 in epoch 3, gen_loss = 0.7869409538981088, disc_loss = 0.10637677047144534
Trained batch 594 in epoch 3, gen_loss = 0.7866295099759302, disc_loss = 0.10647320865238664
Trained batch 595 in epoch 3, gen_loss = 0.7865312295972101, disc_loss = 0.10643569613969416
Trained batch 596 in epoch 3, gen_loss = 0.7869413632344161, disc_loss = 0.10644537900766386
Trained batch 597 in epoch 3, gen_loss = 0.7867728031698278, disc_loss = 0.10642924005427339
Trained batch 598 in epoch 3, gen_loss = 0.786727403509796, disc_loss = 0.10657917082664216
Trained batch 599 in epoch 3, gen_loss = 0.786625934690237, disc_loss = 0.10671940672056128
Trained batch 600 in epoch 3, gen_loss = 0.7863875701403658, disc_loss = 0.10662407730667295
Trained batch 601 in epoch 3, gen_loss = 0.7859215149748761, disc_loss = 0.10675221135951207
Trained batch 602 in epoch 3, gen_loss = 0.7868005793980303, disc_loss = 0.10680117314931617
Trained batch 603 in epoch 3, gen_loss = 0.7871665780414019, disc_loss = 0.1069068659901841
Trained batch 604 in epoch 3, gen_loss = 0.7866740334625086, disc_loss = 0.10726634834331175
Trained batch 605 in epoch 3, gen_loss = 0.7866927435984312, disc_loss = 0.10717575607526272
Trained batch 606 in epoch 3, gen_loss = 0.786749543576107, disc_loss = 0.10709772672185051
Trained batch 607 in epoch 3, gen_loss = 0.7868423147715236, disc_loss = 0.10700727566175997
Trained batch 608 in epoch 3, gen_loss = 0.786642598058594, disc_loss = 0.10703702291323879
Trained batch 609 in epoch 3, gen_loss = 0.7866142111234977, disc_loss = 0.10698224233585547
Trained batch 610 in epoch 3, gen_loss = 0.787022695847697, disc_loss = 0.10692954781189341
Trained batch 611 in epoch 3, gen_loss = 0.7869769300218501, disc_loss = 0.10693194814105488
Trained batch 612 in epoch 3, gen_loss = 0.7867763639954913, disc_loss = 0.1070005015392604
Trained batch 613 in epoch 3, gen_loss = 0.7866499702103363, disc_loss = 0.10706857329307287
Trained batch 614 in epoch 3, gen_loss = 0.786270608310777, disc_loss = 0.10711905476069306
Trained batch 615 in epoch 3, gen_loss = 0.7864870451777787, disc_loss = 0.10701804372403384
Trained batch 616 in epoch 3, gen_loss = 0.7865366650265272, disc_loss = 0.1069472039577278
Trained batch 617 in epoch 3, gen_loss = 0.786460102038476, disc_loss = 0.10693248671337865
Trained batch 618 in epoch 3, gen_loss = 0.7865420802825872, disc_loss = 0.10680368489259327
Trained batch 619 in epoch 3, gen_loss = 0.7861272168255622, disc_loss = 0.10704706354036687
Trained batch 620 in epoch 3, gen_loss = 0.7864563297630316, disc_loss = 0.10710437067494924
Trained batch 621 in epoch 3, gen_loss = 0.7869411702612206, disc_loss = 0.1070763529787421
Trained batch 622 in epoch 3, gen_loss = 0.7865135256876723, disc_loss = 0.1071242703196636
Trained batch 623 in epoch 3, gen_loss = 0.7863148080710417, disc_loss = 0.1071805013776518
Trained batch 624 in epoch 3, gen_loss = 0.786409920167923, disc_loss = 0.10712121376544237
Trained batch 625 in epoch 3, gen_loss = 0.786724799690536, disc_loss = 0.10711964635928266
Trained batch 626 in epoch 3, gen_loss = 0.7864135419637963, disc_loss = 0.10714436425386291
Trained batch 627 in epoch 3, gen_loss = 0.7864355843063373, disc_loss = 0.10700472612912725
Trained batch 628 in epoch 3, gen_loss = 0.7866153189696264, disc_loss = 0.10692914446966874
Trained batch 629 in epoch 3, gen_loss = 0.7868026430171634, disc_loss = 0.106794531869569
Trained batch 630 in epoch 3, gen_loss = 0.787001984196873, disc_loss = 0.10666290851436827
Trained batch 631 in epoch 3, gen_loss = 0.7870740991887413, disc_loss = 0.1065284368372817
Trained batch 632 in epoch 3, gen_loss = 0.7868958658422527, disc_loss = 0.10645975421019499
Trained batch 633 in epoch 3, gen_loss = 0.7870536885144959, disc_loss = 0.10634764443865569
Trained batch 634 in epoch 3, gen_loss = 0.7871759312828694, disc_loss = 0.10626104695971791
Trained batch 635 in epoch 3, gen_loss = 0.7869555075307312, disc_loss = 0.10634234881631842
Trained batch 636 in epoch 3, gen_loss = 0.7867996844710136, disc_loss = 0.10630013632443346
Trained batch 637 in epoch 3, gen_loss = 0.7871198284682062, disc_loss = 0.10644443661447463
Trained batch 638 in epoch 3, gen_loss = 0.7869294369258045, disc_loss = 0.10637308557041235
Trained batch 639 in epoch 3, gen_loss = 0.7867338909301906, disc_loss = 0.1062839702135534
Trained batch 640 in epoch 3, gen_loss = 0.786742980459737, disc_loss = 0.10620213716251663
Trained batch 641 in epoch 3, gen_loss = 0.7870443427581282, disc_loss = 0.10610587812664214
Trained batch 642 in epoch 3, gen_loss = 0.7868297323932173, disc_loss = 0.10612611068357622
Trained batch 643 in epoch 3, gen_loss = 0.7864384813615994, disc_loss = 0.10608560599022261
Trained batch 644 in epoch 3, gen_loss = 0.7859670137712198, disc_loss = 0.10636218654699335
Trained batch 645 in epoch 3, gen_loss = 0.7874435003235614, disc_loss = 0.10694735608101122
Trained batch 646 in epoch 3, gen_loss = 0.7878653105388653, disc_loss = 0.10682862242352695
Trained batch 647 in epoch 3, gen_loss = 0.7876347428026759, disc_loss = 0.10698741622251907
Trained batch 648 in epoch 3, gen_loss = 0.7878841958446385, disc_loss = 0.10689215890873792
Trained batch 649 in epoch 3, gen_loss = 0.7878920606007943, disc_loss = 0.10695764567559728
Trained batch 650 in epoch 3, gen_loss = 0.7879083936207122, disc_loss = 0.10690793063857817
Trained batch 651 in epoch 3, gen_loss = 0.7875545723763712, disc_loss = 0.10698216674318023
Trained batch 652 in epoch 3, gen_loss = 0.7876299399237903, disc_loss = 0.10687974633457878
Trained batch 653 in epoch 3, gen_loss = 0.787693427106656, disc_loss = 0.1068238895058928
Trained batch 654 in epoch 3, gen_loss = 0.7875293272597189, disc_loss = 0.10686512816526735
Trained batch 655 in epoch 3, gen_loss = 0.7873057722591046, disc_loss = 0.10679830235525647
Trained batch 656 in epoch 3, gen_loss = 0.7872722591167172, disc_loss = 0.10674954283574264
Trained batch 657 in epoch 3, gen_loss = 0.7870744585900321, disc_loss = 0.10667783114917599
Trained batch 658 in epoch 3, gen_loss = 0.7870518068171054, disc_loss = 0.10660610123705656
Trained batch 659 in epoch 3, gen_loss = 0.787077751259009, disc_loss = 0.10670914677761947
Trained batch 660 in epoch 3, gen_loss = 0.7868071574035823, disc_loss = 0.10668474835528233
Trained batch 661 in epoch 3, gen_loss = 0.7865372684156786, disc_loss = 0.10666626810695515
Trained batch 662 in epoch 3, gen_loss = 0.7867799040329043, disc_loss = 0.10655788504300838
Trained batch 663 in epoch 3, gen_loss = 0.7870911721992924, disc_loss = 0.10649863139204456
Trained batch 664 in epoch 3, gen_loss = 0.7868167925149875, disc_loss = 0.10653470759245014
Trained batch 665 in epoch 3, gen_loss = 0.7868339244399343, disc_loss = 0.10645848393647207
Trained batch 666 in epoch 3, gen_loss = 0.7870061635702983, disc_loss = 0.10635178669801225
Trained batch 667 in epoch 3, gen_loss = 0.7870343179849093, disc_loss = 0.10626074579867818
Trained batch 668 in epoch 3, gen_loss = 0.7868703395707368, disc_loss = 0.10624636266024168
Trained batch 669 in epoch 3, gen_loss = 0.78709897412293, disc_loss = 0.10614381943648653
Trained batch 670 in epoch 3, gen_loss = 0.7869152978795474, disc_loss = 0.10606789328685327
Trained batch 671 in epoch 3, gen_loss = 0.7871718882538733, disc_loss = 0.10606569917235036
Trained batch 672 in epoch 3, gen_loss = 0.7870006107380627, disc_loss = 0.10614954418520738
Trained batch 673 in epoch 3, gen_loss = 0.786566493684531, disc_loss = 0.10637520260981752
Trained batch 674 in epoch 3, gen_loss = 0.7866826117480242, disc_loss = 0.10636817744070733
Trained batch 675 in epoch 3, gen_loss = 0.7867971820062434, disc_loss = 0.10634853034665996
Trained batch 676 in epoch 3, gen_loss = 0.7865298433529221, disc_loss = 0.10639465597638395
Trained batch 677 in epoch 3, gen_loss = 0.7868817738727131, disc_loss = 0.10630877217233928
Trained batch 678 in epoch 3, gen_loss = 0.7873478490579462, disc_loss = 0.10620745667702187
Trained batch 679 in epoch 3, gen_loss = 0.7870695986291941, disc_loss = 0.10614342754295862
Trained batch 680 in epoch 3, gen_loss = 0.786837274632615, disc_loss = 0.10609338165735402
Trained batch 681 in epoch 3, gen_loss = 0.7871954154408922, disc_loss = 0.106213587504208
Trained batch 682 in epoch 3, gen_loss = 0.7869898122714868, disc_loss = 0.10625660575593592
Trained batch 683 in epoch 3, gen_loss = 0.7869132523648223, disc_loss = 0.10623521619334773
Trained batch 684 in epoch 3, gen_loss = 0.7872036417035291, disc_loss = 0.10626546853786185
Trained batch 685 in epoch 3, gen_loss = 0.78709384503587, disc_loss = 0.10618642254518046
Trained batch 686 in epoch 3, gen_loss = 0.7874366049336207, disc_loss = 0.10612296376626781
Trained batch 687 in epoch 3, gen_loss = 0.7873067579470402, disc_loss = 0.10607712280118925
Trained batch 688 in epoch 3, gen_loss = 0.7870575627325581, disc_loss = 0.10609688841925694
Trained batch 689 in epoch 3, gen_loss = 0.7872567194095557, disc_loss = 0.10620210222171053
Trained batch 690 in epoch 3, gen_loss = 0.7871032077738241, disc_loss = 0.10621210162469905
Trained batch 691 in epoch 3, gen_loss = 0.7868873940382389, disc_loss = 0.1061962828473484
Trained batch 692 in epoch 3, gen_loss = 0.7868989047205981, disc_loss = 0.10610531443195124
Trained batch 693 in epoch 3, gen_loss = 0.7871535324225851, disc_loss = 0.10604427705092156
Trained batch 694 in epoch 3, gen_loss = 0.787190938424721, disc_loss = 0.10599325977453439
Trained batch 695 in epoch 3, gen_loss = 0.787441017812696, disc_loss = 0.10591642952111989
Trained batch 696 in epoch 3, gen_loss = 0.7871198334345003, disc_loss = 0.10600789795246195
Trained batch 697 in epoch 3, gen_loss = 0.7871335933577366, disc_loss = 0.1060033328470942
Trained batch 698 in epoch 3, gen_loss = 0.7871499078638734, disc_loss = 0.10591803506171285
Trained batch 699 in epoch 3, gen_loss = 0.7873029867240361, disc_loss = 0.10588356223622603
Trained batch 700 in epoch 3, gen_loss = 0.7875132280137501, disc_loss = 0.10588028764594001
Trained batch 701 in epoch 3, gen_loss = 0.7872097680711339, disc_loss = 0.10600894650423162
Trained batch 702 in epoch 3, gen_loss = 0.787577829354179, disc_loss = 0.10588181941805787
Trained batch 703 in epoch 3, gen_loss = 0.7878535434773023, disc_loss = 0.10581919899480206
Trained batch 704 in epoch 3, gen_loss = 0.787743919538268, disc_loss = 0.10578376886877397
Trained batch 705 in epoch 3, gen_loss = 0.7878145146640096, disc_loss = 0.10570965190589554
Trained batch 706 in epoch 3, gen_loss = 0.7876978896800666, disc_loss = 0.10571339010238605
Trained batch 707 in epoch 3, gen_loss = 0.7875105493654639, disc_loss = 0.10571781748321728
Trained batch 708 in epoch 3, gen_loss = 0.7873455589513685, disc_loss = 0.10564888030558572
Trained batch 709 in epoch 3, gen_loss = 0.7877340221908731, disc_loss = 0.10553382337749215
Trained batch 710 in epoch 3, gen_loss = 0.7877521196330483, disc_loss = 0.10540782053117888
Trained batch 711 in epoch 3, gen_loss = 0.7879679243216354, disc_loss = 0.1053818113162716
Trained batch 712 in epoch 3, gen_loss = 0.787849497243365, disc_loss = 0.10539639788858729
Trained batch 713 in epoch 3, gen_loss = 0.7876877321415588, disc_loss = 0.10532001191645819
Trained batch 714 in epoch 3, gen_loss = 0.7879987854223985, disc_loss = 0.10550728609746361
Trained batch 715 in epoch 3, gen_loss = 0.787706303030419, disc_loss = 0.1055825969591924
Trained batch 716 in epoch 3, gen_loss = 0.7877138764123371, disc_loss = 0.10549823032767412
Trained batch 717 in epoch 3, gen_loss = 0.7878552640380966, disc_loss = 0.10549328407833046
Trained batch 718 in epoch 3, gen_loss = 0.7882607842022256, disc_loss = 0.10537005342952441
Trained batch 719 in epoch 3, gen_loss = 0.7881685990426276, disc_loss = 0.10536083129570922
Trained batch 720 in epoch 3, gen_loss = 0.7882152944596564, disc_loss = 0.1052625741300673
Trained batch 721 in epoch 3, gen_loss = 0.7884048935944353, disc_loss = 0.10519337287389381
Trained batch 722 in epoch 3, gen_loss = 0.7885721424803199, disc_loss = 0.10510612461705632
Trained batch 723 in epoch 3, gen_loss = 0.7884936988847691, disc_loss = 0.10504072860979284
Trained batch 724 in epoch 3, gen_loss = 0.788537738405425, disc_loss = 0.10496750912404267
Trained batch 725 in epoch 3, gen_loss = 0.7889441204136725, disc_loss = 0.1049370292135445
Trained batch 726 in epoch 3, gen_loss = 0.788803313670493, disc_loss = 0.10495298579873254
Trained batch 727 in epoch 3, gen_loss = 0.7887114681057877, disc_loss = 0.10491470249170172
Trained batch 728 in epoch 3, gen_loss = 0.789183910818584, disc_loss = 0.10485811332887134
Trained batch 729 in epoch 3, gen_loss = 0.7902762542032216, disc_loss = 0.10492329621585468
Trained batch 730 in epoch 3, gen_loss = 0.7906796767512686, disc_loss = 0.10481741279745845
Trained batch 731 in epoch 3, gen_loss = 0.790561761198148, disc_loss = 0.10480103626862534
Trained batch 732 in epoch 3, gen_loss = 0.7904521331780604, disc_loss = 0.10477165370991537
Trained batch 733 in epoch 3, gen_loss = 0.7907330398663514, disc_loss = 0.10466114230509797
Trained batch 734 in epoch 3, gen_loss = 0.7908877457891191, disc_loss = 0.10460947334234204
Trained batch 735 in epoch 3, gen_loss = 0.7906697756894256, disc_loss = 0.10458110903425183
Trained batch 736 in epoch 3, gen_loss = 0.7907093417207778, disc_loss = 0.10453891975418482
Trained batch 737 in epoch 3, gen_loss = 0.7908584302679956, disc_loss = 0.10443025977706642
Trained batch 738 in epoch 3, gen_loss = 0.7908995430588883, disc_loss = 0.10442093041812414
Trained batch 739 in epoch 3, gen_loss = 0.7907465256549217, disc_loss = 0.10437916737628748
Trained batch 740 in epoch 3, gen_loss = 0.7905179773747679, disc_loss = 0.10437434247987755
Trained batch 741 in epoch 3, gen_loss = 0.7905151979781868, disc_loss = 0.10426882513725974
Trained batch 742 in epoch 3, gen_loss = 0.7906114045896568, disc_loss = 0.10420860510951216
Trained batch 743 in epoch 3, gen_loss = 0.7907197446592392, disc_loss = 0.10421121663599205
Trained batch 744 in epoch 3, gen_loss = 0.7907848337352675, disc_loss = 0.1040967704103197
Trained batch 745 in epoch 3, gen_loss = 0.790706908095618, disc_loss = 0.10401074357465628
Trained batch 746 in epoch 3, gen_loss = 0.7913265916078764, disc_loss = 0.1039488717572018
Trained batch 747 in epoch 3, gen_loss = 0.791185220932578, disc_loss = 0.10396860027312237
Trained batch 748 in epoch 3, gen_loss = 0.7911162596837542, disc_loss = 0.10402358232192864
Trained batch 749 in epoch 3, gen_loss = 0.7913532036940257, disc_loss = 0.10392493611946702
Trained batch 750 in epoch 3, gen_loss = 0.7914531421407403, disc_loss = 0.1038470944345057
Trained batch 751 in epoch 3, gen_loss = 0.791310839037946, disc_loss = 0.10377018789121722
Trained batch 752 in epoch 3, gen_loss = 0.791604526014442, disc_loss = 0.1036570128758412
Trained batch 753 in epoch 3, gen_loss = 0.7921983169623964, disc_loss = 0.10356342752861843
Trained batch 754 in epoch 3, gen_loss = 0.7925812097574702, disc_loss = 0.10346346396508793
Trained batch 755 in epoch 3, gen_loss = 0.7923143198565831, disc_loss = 0.10350569104652596
Trained batch 756 in epoch 3, gen_loss = 0.7925194987690118, disc_loss = 0.10338482053401724
Trained batch 757 in epoch 3, gen_loss = 0.7928235358644601, disc_loss = 0.10330920604900469
Trained batch 758 in epoch 3, gen_loss = 0.7930874248110101, disc_loss = 0.10318760666260017
Trained batch 759 in epoch 3, gen_loss = 0.7929970869892522, disc_loss = 0.10312532033697751
Trained batch 760 in epoch 3, gen_loss = 0.7930938423698114, disc_loss = 0.10308832773246096
Trained batch 761 in epoch 3, gen_loss = 0.7931895566581115, disc_loss = 0.1030421871948606
Trained batch 762 in epoch 3, gen_loss = 0.7930384336105337, disc_loss = 0.10297929407811454
Trained batch 763 in epoch 3, gen_loss = 0.7930268834086613, disc_loss = 0.10289899351109424
Trained batch 764 in epoch 3, gen_loss = 0.7932306129168841, disc_loss = 0.10281868803564435
Trained batch 765 in epoch 3, gen_loss = 0.7930138731282934, disc_loss = 0.1027602195489286
Trained batch 766 in epoch 3, gen_loss = 0.7928759810044836, disc_loss = 0.10278295270608061
Trained batch 767 in epoch 3, gen_loss = 0.7927355942471573, disc_loss = 0.10269276415662414
Trained batch 768 in epoch 3, gen_loss = 0.7925107057444916, disc_loss = 0.10265638338346204
Trained batch 769 in epoch 3, gen_loss = 0.7927921053651091, disc_loss = 0.10257059251647685
Trained batch 770 in epoch 3, gen_loss = 0.7929162388491104, disc_loss = 0.10253425486670896
Trained batch 771 in epoch 3, gen_loss = 0.7931385664124563, disc_loss = 0.10256862871160663
Trained batch 772 in epoch 3, gen_loss = 0.7930680084660322, disc_loss = 0.10252725423698014
Trained batch 773 in epoch 3, gen_loss = 0.7930270044532549, disc_loss = 0.1024493551813066
Trained batch 774 in epoch 3, gen_loss = 0.7937816074586683, disc_loss = 0.10252749975770711
Trained batch 775 in epoch 3, gen_loss = 0.7942660738973274, disc_loss = 0.10244203973489516
Trained batch 776 in epoch 3, gen_loss = 0.7941793173436492, disc_loss = 0.10243356478265085
Trained batch 777 in epoch 3, gen_loss = 0.7947255038203801, disc_loss = 0.10236759161203142
Trained batch 778 in epoch 3, gen_loss = 0.7948977739881337, disc_loss = 0.10226788201915706
Trained batch 779 in epoch 3, gen_loss = 0.7951353754752721, disc_loss = 0.10216172670778365
Trained batch 780 in epoch 3, gen_loss = 0.795113100132472, disc_loss = 0.10213255373672815
Trained batch 781 in epoch 3, gen_loss = 0.7949436695679374, disc_loss = 0.102084194416004
Trained batch 782 in epoch 3, gen_loss = 0.7952040465094273, disc_loss = 0.1020132835233634
Trained batch 783 in epoch 3, gen_loss = 0.7951491523762139, disc_loss = 0.10196465152025945
Trained batch 784 in epoch 3, gen_loss = 0.7951767125706763, disc_loss = 0.10186426174844716
Trained batch 785 in epoch 3, gen_loss = 0.7955029840384428, disc_loss = 0.101768869926807
Trained batch 786 in epoch 3, gen_loss = 0.7954895984111626, disc_loss = 0.10167847164424924
Trained batch 787 in epoch 3, gen_loss = 0.795501806257945, disc_loss = 0.10158510349081064
Trained batch 788 in epoch 3, gen_loss = 0.7954565600901653, disc_loss = 0.1016221664201454
Trained batch 789 in epoch 3, gen_loss = 0.7952514574497561, disc_loss = 0.10158886993303895
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9786800146102905, disc_loss = 0.0729808658361435
Trained batch 1 in epoch 4, gen_loss = 0.8813190460205078, disc_loss = 0.06355555728077888
Trained batch 2 in epoch 4, gen_loss = 0.9203896919886271, disc_loss = 0.048552692557374634
Trained batch 3 in epoch 4, gen_loss = 0.9460906982421875, disc_loss = 0.040991672314703465
Trained batch 4 in epoch 4, gen_loss = 0.9480660915374756, disc_loss = 0.03598285503685474
Trained batch 5 in epoch 4, gen_loss = 0.9251815875371298, disc_loss = 0.03312002525975307
Trained batch 6 in epoch 4, gen_loss = 0.9252822910036359, disc_loss = 0.030393555893429687
Trained batch 7 in epoch 4, gen_loss = 0.9315141811966896, disc_loss = 0.028220558655448258
Trained batch 8 in epoch 4, gen_loss = 0.9239437116516961, disc_loss = 0.029196086132691965
Trained batch 9 in epoch 4, gen_loss = 0.9156268894672394, disc_loss = 0.03269337797537446
Trained batch 10 in epoch 4, gen_loss = 0.9040304043076255, disc_loss = 0.031071031466126442
Trained batch 11 in epoch 4, gen_loss = 0.8922050148248672, disc_loss = 0.03154545261835059
Trained batch 12 in epoch 4, gen_loss = 0.8928745297285227, disc_loss = 0.031760674686386034
Trained batch 13 in epoch 4, gen_loss = 0.9009229242801666, disc_loss = 0.03548794386110136
Trained batch 14 in epoch 4, gen_loss = 0.8859586437543233, disc_loss = 0.038623318448662756
Trained batch 15 in epoch 4, gen_loss = 0.9033909477293491, disc_loss = 0.03963662206660956
Trained batch 16 in epoch 4, gen_loss = 0.8987733511363759, disc_loss = 0.039398035472806764
Trained batch 17 in epoch 4, gen_loss = 0.8842153317398496, disc_loss = 0.04646190659453472
Trained batch 18 in epoch 4, gen_loss = 0.8918943562005696, disc_loss = 0.046825778229456196
Trained batch 19 in epoch 4, gen_loss = 0.8921546906232833, disc_loss = 0.04559611910954118
Trained batch 20 in epoch 4, gen_loss = 0.8823793587230501, disc_loss = 0.0476469834822984
Trained batch 21 in epoch 4, gen_loss = 0.8837385638193651, disc_loss = 0.048888565210456196
Trained batch 22 in epoch 4, gen_loss = 0.8929963656093763, disc_loss = 0.05003919978828534
Trained batch 23 in epoch 4, gen_loss = 0.8857113247116407, disc_loss = 0.050657522942249976
Trained batch 24 in epoch 4, gen_loss = 0.8791057753562928, disc_loss = 0.05599692024290562
Trained batch 25 in epoch 4, gen_loss = 0.886169073673395, disc_loss = 0.05833461429350651
Trained batch 26 in epoch 4, gen_loss = 0.8990585870212979, disc_loss = 0.05992482443926511
Trained batch 27 in epoch 4, gen_loss = 0.8891260602644512, disc_loss = 0.06510115687602333
Trained batch 28 in epoch 4, gen_loss = 0.8858497409984983, disc_loss = 0.06440719531784797
Trained batch 29 in epoch 4, gen_loss = 0.8997628708680471, disc_loss = 0.06669989159951607
Trained batch 30 in epoch 4, gen_loss = 0.9036975541422444, disc_loss = 0.06538350177147696
Trained batch 31 in epoch 4, gen_loss = 0.9064472261816263, disc_loss = 0.06483817606931552
Trained batch 32 in epoch 4, gen_loss = 0.896482603116469, disc_loss = 0.06658886886681571
Trained batch 33 in epoch 4, gen_loss = 0.8908248158062205, disc_loss = 0.06634743582895573
Trained batch 34 in epoch 4, gen_loss = 0.890754553249904, disc_loss = 0.06574533118733338
Trained batch 35 in epoch 4, gen_loss = 0.8920034137037065, disc_loss = 0.06813760769243042
Trained batch 36 in epoch 4, gen_loss = 0.8880233184711354, disc_loss = 0.06819888833608176
Trained batch 37 in epoch 4, gen_loss = 0.8826476837459364, disc_loss = 0.06877276090610969
Trained batch 38 in epoch 4, gen_loss = 0.879119656024835, disc_loss = 0.06817250101803204
Trained batch 39 in epoch 4, gen_loss = 0.8814829647541046, disc_loss = 0.0685599699150771
Trained batch 40 in epoch 4, gen_loss = 0.8835825658426052, disc_loss = 0.06879118661873224
Trained batch 41 in epoch 4, gen_loss = 0.8819273468993959, disc_loss = 0.06829538591028679
Trained batch 42 in epoch 4, gen_loss = 0.8789356115252472, disc_loss = 0.0681883005295382
Trained batch 43 in epoch 4, gen_loss = 0.8771611519835212, disc_loss = 0.06739307927306402
Trained batch 44 in epoch 4, gen_loss = 0.8741213427649603, disc_loss = 0.0664948293318351
Trained batch 45 in epoch 4, gen_loss = 0.8720668048962302, disc_loss = 0.06611510702287374
Trained batch 46 in epoch 4, gen_loss = 0.8819872838385562, disc_loss = 0.06648594343123283
Trained batch 47 in epoch 4, gen_loss = 0.8773801885545254, disc_loss = 0.06699918734375387
Trained batch 48 in epoch 4, gen_loss = 0.8851738036895285, disc_loss = 0.07003891798762643
Trained batch 49 in epoch 4, gen_loss = 0.878726943731308, disc_loss = 0.0709933502599597
Trained batch 50 in epoch 4, gen_loss = 0.8766380723784951, disc_loss = 0.07057406676604468
Trained batch 51 in epoch 4, gen_loss = 0.8764441391596427, disc_loss = 0.07027899756884345
Trained batch 52 in epoch 4, gen_loss = 0.8712937134616779, disc_loss = 0.07134980156595977
Trained batch 53 in epoch 4, gen_loss = 0.8675680955251058, disc_loss = 0.07146084967448756
Trained batch 54 in epoch 4, gen_loss = 0.8692497058348222, disc_loss = 0.07188770117407495
Trained batch 55 in epoch 4, gen_loss = 0.8707844944936889, disc_loss = 0.07146663880640906
Trained batch 56 in epoch 4, gen_loss = 0.8653497779578493, disc_loss = 0.07443887828604172
Trained batch 57 in epoch 4, gen_loss = 0.8682438854513497, disc_loss = 0.0742831327470726
Trained batch 58 in epoch 4, gen_loss = 0.8753362186884476, disc_loss = 0.0742055279660528
Trained batch 59 in epoch 4, gen_loss = 0.872440833846728, disc_loss = 0.07424870540077487
Trained batch 60 in epoch 4, gen_loss = 0.8676742432547397, disc_loss = 0.07594240356053485
Trained batch 61 in epoch 4, gen_loss = 0.8721821019726415, disc_loss = 0.07716100383549929
Trained batch 62 in epoch 4, gen_loss = 0.8710774561715504, disc_loss = 0.07684936525211447
Trained batch 63 in epoch 4, gen_loss = 0.8729057554155588, disc_loss = 0.0763129873375874
Trained batch 64 in epoch 4, gen_loss = 0.8695067689968989, disc_loss = 0.07599872617194285
Trained batch 65 in epoch 4, gen_loss = 0.8654439855705608, disc_loss = 0.07581600244862563
Trained batch 66 in epoch 4, gen_loss = 0.8669649496007321, disc_loss = 0.07727492625700004
Trained batch 67 in epoch 4, gen_loss = 0.8681320399045944, disc_loss = 0.07640781133052181
Trained batch 68 in epoch 4, gen_loss = 0.8621065677076146, disc_loss = 0.0800207742098449
Trained batch 69 in epoch 4, gen_loss = 0.8671855611460549, disc_loss = 0.0794384459831885
Trained batch 70 in epoch 4, gen_loss = 0.8659587829885348, disc_loss = 0.08023014218664505
Trained batch 71 in epoch 4, gen_loss = 0.8648277165161239, disc_loss = 0.0802586445481413
Trained batch 72 in epoch 4, gen_loss = 0.8591417315071577, disc_loss = 0.08093605124174733
Trained batch 73 in epoch 4, gen_loss = 0.8552872896999926, disc_loss = 0.08184148295706994
Trained batch 74 in epoch 4, gen_loss = 0.8564499715963999, disc_loss = 0.08177355562647183
Trained batch 75 in epoch 4, gen_loss = 0.8587028654782396, disc_loss = 0.08171439960010742
Trained batch 76 in epoch 4, gen_loss = 0.8568689269678933, disc_loss = 0.0812475314097745
Trained batch 77 in epoch 4, gen_loss = 0.8550934963501416, disc_loss = 0.08162314134339492
Trained batch 78 in epoch 4, gen_loss = 0.8589043455033363, disc_loss = 0.08201350304710714
Trained batch 79 in epoch 4, gen_loss = 0.8573069985955953, disc_loss = 0.08157627498731017
Trained batch 80 in epoch 4, gen_loss = 0.8568386924855503, disc_loss = 0.08114152355694476
Trained batch 81 in epoch 4, gen_loss = 0.8587542783196379, disc_loss = 0.0803155613972283
Trained batch 82 in epoch 4, gen_loss = 0.8562478153820497, disc_loss = 0.08000904593212776
Trained batch 83 in epoch 4, gen_loss = 0.8591821459787232, disc_loss = 0.08066332484373734
Trained batch 84 in epoch 4, gen_loss = 0.8560566772432888, disc_loss = 0.08155050122124308
Trained batch 85 in epoch 4, gen_loss = 0.8571427405573601, disc_loss = 0.0814238440375342
Trained batch 86 in epoch 4, gen_loss = 0.8574690171356859, disc_loss = 0.0809559406948158
Trained batch 87 in epoch 4, gen_loss = 0.8550997312096033, disc_loss = 0.08109484606591816
Trained batch 88 in epoch 4, gen_loss = 0.8564932061715073, disc_loss = 0.08147969735221247
Trained batch 89 in epoch 4, gen_loss = 0.8560272438658608, disc_loss = 0.08098075193249517
Trained batch 90 in epoch 4, gen_loss = 0.8533652362587688, disc_loss = 0.08098272973118903
Trained batch 91 in epoch 4, gen_loss = 0.8540765290027079, disc_loss = 0.08237908661122555
Trained batch 92 in epoch 4, gen_loss = 0.851277171604095, disc_loss = 0.08272579795009988
Trained batch 93 in epoch 4, gen_loss = 0.850890226503636, disc_loss = 0.08247155717950552
Trained batch 94 in epoch 4, gen_loss = 0.8518932502520712, disc_loss = 0.08190771911881473
Trained batch 95 in epoch 4, gen_loss = 0.8522893336291114, disc_loss = 0.08134665429436912
Trained batch 96 in epoch 4, gen_loss = 0.850066761073378, disc_loss = 0.08128626179910198
Trained batch 97 in epoch 4, gen_loss = 0.8488633939806296, disc_loss = 0.0811282142768709
Trained batch 98 in epoch 4, gen_loss = 0.8499183061749044, disc_loss = 0.08163108507340605
Trained batch 99 in epoch 4, gen_loss = 0.8488740679621697, disc_loss = 0.08120008815079928
Trained batch 100 in epoch 4, gen_loss = 0.8471862476060886, disc_loss = 0.08098240429074458
Trained batch 101 in epoch 4, gen_loss = 0.8500054615969751, disc_loss = 0.0808933201592927
Trained batch 102 in epoch 4, gen_loss = 0.8490279441319623, disc_loss = 0.08046114173473663
Trained batch 103 in epoch 4, gen_loss = 0.8494465302389401, disc_loss = 0.08006337034301116
Trained batch 104 in epoch 4, gen_loss = 0.851323424918311, disc_loss = 0.07951817067251318
Trained batch 105 in epoch 4, gen_loss = 0.8497606569303656, disc_loss = 0.0795586389788198
Trained batch 106 in epoch 4, gen_loss = 0.8494433390202923, disc_loss = 0.07926255800526276
Trained batch 107 in epoch 4, gen_loss = 0.849400941144537, disc_loss = 0.0793003440765595
Trained batch 108 in epoch 4, gen_loss = 0.8498338419909871, disc_loss = 0.07878431365098976
Trained batch 109 in epoch 4, gen_loss = 0.849657918377356, disc_loss = 0.07850685869766907
Trained batch 110 in epoch 4, gen_loss = 0.8482985912679551, disc_loss = 0.07848513842904353
Trained batch 111 in epoch 4, gen_loss = 0.8483742089676005, disc_loss = 0.0779296483545165
Trained batch 112 in epoch 4, gen_loss = 0.8476590063192148, disc_loss = 0.07769563377101336
Trained batch 113 in epoch 4, gen_loss = 0.8464102162080899, disc_loss = 0.07774872579530143
Trained batch 114 in epoch 4, gen_loss = 0.8479369839896327, disc_loss = 0.07787157159460628
Trained batch 115 in epoch 4, gen_loss = 0.8476335645235819, disc_loss = 0.07772174411742337
Trained batch 116 in epoch 4, gen_loss = 0.8460847865312527, disc_loss = 0.07779036447978936
Trained batch 117 in epoch 4, gen_loss = 0.8464602234504991, disc_loss = 0.0787503370636348
Trained batch 118 in epoch 4, gen_loss = 0.8477709636467845, disc_loss = 0.07820966201951775
Trained batch 119 in epoch 4, gen_loss = 0.8468829813102882, disc_loss = 0.0783049061972027
Trained batch 120 in epoch 4, gen_loss = 0.8473836767279412, disc_loss = 0.07781676289987219
Trained batch 121 in epoch 4, gen_loss = 0.8484488342140541, disc_loss = 0.07930286931728975
Trained batch 122 in epoch 4, gen_loss = 0.8462245898033546, disc_loss = 0.08010093935167159
Trained batch 123 in epoch 4, gen_loss = 0.845331989709408, disc_loss = 0.07981974319855292
Trained batch 124 in epoch 4, gen_loss = 0.8445416276454926, disc_loss = 0.07960327119380235
Trained batch 125 in epoch 4, gen_loss = 0.8430581497294563, disc_loss = 0.07931276648083613
Trained batch 126 in epoch 4, gen_loss = 0.8439405755264553, disc_loss = 0.07961463266030305
Trained batch 127 in epoch 4, gen_loss = 0.8433052862528712, disc_loss = 0.07946613850799622
Trained batch 128 in epoch 4, gen_loss = 0.843188195958618, disc_loss = 0.07951851022364788
Trained batch 129 in epoch 4, gen_loss = 0.8425404225404446, disc_loss = 0.07990020955554568
Trained batch 130 in epoch 4, gen_loss = 0.8411064409572659, disc_loss = 0.0797621798950411
Trained batch 131 in epoch 4, gen_loss = 0.8439713154326786, disc_loss = 0.07940048550142709
Trained batch 132 in epoch 4, gen_loss = 0.8441952729135528, disc_loss = 0.07921901194700845
Trained batch 133 in epoch 4, gen_loss = 0.8455333836487869, disc_loss = 0.07874856557724859
Trained batch 134 in epoch 4, gen_loss = 0.8457424298480705, disc_loss = 0.07873193998993547
Trained batch 135 in epoch 4, gen_loss = 0.8469224434126826, disc_loss = 0.07828213975025232
Trained batch 136 in epoch 4, gen_loss = 0.8444695092030685, disc_loss = 0.07920908905484163
Trained batch 137 in epoch 4, gen_loss = 0.8463043002546697, disc_loss = 0.07899957516676058
Trained batch 138 in epoch 4, gen_loss = 0.8477333820552277, disc_loss = 0.07869007644116235
Trained batch 139 in epoch 4, gen_loss = 0.8457695401140621, disc_loss = 0.07886466806355331
Trained batch 140 in epoch 4, gen_loss = 0.8458141919146193, disc_loss = 0.07879836732482022
Trained batch 141 in epoch 4, gen_loss = 0.8445196796051213, disc_loss = 0.07859746381824076
Trained batch 142 in epoch 4, gen_loss = 0.8431075709266262, disc_loss = 0.0787805682959986
Trained batch 143 in epoch 4, gen_loss = 0.8424203269597557, disc_loss = 0.07889898829550172
Trained batch 144 in epoch 4, gen_loss = 0.842461731721615, disc_loss = 0.07862129858213251
Trained batch 145 in epoch 4, gen_loss = 0.8426523725055668, disc_loss = 0.07876421428885158
Trained batch 146 in epoch 4, gen_loss = 0.8415084195380308, disc_loss = 0.07887377675470648
Trained batch 147 in epoch 4, gen_loss = 0.8440379196324864, disc_loss = 0.07881742005387472
Trained batch 148 in epoch 4, gen_loss = 0.843982840744441, disc_loss = 0.07855860973339553
Trained batch 149 in epoch 4, gen_loss = 0.8425206965208054, disc_loss = 0.07903301859274507
Trained batch 150 in epoch 4, gen_loss = 0.842019775253258, disc_loss = 0.07878015387112534
Trained batch 151 in epoch 4, gen_loss = 0.8417379948261537, disc_loss = 0.07847556650123902
Trained batch 152 in epoch 4, gen_loss = 0.8421839247731602, disc_loss = 0.0783236595479394
Trained batch 153 in epoch 4, gen_loss = 0.8426523318925461, disc_loss = 0.07832033428448168
Trained batch 154 in epoch 4, gen_loss = 0.8429884658705804, disc_loss = 0.0780008205903634
Trained batch 155 in epoch 4, gen_loss = 0.8414578134050736, disc_loss = 0.07852659703423388
Trained batch 156 in epoch 4, gen_loss = 0.840261052938024, disc_loss = 0.07852700181234225
Trained batch 157 in epoch 4, gen_loss = 0.8412936448673659, disc_loss = 0.07872083796706947
Trained batch 158 in epoch 4, gen_loss = 0.839356965051507, disc_loss = 0.07896990066031052
Trained batch 159 in epoch 4, gen_loss = 0.8404863147065044, disc_loss = 0.07932651335722767
Trained batch 160 in epoch 4, gen_loss = 0.8415253175341565, disc_loss = 0.07907541486671808
Trained batch 161 in epoch 4, gen_loss = 0.8421584001661818, disc_loss = 0.07872541072306993
Trained batch 162 in epoch 4, gen_loss = 0.8415371978575467, disc_loss = 0.0785969356189202
Trained batch 163 in epoch 4, gen_loss = 0.841341053749003, disc_loss = 0.07842947854433299
Trained batch 164 in epoch 4, gen_loss = 0.8420737178036661, disc_loss = 0.07866175751004255
Trained batch 165 in epoch 4, gen_loss = 0.8402391325637518, disc_loss = 0.07960612854796899
Trained batch 166 in epoch 4, gen_loss = 0.8399553828967545, disc_loss = 0.08021437798899983
Trained batch 167 in epoch 4, gen_loss = 0.839078526234343, disc_loss = 0.08026520742125631
Trained batch 168 in epoch 4, gen_loss = 0.839878612545115, disc_loss = 0.07998745093265405
Trained batch 169 in epoch 4, gen_loss = 0.840576155220761, disc_loss = 0.07966370793497737
Trained batch 170 in epoch 4, gen_loss = 0.839498186843437, disc_loss = 0.07949169947934603
Trained batch 171 in epoch 4, gen_loss = 0.8382625734043676, disc_loss = 0.07969763814904836
Trained batch 172 in epoch 4, gen_loss = 0.8385766925494795, disc_loss = 0.07963395778175895
Trained batch 173 in epoch 4, gen_loss = 0.8383483525322771, disc_loss = 0.07965191115957053
Trained batch 174 in epoch 4, gen_loss = 0.8381071432999202, disc_loss = 0.07953368743083307
Trained batch 175 in epoch 4, gen_loss = 0.8394960031252016, disc_loss = 0.0795677048842084
Trained batch 176 in epoch 4, gen_loss = 0.8384100830150862, disc_loss = 0.07945640926580813
Trained batch 177 in epoch 4, gen_loss = 0.8383890830733803, disc_loss = 0.07924431391332425
Trained batch 178 in epoch 4, gen_loss = 0.8383085346421716, disc_loss = 0.07915675528243434
Trained batch 179 in epoch 4, gen_loss = 0.8385432635744413, disc_loss = 0.07891426906507049
Trained batch 180 in epoch 4, gen_loss = 0.8375172830747636, disc_loss = 0.07897058393271095
Trained batch 181 in epoch 4, gen_loss = 0.839429530959863, disc_loss = 0.07991614528921442
Trained batch 182 in epoch 4, gen_loss = 0.8385337146579243, disc_loss = 0.07977617296385146
Trained batch 183 in epoch 4, gen_loss = 0.8372714858016242, disc_loss = 0.07997141507676923
Trained batch 184 in epoch 4, gen_loss = 0.8378176884071247, disc_loss = 0.0798259653402744
Trained batch 185 in epoch 4, gen_loss = 0.8381336922607114, disc_loss = 0.07951403521902618
Trained batch 186 in epoch 4, gen_loss = 0.8382355974001043, disc_loss = 0.0792552728335408
Trained batch 187 in epoch 4, gen_loss = 0.8378208696525148, disc_loss = 0.07938651228818963
Trained batch 188 in epoch 4, gen_loss = 0.8379012855587813, disc_loss = 0.07924651093879546
Trained batch 189 in epoch 4, gen_loss = 0.8387073176471811, disc_loss = 0.07902632486565332
Trained batch 190 in epoch 4, gen_loss = 0.8374949111676341, disc_loss = 0.07957320802245309
Trained batch 191 in epoch 4, gen_loss = 0.837980039883405, disc_loss = 0.07947630087437574
Trained batch 192 in epoch 4, gen_loss = 0.8392686582908729, disc_loss = 0.07937002951674973
Trained batch 193 in epoch 4, gen_loss = 0.8384449535731188, disc_loss = 0.07946382721732419
Trained batch 194 in epoch 4, gen_loss = 0.8368542107251974, disc_loss = 0.0805668793953
Trained batch 195 in epoch 4, gen_loss = 0.8382882845340943, disc_loss = 0.08172842264840645
Trained batch 196 in epoch 4, gen_loss = 0.8387233797971367, disc_loss = 0.08146513396694424
Trained batch 197 in epoch 4, gen_loss = 0.8374172718536974, disc_loss = 0.08203521916040718
Trained batch 198 in epoch 4, gen_loss = 0.8375164203008815, disc_loss = 0.0818912313090422
Trained batch 199 in epoch 4, gen_loss = 0.8381145180761814, disc_loss = 0.08185870211105793
Trained batch 200 in epoch 4, gen_loss = 0.837433735677852, disc_loss = 0.08173988768321216
Trained batch 201 in epoch 4, gen_loss = 0.8370184970669227, disc_loss = 0.08155125497130326
Trained batch 202 in epoch 4, gen_loss = 0.8379836031075182, disc_loss = 0.08181154521943754
Trained batch 203 in epoch 4, gen_loss = 0.8389041220732764, disc_loss = 0.08155925632637068
Trained batch 204 in epoch 4, gen_loss = 0.8383627026546292, disc_loss = 0.08155054848459435
Trained batch 205 in epoch 4, gen_loss = 0.8382294792862772, disc_loss = 0.0814942651229359
Trained batch 206 in epoch 4, gen_loss = 0.8369084733407854, disc_loss = 0.08186932687832106
Trained batch 207 in epoch 4, gen_loss = 0.8402358859490889, disc_loss = 0.08328901871125428
Trained batch 208 in epoch 4, gen_loss = 0.8406257867527921, disc_loss = 0.08300074484448826
Trained batch 209 in epoch 4, gen_loss = 0.8398224261545, disc_loss = 0.0833454946543844
Trained batch 210 in epoch 4, gen_loss = 0.8399836106040467, disc_loss = 0.0832191693918753
Trained batch 211 in epoch 4, gen_loss = 0.8403381692632189, disc_loss = 0.08337700850646591
Trained batch 212 in epoch 4, gen_loss = 0.8405599061032416, disc_loss = 0.08304275069035974
Trained batch 213 in epoch 4, gen_loss = 0.8395828260718105, disc_loss = 0.0832050089706954
Trained batch 214 in epoch 4, gen_loss = 0.8389994492364484, disc_loss = 0.08308661263436079
Trained batch 215 in epoch 4, gen_loss = 0.8409359989066919, disc_loss = 0.08362331588459374
Trained batch 216 in epoch 4, gen_loss = 0.8400344284174079, disc_loss = 0.08352454132421912
Trained batch 217 in epoch 4, gen_loss = 0.8396235692118286, disc_loss = 0.08347832317968164
Trained batch 218 in epoch 4, gen_loss = 0.8395354583110983, disc_loss = 0.08323461816276181
Trained batch 219 in epoch 4, gen_loss = 0.8410590614784847, disc_loss = 0.08319326698864725
Trained batch 220 in epoch 4, gen_loss = 0.8406506516545067, disc_loss = 0.08331290809901187
Trained batch 221 in epoch 4, gen_loss = 0.8408856865790513, disc_loss = 0.083053748387642
Trained batch 222 in epoch 4, gen_loss = 0.8411059584050969, disc_loss = 0.08291980751577113
Trained batch 223 in epoch 4, gen_loss = 0.8403442375628012, disc_loss = 0.0827957040039889
Trained batch 224 in epoch 4, gen_loss = 0.8393583071231842, disc_loss = 0.08301809630874131
Trained batch 225 in epoch 4, gen_loss = 0.8397838756837676, disc_loss = 0.08349580458258238
Trained batch 226 in epoch 4, gen_loss = 0.8394910547439223, disc_loss = 0.083472982660297
Trained batch 227 in epoch 4, gen_loss = 0.8385341404038563, disc_loss = 0.0836231351233692
Trained batch 228 in epoch 4, gen_loss = 0.8387307809690201, disc_loss = 0.08333551539230165
Trained batch 229 in epoch 4, gen_loss = 0.8382999867200851, disc_loss = 0.0831845360322167
Trained batch 230 in epoch 4, gen_loss = 0.8386127206928287, disc_loss = 0.08306833482811074
Trained batch 231 in epoch 4, gen_loss = 0.8377010833857388, disc_loss = 0.0833491352266343
Trained batch 232 in epoch 4, gen_loss = 0.8372881720761884, disc_loss = 0.08381741689398181
Trained batch 233 in epoch 4, gen_loss = 0.836802128670562, disc_loss = 0.08370054233421245
Trained batch 234 in epoch 4, gen_loss = 0.8367341565324905, disc_loss = 0.08355832575879832
Trained batch 235 in epoch 4, gen_loss = 0.8361380379331314, disc_loss = 0.08370572114284387
Trained batch 236 in epoch 4, gen_loss = 0.8359512851459567, disc_loss = 0.08398203181205043
Trained batch 237 in epoch 4, gen_loss = 0.836091474449935, disc_loss = 0.08386169150549949
Trained batch 238 in epoch 4, gen_loss = 0.8354057586093327, disc_loss = 0.08395863544569979
Trained batch 239 in epoch 4, gen_loss = 0.8358737874776125, disc_loss = 0.08394411478269224
Trained batch 240 in epoch 4, gen_loss = 0.8358792270614893, disc_loss = 0.08381075358319703
Trained batch 241 in epoch 4, gen_loss = 0.8350258039787781, disc_loss = 0.08377319486996482
Trained batch 242 in epoch 4, gen_loss = 0.8360545413239012, disc_loss = 0.08379414550760769
Trained batch 243 in epoch 4, gen_loss = 0.8352955358683086, disc_loss = 0.08382108299534952
Trained batch 244 in epoch 4, gen_loss = 0.834620933994955, disc_loss = 0.08410320299088346
Trained batch 245 in epoch 4, gen_loss = 0.8348022317740975, disc_loss = 0.08407162219603978
Trained batch 246 in epoch 4, gen_loss = 0.8339943990774965, disc_loss = 0.08413380573349082
Trained batch 247 in epoch 4, gen_loss = 0.8323404215756924, disc_loss = 0.08448196444735531
Trained batch 248 in epoch 4, gen_loss = 0.8338037287614432, disc_loss = 0.08499590665416186
Trained batch 249 in epoch 4, gen_loss = 0.8332264636754989, disc_loss = 0.08500005086138844
Trained batch 250 in epoch 4, gen_loss = 0.8325733339406579, disc_loss = 0.08503704214194026
Trained batch 251 in epoch 4, gen_loss = 0.8325422669923495, disc_loss = 0.08493971542662217
Trained batch 252 in epoch 4, gen_loss = 0.8322287584717566, disc_loss = 0.08480629977575051
Trained batch 253 in epoch 4, gen_loss = 0.8323231120043852, disc_loss = 0.08460729210234182
Trained batch 254 in epoch 4, gen_loss = 0.8319085942763909, disc_loss = 0.08450410150210647
Trained batch 255 in epoch 4, gen_loss = 0.832525804056786, disc_loss = 0.0845580711356888
Trained batch 256 in epoch 4, gen_loss = 0.8321974415491528, disc_loss = 0.084335688367515
Trained batch 257 in epoch 4, gen_loss = 0.8313563183065533, disc_loss = 0.08446465391853406
Trained batch 258 in epoch 4, gen_loss = 0.8318389593174098, disc_loss = 0.08439129308714714
Trained batch 259 in epoch 4, gen_loss = 0.8310610902997163, disc_loss = 0.08429728435137523
Trained batch 260 in epoch 4, gen_loss = 0.8318620905337206, disc_loss = 0.08435595724588953
Trained batch 261 in epoch 4, gen_loss = 0.8317960535979453, disc_loss = 0.08413451166027261
Trained batch 262 in epoch 4, gen_loss = 0.8310642660570688, disc_loss = 0.08422646199498227
Trained batch 263 in epoch 4, gen_loss = 0.8310572187783141, disc_loss = 0.08415536532728848
Trained batch 264 in epoch 4, gen_loss = 0.8305291404139321, disc_loss = 0.08412339140151469
Trained batch 265 in epoch 4, gen_loss = 0.8323852857924942, disc_loss = 0.08440181538392615
Trained batch 266 in epoch 4, gen_loss = 0.8314297660236502, disc_loss = 0.08469179075574049
Trained batch 267 in epoch 4, gen_loss = 0.8316740541538196, disc_loss = 0.08453897034763289
Trained batch 268 in epoch 4, gen_loss = 0.8322280096963436, disc_loss = 0.08464777642397078
Trained batch 269 in epoch 4, gen_loss = 0.8327149334881041, disc_loss = 0.0845563070193209
Trained batch 270 in epoch 4, gen_loss = 0.8320716127918215, disc_loss = 0.084864803576134
Trained batch 271 in epoch 4, gen_loss = 0.8322740820619989, disc_loss = 0.08481434421435766
Trained batch 272 in epoch 4, gen_loss = 0.8321217504831461, disc_loss = 0.08493274437679803
Trained batch 273 in epoch 4, gen_loss = 0.8318818902229741, disc_loss = 0.08481352344957473
Trained batch 274 in epoch 4, gen_loss = 0.833226447430524, disc_loss = 0.08473441534082998
Trained batch 275 in epoch 4, gen_loss = 0.83237298750791, disc_loss = 0.08500640092593065
Trained batch 276 in epoch 4, gen_loss = 0.833394204989237, disc_loss = 0.0851082616596607
Trained batch 277 in epoch 4, gen_loss = 0.8336940202996027, disc_loss = 0.08487997756493713
Trained batch 278 in epoch 4, gen_loss = 0.8337459680640996, disc_loss = 0.08473500900811726
Trained batch 279 in epoch 4, gen_loss = 0.8337725184857845, disc_loss = 0.08455408460660173
Trained batch 280 in epoch 4, gen_loss = 0.8328400119555802, disc_loss = 0.08466512665112778
Trained batch 281 in epoch 4, gen_loss = 0.8333733645102657, disc_loss = 0.08451063239101506
Trained batch 282 in epoch 4, gen_loss = 0.8332256128215115, disc_loss = 0.08449332382161394
Trained batch 283 in epoch 4, gen_loss = 0.8327630184276004, disc_loss = 0.08441233779566074
Trained batch 284 in epoch 4, gen_loss = 0.83525140505088, disc_loss = 0.08556083731287926
Trained batch 285 in epoch 4, gen_loss = 0.8358067358498806, disc_loss = 0.08537643008468139
Trained batch 286 in epoch 4, gen_loss = 0.8353460101923461, disc_loss = 0.08546459583000958
Trained batch 287 in epoch 4, gen_loss = 0.834898573346436, disc_loss = 0.08538646068902583
Trained batch 288 in epoch 4, gen_loss = 0.835101430906969, disc_loss = 0.08548125474162684
Trained batch 289 in epoch 4, gen_loss = 0.8343653624427729, disc_loss = 0.08561352546936993
Trained batch 290 in epoch 4, gen_loss = 0.8345634715049127, disc_loss = 0.08549289670660835
Trained batch 291 in epoch 4, gen_loss = 0.8342475212396008, disc_loss = 0.08540480997579249
Trained batch 292 in epoch 4, gen_loss = 0.8336548466527828, disc_loss = 0.08539480662907858
Trained batch 293 in epoch 4, gen_loss = 0.8340135714432009, disc_loss = 0.08533638391681776
Trained batch 294 in epoch 4, gen_loss = 0.8336225169189906, disc_loss = 0.08535300286455175
Trained batch 295 in epoch 4, gen_loss = 0.8342966456469652, disc_loss = 0.08562631180472169
Trained batch 296 in epoch 4, gen_loss = 0.8343094449854057, disc_loss = 0.08567096361018692
Trained batch 297 in epoch 4, gen_loss = 0.8341424740200875, disc_loss = 0.08588296537843827
Trained batch 298 in epoch 4, gen_loss = 0.8346768076403882, disc_loss = 0.08610655743952679
Trained batch 299 in epoch 4, gen_loss = 0.8348045928279558, disc_loss = 0.08659562093826632
Trained batch 300 in epoch 4, gen_loss = 0.8357409130893276, disc_loss = 0.08682604329939003
Trained batch 301 in epoch 4, gen_loss = 0.8355839579113272, disc_loss = 0.08679370713167336
Trained batch 302 in epoch 4, gen_loss = 0.8351801601376864, disc_loss = 0.08676771074840829
Trained batch 303 in epoch 4, gen_loss = 0.8351006299061211, disc_loss = 0.08682864439048756
Trained batch 304 in epoch 4, gen_loss = 0.8348399935198612, disc_loss = 0.0867819627075166
Trained batch 305 in epoch 4, gen_loss = 0.835102350201482, disc_loss = 0.08673312481237101
Trained batch 306 in epoch 4, gen_loss = 0.8348627112781575, disc_loss = 0.086770867755946
Trained batch 307 in epoch 4, gen_loss = 0.834235176734336, disc_loss = 0.08675391072492031
Trained batch 308 in epoch 4, gen_loss = 0.8338332445297426, disc_loss = 0.08676007882206667
Trained batch 309 in epoch 4, gen_loss = 0.8335538219059667, disc_loss = 0.08665234837380628
Trained batch 310 in epoch 4, gen_loss = 0.8329306489210037, disc_loss = 0.08659571022621784
Trained batch 311 in epoch 4, gen_loss = 0.8334914912971166, disc_loss = 0.08650516892055002
Trained batch 312 in epoch 4, gen_loss = 0.8341954193366602, disc_loss = 0.0863119714801161
Trained batch 313 in epoch 4, gen_loss = 0.834485867695444, disc_loss = 0.08622259045446849
Trained batch 314 in epoch 4, gen_loss = 0.8339429116438306, disc_loss = 0.08639059564956124
Trained batch 315 in epoch 4, gen_loss = 0.834196107957182, disc_loss = 0.08672678476800741
Trained batch 316 in epoch 4, gen_loss = 0.8340151636194355, disc_loss = 0.08662842763205902
Trained batch 317 in epoch 4, gen_loss = 0.8334086691995837, disc_loss = 0.08665601334259289
Trained batch 318 in epoch 4, gen_loss = 0.8327170671153592, disc_loss = 0.08676257070013815
Trained batch 319 in epoch 4, gen_loss = 0.8340620351023972, disc_loss = 0.08726186588464771
Trained batch 320 in epoch 4, gen_loss = 0.8340509597943208, disc_loss = 0.08704955551216256
Trained batch 321 in epoch 4, gen_loss = 0.8335492489685924, disc_loss = 0.08721043618673587
Trained batch 322 in epoch 4, gen_loss = 0.8331010073146584, disc_loss = 0.08720001546325791
Trained batch 323 in epoch 4, gen_loss = 0.833047681292634, disc_loss = 0.08732364009663371
Trained batch 324 in epoch 4, gen_loss = 0.8325082704654106, disc_loss = 0.08737408429670793
Trained batch 325 in epoch 4, gen_loss = 0.8315493946243648, disc_loss = 0.0874328342483499
Trained batch 326 in epoch 4, gen_loss = 0.8320095937368702, disc_loss = 0.08734782491540052
Trained batch 327 in epoch 4, gen_loss = 0.8315679878905052, disc_loss = 0.08734381458120102
Trained batch 328 in epoch 4, gen_loss = 0.8312450981611177, disc_loss = 0.08722125083536453
Trained batch 329 in epoch 4, gen_loss = 0.8311549736694857, disc_loss = 0.08723656843613946
Trained batch 330 in epoch 4, gen_loss = 0.8322975845315305, disc_loss = 0.08746839750535629
Trained batch 331 in epoch 4, gen_loss = 0.8315079999436815, disc_loss = 0.08800202815972986
Trained batch 332 in epoch 4, gen_loss = 0.8314735453587037, disc_loss = 0.08793350706553764
Trained batch 333 in epoch 4, gen_loss = 0.8314625478968649, disc_loss = 0.08786672453290063
Trained batch 334 in epoch 4, gen_loss = 0.8317858691535779, disc_loss = 0.08787394380891946
Trained batch 335 in epoch 4, gen_loss = 0.8308440442418769, disc_loss = 0.08819524457378845
Trained batch 336 in epoch 4, gen_loss = 0.8311181987251656, disc_loss = 0.08803843451768867
Trained batch 337 in epoch 4, gen_loss = 0.8319610215326738, disc_loss = 0.08794283562962561
Trained batch 338 in epoch 4, gen_loss = 0.8319619393805838, disc_loss = 0.08776590980556423
Trained batch 339 in epoch 4, gen_loss = 0.8321463981972022, disc_loss = 0.08760388218249907
Trained batch 340 in epoch 4, gen_loss = 0.8319901204353903, disc_loss = 0.08757059884331356
Trained batch 341 in epoch 4, gen_loss = 0.8319292093752421, disc_loss = 0.08746779338342317
Trained batch 342 in epoch 4, gen_loss = 0.8317164847350329, disc_loss = 0.08739814538856203
Trained batch 343 in epoch 4, gen_loss = 0.8314512958533542, disc_loss = 0.0873862016204268
Trained batch 344 in epoch 4, gen_loss = 0.8312870793584465, disc_loss = 0.08725989852640507
Trained batch 345 in epoch 4, gen_loss = 0.8312172353095402, disc_loss = 0.0872886301330533
Trained batch 346 in epoch 4, gen_loss = 0.8311722214180729, disc_loss = 0.0871953900221746
Trained batch 347 in epoch 4, gen_loss = 0.8304512707152586, disc_loss = 0.08734079908269148
Trained batch 348 in epoch 4, gen_loss = 0.8306535076787616, disc_loss = 0.08748897619513438
Trained batch 350 in epoch 4, gen_loss = 0.8295345089883885, disc_loss = 0.08741871401020179
Trained batch 351 in epoch 4, gen_loss = 0.8299309305677359, disc_loss = 0.08750875469625251
Trained batch 352 in epoch 4, gen_loss = 0.8306050664473525, disc_loss = 0.08753378553943915
Trained batch 353 in epoch 4, gen_loss = 0.8299535358861342, disc_loss = 0.08779047004152406
Trained batch 354 in epoch 4, gen_loss = 0.8296409621205129, disc_loss = 0.08776296114575276
Trained batch 355 in epoch 4, gen_loss = 0.8300236330440874, disc_loss = 0.0877405471362048
Trained batch 356 in epoch 4, gen_loss = 0.829744643941313, disc_loss = 0.08778358190072601
Trained batch 357 in epoch 4, gen_loss = 0.8294771139681673, disc_loss = 0.08768912994526534
Trained batch 358 in epoch 4, gen_loss = 0.8290694134315076, disc_loss = 0.08760102247575448
Trained batch 359 in epoch 4, gen_loss = 0.8296957528425588, disc_loss = 0.0877824210949863
Trained batch 360 in epoch 4, gen_loss = 0.8294539270803869, disc_loss = 0.08774507828727571
Trained batch 361 in epoch 4, gen_loss = 0.8294425940151373, disc_loss = 0.0875993977424313
Trained batch 362 in epoch 4, gen_loss = 0.8287631185422587, disc_loss = 0.08756623491798797
Trained batch 363 in epoch 4, gen_loss = 0.8290887515132244, disc_loss = 0.08738947549456177
Trained batch 364 in epoch 4, gen_loss = 0.8287412299685282, disc_loss = 0.08733249286521379
Trained batch 365 in epoch 4, gen_loss = 0.8286764164928531, disc_loss = 0.08720956574056725
Trained batch 366 in epoch 4, gen_loss = 0.8294100026506169, disc_loss = 0.08732392679778123
Trained batch 367 in epoch 4, gen_loss = 0.8290858661512965, disc_loss = 0.08732110513222363
Trained batch 368 in epoch 4, gen_loss = 0.8285292851407999, disc_loss = 0.08738417198836076
Trained batch 369 in epoch 4, gen_loss = 0.8298176171811851, disc_loss = 0.08760846847466923
Trained batch 370 in epoch 4, gen_loss = 0.8295606749880347, disc_loss = 0.08766739301614443
Trained batch 371 in epoch 4, gen_loss = 0.8293542100056526, disc_loss = 0.08775104890998092
Trained batch 372 in epoch 4, gen_loss = 0.8287015019568936, disc_loss = 0.0878393179075368
Trained batch 373 in epoch 4, gen_loss = 0.8281922894206276, disc_loss = 0.08787972783112032
Trained batch 374 in epoch 4, gen_loss = 0.8284905976454416, disc_loss = 0.0879833072051406
Trained batch 375 in epoch 4, gen_loss = 0.8289294326083457, disc_loss = 0.0878907701005525
Trained batch 376 in epoch 4, gen_loss = 0.8279964995795283, disc_loss = 0.08824489079168762
Trained batch 377 in epoch 4, gen_loss = 0.8287887033173647, disc_loss = 0.08814325088280298
Trained batch 378 in epoch 4, gen_loss = 0.8291352984930406, disc_loss = 0.08835386686606976
Trained batch 379 in epoch 4, gen_loss = 0.8283766817889715, disc_loss = 0.0886701459481724
Trained batch 380 in epoch 4, gen_loss = 0.8283159588109165, disc_loss = 0.08861466819112461
Trained batch 381 in epoch 4, gen_loss = 0.8277586276462565, disc_loss = 0.08860120896240258
Trained batch 382 in epoch 4, gen_loss = 0.8277595761394999, disc_loss = 0.0886876550734082
Trained batch 383 in epoch 4, gen_loss = 0.8277342359069735, disc_loss = 0.08896145239365676
Trained batch 384 in epoch 4, gen_loss = 0.8274513694373045, disc_loss = 0.08905057170996805
Trained batch 385 in epoch 4, gen_loss = 0.82721362050642, disc_loss = 0.08907951645485555
Trained batch 386 in epoch 4, gen_loss = 0.8275404542453529, disc_loss = 0.08939176539166106
Trained batch 387 in epoch 4, gen_loss = 0.8272233996348283, disc_loss = 0.08955099640327707
Trained batch 388 in epoch 4, gen_loss = 0.8270458849506084, disc_loss = 0.08960069297719507
Trained batch 389 in epoch 4, gen_loss = 0.8270558119584352, disc_loss = 0.08968135505580367
Trained batch 390 in epoch 4, gen_loss = 0.8271648899825943, disc_loss = 0.08968909680509887
Trained batch 391 in epoch 4, gen_loss = 0.8270018505958878, disc_loss = 0.08967600879972154
Trained batch 392 in epoch 4, gen_loss = 0.8267224466679357, disc_loss = 0.08960507624562232
Trained batch 393 in epoch 4, gen_loss = 0.8273555531265772, disc_loss = 0.08951545176025348
Trained batch 394 in epoch 4, gen_loss = 0.8274666421775576, disc_loss = 0.08939772188144772
Trained batch 395 in epoch 4, gen_loss = 0.8271145664832809, disc_loss = 0.08939108211368398
Trained batch 396 in epoch 4, gen_loss = 0.8271515716983929, disc_loss = 0.08943863457270548
Trained batch 397 in epoch 4, gen_loss = 0.8271111810776457, disc_loss = 0.0893500286865811
Trained batch 398 in epoch 4, gen_loss = 0.8267875124786731, disc_loss = 0.08925525102073462
Trained batch 399 in epoch 4, gen_loss = 0.8266323841363191, disc_loss = 0.08926062965067104
Trained batch 400 in epoch 4, gen_loss = 0.826442051781086, disc_loss = 0.08919230260726
Trained batch 401 in epoch 4, gen_loss = 0.8267387883431876, disc_loss = 0.08906363638636855
Trained batch 402 in epoch 4, gen_loss = 0.8273153872259201, disc_loss = 0.08898206832807132
Trained batch 403 in epoch 4, gen_loss = 0.8269656476850556, disc_loss = 0.08886078877217772
Trained batch 404 in epoch 4, gen_loss = 0.826767561097204, disc_loss = 0.08888127242019515
Trained batch 405 in epoch 4, gen_loss = 0.8271324601519872, disc_loss = 0.08883757051768634
Trained batch 406 in epoch 4, gen_loss = 0.8268510598954756, disc_loss = 0.08890082146423235
Trained batch 407 in epoch 4, gen_loss = 0.8266736894992053, disc_loss = 0.0887670210019375
Trained batch 408 in epoch 4, gen_loss = 0.8260764199101838, disc_loss = 0.08877423061581652
Trained batch 409 in epoch 4, gen_loss = 0.8264088176372575, disc_loss = 0.08861330010042322
Trained batch 410 in epoch 4, gen_loss = 0.8267584751267213, disc_loss = 0.0886381418804509
Trained batch 411 in epoch 4, gen_loss = 0.8261188610809521, disc_loss = 0.08867085716253129
Trained batch 412 in epoch 4, gen_loss = 0.8257776557244632, disc_loss = 0.08864924364179806
Trained batch 413 in epoch 4, gen_loss = 0.8260035491076069, disc_loss = 0.08865825427192205
Trained batch 414 in epoch 4, gen_loss = 0.8258357947849365, disc_loss = 0.08852486834154431
Trained batch 415 in epoch 4, gen_loss = 0.8251340655036844, disc_loss = 0.08855087078364494
Trained batch 416 in epoch 4, gen_loss = 0.8258512170909406, disc_loss = 0.08873912975486876
Trained batch 417 in epoch 4, gen_loss = 0.825998032563611, disc_loss = 0.08862542957468537
Trained batch 418 in epoch 4, gen_loss = 0.8256643063839978, disc_loss = 0.08860661376818908
Trained batch 419 in epoch 4, gen_loss = 0.8258619956317402, disc_loss = 0.08848669536278717
Trained batch 420 in epoch 4, gen_loss = 0.8255805620246714, disc_loss = 0.08841868704339742
Trained batch 421 in epoch 4, gen_loss = 0.8253974827686192, disc_loss = 0.08845097713075331
Trained batch 422 in epoch 4, gen_loss = 0.8260092203357823, disc_loss = 0.08829015259351361
Trained batch 423 in epoch 4, gen_loss = 0.825693602620993, disc_loss = 0.08819096481190326
Trained batch 424 in epoch 4, gen_loss = 0.8255876373543459, disc_loss = 0.08804682660847903
Trained batch 425 in epoch 4, gen_loss = 0.8257904652278748, disc_loss = 0.08803284484149775
Trained batch 426 in epoch 4, gen_loss = 0.8250642067794219, disc_loss = 0.08840964170308038
Trained batch 427 in epoch 4, gen_loss = 0.8260161733933699, disc_loss = 0.0884049039129516
Trained batch 428 in epoch 4, gen_loss = 0.8261038700600604, disc_loss = 0.08823368777814028
Trained batch 429 in epoch 4, gen_loss = 0.8263543014609537, disc_loss = 0.08809072485323562
Trained batch 430 in epoch 4, gen_loss = 0.8269324824732583, disc_loss = 0.08797921979337446
Trained batch 431 in epoch 4, gen_loss = 0.8263312874154912, disc_loss = 0.08811588729386804
Trained batch 432 in epoch 4, gen_loss = 0.8264038464351284, disc_loss = 0.08805252917059299
Trained batch 433 in epoch 4, gen_loss = 0.8272743297200049, disc_loss = 0.08793468975080049
Trained batch 434 in epoch 4, gen_loss = 0.8275674279393821, disc_loss = 0.0877733506219483
Trained batch 435 in epoch 4, gen_loss = 0.8270191708152447, disc_loss = 0.08795190956699875
Trained batch 436 in epoch 4, gen_loss = 0.827751381378152, disc_loss = 0.08779336947700525
Trained batch 437 in epoch 4, gen_loss = 0.8284645972594823, disc_loss = 0.08788763928188853
Trained batch 438 in epoch 4, gen_loss = 0.8282619225272828, disc_loss = 0.08785603532317288
Trained batch 439 in epoch 4, gen_loss = 0.8278809060427276, disc_loss = 0.08786815354939212
Trained batch 440 in epoch 4, gen_loss = 0.8283467680013099, disc_loss = 0.08786112256770502
Trained batch 441 in epoch 4, gen_loss = 0.8279986781367349, disc_loss = 0.08780760302027156
Trained batch 442 in epoch 4, gen_loss = 0.8280926644802094, disc_loss = 0.08766407177323143
Trained batch 443 in epoch 4, gen_loss = 0.827565913868917, disc_loss = 0.08775355427752475
Trained batch 444 in epoch 4, gen_loss = 0.8279040362727776, disc_loss = 0.08800984610165104
Trained batch 445 in epoch 4, gen_loss = 0.8276731027749622, disc_loss = 0.08796993097616151
Trained batch 446 in epoch 4, gen_loss = 0.8278229195932947, disc_loss = 0.08811078098096303
Trained batch 447 in epoch 4, gen_loss = 0.8274730118656797, disc_loss = 0.08803854407908927
Trained batch 448 in epoch 4, gen_loss = 0.8267091466881384, disc_loss = 0.08814742080120573
Trained batch 449 in epoch 4, gen_loss = 0.8270373979541991, disc_loss = 0.0880861275146405
Trained batch 450 in epoch 4, gen_loss = 0.8269823758538705, disc_loss = 0.08806794702577221
Trained batch 451 in epoch 4, gen_loss = 0.8266832990060865, disc_loss = 0.08796801845815065
Trained batch 452 in epoch 4, gen_loss = 0.8272386226827735, disc_loss = 0.08790143957530162
Trained batch 453 in epoch 4, gen_loss = 0.8270893365407305, disc_loss = 0.08779547953494057
Trained batch 454 in epoch 4, gen_loss = 0.8272321636205191, disc_loss = 0.08764379918165914
Trained batch 455 in epoch 4, gen_loss = 0.827233087271452, disc_loss = 0.08766993015530732
Trained batch 456 in epoch 4, gen_loss = 0.826752448694972, disc_loss = 0.08760652063043556
Trained batch 457 in epoch 4, gen_loss = 0.8266895194110913, disc_loss = 0.08752003489834903
Trained batch 458 in epoch 4, gen_loss = 0.8271593556035318, disc_loss = 0.0873786823251863
Trained batch 459 in epoch 4, gen_loss = 0.8270526697454246, disc_loss = 0.08724574028797771
Trained batch 460 in epoch 4, gen_loss = 0.8270290162325422, disc_loss = 0.08711023841239109
Trained batch 461 in epoch 4, gen_loss = 0.8273745166919965, disc_loss = 0.08705667894962546
Trained batch 462 in epoch 4, gen_loss = 0.8272904490420422, disc_loss = 0.08701143001827771
Trained batch 463 in epoch 4, gen_loss = 0.8271261138263447, disc_loss = 0.08694703458679905
Trained batch 464 in epoch 4, gen_loss = 0.8265355876056096, disc_loss = 0.08693221231461853
Trained batch 465 in epoch 4, gen_loss = 0.8267239497838614, disc_loss = 0.08697722846634143
Trained batch 466 in epoch 4, gen_loss = 0.8271370895797231, disc_loss = 0.0868609820749826
Trained batch 467 in epoch 4, gen_loss = 0.8268958864431096, disc_loss = 0.08682368845384345
Trained batch 468 in epoch 4, gen_loss = 0.8269722574174023, disc_loss = 0.08678792390043039
Trained batch 469 in epoch 4, gen_loss = 0.8269889329976224, disc_loss = 0.08668757364787955
Trained batch 470 in epoch 4, gen_loss = 0.8267831048768037, disc_loss = 0.08668132966301244
Trained batch 471 in epoch 4, gen_loss = 0.8271141318067655, disc_loss = 0.08689430442843903
Trained batch 472 in epoch 4, gen_loss = 0.8272902895607858, disc_loss = 0.08681172238816419
Trained batch 473 in epoch 4, gen_loss = 0.8269354663946458, disc_loss = 0.08686460561673098
Trained batch 474 in epoch 4, gen_loss = 0.8267085924274044, disc_loss = 0.0868417044768208
Trained batch 475 in epoch 4, gen_loss = 0.8268557554658722, disc_loss = 0.08698135655874215
Trained batch 476 in epoch 4, gen_loss = 0.827043951244974, disc_loss = 0.08705999407784494
Trained batch 477 in epoch 4, gen_loss = 0.8266798989169268, disc_loss = 0.08732847876410355
Trained batch 478 in epoch 4, gen_loss = 0.8265408993638383, disc_loss = 0.0873574774813428
Trained batch 479 in epoch 4, gen_loss = 0.8264754806334774, disc_loss = 0.08737728903846194
Trained batch 480 in epoch 4, gen_loss = 0.826804424583788, disc_loss = 0.08726980311025453
Trained batch 481 in epoch 4, gen_loss = 0.8271773660949652, disc_loss = 0.08714857557981712
Trained batch 482 in epoch 4, gen_loss = 0.8272578637915862, disc_loss = 0.0870136418273792
Trained batch 483 in epoch 4, gen_loss = 0.8270140221912013, disc_loss = 0.08694971965872182
Trained batch 484 in epoch 4, gen_loss = 0.8267224529969324, disc_loss = 0.08683685133060844
Trained batch 485 in epoch 4, gen_loss = 0.8275411714619569, disc_loss = 0.08698670582562194
Trained batch 486 in epoch 4, gen_loss = 0.8269563047425703, disc_loss = 0.08718179366350541
Trained batch 487 in epoch 4, gen_loss = 0.8272657241122644, disc_loss = 0.08707160680921229
Trained batch 488 in epoch 4, gen_loss = 0.8274849034647757, disc_loss = 0.08702621939220677
Trained batch 489 in epoch 4, gen_loss = 0.8270081377151061, disc_loss = 0.08719233769771396
Trained batch 490 in epoch 4, gen_loss = 0.8269373946301564, disc_loss = 0.08724556747603926
Trained batch 491 in epoch 4, gen_loss = 0.8267782189375986, disc_loss = 0.0872171690301379
Trained batch 492 in epoch 4, gen_loss = 0.8268329554953391, disc_loss = 0.08730471126251603
Trained batch 493 in epoch 4, gen_loss = 0.826473872852229, disc_loss = 0.08736263454970923
Trained batch 494 in epoch 4, gen_loss = 0.8261027490851856, disc_loss = 0.08734950236223563
Trained batch 495 in epoch 4, gen_loss = 0.8262590820630712, disc_loss = 0.08737848803866655
Trained batch 496 in epoch 4, gen_loss = 0.8263773742456072, disc_loss = 0.0872862066144135
Trained batch 497 in epoch 4, gen_loss = 0.8264246909134838, disc_loss = 0.08718151697537387
Trained batch 498 in epoch 4, gen_loss = 0.8260680744667092, disc_loss = 0.08715796344848219
Trained batch 499 in epoch 4, gen_loss = 0.8257928070425987, disc_loss = 0.08720476093515754
Trained batch 500 in epoch 4, gen_loss = 0.8264272838176605, disc_loss = 0.08733260889952173
Trained batch 501 in epoch 4, gen_loss = 0.8261691953437736, disc_loss = 0.08730229797338941
Trained batch 502 in epoch 4, gen_loss = 0.8261168990765604, disc_loss = 0.08722271872073353
Trained batch 503 in epoch 4, gen_loss = 0.8262883854645585, disc_loss = 0.08713056051379277
Trained batch 504 in epoch 4, gen_loss = 0.8259624192620268, disc_loss = 0.0870614305175472
Trained batch 505 in epoch 4, gen_loss = 0.8260107430898154, disc_loss = 0.08694363813552813
Trained batch 506 in epoch 4, gen_loss = 0.8260377299268336, disc_loss = 0.08692484059145111
Trained batch 507 in epoch 4, gen_loss = 0.8257954880360543, disc_loss = 0.0868777939059779
Trained batch 508 in epoch 4, gen_loss = 0.8254124912742548, disc_loss = 0.08695756813441724
Trained batch 509 in epoch 4, gen_loss = 0.8263393360610102, disc_loss = 0.08720170205057251
Trained batch 510 in epoch 4, gen_loss = 0.8262073064620248, disc_loss = 0.08712271771187768
Trained batch 511 in epoch 4, gen_loss = 0.8260226016282104, disc_loss = 0.08702788349546609
Trained batch 512 in epoch 4, gen_loss = 0.8259915840207485, disc_loss = 0.08693412709146099
Trained batch 513 in epoch 4, gen_loss = 0.825871819594027, disc_loss = 0.08686907319460746
Trained batch 514 in epoch 4, gen_loss = 0.8254453548528615, disc_loss = 0.08690935124109671
Trained batch 515 in epoch 4, gen_loss = 0.8258620078365008, disc_loss = 0.08739092518293927
Trained batch 516 in epoch 4, gen_loss = 0.8254367904575466, disc_loss = 0.08745371303530104
Trained batch 517 in epoch 4, gen_loss = 0.8250226192607842, disc_loss = 0.0875383266517497
Trained batch 518 in epoch 4, gen_loss = 0.8257655202193986, disc_loss = 0.08824611275397629
Trained batch 519 in epoch 4, gen_loss = 0.8255922921001911, disc_loss = 0.08827131490509671
Trained batch 520 in epoch 4, gen_loss = 0.8254348818148395, disc_loss = 0.08819464056783011
Trained batch 521 in epoch 4, gen_loss = 0.8257213217202731, disc_loss = 0.08816384849891466
Trained batch 522 in epoch 4, gen_loss = 0.825322783984828, disc_loss = 0.08812587598897872
Trained batch 523 in epoch 4, gen_loss = 0.8252107278650044, disc_loss = 0.08808290543574981
Trained batch 524 in epoch 4, gen_loss = 0.8253413418928782, disc_loss = 0.08814751907828308
Trained batch 525 in epoch 4, gen_loss = 0.8249606030635508, disc_loss = 0.08810525706583217
Trained batch 526 in epoch 4, gen_loss = 0.8242871493270773, disc_loss = 0.08824262044532136
Trained batch 527 in epoch 4, gen_loss = 0.8242030047783346, disc_loss = 0.08812254772055894
Trained batch 528 in epoch 4, gen_loss = 0.8239585721199815, disc_loss = 0.08814024465028303
Trained batch 529 in epoch 4, gen_loss = 0.8236512923015739, disc_loss = 0.08818955105500964
Trained batch 530 in epoch 4, gen_loss = 0.8235515156259196, disc_loss = 0.08816284404650133
Trained batch 531 in epoch 4, gen_loss = 0.8235029963622416, disc_loss = 0.0881157524470604
Trained batch 532 in epoch 4, gen_loss = 0.8234402415452711, disc_loss = 0.08808222656639722
Trained batch 533 in epoch 4, gen_loss = 0.822931633906418, disc_loss = 0.08814774533517464
Trained batch 534 in epoch 4, gen_loss = 0.8236177346416723, disc_loss = 0.08815250220212424
Trained batch 535 in epoch 4, gen_loss = 0.8236742247618846, disc_loss = 0.0882753168976407
Trained batch 536 in epoch 4, gen_loss = 0.8234865370187457, disc_loss = 0.08825976557308181
Trained batch 537 in epoch 4, gen_loss = 0.823275954528369, disc_loss = 0.08826156690730592
Trained batch 538 in epoch 4, gen_loss = 0.8237669983246331, disc_loss = 0.08815131364787665
Trained batch 539 in epoch 4, gen_loss = 0.8240564533957728, disc_loss = 0.08810418413055164
Trained batch 540 in epoch 4, gen_loss = 0.8236384140585795, disc_loss = 0.08812604218638759
Trained batch 541 in epoch 4, gen_loss = 0.8231311539442336, disc_loss = 0.08818357965025735
Trained batch 542 in epoch 4, gen_loss = 0.8230195666764543, disc_loss = 0.0880916432767393
Trained batch 543 in epoch 4, gen_loss = 0.8236030259114855, disc_loss = 0.08811310089111109
Trained batch 544 in epoch 4, gen_loss = 0.8234878069763883, disc_loss = 0.08811524747571814
Trained batch 545 in epoch 4, gen_loss = 0.8233071108222444, disc_loss = 0.08808285854211002
Trained batch 546 in epoch 4, gen_loss = 0.8233213920479937, disc_loss = 0.08808456793754367
Trained batch 547 in epoch 4, gen_loss = 0.8229038662066425, disc_loss = 0.08821674560733737
Trained batch 548 in epoch 4, gen_loss = 0.8233972749857738, disc_loss = 0.08820512506072639
Trained batch 549 in epoch 4, gen_loss = 0.8233864590254697, disc_loss = 0.08827842271463437
Trained batch 550 in epoch 4, gen_loss = 0.8232491691402428, disc_loss = 0.08826293779398482
Trained batch 551 in epoch 4, gen_loss = 0.82288106865641, disc_loss = 0.08828573348000646
Trained batch 552 in epoch 4, gen_loss = 0.8229885804071133, disc_loss = 0.088556747708409
Trained batch 553 in epoch 4, gen_loss = 0.8224945159810545, disc_loss = 0.08867114573206067
Trained batch 554 in epoch 4, gen_loss = 0.8224399889911618, disc_loss = 0.08860898704544919
Trained batch 555 in epoch 4, gen_loss = 0.8230691358125467, disc_loss = 0.08870239370241226
Trained batch 556 in epoch 4, gen_loss = 0.8225123010161107, disc_loss = 0.08892692491091132
Trained batch 557 in epoch 4, gen_loss = 0.8231406627376447, disc_loss = 0.08893141438216505
Trained batch 558 in epoch 4, gen_loss = 0.8234097512975361, disc_loss = 0.08885171035161385
Trained batch 559 in epoch 4, gen_loss = 0.8228874940957341, disc_loss = 0.08912523605727724
Trained batch 560 in epoch 4, gen_loss = 0.8230683372194967, disc_loss = 0.08908464632091675
Trained batch 561 in epoch 4, gen_loss = 0.823091498685477, disc_loss = 0.08913790084607236
Trained batch 562 in epoch 4, gen_loss = 0.8229035325414545, disc_loss = 0.08912313283548473
Trained batch 563 in epoch 4, gen_loss = 0.8225876992264538, disc_loss = 0.08910589678384734
Trained batch 564 in epoch 4, gen_loss = 0.8227740475561767, disc_loss = 0.08910558002184978
Trained batch 565 in epoch 4, gen_loss = 0.82330082962454, disc_loss = 0.08905843719050235
Trained batch 566 in epoch 4, gen_loss = 0.8232537953731665, disc_loss = 0.08899443275976854
Trained batch 567 in epoch 4, gen_loss = 0.8228264190781285, disc_loss = 0.08901928193394987
Trained batch 568 in epoch 4, gen_loss = 0.822641384727297, disc_loss = 0.08897334529718741
Trained batch 569 in epoch 4, gen_loss = 0.8228529444912024, disc_loss = 0.08905750903905484
Trained batch 570 in epoch 4, gen_loss = 0.822525666599307, disc_loss = 0.08908523766620773
Trained batch 571 in epoch 4, gen_loss = 0.822194534581858, disc_loss = 0.08919872957040796
Trained batch 572 in epoch 4, gen_loss = 0.8223717050402576, disc_loss = 0.08919028428108489
Trained batch 573 in epoch 4, gen_loss = 0.8225667658375531, disc_loss = 0.08909324812946212
Trained batch 574 in epoch 4, gen_loss = 0.8225040750918181, disc_loss = 0.08903645207700522
Trained batch 575 in epoch 4, gen_loss = 0.8227315735485818, disc_loss = 0.08903942565666512
Trained batch 576 in epoch 4, gen_loss = 0.8224192792662715, disc_loss = 0.08904050415191328
Trained batch 577 in epoch 4, gen_loss = 0.8219935047379002, disc_loss = 0.08919110105962695
Trained batch 578 in epoch 4, gen_loss = 0.8222222960262925, disc_loss = 0.08915761456099405
Trained batch 579 in epoch 4, gen_loss = 0.8224135559180688, disc_loss = 0.08912994073511198
Trained batch 580 in epoch 4, gen_loss = 0.8221965466021671, disc_loss = 0.08906987866646451
Trained batch 581 in epoch 4, gen_loss = 0.821738751483537, disc_loss = 0.08904735509088564
Trained batch 582 in epoch 4, gen_loss = 0.8215968133450372, disc_loss = 0.08919916988876017
Trained batch 583 in epoch 4, gen_loss = 0.8215095594729462, disc_loss = 0.08911444543388812
Trained batch 584 in epoch 4, gen_loss = 0.8215690441620656, disc_loss = 0.08902411992605935
Trained batch 585 in epoch 4, gen_loss = 0.8219192076868571, disc_loss = 0.08890154673606666
Trained batch 586 in epoch 4, gen_loss = 0.8214614003439779, disc_loss = 0.0888988926207085
Trained batch 587 in epoch 4, gen_loss = 0.8213366529568523, disc_loss = 0.08886539289208294
Trained batch 588 in epoch 4, gen_loss = 0.8211212386906855, disc_loss = 0.08886507342621709
Trained batch 589 in epoch 4, gen_loss = 0.8220523644301851, disc_loss = 0.08899920200771194
Trained batch 590 in epoch 4, gen_loss = 0.8217441500140931, disc_loss = 0.08901753942852496
Trained batch 591 in epoch 4, gen_loss = 0.8212630503080987, disc_loss = 0.08926258605552485
Trained batch 592 in epoch 4, gen_loss = 0.8219296711090243, disc_loss = 0.08947463091745546
Trained batch 593 in epoch 4, gen_loss = 0.8219436768329504, disc_loss = 0.08940546266007102
Trained batch 594 in epoch 4, gen_loss = 0.8215325544862186, disc_loss = 0.08946762243990136
Trained batch 595 in epoch 4, gen_loss = 0.8216214813042007, disc_loss = 0.08934484246255667
Trained batch 596 in epoch 4, gen_loss = 0.8217278342550524, disc_loss = 0.08923051783649666
Trained batch 597 in epoch 4, gen_loss = 0.821930783947176, disc_loss = 0.08911275503266117
Trained batch 598 in epoch 4, gen_loss = 0.8220348504429469, disc_loss = 0.0890214110511621
Trained batch 599 in epoch 4, gen_loss = 0.8219370191295942, disc_loss = 0.08890461150246362
Trained batch 600 in epoch 4, gen_loss = 0.8218122858572721, disc_loss = 0.08882985064161697
Trained batch 601 in epoch 4, gen_loss = 0.8219849486089624, disc_loss = 0.08877984940250748
Trained batch 602 in epoch 4, gen_loss = 0.8219198785215666, disc_loss = 0.08867429563494562
Trained batch 603 in epoch 4, gen_loss = 0.8220204765236141, disc_loss = 0.08855562608084636
Trained batch 604 in epoch 4, gen_loss = 0.8219177383036653, disc_loss = 0.08846312956807535
Trained batch 605 in epoch 4, gen_loss = 0.8222204233356828, disc_loss = 0.0883574330066592
Trained batch 606 in epoch 4, gen_loss = 0.82227430125634, disc_loss = 0.08825154412580774
Trained batch 607 in epoch 4, gen_loss = 0.8224273700463144, disc_loss = 0.08812477144927375
Trained batch 608 in epoch 4, gen_loss = 0.822660744581708, disc_loss = 0.08812176064880219
Trained batch 609 in epoch 4, gen_loss = 0.8222546850071579, disc_loss = 0.08813621464689247
Trained batch 610 in epoch 4, gen_loss = 0.8226474387946183, disc_loss = 0.08807298526436139
Trained batch 611 in epoch 4, gen_loss = 0.8225638791431789, disc_loss = 0.08799963774390859
Trained batch 612 in epoch 4, gen_loss = 0.8223813779980285, disc_loss = 0.08794022278577623
Trained batch 613 in epoch 4, gen_loss = 0.8219927395011393, disc_loss = 0.08810784457803549
Trained batch 614 in epoch 4, gen_loss = 0.8225767338178991, disc_loss = 0.08815418410349668
Trained batch 615 in epoch 4, gen_loss = 0.8231140240639835, disc_loss = 0.08813475350571143
Trained batch 616 in epoch 4, gen_loss = 0.8226209603600216, disc_loss = 0.08846619544094926
Trained batch 617 in epoch 4, gen_loss = 0.8227113541275938, disc_loss = 0.08837562791014567
Trained batch 618 in epoch 4, gen_loss = 0.8230383883385358, disc_loss = 0.08840224013238038
Trained batch 619 in epoch 4, gen_loss = 0.8229168424683232, disc_loss = 0.0883723403777807
Trained batch 620 in epoch 4, gen_loss = 0.8224392958501303, disc_loss = 0.08843355119564299
Trained batch 621 in epoch 4, gen_loss = 0.8227896169067579, disc_loss = 0.08842268671205573
Trained batch 622 in epoch 4, gen_loss = 0.8227074719355538, disc_loss = 0.08834707146184594
Trained batch 623 in epoch 4, gen_loss = 0.8223705879197671, disc_loss = 0.08849075286147687
Trained batch 624 in epoch 4, gen_loss = 0.8221617741584778, disc_loss = 0.0884325427889824
Trained batch 625 in epoch 4, gen_loss = 0.8219438279970005, disc_loss = 0.08834601532870208
Trained batch 626 in epoch 4, gen_loss = 0.822189010786668, disc_loss = 0.0883623314650055
Trained batch 627 in epoch 4, gen_loss = 0.821987288962504, disc_loss = 0.08828357897200592
Trained batch 628 in epoch 4, gen_loss = 0.8216367647265024, disc_loss = 0.08833769220260634
Trained batch 629 in epoch 4, gen_loss = 0.8214694981537168, disc_loss = 0.08827002226478524
Trained batch 630 in epoch 4, gen_loss = 0.8215680010911969, disc_loss = 0.08825968256111001
Trained batch 631 in epoch 4, gen_loss = 0.821803750871103, disc_loss = 0.08814195367725731
Trained batch 632 in epoch 4, gen_loss = 0.821350272044563, disc_loss = 0.08823957680143404
Trained batch 633 in epoch 4, gen_loss = 0.8217034522291238, disc_loss = 0.0882594836890486
Trained batch 634 in epoch 4, gen_loss = 0.8219033342646802, disc_loss = 0.08820515415066575
Trained batch 635 in epoch 4, gen_loss = 0.821663054842619, disc_loss = 0.08816482370818889
Trained batch 636 in epoch 4, gen_loss = 0.8215866571692881, disc_loss = 0.08809173470172955
Trained batch 637 in epoch 4, gen_loss = 0.8215897415872652, disc_loss = 0.08812799778121719
Trained batch 638 in epoch 4, gen_loss = 0.8216754117855257, disc_loss = 0.08814591672329788
Trained batch 639 in epoch 4, gen_loss = 0.8213312295265496, disc_loss = 0.08820235376915661
Trained batch 640 in epoch 4, gen_loss = 0.8212639455118343, disc_loss = 0.08812230656740028
Trained batch 641 in epoch 4, gen_loss = 0.8214997329815897, disc_loss = 0.08814891613294541
Trained batch 642 in epoch 4, gen_loss = 0.8217846394326787, disc_loss = 0.08805312503210354
Trained batch 643 in epoch 4, gen_loss = 0.8215301035909179, disc_loss = 0.08803753259371944
Trained batch 644 in epoch 4, gen_loss = 0.8223022705824801, disc_loss = 0.08807360644979301
Trained batch 645 in epoch 4, gen_loss = 0.8218529980064546, disc_loss = 0.08825446710988141
Trained batch 646 in epoch 4, gen_loss = 0.8215799854011772, disc_loss = 0.08833897649994267
Trained batch 647 in epoch 4, gen_loss = 0.821738860949322, disc_loss = 0.08832888446179116
Trained batch 648 in epoch 4, gen_loss = 0.8218039920774557, disc_loss = 0.08833174196965934
Trained batch 649 in epoch 4, gen_loss = 0.8214298502298502, disc_loss = 0.08843802787506809
Trained batch 650 in epoch 4, gen_loss = 0.8212353102805611, disc_loss = 0.08848086010504475
Trained batch 651 in epoch 4, gen_loss = 0.8214985552740974, disc_loss = 0.0884707530266234
Trained batch 652 in epoch 4, gen_loss = 0.8214677957444242, disc_loss = 0.08839231505448064
Trained batch 653 in epoch 4, gen_loss = 0.8215223063204996, disc_loss = 0.08845345427165384
Trained batch 654 in epoch 4, gen_loss = 0.8212286898198019, disc_loss = 0.08857831647406325
Trained batch 655 in epoch 4, gen_loss = 0.8212160135551196, disc_loss = 0.08855601855150493
Trained batch 656 in epoch 4, gen_loss = 0.8211816839612964, disc_loss = 0.08853053931668514
Trained batch 657 in epoch 4, gen_loss = 0.8211940923722681, disc_loss = 0.08845801488567133
Trained batch 658 in epoch 4, gen_loss = 0.8209427620463741, disc_loss = 0.08852978810605809
Trained batch 659 in epoch 4, gen_loss = 0.820952807412003, disc_loss = 0.08854763129810718
Trained batch 660 in epoch 4, gen_loss = 0.8207258674092084, disc_loss = 0.08850175715030457
Trained batch 661 in epoch 4, gen_loss = 0.8206085417746057, disc_loss = 0.08843298753430881
Trained batch 662 in epoch 4, gen_loss = 0.8208048288818578, disc_loss = 0.08855208634998689
Trained batch 663 in epoch 4, gen_loss = 0.8204092931855156, disc_loss = 0.0886625185656552
Trained batch 664 in epoch 4, gen_loss = 0.8205531666153356, disc_loss = 0.08860841794149545
Trained batch 665 in epoch 4, gen_loss = 0.82048107142205, disc_loss = 0.08875473342170273
Trained batch 666 in epoch 4, gen_loss = 0.8204453082635127, disc_loss = 0.08872812682123243
Trained batch 667 in epoch 4, gen_loss = 0.8200987283876556, disc_loss = 0.08874324147734501
Trained batch 668 in epoch 4, gen_loss = 0.8202771834906619, disc_loss = 0.08868186443247826
Trained batch 669 in epoch 4, gen_loss = 0.8203537959661057, disc_loss = 0.08857928104837662
Trained batch 670 in epoch 4, gen_loss = 0.8204972226111615, disc_loss = 0.08857320440758225
Trained batch 671 in epoch 4, gen_loss = 0.820362242825684, disc_loss = 0.0885406281047922
Trained batch 672 in epoch 4, gen_loss = 0.820185615704637, disc_loss = 0.08854601469809774
Trained batch 673 in epoch 4, gen_loss = 0.8203225684979549, disc_loss = 0.08844588396418564
Trained batch 674 in epoch 4, gen_loss = 0.8207283192210727, disc_loss = 0.08844062183880144
Trained batch 675 in epoch 4, gen_loss = 0.8205286494549915, disc_loss = 0.0884534484285244
Trained batch 676 in epoch 4, gen_loss = 0.8208065336704958, disc_loss = 0.08840171910926942
Trained batch 677 in epoch 4, gen_loss = 0.8204123092084508, disc_loss = 0.08849114941839667
Trained batch 678 in epoch 4, gen_loss = 0.8203951827029592, disc_loss = 0.08841494220241751
Trained batch 679 in epoch 4, gen_loss = 0.8204775180010234, disc_loss = 0.08836489731363734
Trained batch 680 in epoch 4, gen_loss = 0.8205796512563148, disc_loss = 0.08832275213348227
Trained batch 681 in epoch 4, gen_loss = 0.8201365586250059, disc_loss = 0.08838607355695535
Trained batch 682 in epoch 4, gen_loss = 0.8199452103318791, disc_loss = 0.0882868873484509
Trained batch 683 in epoch 4, gen_loss = 0.8201415884738777, disc_loss = 0.08840542559087146
Trained batch 684 in epoch 4, gen_loss = 0.8202992594155082, disc_loss = 0.08837938772201756
Trained batch 685 in epoch 4, gen_loss = 0.8201177142799422, disc_loss = 0.08846866895659194
Trained batch 686 in epoch 4, gen_loss = 0.8205536281177571, disc_loss = 0.08842097773329183
Trained batch 687 in epoch 4, gen_loss = 0.8208707182906395, disc_loss = 0.08833520566681834
Trained batch 688 in epoch 4, gen_loss = 0.8207146661201997, disc_loss = 0.08831630196930579
Trained batch 689 in epoch 4, gen_loss = 0.8208119229993959, disc_loss = 0.08823003752319061
Trained batch 690 in epoch 4, gen_loss = 0.8209691906803424, disc_loss = 0.0881493790452564
Trained batch 691 in epoch 4, gen_loss = 0.8208796307875242, disc_loss = 0.08806981929211818
Trained batch 692 in epoch 4, gen_loss = 0.8205845486722123, disc_loss = 0.08805770180920545
Trained batch 693 in epoch 4, gen_loss = 0.8210124344234851, disc_loss = 0.08808828370849621
Trained batch 694 in epoch 4, gen_loss = 0.8208059209713833, disc_loss = 0.08803416407606798
Trained batch 695 in epoch 4, gen_loss = 0.8208828490527197, disc_loss = 0.08802229955647911
Trained batch 696 in epoch 4, gen_loss = 0.8203833721460537, disc_loss = 0.08819592757607507
Trained batch 697 in epoch 4, gen_loss = 0.820945864676746, disc_loss = 0.08825261499812789
Trained batch 698 in epoch 4, gen_loss = 0.8208917535425767, disc_loss = 0.08818196028455004
Trained batch 699 in epoch 4, gen_loss = 0.8205604078088488, disc_loss = 0.08827534511286234
Trained batch 700 in epoch 4, gen_loss = 0.8208275002861839, disc_loss = 0.08817099483973333
Trained batch 701 in epoch 4, gen_loss = 0.8212627155488712, disc_loss = 0.08831311177138632
Trained batch 702 in epoch 4, gen_loss = 0.8210823921696051, disc_loss = 0.08836132485769255
Trained batch 703 in epoch 4, gen_loss = 0.8207953940568999, disc_loss = 0.08835162963871633
Trained batch 704 in epoch 4, gen_loss = 0.820664437780989, disc_loss = 0.08833953540190949
Trained batch 705 in epoch 4, gen_loss = 0.8209387236208822, disc_loss = 0.08840072835286387
Trained batch 706 in epoch 4, gen_loss = 0.8204795814302382, disc_loss = 0.08855428824483126
Trained batch 707 in epoch 4, gen_loss = 0.8206598568434096, disc_loss = 0.0885809649395004
Trained batch 708 in epoch 4, gen_loss = 0.8205819952134857, disc_loss = 0.08856275870644702
Trained batch 709 in epoch 4, gen_loss = 0.8202269798433277, disc_loss = 0.08862701146141953
Trained batch 710 in epoch 4, gen_loss = 0.8199009450176095, disc_loss = 0.08867643607594335
Trained batch 711 in epoch 4, gen_loss = 0.8196379045924443, disc_loss = 0.08866749667913099
Trained batch 712 in epoch 4, gen_loss = 0.8195462729285509, disc_loss = 0.08871050225636108
Trained batch 713 in epoch 4, gen_loss = 0.8196128615144254, disc_loss = 0.08864106703940935
Trained batch 714 in epoch 4, gen_loss = 0.8192974060565441, disc_loss = 0.08865482995377762
Trained batch 715 in epoch 4, gen_loss = 0.8190615802337338, disc_loss = 0.08877687508568126
Trained batch 716 in epoch 4, gen_loss = 0.8191081410172594, disc_loss = 0.0887147835423362
Trained batch 717 in epoch 4, gen_loss = 0.8196057243931593, disc_loss = 0.08877536889637787
Trained batch 718 in epoch 4, gen_loss = 0.8196246914969698, disc_loss = 0.08867908344683088
Trained batch 719 in epoch 4, gen_loss = 0.8191902692947123, disc_loss = 0.08876361881977775
Trained batch 720 in epoch 4, gen_loss = 0.8189307133797634, disc_loss = 0.08876205717139825
Trained batch 721 in epoch 4, gen_loss = 0.8194784700375184, disc_loss = 0.08895809222864105
Trained batch 722 in epoch 4, gen_loss = 0.8193009584771153, disc_loss = 0.08892929204514206
Trained batch 723 in epoch 4, gen_loss = 0.8192503618601278, disc_loss = 0.08886458310401531
Trained batch 724 in epoch 4, gen_loss = 0.8192415028604968, disc_loss = 0.08899427035116944
Trained batch 725 in epoch 4, gen_loss = 0.819530738779336, disc_loss = 0.08894644219289757
Trained batch 726 in epoch 4, gen_loss = 0.8190574725113676, disc_loss = 0.08964872201763739
Trained batch 727 in epoch 4, gen_loss = 0.8193401088835773, disc_loss = 0.0895766747109899
Trained batch 728 in epoch 4, gen_loss = 0.8193570874600744, disc_loss = 0.08966640241326577
Trained batch 729 in epoch 4, gen_loss = 0.8192197432664976, disc_loss = 0.08964134771504427
Trained batch 730 in epoch 4, gen_loss = 0.8190731930096726, disc_loss = 0.08960420915935947
Trained batch 731 in epoch 4, gen_loss = 0.8188045949476664, disc_loss = 0.0896328967102788
Trained batch 732 in epoch 4, gen_loss = 0.8186134257306832, disc_loss = 0.08966391312408212
Trained batch 733 in epoch 4, gen_loss = 0.8184747131140421, disc_loss = 0.08967753118462353
Trained batch 734 in epoch 4, gen_loss = 0.8185250529221126, disc_loss = 0.0896567512366946
Trained batch 735 in epoch 4, gen_loss = 0.8186685762408635, disc_loss = 0.08960860130837714
Trained batch 736 in epoch 4, gen_loss = 0.8185373144767663, disc_loss = 0.08974799078483554
Trained batch 737 in epoch 4, gen_loss = 0.8183456358467014, disc_loss = 0.08975013824391777
Trained batch 738 in epoch 4, gen_loss = 0.8186083017005327, disc_loss = 0.08968286033145105
Trained batch 739 in epoch 4, gen_loss = 0.818521429356691, disc_loss = 0.0896341063623392
Trained batch 740 in epoch 4, gen_loss = 0.8184536824583525, disc_loss = 0.08966259950301868
Trained batch 741 in epoch 4, gen_loss = 0.8181480656495955, disc_loss = 0.08965654311089141
Trained batch 742 in epoch 4, gen_loss = 0.8177736177338566, disc_loss = 0.08968614844397252
Trained batch 743 in epoch 4, gen_loss = 0.8183573512861164, disc_loss = 0.08975699185819355
Trained batch 744 in epoch 4, gen_loss = 0.8183811761788874, disc_loss = 0.08968334591403704
Trained batch 745 in epoch 4, gen_loss = 0.8178878252372026, disc_loss = 0.08998489984493432
Trained batch 746 in epoch 4, gen_loss = 0.8185594525522337, disc_loss = 0.0901702514910694
Trained batch 747 in epoch 4, gen_loss = 0.8187097892722982, disc_loss = 0.09009156382971388
Trained batch 748 in epoch 4, gen_loss = 0.8185105974747438, disc_loss = 0.09009938456182764
Trained batch 749 in epoch 4, gen_loss = 0.8185088083744049, disc_loss = 0.09007555793598294
Trained batch 750 in epoch 4, gen_loss = 0.8183829421685952, disc_loss = 0.0900538033246498
Trained batch 751 in epoch 4, gen_loss = 0.8185242554767335, disc_loss = 0.09002826513321277
Trained batch 752 in epoch 4, gen_loss = 0.8185988323463703, disc_loss = 0.0899498555697946
Trained batch 753 in epoch 4, gen_loss = 0.8187259300476044, disc_loss = 0.08988648924892595
Trained batch 754 in epoch 4, gen_loss = 0.8185958640464884, disc_loss = 0.08982515711189303
Trained batch 755 in epoch 4, gen_loss = 0.8188227184865841, disc_loss = 0.08974240067483927
Trained batch 756 in epoch 4, gen_loss = 0.818949377599764, disc_loss = 0.08971908047445896
Trained batch 757 in epoch 4, gen_loss = 0.8192038922165189, disc_loss = 0.08971589481910214
Trained batch 758 in epoch 4, gen_loss = 0.8191599058225378, disc_loss = 0.08977316114413447
Trained batch 759 in epoch 4, gen_loss = 0.8192810900901494, disc_loss = 0.08976182802947924
Trained batch 760 in epoch 4, gen_loss = 0.8196864493103128, disc_loss = 0.08972341743140003
Trained batch 761 in epoch 4, gen_loss = 0.8199007727811969, disc_loss = 0.08967801049630356
Trained batch 762 in epoch 4, gen_loss = 0.819437465145891, disc_loss = 0.08987780355849592
Trained batch 763 in epoch 4, gen_loss = 0.8197346945239611, disc_loss = 0.08984318861362392
Trained batch 764 in epoch 4, gen_loss = 0.8199463129043579, disc_loss = 0.08979096725899605
Trained batch 765 in epoch 4, gen_loss = 0.8196828044736977, disc_loss = 0.08979465954088395
Trained batch 766 in epoch 4, gen_loss = 0.819773583866005, disc_loss = 0.08970781937217269
Trained batch 767 in epoch 4, gen_loss = 0.8196074970376989, disc_loss = 0.08968270599992441
Trained batch 768 in epoch 4, gen_loss = 0.8197565572469535, disc_loss = 0.08959419152279165
Trained batch 769 in epoch 4, gen_loss = 0.8198257776049824, disc_loss = 0.0895100786786091
Trained batch 770 in epoch 4, gen_loss = 0.8197453975986723, disc_loss = 0.08944774796792467
Trained batch 771 in epoch 4, gen_loss = 0.8200843008379862, disc_loss = 0.08935499788319856
Trained batch 772 in epoch 4, gen_loss = 0.819949964502342, disc_loss = 0.08937977916196008
Trained batch 773 in epoch 4, gen_loss = 0.8203221012763583, disc_loss = 0.08938254322255035
Trained batch 774 in epoch 4, gen_loss = 0.8202655986816653, disc_loss = 0.08934882803910202
Trained batch 775 in epoch 4, gen_loss = 0.8200228723514941, disc_loss = 0.08953187998369835
Trained batch 776 in epoch 4, gen_loss = 0.8198255218440809, disc_loss = 0.08950293261289329
Trained batch 777 in epoch 4, gen_loss = 0.8200031105993952, disc_loss = 0.08943450068911313
Trained batch 778 in epoch 4, gen_loss = 0.8199442838520692, disc_loss = 0.08936958762055529
Trained batch 779 in epoch 4, gen_loss = 0.8199225016129322, disc_loss = 0.08933217437245333
Trained batch 780 in epoch 4, gen_loss = 0.819968503049638, disc_loss = 0.08938343578379568
Trained batch 781 in epoch 4, gen_loss = 0.8194583952808014, disc_loss = 0.08968860888139099
Trained batch 782 in epoch 4, gen_loss = 0.8195207898872565, disc_loss = 0.08963583261940253
Trained batch 783 in epoch 4, gen_loss = 0.8200303316496464, disc_loss = 0.08958216017344967
Trained batch 784 in epoch 4, gen_loss = 0.8198319888798294, disc_loss = 0.08956968364940518
Trained batch 785 in epoch 4, gen_loss = 0.8198666114161033, disc_loss = 0.08961211059730662
Trained batch 786 in epoch 4, gen_loss = 0.8195249955944972, disc_loss = 0.08967582603237263
Trained batch 787 in epoch 4, gen_loss = 0.819497789034081, disc_loss = 0.08967620682864814
Trained batch 788 in epoch 4, gen_loss = 0.8194856258021863, disc_loss = 0.08960353162054667
Trained batch 789 in epoch 4, gen_loss = 0.8196548117489755, disc_loss = 0.0895034487771837
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.8145227432250977, disc_loss = 0.034468650817871094
Trained batch 1 in epoch 5, gen_loss = 0.7447850108146667, disc_loss = 0.04559599980711937
Trained batch 2 in epoch 5, gen_loss = 0.7319111824035645, disc_loss = 0.0666672761241595
Trained batch 3 in epoch 5, gen_loss = 0.7338606864213943, disc_loss = 0.06000021379441023
Trained batch 4 in epoch 5, gen_loss = 0.696384847164154, disc_loss = 0.06277926489710808
Trained batch 5 in epoch 5, gen_loss = 0.7355818450450897, disc_loss = 0.056431916231910385
Trained batch 6 in epoch 5, gen_loss = 0.7821967005729675, disc_loss = 0.06286054051348142
Trained batch 7 in epoch 5, gen_loss = 0.7639866024255753, disc_loss = 0.06527292961254716
Trained batch 8 in epoch 5, gen_loss = 0.7689167857170105, disc_loss = 0.0638345442712307
Trained batch 9 in epoch 5, gen_loss = 0.7655155062675476, disc_loss = 0.06048205401748419
Trained batch 10 in epoch 5, gen_loss = 0.7717810598286715, disc_loss = 0.05859206058084965
Trained batch 11 in epoch 5, gen_loss = 0.7700706968704859, disc_loss = 0.055685789324343204
Trained batch 12 in epoch 5, gen_loss = 0.7861603315059955, disc_loss = 0.05251468925808485
Trained batch 13 in epoch 5, gen_loss = 0.799143156835011, disc_loss = 0.0521486734838358
Trained batch 14 in epoch 5, gen_loss = 0.7796898444493612, disc_loss = 0.06281562379250924
Trained batch 15 in epoch 5, gen_loss = 0.8039067462086678, disc_loss = 0.07066615979420021
Trained batch 16 in epoch 5, gen_loss = 0.7980561712208916, disc_loss = 0.07046240814687575
Trained batch 17 in epoch 5, gen_loss = 0.7962153851985931, disc_loss = 0.06935620602841179
Trained batch 18 in epoch 5, gen_loss = 0.8053977928663555, disc_loss = 0.071049149540302
Trained batch 19 in epoch 5, gen_loss = 0.7934889256954193, disc_loss = 0.07698888001032174
Trained batch 20 in epoch 5, gen_loss = 0.8026506503423055, disc_loss = 0.07621334142805565
Trained batch 21 in epoch 5, gen_loss = 0.8024499822746624, disc_loss = 0.07523844971067527
Trained batch 22 in epoch 5, gen_loss = 0.79607754945755, disc_loss = 0.07525878727598034
Trained batch 23 in epoch 5, gen_loss = 0.7992368613680204, disc_loss = 0.07393389416392893
Trained batch 24 in epoch 5, gen_loss = 0.7946050453186035, disc_loss = 0.074011888243258
Trained batch 25 in epoch 5, gen_loss = 0.8019370826391073, disc_loss = 0.07207124941767408
Trained batch 26 in epoch 5, gen_loss = 0.8024439303963272, disc_loss = 0.0707889908786725
Trained batch 27 in epoch 5, gen_loss = 0.810398376413754, disc_loss = 0.06886530331602055
Trained batch 28 in epoch 5, gen_loss = 0.8089430599377073, disc_loss = 0.0677615214974202
Trained batch 29 in epoch 5, gen_loss = 0.8081670780976613, disc_loss = 0.06697175710772475
Trained batch 30 in epoch 5, gen_loss = 0.8134953802631747, disc_loss = 0.06749761978825254
Trained batch 31 in epoch 5, gen_loss = 0.8087424356490374, disc_loss = 0.06867257234989665
Trained batch 32 in epoch 5, gen_loss = 0.8084823561437202, disc_loss = 0.06811520522178123
Trained batch 33 in epoch 5, gen_loss = 0.8079471044680652, disc_loss = 0.06842350672163508
Trained batch 34 in epoch 5, gen_loss = 0.8139689564704895, disc_loss = 0.06696223709732294
Trained batch 35 in epoch 5, gen_loss = 0.8225443181064394, disc_loss = 0.0656855983607885
Trained batch 36 in epoch 5, gen_loss = 0.8183372906736426, disc_loss = 0.06549665409870245
Trained batch 37 in epoch 5, gen_loss = 0.8141567518836573, disc_loss = 0.06532612489536405
Trained batch 38 in epoch 5, gen_loss = 0.8173843438808734, disc_loss = 0.06507833452465442
Trained batch 39 in epoch 5, gen_loss = 0.8138633474707604, disc_loss = 0.06576399037148803
Trained batch 40 in epoch 5, gen_loss = 0.8157353590174419, disc_loss = 0.06469494642735255
Trained batch 41 in epoch 5, gen_loss = 0.8178730734757015, disc_loss = 0.06402640995968666
Trained batch 42 in epoch 5, gen_loss = 0.8139247783394747, disc_loss = 0.0656059411419339
Trained batch 43 in epoch 5, gen_loss = 0.8164072849533774, disc_loss = 0.06530572738583115
Trained batch 44 in epoch 5, gen_loss = 0.8214989079369439, disc_loss = 0.06462905135833555
Trained batch 45 in epoch 5, gen_loss = 0.8184865803822227, disc_loss = 0.06460031796165783
Trained batch 46 in epoch 5, gen_loss = 0.8164737617715876, disc_loss = 0.06455696431642517
Trained batch 47 in epoch 5, gen_loss = 0.8136003129184246, disc_loss = 0.06442135256171848
Trained batch 48 in epoch 5, gen_loss = 0.8245465305386758, disc_loss = 0.0710000705392081
Trained batch 49 in epoch 5, gen_loss = 0.8219456553459168, disc_loss = 0.07154238739982248
Trained batch 50 in epoch 5, gen_loss = 0.8198145651349834, disc_loss = 0.0716917200160085
Trained batch 51 in epoch 5, gen_loss = 0.8226587084623483, disc_loss = 0.07135911925265995
Trained batch 52 in epoch 5, gen_loss = 0.8243946882913697, disc_loss = 0.07146890667038706
Trained batch 53 in epoch 5, gen_loss = 0.8258350215576313, disc_loss = 0.07128793706565544
Trained batch 54 in epoch 5, gen_loss = 0.8250519785014065, disc_loss = 0.07163687905466015
Trained batch 55 in epoch 5, gen_loss = 0.8228136801293918, disc_loss = 0.07222848839592189
Trained batch 56 in epoch 5, gen_loss = 0.8232986812005963, disc_loss = 0.072459999161462
Trained batch 57 in epoch 5, gen_loss = 0.8206421640412561, disc_loss = 0.07226868309401746
Trained batch 58 in epoch 5, gen_loss = 0.8198813634403681, disc_loss = 0.0715932677010611
Trained batch 59 in epoch 5, gen_loss = 0.8245559602975845, disc_loss = 0.0721094954914103
Trained batch 60 in epoch 5, gen_loss = 0.8209834010874639, disc_loss = 0.07430478724360955
Trained batch 61 in epoch 5, gen_loss = 0.8211372244742609, disc_loss = 0.07434333682120327
Trained batch 62 in epoch 5, gen_loss = 0.8218105709741986, disc_loss = 0.07407922795899803
Trained batch 63 in epoch 5, gen_loss = 0.8234013421460986, disc_loss = 0.07377200295741204
Trained batch 64 in epoch 5, gen_loss = 0.8208623574330256, disc_loss = 0.07442385693295644
Trained batch 65 in epoch 5, gen_loss = 0.8222756837353562, disc_loss = 0.07395136380342371
Trained batch 66 in epoch 5, gen_loss = 0.8236957405930134, disc_loss = 0.07586613943828131
Trained batch 67 in epoch 5, gen_loss = 0.8213926457306918, disc_loss = 0.07683008362758248
Trained batch 68 in epoch 5, gen_loss = 0.8196448269097701, disc_loss = 0.07742323198666175
Trained batch 69 in epoch 5, gen_loss = 0.8158410813127245, disc_loss = 0.07822717961722186
Trained batch 70 in epoch 5, gen_loss = 0.8150033186858808, disc_loss = 0.07882383194240467
Trained batch 71 in epoch 5, gen_loss = 0.8162785569826762, disc_loss = 0.07834966057756294
Trained batch 72 in epoch 5, gen_loss = 0.821096952647379, disc_loss = 0.07807425022992777
Trained batch 73 in epoch 5, gen_loss = 0.8196805610850051, disc_loss = 0.07738936416855133
Trained batch 74 in epoch 5, gen_loss = 0.8163353705406189, disc_loss = 0.07934344794601202
Trained batch 75 in epoch 5, gen_loss = 0.8185257809726816, disc_loss = 0.07847639598491553
Trained batch 76 in epoch 5, gen_loss = 0.8278291511845279, disc_loss = 0.081418970902148
Trained batch 77 in epoch 5, gen_loss = 0.8286090401502756, disc_loss = 0.08117748437544857
Trained batch 78 in epoch 5, gen_loss = 0.8254216373721256, disc_loss = 0.08293798984370276
Trained batch 79 in epoch 5, gen_loss = 0.8256403006613254, disc_loss = 0.08252308344235644
Trained batch 80 in epoch 5, gen_loss = 0.8237566109056826, disc_loss = 0.08209555875509977
Trained batch 81 in epoch 5, gen_loss = 0.8233868436115545, disc_loss = 0.08145341026119707
Trained batch 82 in epoch 5, gen_loss = 0.8261612151042524, disc_loss = 0.08165191997022155
Trained batch 83 in epoch 5, gen_loss = 0.8262144234918413, disc_loss = 0.08095625059546105
Trained batch 84 in epoch 5, gen_loss = 0.8265202213736141, disc_loss = 0.08053493288290851
Trained batch 85 in epoch 5, gen_loss = 0.8301705094270928, disc_loss = 0.07986556969279814
Trained batch 86 in epoch 5, gen_loss = 0.8299034326926045, disc_loss = 0.07973069994143028
Trained batch 87 in epoch 5, gen_loss = 0.8298129263249311, disc_loss = 0.07938596641179174
Trained batch 88 in epoch 5, gen_loss = 0.8293627848785915, disc_loss = 0.0796310981275158
Trained batch 89 in epoch 5, gen_loss = 0.832117501894633, disc_loss = 0.07891814703535703
Trained batch 90 in epoch 5, gen_loss = 0.8339347826255546, disc_loss = 0.07825999048917176
Trained batch 91 in epoch 5, gen_loss = 0.8320559340974559, disc_loss = 0.07829341759054881
Trained batch 92 in epoch 5, gen_loss = 0.8321714183335663, disc_loss = 0.07763543249338224
Trained batch 93 in epoch 5, gen_loss = 0.8348966621338053, disc_loss = 0.077068674348374
Trained batch 94 in epoch 5, gen_loss = 0.8340904863257157, disc_loss = 0.07689169546295153
Trained batch 95 in epoch 5, gen_loss = 0.8340444248169661, disc_loss = 0.07646442413291273
Trained batch 96 in epoch 5, gen_loss = 0.8326566372950053, disc_loss = 0.07608726865506356
Trained batch 97 in epoch 5, gen_loss = 0.8347978938599022, disc_loss = 0.07569240253152591
Trained batch 98 in epoch 5, gen_loss = 0.83452682242249, disc_loss = 0.07522645093161952
Trained batch 99 in epoch 5, gen_loss = 0.838292230963707, disc_loss = 0.07518135947175324
Trained batch 100 in epoch 5, gen_loss = 0.8415475098213346, disc_loss = 0.07483545083109991
Trained batch 101 in epoch 5, gen_loss = 0.8402845035581028, disc_loss = 0.0744519351397221
Trained batch 102 in epoch 5, gen_loss = 0.8402036931908247, disc_loss = 0.07393076080033212
Trained batch 103 in epoch 5, gen_loss = 0.8415861977980688, disc_loss = 0.07334030585256048
Trained batch 104 in epoch 5, gen_loss = 0.8432561193193708, disc_loss = 0.07279280552729255
Trained batch 105 in epoch 5, gen_loss = 0.8443185344057264, disc_loss = 0.07260617136709252
Trained batch 106 in epoch 5, gen_loss = 0.8436622697616292, disc_loss = 0.0723203797781161
Trained batch 107 in epoch 5, gen_loss = 0.8427955475118425, disc_loss = 0.07206892709385741
Trained batch 108 in epoch 5, gen_loss = 0.8430406757450979, disc_loss = 0.07168980804912814
Trained batch 109 in epoch 5, gen_loss = 0.843731983683326, disc_loss = 0.07116654910655185
Trained batch 110 in epoch 5, gen_loss = 0.8434017869803283, disc_loss = 0.0706641613715538
Trained batch 111 in epoch 5, gen_loss = 0.8479500311825957, disc_loss = 0.07130216475343332
Trained batch 112 in epoch 5, gen_loss = 0.8477900497681272, disc_loss = 0.0707590766498341
Trained batch 113 in epoch 5, gen_loss = 0.8461102205410338, disc_loss = 0.07115880484088209
Trained batch 114 in epoch 5, gen_loss = 0.8463774178339087, disc_loss = 0.07076752790776283
Trained batch 115 in epoch 5, gen_loss = 0.8452271500538135, disc_loss = 0.0704765686813485
Trained batch 116 in epoch 5, gen_loss = 0.8459791566571618, disc_loss = 0.07021871851518369
Trained batch 117 in epoch 5, gen_loss = 0.8473964687121116, disc_loss = 0.07061528104310066
Trained batch 118 in epoch 5, gen_loss = 0.8463639010902212, disc_loss = 0.07046654941748921
Trained batch 119 in epoch 5, gen_loss = 0.8445691679914792, disc_loss = 0.07139576818638792
Trained batch 120 in epoch 5, gen_loss = 0.8439414476560168, disc_loss = 0.07166183261924293
Trained batch 121 in epoch 5, gen_loss = 0.8477820426714225, disc_loss = 0.0718914671862101
Trained batch 122 in epoch 5, gen_loss = 0.845780074596405, disc_loss = 0.07261819225107509
Trained batch 123 in epoch 5, gen_loss = 0.8440554396760079, disc_loss = 0.07284577283257197
Trained batch 124 in epoch 5, gen_loss = 0.8464660210609436, disc_loss = 0.07265920849889516
Trained batch 125 in epoch 5, gen_loss = 0.8453553352091048, disc_loss = 0.07245492369734816
Trained batch 126 in epoch 5, gen_loss = 0.8459350354089512, disc_loss = 0.07208113345192878
Trained batch 127 in epoch 5, gen_loss = 0.8454289035871625, disc_loss = 0.07184547036740696
Trained batch 128 in epoch 5, gen_loss = 0.8446174236231072, disc_loss = 0.07193844062962042
Trained batch 129 in epoch 5, gen_loss = 0.8431692999142867, disc_loss = 0.07209872278886345
Trained batch 130 in epoch 5, gen_loss = 0.8457442535698869, disc_loss = 0.0719560822614163
Trained batch 131 in epoch 5, gen_loss = 0.8444183057907856, disc_loss = 0.0719438684525702
Trained batch 132 in epoch 5, gen_loss = 0.8441218563488552, disc_loss = 0.07169848363286346
Trained batch 133 in epoch 5, gen_loss = 0.8436239815469998, disc_loss = 0.07134775271806032
Trained batch 134 in epoch 5, gen_loss = 0.8456973173000194, disc_loss = 0.07103134994567545
Trained batch 135 in epoch 5, gen_loss = 0.8459407731014139, disc_loss = 0.0706513256779598
Trained batch 136 in epoch 5, gen_loss = 0.8463375633650453, disc_loss = 0.07074373091033993
Trained batch 137 in epoch 5, gen_loss = 0.8456647080787714, disc_loss = 0.07055474402706909
Trained batch 138 in epoch 5, gen_loss = 0.8445029417387873, disc_loss = 0.07045172412859664
Trained batch 139 in epoch 5, gen_loss = 0.8422241432326181, disc_loss = 0.07098302384173232
Trained batch 140 in epoch 5, gen_loss = 0.844569777766018, disc_loss = 0.07240949698611565
Trained batch 141 in epoch 5, gen_loss = 0.8465108871459961, disc_loss = 0.07218987395672101
Trained batch 142 in epoch 5, gen_loss = 0.8451179870358714, disc_loss = 0.07254733640856885
Trained batch 143 in epoch 5, gen_loss = 0.8432397842407227, disc_loss = 0.0730863140650197
Trained batch 144 in epoch 5, gen_loss = 0.8451065038812572, disc_loss = 0.07290139270882154
Trained batch 145 in epoch 5, gen_loss = 0.8449730019863337, disc_loss = 0.07283384598510927
Trained batch 146 in epoch 5, gen_loss = 0.8449971769131771, disc_loss = 0.07276514659756098
Trained batch 147 in epoch 5, gen_loss = 0.8436955926386086, disc_loss = 0.07298055291805114
Trained batch 148 in epoch 5, gen_loss = 0.8424014121094006, disc_loss = 0.07317669400257752
Trained batch 149 in epoch 5, gen_loss = 0.8431814881165822, disc_loss = 0.07324589208389322
Trained batch 150 in epoch 5, gen_loss = 0.8430401828904815, disc_loss = 0.07308232089171544
Trained batch 151 in epoch 5, gen_loss = 0.8420441632992343, disc_loss = 0.07298144262504618
Trained batch 152 in epoch 5, gen_loss = 0.843021478138718, disc_loss = 0.07274117710957535
Trained batch 153 in epoch 5, gen_loss = 0.8431433419902603, disc_loss = 0.07264573168759415
Trained batch 154 in epoch 5, gen_loss = 0.8439044564001021, disc_loss = 0.07276757098133525
Trained batch 155 in epoch 5, gen_loss = 0.8429752263503197, disc_loss = 0.07268433032246928
Trained batch 156 in epoch 5, gen_loss = 0.8420200541520574, disc_loss = 0.07256288283688438
Trained batch 157 in epoch 5, gen_loss = 0.8417734156681013, disc_loss = 0.0724541110906137
Trained batch 158 in epoch 5, gen_loss = 0.841312862792105, disc_loss = 0.07245375373570612
Trained batch 159 in epoch 5, gen_loss = 0.8425204627215862, disc_loss = 0.07223477066145279
Trained batch 160 in epoch 5, gen_loss = 0.8412621709870995, disc_loss = 0.07236995798483584
Trained batch 161 in epoch 5, gen_loss = 0.842417515354392, disc_loss = 0.0722696835025685
Trained batch 162 in epoch 5, gen_loss = 0.8435304113692301, disc_loss = 0.07198327607789472
Trained batch 163 in epoch 5, gen_loss = 0.843164011472609, disc_loss = 0.07183827200291179
Trained batch 164 in epoch 5, gen_loss = 0.8423553759401495, disc_loss = 0.07179767538539387
Trained batch 165 in epoch 5, gen_loss = 0.8424545336200531, disc_loss = 0.07184973506660886
Trained batch 166 in epoch 5, gen_loss = 0.8418100283531371, disc_loss = 0.07152021285369546
Trained batch 167 in epoch 5, gen_loss = 0.8412228475014368, disc_loss = 0.07135173662321731
Trained batch 168 in epoch 5, gen_loss = 0.8417135265451916, disc_loss = 0.07108684734457872
Trained batch 169 in epoch 5, gen_loss = 0.8412675980259391, disc_loss = 0.07084066352313932
Trained batch 170 in epoch 5, gen_loss = 0.8402247090785824, disc_loss = 0.0708489869149369
Trained batch 171 in epoch 5, gen_loss = 0.8427905499242073, disc_loss = 0.07187393062401476
Trained batch 172 in epoch 5, gen_loss = 0.8413641091027012, disc_loss = 0.07199428102938253
Trained batch 173 in epoch 5, gen_loss = 0.8420340031727978, disc_loss = 0.07173216933298898
Trained batch 174 in epoch 5, gen_loss = 0.8421804526873997, disc_loss = 0.07150443319231271
Trained batch 175 in epoch 5, gen_loss = 0.8423951332542029, disc_loss = 0.07115725350608541
Trained batch 176 in epoch 5, gen_loss = 0.8429747547133494, disc_loss = 0.07089699230204194
Trained batch 177 in epoch 5, gen_loss = 0.8425435052159127, disc_loss = 0.07063278574705793
Trained batch 178 in epoch 5, gen_loss = 0.8410538198561642, disc_loss = 0.07084906910801067
Trained batch 179 in epoch 5, gen_loss = 0.8415089266167747, disc_loss = 0.07061843223248919
Trained batch 180 in epoch 5, gen_loss = 0.842987301929221, disc_loss = 0.07048973827031106
Trained batch 181 in epoch 5, gen_loss = 0.8424948660226969, disc_loss = 0.07046191847709181
Trained batch 182 in epoch 5, gen_loss = 0.8426286669376769, disc_loss = 0.07013837875075679
Trained batch 183 in epoch 5, gen_loss = 0.843277786736903, disc_loss = 0.06995989754796028
Trained batch 184 in epoch 5, gen_loss = 0.8438350806365142, disc_loss = 0.0696894692408072
Trained batch 185 in epoch 5, gen_loss = 0.8438392730169398, disc_loss = 0.06942921736708252
Trained batch 186 in epoch 5, gen_loss = 0.8431162247683275, disc_loss = 0.0693433541744788
Trained batch 187 in epoch 5, gen_loss = 0.8429994310470338, disc_loss = 0.06926361467451492
Trained batch 188 in epoch 5, gen_loss = 0.8433163926084205, disc_loss = 0.06911981099891285
Trained batch 189 in epoch 5, gen_loss = 0.8432590619513863, disc_loss = 0.06886226999524393
Trained batch 190 in epoch 5, gen_loss = 0.8438355351617823, disc_loss = 0.06855247431576096
Trained batch 191 in epoch 5, gen_loss = 0.842781284203132, disc_loss = 0.06844706490422443
Trained batch 192 in epoch 5, gen_loss = 0.8416053427315746, disc_loss = 0.06862585210371666
Trained batch 193 in epoch 5, gen_loss = 0.842180324276698, disc_loss = 0.06838247629804249
Trained batch 194 in epoch 5, gen_loss = 0.8423997808725406, disc_loss = 0.06901009851254714
Trained batch 195 in epoch 5, gen_loss = 0.8429184850989556, disc_loss = 0.06872297524550587
Trained batch 196 in epoch 5, gen_loss = 0.8417009348191585, disc_loss = 0.06924151025504478
Trained batch 197 in epoch 5, gen_loss = 0.8431104906279632, disc_loss = 0.07012963157165984
Trained batch 198 in epoch 5, gen_loss = 0.8421605238363371, disc_loss = 0.0702070458441149
Trained batch 199 in epoch 5, gen_loss = 0.8427637374401092, disc_loss = 0.07002373290713876
Trained batch 200 in epoch 5, gen_loss = 0.8419339229811483, disc_loss = 0.0701757217363561
Trained batch 201 in epoch 5, gen_loss = 0.841383012509582, disc_loss = 0.0701711043706256
Trained batch 202 in epoch 5, gen_loss = 0.8413563952070152, disc_loss = 0.07000351632518574
Trained batch 203 in epoch 5, gen_loss = 0.8423340072234472, disc_loss = 0.06973029907299753
Trained batch 204 in epoch 5, gen_loss = 0.8427752457013944, disc_loss = 0.06955794572557618
Trained batch 205 in epoch 5, gen_loss = 0.8427737693763474, disc_loss = 0.06951101766718389
Trained batch 206 in epoch 5, gen_loss = 0.8438444768173107, disc_loss = 0.06951603925548458
Trained batch 207 in epoch 5, gen_loss = 0.8438661390772233, disc_loss = 0.06927229290774378
Trained batch 208 in epoch 5, gen_loss = 0.8429227890580465, disc_loss = 0.06916880654393914
Trained batch 209 in epoch 5, gen_loss = 0.842631684314637, disc_loss = 0.06897986649668643
Trained batch 210 in epoch 5, gen_loss = 0.8450550905901109, disc_loss = 0.06889934969792293
Trained batch 211 in epoch 5, gen_loss = 0.8445701264547851, disc_loss = 0.06876537117246047
Trained batch 212 in epoch 5, gen_loss = 0.8437369465827942, disc_loss = 0.06879090893349038
Trained batch 213 in epoch 5, gen_loss = 0.8443471892414806, disc_loss = 0.06873633769541004
Trained batch 214 in epoch 5, gen_loss = 0.8430955579114515, disc_loss = 0.06888685203482245
Trained batch 215 in epoch 5, gen_loss = 0.8425695446354372, disc_loss = 0.06891228139176275
Trained batch 216 in epoch 5, gen_loss = 0.8427067404518479, disc_loss = 0.06866918416256042
Trained batch 217 in epoch 5, gen_loss = 0.8429893750116366, disc_loss = 0.06849771462500505
Trained batch 218 in epoch 5, gen_loss = 0.8421835787764423, disc_loss = 0.0685783696560759
Trained batch 219 in epoch 5, gen_loss = 0.8419440039179542, disc_loss = 0.06838915511881086
Trained batch 220 in epoch 5, gen_loss = 0.8437400951105005, disc_loss = 0.06853002331291254
Trained batch 221 in epoch 5, gen_loss = 0.8437917680890711, disc_loss = 0.06832556226416617
Trained batch 222 in epoch 5, gen_loss = 0.8439720903811433, disc_loss = 0.06810253660190399
Trained batch 223 in epoch 5, gen_loss = 0.8443393071315118, disc_loss = 0.06789868377797705
Trained batch 224 in epoch 5, gen_loss = 0.8453595858150058, disc_loss = 0.06775805401719279
Trained batch 225 in epoch 5, gen_loss = 0.844660527147023, disc_loss = 0.06780820456539503
Trained batch 226 in epoch 5, gen_loss = 0.8443766202170419, disc_loss = 0.06779471274038637
Trained batch 227 in epoch 5, gen_loss = 0.8444428077915258, disc_loss = 0.068125227217056
Trained batch 228 in epoch 5, gen_loss = 0.8438394303925694, disc_loss = 0.06815172355687124
Trained batch 229 in epoch 5, gen_loss = 0.842582647955936, disc_loss = 0.06807463374393789
Trained batch 230 in epoch 5, gen_loss = 0.8419581029838298, disc_loss = 0.06813414483149717
Trained batch 231 in epoch 5, gen_loss = 0.8425797881751225, disc_loss = 0.06806644149815086
Trained batch 232 in epoch 5, gen_loss = 0.8420815667369335, disc_loss = 0.06790510646982893
Trained batch 233 in epoch 5, gen_loss = 0.8417113079474523, disc_loss = 0.0678797353289894
Trained batch 234 in epoch 5, gen_loss = 0.8412689257175364, disc_loss = 0.06783935645238516
Trained batch 235 in epoch 5, gen_loss = 0.8419200384010703, disc_loss = 0.06774985591754697
Trained batch 236 in epoch 5, gen_loss = 0.8406133576284481, disc_loss = 0.06816891637799735
Trained batch 237 in epoch 5, gen_loss = 0.84182726184861, disc_loss = 0.0682044285975647
Trained batch 238 in epoch 5, gen_loss = 0.8421873033794898, disc_loss = 0.06795986236373126
Trained batch 239 in epoch 5, gen_loss = 0.8425099906822046, disc_loss = 0.06771591455520441
Trained batch 240 in epoch 5, gen_loss = 0.8428046319989247, disc_loss = 0.06747591242781566
Trained batch 241 in epoch 5, gen_loss = 0.8418843041766774, disc_loss = 0.06769193220144708
Trained batch 242 in epoch 5, gen_loss = 0.8427511002301189, disc_loss = 0.06783981094665734
Trained batch 243 in epoch 5, gen_loss = 0.842596637420967, disc_loss = 0.0678899693455486
Trained batch 244 in epoch 5, gen_loss = 0.8412523649176773, disc_loss = 0.06832817778447453
Trained batch 245 in epoch 5, gen_loss = 0.8402011876668387, disc_loss = 0.06843227600088207
Trained batch 246 in epoch 5, gen_loss = 0.8404385966327992, disc_loss = 0.06830947448759668
Trained batch 247 in epoch 5, gen_loss = 0.8401588215943305, disc_loss = 0.06824373721986288
Trained batch 248 in epoch 5, gen_loss = 0.8419922250341699, disc_loss = 0.06837673889974274
Trained batch 249 in epoch 5, gen_loss = 0.8406217426061631, disc_loss = 0.0692609064951539
Trained batch 250 in epoch 5, gen_loss = 0.840240217893722, disc_loss = 0.06918847668485575
Trained batch 251 in epoch 5, gen_loss = 0.841338315298633, disc_loss = 0.07000288119657881
Trained batch 252 in epoch 5, gen_loss = 0.8408591819139337, disc_loss = 0.0700631435636593
Trained batch 253 in epoch 5, gen_loss = 0.8398077083150233, disc_loss = 0.07076571724106243
Trained batch 254 in epoch 5, gen_loss = 0.839915477177676, disc_loss = 0.07100747105683766
Trained batch 255 in epoch 5, gen_loss = 0.8417338110739365, disc_loss = 0.07160769007896306
Trained batch 256 in epoch 5, gen_loss = 0.840923843796615, disc_loss = 0.07158547162226898
Trained batch 257 in epoch 5, gen_loss = 0.8398258858179861, disc_loss = 0.07198329706669085
Trained batch 258 in epoch 5, gen_loss = 0.8399189504647347, disc_loss = 0.07186882207206087
Trained batch 259 in epoch 5, gen_loss = 0.8393755001517442, disc_loss = 0.0717417921942587
Trained batch 260 in epoch 5, gen_loss = 0.8396529357780442, disc_loss = 0.071562136441355
Trained batch 261 in epoch 5, gen_loss = 0.8393801495091606, disc_loss = 0.07144507425943859
Trained batch 262 in epoch 5, gen_loss = 0.8394696797481508, disc_loss = 0.07136374197815308
Trained batch 263 in epoch 5, gen_loss = 0.8394648856060072, disc_loss = 0.07114987583675732
Trained batch 264 in epoch 5, gen_loss = 0.8393100269560544, disc_loss = 0.07099911211726238
Trained batch 265 in epoch 5, gen_loss = 0.8395417387548246, disc_loss = 0.07095872522226739
Trained batch 266 in epoch 5, gen_loss = 0.8389334936490219, disc_loss = 0.07113497953666618
Trained batch 267 in epoch 5, gen_loss = 0.8386391678185605, disc_loss = 0.07123399368459497
Trained batch 268 in epoch 5, gen_loss = 0.839340391766183, disc_loss = 0.07138063117072374
Trained batch 269 in epoch 5, gen_loss = 0.8405835263155125, disc_loss = 0.0712339899847629
Trained batch 270 in epoch 5, gen_loss = 0.8397401464601284, disc_loss = 0.07174370355038076
Trained batch 271 in epoch 5, gen_loss = 0.8398402047288769, disc_loss = 0.07165096668348483
Trained batch 272 in epoch 5, gen_loss = 0.8396865117462563, disc_loss = 0.07150003320499981
Trained batch 273 in epoch 5, gen_loss = 0.8405443448437392, disc_loss = 0.0716513026145416
Trained batch 274 in epoch 5, gen_loss = 0.840018776438453, disc_loss = 0.0717526421865279
Trained batch 275 in epoch 5, gen_loss = 0.8395848657557929, disc_loss = 0.07173644730726769
Trained batch 276 in epoch 5, gen_loss = 0.8404462969044916, disc_loss = 0.07165571935273142
Trained batch 277 in epoch 5, gen_loss = 0.8401803491141299, disc_loss = 0.07167010610628365
Trained batch 278 in epoch 5, gen_loss = 0.8395466421026483, disc_loss = 0.07161601450908461
Trained batch 279 in epoch 5, gen_loss = 0.8394704051315784, disc_loss = 0.07163693321802254
Trained batch 280 in epoch 5, gen_loss = 0.839626990073092, disc_loss = 0.07164083115981885
Trained batch 281 in epoch 5, gen_loss = 0.8391249844579832, disc_loss = 0.07167395003179604
Trained batch 282 in epoch 5, gen_loss = 0.8398123930073459, disc_loss = 0.07160762812968594
Trained batch 283 in epoch 5, gen_loss = 0.8396928286258604, disc_loss = 0.0714869384660425
Trained batch 284 in epoch 5, gen_loss = 0.8393537043479451, disc_loss = 0.07151989480317161
Trained batch 285 in epoch 5, gen_loss = 0.8400855180058446, disc_loss = 0.07155398788399525
Trained batch 286 in epoch 5, gen_loss = 0.8391152536204468, disc_loss = 0.07167310868341228
Trained batch 287 in epoch 5, gen_loss = 0.8395672261507975, disc_loss = 0.0714978540102796
Trained batch 288 in epoch 5, gen_loss = 0.8409263884526224, disc_loss = 0.07155518049122862
Trained batch 289 in epoch 5, gen_loss = 0.8408288208575084, disc_loss = 0.07149854198033953
Trained batch 290 in epoch 5, gen_loss = 0.8403698915673286, disc_loss = 0.07135573970121924
Trained batch 291 in epoch 5, gen_loss = 0.8400170293776956, disc_loss = 0.07134915437638657
Trained batch 292 in epoch 5, gen_loss = 0.8389771203335642, disc_loss = 0.07166293058417254
Trained batch 293 in epoch 5, gen_loss = 0.8391381898502104, disc_loss = 0.07145886281251806
Trained batch 294 in epoch 5, gen_loss = 0.8395343504719815, disc_loss = 0.07145687180997456
Trained batch 295 in epoch 5, gen_loss = 0.839480662970124, disc_loss = 0.07138025451992713
Trained batch 296 in epoch 5, gen_loss = 0.8387075284314075, disc_loss = 0.07157600461270171
Trained batch 297 in epoch 5, gen_loss = 0.838922026873435, disc_loss = 0.07147569951582575
Trained batch 298 in epoch 5, gen_loss = 0.8387265296086021, disc_loss = 0.07141166275996329
Trained batch 299 in epoch 5, gen_loss = 0.8383494610587756, disc_loss = 0.0714412776225557
Trained batch 300 in epoch 5, gen_loss = 0.8383957596118268, disc_loss = 0.07178338615539363
Trained batch 301 in epoch 5, gen_loss = 0.8377131011509737, disc_loss = 0.07180751858599829
Trained batch 302 in epoch 5, gen_loss = 0.838351972130659, disc_loss = 0.07182758115539357
Trained batch 303 in epoch 5, gen_loss = 0.8372190549577537, disc_loss = 0.07226970187376107
Trained batch 304 in epoch 5, gen_loss = 0.8377855287223566, disc_loss = 0.07247265575789526
Trained batch 305 in epoch 5, gen_loss = 0.8375242934897055, disc_loss = 0.072408983237384
Trained batch 306 in epoch 5, gen_loss = 0.8375400225192017, disc_loss = 0.07227742998081135
Trained batch 307 in epoch 5, gen_loss = 0.8372380503199317, disc_loss = 0.07215410592820641
Trained batch 308 in epoch 5, gen_loss = 0.8376254836718241, disc_loss = 0.0720377344981704
Trained batch 309 in epoch 5, gen_loss = 0.8372723585174929, disc_loss = 0.07205234813774306
Trained batch 310 in epoch 5, gen_loss = 0.8366172139284311, disc_loss = 0.07212023285795542
Trained batch 311 in epoch 5, gen_loss = 0.8363529871671628, disc_loss = 0.07208281475752114
Trained batch 312 in epoch 5, gen_loss = 0.8368044101392118, disc_loss = 0.07197485117616649
Trained batch 313 in epoch 5, gen_loss = 0.8361463960568616, disc_loss = 0.07205948265340582
Trained batch 314 in epoch 5, gen_loss = 0.8367566354691036, disc_loss = 0.07225743294176128
Trained batch 315 in epoch 5, gen_loss = 0.8364161375579955, disc_loss = 0.07221017177570375
Trained batch 316 in epoch 5, gen_loss = 0.836223307092107, disc_loss = 0.07233945927538613
Trained batch 317 in epoch 5, gen_loss = 0.8363378276615023, disc_loss = 0.07218005125990735
Trained batch 318 in epoch 5, gen_loss = 0.8354431986808777, disc_loss = 0.07242672978885775
Trained batch 319 in epoch 5, gen_loss = 0.834579493664205, disc_loss = 0.07274129937577527
Trained batch 320 in epoch 5, gen_loss = 0.8350363767407022, disc_loss = 0.07318326187642099
Trained batch 321 in epoch 5, gen_loss = 0.835658634856621, disc_loss = 0.07302081265330593
Trained batch 322 in epoch 5, gen_loss = 0.8353334753875024, disc_loss = 0.07314384100964472
Trained batch 323 in epoch 5, gen_loss = 0.8344597205703641, disc_loss = 0.07319832293972096
Trained batch 324 in epoch 5, gen_loss = 0.8349608300282405, disc_loss = 0.0733375854188433
Trained batch 325 in epoch 5, gen_loss = 0.8342791089982343, disc_loss = 0.07333734290720038
Trained batch 326 in epoch 5, gen_loss = 0.8333061769467975, disc_loss = 0.07338728406822553
Trained batch 327 in epoch 5, gen_loss = 0.8339469665434303, disc_loss = 0.07327454396035159
Trained batch 328 in epoch 5, gen_loss = 0.8345587028920831, disc_loss = 0.0733845054078564
Trained batch 329 in epoch 5, gen_loss = 0.8340781390666961, disc_loss = 0.07336448521042864
Trained batch 330 in epoch 5, gen_loss = 0.8338500670075777, disc_loss = 0.07327266631428479
Trained batch 331 in epoch 5, gen_loss = 0.8337522491992239, disc_loss = 0.07351299846286785
Trained batch 332 in epoch 5, gen_loss = 0.8329941164981853, disc_loss = 0.07347634253189997
Trained batch 333 in epoch 5, gen_loss = 0.832370682569321, disc_loss = 0.07356019846503874
Trained batch 334 in epoch 5, gen_loss = 0.8321627725416155, disc_loss = 0.07404007677878462
Trained batch 335 in epoch 5, gen_loss = 0.8314862572366283, disc_loss = 0.07411449067460905
Trained batch 336 in epoch 5, gen_loss = 0.8319116839669225, disc_loss = 0.07410438475682668
Trained batch 337 in epoch 5, gen_loss = 0.8317313846751783, disc_loss = 0.0739819275066477
Trained batch 338 in epoch 5, gen_loss = 0.8316776624119739, disc_loss = 0.07390156408887258
Trained batch 339 in epoch 5, gen_loss = 0.8317498964421889, disc_loss = 0.07383829991552321
Trained batch 340 in epoch 5, gen_loss = 0.8309036495049329, disc_loss = 0.07409586895890861
Trained batch 341 in epoch 5, gen_loss = 0.8308994367457273, disc_loss = 0.07405163818011769
Trained batch 342 in epoch 5, gen_loss = 0.8319950939614988, disc_loss = 0.0740194619543655
Trained batch 343 in epoch 5, gen_loss = 0.8325252333699271, disc_loss = 0.07403139927868493
Trained batch 344 in epoch 5, gen_loss = 0.8320815606393676, disc_loss = 0.07421092772991329
Trained batch 345 in epoch 5, gen_loss = 0.8314355255206886, disc_loss = 0.07452987282768408
Trained batch 346 in epoch 5, gen_loss = 0.8312843855932054, disc_loss = 0.0744955466888437
Trained batch 347 in epoch 5, gen_loss = 0.8318278919691326, disc_loss = 0.07500258886426601
Trained batch 348 in epoch 5, gen_loss = 0.8311759913206783, disc_loss = 0.07514053192203143
Trained batch 349 in epoch 5, gen_loss = 0.8312694205556597, disc_loss = 0.07511368263778942
Trained batch 350 in epoch 5, gen_loss = 0.8314561127257822, disc_loss = 0.0749340767221276
Trained batch 351 in epoch 5, gen_loss = 0.8303918340666727, disc_loss = 0.07506767146299932
Trained batch 352 in epoch 5, gen_loss = 0.831232947938503, disc_loss = 0.07498650630888537
Trained batch 353 in epoch 5, gen_loss = 0.8317383999204905, disc_loss = 0.07489183529590566
Trained batch 354 in epoch 5, gen_loss = 0.831197749393087, disc_loss = 0.07484297534372185
Trained batch 355 in epoch 5, gen_loss = 0.8304556385519799, disc_loss = 0.07491442435839621
Trained batch 356 in epoch 5, gen_loss = 0.8306702562406951, disc_loss = 0.07525901212839603
Trained batch 357 in epoch 5, gen_loss = 0.8300917659724891, disc_loss = 0.07532658030710823
Trained batch 358 in epoch 5, gen_loss = 0.8294260639666182, disc_loss = 0.07552998608709793
Trained batch 359 in epoch 5, gen_loss = 0.8306124205390613, disc_loss = 0.07558970809655471
Trained batch 360 in epoch 5, gen_loss = 0.8304915510716531, disc_loss = 0.0754712728236562
Trained batch 361 in epoch 5, gen_loss = 0.8300588824143067, disc_loss = 0.0753733409769339
Trained batch 362 in epoch 5, gen_loss = 0.8295658248843569, disc_loss = 0.07540892356283162
Trained batch 363 in epoch 5, gen_loss = 0.8301639917132618, disc_loss = 0.07569335687874847
Trained batch 364 in epoch 5, gen_loss = 0.8294803335242076, disc_loss = 0.0757034702277551
Trained batch 365 in epoch 5, gen_loss = 0.8289676321660234, disc_loss = 0.07564781885339669
Trained batch 366 in epoch 5, gen_loss = 0.828790497714882, disc_loss = 0.07561321981119282
Trained batch 367 in epoch 5, gen_loss = 0.8287882791913074, disc_loss = 0.07559232573966375
Trained batch 368 in epoch 5, gen_loss = 0.8285468031720418, disc_loss = 0.07545194699401213
Trained batch 369 in epoch 5, gen_loss = 0.8284002452283292, disc_loss = 0.07534975281891387
Trained batch 370 in epoch 5, gen_loss = 0.8280455497397246, disc_loss = 0.07530434113598336
Trained batch 371 in epoch 5, gen_loss = 0.8295035320584492, disc_loss = 0.07561045405655219
Trained batch 372 in epoch 5, gen_loss = 0.8295626010715802, disc_loss = 0.07555101245851444
Trained batch 373 in epoch 5, gen_loss = 0.8291250011500191, disc_loss = 0.07578660560931194
Trained batch 374 in epoch 5, gen_loss = 0.8290765736897786, disc_loss = 0.07582111534724632
Trained batch 375 in epoch 5, gen_loss = 0.8300007521472079, disc_loss = 0.07663743674725373
Trained batch 376 in epoch 5, gen_loss = 0.829618672002848, disc_loss = 0.07716645487393957
Trained batch 377 in epoch 5, gen_loss = 0.8293122409512756, disc_loss = 0.07724126469018677
Trained batch 378 in epoch 5, gen_loss = 0.830047892391839, disc_loss = 0.0774789644149685
Trained batch 379 in epoch 5, gen_loss = 0.8302887571485419, disc_loss = 0.07736484352744331
Trained batch 380 in epoch 5, gen_loss = 0.8299128790227134, disc_loss = 0.07745992864807212
Trained batch 381 in epoch 5, gen_loss = 0.8293844995074248, disc_loss = 0.07762250001176568
Trained batch 382 in epoch 5, gen_loss = 0.8294080221933111, disc_loss = 0.0777482339557912
Trained batch 383 in epoch 5, gen_loss = 0.8291081564190487, disc_loss = 0.07788680541610422
Trained batch 384 in epoch 5, gen_loss = 0.8285481164981793, disc_loss = 0.07811295998996341
Trained batch 385 in epoch 5, gen_loss = 0.8291390921167759, disc_loss = 0.07844905290086729
Trained batch 386 in epoch 5, gen_loss = 0.8282957865594277, disc_loss = 0.07864643137863517
Trained batch 387 in epoch 5, gen_loss = 0.8280734796192228, disc_loss = 0.07869209801614976
Trained batch 388 in epoch 5, gen_loss = 0.8282262793236955, disc_loss = 0.07860648043329198
Trained batch 389 in epoch 5, gen_loss = 0.8278098849149851, disc_loss = 0.07860599835761464
Trained batch 390 in epoch 5, gen_loss = 0.8278273633678855, disc_loss = 0.0785105881469367
Trained batch 391 in epoch 5, gen_loss = 0.8281773987169169, disc_loss = 0.07843067483947974
Trained batch 392 in epoch 5, gen_loss = 0.828855533181256, disc_loss = 0.07831817754703092
Trained batch 393 in epoch 5, gen_loss = 0.8289443845978848, disc_loss = 0.07818948569457014
Trained batch 394 in epoch 5, gen_loss = 0.8291531371164925, disc_loss = 0.07814289113813186
Trained batch 395 in epoch 5, gen_loss = 0.8287707412182682, disc_loss = 0.07824557840193838
Trained batch 396 in epoch 5, gen_loss = 0.8284644385429113, disc_loss = 0.07828620482724094
Trained batch 397 in epoch 5, gen_loss = 0.8288804388525498, disc_loss = 0.07832170425020346
Trained batch 398 in epoch 5, gen_loss = 0.8287903285564336, disc_loss = 0.07822814457968139
Trained batch 399 in epoch 5, gen_loss = 0.8292889615893364, disc_loss = 0.07810408705146983
Trained batch 400 in epoch 5, gen_loss = 0.8297552191408495, disc_loss = 0.07796902660317626
Trained batch 401 in epoch 5, gen_loss = 0.8289915742862284, disc_loss = 0.07809771281616086
Trained batch 402 in epoch 5, gen_loss = 0.8290761457779271, disc_loss = 0.07802148665493312
Trained batch 403 in epoch 5, gen_loss = 0.8294392769584561, disc_loss = 0.07815015805875974
Trained batch 404 in epoch 5, gen_loss = 0.8290860717679247, disc_loss = 0.07826955163230499
Trained batch 405 in epoch 5, gen_loss = 0.8294606900273873, disc_loss = 0.07829514514021758
Trained batch 406 in epoch 5, gen_loss = 0.8296699059683216, disc_loss = 0.0782524742373707
Trained batch 407 in epoch 5, gen_loss = 0.8294625689878183, disc_loss = 0.07821513623154412
Trained batch 408 in epoch 5, gen_loss = 0.8297769163523443, disc_loss = 0.07808301087541729
Trained batch 409 in epoch 5, gen_loss = 0.829692005238882, disc_loss = 0.07795285770851301
Trained batch 410 in epoch 5, gen_loss = 0.8295938504583354, disc_loss = 0.07807553259751004
Trained batch 411 in epoch 5, gen_loss = 0.8289964129623858, disc_loss = 0.07812706857820231
Trained batch 412 in epoch 5, gen_loss = 0.8300283691207664, disc_loss = 0.07824669088536905
Trained batch 413 in epoch 5, gen_loss = 0.8300615861508005, disc_loss = 0.07810842214548142
Trained batch 414 in epoch 5, gen_loss = 0.8293801672487374, disc_loss = 0.07834839807621327
Trained batch 415 in epoch 5, gen_loss = 0.8302144932632263, disc_loss = 0.07868107026129459
Trained batch 416 in epoch 5, gen_loss = 0.8301519978818276, disc_loss = 0.07857658584742881
Trained batch 417 in epoch 5, gen_loss = 0.8302302065363341, disc_loss = 0.07860927926554706
Trained batch 418 in epoch 5, gen_loss = 0.8300278339010434, disc_loss = 0.0785216257478464
Trained batch 419 in epoch 5, gen_loss = 0.8300205019258318, disc_loss = 0.07856921425222287
Trained batch 420 in epoch 5, gen_loss = 0.8292505176220257, disc_loss = 0.07916423068945949
Trained batch 421 in epoch 5, gen_loss = 0.8298495178821528, disc_loss = 0.07909848745161958
Trained batch 422 in epoch 5, gen_loss = 0.8300982171198437, disc_loss = 0.07913144235113904
Trained batch 423 in epoch 5, gen_loss = 0.8298122695875618, disc_loss = 0.07904052379637745
Trained batch 424 in epoch 5, gen_loss = 0.8296358523649328, disc_loss = 0.07897299827240846
Trained batch 425 in epoch 5, gen_loss = 0.8300917708258114, disc_loss = 0.07884485999279668
Trained batch 426 in epoch 5, gen_loss = 0.8304613062313625, disc_loss = 0.07896881971717648
Trained batch 427 in epoch 5, gen_loss = 0.8310327470024056, disc_loss = 0.07885476517943647
Trained batch 428 in epoch 5, gen_loss = 0.8306115055695559, disc_loss = 0.07876952350495647
Trained batch 429 in epoch 5, gen_loss = 0.8299179932405782, disc_loss = 0.07900849081965726
Trained batch 430 in epoch 5, gen_loss = 0.830249043462448, disc_loss = 0.0790742019303748
Trained batch 431 in epoch 5, gen_loss = 0.8307853134142028, disc_loss = 0.07899134595990526
Trained batch 432 in epoch 5, gen_loss = 0.8305007238586285, disc_loss = 0.07895612575793445
Trained batch 433 in epoch 5, gen_loss = 0.8299343360733876, disc_loss = 0.07893164277565988
Trained batch 434 in epoch 5, gen_loss = 0.8296330972649585, disc_loss = 0.07885393092044811
Trained batch 435 in epoch 5, gen_loss = 0.8297949967854613, disc_loss = 0.0787577032807941
Trained batch 436 in epoch 5, gen_loss = 0.8298507190950948, disc_loss = 0.07870620762123737
Trained batch 437 in epoch 5, gen_loss = 0.8297197515289533, disc_loss = 0.07860197681618948
Trained batch 438 in epoch 5, gen_loss = 0.8293526269037251, disc_loss = 0.07852929700081128
Trained batch 439 in epoch 5, gen_loss = 0.8290217873725024, disc_loss = 0.07843464589466087
Trained batch 440 in epoch 5, gen_loss = 0.8283450108807103, disc_loss = 0.07856826278298688
Trained batch 441 in epoch 5, gen_loss = 0.8283030676625972, disc_loss = 0.07844911266025577
Trained batch 442 in epoch 5, gen_loss = 0.8287195548516095, disc_loss = 0.07842035934488809
Trained batch 443 in epoch 5, gen_loss = 0.8292032480239868, disc_loss = 0.0783446981122734
Trained batch 444 in epoch 5, gen_loss = 0.8295795123228866, disc_loss = 0.07822850368958846
Trained batch 445 in epoch 5, gen_loss = 0.829193161341107, disc_loss = 0.0781723572496709
Trained batch 446 in epoch 5, gen_loss = 0.8285907173583438, disc_loss = 0.07852341800353071
Trained batch 447 in epoch 5, gen_loss = 0.8286061984087739, disc_loss = 0.07855338944812372
Trained batch 448 in epoch 5, gen_loss = 0.8288762659697331, disc_loss = 0.07852212137818536
Trained batch 449 in epoch 5, gen_loss = 0.8288467646969689, disc_loss = 0.07843153304316931
Trained batch 450 in epoch 5, gen_loss = 0.8288441177482351, disc_loss = 0.07843611364411872
Trained batch 451 in epoch 5, gen_loss = 0.8284460477596891, disc_loss = 0.07851517058505092
Trained batch 452 in epoch 5, gen_loss = 0.8283809673444061, disc_loss = 0.07846488596184825
Trained batch 453 in epoch 5, gen_loss = 0.8292974409552922, disc_loss = 0.07857174785512332
Trained batch 454 in epoch 5, gen_loss = 0.8287928020561134, disc_loss = 0.07864676214304271
Trained batch 455 in epoch 5, gen_loss = 0.8290845810582763, disc_loss = 0.07850562902616762
Trained batch 456 in epoch 5, gen_loss = 0.8287796054679403, disc_loss = 0.07841888131039865
Trained batch 457 in epoch 5, gen_loss = 0.8286771104065092, disc_loss = 0.07837135970031266
Trained batch 458 in epoch 5, gen_loss = 0.8290792878936318, disc_loss = 0.07830060045955163
Trained batch 459 in epoch 5, gen_loss = 0.8292021199412968, disc_loss = 0.0781984406300699
Trained batch 460 in epoch 5, gen_loss = 0.8291301587657143, disc_loss = 0.07811627187715629
Trained batch 461 in epoch 5, gen_loss = 0.8289691091099859, disc_loss = 0.07798298997643255
Trained batch 462 in epoch 5, gen_loss = 0.8295641254400331, disc_loss = 0.07795975670483986
Trained batch 463 in epoch 5, gen_loss = 0.8292487375438213, disc_loss = 0.0780157895120471
Trained batch 464 in epoch 5, gen_loss = 0.8292382718414388, disc_loss = 0.07805036470814739
Trained batch 465 in epoch 5, gen_loss = 0.8291726858063317, disc_loss = 0.07795957377772027
Trained batch 466 in epoch 5, gen_loss = 0.8291670473280505, disc_loss = 0.0781795271877718
Trained batch 467 in epoch 5, gen_loss = 0.8294498362602332, disc_loss = 0.07806355526280773
Trained batch 468 in epoch 5, gen_loss = 0.8293637036006334, disc_loss = 0.07795632440152007
Trained batch 469 in epoch 5, gen_loss = 0.8290552120259468, disc_loss = 0.07799173390809842
Trained batch 470 in epoch 5, gen_loss = 0.8295604966248676, disc_loss = 0.07802873592222635
Trained batch 471 in epoch 5, gen_loss = 0.8295109509411505, disc_loss = 0.07802356284119631
Trained batch 472 in epoch 5, gen_loss = 0.8293214892736197, disc_loss = 0.07801824223927477
Trained batch 473 in epoch 5, gen_loss = 0.8290555897141307, disc_loss = 0.07799541483582136
Trained batch 474 in epoch 5, gen_loss = 0.8294875308086997, disc_loss = 0.07816313776726785
Trained batch 475 in epoch 5, gen_loss = 0.8292069415084454, disc_loss = 0.07810407974992041
Trained batch 476 in epoch 5, gen_loss = 0.8292730871736379, disc_loss = 0.07797850304296869
Trained batch 477 in epoch 5, gen_loss = 0.8297946812218702, disc_loss = 0.07785661498505513
Trained batch 478 in epoch 5, gen_loss = 0.8298459824540172, disc_loss = 0.0777728092372573
Trained batch 479 in epoch 5, gen_loss = 0.8300158761441707, disc_loss = 0.0776639226571812
Trained batch 480 in epoch 5, gen_loss = 0.8305011645671979, disc_loss = 0.0776403733507852
Trained batch 481 in epoch 5, gen_loss = 0.830410113225834, disc_loss = 0.0775475348191359
Trained batch 482 in epoch 5, gen_loss = 0.8300897606164526, disc_loss = 0.0775621488177474
Trained batch 483 in epoch 5, gen_loss = 0.830309005561939, disc_loss = 0.07763540099590463
Trained batch 484 in epoch 5, gen_loss = 0.8303399105661923, disc_loss = 0.07764266474153271
Trained batch 485 in epoch 5, gen_loss = 0.830000239757844, disc_loss = 0.07768349864408987
Trained batch 486 in epoch 5, gen_loss = 0.8299624918667443, disc_loss = 0.07762518755946254
Trained batch 487 in epoch 5, gen_loss = 0.8305573765127385, disc_loss = 0.07751729832313282
Trained batch 488 in epoch 5, gen_loss = 0.8307945761212542, disc_loss = 0.07741424354299872
Trained batch 489 in epoch 5, gen_loss = 0.8308130275230019, disc_loss = 0.07737677000577048
Trained batch 490 in epoch 5, gen_loss = 0.8306786199451222, disc_loss = 0.07732664785194239
Trained batch 491 in epoch 5, gen_loss = 0.8304778968657904, disc_loss = 0.07724585341539507
Trained batch 492 in epoch 5, gen_loss = 0.8304485902341335, disc_loss = 0.07722561987604319
Trained batch 493 in epoch 5, gen_loss = 0.830246193206262, disc_loss = 0.07720242117754059
Trained batch 494 in epoch 5, gen_loss = 0.830602088841525, disc_loss = 0.07706722996263492
Trained batch 495 in epoch 5, gen_loss = 0.8300868630889924, disc_loss = 0.07708075359996949
Trained batch 496 in epoch 5, gen_loss = 0.829928737291148, disc_loss = 0.07700669437729317
Trained batch 497 in epoch 5, gen_loss = 0.8302027397605789, disc_loss = 0.0772645753755956
Trained batch 498 in epoch 5, gen_loss = 0.8302177906275273, disc_loss = 0.07713567054194057
Trained batch 499 in epoch 5, gen_loss = 0.8297808151245117, disc_loss = 0.07723422794789075
Trained batch 500 in epoch 5, gen_loss = 0.8299293306297408, disc_loss = 0.07714330393843308
Trained batch 501 in epoch 5, gen_loss = 0.8302131981488718, disc_loss = 0.07712277473948628
Trained batch 502 in epoch 5, gen_loss = 0.8306942697073783, disc_loss = 0.07704327265856044
Trained batch 503 in epoch 5, gen_loss = 0.830492189715779, disc_loss = 0.07697314196192319
Trained batch 504 in epoch 5, gen_loss = 0.8305533963854951, disc_loss = 0.0768529445117358
Trained batch 505 in epoch 5, gen_loss = 0.8307272652863514, disc_loss = 0.07672375629622886
Trained batch 506 in epoch 5, gen_loss = 0.830977764237797, disc_loss = 0.07663464183777688
Trained batch 507 in epoch 5, gen_loss = 0.8305964887611509, disc_loss = 0.07683565364013917
Trained batch 508 in epoch 5, gen_loss = 0.8310006592269028, disc_loss = 0.07678625395078732
Trained batch 509 in epoch 5, gen_loss = 0.8309434561168446, disc_loss = 0.07672329108760345
Trained batch 510 in epoch 5, gen_loss = 0.831181532016239, disc_loss = 0.07671573588081478
Trained batch 511 in epoch 5, gen_loss = 0.8308576650451869, disc_loss = 0.07672435805397981
Trained batch 512 in epoch 5, gen_loss = 0.8310301790692886, disc_loss = 0.07667977430950305
Trained batch 513 in epoch 5, gen_loss = 0.8307805454452678, disc_loss = 0.07657155736099479
Trained batch 514 in epoch 5, gen_loss = 0.8309743183330425, disc_loss = 0.07645205369092596
Trained batch 515 in epoch 5, gen_loss = 0.8307217055743978, disc_loss = 0.07639142814409998
Trained batch 516 in epoch 5, gen_loss = 0.8313813999266413, disc_loss = 0.07630330411180479
Trained batch 517 in epoch 5, gen_loss = 0.8308881082820155, disc_loss = 0.07639094376505054
Trained batch 518 in epoch 5, gen_loss = 0.8313857791281389, disc_loss = 0.07638877202973832
Trained batch 519 in epoch 5, gen_loss = 0.8318416534708096, disc_loss = 0.07627144211795754
Trained batch 520 in epoch 5, gen_loss = 0.8315675115631089, disc_loss = 0.07621447481179248
Trained batch 521 in epoch 5, gen_loss = 0.830846125367044, disc_loss = 0.07637961619351616
Trained batch 522 in epoch 5, gen_loss = 0.8316051048256927, disc_loss = 0.076580696728572
Trained batch 523 in epoch 5, gen_loss = 0.8320478683209601, disc_loss = 0.07649151823227472
Trained batch 524 in epoch 5, gen_loss = 0.831990905262175, disc_loss = 0.07639213768676632
Trained batch 525 in epoch 5, gen_loss = 0.831892780251376, disc_loss = 0.07636468927818615
Trained batch 526 in epoch 5, gen_loss = 0.8316849307271968, disc_loss = 0.07630502479415974
Trained batch 527 in epoch 5, gen_loss = 0.8319080984502127, disc_loss = 0.07646496580017617
Trained batch 528 in epoch 5, gen_loss = 0.8317748934650241, disc_loss = 0.07643424093702171
Trained batch 529 in epoch 5, gen_loss = 0.8316870718632104, disc_loss = 0.07636628542622587
Trained batch 530 in epoch 5, gen_loss = 0.8320135425937603, disc_loss = 0.07625048496214964
Trained batch 531 in epoch 5, gen_loss = 0.8321486143465329, disc_loss = 0.07631909017647176
Trained batch 532 in epoch 5, gen_loss = 0.8319030312391428, disc_loss = 0.07637508832246737
Trained batch 533 in epoch 5, gen_loss = 0.8319721735372079, disc_loss = 0.07642447812594334
Trained batch 534 in epoch 5, gen_loss = 0.831702696051553, disc_loss = 0.07640943202216213
Trained batch 535 in epoch 5, gen_loss = 0.8316398100621665, disc_loss = 0.07634514283368003
Trained batch 536 in epoch 5, gen_loss = 0.8316803923088301, disc_loss = 0.07637899652907358
Trained batch 537 in epoch 5, gen_loss = 0.8313598798996454, disc_loss = 0.07641473909161403
Trained batch 538 in epoch 5, gen_loss = 0.8314764993973698, disc_loss = 0.07635678054595535
Trained batch 539 in epoch 5, gen_loss = 0.8314574693088178, disc_loss = 0.07632800152490812
Trained batch 540 in epoch 5, gen_loss = 0.8315700605484122, disc_loss = 0.07637487867822984
Trained batch 541 in epoch 5, gen_loss = 0.8310192805814567, disc_loss = 0.07651310346202712
Trained batch 542 in epoch 5, gen_loss = 0.830910506608517, disc_loss = 0.07641939072257412
Trained batch 543 in epoch 5, gen_loss = 0.8315219857236918, disc_loss = 0.07652398987556808
Trained batch 544 in epoch 5, gen_loss = 0.8309701046812425, disc_loss = 0.07664997949341842
Trained batch 545 in epoch 5, gen_loss = 0.8307771254808475, disc_loss = 0.07669233552422443
Trained batch 546 in epoch 5, gen_loss = 0.830818626954743, disc_loss = 0.07670864887651349
Trained batch 547 in epoch 5, gen_loss = 0.8303112010233593, disc_loss = 0.07692746029330594
Trained batch 548 in epoch 5, gen_loss = 0.8309580816162957, disc_loss = 0.07687723571315869
Trained batch 549 in epoch 5, gen_loss = 0.830884045904333, disc_loss = 0.07709230644967069
Trained batch 550 in epoch 5, gen_loss = 0.8303156285234026, disc_loss = 0.07740378195754576
Trained batch 551 in epoch 5, gen_loss = 0.8301156179412551, disc_loss = 0.07743961331468291
Trained batch 552 in epoch 5, gen_loss = 0.8302823502375032, disc_loss = 0.07758009579086551
Trained batch 553 in epoch 5, gen_loss = 0.830459063987009, disc_loss = 0.07752374942760766
Trained batch 554 in epoch 5, gen_loss = 0.8300692439079285, disc_loss = 0.07758035354886775
Trained batch 555 in epoch 5, gen_loss = 0.8295696989881048, disc_loss = 0.07781909115230598
Trained batch 556 in epoch 5, gen_loss = 0.8294858256191069, disc_loss = 0.07778100710683226
Trained batch 557 in epoch 5, gen_loss = 0.8298582041562672, disc_loss = 0.07786892417077255
Trained batch 558 in epoch 5, gen_loss = 0.8296997250725844, disc_loss = 0.07786091146340897
Trained batch 559 in epoch 5, gen_loss = 0.8292968965002468, disc_loss = 0.07794473708573994
Trained batch 560 in epoch 5, gen_loss = 0.8295136110030393, disc_loss = 0.07791540173916628
Trained batch 561 in epoch 5, gen_loss = 0.8295415524274005, disc_loss = 0.0779821092239664
Trained batch 562 in epoch 5, gen_loss = 0.8293062870921716, disc_loss = 0.07791255747810086
Trained batch 563 in epoch 5, gen_loss = 0.8294503776528311, disc_loss = 0.07780678001404179
Trained batch 564 in epoch 5, gen_loss = 0.8292220929027658, disc_loss = 0.07783046849236816
Trained batch 565 in epoch 5, gen_loss = 0.8297304760651538, disc_loss = 0.07781843325557589
Trained batch 566 in epoch 5, gen_loss = 0.8299177989127144, disc_loss = 0.07776296568945759
Trained batch 567 in epoch 5, gen_loss = 0.8297403176695528, disc_loss = 0.07782457025662641
Trained batch 568 in epoch 5, gen_loss = 0.8299424426207852, disc_loss = 0.07797276669121322
Trained batch 569 in epoch 5, gen_loss = 0.8296506970597987, disc_loss = 0.07796377818541307
Trained batch 570 in epoch 5, gen_loss = 0.829570200418215, disc_loss = 0.07790367746148291
Trained batch 571 in epoch 5, gen_loss = 0.8295285772610378, disc_loss = 0.07789656141987787
Trained batch 572 in epoch 5, gen_loss = 0.8299041008658018, disc_loss = 0.07787391597837418
Trained batch 573 in epoch 5, gen_loss = 0.8302354245651059, disc_loss = 0.07776613705645506
Trained batch 574 in epoch 5, gen_loss = 0.8297150897979736, disc_loss = 0.07797106567446305
Trained batch 575 in epoch 5, gen_loss = 0.829916418219606, disc_loss = 0.07789553088271835
Trained batch 576 in epoch 5, gen_loss = 0.8305800128437617, disc_loss = 0.07787115605422126
Trained batch 577 in epoch 5, gen_loss = 0.8303480967105878, disc_loss = 0.07792988413893279
Trained batch 578 in epoch 5, gen_loss = 0.8303129650356444, disc_loss = 0.07796141545936491
Trained batch 579 in epoch 5, gen_loss = 0.8303235323264682, disc_loss = 0.0779315455415254
Trained batch 580 in epoch 5, gen_loss = 0.8303288588630559, disc_loss = 0.07805866943816567
Trained batch 581 in epoch 5, gen_loss = 0.8297708686889242, disc_loss = 0.07835252370038853
Trained batch 582 in epoch 5, gen_loss = 0.8296467829527617, disc_loss = 0.07828836614109486
Trained batch 583 in epoch 5, gen_loss = 0.8303954690082432, disc_loss = 0.07850621184748789
Trained batch 584 in epoch 5, gen_loss = 0.8304727537000282, disc_loss = 0.07845966632071978
Trained batch 585 in epoch 5, gen_loss = 0.8301381221606869, disc_loss = 0.07847661425362726
Trained batch 586 in epoch 5, gen_loss = 0.8300429451607765, disc_loss = 0.07849804612330369
Trained batch 587 in epoch 5, gen_loss = 0.8295874039129335, disc_loss = 0.07863009046465412
Trained batch 588 in epoch 5, gen_loss = 0.829471343037228, disc_loss = 0.07857867587256563
Trained batch 589 in epoch 5, gen_loss = 0.8291223483570551, disc_loss = 0.07874525199660053
Trained batch 590 in epoch 5, gen_loss = 0.8287087321886556, disc_loss = 0.07879941944701065
Trained batch 591 in epoch 5, gen_loss = 0.8287189115543623, disc_loss = 0.07876192292708249
Trained batch 592 in epoch 5, gen_loss = 0.8289338886034228, disc_loss = 0.07870742740363988
Trained batch 593 in epoch 5, gen_loss = 0.8284411579872222, disc_loss = 0.07879235172920206
Trained batch 594 in epoch 5, gen_loss = 0.8285571471983645, disc_loss = 0.0787072527762346
Trained batch 595 in epoch 5, gen_loss = 0.8283787092706502, disc_loss = 0.07867743235687731
Trained batch 596 in epoch 5, gen_loss = 0.8287215319710162, disc_loss = 0.07864397363128824
Trained batch 597 in epoch 5, gen_loss = 0.8284604068982562, disc_loss = 0.07860843995025375
Trained batch 598 in epoch 5, gen_loss = 0.8283482123296926, disc_loss = 0.07856344676208069
Trained batch 599 in epoch 5, gen_loss = 0.8287237606445949, disc_loss = 0.07857786873510729
Trained batch 600 in epoch 5, gen_loss = 0.8285080480099518, disc_loss = 0.07853685444788062
Trained batch 601 in epoch 5, gen_loss = 0.8281829219521875, disc_loss = 0.07852849974590927
Trained batch 602 in epoch 5, gen_loss = 0.8286892232017138, disc_loss = 0.07848975003216645
Trained batch 603 in epoch 5, gen_loss = 0.8288583040040061, disc_loss = 0.07846207778734333
Trained batch 604 in epoch 5, gen_loss = 0.8283742054434847, disc_loss = 0.07858061687174168
Trained batch 605 in epoch 5, gen_loss = 0.828289257024381, disc_loss = 0.07859552548522063
Trained batch 606 in epoch 5, gen_loss = 0.828136054255817, disc_loss = 0.07854191971332129
Trained batch 607 in epoch 5, gen_loss = 0.8282885249508055, disc_loss = 0.0784789364261087
Trained batch 608 in epoch 5, gen_loss = 0.8279926961865919, disc_loss = 0.07854207233359123
Trained batch 609 in epoch 5, gen_loss = 0.8286370829480594, disc_loss = 0.07858811378875961
Trained batch 610 in epoch 5, gen_loss = 0.8289192742294649, disc_loss = 0.07847765664861167
Trained batch 611 in epoch 5, gen_loss = 0.8290820364274231, disc_loss = 0.0783837154824165
Trained batch 612 in epoch 5, gen_loss = 0.8290210883535725, disc_loss = 0.07829185298736682
Trained batch 613 in epoch 5, gen_loss = 0.8284331359187632, disc_loss = 0.07838414417100457
Trained batch 614 in epoch 5, gen_loss = 0.8285832516546172, disc_loss = 0.07857210713067675
Trained batch 615 in epoch 5, gen_loss = 0.828462194990028, disc_loss = 0.07848895029406752
Trained batch 616 in epoch 5, gen_loss = 0.8281047847514408, disc_loss = 0.07852358640604797
Trained batch 617 in epoch 5, gen_loss = 0.8286495317726074, disc_loss = 0.07863033143652778
Trained batch 618 in epoch 5, gen_loss = 0.8282915988338205, disc_loss = 0.07864698400850346
Trained batch 619 in epoch 5, gen_loss = 0.8283464161619063, disc_loss = 0.07855580041124936
Trained batch 620 in epoch 5, gen_loss = 0.8282093133135502, disc_loss = 0.0785951470947208
Trained batch 621 in epoch 5, gen_loss = 0.8283305681786737, disc_loss = 0.0785309583296059
Trained batch 622 in epoch 5, gen_loss = 0.8284050308490832, disc_loss = 0.07847663728493366
Trained batch 623 in epoch 5, gen_loss = 0.8281843073857136, disc_loss = 0.0784674666953297
Trained batch 624 in epoch 5, gen_loss = 0.8286027179718017, disc_loss = 0.07852426144480705
Trained batch 625 in epoch 5, gen_loss = 0.8286741828194822, disc_loss = 0.07851931723519065
Trained batch 626 in epoch 5, gen_loss = 0.8283247023678282, disc_loss = 0.07856880360694403
Trained batch 627 in epoch 5, gen_loss = 0.8282334504613451, disc_loss = 0.07855534040410618
Trained batch 628 in epoch 5, gen_loss = 0.8281965471792296, disc_loss = 0.07848374602430765
Trained batch 629 in epoch 5, gen_loss = 0.8277892097594246, disc_loss = 0.07855128958111718
Trained batch 630 in epoch 5, gen_loss = 0.8283849346278775, disc_loss = 0.07876463182471256
Trained batch 631 in epoch 5, gen_loss = 0.8283545018374165, disc_loss = 0.07867769405092526
Trained batch 632 in epoch 5, gen_loss = 0.8281818721531692, disc_loss = 0.07871351124774693
Trained batch 633 in epoch 5, gen_loss = 0.8278973433497576, disc_loss = 0.07878835732851777
Trained batch 634 in epoch 5, gen_loss = 0.8278130332316, disc_loss = 0.07887033168666475
Trained batch 635 in epoch 5, gen_loss = 0.8273958048355654, disc_loss = 0.07892561587651477
Trained batch 636 in epoch 5, gen_loss = 0.8275837991825266, disc_loss = 0.07885868317232682
Trained batch 637 in epoch 5, gen_loss = 0.827743683582563, disc_loss = 0.07875902376788724
Trained batch 638 in epoch 5, gen_loss = 0.8278375090754274, disc_loss = 0.07876392888234628
Trained batch 639 in epoch 5, gen_loss = 0.827694278024137, disc_loss = 0.0787719334650319
Trained batch 640 in epoch 5, gen_loss = 0.8275558697452039, disc_loss = 0.0787118772355703
Trained batch 641 in epoch 5, gen_loss = 0.8275001580098708, disc_loss = 0.07863750605846863
Trained batch 642 in epoch 5, gen_loss = 0.8274340148476382, disc_loss = 0.07856174757121881
Trained batch 643 in epoch 5, gen_loss = 0.8278282811367734, disc_loss = 0.0785344169180123
Trained batch 644 in epoch 5, gen_loss = 0.8280017052509988, disc_loss = 0.07849308977755465
Trained batch 645 in epoch 5, gen_loss = 0.8277785017763498, disc_loss = 0.07846270539673858
Trained batch 646 in epoch 5, gen_loss = 0.8272707189621844, disc_loss = 0.07859622682495132
Trained batch 647 in epoch 5, gen_loss = 0.8279192559880975, disc_loss = 0.0786469268647057
Trained batch 648 in epoch 5, gen_loss = 0.828180932851712, disc_loss = 0.07862978405642032
Trained batch 649 in epoch 5, gen_loss = 0.8278658036085276, disc_loss = 0.0786839187832979
Trained batch 650 in epoch 5, gen_loss = 0.8276413651655347, disc_loss = 0.07876329755728145
Trained batch 651 in epoch 5, gen_loss = 0.8277786224166308, disc_loss = 0.07879032597997071
Trained batch 652 in epoch 5, gen_loss = 0.827749983640031, disc_loss = 0.07877550951874092
Trained batch 653 in epoch 5, gen_loss = 0.8280918893464114, disc_loss = 0.07868421645635676
Trained batch 654 in epoch 5, gen_loss = 0.8278300932345499, disc_loss = 0.07872672916482423
Trained batch 655 in epoch 5, gen_loss = 0.8275656074103785, disc_loss = 0.07878023518317538
Trained batch 656 in epoch 5, gen_loss = 0.827661221248737, disc_loss = 0.07886752752159103
Trained batch 657 in epoch 5, gen_loss = 0.8276869127453279, disc_loss = 0.07877453003293837
Trained batch 658 in epoch 5, gen_loss = 0.8273868291258631, disc_loss = 0.0787405532096514
Trained batch 659 in epoch 5, gen_loss = 0.827325066833785, disc_loss = 0.07868886324153705
Trained batch 660 in epoch 5, gen_loss = 0.8273876472608765, disc_loss = 0.0787600804621892
Trained batch 661 in epoch 5, gen_loss = 0.8274493168848158, disc_loss = 0.07874220398640164
Trained batch 662 in epoch 5, gen_loss = 0.8277063936129954, disc_loss = 0.07866246824968905
Trained batch 663 in epoch 5, gen_loss = 0.8274759076625468, disc_loss = 0.07864478250393217
Trained batch 664 in epoch 5, gen_loss = 0.8274387542466471, disc_loss = 0.07859838629295503
Trained batch 665 in epoch 5, gen_loss = 0.8274289031286497, disc_loss = 0.07866471441736719
Trained batch 666 in epoch 5, gen_loss = 0.8273128810851113, disc_loss = 0.0787220371599453
Trained batch 667 in epoch 5, gen_loss = 0.8271285186627668, disc_loss = 0.07874909088762845
Trained batch 668 in epoch 5, gen_loss = 0.8268728108327663, disc_loss = 0.07875135435997015
Trained batch 669 in epoch 5, gen_loss = 0.8271121985876738, disc_loss = 0.07872287417803682
Trained batch 670 in epoch 5, gen_loss = 0.8269161909774234, disc_loss = 0.07866470504346708
Trained batch 671 in epoch 5, gen_loss = 0.8268839033941427, disc_loss = 0.07870526988491681
Trained batch 672 in epoch 5, gen_loss = 0.8267926859820226, disc_loss = 0.07867140563988137
Trained batch 673 in epoch 5, gen_loss = 0.8267535422251557, disc_loss = 0.0786420223759128
Trained batch 674 in epoch 5, gen_loss = 0.8267651806937324, disc_loss = 0.07856174069146316
Trained batch 675 in epoch 5, gen_loss = 0.8266714262891803, disc_loss = 0.0785929343178207
Trained batch 676 in epoch 5, gen_loss = 0.8269246604453162, disc_loss = 0.07852841335097038
Trained batch 677 in epoch 5, gen_loss = 0.8269660593309937, disc_loss = 0.0784606741422617
Trained batch 678 in epoch 5, gen_loss = 0.8268145537867988, disc_loss = 0.07840319318266172
Trained batch 679 in epoch 5, gen_loss = 0.8266013118274071, disc_loss = 0.07839349877801449
Trained batch 680 in epoch 5, gen_loss = 0.8268278643773341, disc_loss = 0.07829673078715275
Trained batch 681 in epoch 5, gen_loss = 0.8268090081005153, disc_loss = 0.0783093121268751
Trained batch 682 in epoch 5, gen_loss = 0.8268116490034547, disc_loss = 0.07831414148898722
Trained batch 683 in epoch 5, gen_loss = 0.8264430875492375, disc_loss = 0.07842700479944285
Trained batch 684 in epoch 5, gen_loss = 0.8264260459990397, disc_loss = 0.07835715658092586
Trained batch 685 in epoch 5, gen_loss = 0.8265352190062186, disc_loss = 0.07860959072817258
Trained batch 686 in epoch 5, gen_loss = 0.8261015402177536, disc_loss = 0.07864839765019552
Trained batch 687 in epoch 5, gen_loss = 0.8265171776157479, disc_loss = 0.07861213875273892
Trained batch 688 in epoch 5, gen_loss = 0.8263847185150113, disc_loss = 0.07859229686547001
Trained batch 689 in epoch 5, gen_loss = 0.8262727052405261, disc_loss = 0.07861086772349865
Trained batch 690 in epoch 5, gen_loss = 0.826161028593563, disc_loss = 0.07854758375277136
Trained batch 691 in epoch 5, gen_loss = 0.8258531411431428, disc_loss = 0.07861973166282725
Trained batch 692 in epoch 5, gen_loss = 0.8261957544441003, disc_loss = 0.0785869165722813
Trained batch 693 in epoch 5, gen_loss = 0.8257970704297167, disc_loss = 0.07867537369355775
Trained batch 694 in epoch 5, gen_loss = 0.8254579304791183, disc_loss = 0.07869590300289418
Trained batch 695 in epoch 5, gen_loss = 0.8252760007463652, disc_loss = 0.07877600184727418
Trained batch 696 in epoch 5, gen_loss = 0.8251789556856306, disc_loss = 0.07872725138373919
Trained batch 697 in epoch 5, gen_loss = 0.8256270547309372, disc_loss = 0.0787640969725299
Trained batch 698 in epoch 5, gen_loss = 0.8258060213492834, disc_loss = 0.07869525283884167
Trained batch 699 in epoch 5, gen_loss = 0.8253625479766301, disc_loss = 0.0787883852874594
Trained batch 700 in epoch 5, gen_loss = 0.8252063602761773, disc_loss = 0.07876106980024238
Trained batch 701 in epoch 5, gen_loss = 0.825344139439428, disc_loss = 0.07883946960818479
Trained batch 702 in epoch 5, gen_loss = 0.8253913354738, disc_loss = 0.07875539779737274
Trained batch 703 in epoch 5, gen_loss = 0.8257480969821865, disc_loss = 0.07867659817037004
Trained batch 704 in epoch 5, gen_loss = 0.8257518255964239, disc_loss = 0.07859059241699412
Trained batch 705 in epoch 5, gen_loss = 0.8254075919940181, disc_loss = 0.07866845057522694
Trained batch 706 in epoch 5, gen_loss = 0.8252872943540948, disc_loss = 0.07875028083198395
Trained batch 707 in epoch 5, gen_loss = 0.8251307473681068, disc_loss = 0.07870436860985086
Trained batch 708 in epoch 5, gen_loss = 0.8251989490558802, disc_loss = 0.07870177950116324
Trained batch 709 in epoch 5, gen_loss = 0.8251808242898592, disc_loss = 0.07863698066802512
Trained batch 710 in epoch 5, gen_loss = 0.8249990993746558, disc_loss = 0.07864112413518455
Trained batch 711 in epoch 5, gen_loss = 0.825223487665814, disc_loss = 0.07866872264480407
Trained batch 712 in epoch 5, gen_loss = 0.8251760690610171, disc_loss = 0.07862049884843375
Trained batch 713 in epoch 5, gen_loss = 0.8249607272341806, disc_loss = 0.07866004752438693
Trained batch 714 in epoch 5, gen_loss = 0.825040343424657, disc_loss = 0.0786999356835247
Trained batch 715 in epoch 5, gen_loss = 0.8250796701655042, disc_loss = 0.07866505441104983
Trained batch 716 in epoch 5, gen_loss = 0.8248285940501481, disc_loss = 0.07866046402338409
Trained batch 717 in epoch 5, gen_loss = 0.8250007679203427, disc_loss = 0.07864258832928613
Trained batch 718 in epoch 5, gen_loss = 0.8250006439788616, disc_loss = 0.07857244497007057
Trained batch 719 in epoch 5, gen_loss = 0.8253414654897319, disc_loss = 0.07863185624074605
Trained batch 720 in epoch 5, gen_loss = 0.825716984999494, disc_loss = 0.0785655314529033
Trained batch 721 in epoch 5, gen_loss = 0.8255516672893904, disc_loss = 0.07855453075185789
Trained batch 722 in epoch 5, gen_loss = 0.8257025379692701, disc_loss = 0.07849373861395059
Trained batch 723 in epoch 5, gen_loss = 0.8256468068993552, disc_loss = 0.07845625975709511
Trained batch 724 in epoch 5, gen_loss = 0.8254384093449033, disc_loss = 0.07848768820793464
Trained batch 725 in epoch 5, gen_loss = 0.8256859024037343, disc_loss = 0.07842310992410771
Trained batch 726 in epoch 5, gen_loss = 0.8256934151524855, disc_loss = 0.07834927226061916
Trained batch 727 in epoch 5, gen_loss = 0.8257713165584502, disc_loss = 0.07830411559840726
Trained batch 728 in epoch 5, gen_loss = 0.8254444649844176, disc_loss = 0.07834541421276306
Trained batch 729 in epoch 5, gen_loss = 0.8252762468710337, disc_loss = 0.07836285360820898
Trained batch 730 in epoch 5, gen_loss = 0.8257128080982516, disc_loss = 0.07833760780334555
Trained batch 731 in epoch 5, gen_loss = 0.8256251578285394, disc_loss = 0.07828369545572199
Trained batch 732 in epoch 5, gen_loss = 0.8258199869854551, disc_loss = 0.07820914139130024
Trained batch 733 in epoch 5, gen_loss = 0.8258741783835908, disc_loss = 0.07817509781305325
Trained batch 734 in epoch 5, gen_loss = 0.8259595729866807, disc_loss = 0.07810517204608641
Trained batch 735 in epoch 5, gen_loss = 0.8258676870685556, disc_loss = 0.07808009485218106
Trained batch 736 in epoch 5, gen_loss = 0.8255154361880133, disc_loss = 0.07811928696910189
Trained batch 737 in epoch 5, gen_loss = 0.826414310512181, disc_loss = 0.07844008278949716
Trained batch 738 in epoch 5, gen_loss = 0.8266227144511046, disc_loss = 0.07837633333132377
Trained batch 739 in epoch 5, gen_loss = 0.8263398018237706, disc_loss = 0.07850149801705737
Trained batch 740 in epoch 5, gen_loss = 0.8260597046892009, disc_loss = 0.07851159222946878
Trained batch 741 in epoch 5, gen_loss = 0.8263477501522177, disc_loss = 0.0787644156171988
Trained batch 742 in epoch 5, gen_loss = 0.8259102973289798, disc_loss = 0.07907012751022627
Trained batch 743 in epoch 5, gen_loss = 0.8260271722270597, disc_loss = 0.07906096405850382
Trained batch 744 in epoch 5, gen_loss = 0.8262764981929088, disc_loss = 0.07930126883489573
Trained batch 745 in epoch 5, gen_loss = 0.8260298225898844, disc_loss = 0.07935647851470408
Trained batch 746 in epoch 5, gen_loss = 0.8259792373362316, disc_loss = 0.0793108740070937
Trained batch 747 in epoch 5, gen_loss = 0.8262713294137608, disc_loss = 0.07938782480560283
Trained batch 748 in epoch 5, gen_loss = 0.8260201948666286, disc_loss = 0.0794730090594618
Trained batch 749 in epoch 5, gen_loss = 0.8258087911605835, disc_loss = 0.07952626218646765
Trained batch 750 in epoch 5, gen_loss = 0.8257980037941913, disc_loss = 0.0796850159213681
Trained batch 751 in epoch 5, gen_loss = 0.8257574010244075, disc_loss = 0.07978062044601253
Trained batch 752 in epoch 5, gen_loss = 0.8254859573337662, disc_loss = 0.07980831949210974
Trained batch 753 in epoch 5, gen_loss = 0.8252231952208107, disc_loss = 0.07983001863302303
Trained batch 754 in epoch 5, gen_loss = 0.8252362784170947, disc_loss = 0.07989764569068192
Trained batch 755 in epoch 5, gen_loss = 0.8249644436060436, disc_loss = 0.07995191414806026
Trained batch 756 in epoch 5, gen_loss = 0.825236206876712, disc_loss = 0.07995934331915101
Trained batch 757 in epoch 5, gen_loss = 0.8249411324240602, disc_loss = 0.07999217658890977
Trained batch 758 in epoch 5, gen_loss = 0.8249030096728811, disc_loss = 0.08004061945705467
Trained batch 759 in epoch 5, gen_loss = 0.8245926856210357, disc_loss = 0.0800229301112459
Trained batch 760 in epoch 5, gen_loss = 0.8247208943818152, disc_loss = 0.0800787803891963
Trained batch 761 in epoch 5, gen_loss = 0.8244705927653575, disc_loss = 0.0801468332691651
Trained batch 762 in epoch 5, gen_loss = 0.8243190536024061, disc_loss = 0.08019473267228466
Trained batch 763 in epoch 5, gen_loss = 0.8240836588812124, disc_loss = 0.08022325430601757
Trained batch 764 in epoch 5, gen_loss = 0.8244100765465132, disc_loss = 0.0802230969777489
Trained batch 765 in epoch 5, gen_loss = 0.8243541633491417, disc_loss = 0.08018861986531368
Trained batch 766 in epoch 5, gen_loss = 0.8241469791690871, disc_loss = 0.08021038911770421
Trained batch 767 in epoch 5, gen_loss = 0.8242225283756852, disc_loss = 0.08020101593623015
Trained batch 768 in epoch 5, gen_loss = 0.8240878483563933, disc_loss = 0.0801562947597747
Trained batch 769 in epoch 5, gen_loss = 0.8241270475573353, disc_loss = 0.08032208384292853
Trained batch 770 in epoch 5, gen_loss = 0.823799793744984, disc_loss = 0.08034326463947424
Trained batch 771 in epoch 5, gen_loss = 0.8235930861432318, disc_loss = 0.08027894182343016
Trained batch 772 in epoch 5, gen_loss = 0.82335441410156, disc_loss = 0.08025688029594363
Trained batch 773 in epoch 5, gen_loss = 0.8237031223083959, disc_loss = 0.08024099203745909
Trained batch 774 in epoch 5, gen_loss = 0.8238926819063002, disc_loss = 0.08015747929051999
Trained batch 775 in epoch 5, gen_loss = 0.8238584393078519, disc_loss = 0.0802379377191099
Trained batch 776 in epoch 5, gen_loss = 0.8234935695140058, disc_loss = 0.08027194463617937
Trained batch 777 in epoch 5, gen_loss = 0.8233522288597028, disc_loss = 0.08025401172043808
Trained batch 778 in epoch 5, gen_loss = 0.8231841062550673, disc_loss = 0.08026777124881208
Trained batch 779 in epoch 5, gen_loss = 0.8235772871054136, disc_loss = 0.08041048799999631
Trained batch 780 in epoch 5, gen_loss = 0.8237748632205127, disc_loss = 0.0803378384116746
Trained batch 781 in epoch 5, gen_loss = 0.8237847230775887, disc_loss = 0.08027588396006838
Trained batch 782 in epoch 5, gen_loss = 0.8235894083063264, disc_loss = 0.08038546271517512
Trained batch 783 in epoch 5, gen_loss = 0.8237071684276571, disc_loss = 0.08038957434117186
Trained batch 784 in epoch 5, gen_loss = 0.8237001845031787, disc_loss = 0.08048906749600818
Trained batch 785 in epoch 5, gen_loss = 0.8236919542912006, disc_loss = 0.08046911672971024
Trained batch 786 in epoch 5, gen_loss = 0.8237767256654354, disc_loss = 0.08047079582718761
Trained batch 787 in epoch 5, gen_loss = 0.8236765509783314, disc_loss = 0.0804859990168949
Trained batch 788 in epoch 5, gen_loss = 0.8234762948275519, disc_loss = 0.08054330100804681
Trained batch 789 in epoch 5, gen_loss = 0.8236257052874263, disc_loss = 0.08048841217650643
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.8732422590255737, disc_loss = 0.04698042944073677
Trained batch 1 in epoch 6, gen_loss = 0.8648838698863983, disc_loss = 0.04235953651368618
Trained batch 2 in epoch 6, gen_loss = 0.8458148241043091, disc_loss = 0.06024844820300738
Trained batch 3 in epoch 6, gen_loss = 0.8227917850017548, disc_loss = 0.0614918963983655
Trained batch 4 in epoch 6, gen_loss = 0.832784914970398, disc_loss = 0.09190752282738686
Trained batch 5 in epoch 6, gen_loss = 0.7967930138111115, disc_loss = 0.0906650231530269
Trained batch 6 in epoch 6, gen_loss = 0.7925930108342852, disc_loss = 0.08171168767980166
Trained batch 7 in epoch 6, gen_loss = 0.7925684079527855, disc_loss = 0.08293262077495456
Trained batch 8 in epoch 6, gen_loss = 0.7704976863331265, disc_loss = 0.08128250100546414
Trained batch 9 in epoch 6, gen_loss = 0.7852792799472809, disc_loss = 0.08383229784667492
Trained batch 10 in epoch 6, gen_loss = 0.7827766808596525, disc_loss = 0.08069541813297705
Trained batch 11 in epoch 6, gen_loss = 0.7645625422398249, disc_loss = 0.08290844752142827
Trained batch 12 in epoch 6, gen_loss = 0.7573093680235056, disc_loss = 0.08475838458308807
Trained batch 13 in epoch 6, gen_loss = 0.7743300242083413, disc_loss = 0.08562411181628704
Trained batch 14 in epoch 6, gen_loss = 0.8089044292767843, disc_loss = 0.09032943869630496
Trained batch 15 in epoch 6, gen_loss = 0.7997805438935757, disc_loss = 0.09049613052047789
Trained batch 16 in epoch 6, gen_loss = 0.7883687019348145, disc_loss = 0.0910708704853759
Trained batch 17 in epoch 6, gen_loss = 0.7808462911181979, disc_loss = 0.09435281095405419
Trained batch 18 in epoch 6, gen_loss = 0.777235326014067, disc_loss = 0.09288524895122177
Trained batch 19 in epoch 6, gen_loss = 0.7679589748382568, disc_loss = 0.09145492408424616
Trained batch 20 in epoch 6, gen_loss = 0.7738229632377625, disc_loss = 0.0917263887822628
Trained batch 21 in epoch 6, gen_loss = 0.7740557925267653, disc_loss = 0.09094121865928173
Trained batch 22 in epoch 6, gen_loss = 0.7706221912218176, disc_loss = 0.08932427689433098
Trained batch 23 in epoch 6, gen_loss = 0.769065702954928, disc_loss = 0.0888238640812536
Trained batch 24 in epoch 6, gen_loss = 0.7666570711135864, disc_loss = 0.08731158271431923
Trained batch 25 in epoch 6, gen_loss = 0.7729996626193707, disc_loss = 0.08485190713634858
Trained batch 26 in epoch 6, gen_loss = 0.7808326659379182, disc_loss = 0.08905455000974515
Trained batch 27 in epoch 6, gen_loss = 0.77698700768607, disc_loss = 0.08861922046967916
Trained batch 28 in epoch 6, gen_loss = 0.7747671830243078, disc_loss = 0.08933865176192646
Trained batch 29 in epoch 6, gen_loss = 0.7754613121350606, disc_loss = 0.08848505516846975
Trained batch 30 in epoch 6, gen_loss = 0.7847319379929574, disc_loss = 0.09145618638684673
Trained batch 31 in epoch 6, gen_loss = 0.7754668304696679, disc_loss = 0.09506362769752741
Trained batch 32 in epoch 6, gen_loss = 0.7752450171745184, disc_loss = 0.09301077986531185
Trained batch 33 in epoch 6, gen_loss = 0.7728960207279991, disc_loss = 0.09213989299228963
Trained batch 34 in epoch 6, gen_loss = 0.7908323330538614, disc_loss = 0.09335791878402233
Trained batch 35 in epoch 6, gen_loss = 0.8015698633260198, disc_loss = 0.09426528613807426
Trained batch 36 in epoch 6, gen_loss = 0.7915674415794579, disc_loss = 0.09749856374755099
Trained batch 37 in epoch 6, gen_loss = 0.7881543761805484, disc_loss = 0.09728757806710507
Trained batch 38 in epoch 6, gen_loss = 0.7890100723657852, disc_loss = 0.09704461068106003
Trained batch 39 in epoch 6, gen_loss = 0.7961414992809296, disc_loss = 0.09806303740479053
Trained batch 40 in epoch 6, gen_loss = 0.7927774161827273, disc_loss = 0.09922992406276668
Trained batch 41 in epoch 6, gen_loss = 0.79509256425358, disc_loss = 0.09785759009953056
Trained batch 42 in epoch 6, gen_loss = 0.7973740724630134, disc_loss = 0.09766888865378014
Trained batch 43 in epoch 6, gen_loss = 0.7931181422688744, disc_loss = 0.09795607393607497
Trained batch 44 in epoch 6, gen_loss = 0.7931661460134718, disc_loss = 0.09652535414530171
Trained batch 45 in epoch 6, gen_loss = 0.7921783781569937, disc_loss = 0.09564114536118248
Trained batch 46 in epoch 6, gen_loss = 0.7896357888871051, disc_loss = 0.09563281668468993
Trained batch 47 in epoch 6, gen_loss = 0.7881305478513241, disc_loss = 0.09439544624183327
Trained batch 48 in epoch 6, gen_loss = 0.7862392578806195, disc_loss = 0.09324395629976477
Trained batch 49 in epoch 6, gen_loss = 0.7805477154254913, disc_loss = 0.09368108335882425
Trained batch 50 in epoch 6, gen_loss = 0.7773094317492317, disc_loss = 0.09391270011809527
Trained batch 51 in epoch 6, gen_loss = 0.7858185584728534, disc_loss = 0.09550965251401067
Trained batch 52 in epoch 6, gen_loss = 0.7873950814301113, disc_loss = 0.0947820995846447
Trained batch 53 in epoch 6, gen_loss = 0.7860027198438291, disc_loss = 0.09392056134701879
Trained batch 54 in epoch 6, gen_loss = 0.790031081979925, disc_loss = 0.09256689409640702
Trained batch 55 in epoch 6, gen_loss = 0.7917851454445294, disc_loss = 0.09247286042331584
Trained batch 56 in epoch 6, gen_loss = 0.7922012565428751, disc_loss = 0.09159186041276705
Trained batch 57 in epoch 6, gen_loss = 0.7906327864219402, disc_loss = 0.09115063183908832
Trained batch 58 in epoch 6, gen_loss = 0.7932383791875031, disc_loss = 0.09080235650605065
Trained batch 59 in epoch 6, gen_loss = 0.7991498629252116, disc_loss = 0.0896829064314564
Trained batch 60 in epoch 6, gen_loss = 0.7987706368086768, disc_loss = 0.08926485546055388
Trained batch 61 in epoch 6, gen_loss = 0.7985913724668564, disc_loss = 0.08849638604348706
Trained batch 62 in epoch 6, gen_loss = 0.7980802920129564, disc_loss = 0.0877993953606439
Trained batch 63 in epoch 6, gen_loss = 0.8012174824252725, disc_loss = 0.08712446299614385
Trained batch 64 in epoch 6, gen_loss = 0.8082465125964238, disc_loss = 0.08635002546585523
Trained batch 65 in epoch 6, gen_loss = 0.8085805891138135, disc_loss = 0.08570545945655215
Trained batch 66 in epoch 6, gen_loss = 0.80908648558517, disc_loss = 0.0847430602272055
Trained batch 67 in epoch 6, gen_loss = 0.8147507546579137, disc_loss = 0.08375134645029902
Trained batch 68 in epoch 6, gen_loss = 0.8154681730961454, disc_loss = 0.08279271915123082
Trained batch 69 in epoch 6, gen_loss = 0.8170450193541391, disc_loss = 0.08265996963850089
Trained batch 70 in epoch 6, gen_loss = 0.8181630641641752, disc_loss = 0.0819935502195862
Trained batch 71 in epoch 6, gen_loss = 0.8138126714362038, disc_loss = 0.08376568405785495
Trained batch 72 in epoch 6, gen_loss = 0.8162408781378236, disc_loss = 0.08341743511288133
Trained batch 73 in epoch 6, gen_loss = 0.8142580301375002, disc_loss = 0.08481434843427427
Trained batch 74 in epoch 6, gen_loss = 0.8132616146405538, disc_loss = 0.08540504842996598
Trained batch 75 in epoch 6, gen_loss = 0.8110803342179248, disc_loss = 0.08697390585745636
Trained batch 76 in epoch 6, gen_loss = 0.8147743437197301, disc_loss = 0.08906774967908859
Trained batch 77 in epoch 6, gen_loss = 0.818050613005956, disc_loss = 0.0904876630848799
Trained batch 78 in epoch 6, gen_loss = 0.8166925145100944, disc_loss = 0.09168120945179009
Trained batch 79 in epoch 6, gen_loss = 0.8160146839916707, disc_loss = 0.09127717348746955
Trained batch 80 in epoch 6, gen_loss = 0.8202108946847327, disc_loss = 0.09139894551517051
Trained batch 81 in epoch 6, gen_loss = 0.8177584504208913, disc_loss = 0.09236396681063058
Trained batch 82 in epoch 6, gen_loss = 0.8204062265085886, disc_loss = 0.09307022872998054
Trained batch 83 in epoch 6, gen_loss = 0.8189418833880198, disc_loss = 0.09325493841121595
Trained batch 84 in epoch 6, gen_loss = 0.8158795595169067, disc_loss = 0.09507085720405858
Trained batch 85 in epoch 6, gen_loss = 0.8185281545616859, disc_loss = 0.09466369766308817
Trained batch 86 in epoch 6, gen_loss = 0.8203927566265238, disc_loss = 0.09469194320597868
Trained batch 87 in epoch 6, gen_loss = 0.8230762075294148, disc_loss = 0.09376595528076657
Trained batch 88 in epoch 6, gen_loss = 0.8207067144051027, disc_loss = 0.09459354120484564
Trained batch 89 in epoch 6, gen_loss = 0.8236392550998264, disc_loss = 0.09478767591839035
Trained batch 90 in epoch 6, gen_loss = 0.8217262723943689, disc_loss = 0.09423348028212786
Trained batch 91 in epoch 6, gen_loss = 0.8197168992913287, disc_loss = 0.09378016577102244
Trained batch 92 in epoch 6, gen_loss = 0.8190090681916924, disc_loss = 0.09373621401246837
Trained batch 93 in epoch 6, gen_loss = 0.8177518806558974, disc_loss = 0.09367077590580633
Trained batch 94 in epoch 6, gen_loss = 0.8145331608621698, disc_loss = 0.09434104811792311
Trained batch 95 in epoch 6, gen_loss = 0.8170327320694923, disc_loss = 0.09534675487278339
Trained batch 96 in epoch 6, gen_loss = 0.8172794101164513, disc_loss = 0.094841396100051
Trained batch 97 in epoch 6, gen_loss = 0.8152077781910799, disc_loss = 0.09511695044799423
Trained batch 98 in epoch 6, gen_loss = 0.814302080809468, disc_loss = 0.09523803690881139
Trained batch 99 in epoch 6, gen_loss = 0.8163251626491547, disc_loss = 0.09520778927020729
Trained batch 100 in epoch 6, gen_loss = 0.8125989265961222, disc_loss = 0.09668830261187683
Trained batch 101 in epoch 6, gen_loss = 0.8153240698225358, disc_loss = 0.09647064863284137
Trained batch 102 in epoch 6, gen_loss = 0.8147094301807071, disc_loss = 0.09599244770892326
Trained batch 103 in epoch 6, gen_loss = 0.8166147052095487, disc_loss = 0.0952470924329156
Trained batch 104 in epoch 6, gen_loss = 0.8169491268339611, disc_loss = 0.09473874436780101
Trained batch 105 in epoch 6, gen_loss = 0.8148689118196379, disc_loss = 0.09467243448005251
Trained batch 106 in epoch 6, gen_loss = 0.8145636960724804, disc_loss = 0.09443552502230784
Trained batch 107 in epoch 6, gen_loss = 0.8151546324844714, disc_loss = 0.09457767626305146
Trained batch 108 in epoch 6, gen_loss = 0.8132420647034951, disc_loss = 0.09442165749438039
Trained batch 109 in epoch 6, gen_loss = 0.8122529035264795, disc_loss = 0.0940522276119075
Trained batch 110 in epoch 6, gen_loss = 0.8148835655805227, disc_loss = 0.09393273121970999
Trained batch 111 in epoch 6, gen_loss = 0.8192389612751347, disc_loss = 0.09383293815855202
Trained batch 112 in epoch 6, gen_loss = 0.8183006369962101, disc_loss = 0.09362663561890347
Trained batch 113 in epoch 6, gen_loss = 0.816266128368545, disc_loss = 0.09467784324334118
Trained batch 114 in epoch 6, gen_loss = 0.8158311449963114, disc_loss = 0.09430634278156187
Trained batch 115 in epoch 6, gen_loss = 0.8159059337500868, disc_loss = 0.09409930809914809
Trained batch 116 in epoch 6, gen_loss = 0.8156452382731642, disc_loss = 0.09400989022105932
Trained batch 117 in epoch 6, gen_loss = 0.8142668109829143, disc_loss = 0.09381066561850199
Trained batch 118 in epoch 6, gen_loss = 0.8150602113299009, disc_loss = 0.09345863182723772
Trained batch 119 in epoch 6, gen_loss = 0.8146873945991199, disc_loss = 0.09292217518668622
Trained batch 120 in epoch 6, gen_loss = 0.8131458527785688, disc_loss = 0.09279226740314202
Trained batch 121 in epoch 6, gen_loss = 0.8174303657695895, disc_loss = 0.09341747082433983
Trained batch 122 in epoch 6, gen_loss = 0.8177221325354848, disc_loss = 0.09307796318023427
Trained batch 123 in epoch 6, gen_loss = 0.8156052510584554, disc_loss = 0.0934609083173376
Trained batch 124 in epoch 6, gen_loss = 0.8143751840591431, disc_loss = 0.09338436887413264
Trained batch 125 in epoch 6, gen_loss = 0.8148350706176152, disc_loss = 0.09335351863225537
Trained batch 126 in epoch 6, gen_loss = 0.8170668496860294, disc_loss = 0.0928627262478621
Trained batch 127 in epoch 6, gen_loss = 0.8176953326910734, disc_loss = 0.09237640341598308
Trained batch 128 in epoch 6, gen_loss = 0.8155723958052405, disc_loss = 0.0927131339084617
Trained batch 129 in epoch 6, gen_loss = 0.813801188652332, disc_loss = 0.09290071338271866
Trained batch 130 in epoch 6, gen_loss = 0.8161850330483822, disc_loss = 0.09338018425406162
Trained batch 131 in epoch 6, gen_loss = 0.8146826787428423, disc_loss = 0.09317737503795687
Trained batch 132 in epoch 6, gen_loss = 0.8138362330601627, disc_loss = 0.09281438495963812
Trained batch 133 in epoch 6, gen_loss = 0.8147076928793494, disc_loss = 0.09387462349163729
Trained batch 134 in epoch 6, gen_loss = 0.8142508855572453, disc_loss = 0.09366386970850053
Trained batch 135 in epoch 6, gen_loss = 0.8130502266918912, disc_loss = 0.0937114867641974
Trained batch 136 in epoch 6, gen_loss = 0.8150234627027582, disc_loss = 0.09339140830765458
Trained batch 137 in epoch 6, gen_loss = 0.8154613716878752, disc_loss = 0.09347388603846016
Trained batch 138 in epoch 6, gen_loss = 0.8148229546684156, disc_loss = 0.092914192173496
Trained batch 139 in epoch 6, gen_loss = 0.8133895367383956, disc_loss = 0.0930738817567804
Trained batch 140 in epoch 6, gen_loss = 0.8145882715570166, disc_loss = 0.09312832690379087
Trained batch 141 in epoch 6, gen_loss = 0.8139878179825527, disc_loss = 0.09302286286248078
Trained batch 142 in epoch 6, gen_loss = 0.8119314171217539, disc_loss = 0.09373169686072148
Trained batch 143 in epoch 6, gen_loss = 0.8131067715585232, disc_loss = 0.0934099356786141
Trained batch 144 in epoch 6, gen_loss = 0.8134625570527438, disc_loss = 0.09308946070357643
Trained batch 145 in epoch 6, gen_loss = 0.8129529307966363, disc_loss = 0.09280569149079183
Trained batch 146 in epoch 6, gen_loss = 0.8119763289990068, disc_loss = 0.09260345601989907
Trained batch 147 in epoch 6, gen_loss = 0.8136302957663665, disc_loss = 0.09262266067309759
Trained batch 148 in epoch 6, gen_loss = 0.8128421770646268, disc_loss = 0.09271218514557453
Trained batch 149 in epoch 6, gen_loss = 0.811101279258728, disc_loss = 0.09270927202577392
Trained batch 150 in epoch 6, gen_loss = 0.8110523330454795, disc_loss = 0.0922626219874877
Trained batch 151 in epoch 6, gen_loss = 0.8117827890734923, disc_loss = 0.09207807701252597
Trained batch 152 in epoch 6, gen_loss = 0.8110161147086449, disc_loss = 0.09190010629423888
Trained batch 153 in epoch 6, gen_loss = 0.8113664706031998, disc_loss = 0.09192309837619012
Trained batch 154 in epoch 6, gen_loss = 0.8119562983512878, disc_loss = 0.09154118488753034
Trained batch 155 in epoch 6, gen_loss = 0.8135230560333301, disc_loss = 0.0921368355062814
Trained batch 156 in epoch 6, gen_loss = 0.8117312508024228, disc_loss = 0.09266737015075555
Trained batch 157 in epoch 6, gen_loss = 0.8103317433520209, disc_loss = 0.09267489396955204
Trained batch 158 in epoch 6, gen_loss = 0.8147553134264436, disc_loss = 0.09778975982968725
Trained batch 159 in epoch 6, gen_loss = 0.8128512505441904, disc_loss = 0.0989014241087716
Trained batch 160 in epoch 6, gen_loss = 0.8114757497118127, disc_loss = 0.099153308689548
Trained batch 161 in epoch 6, gen_loss = 0.812543773724709, disc_loss = 0.10010860098617864
Trained batch 162 in epoch 6, gen_loss = 0.8114570978960377, disc_loss = 0.10063305252054534
Trained batch 163 in epoch 6, gen_loss = 0.8101184004690589, disc_loss = 0.10140680723323874
Trained batch 164 in epoch 6, gen_loss = 0.8108113729592525, disc_loss = 0.10235711861627572
Trained batch 165 in epoch 6, gen_loss = 0.8100963026644236, disc_loss = 0.10266467804897082
Trained batch 166 in epoch 6, gen_loss = 0.808591841223711, disc_loss = 0.10295989281291555
Trained batch 167 in epoch 6, gen_loss = 0.8079035885277248, disc_loss = 0.10262203169432246
Trained batch 168 in epoch 6, gen_loss = 0.8093704570679975, disc_loss = 0.10319776892022797
Trained batch 169 in epoch 6, gen_loss = 0.8080999037798713, disc_loss = 0.10336125490310437
Trained batch 170 in epoch 6, gen_loss = 0.8073016718814248, disc_loss = 0.10308306208370548
Trained batch 171 in epoch 6, gen_loss = 0.8075163995110711, disc_loss = 0.10301818990495143
Trained batch 172 in epoch 6, gen_loss = 0.8058392057529075, disc_loss = 0.10326861385040717
Trained batch 173 in epoch 6, gen_loss = 0.8064890476478928, disc_loss = 0.1036576034940094
Trained batch 174 in epoch 6, gen_loss = 0.8062798936026437, disc_loss = 0.10375827646149056
Trained batch 175 in epoch 6, gen_loss = 0.8046139607375319, disc_loss = 0.10451989503979514
Trained batch 176 in epoch 6, gen_loss = 0.804626366849673, disc_loss = 0.10412498184158808
Trained batch 177 in epoch 6, gen_loss = 0.805372374781062, disc_loss = 0.10424550818907244
Trained batch 178 in epoch 6, gen_loss = 0.8040389764908306, disc_loss = 0.10445035464915983
Trained batch 179 in epoch 6, gen_loss = 0.8038009746207131, disc_loss = 0.1043090989968429
Trained batch 180 in epoch 6, gen_loss = 0.8039397580847556, disc_loss = 0.104080930100085
Trained batch 181 in epoch 6, gen_loss = 0.8040338080007952, disc_loss = 0.10380991846630043
Trained batch 182 in epoch 6, gen_loss = 0.8035032801289376, disc_loss = 0.10350381743285011
Trained batch 183 in epoch 6, gen_loss = 0.8035037873879723, disc_loss = 0.10313405393643062
Trained batch 184 in epoch 6, gen_loss = 0.8038807849626284, disc_loss = 0.10309553965422753
Trained batch 185 in epoch 6, gen_loss = 0.8042781583724483, disc_loss = 0.10288002471669867
Trained batch 186 in epoch 6, gen_loss = 0.8022454431987701, disc_loss = 0.10348793236229988
Trained batch 187 in epoch 6, gen_loss = 0.8031075492184213, disc_loss = 0.10329722499653221
Trained batch 188 in epoch 6, gen_loss = 0.8037845467133496, disc_loss = 0.10311110622727523
Trained batch 189 in epoch 6, gen_loss = 0.8027917005513844, disc_loss = 0.10321449991805773
Trained batch 190 in epoch 6, gen_loss = 0.8029564372532031, disc_loss = 0.10299880653912329
Trained batch 191 in epoch 6, gen_loss = 0.8026716941967607, disc_loss = 0.10283700449993678
Trained batch 192 in epoch 6, gen_loss = 0.8045350137152203, disc_loss = 0.10317214207308743
Trained batch 193 in epoch 6, gen_loss = 0.8036046787021086, disc_loss = 0.10359529209486448
Trained batch 194 in epoch 6, gen_loss = 0.805225573747586, disc_loss = 0.10329166247198979
Trained batch 195 in epoch 6, gen_loss = 0.8048029353423994, disc_loss = 0.10319114052120368
Trained batch 196 in epoch 6, gen_loss = 0.8045722436783883, disc_loss = 0.10287901486369408
Trained batch 197 in epoch 6, gen_loss = 0.8034884306517515, disc_loss = 0.10283625290983102
Trained batch 198 in epoch 6, gen_loss = 0.8025954485538617, disc_loss = 0.10275606357553346
Trained batch 199 in epoch 6, gen_loss = 0.8025871166586875, disc_loss = 0.10322157192509622
Trained batch 200 in epoch 6, gen_loss = 0.8016594612776343, disc_loss = 0.10312048426889513
Trained batch 201 in epoch 6, gen_loss = 0.8017148021424171, disc_loss = 0.10311879715098456
Trained batch 202 in epoch 6, gen_loss = 0.801367252037443, disc_loss = 0.10299146905302854
Trained batch 203 in epoch 6, gen_loss = 0.8007160258643767, disc_loss = 0.10294546672216087
Trained batch 204 in epoch 6, gen_loss = 0.799853355419345, disc_loss = 0.10301919204705372
Trained batch 205 in epoch 6, gen_loss = 0.7998998850873373, disc_loss = 0.10262539899157523
Trained batch 206 in epoch 6, gen_loss = 0.7998407736492618, disc_loss = 0.10259898139640761
Trained batch 207 in epoch 6, gen_loss = 0.7998469451872202, disc_loss = 0.10235258270180426
Trained batch 208 in epoch 6, gen_loss = 0.7997128281867105, disc_loss = 0.10195482386338511
Trained batch 209 in epoch 6, gen_loss = 0.7990610766978491, disc_loss = 0.1016852276621475
Trained batch 210 in epoch 6, gen_loss = 0.7990121544819873, disc_loss = 0.10209998417363206
Trained batch 211 in epoch 6, gen_loss = 0.7995080554260398, disc_loss = 0.10187057073157772
Trained batch 212 in epoch 6, gen_loss = 0.7985956551323474, disc_loss = 0.10159562903723107
Trained batch 213 in epoch 6, gen_loss = 0.7979953068996144, disc_loss = 0.10147771595707425
Trained batch 214 in epoch 6, gen_loss = 0.798845076838205, disc_loss = 0.1014905426867826
Trained batch 215 in epoch 6, gen_loss = 0.7996576707120295, disc_loss = 0.10117948506700082
Trained batch 216 in epoch 6, gen_loss = 0.7984068715077941, disc_loss = 0.10135770059933173
Trained batch 217 in epoch 6, gen_loss = 0.7987838390223477, disc_loss = 0.10141905779531653
Trained batch 218 in epoch 6, gen_loss = 0.8006710959896105, disc_loss = 0.10111990655649063
Trained batch 219 in epoch 6, gen_loss = 0.8010521929372441, disc_loss = 0.10079398834654553
Trained batch 220 in epoch 6, gen_loss = 0.8003103746547958, disc_loss = 0.10094835034811793
Trained batch 221 in epoch 6, gen_loss = 0.8014116800046182, disc_loss = 0.10057661061066094
Trained batch 222 in epoch 6, gen_loss = 0.8013819688638764, disc_loss = 0.10052339588563405
Trained batch 223 in epoch 6, gen_loss = 0.8020567449608019, disc_loss = 0.10048564090642945
Trained batch 224 in epoch 6, gen_loss = 0.8025661855273777, disc_loss = 0.10050805800076988
Trained batch 225 in epoch 6, gen_loss = 0.8015998752243751, disc_loss = 0.10038246276615335
Trained batch 226 in epoch 6, gen_loss = 0.8017551208382662, disc_loss = 0.10002888116722984
Trained batch 227 in epoch 6, gen_loss = 0.801189895261798, disc_loss = 0.09990259898385327
Trained batch 228 in epoch 6, gen_loss = 0.8009331624580783, disc_loss = 0.09977298120532885
Trained batch 229 in epoch 6, gen_loss = 0.8027597207090129, disc_loss = 0.09969327246932232
Trained batch 230 in epoch 6, gen_loss = 0.8014860455091898, disc_loss = 0.09993524711933874
Trained batch 231 in epoch 6, gen_loss = 0.8014107035665676, disc_loss = 0.09967429460235068
Trained batch 232 in epoch 6, gen_loss = 0.8016625003241674, disc_loss = 0.09972425626566865
Trained batch 233 in epoch 6, gen_loss = 0.8011089614313892, disc_loss = 0.0995332742563616
Trained batch 234 in epoch 6, gen_loss = 0.8006249983259972, disc_loss = 0.09965128746042226
Trained batch 235 in epoch 6, gen_loss = 0.8017626745721042, disc_loss = 0.0992873024661094
Trained batch 236 in epoch 6, gen_loss = 0.8024962861326677, disc_loss = 0.09890930149075478
Trained batch 237 in epoch 6, gen_loss = 0.8025057919386054, disc_loss = 0.09871692093433578
Trained batch 238 in epoch 6, gen_loss = 0.8031501014362319, disc_loss = 0.09842152082630157
Trained batch 239 in epoch 6, gen_loss = 0.8035111752649148, disc_loss = 0.09819222460112845
Trained batch 240 in epoch 6, gen_loss = 0.8028260884937903, disc_loss = 0.09819111819630218
Trained batch 241 in epoch 6, gen_loss = 0.8034022051440782, disc_loss = 0.09789813458072869
Trained batch 242 in epoch 6, gen_loss = 0.8049233793721768, disc_loss = 0.09769114141003708
Trained batch 243 in epoch 6, gen_loss = 0.8051536808736989, disc_loss = 0.09781454308492848
Trained batch 244 in epoch 6, gen_loss = 0.8041318669611094, disc_loss = 0.09823330197179196
Trained batch 245 in epoch 6, gen_loss = 0.8046307374791402, disc_loss = 0.09805173922436146
Trained batch 246 in epoch 6, gen_loss = 0.8061063120722288, disc_loss = 0.09779379975714302
Trained batch 247 in epoch 6, gen_loss = 0.8068023364870779, disc_loss = 0.09746013024085833
Trained batch 248 in epoch 6, gen_loss = 0.8072781337791657, disc_loss = 0.09744793497938588
Trained batch 249 in epoch 6, gen_loss = 0.8065518219470977, disc_loss = 0.09762701485678553
Trained batch 250 in epoch 6, gen_loss = 0.8079026469671394, disc_loss = 0.0973659192890938
Trained batch 251 in epoch 6, gen_loss = 0.8085919900072945, disc_loss = 0.09705022772374962
Trained batch 252 in epoch 6, gen_loss = 0.8095985615677513, disc_loss = 0.09671942154203243
Trained batch 253 in epoch 6, gen_loss = 0.8091732810332081, disc_loss = 0.09663053397382573
Trained batch 254 in epoch 6, gen_loss = 0.8091432814504586, disc_loss = 0.09643095735387475
Trained batch 255 in epoch 6, gen_loss = 0.8085562195628881, disc_loss = 0.09652606480085524
Trained batch 256 in epoch 6, gen_loss = 0.8089417381509268, disc_loss = 0.09629363016540671
Trained batch 257 in epoch 6, gen_loss = 0.80832646683205, disc_loss = 0.09638086790868709
Trained batch 258 in epoch 6, gen_loss = 0.8074733370979781, disc_loss = 0.09626342112407031
Trained batch 259 in epoch 6, gen_loss = 0.8078956675070983, disc_loss = 0.09609891497888244
Trained batch 260 in epoch 6, gen_loss = 0.8079568542739898, disc_loss = 0.09592159721158246
Trained batch 261 in epoch 6, gen_loss = 0.807894072004857, disc_loss = 0.09572852865743045
Trained batch 262 in epoch 6, gen_loss = 0.8073132443790654, disc_loss = 0.09570594187896742
Trained batch 263 in epoch 6, gen_loss = 0.8084840167200926, disc_loss = 0.09566304411485115
Trained batch 264 in epoch 6, gen_loss = 0.8089669981092776, disc_loss = 0.09553502876100675
Trained batch 265 in epoch 6, gen_loss = 0.8080128632990041, disc_loss = 0.0957470320487269
Trained batch 266 in epoch 6, gen_loss = 0.8076982837491268, disc_loss = 0.09551614889184411
Trained batch 267 in epoch 6, gen_loss = 0.8090181066029107, disc_loss = 0.09564482602082304
Trained batch 268 in epoch 6, gen_loss = 0.8079295453085775, disc_loss = 0.09602759538225303
Trained batch 269 in epoch 6, gen_loss = 0.8088096726823736, disc_loss = 0.09582972626581236
Trained batch 270 in epoch 6, gen_loss = 0.8091030954434862, disc_loss = 0.09574698720718441
Trained batch 271 in epoch 6, gen_loss = 0.8084763110998798, disc_loss = 0.09578271139659644
Trained batch 272 in epoch 6, gen_loss = 0.8083273194211743, disc_loss = 0.0955407109466337
Trained batch 273 in epoch 6, gen_loss = 0.8095822186365614, disc_loss = 0.09592521444207779
Trained batch 274 in epoch 6, gen_loss = 0.8088628937981346, disc_loss = 0.09579532610421831
Trained batch 275 in epoch 6, gen_loss = 0.8078953010448511, disc_loss = 0.09607993771551528
Trained batch 276 in epoch 6, gen_loss = 0.8077815231003056, disc_loss = 0.09593507771914832
Trained batch 277 in epoch 6, gen_loss = 0.8083773538363066, disc_loss = 0.09585760974010332
Trained batch 278 in epoch 6, gen_loss = 0.8089553508707272, disc_loss = 0.09575575265005284
Trained batch 279 in epoch 6, gen_loss = 0.8089249806744712, disc_loss = 0.09561670896863299
Trained batch 280 in epoch 6, gen_loss = 0.8082133262182895, disc_loss = 0.09577855261645919
Trained batch 281 in epoch 6, gen_loss = 0.8082481527582128, disc_loss = 0.09597517608777217
Trained batch 282 in epoch 6, gen_loss = 0.8082806754449231, disc_loss = 0.09573998814942349
Trained batch 283 in epoch 6, gen_loss = 0.8078508013990563, disc_loss = 0.0955901693644553
Trained batch 284 in epoch 6, gen_loss = 0.8074400489790398, disc_loss = 0.09551991100766156
Trained batch 285 in epoch 6, gen_loss = 0.8076063625879221, disc_loss = 0.09543239183958385
Trained batch 286 in epoch 6, gen_loss = 0.8073325985815467, disc_loss = 0.09531409708127535
Trained batch 287 in epoch 6, gen_loss = 0.8068947392619319, disc_loss = 0.09513316194190541
Trained batch 288 in epoch 6, gen_loss = 0.8070922112382407, disc_loss = 0.09495198076339535
Trained batch 289 in epoch 6, gen_loss = 0.8067144328150256, disc_loss = 0.09506035621181644
Trained batch 290 in epoch 6, gen_loss = 0.8068808595749111, disc_loss = 0.09496204298360855
Trained batch 291 in epoch 6, gen_loss = 0.8072188908923162, disc_loss = 0.09493610479116235
Trained batch 292 in epoch 6, gen_loss = 0.8063830283721559, disc_loss = 0.0953911921969351
Trained batch 293 in epoch 6, gen_loss = 0.8058081364550558, disc_loss = 0.09553983480016999
Trained batch 294 in epoch 6, gen_loss = 0.8061619405019081, disc_loss = 0.0958207935789379
Trained batch 295 in epoch 6, gen_loss = 0.8054728169698973, disc_loss = 0.09592622792272754
Trained batch 296 in epoch 6, gen_loss = 0.8049428711836587, disc_loss = 0.09588479849600832
Trained batch 297 in epoch 6, gen_loss = 0.8053209965661068, disc_loss = 0.09610088588982421
Trained batch 298 in epoch 6, gen_loss = 0.8046786444242982, disc_loss = 0.0963623530128628
Trained batch 299 in epoch 6, gen_loss = 0.8045658797025681, disc_loss = 0.09618649668370684
Trained batch 300 in epoch 6, gen_loss = 0.8048643265847748, disc_loss = 0.09604982642512583
Trained batch 301 in epoch 6, gen_loss = 0.8042470528589969, disc_loss = 0.09602154356532341
Trained batch 302 in epoch 6, gen_loss = 0.8039571672382921, disc_loss = 0.09609027361196062
Trained batch 303 in epoch 6, gen_loss = 0.804231367417072, disc_loss = 0.09583642766320784
Trained batch 304 in epoch 6, gen_loss = 0.8038232308919313, disc_loss = 0.09567698651894194
Trained batch 305 in epoch 6, gen_loss = 0.8037518021327997, disc_loss = 0.09547507983261073
Trained batch 306 in epoch 6, gen_loss = 0.8033974221164318, disc_loss = 0.09536735020602176
Trained batch 307 in epoch 6, gen_loss = 0.8026106465946544, disc_loss = 0.09556737509495639
Trained batch 308 in epoch 6, gen_loss = 0.8026091491134422, disc_loss = 0.09563890930180796
Trained batch 309 in epoch 6, gen_loss = 0.803604906797409, disc_loss = 0.09540396486559222
Trained batch 310 in epoch 6, gen_loss = 0.8032607798407698, disc_loss = 0.09561496235166715
Trained batch 311 in epoch 6, gen_loss = 0.8027917098922607, disc_loss = 0.09547602884375896
Trained batch 312 in epoch 6, gen_loss = 0.8032598543090942, disc_loss = 0.0953339391980118
Trained batch 313 in epoch 6, gen_loss = 0.8028658831575114, disc_loss = 0.09531771748736026
Trained batch 314 in epoch 6, gen_loss = 0.8028330017649938, disc_loss = 0.09515115919094237
Trained batch 315 in epoch 6, gen_loss = 0.8026356563160691, disc_loss = 0.09519896941566014
Trained batch 316 in epoch 6, gen_loss = 0.8030008239324913, disc_loss = 0.09497521743648436
Trained batch 317 in epoch 6, gen_loss = 0.8023155721478492, disc_loss = 0.09494965070120569
Trained batch 318 in epoch 6, gen_loss = 0.8025040697528277, disc_loss = 0.09516889245766083
Trained batch 319 in epoch 6, gen_loss = 0.8023837203159928, disc_loss = 0.0950133568025194
Trained batch 320 in epoch 6, gen_loss = 0.8025072540078207, disc_loss = 0.09483665022476812
Trained batch 321 in epoch 6, gen_loss = 0.8021958757261312, disc_loss = 0.09486879120285836
Trained batch 322 in epoch 6, gen_loss = 0.8032175902242631, disc_loss = 0.09510430955434732
Trained batch 323 in epoch 6, gen_loss = 0.8033450887894925, disc_loss = 0.0948846839874247
Trained batch 324 in epoch 6, gen_loss = 0.8029420982874357, disc_loss = 0.09488627754724943
Trained batch 325 in epoch 6, gen_loss = 0.8035770305460948, disc_loss = 0.09556364711442608
Trained batch 326 in epoch 6, gen_loss = 0.8025055176803461, disc_loss = 0.09604710458980059
Trained batch 327 in epoch 6, gen_loss = 0.8019924673547105, disc_loss = 0.09611868540324815
Trained batch 328 in epoch 6, gen_loss = 0.8024298415539113, disc_loss = 0.09627690404019457
Trained batch 329 in epoch 6, gen_loss = 0.8014558030800386, disc_loss = 0.09656149550820842
Trained batch 330 in epoch 6, gen_loss = 0.8015262195530976, disc_loss = 0.0965534957333994
Trained batch 331 in epoch 6, gen_loss = 0.8014459370310048, disc_loss = 0.09670882900974836
Trained batch 332 in epoch 6, gen_loss = 0.8006124599380894, disc_loss = 0.09672717454734149
Trained batch 333 in epoch 6, gen_loss = 0.8004940270842192, disc_loss = 0.0966767035201638
Trained batch 334 in epoch 6, gen_loss = 0.8004240100953116, disc_loss = 0.09659099467654726
Trained batch 335 in epoch 6, gen_loss = 0.8000143233331896, disc_loss = 0.09649299045226403
Trained batch 336 in epoch 6, gen_loss = 0.8008700420842326, disc_loss = 0.09636180927473996
Trained batch 337 in epoch 6, gen_loss = 0.80023894816108, disc_loss = 0.0963135680856084
Trained batch 338 in epoch 6, gen_loss = 0.7998586250441616, disc_loss = 0.09623816433557719
Trained batch 339 in epoch 6, gen_loss = 0.8007483016918687, disc_loss = 0.09654295724980971
Trained batch 340 in epoch 6, gen_loss = 0.8002842448848434, disc_loss = 0.09666765583924884
Trained batch 341 in epoch 6, gen_loss = 0.7998987384881192, disc_loss = 0.09662808565019865
Trained batch 342 in epoch 6, gen_loss = 0.7999976333828084, disc_loss = 0.09667498611847791
Trained batch 343 in epoch 6, gen_loss = 0.7997534268990506, disc_loss = 0.09653504716968814
Trained batch 344 in epoch 6, gen_loss = 0.7992671742819357, disc_loss = 0.09659732472205508
Trained batch 345 in epoch 6, gen_loss = 0.7993510745336555, disc_loss = 0.09639050214513706
Trained batch 346 in epoch 6, gen_loss = 0.7995028201200777, disc_loss = 0.09615797472725855
Trained batch 347 in epoch 6, gen_loss = 0.7989271905744213, disc_loss = 0.09627078026640175
Trained batch 348 in epoch 6, gen_loss = 0.7990973876164772, disc_loss = 0.09643596985556165
Trained batch 349 in epoch 6, gen_loss = 0.7983346710034779, disc_loss = 0.09647554300193276
Trained batch 350 in epoch 6, gen_loss = 0.7994438521033339, disc_loss = 0.09705706764851031
Trained batch 351 in epoch 6, gen_loss = 0.7991045729511164, disc_loss = 0.09698254869594662
Trained batch 352 in epoch 6, gen_loss = 0.7994456921859774, disc_loss = 0.09680493070978788
Trained batch 353 in epoch 6, gen_loss = 0.7990710490335853, disc_loss = 0.09677376451318041
Trained batch 354 in epoch 6, gen_loss = 0.799444606018738, disc_loss = 0.09668355364299996
Trained batch 355 in epoch 6, gen_loss = 0.7995370684212513, disc_loss = 0.09658565067194319
Trained batch 356 in epoch 6, gen_loss = 0.7997626898502436, disc_loss = 0.09639017774360854
Trained batch 357 in epoch 6, gen_loss = 0.7996121202933721, disc_loss = 0.09625364954494897
Trained batch 358 in epoch 6, gen_loss = 0.7996908559938659, disc_loss = 0.09610555877177496
Trained batch 359 in epoch 6, gen_loss = 0.8004401105145613, disc_loss = 0.09643637411710289
Trained batch 360 in epoch 6, gen_loss = 0.800339801902586, disc_loss = 0.09630688359326273
Trained batch 361 in epoch 6, gen_loss = 0.8006007616197207, disc_loss = 0.09608452214000139
Trained batch 362 in epoch 6, gen_loss = 0.8007246048161478, disc_loss = 0.09599256555013584
Trained batch 363 in epoch 6, gen_loss = 0.8009852438673868, disc_loss = 0.09577744814393284
Trained batch 364 in epoch 6, gen_loss = 0.8001900639436016, disc_loss = 0.0959482393852652
Trained batch 365 in epoch 6, gen_loss = 0.8008809792376607, disc_loss = 0.09604410399667553
Trained batch 366 in epoch 6, gen_loss = 0.8011124126755249, disc_loss = 0.09595930976260261
Trained batch 367 in epoch 6, gen_loss = 0.800796564101525, disc_loss = 0.09599233805404409
Trained batch 368 in epoch 6, gen_loss = 0.8004954296560468, disc_loss = 0.09589512250449277
Trained batch 369 in epoch 6, gen_loss = 0.8008268751808115, disc_loss = 0.09601492511259543
Trained batch 370 in epoch 6, gen_loss = 0.8001912169540025, disc_loss = 0.09609975089442055
Trained batch 371 in epoch 6, gen_loss = 0.799649546944326, disc_loss = 0.09611825817214545
Trained batch 372 in epoch 6, gen_loss = 0.7993477494243643, disc_loss = 0.09608003666909067
Trained batch 373 in epoch 6, gen_loss = 0.799471154330886, disc_loss = 0.09594241730908659
Trained batch 374 in epoch 6, gen_loss = 0.7990324100653331, disc_loss = 0.09594576835632324
Trained batch 375 in epoch 6, gen_loss = 0.7989637595700457, disc_loss = 0.09588003665842909
Trained batch 376 in epoch 6, gen_loss = 0.7997675192609074, disc_loss = 0.09591905845808414
Trained batch 377 in epoch 6, gen_loss = 0.8001376121605515, disc_loss = 0.0956988762152534
Trained batch 378 in epoch 6, gen_loss = 0.8002660320899732, disc_loss = 0.09547622262261866
Trained batch 379 in epoch 6, gen_loss = 0.7992545922335825, disc_loss = 0.09590480092569793
Trained batch 380 in epoch 6, gen_loss = 0.7992901159865963, disc_loss = 0.09583300581138356
Trained batch 381 in epoch 6, gen_loss = 0.8008108562667956, disc_loss = 0.09671603519888838
Trained batch 382 in epoch 6, gen_loss = 0.8002385446514847, disc_loss = 0.09674275771765811
Trained batch 383 in epoch 6, gen_loss = 0.7997822236114492, disc_loss = 0.09685489820791797
Trained batch 384 in epoch 6, gen_loss = 0.7990072562322988, disc_loss = 0.09694322001479276
Trained batch 385 in epoch 6, gen_loss = 0.8001845543094249, disc_loss = 0.09733104943466696
Trained batch 386 in epoch 6, gen_loss = 0.8011069050592969, disc_loss = 0.09726017118896085
Trained batch 387 in epoch 6, gen_loss = 0.8007813178233265, disc_loss = 0.09722530928478797
Trained batch 388 in epoch 6, gen_loss = 0.7999864484932858, disc_loss = 0.0974978836214979
Trained batch 389 in epoch 6, gen_loss = 0.7997014961945705, disc_loss = 0.0975188590419025
Trained batch 390 in epoch 6, gen_loss = 0.8001850421928689, disc_loss = 0.09761975972634523
Trained batch 391 in epoch 6, gen_loss = 0.8005806401524008, disc_loss = 0.09765265270240833
Trained batch 392 in epoch 6, gen_loss = 0.8000499491624856, disc_loss = 0.09801598826219486
Trained batch 393 in epoch 6, gen_loss = 0.799515545443835, disc_loss = 0.0981274439319779
Trained batch 394 in epoch 6, gen_loss = 0.7998242997670475, disc_loss = 0.09810599579322564
Trained batch 395 in epoch 6, gen_loss = 0.7997950651880467, disc_loss = 0.09807161584430647
Trained batch 396 in epoch 6, gen_loss = 0.8003197931672824, disc_loss = 0.09788896906557927
Trained batch 397 in epoch 6, gen_loss = 0.7999845320106151, disc_loss = 0.09797226028498168
Trained batch 398 in epoch 6, gen_loss = 0.799659581486145, disc_loss = 0.09796951869199225
Trained batch 399 in epoch 6, gen_loss = 0.8000531397014856, disc_loss = 0.09791728605749085
Trained batch 400 in epoch 6, gen_loss = 0.799493606919957, disc_loss = 0.09792207459456977
Trained batch 401 in epoch 6, gen_loss = 0.7992739642585688, disc_loss = 0.09786039486351372
Trained batch 402 in epoch 6, gen_loss = 0.7992338782948241, disc_loss = 0.09773561981721567
Trained batch 403 in epoch 6, gen_loss = 0.7993606503794689, disc_loss = 0.0976188906150326
Trained batch 404 in epoch 6, gen_loss = 0.7988043688697579, disc_loss = 0.09756710036531274
Trained batch 405 in epoch 6, gen_loss = 0.7992284868297905, disc_loss = 0.09741401463389177
Trained batch 406 in epoch 6, gen_loss = 0.7995092670366863, disc_loss = 0.09722963356039961
Trained batch 407 in epoch 6, gen_loss = 0.7993226900842845, disc_loss = 0.09717434191592403
Trained batch 408 in epoch 6, gen_loss = 0.7987921311540533, disc_loss = 0.09719542342677603
Trained batch 409 in epoch 6, gen_loss = 0.7989297120309458, disc_loss = 0.09748867742671835
Trained batch 410 in epoch 6, gen_loss = 0.7983687688979499, disc_loss = 0.09753268402196702
Trained batch 411 in epoch 6, gen_loss = 0.7982128989493963, disc_loss = 0.09741727087095163
Trained batch 412 in epoch 6, gen_loss = 0.7983021010931122, disc_loss = 0.09734187962275369
Trained batch 413 in epoch 6, gen_loss = 0.798902540895098, disc_loss = 0.0972491057144235
Trained batch 414 in epoch 6, gen_loss = 0.7982953814856978, disc_loss = 0.09743238270776458
Trained batch 415 in epoch 6, gen_loss = 0.7979247586515087, disc_loss = 0.0974537029732556
Trained batch 416 in epoch 6, gen_loss = 0.7988675517572773, disc_loss = 0.09749389686163881
Trained batch 417 in epoch 6, gen_loss = 0.7996590082582674, disc_loss = 0.09760442249361051
Trained batch 418 in epoch 6, gen_loss = 0.7991005262640041, disc_loss = 0.09780274173089243
Trained batch 419 in epoch 6, gen_loss = 0.7989610170324644, disc_loss = 0.09767761581488663
Trained batch 420 in epoch 6, gen_loss = 0.7989486255583458, disc_loss = 0.09765732279290708
Trained batch 421 in epoch 6, gen_loss = 0.7990014734567624, disc_loss = 0.09748022218336355
Trained batch 422 in epoch 6, gen_loss = 0.7988398447808926, disc_loss = 0.0973862594072806
Trained batch 423 in epoch 6, gen_loss = 0.7989098797288706, disc_loss = 0.09722504361295405
Trained batch 424 in epoch 6, gen_loss = 0.7994340034793405, disc_loss = 0.09741602754549068
Trained batch 425 in epoch 6, gen_loss = 0.799283128319212, disc_loss = 0.09744039206533854
Trained batch 426 in epoch 6, gen_loss = 0.7992497782377783, disc_loss = 0.09737212433146021
Trained batch 427 in epoch 6, gen_loss = 0.7988325580954552, disc_loss = 0.09730197232277524
Trained batch 428 in epoch 6, gen_loss = 0.7995061908429597, disc_loss = 0.09760034981125093
Trained batch 429 in epoch 6, gen_loss = 0.7994720566411351, disc_loss = 0.09752860891221221
Trained batch 430 in epoch 6, gen_loss = 0.7992698992073121, disc_loss = 0.09741563189843899
Trained batch 431 in epoch 6, gen_loss = 0.7988480127382057, disc_loss = 0.09749253394935901
Trained batch 432 in epoch 6, gen_loss = 0.7990125977277205, disc_loss = 0.09743951433757643
Trained batch 433 in epoch 6, gen_loss = 0.7999798051909917, disc_loss = 0.09743529521057614
Trained batch 434 in epoch 6, gen_loss = 0.8001021506457493, disc_loss = 0.09726976038267215
Trained batch 435 in epoch 6, gen_loss = 0.7996089638236465, disc_loss = 0.09741207132107416
Trained batch 436 in epoch 6, gen_loss = 0.7991918743475078, disc_loss = 0.09741927562515919
Trained batch 437 in epoch 6, gen_loss = 0.7993364119774675, disc_loss = 0.09740629425000179
Trained batch 438 in epoch 6, gen_loss = 0.7997426952072048, disc_loss = 0.09746649761414813
Trained batch 439 in epoch 6, gen_loss = 0.7993021716448394, disc_loss = 0.09748451449188658
Trained batch 440 in epoch 6, gen_loss = 0.7994092948177234, disc_loss = 0.09731994534033835
Trained batch 441 in epoch 6, gen_loss = 0.7991440252346151, disc_loss = 0.09720379008165649
Trained batch 442 in epoch 6, gen_loss = 0.7998667010200751, disc_loss = 0.09717500537978674
Trained batch 443 in epoch 6, gen_loss = 0.7993751587765711, disc_loss = 0.09718863184664499
Trained batch 444 in epoch 6, gen_loss = 0.79957730589288, disc_loss = 0.09701878655534447
Trained batch 445 in epoch 6, gen_loss = 0.79932561082423, disc_loss = 0.09701941739726026
Trained batch 446 in epoch 6, gen_loss = 0.799437777107994, disc_loss = 0.096870797598772
Trained batch 447 in epoch 6, gen_loss = 0.800192125740328, disc_loss = 0.09683682146507115
Trained batch 448 in epoch 6, gen_loss = 0.8005964837653069, disc_loss = 0.09666217065609178
Trained batch 449 in epoch 6, gen_loss = 0.8003608051273557, disc_loss = 0.09669527555712396
Trained batch 450 in epoch 6, gen_loss = 0.8009783472956681, disc_loss = 0.09665679380074639
Trained batch 451 in epoch 6, gen_loss = 0.8005967507452036, disc_loss = 0.09668282483935159
Trained batch 452 in epoch 6, gen_loss = 0.8005276334864677, disc_loss = 0.09683135841206275
Trained batch 453 in epoch 6, gen_loss = 0.8008051985292183, disc_loss = 0.09681740203166651
Trained batch 454 in epoch 6, gen_loss = 0.7999771900884398, disc_loss = 0.09702320341430196
Trained batch 455 in epoch 6, gen_loss = 0.7996376788799178, disc_loss = 0.09699261659274303
Trained batch 456 in epoch 6, gen_loss = 0.7994402775487962, disc_loss = 0.0969567222284312
Trained batch 457 in epoch 6, gen_loss = 0.8003750524796773, disc_loss = 0.09727646082062193
Trained batch 458 in epoch 6, gen_loss = 0.8000370793223122, disc_loss = 0.09732042821347389
Trained batch 459 in epoch 6, gen_loss = 0.7992757446739984, disc_loss = 0.09778164968744892
Trained batch 460 in epoch 6, gen_loss = 0.7990474885172026, disc_loss = 0.09780634871993109
Trained batch 461 in epoch 6, gen_loss = 0.7990837548073236, disc_loss = 0.09791130446970012
Trained batch 462 in epoch 6, gen_loss = 0.7992390518440798, disc_loss = 0.09782060696170153
Trained batch 463 in epoch 6, gen_loss = 0.7991216409437615, disc_loss = 0.09775195966257938
Trained batch 464 in epoch 6, gen_loss = 0.7995137666502307, disc_loss = 0.09763064729149944
Trained batch 465 in epoch 6, gen_loss = 0.8004507548435563, disc_loss = 0.09757985019768577
Trained batch 466 in epoch 6, gen_loss = 0.8007359506614203, disc_loss = 0.0974218513142533
Trained batch 467 in epoch 6, gen_loss = 0.8004806067826401, disc_loss = 0.09735346107313839
Trained batch 468 in epoch 6, gen_loss = 0.800105010332075, disc_loss = 0.09726458938240307
Trained batch 469 in epoch 6, gen_loss = 0.7999069723043036, disc_loss = 0.09731071446526875
Trained batch 470 in epoch 6, gen_loss = 0.800039058974341, disc_loss = 0.09715607663667948
Trained batch 471 in epoch 6, gen_loss = 0.7994409319076498, disc_loss = 0.09738115567942861
Trained batch 472 in epoch 6, gen_loss = 0.8002621640488663, disc_loss = 0.09757817165835526
Trained batch 473 in epoch 6, gen_loss = 0.8003731185751122, disc_loss = 0.09751353885404734
Trained batch 474 in epoch 6, gen_loss = 0.7996862904021614, disc_loss = 0.09773556857712959
Trained batch 475 in epoch 6, gen_loss = 0.7995039261564487, disc_loss = 0.0977551546202143
Trained batch 476 in epoch 6, gen_loss = 0.7993640086810794, disc_loss = 0.09786387373043119
Trained batch 477 in epoch 6, gen_loss = 0.799471081737195, disc_loss = 0.09781035744472091
Trained batch 478 in epoch 6, gen_loss = 0.799088078339065, disc_loss = 0.09794883723399896
Trained batch 479 in epoch 6, gen_loss = 0.7992278290912509, disc_loss = 0.09797662056710882
Trained batch 480 in epoch 6, gen_loss = 0.7990393884588428, disc_loss = 0.09791808742100447
Trained batch 481 in epoch 6, gen_loss = 0.7985339478214747, disc_loss = 0.09793977380084855
Trained batch 482 in epoch 6, gen_loss = 0.7981837286342005, disc_loss = 0.09792860743337105
Trained batch 483 in epoch 6, gen_loss = 0.7983790231514568, disc_loss = 0.09802093285459194
Trained batch 484 in epoch 6, gen_loss = 0.7981425569844001, disc_loss = 0.09793957657151922
Trained batch 485 in epoch 6, gen_loss = 0.799233946964574, disc_loss = 0.09785738710980908
Trained batch 486 in epoch 6, gen_loss = 0.7992190878371683, disc_loss = 0.09771001150208149
Trained batch 487 in epoch 6, gen_loss = 0.7991946440373288, disc_loss = 0.09757873587898117
Trained batch 488 in epoch 6, gen_loss = 0.7993959978923719, disc_loss = 0.09755079287669959
Trained batch 489 in epoch 6, gen_loss = 0.7996862317226371, disc_loss = 0.09739052732570135
Trained batch 490 in epoch 6, gen_loss = 0.7992970956197338, disc_loss = 0.09755629504596447
Trained batch 491 in epoch 6, gen_loss = 0.7994617781624561, disc_loss = 0.0974163242097096
Trained batch 492 in epoch 6, gen_loss = 0.799553061776906, disc_loss = 0.09728686382491557
Trained batch 493 in epoch 6, gen_loss = 0.7998874920461825, disc_loss = 0.09715166255296302
Trained batch 494 in epoch 6, gen_loss = 0.8000609854857127, disc_loss = 0.0970393433809431
Trained batch 495 in epoch 6, gen_loss = 0.8007858346907362, disc_loss = 0.09701059511750035
Trained batch 496 in epoch 6, gen_loss = 0.8005341602643011, disc_loss = 0.0970064964936203
Trained batch 497 in epoch 6, gen_loss = 0.8005625870692203, disc_loss = 0.09683911945207052
Trained batch 498 in epoch 6, gen_loss = 0.8001627133102838, disc_loss = 0.0968238971754162
Trained batch 499 in epoch 6, gen_loss = 0.800231900036335, disc_loss = 0.0967325185984373
Trained batch 500 in epoch 6, gen_loss = 0.8003894985911851, disc_loss = 0.09656880084172396
Trained batch 501 in epoch 6, gen_loss = 0.8009522154155481, disc_loss = 0.0965039509578619
Trained batch 502 in epoch 6, gen_loss = 0.8008065150817393, disc_loss = 0.09641591129013546
Trained batch 503 in epoch 6, gen_loss = 0.8004569659039141, disc_loss = 0.09637490183758061
Trained batch 504 in epoch 6, gen_loss = 0.8011130046726453, disc_loss = 0.09628993403904214
Trained batch 505 in epoch 6, gen_loss = 0.8016333527597985, disc_loss = 0.09614483640518172
Trained batch 506 in epoch 6, gen_loss = 0.8019556904568005, disc_loss = 0.09601437482115843
Trained batch 507 in epoch 6, gen_loss = 0.8016064245048471, disc_loss = 0.09611323588219743
Trained batch 508 in epoch 6, gen_loss = 0.8015347082746053, disc_loss = 0.09599107842936322
Trained batch 509 in epoch 6, gen_loss = 0.8014976602558996, disc_loss = 0.09607301245753964
Trained batch 510 in epoch 6, gen_loss = 0.8013533342724444, disc_loss = 0.09596239452645795
Trained batch 511 in epoch 6, gen_loss = 0.801895881362725, disc_loss = 0.09581022220845625
Trained batch 512 in epoch 6, gen_loss = 0.8017685000310865, disc_loss = 0.09567584942111321
Trained batch 513 in epoch 6, gen_loss = 0.8016315766461628, disc_loss = 0.09560596063943283
Trained batch 514 in epoch 6, gen_loss = 0.8019435210714062, disc_loss = 0.09555023391595453
Trained batch 515 in epoch 6, gen_loss = 0.8016256114193635, disc_loss = 0.09564197685230205
Trained batch 516 in epoch 6, gen_loss = 0.8016194154146331, disc_loss = 0.09553286545086702
Trained batch 517 in epoch 6, gen_loss = 0.8012936041046754, disc_loss = 0.09548820136114955
Trained batch 518 in epoch 6, gen_loss = 0.8013188256119488, disc_loss = 0.09541316114559856
Trained batch 519 in epoch 6, gen_loss = 0.8012538924240149, disc_loss = 0.09529059505125938
Trained batch 520 in epoch 6, gen_loss = 0.8017253617750706, disc_loss = 0.09514331209317793
Trained batch 521 in epoch 6, gen_loss = 0.8021461550874271, disc_loss = 0.09500682653174147
Trained batch 522 in epoch 6, gen_loss = 0.8021783894266271, disc_loss = 0.09490308847392323
Trained batch 523 in epoch 6, gen_loss = 0.8021959147721757, disc_loss = 0.09476023213049212
Trained batch 524 in epoch 6, gen_loss = 0.8023923094499679, disc_loss = 0.09462381464207456
Trained batch 525 in epoch 6, gen_loss = 0.8022992684020742, disc_loss = 0.094609405794057
Trained batch 526 in epoch 6, gen_loss = 0.8026219902160724, disc_loss = 0.09453634505444675
Trained batch 527 in epoch 6, gen_loss = 0.8027525124789188, disc_loss = 0.09443685349436816
Trained batch 528 in epoch 6, gen_loss = 0.8023480632692744, disc_loss = 0.09449990101278335
Trained batch 529 in epoch 6, gen_loss = 0.8025744067610435, disc_loss = 0.09438253193215099
Trained batch 530 in epoch 6, gen_loss = 0.8029765834130361, disc_loss = 0.0946339355823768
Trained batch 531 in epoch 6, gen_loss = 0.8029693825016344, disc_loss = 0.09453221240178927
Trained batch 532 in epoch 6, gen_loss = 0.8030184908275533, disc_loss = 0.0944602347431638
Trained batch 533 in epoch 6, gen_loss = 0.8028948733980736, disc_loss = 0.09435690792751837
Trained batch 534 in epoch 6, gen_loss = 0.8027231234813405, disc_loss = 0.09442963865977302
Trained batch 535 in epoch 6, gen_loss = 0.8028692957291852, disc_loss = 0.0944891751990584
Trained batch 536 in epoch 6, gen_loss = 0.8031041933504562, disc_loss = 0.09455677923647551
Trained batch 537 in epoch 6, gen_loss = 0.8034229090776586, disc_loss = 0.09441308203399126
Trained batch 538 in epoch 6, gen_loss = 0.8032938232558999, disc_loss = 0.09432066902207256
Trained batch 539 in epoch 6, gen_loss = 0.8029950019937975, disc_loss = 0.09424637643516892
Trained batch 540 in epoch 6, gen_loss = 0.804240141855811, disc_loss = 0.09465621094186678
Trained batch 541 in epoch 6, gen_loss = 0.8042678757677219, disc_loss = 0.09451844817288632
Trained batch 542 in epoch 6, gen_loss = 0.8035298253840065, disc_loss = 0.0947919766132207
Trained batch 543 in epoch 6, gen_loss = 0.8039233125198413, disc_loss = 0.09467041817911462
Trained batch 544 in epoch 6, gen_loss = 0.8034418809851375, disc_loss = 0.09479880086359901
Trained batch 545 in epoch 6, gen_loss = 0.8038202693938336, disc_loss = 0.09483887283336166
Trained batch 546 in epoch 6, gen_loss = 0.8035145069062165, disc_loss = 0.09483198046010036
Trained batch 547 in epoch 6, gen_loss = 0.803462959717225, disc_loss = 0.09478053968080258
Trained batch 548 in epoch 6, gen_loss = 0.8036033281537353, disc_loss = 0.09475636423373754
Trained batch 549 in epoch 6, gen_loss = 0.8033628957379948, disc_loss = 0.09519980052147399
Trained batch 550 in epoch 6, gen_loss = 0.8027011767273157, disc_loss = 0.09553265307409631
Trained batch 551 in epoch 6, gen_loss = 0.8029326756579288, disc_loss = 0.09550509687708826
Trained batch 552 in epoch 6, gen_loss = 0.8028360082486654, disc_loss = 0.09543464646908786
Trained batch 553 in epoch 6, gen_loss = 0.8029070981788291, disc_loss = 0.09540661298148738
Trained batch 554 in epoch 6, gen_loss = 0.802391153949875, disc_loss = 0.09575299948353219
Trained batch 555 in epoch 6, gen_loss = 0.802366415909726, disc_loss = 0.09583157858570113
Trained batch 556 in epoch 6, gen_loss = 0.8027122126661469, disc_loss = 0.09586278271746004
Trained batch 557 in epoch 6, gen_loss = 0.8022487346203097, disc_loss = 0.09593953607657317
Trained batch 558 in epoch 6, gen_loss = 0.802192169886369, disc_loss = 0.09582872722924342
Trained batch 559 in epoch 6, gen_loss = 0.8019489742815494, disc_loss = 0.09603874438076414
Trained batch 560 in epoch 6, gen_loss = 0.8018421029237077, disc_loss = 0.09599250029945172
Trained batch 561 in epoch 6, gen_loss = 0.8016582670160884, disc_loss = 0.09599824987676697
Trained batch 562 in epoch 6, gen_loss = 0.8014488664867612, disc_loss = 0.09601981921508564
Trained batch 563 in epoch 6, gen_loss = 0.8010166067603632, disc_loss = 0.09595543711036708
Trained batch 564 in epoch 6, gen_loss = 0.800991798713144, disc_loss = 0.09594254432559277
Trained batch 565 in epoch 6, gen_loss = 0.8014401869302082, disc_loss = 0.09586110194592141
Trained batch 566 in epoch 6, gen_loss = 0.800805979883019, disc_loss = 0.0961464875224958
Trained batch 567 in epoch 6, gen_loss = 0.8010181783055755, disc_loss = 0.09620264990576609
Trained batch 568 in epoch 6, gen_loss = 0.8013776423956263, disc_loss = 0.09618110056010669
Trained batch 569 in epoch 6, gen_loss = 0.8012358065759927, disc_loss = 0.09611120610416198
Trained batch 570 in epoch 6, gen_loss = 0.8010186153723354, disc_loss = 0.09608363661093021
Trained batch 571 in epoch 6, gen_loss = 0.8012889865916092, disc_loss = 0.09610983971148156
Trained batch 572 in epoch 6, gen_loss = 0.8011559101819576, disc_loss = 0.09607723698078494
Trained batch 573 in epoch 6, gen_loss = 0.8009990969289886, disc_loss = 0.09602671482142723
Trained batch 574 in epoch 6, gen_loss = 0.8006819287072058, disc_loss = 0.09607671341980281
Trained batch 575 in epoch 6, gen_loss = 0.8013069374590285, disc_loss = 0.09620374974878763
Trained batch 576 in epoch 6, gen_loss = 0.8011822617343228, disc_loss = 0.09617083018203387
Trained batch 577 in epoch 6, gen_loss = 0.800598726810881, disc_loss = 0.09627879267416663
Trained batch 578 in epoch 6, gen_loss = 0.8003027981118217, disc_loss = 0.09624708170595615
Trained batch 579 in epoch 6, gen_loss = 0.8004421098992742, disc_loss = 0.09626719627433039
Trained batch 580 in epoch 6, gen_loss = 0.8007515094879367, disc_loss = 0.09616363504596966
Trained batch 581 in epoch 6, gen_loss = 0.8005046642215801, disc_loss = 0.09612625142994666
Trained batch 582 in epoch 6, gen_loss = 0.8001990949616833, disc_loss = 0.09610757631238544
Trained batch 583 in epoch 6, gen_loss = 0.8006581032827292, disc_loss = 0.09601462643421318
Trained batch 584 in epoch 6, gen_loss = 0.8007405199046828, disc_loss = 0.09590985413449697
Trained batch 585 in epoch 6, gen_loss = 0.8007581293481202, disc_loss = 0.0958348783734334
Trained batch 586 in epoch 6, gen_loss = 0.8006478166762975, disc_loss = 0.09574312026401445
Trained batch 587 in epoch 6, gen_loss = 0.8010370638601634, disc_loss = 0.09562816261313856
Trained batch 588 in epoch 6, gen_loss = 0.8011320259150099, disc_loss = 0.09552910903876675
Trained batch 589 in epoch 6, gen_loss = 0.8009670556096707, disc_loss = 0.09542755093267662
Trained batch 590 in epoch 6, gen_loss = 0.8008525389200943, disc_loss = 0.09533051352368041
Trained batch 591 in epoch 6, gen_loss = 0.8006298984526783, disc_loss = 0.09529374743893591
Trained batch 592 in epoch 6, gen_loss = 0.8006081705250185, disc_loss = 0.09520792871443508
Trained batch 593 in epoch 6, gen_loss = 0.8002842882967959, disc_loss = 0.09519516054057965
Trained batch 594 in epoch 6, gen_loss = 0.8005553679806846, disc_loss = 0.09506017165649838
Trained batch 595 in epoch 6, gen_loss = 0.8006794930204449, disc_loss = 0.09507258739572444
Trained batch 596 in epoch 6, gen_loss = 0.8007531681751686, disc_loss = 0.0950292205528498
Trained batch 597 in epoch 6, gen_loss = 0.8004348416093201, disc_loss = 0.09510146701291054
Trained batch 598 in epoch 6, gen_loss = 0.8000856504117905, disc_loss = 0.09518264534452522
Trained batch 599 in epoch 6, gen_loss = 0.800823492159446, disc_loss = 0.09551416033878922
Trained batch 600 in epoch 6, gen_loss = 0.8007535780229902, disc_loss = 0.09549644128876597
Trained batch 601 in epoch 6, gen_loss = 0.8007787045747339, disc_loss = 0.0954849917590123
Trained batch 602 in epoch 6, gen_loss = 0.800835508266294, disc_loss = 0.0953961738862505
Trained batch 603 in epoch 6, gen_loss = 0.800976853743689, disc_loss = 0.09534294433916445
Trained batch 604 in epoch 6, gen_loss = 0.8016548655742456, disc_loss = 0.09528700571414853
Trained batch 605 in epoch 6, gen_loss = 0.8018004926222779, disc_loss = 0.09517746685509242
Trained batch 606 in epoch 6, gen_loss = 0.8015675269300502, disc_loss = 0.0952103092922803
Trained batch 607 in epoch 6, gen_loss = 0.8019908928851548, disc_loss = 0.09512096881180217
Trained batch 608 in epoch 6, gen_loss = 0.8016095297970796, disc_loss = 0.09517004183066889
Trained batch 609 in epoch 6, gen_loss = 0.8014225346631692, disc_loss = 0.0952635934362646
Trained batch 610 in epoch 6, gen_loss = 0.8016174864359261, disc_loss = 0.09536184275403936
Trained batch 611 in epoch 6, gen_loss = 0.8014536095308322, disc_loss = 0.09533303352742413
Trained batch 612 in epoch 6, gen_loss = 0.8011623055569305, disc_loss = 0.09539481258509015
Trained batch 613 in epoch 6, gen_loss = 0.8014934708027576, disc_loss = 0.0952757305559681
Trained batch 614 in epoch 6, gen_loss = 0.8019648723001402, disc_loss = 0.09521297840325813
Trained batch 615 in epoch 6, gen_loss = 0.8024526250536566, disc_loss = 0.09520303093912927
Trained batch 616 in epoch 6, gen_loss = 0.8024808639355572, disc_loss = 0.09514047014655325
Trained batch 617 in epoch 6, gen_loss = 0.8020680709274841, disc_loss = 0.09553286042606947
Trained batch 618 in epoch 6, gen_loss = 0.8027236639297837, disc_loss = 0.09555153049203614
Trained batch 619 in epoch 6, gen_loss = 0.8026065803823933, disc_loss = 0.09547548907538575
Trained batch 620 in epoch 6, gen_loss = 0.8027452165665834, disc_loss = 0.09544250408064532
Trained batch 621 in epoch 6, gen_loss = 0.8023097648785429, disc_loss = 0.09554574097779212
Trained batch 622 in epoch 6, gen_loss = 0.8025471762803355, disc_loss = 0.09569474603281167
Trained batch 623 in epoch 6, gen_loss = 0.8026195427832695, disc_loss = 0.09574678581422912
Trained batch 624 in epoch 6, gen_loss = 0.8023999284267426, disc_loss = 0.09570430145859718
Trained batch 625 in epoch 6, gen_loss = 0.8019658971232728, disc_loss = 0.09583753576508156
Trained batch 626 in epoch 6, gen_loss = 0.8017732260044682, disc_loss = 0.09592419561515585
Trained batch 627 in epoch 6, gen_loss = 0.8022449589364088, disc_loss = 0.09593643176304117
Trained batch 628 in epoch 6, gen_loss = 0.8019408633390557, disc_loss = 0.0960543952787529
Trained batch 629 in epoch 6, gen_loss = 0.801875042868039, disc_loss = 0.09596960834330982
Trained batch 630 in epoch 6, gen_loss = 0.8019195224044818, disc_loss = 0.09604491415048363
Trained batch 631 in epoch 6, gen_loss = 0.8017183431435989, disc_loss = 0.09610621717204398
Trained batch 632 in epoch 6, gen_loss = 0.8016159548107858, disc_loss = 0.09607678939004269
Trained batch 633 in epoch 6, gen_loss = 0.8013422008286515, disc_loss = 0.09606527135199176
Trained batch 634 in epoch 6, gen_loss = 0.8012906039324332, disc_loss = 0.096168718023563
Trained batch 635 in epoch 6, gen_loss = 0.8012012648601202, disc_loss = 0.09619873612181945
Trained batch 636 in epoch 6, gen_loss = 0.8011481106468422, disc_loss = 0.09612585220550256
Trained batch 637 in epoch 6, gen_loss = 0.8013927891243214, disc_loss = 0.09613148893775611
Trained batch 638 in epoch 6, gen_loss = 0.8012117460393383, disc_loss = 0.09609387560816064
Trained batch 639 in epoch 6, gen_loss = 0.8011908229906112, disc_loss = 0.09608183635864406
Trained batch 640 in epoch 6, gen_loss = 0.8014456630218048, disc_loss = 0.09615622272543528
Trained batch 641 in epoch 6, gen_loss = 0.8012595549457913, disc_loss = 0.09611051074719504
Trained batch 642 in epoch 6, gen_loss = 0.8011179365692762, disc_loss = 0.09602422122358349
Trained batch 643 in epoch 6, gen_loss = 0.8019508007242813, disc_loss = 0.09602212109921142
Trained batch 644 in epoch 6, gen_loss = 0.8019962106102196, disc_loss = 0.0959376130570737
Trained batch 645 in epoch 6, gen_loss = 0.801628385857901, disc_loss = 0.09592116887078565
Trained batch 646 in epoch 6, gen_loss = 0.8015587616832769, disc_loss = 0.09581962585380126
Trained batch 647 in epoch 6, gen_loss = 0.8016031040913529, disc_loss = 0.09581095900639523
Trained batch 648 in epoch 6, gen_loss = 0.8015503981172212, disc_loss = 0.09574072573259358
Trained batch 649 in epoch 6, gen_loss = 0.8012541963045414, disc_loss = 0.09574725057643194
Trained batch 650 in epoch 6, gen_loss = 0.8008986541660883, disc_loss = 0.09578196686648187
Trained batch 651 in epoch 6, gen_loss = 0.8008640915429666, disc_loss = 0.0956782054533165
Trained batch 652 in epoch 6, gen_loss = 0.8008453410124523, disc_loss = 0.09561735559910947
Trained batch 653 in epoch 6, gen_loss = 0.8012459420738599, disc_loss = 0.09574397532013032
Trained batch 654 in epoch 6, gen_loss = 0.8010375407360892, disc_loss = 0.09577295569176893
Trained batch 655 in epoch 6, gen_loss = 0.8004362501840039, disc_loss = 0.09601675390220452
Trained batch 656 in epoch 6, gen_loss = 0.8006961685428154, disc_loss = 0.09597806819066791
Trained batch 657 in epoch 6, gen_loss = 0.8006448776979215, disc_loss = 0.09592002911045922
Trained batch 658 in epoch 6, gen_loss = 0.8006640691225373, disc_loss = 0.09597583250771524
Trained batch 659 in epoch 6, gen_loss = 0.8002481489922061, disc_loss = 0.09619002818609729
Trained batch 660 in epoch 6, gen_loss = 0.8001956354020764, disc_loss = 0.0961532423585518
Trained batch 661 in epoch 6, gen_loss = 0.8003886324491386, disc_loss = 0.09628382657184702
Trained batch 662 in epoch 6, gen_loss = 0.8000986447071777, disc_loss = 0.09628589977236356
Trained batch 663 in epoch 6, gen_loss = 0.7999610901327736, disc_loss = 0.0962548053385802
Trained batch 664 in epoch 6, gen_loss = 0.800123596684377, disc_loss = 0.09617744509438823
Trained batch 665 in epoch 6, gen_loss = 0.7999491975740628, disc_loss = 0.09615718869788868
Trained batch 666 in epoch 6, gen_loss = 0.7998721930666127, disc_loss = 0.09614026098549813
Trained batch 667 in epoch 6, gen_loss = 0.799897126675009, disc_loss = 0.09611031893796906
Trained batch 668 in epoch 6, gen_loss = 0.7999524065642791, disc_loss = 0.09602167383281818
Trained batch 669 in epoch 6, gen_loss = 0.7997017214992153, disc_loss = 0.09603242534421273
Trained batch 670 in epoch 6, gen_loss = 0.7997470012631395, disc_loss = 0.09597905753555135
Trained batch 671 in epoch 6, gen_loss = 0.800094809072713, disc_loss = 0.09617751792982399
Trained batch 672 in epoch 6, gen_loss = 0.8000722447352104, disc_loss = 0.09610807182707369
Trained batch 673 in epoch 6, gen_loss = 0.8000054487223441, disc_loss = 0.09602278864525192
Trained batch 674 in epoch 6, gen_loss = 0.8001731321105251, disc_loss = 0.09591746918029255
Trained batch 675 in epoch 6, gen_loss = 0.8000589460575369, disc_loss = 0.09582155556610879
Trained batch 676 in epoch 6, gen_loss = 0.8002276777604834, disc_loss = 0.09571399647560923
Trained batch 677 in epoch 6, gen_loss = 0.8001684611086297, disc_loss = 0.09563345439556249
Trained batch 678 in epoch 6, gen_loss = 0.7999827436477341, disc_loss = 0.09564067488632251
Trained batch 679 in epoch 6, gen_loss = 0.8003601219285937, disc_loss = 0.09580154267194517
Trained batch 680 in epoch 6, gen_loss = 0.800151646093475, disc_loss = 0.09585841612209307
Trained batch 681 in epoch 6, gen_loss = 0.799696366283551, disc_loss = 0.09611850895555663
Trained batch 682 in epoch 6, gen_loss = 0.7993917395394857, disc_loss = 0.09610360452297143
Trained batch 683 in epoch 6, gen_loss = 0.7999111811319987, disc_loss = 0.0964431041328792
Trained batch 684 in epoch 6, gen_loss = 0.799994072774901, disc_loss = 0.09634409955546369
Trained batch 685 in epoch 6, gen_loss = 0.7998565736039387, disc_loss = 0.09624681096665191
Trained batch 686 in epoch 6, gen_loss = 0.7997973995958353, disc_loss = 0.09614790697057435
Trained batch 687 in epoch 6, gen_loss = 0.7994348455307095, disc_loss = 0.0962673505459544
Trained batch 688 in epoch 6, gen_loss = 0.7994345584870769, disc_loss = 0.0964305235264912
Trained batch 689 in epoch 6, gen_loss = 0.799432692234067, disc_loss = 0.09646141390599634
Trained batch 690 in epoch 6, gen_loss = 0.7989596727960534, disc_loss = 0.09671062752658396
Trained batch 691 in epoch 6, gen_loss = 0.798726065052038, disc_loss = 0.09666410778417667
Trained batch 692 in epoch 6, gen_loss = 0.7994276937984285, disc_loss = 0.09676042214992844
Trained batch 693 in epoch 6, gen_loss = 0.7994702385378846, disc_loss = 0.09674153653824277
Trained batch 694 in epoch 6, gen_loss = 0.7991537918289788, disc_loss = 0.09681994883651784
Trained batch 695 in epoch 6, gen_loss = 0.7990125551305968, disc_loss = 0.09678552495369196
Trained batch 696 in epoch 6, gen_loss = 0.7993833329448399, disc_loss = 0.0968915170494205
Trained batch 697 in epoch 6, gen_loss = 0.7995255307686705, disc_loss = 0.09690618005589206
Trained batch 698 in epoch 6, gen_loss = 0.7991372798815988, disc_loss = 0.09704112930647038
Trained batch 699 in epoch 6, gen_loss = 0.7991791817971639, disc_loss = 0.09699189780812179
Trained batch 700 in epoch 6, gen_loss = 0.7994149483729701, disc_loss = 0.0969254111315784
Trained batch 701 in epoch 6, gen_loss = 0.7993363289751558, disc_loss = 0.09686358869234976
Trained batch 702 in epoch 6, gen_loss = 0.799381908956666, disc_loss = 0.09678033326790902
Trained batch 703 in epoch 6, gen_loss = 0.7991563677787781, disc_loss = 0.09677755921306512
Trained batch 704 in epoch 6, gen_loss = 0.7991276330981695, disc_loss = 0.0967711523888593
Trained batch 705 in epoch 6, gen_loss = 0.7995925587061107, disc_loss = 0.09674707485399824
Trained batch 706 in epoch 6, gen_loss = 0.7994567072374649, disc_loss = 0.09666388235522548
Trained batch 707 in epoch 6, gen_loss = 0.799355976578206, disc_loss = 0.09658375837298183
Trained batch 708 in epoch 6, gen_loss = 0.7992618940612998, disc_loss = 0.0965572954280294
Trained batch 709 in epoch 6, gen_loss = 0.7994764861926227, disc_loss = 0.09651173385988239
Trained batch 710 in epoch 6, gen_loss = 0.7994249130267802, disc_loss = 0.09645210464030463
Trained batch 711 in epoch 6, gen_loss = 0.79946996171153, disc_loss = 0.09634919251378081
Trained batch 712 in epoch 6, gen_loss = 0.7996009143505658, disc_loss = 0.09628374213914466
Trained batch 713 in epoch 6, gen_loss = 0.7998041717612109, disc_loss = 0.09618947138691566
Trained batch 714 in epoch 6, gen_loss = 0.7996246582144624, disc_loss = 0.09617694765589871
Trained batch 715 in epoch 6, gen_loss = 0.7991684396340194, disc_loss = 0.09624535514707755
Trained batch 716 in epoch 6, gen_loss = 0.7988509445177129, disc_loss = 0.09625697392850824
Trained batch 717 in epoch 6, gen_loss = 0.7990455955349968, disc_loss = 0.0963487190254095
Trained batch 718 in epoch 6, gen_loss = 0.798741918197096, disc_loss = 0.09632484852407588
Trained batch 719 in epoch 6, gen_loss = 0.7986771094302336, disc_loss = 0.0963023200346571
Trained batch 720 in epoch 6, gen_loss = 0.7982061430088525, disc_loss = 0.09641018845967628
Trained batch 721 in epoch 6, gen_loss = 0.798312268759075, disc_loss = 0.09649438240985873
Trained batch 722 in epoch 6, gen_loss = 0.7984653279329567, disc_loss = 0.0964293719899234
Trained batch 723 in epoch 6, gen_loss = 0.7986549451864885, disc_loss = 0.09631200506254126
Trained batch 724 in epoch 6, gen_loss = 0.7984222538717862, disc_loss = 0.09634125504000433
Trained batch 725 in epoch 6, gen_loss = 0.7983395780742004, disc_loss = 0.09632309876156575
Trained batch 726 in epoch 6, gen_loss = 0.7982612647413387, disc_loss = 0.09625564126151792
Trained batch 727 in epoch 6, gen_loss = 0.7982108608543218, disc_loss = 0.09619299450295639
Trained batch 728 in epoch 6, gen_loss = 0.7986876381604596, disc_loss = 0.09620124791507367
Trained batch 729 in epoch 6, gen_loss = 0.799020244732295, disc_loss = 0.09609689727323513
Trained batch 730 in epoch 6, gen_loss = 0.7987250691399529, disc_loss = 0.0961601930108589
Trained batch 731 in epoch 6, gen_loss = 0.7990459337260554, disc_loss = 0.09605339842293757
Trained batch 732 in epoch 6, gen_loss = 0.7992571862300129, disc_loss = 0.09595525292184148
Trained batch 733 in epoch 6, gen_loss = 0.7995541659297996, disc_loss = 0.09592942990951382
Trained batch 734 in epoch 6, gen_loss = 0.7992389291322151, disc_loss = 0.09599109829283085
Trained batch 735 in epoch 6, gen_loss = 0.7993927439269812, disc_loss = 0.0959324072641523
Trained batch 736 in epoch 6, gen_loss = 0.7995273790333617, disc_loss = 0.09588185351043738
Trained batch 737 in epoch 6, gen_loss = 0.7992758993210831, disc_loss = 0.09590702643239402
Trained batch 738 in epoch 6, gen_loss = 0.7995656231904708, disc_loss = 0.09585868229986205
Trained batch 739 in epoch 6, gen_loss = 0.7995118801658218, disc_loss = 0.0958006029344491
Trained batch 740 in epoch 6, gen_loss = 0.7993669263747057, disc_loss = 0.0958354039401741
Trained batch 741 in epoch 6, gen_loss = 0.7993346801343953, disc_loss = 0.09581749693985095
Trained batch 742 in epoch 6, gen_loss = 0.7992379549855659, disc_loss = 0.09577042862151225
Trained batch 743 in epoch 6, gen_loss = 0.7996578431257637, disc_loss = 0.09570183898873066
Trained batch 744 in epoch 6, gen_loss = 0.7996103310745034, disc_loss = 0.09565327698552369
Trained batch 745 in epoch 6, gen_loss = 0.7998825859767822, disc_loss = 0.09554641026673943
Trained batch 746 in epoch 6, gen_loss = 0.8001180823388668, disc_loss = 0.09552166904191894
Trained batch 747 in epoch 6, gen_loss = 0.8003034541473032, disc_loss = 0.09541529936486864
Trained batch 748 in epoch 6, gen_loss = 0.8001117251107148, disc_loss = 0.0954343248084088
Trained batch 749 in epoch 6, gen_loss = 0.7998434295654296, disc_loss = 0.09550646381080151
Trained batch 750 in epoch 6, gen_loss = 0.7998587937551872, disc_loss = 0.09543741889764243
Trained batch 751 in epoch 6, gen_loss = 0.7998422527725392, disc_loss = 0.09545549111777639
Trained batch 752 in epoch 6, gen_loss = 0.8000912731228913, disc_loss = 0.09536738922030406
Trained batch 753 in epoch 6, gen_loss = 0.7997646877240755, disc_loss = 0.09554198246686386
Trained batch 754 in epoch 6, gen_loss = 0.7998722112731428, disc_loss = 0.09544773313235368
Trained batch 755 in epoch 6, gen_loss = 0.8004302754603997, disc_loss = 0.09553343791110569
Trained batch 756 in epoch 6, gen_loss = 0.800000814812029, disc_loss = 0.0956349367770407
Trained batch 757 in epoch 6, gen_loss = 0.8000339772896276, disc_loss = 0.0955452419507826
Trained batch 758 in epoch 6, gen_loss = 0.8002713300650927, disc_loss = 0.09545870617090949
Trained batch 759 in epoch 6, gen_loss = 0.8004301210767344, disc_loss = 0.09539334615692496
Trained batch 760 in epoch 6, gen_loss = 0.8005767621285969, disc_loss = 0.09530368498214441
Trained batch 761 in epoch 6, gen_loss = 0.8005864192338128, disc_loss = 0.09522302099686908
Trained batch 762 in epoch 6, gen_loss = 0.8009815276215929, disc_loss = 0.09512804099755315
Trained batch 763 in epoch 6, gen_loss = 0.8013650722684661, disc_loss = 0.09511054426929011
Trained batch 764 in epoch 6, gen_loss = 0.8011296417198929, disc_loss = 0.09510430235634831
Trained batch 765 in epoch 6, gen_loss = 0.8008112214875284, disc_loss = 0.0951402329428817
Trained batch 766 in epoch 6, gen_loss = 0.8011671373088792, disc_loss = 0.0952298827590773
Trained batch 767 in epoch 6, gen_loss = 0.8017795118503273, disc_loss = 0.09516175383032532
Trained batch 768 in epoch 6, gen_loss = 0.8018378195278977, disc_loss = 0.09507112928529322
Trained batch 769 in epoch 6, gen_loss = 0.8018806723031131, disc_loss = 0.09496777313700938
Trained batch 770 in epoch 6, gen_loss = 0.802037406988181, disc_loss = 0.09487636103361227
Trained batch 771 in epoch 6, gen_loss = 0.8018407184688539, disc_loss = 0.09486376891911531
Trained batch 772 in epoch 6, gen_loss = 0.801852196108015, disc_loss = 0.09480130017155548
Trained batch 773 in epoch 6, gen_loss = 0.8017794459827187, disc_loss = 0.09479571626827275
Trained batch 774 in epoch 6, gen_loss = 0.8016456183310477, disc_loss = 0.09479796770239068
Trained batch 775 in epoch 6, gen_loss = 0.8017794499845848, disc_loss = 0.0946968384051081
Trained batch 776 in epoch 6, gen_loss = 0.8023000727749239, disc_loss = 0.0946089598929157
Trained batch 777 in epoch 6, gen_loss = 0.8022358445857668, disc_loss = 0.09453378180472856
Trained batch 778 in epoch 6, gen_loss = 0.8027278317260498, disc_loss = 0.09443807138419388
Trained batch 779 in epoch 6, gen_loss = 0.8026075134674708, disc_loss = 0.09440141594729935
Trained batch 780 in epoch 6, gen_loss = 0.8024308923417262, disc_loss = 0.09441922362130636
Trained batch 781 in epoch 6, gen_loss = 0.8025635173711021, disc_loss = 0.09444541368238113
Trained batch 782 in epoch 6, gen_loss = 0.8024754112403207, disc_loss = 0.09442250990447984
Trained batch 783 in epoch 6, gen_loss = 0.8020387177488634, disc_loss = 0.09459215895230026
Trained batch 784 in epoch 6, gen_loss = 0.8020684304131065, disc_loss = 0.09473666742705046
Trained batch 785 in epoch 6, gen_loss = 0.8019772896557363, disc_loss = 0.09470733331336283
Trained batch 786 in epoch 6, gen_loss = 0.801728116852507, disc_loss = 0.09476833613861584
Trained batch 787 in epoch 6, gen_loss = 0.8016061370218466, disc_loss = 0.09472498781199042
Trained batch 788 in epoch 6, gen_loss = 0.8021003854365403, disc_loss = 0.09475431410319565
Trained batch 789 in epoch 6, gen_loss = 0.8023158405023285, disc_loss = 0.09467836979988821
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.5986384749412537, disc_loss = 0.12848232686519623
Trained batch 1 in epoch 7, gen_loss = 0.724097341299057, disc_loss = 0.08307816088199615
Trained batch 2 in epoch 7, gen_loss = 0.7795558969179789, disc_loss = 0.08722574512163798
Trained batch 3 in epoch 7, gen_loss = 0.7491433173418045, disc_loss = 0.09119218029081821
Trained batch 4 in epoch 7, gen_loss = 0.7291479587554932, disc_loss = 0.09244351238012313
Trained batch 5 in epoch 7, gen_loss = 0.7169586221377054, disc_loss = 0.08999878913164139
Trained batch 6 in epoch 7, gen_loss = 0.7506929295403617, disc_loss = 0.08725688393626894
Trained batch 7 in epoch 7, gen_loss = 0.7642825096845627, disc_loss = 0.07812146563082933
Trained batch 8 in epoch 7, gen_loss = 0.7485798597335815, disc_loss = 0.08526581443018383
Trained batch 9 in epoch 7, gen_loss = 0.7517379522323608, disc_loss = 0.08246007412672043
Trained batch 10 in epoch 7, gen_loss = 0.7774348475716331, disc_loss = 0.08689633011817932
Trained batch 11 in epoch 7, gen_loss = 0.773758148153623, disc_loss = 0.08811656882365544
Trained batch 12 in epoch 7, gen_loss = 0.7906972078176645, disc_loss = 0.08234372212050053
Trained batch 13 in epoch 7, gen_loss = 0.7855123451777867, disc_loss = 0.08239711974082249
Trained batch 14 in epoch 7, gen_loss = 0.7714033404986064, disc_loss = 0.08287490550428629
Trained batch 15 in epoch 7, gen_loss = 0.7779680490493774, disc_loss = 0.08740419748937711
Trained batch 16 in epoch 7, gen_loss = 0.7879055107341093, disc_loss = 0.08574162922142183
Trained batch 17 in epoch 7, gen_loss = 0.7762391202979617, disc_loss = 0.08631230823488699
Trained batch 18 in epoch 7, gen_loss = 0.7815809187136198, disc_loss = 0.08249013983693562
Trained batch 19 in epoch 7, gen_loss = 0.7968252956867218, disc_loss = 0.07923558945767581
Trained batch 20 in epoch 7, gen_loss = 0.7967686028707595, disc_loss = 0.07761464742500157
Trained batch 21 in epoch 7, gen_loss = 0.7896316701715643, disc_loss = 0.07666279862380841
Trained batch 22 in epoch 7, gen_loss = 0.784995612890824, disc_loss = 0.07684296705638585
Trained batch 23 in epoch 7, gen_loss = 0.7802250037590662, disc_loss = 0.07595123548526317
Trained batch 24 in epoch 7, gen_loss = 0.7825003409385681, disc_loss = 0.07585965346544982
Trained batch 25 in epoch 7, gen_loss = 0.7823940951090592, disc_loss = 0.07411827143424979
Trained batch 26 in epoch 7, gen_loss = 0.7970352945504365, disc_loss = 0.07387409217793632
Trained batch 27 in epoch 7, gen_loss = 0.8030812335865838, disc_loss = 0.07184235122986138
Trained batch 28 in epoch 7, gen_loss = 0.8005432322107512, disc_loss = 0.07457447061636324
Trained batch 29 in epoch 7, gen_loss = 0.8021091123421987, disc_loss = 0.07329450023050109
Trained batch 30 in epoch 7, gen_loss = 0.8063153586079997, disc_loss = 0.07166777956750124
Trained batch 31 in epoch 7, gen_loss = 0.8074226342141628, disc_loss = 0.07264628700795583
Trained batch 32 in epoch 7, gen_loss = 0.8063995982661392, disc_loss = 0.07281817380113131
Trained batch 33 in epoch 7, gen_loss = 0.801125638625201, disc_loss = 0.07279616547748446
Trained batch 34 in epoch 7, gen_loss = 0.7953978419303894, disc_loss = 0.07295189369469882
Trained batch 35 in epoch 7, gen_loss = 0.8126053263743719, disc_loss = 0.07772226836014953
Trained batch 36 in epoch 7, gen_loss = 0.8070437505438521, disc_loss = 0.07875534184780475
Trained batch 37 in epoch 7, gen_loss = 0.8044303483084628, disc_loss = 0.0782983855736491
Trained batch 38 in epoch 7, gen_loss = 0.8008867441079556, disc_loss = 0.07826130433628957
Trained batch 39 in epoch 7, gen_loss = 0.7970908105373382, disc_loss = 0.07784949864726513
Trained batch 40 in epoch 7, gen_loss = 0.7963114046468968, disc_loss = 0.07868978733242285
Trained batch 41 in epoch 7, gen_loss = 0.7999958339191618, disc_loss = 0.08037896762557682
Trained batch 42 in epoch 7, gen_loss = 0.80448229091112, disc_loss = 0.08006823675836934
Trained batch 43 in epoch 7, gen_loss = 0.8001042875376615, disc_loss = 0.08221404176120731
Trained batch 44 in epoch 7, gen_loss = 0.8001532634099324, disc_loss = 0.08117886307752795
Trained batch 45 in epoch 7, gen_loss = 0.7996679285298223, disc_loss = 0.08055751250408914
Trained batch 46 in epoch 7, gen_loss = 0.8049862410159822, disc_loss = 0.08250241011301888
Trained batch 47 in epoch 7, gen_loss = 0.8018770565589269, disc_loss = 0.08254957181634381
Trained batch 48 in epoch 7, gen_loss = 0.7998347002632764, disc_loss = 0.0816742880269885
Trained batch 49 in epoch 7, gen_loss = 0.7990984439849853, disc_loss = 0.08128794243559241
Trained batch 50 in epoch 7, gen_loss = 0.799069042299308, disc_loss = 0.08039387014201459
Trained batch 51 in epoch 7, gen_loss = 0.8043831059565911, disc_loss = 0.08132536657369481
Trained batch 52 in epoch 7, gen_loss = 0.8014308349141535, disc_loss = 0.08089315798133612
Trained batch 53 in epoch 7, gen_loss = 0.7976187003983392, disc_loss = 0.08213307975825888
Trained batch 54 in epoch 7, gen_loss = 0.8007638085972179, disc_loss = 0.08120331410318612
Trained batch 55 in epoch 7, gen_loss = 0.795348082269941, disc_loss = 0.08246369046225611
Trained batch 56 in epoch 7, gen_loss = 0.7917480301438716, disc_loss = 0.08352726826999794
Trained batch 57 in epoch 7, gen_loss = 0.793619546396979, disc_loss = 0.08385666843567943
Trained batch 58 in epoch 7, gen_loss = 0.791248507418875, disc_loss = 0.08377458784981805
Trained batch 59 in epoch 7, gen_loss = 0.7909525364637375, disc_loss = 0.08302936422017713
Trained batch 60 in epoch 7, gen_loss = 0.7949235507699309, disc_loss = 0.08337130011288357
Trained batch 61 in epoch 7, gen_loss = 0.7930649124806927, disc_loss = 0.08362752071491653
Trained batch 62 in epoch 7, gen_loss = 0.7905393261758108, disc_loss = 0.08443508774692578
Trained batch 63 in epoch 7, gen_loss = 0.7910614861175418, disc_loss = 0.08403274927695747
Trained batch 64 in epoch 7, gen_loss = 0.7912016474283659, disc_loss = 0.08323516580634392
Trained batch 65 in epoch 7, gen_loss = 0.7880729193037207, disc_loss = 0.08300307572283076
Trained batch 66 in epoch 7, gen_loss = 0.7879082293652776, disc_loss = 0.08305129262882827
Trained batch 67 in epoch 7, gen_loss = 0.7894846726866329, disc_loss = 0.0823553398333709
Trained batch 68 in epoch 7, gen_loss = 0.7880521615346273, disc_loss = 0.08224370653160672
Trained batch 69 in epoch 7, gen_loss = 0.7909286413873945, disc_loss = 0.08156326411824141
Trained batch 70 in epoch 7, gen_loss = 0.7954588591212958, disc_loss = 0.08074852896355827
Trained batch 71 in epoch 7, gen_loss = 0.7967626170979606, disc_loss = 0.07993573745867859
Trained batch 72 in epoch 7, gen_loss = 0.7912595472107194, disc_loss = 0.08304000848725643
Trained batch 73 in epoch 7, gen_loss = 0.7927014896193066, disc_loss = 0.08268076019059564
Trained batch 74 in epoch 7, gen_loss = 0.7968171838919321, disc_loss = 0.08502200959871213
Trained batch 75 in epoch 7, gen_loss = 0.7972689141568384, disc_loss = 0.08443595247196131
Trained batch 76 in epoch 7, gen_loss = 0.795792930699014, disc_loss = 0.0853577878737411
Trained batch 77 in epoch 7, gen_loss = 0.7962406006379005, disc_loss = 0.08514476313184087
Trained batch 78 in epoch 7, gen_loss = 0.7965895884399172, disc_loss = 0.08538464818715671
Trained batch 79 in epoch 7, gen_loss = 0.7949229490011931, disc_loss = 0.08584524806356057
Trained batch 80 in epoch 7, gen_loss = 0.7945990352718918, disc_loss = 0.08564422402622891
Trained batch 81 in epoch 7, gen_loss = 0.7958047924245276, disc_loss = 0.08516766738555417
Trained batch 82 in epoch 7, gen_loss = 0.7968226480914886, disc_loss = 0.08447169022163353
Trained batch 83 in epoch 7, gen_loss = 0.7982411203639848, disc_loss = 0.08415655564472434
Trained batch 84 in epoch 7, gen_loss = 0.7973965164493112, disc_loss = 0.08392635683583863
Trained batch 85 in epoch 7, gen_loss = 0.7951772618432378, disc_loss = 0.08383991659164082
Trained batch 86 in epoch 7, gen_loss = 0.7958305872034752, disc_loss = 0.08337873840254956
Trained batch 87 in epoch 7, gen_loss = 0.798453323204409, disc_loss = 0.0829563196642663
Trained batch 88 in epoch 7, gen_loss = 0.8013604802362034, disc_loss = 0.08314332398429011
Trained batch 89 in epoch 7, gen_loss = 0.798916807770729, disc_loss = 0.0864094687729246
Trained batch 90 in epoch 7, gen_loss = 0.8026703979287829, disc_loss = 0.08757712076940052
Trained batch 91 in epoch 7, gen_loss = 0.8033940575045088, disc_loss = 0.08702473851609165
Trained batch 92 in epoch 7, gen_loss = 0.8039518931219655, disc_loss = 0.0868965355999848
Trained batch 93 in epoch 7, gen_loss = 0.8003862661884186, disc_loss = 0.08875532011362783
Trained batch 94 in epoch 7, gen_loss = 0.8017969197348545, disc_loss = 0.08922617991307849
Trained batch 95 in epoch 7, gen_loss = 0.8012644800667962, disc_loss = 0.08906494615560707
Trained batch 96 in epoch 7, gen_loss = 0.800579584443692, disc_loss = 0.08908526990178627
Trained batch 97 in epoch 7, gen_loss = 0.7981828569757695, disc_loss = 0.08968288184390688
Trained batch 98 in epoch 7, gen_loss = 0.8006242956175948, disc_loss = 0.08921370364612702
Trained batch 99 in epoch 7, gen_loss = 0.8040875002741814, disc_loss = 0.08981911244802177
Trained batch 100 in epoch 7, gen_loss = 0.8019064030434826, disc_loss = 0.09107839754127925
Trained batch 101 in epoch 7, gen_loss = 0.8005822771320156, disc_loss = 0.09068558309409841
Trained batch 102 in epoch 7, gen_loss = 0.7999078072969196, disc_loss = 0.09102762529391398
Trained batch 103 in epoch 7, gen_loss = 0.799526227494845, disc_loss = 0.09099329788631831
Trained batch 104 in epoch 7, gen_loss = 0.7995781384763263, disc_loss = 0.09074414673128299
Trained batch 105 in epoch 7, gen_loss = 0.7979160926814349, disc_loss = 0.09117960103102168
Trained batch 106 in epoch 7, gen_loss = 0.8000226196284607, disc_loss = 0.09114467696434705
Trained batch 107 in epoch 7, gen_loss = 0.7996893759678911, disc_loss = 0.09072573233775243
Trained batch 108 in epoch 7, gen_loss = 0.8000032899029758, disc_loss = 0.09063298678145222
Trained batch 109 in epoch 7, gen_loss = 0.7987229983914982, disc_loss = 0.09090499985455112
Trained batch 110 in epoch 7, gen_loss = 0.8019043505191803, disc_loss = 0.09138973915597072
Trained batch 111 in epoch 7, gen_loss = 0.7994213085621595, disc_loss = 0.09204019565368071
Trained batch 112 in epoch 7, gen_loss = 0.7997736801615859, disc_loss = 0.09152430944573299
Trained batch 113 in epoch 7, gen_loss = 0.799482027428192, disc_loss = 0.09108547865527503
Trained batch 114 in epoch 7, gen_loss = 0.8016193076320316, disc_loss = 0.0909547122195363
Trained batch 115 in epoch 7, gen_loss = 0.8012390226639551, disc_loss = 0.09049291108285301
Trained batch 116 in epoch 7, gen_loss = 0.7995415790977641, disc_loss = 0.09036067729163119
Trained batch 117 in epoch 7, gen_loss = 0.798873950616788, disc_loss = 0.09065628773927437
Trained batch 118 in epoch 7, gen_loss = 0.8000278951240187, disc_loss = 0.09018105220738329
Trained batch 119 in epoch 7, gen_loss = 0.799409831315279, disc_loss = 0.09070096092764288
Trained batch 120 in epoch 7, gen_loss = 0.7983888390143056, disc_loss = 0.09065100823890818
Trained batch 121 in epoch 7, gen_loss = 0.797825922487212, disc_loss = 0.09025175196927834
Trained batch 122 in epoch 7, gen_loss = 0.7998719949547838, disc_loss = 0.09075627990097292
Trained batch 123 in epoch 7, gen_loss = 0.8005093737475334, disc_loss = 0.09015594998885307
Trained batch 124 in epoch 7, gen_loss = 0.7984474952220917, disc_loss = 0.09060970842093229
Trained batch 125 in epoch 7, gen_loss = 0.7982547853201155, disc_loss = 0.09038172696997958
Trained batch 126 in epoch 7, gen_loss = 0.7998160224730574, disc_loss = 0.09061153068053206
Trained batch 127 in epoch 7, gen_loss = 0.7980049562174827, disc_loss = 0.09093656401819317
Trained batch 128 in epoch 7, gen_loss = 0.7981810812340226, disc_loss = 0.09092083018157603
Trained batch 129 in epoch 7, gen_loss = 0.7998437186846367, disc_loss = 0.09051372912497474
Trained batch 130 in epoch 7, gen_loss = 0.8004983502034922, disc_loss = 0.0902549886279775
Trained batch 131 in epoch 7, gen_loss = 0.7993670758424383, disc_loss = 0.09069452617514992
Trained batch 132 in epoch 7, gen_loss = 0.8019190105728637, disc_loss = 0.09056970075865213
Trained batch 133 in epoch 7, gen_loss = 0.8001980241110076, disc_loss = 0.09042622462443228
Trained batch 134 in epoch 7, gen_loss = 0.8021707625300796, disc_loss = 0.08992753544201454
Trained batch 135 in epoch 7, gen_loss = 0.8034496292033616, disc_loss = 0.08943653108743842
Trained batch 136 in epoch 7, gen_loss = 0.8036155072006866, disc_loss = 0.08924679786483519
Trained batch 137 in epoch 7, gen_loss = 0.8004951481369958, disc_loss = 0.09069797690228923
Trained batch 138 in epoch 7, gen_loss = 0.8030792050224413, disc_loss = 0.09067016461421903
Trained batch 139 in epoch 7, gen_loss = 0.8061465190989631, disc_loss = 0.09098741717503539
Trained batch 140 in epoch 7, gen_loss = 0.8045394378350982, disc_loss = 0.09139328536491656
Trained batch 141 in epoch 7, gen_loss = 0.8038330632196345, disc_loss = 0.09110537338608378
Trained batch 142 in epoch 7, gen_loss = 0.8054472608166141, disc_loss = 0.09216599165742005
Trained batch 143 in epoch 7, gen_loss = 0.8039875717626678, disc_loss = 0.09201629107378216
Trained batch 144 in epoch 7, gen_loss = 0.8026332649691351, disc_loss = 0.0924207802412325
Trained batch 145 in epoch 7, gen_loss = 0.8038978037768847, disc_loss = 0.09245155904161399
Trained batch 146 in epoch 7, gen_loss = 0.8038524843397594, disc_loss = 0.09197616288881927
Trained batch 147 in epoch 7, gen_loss = 0.8034948287783442, disc_loss = 0.09197609212778106
Trained batch 148 in epoch 7, gen_loss = 0.8020456701317089, disc_loss = 0.09213781967484111
Trained batch 149 in epoch 7, gen_loss = 0.8013644297917684, disc_loss = 0.09179947108651201
Trained batch 150 in epoch 7, gen_loss = 0.8029824566367446, disc_loss = 0.09248526967346471
Trained batch 151 in epoch 7, gen_loss = 0.8018230521365216, disc_loss = 0.09270310079017163
Trained batch 152 in epoch 7, gen_loss = 0.8024614468898649, disc_loss = 0.09247112951661442
Trained batch 153 in epoch 7, gen_loss = 0.800295011370213, disc_loss = 0.09278525630399198
Trained batch 154 in epoch 7, gen_loss = 0.8021536894382969, disc_loss = 0.09290820466534745
Trained batch 155 in epoch 7, gen_loss = 0.8000799178695067, disc_loss = 0.09368250003824823
Trained batch 156 in epoch 7, gen_loss = 0.799711702545737, disc_loss = 0.09336131909019818
Trained batch 157 in epoch 7, gen_loss = 0.7997376758463776, disc_loss = 0.09438095348474534
Trained batch 158 in epoch 7, gen_loss = 0.7987538518020941, disc_loss = 0.09476157257321684
Trained batch 159 in epoch 7, gen_loss = 0.7994642758741974, disc_loss = 0.09444304651697166
Trained batch 160 in epoch 7, gen_loss = 0.7991010204235219, disc_loss = 0.09494022555903804
Trained batch 161 in epoch 7, gen_loss = 0.7973671130560063, disc_loss = 0.09548652184161323
Trained batch 162 in epoch 7, gen_loss = 0.7971445799239574, disc_loss = 0.09526078956647337
Trained batch 163 in epoch 7, gen_loss = 0.7992787770018345, disc_loss = 0.09551354012134053
Trained batch 164 in epoch 7, gen_loss = 0.7983288058728882, disc_loss = 0.09564246784218333
Trained batch 165 in epoch 7, gen_loss = 0.7972536641790207, disc_loss = 0.09549265467640326
Trained batch 166 in epoch 7, gen_loss = 0.7984533072588686, disc_loss = 0.09511413367766285
Trained batch 167 in epoch 7, gen_loss = 0.7983037196099758, disc_loss = 0.09502083196726051
Trained batch 168 in epoch 7, gen_loss = 0.7971041743924632, disc_loss = 0.09507957842068736
Trained batch 169 in epoch 7, gen_loss = 0.7964777103241752, disc_loss = 0.09508817994090564
Trained batch 170 in epoch 7, gen_loss = 0.7968179846716206, disc_loss = 0.0949591318123609
Trained batch 171 in epoch 7, gen_loss = 0.7961950754356939, disc_loss = 0.09513519358344723
Trained batch 172 in epoch 7, gen_loss = 0.7957964296630352, disc_loss = 0.09519460905515562
Trained batch 173 in epoch 7, gen_loss = 0.7973265718112047, disc_loss = 0.09552949671794114
Trained batch 174 in epoch 7, gen_loss = 0.7968141257762908, disc_loss = 0.09541454779782466
Trained batch 175 in epoch 7, gen_loss = 0.796023324301297, disc_loss = 0.09541546160207046
Trained batch 176 in epoch 7, gen_loss = 0.7970143224896684, disc_loss = 0.09500798569876427
Trained batch 177 in epoch 7, gen_loss = 0.7956634463554018, disc_loss = 0.0956759970540997
Trained batch 178 in epoch 7, gen_loss = 0.7961940397430398, disc_loss = 0.09558867129845826
Trained batch 179 in epoch 7, gen_loss = 0.7967610688673126, disc_loss = 0.09539923381784723
Trained batch 180 in epoch 7, gen_loss = 0.7961558582703712, disc_loss = 0.09530674262250162
Trained batch 181 in epoch 7, gen_loss = 0.7963315607099742, disc_loss = 0.09493453624136336
Trained batch 182 in epoch 7, gen_loss = 0.7970174894632538, disc_loss = 0.09455065766624252
Trained batch 183 in epoch 7, gen_loss = 0.7961214247929014, disc_loss = 0.09451686906243634
Trained batch 184 in epoch 7, gen_loss = 0.7954551105563705, disc_loss = 0.09457951662810267
Trained batch 185 in epoch 7, gen_loss = 0.7959445985735104, disc_loss = 0.0947824565102897
Trained batch 186 in epoch 7, gen_loss = 0.7967608846763876, disc_loss = 0.09456190972384762
Trained batch 187 in epoch 7, gen_loss = 0.7961670719879739, disc_loss = 0.09466983662779502
Trained batch 188 in epoch 7, gen_loss = 0.7952501888943728, disc_loss = 0.09492245071602089
Trained batch 189 in epoch 7, gen_loss = 0.7953857003073943, disc_loss = 0.09456919142976403
Trained batch 190 in epoch 7, gen_loss = 0.7956109479147726, disc_loss = 0.09469124422706078
Trained batch 191 in epoch 7, gen_loss = 0.7968835732899606, disc_loss = 0.09440698297597312
Trained batch 192 in epoch 7, gen_loss = 0.7954683666711027, disc_loss = 0.09437028671388027
Trained batch 193 in epoch 7, gen_loss = 0.7950099459321228, disc_loss = 0.09427389166001038
Trained batch 194 in epoch 7, gen_loss = 0.795963080571248, disc_loss = 0.09424769249386512
Trained batch 195 in epoch 7, gen_loss = 0.7968107308356129, disc_loss = 0.09436069920716085
Trained batch 196 in epoch 7, gen_loss = 0.7959786334316138, disc_loss = 0.09489514725519164
Trained batch 197 in epoch 7, gen_loss = 0.7960691953247244, disc_loss = 0.0946281387263702
Trained batch 198 in epoch 7, gen_loss = 0.7950449692244506, disc_loss = 0.09530172992647443
Trained batch 199 in epoch 7, gen_loss = 0.7947846741974354, disc_loss = 0.09505405377130956
Trained batch 200 in epoch 7, gen_loss = 0.7951429265352031, disc_loss = 0.09477144612731477
Trained batch 201 in epoch 7, gen_loss = 0.7938288050417853, disc_loss = 0.09529358192374653
Trained batch 202 in epoch 7, gen_loss = 0.7934596857120251, disc_loss = 0.09506768228146684
Trained batch 203 in epoch 7, gen_loss = 0.7931713866544705, disc_loss = 0.0951399426386856
Trained batch 204 in epoch 7, gen_loss = 0.792125121703962, disc_loss = 0.09514825926957333
Trained batch 205 in epoch 7, gen_loss = 0.7926772001009543, disc_loss = 0.09518403651699134
Trained batch 206 in epoch 7, gen_loss = 0.7936126487554559, disc_loss = 0.09482590087963907
Trained batch 207 in epoch 7, gen_loss = 0.7929694994997519, disc_loss = 0.0948876589581442
Trained batch 208 in epoch 7, gen_loss = 0.7925554543876192, disc_loss = 0.09492291303788218
Trained batch 209 in epoch 7, gen_loss = 0.7935142155204501, disc_loss = 0.09492785299551629
Trained batch 210 in epoch 7, gen_loss = 0.7943499942808919, disc_loss = 0.09469260748970142
Trained batch 211 in epoch 7, gen_loss = 0.7929349389840972, disc_loss = 0.09550044208079717
Trained batch 212 in epoch 7, gen_loss = 0.7936800449666842, disc_loss = 0.09515514489298275
Trained batch 213 in epoch 7, gen_loss = 0.7937485712153889, disc_loss = 0.09487886645474305
Trained batch 214 in epoch 7, gen_loss = 0.793804978769879, disc_loss = 0.09476911840137354
Trained batch 215 in epoch 7, gen_loss = 0.795682896066595, disc_loss = 0.09448647408108055
Trained batch 216 in epoch 7, gen_loss = 0.7946441140592373, disc_loss = 0.09478745110384468
Trained batch 217 in epoch 7, gen_loss = 0.7942826676806178, disc_loss = 0.09471578898181746
Trained batch 218 in epoch 7, gen_loss = 0.7940392886122613, disc_loss = 0.09447292653954328
Trained batch 219 in epoch 7, gen_loss = 0.7939265045252714, disc_loss = 0.09419290972450241
Trained batch 220 in epoch 7, gen_loss = 0.7931736953118268, disc_loss = 0.09414629085722687
Trained batch 221 in epoch 7, gen_loss = 0.7944038421721071, disc_loss = 0.094719470155568
Trained batch 222 in epoch 7, gen_loss = 0.7938149745154274, disc_loss = 0.0945091499516849
Trained batch 223 in epoch 7, gen_loss = 0.7925029149545091, disc_loss = 0.09456210357685839
Trained batch 224 in epoch 7, gen_loss = 0.7926940125889248, disc_loss = 0.09457674444135693
Trained batch 225 in epoch 7, gen_loss = 0.7927990204992548, disc_loss = 0.094363467277448
Trained batch 226 in epoch 7, gen_loss = 0.7924636064121902, disc_loss = 0.0942559812899006
Trained batch 227 in epoch 7, gen_loss = 0.7932012941230807, disc_loss = 0.09422669734952874
Trained batch 228 in epoch 7, gen_loss = 0.7927221694887986, disc_loss = 0.09400349727315284
Trained batch 229 in epoch 7, gen_loss = 0.792662094986957, disc_loss = 0.09421733444880533
Trained batch 230 in epoch 7, gen_loss = 0.7912398359992288, disc_loss = 0.09438322796143624
Trained batch 231 in epoch 7, gen_loss = 0.7900882368457729, disc_loss = 0.09503451691828026
Trained batch 232 in epoch 7, gen_loss = 0.7911475027067979, disc_loss = 0.09484365702778613
Trained batch 233 in epoch 7, gen_loss = 0.7923162161794484, disc_loss = 0.0953502823662363
Trained batch 234 in epoch 7, gen_loss = 0.7916862858102677, disc_loss = 0.09568926215251075
Trained batch 235 in epoch 7, gen_loss = 0.7904360865132284, disc_loss = 0.09594035526279802
Trained batch 236 in epoch 7, gen_loss = 0.790112892283669, disc_loss = 0.09579601329417294
Trained batch 237 in epoch 7, gen_loss = 0.7916091925957623, disc_loss = 0.09639692900138867
Trained batch 238 in epoch 7, gen_loss = 0.791515639885699, disc_loss = 0.09655670558636283
Trained batch 239 in epoch 7, gen_loss = 0.7913403950631619, disc_loss = 0.09647076870702828
Trained batch 240 in epoch 7, gen_loss = 0.7903505390610438, disc_loss = 0.0968801877132899
Trained batch 241 in epoch 7, gen_loss = 0.7907332255820597, disc_loss = 0.09729987230875399
Trained batch 242 in epoch 7, gen_loss = 0.7901694602927063, disc_loss = 0.09739394119936866
Trained batch 243 in epoch 7, gen_loss = 0.7895664773026451, disc_loss = 0.09741674594535324
Trained batch 244 in epoch 7, gen_loss = 0.7895915659106507, disc_loss = 0.0971082171577276
Trained batch 245 in epoch 7, gen_loss = 0.789795395320024, disc_loss = 0.09685651981839682
Trained batch 246 in epoch 7, gen_loss = 0.7888812121109441, disc_loss = 0.0973864895091788
Trained batch 247 in epoch 7, gen_loss = 0.7897248986747957, disc_loss = 0.09741404649215721
Trained batch 248 in epoch 7, gen_loss = 0.788694177526068, disc_loss = 0.097632555623939
Trained batch 249 in epoch 7, gen_loss = 0.7884841902256012, disc_loss = 0.09737933212146163
Trained batch 250 in epoch 7, gen_loss = 0.7883447983350412, disc_loss = 0.09714191807322649
Trained batch 251 in epoch 7, gen_loss = 0.7886129196674104, disc_loss = 0.09702335995444585
Trained batch 252 in epoch 7, gen_loss = 0.7889542035434557, disc_loss = 0.09693523487186596
Trained batch 253 in epoch 7, gen_loss = 0.7878316314670983, disc_loss = 0.09719479910838674
Trained batch 254 in epoch 7, gen_loss = 0.7876746617111505, disc_loss = 0.09764338398315743
Trained batch 255 in epoch 7, gen_loss = 0.7873012097552419, disc_loss = 0.09753311980966828
Trained batch 256 in epoch 7, gen_loss = 0.7862363126027445, disc_loss = 0.09777027342091622
Trained batch 257 in epoch 7, gen_loss = 0.7874886827875477, disc_loss = 0.09779451154677789
Trained batch 258 in epoch 7, gen_loss = 0.7866563555356618, disc_loss = 0.09813739402169311
Trained batch 259 in epoch 7, gen_loss = 0.7873760968446731, disc_loss = 0.09797243806533515
Trained batch 260 in epoch 7, gen_loss = 0.7874708378908735, disc_loss = 0.09782637843783673
Trained batch 261 in epoch 7, gen_loss = 0.7873638697707926, disc_loss = 0.09760284153318019
Trained batch 262 in epoch 7, gen_loss = 0.7865467078332212, disc_loss = 0.09786334692964423
Trained batch 263 in epoch 7, gen_loss = 0.7872590420372558, disc_loss = 0.09768972827728387
Trained batch 264 in epoch 7, gen_loss = 0.7870887290756657, disc_loss = 0.09767294362679405
Trained batch 265 in epoch 7, gen_loss = 0.7862314752170018, disc_loss = 0.09756280226576933
Trained batch 266 in epoch 7, gen_loss = 0.7860347135236647, disc_loss = 0.09752026760832089
Trained batch 267 in epoch 7, gen_loss = 0.7861329481672885, disc_loss = 0.09739015654160349
Trained batch 268 in epoch 7, gen_loss = 0.7870782126281342, disc_loss = 0.09717390557134795
Trained batch 269 in epoch 7, gen_loss = 0.7862342958097105, disc_loss = 0.09729480049055483
Trained batch 270 in epoch 7, gen_loss = 0.7858231023668802, disc_loss = 0.0970951897569853
Trained batch 271 in epoch 7, gen_loss = 0.786721234812456, disc_loss = 0.09710517781444222
Trained batch 272 in epoch 7, gen_loss = 0.786126916443472, disc_loss = 0.09703257569067535
Trained batch 273 in epoch 7, gen_loss = 0.7856083009799901, disc_loss = 0.09714626040595183
Trained batch 274 in epoch 7, gen_loss = 0.7858775609189814, disc_loss = 0.09705464464358309
Trained batch 275 in epoch 7, gen_loss = 0.7859879263501236, disc_loss = 0.09684906498717981
Trained batch 276 in epoch 7, gen_loss = 0.7871844766372378, disc_loss = 0.09669545449867899
Trained batch 277 in epoch 7, gen_loss = 0.7871912201102689, disc_loss = 0.09654943368618758
Trained batch 278 in epoch 7, gen_loss = 0.7870610668240482, disc_loss = 0.09638852134387019
Trained batch 279 in epoch 7, gen_loss = 0.786611731350422, disc_loss = 0.09651464997857277
Trained batch 280 in epoch 7, gen_loss = 0.7880523703276475, disc_loss = 0.09670634379153044
Trained batch 281 in epoch 7, gen_loss = 0.7880199942605716, disc_loss = 0.09694678359830104
Trained batch 282 in epoch 7, gen_loss = 0.7866037493249132, disc_loss = 0.09751497242968306
Trained batch 283 in epoch 7, gen_loss = 0.7860732490957623, disc_loss = 0.09765219895339662
Trained batch 284 in epoch 7, gen_loss = 0.7872426870622133, disc_loss = 0.09867379380095946
Trained batch 285 in epoch 7, gen_loss = 0.7864344913017499, disc_loss = 0.09863698833876035
Trained batch 286 in epoch 7, gen_loss = 0.7856689389366721, disc_loss = 0.09882845381398131
Trained batch 287 in epoch 7, gen_loss = 0.785017411224544, disc_loss = 0.09898728983049902
Trained batch 288 in epoch 7, gen_loss = 0.7856381994423982, disc_loss = 0.0991228061686286
Trained batch 289 in epoch 7, gen_loss = 0.7858237179188893, disc_loss = 0.09897145486019295
Trained batch 290 in epoch 7, gen_loss = 0.7852541006512658, disc_loss = 0.09900875841155392
Trained batch 291 in epoch 7, gen_loss = 0.7852478324346346, disc_loss = 0.09902629264860019
Trained batch 292 in epoch 7, gen_loss = 0.7854837056109523, disc_loss = 0.09922715190976045
Trained batch 293 in epoch 7, gen_loss = 0.7845392501881333, disc_loss = 0.09943854280107585
Trained batch 294 in epoch 7, gen_loss = 0.7843351704589391, disc_loss = 0.0992457148224368
Trained batch 295 in epoch 7, gen_loss = 0.7840606345719582, disc_loss = 0.09920754581626907
Trained batch 296 in epoch 7, gen_loss = 0.7837767397313808, disc_loss = 0.09944870045427422
Trained batch 297 in epoch 7, gen_loss = 0.7827635369444853, disc_loss = 0.09992398427574327
Trained batch 298 in epoch 7, gen_loss = 0.7827272720161489, disc_loss = 0.10063974958934811
Trained batch 299 in epoch 7, gen_loss = 0.7824797018369039, disc_loss = 0.10071604073978961
Trained batch 300 in epoch 7, gen_loss = 0.7817324780150505, disc_loss = 0.10099575246229421
Trained batch 301 in epoch 7, gen_loss = 0.7815548927578705, disc_loss = 0.10095257007066678
Trained batch 302 in epoch 7, gen_loss = 0.782330575949288, disc_loss = 0.10158386370074926
Trained batch 303 in epoch 7, gen_loss = 0.7816514868877436, disc_loss = 0.10163552724253877
Trained batch 304 in epoch 7, gen_loss = 0.7815722060985253, disc_loss = 0.10154221569355883
Trained batch 305 in epoch 7, gen_loss = 0.7811167838137134, disc_loss = 0.10152916523500108
Trained batch 306 in epoch 7, gen_loss = 0.7806853752959435, disc_loss = 0.10140388780227992
Trained batch 307 in epoch 7, gen_loss = 0.7808730902222843, disc_loss = 0.10118655839559997
Trained batch 308 in epoch 7, gen_loss = 0.7814950406744257, disc_loss = 0.10112001349950589
Trained batch 309 in epoch 7, gen_loss = 0.7818650562917032, disc_loss = 0.10083995977596891
Trained batch 310 in epoch 7, gen_loss = 0.7816175116986707, disc_loss = 0.10073116413913548
Trained batch 311 in epoch 7, gen_loss = 0.7805890759978539, disc_loss = 0.10105411987154721
Trained batch 312 in epoch 7, gen_loss = 0.7805491253590813, disc_loss = 0.10084592608717112
Trained batch 313 in epoch 7, gen_loss = 0.7799645453501659, disc_loss = 0.10119344814306801
Trained batch 314 in epoch 7, gen_loss = 0.7803442572790479, disc_loss = 0.10115675813267155
Trained batch 315 in epoch 7, gen_loss = 0.7798670835887329, disc_loss = 0.10119023695706
Trained batch 316 in epoch 7, gen_loss = 0.780180918869536, disc_loss = 0.10102288501942383
Trained batch 317 in epoch 7, gen_loss = 0.7802440387272985, disc_loss = 0.10077435801496858
Trained batch 318 in epoch 7, gen_loss = 0.780806945409147, disc_loss = 0.10081380689195518
Trained batch 319 in epoch 7, gen_loss = 0.7804290043190122, disc_loss = 0.1007691858743783
Trained batch 320 in epoch 7, gen_loss = 0.7801045080954412, disc_loss = 0.10066630660535948
Trained batch 321 in epoch 7, gen_loss = 0.7797242689947164, disc_loss = 0.10060309220151686
Trained batch 322 in epoch 7, gen_loss = 0.7803015959890265, disc_loss = 0.10070290630423802
Trained batch 323 in epoch 7, gen_loss = 0.7802810534650897, disc_loss = 0.10064433615677702
Trained batch 324 in epoch 7, gen_loss = 0.7798014994767996, disc_loss = 0.1005895420622367
Trained batch 325 in epoch 7, gen_loss = 0.7792686979097823, disc_loss = 0.10046713065036053
Trained batch 326 in epoch 7, gen_loss = 0.7793748912825862, disc_loss = 0.10069494452384452
Trained batch 327 in epoch 7, gen_loss = 0.7784689164198026, disc_loss = 0.10084997423606493
Trained batch 328 in epoch 7, gen_loss = 0.7787860795900814, disc_loss = 0.1006197446453354
Trained batch 329 in epoch 7, gen_loss = 0.7783292771288843, disc_loss = 0.10063595468121948
Trained batch 330 in epoch 7, gen_loss = 0.7787061195899353, disc_loss = 0.10048462617073174
Trained batch 331 in epoch 7, gen_loss = 0.778578399265387, disc_loss = 0.10036930050252073
Trained batch 332 in epoch 7, gen_loss = 0.7786934995973432, disc_loss = 0.10048640108815543
Trained batch 333 in epoch 7, gen_loss = 0.7782882756280328, disc_loss = 0.1005489298750362
Trained batch 334 in epoch 7, gen_loss = 0.7783830332222269, disc_loss = 0.10038299497161339
Trained batch 335 in epoch 7, gen_loss = 0.7794897459624779, disc_loss = 0.10060644836076313
Trained batch 336 in epoch 7, gen_loss = 0.7787508535632748, disc_loss = 0.10068741178786719
Trained batch 337 in epoch 7, gen_loss = 0.7781895895505092, disc_loss = 0.10075692218568551
Trained batch 338 in epoch 7, gen_loss = 0.7786005903310129, disc_loss = 0.10129690832928219
Trained batch 339 in epoch 7, gen_loss = 0.778542851963464, disc_loss = 0.10134519289302475
Trained batch 340 in epoch 7, gen_loss = 0.7780839707320037, disc_loss = 0.10137707625360083
Trained batch 341 in epoch 7, gen_loss = 0.7777776309446982, disc_loss = 0.1015198376378295
Trained batch 342 in epoch 7, gen_loss = 0.7773567081019065, disc_loss = 0.10156408980836326
Trained batch 343 in epoch 7, gen_loss = 0.7770159115451712, disc_loss = 0.10151821995413927
Trained batch 344 in epoch 7, gen_loss = 0.7768170483734297, disc_loss = 0.10157643125756927
Trained batch 345 in epoch 7, gen_loss = 0.7771296124754613, disc_loss = 0.10153996041098426
Trained batch 346 in epoch 7, gen_loss = 0.7768999539981314, disc_loss = 0.10153130045756482
Trained batch 347 in epoch 7, gen_loss = 0.7769718597503914, disc_loss = 0.10134282482295544
Trained batch 348 in epoch 7, gen_loss = 0.7767003138461563, disc_loss = 0.10147425153407463
Trained batch 349 in epoch 7, gen_loss = 0.776418793797493, disc_loss = 0.10128399575395243
Trained batch 350 in epoch 7, gen_loss = 0.7772085808451019, disc_loss = 0.10124573751519887
Trained batch 351 in epoch 7, gen_loss = 0.7769597791643306, disc_loss = 0.10108432465825569
Trained batch 352 in epoch 7, gen_loss = 0.7767837833581498, disc_loss = 0.10091969985039984
Trained batch 353 in epoch 7, gen_loss = 0.7768972683592704, disc_loss = 0.1008021828671128
Trained batch 354 in epoch 7, gen_loss = 0.7769289015884131, disc_loss = 0.10086326841527307
Trained batch 355 in epoch 7, gen_loss = 0.776895788362187, disc_loss = 0.10073572883821941
Trained batch 356 in epoch 7, gen_loss = 0.7764115658293919, disc_loss = 0.1010187345162994
Trained batch 357 in epoch 7, gen_loss = 0.7754754678830088, disc_loss = 0.10136483977002471
Trained batch 358 in epoch 7, gen_loss = 0.7778744934993203, disc_loss = 0.10198842500619237
Trained batch 359 in epoch 7, gen_loss = 0.7776556606094043, disc_loss = 0.10197850148090058
Trained batch 360 in epoch 7, gen_loss = 0.7770750355852608, disc_loss = 0.1019740187127009
Trained batch 361 in epoch 7, gen_loss = 0.7773405981985904, disc_loss = 0.10221595908849608
Trained batch 362 in epoch 7, gen_loss = 0.7770617720837764, disc_loss = 0.10213203901635386
Trained batch 363 in epoch 7, gen_loss = 0.7773104025112404, disc_loss = 0.10215321540382209
Trained batch 364 in epoch 7, gen_loss = 0.77732523565423, disc_loss = 0.10204654949372761
Trained batch 365 in epoch 7, gen_loss = 0.7774636950649199, disc_loss = 0.10187196966688164
Trained batch 366 in epoch 7, gen_loss = 0.7776451401554596, disc_loss = 0.10181238958028421
Trained batch 367 in epoch 7, gen_loss = 0.778290843024202, disc_loss = 0.10177296111562653
Trained batch 368 in epoch 7, gen_loss = 0.7782334796781463, disc_loss = 0.10160423214559956
Trained batch 369 in epoch 7, gen_loss = 0.7783199403737042, disc_loss = 0.10144698419482322
Trained batch 370 in epoch 7, gen_loss = 0.7788262074848391, disc_loss = 0.10123753311699935
Trained batch 371 in epoch 7, gen_loss = 0.7788355984995442, disc_loss = 0.10108056937855098
Trained batch 372 in epoch 7, gen_loss = 0.7787612150885145, disc_loss = 0.10100521505797837
Trained batch 373 in epoch 7, gen_loss = 0.7789466111736502, disc_loss = 0.1010519179968751
Trained batch 374 in epoch 7, gen_loss = 0.7792010542551676, disc_loss = 0.10084907812873523
Trained batch 375 in epoch 7, gen_loss = 0.7789028676900458, disc_loss = 0.10093285407910639
Trained batch 376 in epoch 7, gen_loss = 0.778738114340552, disc_loss = 0.10121262918377112
Trained batch 377 in epoch 7, gen_loss = 0.7784250291882369, disc_loss = 0.10111933417381748
Trained batch 378 in epoch 7, gen_loss = 0.7786146083104579, disc_loss = 0.10092299230062553
Trained batch 379 in epoch 7, gen_loss = 0.7791078760435707, disc_loss = 0.10087871183886339
Trained batch 380 in epoch 7, gen_loss = 0.7787184112966843, disc_loss = 0.10092696133913018
Trained batch 381 in epoch 7, gen_loss = 0.7791658104714299, disc_loss = 0.10078033131025536
Trained batch 382 in epoch 7, gen_loss = 0.7787841281442667, disc_loss = 0.10079695493488648
Trained batch 383 in epoch 7, gen_loss = 0.7792352065443993, disc_loss = 0.10058253053769779
Trained batch 384 in epoch 7, gen_loss = 0.779042720949495, disc_loss = 0.10057119730037528
Trained batch 385 in epoch 7, gen_loss = 0.7800337868342128, disc_loss = 0.10059683670535916
Trained batch 386 in epoch 7, gen_loss = 0.7799164395615727, disc_loss = 0.1004328725219389
Trained batch 387 in epoch 7, gen_loss = 0.7798017421641301, disc_loss = 0.10044143867400504
Trained batch 388 in epoch 7, gen_loss = 0.7794166222636069, disc_loss = 0.1005266858480277
Trained batch 389 in epoch 7, gen_loss = 0.7786115580644363, disc_loss = 0.10062588010078821
Trained batch 390 in epoch 7, gen_loss = 0.7794131606131258, disc_loss = 0.10121229710176473
Trained batch 391 in epoch 7, gen_loss = 0.7793634352939469, disc_loss = 0.10105680728483261
Trained batch 392 in epoch 7, gen_loss = 0.7790681050933954, disc_loss = 0.10100773787339225
Trained batch 393 in epoch 7, gen_loss = 0.7790874616446228, disc_loss = 0.10088445721808727
Trained batch 394 in epoch 7, gen_loss = 0.7795788485792619, disc_loss = 0.10086002927980846
Trained batch 395 in epoch 7, gen_loss = 0.7798193375570606, disc_loss = 0.10074216402088752
Trained batch 396 in epoch 7, gen_loss = 0.7799283318615681, disc_loss = 0.10054299921285295
Trained batch 397 in epoch 7, gen_loss = 0.7794052537661701, disc_loss = 0.10049366118882469
Trained batch 398 in epoch 7, gen_loss = 0.7790796169661042, disc_loss = 0.10048927877443775
Trained batch 399 in epoch 7, gen_loss = 0.7799479348957539, disc_loss = 0.10036185878328979
Trained batch 400 in epoch 7, gen_loss = 0.7812132266096938, disc_loss = 0.10060181569986212
Trained batch 401 in epoch 7, gen_loss = 0.780906607410801, disc_loss = 0.10053119375671617
Trained batch 402 in epoch 7, gen_loss = 0.7804969893791539, disc_loss = 0.10067239611712342
Trained batch 403 in epoch 7, gen_loss = 0.7805213929698018, disc_loss = 0.10048559463887226
Trained batch 404 in epoch 7, gen_loss = 0.7808591120037032, disc_loss = 0.10050952262532564
Trained batch 405 in epoch 7, gen_loss = 0.7816668456704746, disc_loss = 0.10056779068422142
Trained batch 406 in epoch 7, gen_loss = 0.7814711528562504, disc_loss = 0.10046345150185158
Trained batch 407 in epoch 7, gen_loss = 0.7811355015226439, disc_loss = 0.1004922938825307
Trained batch 408 in epoch 7, gen_loss = 0.781879704272543, disc_loss = 0.10031050480082448
Trained batch 409 in epoch 7, gen_loss = 0.7822806000709533, disc_loss = 0.10013291429637408
Trained batch 410 in epoch 7, gen_loss = 0.7822961873961771, disc_loss = 0.10010062942140874
Trained batch 411 in epoch 7, gen_loss = 0.7820264935782812, disc_loss = 0.09999388867754092
Trained batch 412 in epoch 7, gen_loss = 0.7829864162221082, disc_loss = 0.09982306144446063
Trained batch 413 in epoch 7, gen_loss = 0.7830308125790767, disc_loss = 0.09979261073243359
Trained batch 414 in epoch 7, gen_loss = 0.7826171768717018, disc_loss = 0.09971543238554374
Trained batch 415 in epoch 7, gen_loss = 0.7826832726311225, disc_loss = 0.09953679992871073
Trained batch 416 in epoch 7, gen_loss = 0.7830586810763791, disc_loss = 0.09943738936645379
Trained batch 417 in epoch 7, gen_loss = 0.7828180665889996, disc_loss = 0.09949887276105761
Trained batch 418 in epoch 7, gen_loss = 0.7830035064840658, disc_loss = 0.09934272896720714
Trained batch 419 in epoch 7, gen_loss = 0.7841563986880439, disc_loss = 0.09951013557701593
Trained batch 420 in epoch 7, gen_loss = 0.7845409042478457, disc_loss = 0.09934756181461653
Trained batch 421 in epoch 7, gen_loss = 0.7842717724388809, disc_loss = 0.09933920635872684
Trained batch 422 in epoch 7, gen_loss = 0.7842853241214798, disc_loss = 0.0996738695902816
Trained batch 423 in epoch 7, gen_loss = 0.784239189242417, disc_loss = 0.0995627577583534
Trained batch 424 in epoch 7, gen_loss = 0.7840510329078225, disc_loss = 0.09946011222022422
Trained batch 425 in epoch 7, gen_loss = 0.784492595374864, disc_loss = 0.09937240047371583
Trained batch 426 in epoch 7, gen_loss = 0.7852036241066819, disc_loss = 0.09938041002552878
Trained batch 427 in epoch 7, gen_loss = 0.7845127425182645, disc_loss = 0.09951513231444721
Trained batch 428 in epoch 7, gen_loss = 0.7843217820554347, disc_loss = 0.09944487379164824
Trained batch 429 in epoch 7, gen_loss = 0.7848477428735688, disc_loss = 0.09926348469371712
Trained batch 430 in epoch 7, gen_loss = 0.784798694182438, disc_loss = 0.09909156170995634
Trained batch 431 in epoch 7, gen_loss = 0.7842200366711175, disc_loss = 0.09911412099393567
Trained batch 432 in epoch 7, gen_loss = 0.7839532219234845, disc_loss = 0.09906580521537993
Trained batch 433 in epoch 7, gen_loss = 0.7845859886039787, disc_loss = 0.09958966015001183
Trained batch 434 in epoch 7, gen_loss = 0.7849042318333155, disc_loss = 0.09941529381977415
Trained batch 435 in epoch 7, gen_loss = 0.7847951645151191, disc_loss = 0.09947196825262193
Trained batch 436 in epoch 7, gen_loss = 0.784429573221665, disc_loss = 0.09944399197754243
Trained batch 437 in epoch 7, gen_loss = 0.784469129424117, disc_loss = 0.09934689523439565
Trained batch 438 in epoch 7, gen_loss = 0.7846240477301265, disc_loss = 0.09920870941683888
Trained batch 439 in epoch 7, gen_loss = 0.7845884145660834, disc_loss = 0.09915327595292844
Trained batch 440 in epoch 7, gen_loss = 0.7848661600056689, disc_loss = 0.09903292704686151
Trained batch 441 in epoch 7, gen_loss = 0.784915620385252, disc_loss = 0.09889880122355611
Trained batch 442 in epoch 7, gen_loss = 0.7850303170912422, disc_loss = 0.09873911846033875
Trained batch 443 in epoch 7, gen_loss = 0.785156837589032, disc_loss = 0.09860119595284667
Trained batch 444 in epoch 7, gen_loss = 0.7850100416815683, disc_loss = 0.09849405071876022
Trained batch 445 in epoch 7, gen_loss = 0.7848446736688571, disc_loss = 0.09840420342046316
Trained batch 446 in epoch 7, gen_loss = 0.7860232896986157, disc_loss = 0.09833780516947409
Trained batch 447 in epoch 7, gen_loss = 0.7857022238895297, disc_loss = 0.09826724769248228
Trained batch 448 in epoch 7, gen_loss = 0.7853470256174593, disc_loss = 0.09829569537449785
Trained batch 449 in epoch 7, gen_loss = 0.7851128028498755, disc_loss = 0.09833667262560791
Trained batch 450 in epoch 7, gen_loss = 0.7854920738023559, disc_loss = 0.09835294425124075
Trained batch 451 in epoch 7, gen_loss = 0.7855033796709195, disc_loss = 0.09825961817616383
Trained batch 452 in epoch 7, gen_loss = 0.7861056592290765, disc_loss = 0.09808741877509268
Trained batch 453 in epoch 7, gen_loss = 0.785857372740817, disc_loss = 0.09802741136418303
Trained batch 454 in epoch 7, gen_loss = 0.7856597008285942, disc_loss = 0.09807207149627445
Trained batch 455 in epoch 7, gen_loss = 0.7866154160154494, disc_loss = 0.09829792538004224
Trained batch 456 in epoch 7, gen_loss = 0.7873091865942305, disc_loss = 0.09812467834245846
Trained batch 457 in epoch 7, gen_loss = 0.7869497126366894, disc_loss = 0.09828079824120327
Trained batch 458 in epoch 7, gen_loss = 0.7869268863549159, disc_loss = 0.09821272063959788
Trained batch 459 in epoch 7, gen_loss = 0.7871204097633776, disc_loss = 0.09811761539186473
Trained batch 460 in epoch 7, gen_loss = 0.7881002313661472, disc_loss = 0.09829777399574986
Trained batch 461 in epoch 7, gen_loss = 0.7876788159727535, disc_loss = 0.09835359995612206
Trained batch 462 in epoch 7, gen_loss = 0.7877493679652203, disc_loss = 0.0983476949972352
Trained batch 463 in epoch 7, gen_loss = 0.7876327513106938, disc_loss = 0.0982970343862564
Trained batch 464 in epoch 7, gen_loss = 0.7869668916989399, disc_loss = 0.09857853012940576
Trained batch 465 in epoch 7, gen_loss = 0.7873227788143403, disc_loss = 0.09860962301156935
Trained batch 466 in epoch 7, gen_loss = 0.7874965883424502, disc_loss = 0.09852698456089169
Trained batch 467 in epoch 7, gen_loss = 0.7872444638329693, disc_loss = 0.0985108053860947
Trained batch 468 in epoch 7, gen_loss = 0.7870952633143996, disc_loss = 0.09846019188462417
Trained batch 469 in epoch 7, gen_loss = 0.7871213892672925, disc_loss = 0.09836386386305093
Trained batch 470 in epoch 7, gen_loss = 0.7867514072203585, disc_loss = 0.09835754940385145
Trained batch 471 in epoch 7, gen_loss = 0.7869475197236416, disc_loss = 0.09824305567180075
Trained batch 472 in epoch 7, gen_loss = 0.7868446372528157, disc_loss = 0.0981599972809785
Trained batch 473 in epoch 7, gen_loss = 0.7869120183624799, disc_loss = 0.09801730168944044
Trained batch 474 in epoch 7, gen_loss = 0.7872132168318096, disc_loss = 0.09801141589487854
Trained batch 475 in epoch 7, gen_loss = 0.7871185461012256, disc_loss = 0.09792205447550206
Trained batch 476 in epoch 7, gen_loss = 0.7881990973554567, disc_loss = 0.09784878495557378
Trained batch 477 in epoch 7, gen_loss = 0.7883247634606382, disc_loss = 0.09773577649582754
Trained batch 478 in epoch 7, gen_loss = 0.7884840134041294, disc_loss = 0.09757610051533001
Trained batch 479 in epoch 7, gen_loss = 0.7883073180913925, disc_loss = 0.0976722619535091
Trained batch 480 in epoch 7, gen_loss = 0.7881393981574727, disc_loss = 0.09763322219546892
Trained batch 481 in epoch 7, gen_loss = 0.7879973398946628, disc_loss = 0.09754801667160141
Trained batch 482 in epoch 7, gen_loss = 0.7889276324592022, disc_loss = 0.09754586986827184
Trained batch 483 in epoch 7, gen_loss = 0.7890757500879035, disc_loss = 0.09737809743609063
Trained batch 484 in epoch 7, gen_loss = 0.7886824127325077, disc_loss = 0.09765232087871463
Trained batch 485 in epoch 7, gen_loss = 0.7896067952668225, disc_loss = 0.09754984332210243
Trained batch 486 in epoch 7, gen_loss = 0.7897542699161741, disc_loss = 0.09753550892003508
Trained batch 487 in epoch 7, gen_loss = 0.7891956692347761, disc_loss = 0.0976150320445905
Trained batch 488 in epoch 7, gen_loss = 0.7893291450960749, disc_loss = 0.09747359462097623
Trained batch 489 in epoch 7, gen_loss = 0.7890386537629731, disc_loss = 0.09753151579322863
Trained batch 490 in epoch 7, gen_loss = 0.7898102292218179, disc_loss = 0.09760249833255824
Trained batch 491 in epoch 7, gen_loss = 0.7896294046223649, disc_loss = 0.09749180987871033
Trained batch 492 in epoch 7, gen_loss = 0.7893403282513725, disc_loss = 0.09746030348581668
Trained batch 493 in epoch 7, gen_loss = 0.7893718812871076, disc_loss = 0.09750719114323618
Trained batch 494 in epoch 7, gen_loss = 0.7902166690489258, disc_loss = 0.09744688199475558
Trained batch 495 in epoch 7, gen_loss = 0.7897549084117336, disc_loss = 0.09756128305959846
Trained batch 496 in epoch 7, gen_loss = 0.7901781850177757, disc_loss = 0.09752002570560761
Trained batch 497 in epoch 7, gen_loss = 0.7899448651386553, disc_loss = 0.09745212573273833
Trained batch 498 in epoch 7, gen_loss = 0.7899576260713872, disc_loss = 0.09732076944503373
Trained batch 499 in epoch 7, gen_loss = 0.79010067486763, disc_loss = 0.09719756508618593
Trained batch 500 in epoch 7, gen_loss = 0.7902727661256542, disc_loss = 0.09705675808999115
Trained batch 501 in epoch 7, gen_loss = 0.790785733803335, disc_loss = 0.09693835048650602
Trained batch 502 in epoch 7, gen_loss = 0.7906810721867601, disc_loss = 0.0969401496290331
Trained batch 503 in epoch 7, gen_loss = 0.7904847258376697, disc_loss = 0.0968478509845833
Trained batch 504 in epoch 7, gen_loss = 0.7911871913636085, disc_loss = 0.0967512466898649
Trained batch 505 in epoch 7, gen_loss = 0.791229836672191, disc_loss = 0.09660107430011741
Trained batch 506 in epoch 7, gen_loss = 0.7909373194273172, disc_loss = 0.0965632430040801
Trained batch 507 in epoch 7, gen_loss = 0.790870572168996, disc_loss = 0.09654128336985632
Trained batch 508 in epoch 7, gen_loss = 0.7903570170955245, disc_loss = 0.09674891106023184
Trained batch 509 in epoch 7, gen_loss = 0.7906325090165232, disc_loss = 0.09687471886110656
Trained batch 510 in epoch 7, gen_loss = 0.790211781713594, disc_loss = 0.09700484789266395
Trained batch 511 in epoch 7, gen_loss = 0.79011696705129, disc_loss = 0.09696414693826227
Trained batch 512 in epoch 7, gen_loss = 0.7900986619162977, disc_loss = 0.09703711337150304
Trained batch 513 in epoch 7, gen_loss = 0.7907534115277376, disc_loss = 0.09699699893985161
Trained batch 514 in epoch 7, gen_loss = 0.7912296685200293, disc_loss = 0.09687134425689295
Trained batch 515 in epoch 7, gen_loss = 0.7907056357971457, disc_loss = 0.09695421036895971
Trained batch 516 in epoch 7, gen_loss = 0.7906708648172522, disc_loss = 0.09688623331314244
Trained batch 517 in epoch 7, gen_loss = 0.7908772156505511, disc_loss = 0.09674018597352574
Trained batch 518 in epoch 7, gen_loss = 0.791153609063584, disc_loss = 0.09686470556078274
Trained batch 519 in epoch 7, gen_loss = 0.7911260014543167, disc_loss = 0.09676029104381227
Trained batch 520 in epoch 7, gen_loss = 0.790835663704863, disc_loss = 0.09686910861212895
Trained batch 521 in epoch 7, gen_loss = 0.7908505092863836, disc_loss = 0.09676293862833717
Trained batch 522 in epoch 7, gen_loss = 0.7915579995735198, disc_loss = 0.0966175532727066
Trained batch 523 in epoch 7, gen_loss = 0.7913952797423792, disc_loss = 0.0965391455026244
Trained batch 524 in epoch 7, gen_loss = 0.7915332426343645, disc_loss = 0.09640322022140026
Trained batch 525 in epoch 7, gen_loss = 0.7914740580343022, disc_loss = 0.09628268557568807
Trained batch 526 in epoch 7, gen_loss = 0.791757672063766, disc_loss = 0.0962505003921617
Trained batch 527 in epoch 7, gen_loss = 0.7918518135945002, disc_loss = 0.0961128847504204
Trained batch 528 in epoch 7, gen_loss = 0.7919611070016381, disc_loss = 0.0960767252515079
Trained batch 529 in epoch 7, gen_loss = 0.7920525595826923, disc_loss = 0.09597312171223028
Trained batch 530 in epoch 7, gen_loss = 0.7920801805686591, disc_loss = 0.09583264713836816
Trained batch 531 in epoch 7, gen_loss = 0.7918089326835216, disc_loss = 0.09578403839981534
Trained batch 532 in epoch 7, gen_loss = 0.7920949367376474, disc_loss = 0.0956270865201391
Trained batch 533 in epoch 7, gen_loss = 0.792485798342844, disc_loss = 0.09548623585717732
Trained batch 534 in epoch 7, gen_loss = 0.792918774791967, disc_loss = 0.09534035916918907
Trained batch 535 in epoch 7, gen_loss = 0.7926814081286316, disc_loss = 0.0952701592095085
Trained batch 536 in epoch 7, gen_loss = 0.7923522678167461, disc_loss = 0.0952318319062281
Trained batch 537 in epoch 7, gen_loss = 0.7925875358643585, disc_loss = 0.09511604860812758
Trained batch 538 in epoch 7, gen_loss = 0.7927465466488712, disc_loss = 0.09499322646513499
Trained batch 539 in epoch 7, gen_loss = 0.7925596810049481, disc_loss = 0.09491273018497008
Trained batch 540 in epoch 7, gen_loss = 0.7926176615651566, disc_loss = 0.09493721952720402
Trained batch 541 in epoch 7, gen_loss = 0.7922819702167793, disc_loss = 0.09488773428426017
Trained batch 542 in epoch 7, gen_loss = 0.7923866442334366, disc_loss = 0.0947839366357849
Trained batch 543 in epoch 7, gen_loss = 0.7929156786378693, disc_loss = 0.09464971226749613
Trained batch 544 in epoch 7, gen_loss = 0.7932768674071776, disc_loss = 0.09453122046425802
Trained batch 545 in epoch 7, gen_loss = 0.7933792071246402, disc_loss = 0.0944103259224813
Trained batch 546 in epoch 7, gen_loss = 0.7938931122340493, disc_loss = 0.09432977148530906
Trained batch 547 in epoch 7, gen_loss = 0.7942449988892478, disc_loss = 0.09421328711493389
Trained batch 548 in epoch 7, gen_loss = 0.794509384801479, disc_loss = 0.09409544815416218
Trained batch 549 in epoch 7, gen_loss = 0.7943777478824963, disc_loss = 0.094021712761711
Trained batch 550 in epoch 7, gen_loss = 0.794679963437269, disc_loss = 0.0940364888090025
Trained batch 551 in epoch 7, gen_loss = 0.7944789762082307, disc_loss = 0.09400669842000133
Trained batch 552 in epoch 7, gen_loss = 0.7941311899619766, disc_loss = 0.09415852676261938
Trained batch 553 in epoch 7, gen_loss = 0.7939053250994493, disc_loss = 0.09419939570492032
Trained batch 554 in epoch 7, gen_loss = 0.7939313663018717, disc_loss = 0.09408775859655023
Trained batch 555 in epoch 7, gen_loss = 0.7941426469696512, disc_loss = 0.09400673802580228
Trained batch 556 in epoch 7, gen_loss = 0.7944967877286983, disc_loss = 0.0938833056843741
Trained batch 557 in epoch 7, gen_loss = 0.7940976245856199, disc_loss = 0.09385910852208039
Trained batch 558 in epoch 7, gen_loss = 0.7943632247622836, disc_loss = 0.09376937729741358
Trained batch 559 in epoch 7, gen_loss = 0.7943832206938948, disc_loss = 0.09367748694826981
Trained batch 560 in epoch 7, gen_loss = 0.7946104662303619, disc_loss = 0.09373097211029546
Trained batch 561 in epoch 7, gen_loss = 0.7942090241298132, disc_loss = 0.09378029008684315
Trained batch 562 in epoch 7, gen_loss = 0.7943250928636554, disc_loss = 0.09376065749641951
Trained batch 563 in epoch 7, gen_loss = 0.794523667253501, disc_loss = 0.0936889673239743
Trained batch 564 in epoch 7, gen_loss = 0.7939213637229615, disc_loss = 0.09380772873033992
Trained batch 565 in epoch 7, gen_loss = 0.7938816377320475, disc_loss = 0.09370987483566831
Trained batch 566 in epoch 7, gen_loss = 0.7942743598363597, disc_loss = 0.0937713194388824
Trained batch 567 in epoch 7, gen_loss = 0.7945859662558831, disc_loss = 0.09364185510793517
Trained batch 568 in epoch 7, gen_loss = 0.7943308183199911, disc_loss = 0.09362420651518293
Trained batch 569 in epoch 7, gen_loss = 0.7939888903446365, disc_loss = 0.09358681400813032
Trained batch 570 in epoch 7, gen_loss = 0.7944146045557046, disc_loss = 0.09410457453656218
Trained batch 571 in epoch 7, gen_loss = 0.7940983230938444, disc_loss = 0.09415533246107764
Trained batch 572 in epoch 7, gen_loss = 0.7942166386162424, disc_loss = 0.09422514082808665
Trained batch 573 in epoch 7, gen_loss = 0.7940173765404299, disc_loss = 0.09418680501666946
Trained batch 574 in epoch 7, gen_loss = 0.7938892603438833, disc_loss = 0.09445875246563683
Trained batch 575 in epoch 7, gen_loss = 0.793486826794429, disc_loss = 0.09457286776806642
Trained batch 576 in epoch 7, gen_loss = 0.7936106100549317, disc_loss = 0.0944813068672059
Trained batch 577 in epoch 7, gen_loss = 0.7933173029583631, disc_loss = 0.09445466170454829
Trained batch 578 in epoch 7, gen_loss = 0.7934786572872254, disc_loss = 0.09451404051446648
Trained batch 579 in epoch 7, gen_loss = 0.7936592914420982, disc_loss = 0.09439293685015933
Trained batch 580 in epoch 7, gen_loss = 0.7932955647807524, disc_loss = 0.09456947645278273
Trained batch 581 in epoch 7, gen_loss = 0.7940280008869073, disc_loss = 0.09464660421961157
Trained batch 582 in epoch 7, gen_loss = 0.7939559997763888, disc_loss = 0.09457156334973323
Trained batch 583 in epoch 7, gen_loss = 0.7938385261350298, disc_loss = 0.09452281386451158
Trained batch 584 in epoch 7, gen_loss = 0.7937725888867664, disc_loss = 0.09453457379315654
Trained batch 585 in epoch 7, gen_loss = 0.7939575341476108, disc_loss = 0.09464732584870919
Trained batch 586 in epoch 7, gen_loss = 0.7938509281388336, disc_loss = 0.09458562774263209
Trained batch 587 in epoch 7, gen_loss = 0.7933439299666962, disc_loss = 0.09468414362672033
Trained batch 588 in epoch 7, gen_loss = 0.7933316942690184, disc_loss = 0.09463609116869791
Trained batch 589 in epoch 7, gen_loss = 0.7936751140881393, disc_loss = 0.09482245098610045
Trained batch 590 in epoch 7, gen_loss = 0.7933307977396421, disc_loss = 0.09482963722949303
Trained batch 591 in epoch 7, gen_loss = 0.793012570136705, disc_loss = 0.09485941492902064
Trained batch 592 in epoch 7, gen_loss = 0.7928874204673413, disc_loss = 0.09490125070359011
Trained batch 593 in epoch 7, gen_loss = 0.7929858953162074, disc_loss = 0.0948752119622949
Trained batch 594 in epoch 7, gen_loss = 0.7933400312892529, disc_loss = 0.09478237302739079
Trained batch 595 in epoch 7, gen_loss = 0.7929198241373837, disc_loss = 0.09486438375866453
Trained batch 596 in epoch 7, gen_loss = 0.7929026389141978, disc_loss = 0.09477557111500295
Trained batch 597 in epoch 7, gen_loss = 0.7932733121424614, disc_loss = 0.09473100746280971
Trained batch 598 in epoch 7, gen_loss = 0.793445686814383, disc_loss = 0.09470640704384033
Trained batch 599 in epoch 7, gen_loss = 0.7933542978266875, disc_loss = 0.09458840746742983
Trained batch 600 in epoch 7, gen_loss = 0.7933899143868793, disc_loss = 0.0945012800538054
Trained batch 601 in epoch 7, gen_loss = 0.7930806696513959, disc_loss = 0.09452654914218821
Trained batch 602 in epoch 7, gen_loss = 0.7931815118437778, disc_loss = 0.09446242038055538
Trained batch 603 in epoch 7, gen_loss = 0.7933657429372238, disc_loss = 0.09453131790451755
Trained batch 604 in epoch 7, gen_loss = 0.7932649983354837, disc_loss = 0.09447749804797743
Trained batch 605 in epoch 7, gen_loss = 0.7931823607030088, disc_loss = 0.09444458396312329
Trained batch 606 in epoch 7, gen_loss = 0.7930359069067721, disc_loss = 0.09438793136258003
Trained batch 607 in epoch 7, gen_loss = 0.793006652132853, disc_loss = 0.09427268141084105
Trained batch 608 in epoch 7, gen_loss = 0.793139376125508, disc_loss = 0.09439139297822328
Trained batch 609 in epoch 7, gen_loss = 0.7933595034431239, disc_loss = 0.09428794485074087
Trained batch 610 in epoch 7, gen_loss = 0.7934331361771411, disc_loss = 0.094242860061618
Trained batch 611 in epoch 7, gen_loss = 0.7929880311773494, disc_loss = 0.09437381939694675
Trained batch 612 in epoch 7, gen_loss = 0.7935563956446593, disc_loss = 0.0943345554981253
Trained batch 613 in epoch 7, gen_loss = 0.7937612305926189, disc_loss = 0.0942222906628484
Trained batch 614 in epoch 7, gen_loss = 0.7935071841972631, disc_loss = 0.09425003634902035
Trained batch 615 in epoch 7, gen_loss = 0.7935122217160541, disc_loss = 0.09435125546493604
Trained batch 616 in epoch 7, gen_loss = 0.7937731966497059, disc_loss = 0.09423089143027652
Trained batch 617 in epoch 7, gen_loss = 0.7939766914038211, disc_loss = 0.09414013857052067
Trained batch 618 in epoch 7, gen_loss = 0.7939584082374666, disc_loss = 0.09402067389682248
Trained batch 619 in epoch 7, gen_loss = 0.7936772923796408, disc_loss = 0.09404778244694875
Trained batch 620 in epoch 7, gen_loss = 0.7936656211597332, disc_loss = 0.09399770562283563
Trained batch 621 in epoch 7, gen_loss = 0.7944323956678918, disc_loss = 0.09405899023595252
Trained batch 622 in epoch 7, gen_loss = 0.7947185938373614, disc_loss = 0.09394750298325265
Trained batch 623 in epoch 7, gen_loss = 0.7943361857667183, disc_loss = 0.09398467978761078
Trained batch 624 in epoch 7, gen_loss = 0.7940216643810272, disc_loss = 0.09398249373733997
Trained batch 625 in epoch 7, gen_loss = 0.7939016386247671, disc_loss = 0.09398642759889174
Trained batch 626 in epoch 7, gen_loss = 0.794352053027404, disc_loss = 0.09414972181014562
Trained batch 627 in epoch 7, gen_loss = 0.794453699640028, disc_loss = 0.09408422821990339
Trained batch 628 in epoch 7, gen_loss = 0.7942257583709893, disc_loss = 0.09414170141404403
Trained batch 629 in epoch 7, gen_loss = 0.794025354394837, disc_loss = 0.09420170307691608
Trained batch 630 in epoch 7, gen_loss = 0.7939852346236657, disc_loss = 0.09420498613144157
Trained batch 631 in epoch 7, gen_loss = 0.7940311517236354, disc_loss = 0.09421454310193186
Trained batch 632 in epoch 7, gen_loss = 0.7941160607394449, disc_loss = 0.09419363363106009
Trained batch 633 in epoch 7, gen_loss = 0.7942124366854267, disc_loss = 0.09414280146325142
Trained batch 634 in epoch 7, gen_loss = 0.7940688572061343, disc_loss = 0.0941101636737585
Trained batch 635 in epoch 7, gen_loss = 0.7937342753669001, disc_loss = 0.09420516311759188
Trained batch 636 in epoch 7, gen_loss = 0.7934699775753441, disc_loss = 0.09421371054810762
Trained batch 637 in epoch 7, gen_loss = 0.7933549967398837, disc_loss = 0.09419721607002064
Trained batch 638 in epoch 7, gen_loss = 0.7938599784702576, disc_loss = 0.09415348661489237
Trained batch 639 in epoch 7, gen_loss = 0.7937768731731921, disc_loss = 0.09410763774358202
Trained batch 640 in epoch 7, gen_loss = 0.7935807493380191, disc_loss = 0.09406046077969386
Trained batch 641 in epoch 7, gen_loss = 0.7936894475392463, disc_loss = 0.0939700465875669
Trained batch 642 in epoch 7, gen_loss = 0.7939276121915962, disc_loss = 0.09386690203419092
Trained batch 643 in epoch 7, gen_loss = 0.7937791939385189, disc_loss = 0.09381150635630355
Trained batch 644 in epoch 7, gen_loss = 0.7939374991627627, disc_loss = 0.09389180172263652
Trained batch 645 in epoch 7, gen_loss = 0.7941932479386729, disc_loss = 0.09377110375512403
Trained batch 646 in epoch 7, gen_loss = 0.7938421750455588, disc_loss = 0.0937964187955147
Trained batch 647 in epoch 7, gen_loss = 0.7937197039984627, disc_loss = 0.09373994953757911
Trained batch 648 in epoch 7, gen_loss = 0.7942282821529635, disc_loss = 0.09388871080255012
Trained batch 649 in epoch 7, gen_loss = 0.7940944989369466, disc_loss = 0.09382164805840987
Trained batch 650 in epoch 7, gen_loss = 0.794708929715618, disc_loss = 0.09372837583143864
Trained batch 651 in epoch 7, gen_loss = 0.7946572224695259, disc_loss = 0.09368174905071687
Trained batch 652 in epoch 7, gen_loss = 0.7948753400655837, disc_loss = 0.09365339644800923
Trained batch 653 in epoch 7, gen_loss = 0.7951616002787872, disc_loss = 0.09354127911047651
Trained batch 654 in epoch 7, gen_loss = 0.7948253488267651, disc_loss = 0.09361824918225521
Trained batch 655 in epoch 7, gen_loss = 0.795454949185979, disc_loss = 0.09354682104298617
Trained batch 656 in epoch 7, gen_loss = 0.7954385195783648, disc_loss = 0.09346609737276124
Trained batch 657 in epoch 7, gen_loss = 0.7953367742814554, disc_loss = 0.09340347161114579
Trained batch 658 in epoch 7, gen_loss = 0.7956065492582972, disc_loss = 0.09334049944247208
Trained batch 659 in epoch 7, gen_loss = 0.7954533247785135, disc_loss = 0.09325080811977386
Trained batch 660 in epoch 7, gen_loss = 0.7957829023724065, disc_loss = 0.0931273667499671
Trained batch 661 in epoch 7, gen_loss = 0.795992911447211, disc_loss = 0.0930077344843178
Trained batch 662 in epoch 7, gen_loss = 0.7957120113872654, disc_loss = 0.09297501662715169
Trained batch 663 in epoch 7, gen_loss = 0.795867756502815, disc_loss = 0.09289043495453984
Trained batch 664 in epoch 7, gen_loss = 0.7964299197931936, disc_loss = 0.09289417572711643
Trained batch 665 in epoch 7, gen_loss = 0.7964994708249519, disc_loss = 0.09281402171866314
Trained batch 666 in epoch 7, gen_loss = 0.7962121210623717, disc_loss = 0.09282310954902483
Trained batch 667 in epoch 7, gen_loss = 0.7964899405658602, disc_loss = 0.09272176770683
Trained batch 668 in epoch 7, gen_loss = 0.7965726758421625, disc_loss = 0.09263122844076833
Trained batch 669 in epoch 7, gen_loss = 0.7966368871393489, disc_loss = 0.0926221584706609
Trained batch 670 in epoch 7, gen_loss = 0.7965013840070603, disc_loss = 0.09255385530443554
Trained batch 671 in epoch 7, gen_loss = 0.7965448312017889, disc_loss = 0.09245353835147052
Trained batch 672 in epoch 7, gen_loss = 0.7965425802463939, disc_loss = 0.0923689824887406
Trained batch 673 in epoch 7, gen_loss = 0.7967875517175176, disc_loss = 0.09242368408807661
Trained batch 674 in epoch 7, gen_loss = 0.7964624801830009, disc_loss = 0.09242945261575558
Trained batch 675 in epoch 7, gen_loss = 0.7967020423542819, disc_loss = 0.09232055805017345
Trained batch 676 in epoch 7, gen_loss = 0.7965076917471526, disc_loss = 0.09231326735937526
Trained batch 677 in epoch 7, gen_loss = 0.7963375338850471, disc_loss = 0.09232021059709049
Trained batch 678 in epoch 7, gen_loss = 0.7962572175641826, disc_loss = 0.09232722708080321
Trained batch 679 in epoch 7, gen_loss = 0.796302237011054, disc_loss = 0.09255476732300047
Trained batch 680 in epoch 7, gen_loss = 0.7963746643889142, disc_loss = 0.09247891081116885
Trained batch 681 in epoch 7, gen_loss = 0.7960525173857764, disc_loss = 0.09249552798421938
Trained batch 682 in epoch 7, gen_loss = 0.7961606883810693, disc_loss = 0.09239996773617595
Trained batch 683 in epoch 7, gen_loss = 0.7959567516257888, disc_loss = 0.09236631715909867
Trained batch 684 in epoch 7, gen_loss = 0.7960164840639072, disc_loss = 0.09232844326672328
Trained batch 685 in epoch 7, gen_loss = 0.796115734964696, disc_loss = 0.09223320353884826
Trained batch 686 in epoch 7, gen_loss = 0.7963104245010248, disc_loss = 0.09212522310363414
Trained batch 687 in epoch 7, gen_loss = 0.7962761918559323, disc_loss = 0.09205594625009961
Trained batch 688 in epoch 7, gen_loss = 0.7968029403634618, disc_loss = 0.09198961124981177
Trained batch 689 in epoch 7, gen_loss = 0.7967696998862253, disc_loss = 0.09192897564313118
Trained batch 690 in epoch 7, gen_loss = 0.7967298612667062, disc_loss = 0.09184936794968572
Trained batch 691 in epoch 7, gen_loss = 0.7969427694044361, disc_loss = 0.09187095108135157
Trained batch 692 in epoch 7, gen_loss = 0.7966816362966535, disc_loss = 0.0919147144228994
Trained batch 693 in epoch 7, gen_loss = 0.7970095759080535, disc_loss = 0.0917981707662752
Trained batch 694 in epoch 7, gen_loss = 0.796762814581823, disc_loss = 0.09193060870731262
Trained batch 695 in epoch 7, gen_loss = 0.7968353870185627, disc_loss = 0.09188637345488686
Trained batch 696 in epoch 7, gen_loss = 0.7972614641596631, disc_loss = 0.09196411097125609
Trained batch 697 in epoch 7, gen_loss = 0.7969103361183729, disc_loss = 0.09201631251386337
Trained batch 698 in epoch 7, gen_loss = 0.7973617584323337, disc_loss = 0.0920156896559359
Trained batch 699 in epoch 7, gen_loss = 0.7973189229198865, disc_loss = 0.0919870454112866
Trained batch 700 in epoch 7, gen_loss = 0.797212139473492, disc_loss = 0.09190373842108904
Trained batch 701 in epoch 7, gen_loss = 0.797474292905582, disc_loss = 0.09182163384050512
Trained batch 702 in epoch 7, gen_loss = 0.7976747175114253, disc_loss = 0.09171513834329664
Trained batch 703 in epoch 7, gen_loss = 0.7976056568917226, disc_loss = 0.09164901372622064
Trained batch 704 in epoch 7, gen_loss = 0.7979687612530187, disc_loss = 0.09154861723304006
Trained batch 705 in epoch 7, gen_loss = 0.798051405518656, disc_loss = 0.09144700425558278
Trained batch 706 in epoch 7, gen_loss = 0.798025484005835, disc_loss = 0.09139121019662143
Trained batch 707 in epoch 7, gen_loss = 0.7985247948159606, disc_loss = 0.09136373974188194
Trained batch 708 in epoch 7, gen_loss = 0.7982113069220221, disc_loss = 0.09141344354686305
Trained batch 709 in epoch 7, gen_loss = 0.7981606347879894, disc_loss = 0.09134394065673712
Trained batch 710 in epoch 7, gen_loss = 0.7986651039073236, disc_loss = 0.09126954603122885
Trained batch 711 in epoch 7, gen_loss = 0.7982799740236127, disc_loss = 0.09149777770874332
Trained batch 712 in epoch 7, gen_loss = 0.7986439516216642, disc_loss = 0.09167643322845788
Trained batch 713 in epoch 7, gen_loss = 0.7986217563142296, disc_loss = 0.09159374672069061
Trained batch 714 in epoch 7, gen_loss = 0.7992112557787995, disc_loss = 0.09176836591995471
Trained batch 715 in epoch 7, gen_loss = 0.7989227424204016, disc_loss = 0.09192480593165331
Trained batch 716 in epoch 7, gen_loss = 0.7992370326898088, disc_loss = 0.09182617802827553
Trained batch 717 in epoch 7, gen_loss = 0.7992667819381092, disc_loss = 0.09174230959250859
Trained batch 718 in epoch 7, gen_loss = 0.7994420773379495, disc_loss = 0.09170786687075802
Trained batch 719 in epoch 7, gen_loss = 0.7992088162650665, disc_loss = 0.09166239362287645
Trained batch 720 in epoch 7, gen_loss = 0.7994452569835229, disc_loss = 0.09161934687855464
Trained batch 721 in epoch 7, gen_loss = 0.799177696293741, disc_loss = 0.0917162361627037
Trained batch 722 in epoch 7, gen_loss = 0.7993944488043278, disc_loss = 0.0917096965331816
Trained batch 723 in epoch 7, gen_loss = 0.7993988452777678, disc_loss = 0.09162568605957727
Trained batch 724 in epoch 7, gen_loss = 0.7996572718538087, disc_loss = 0.09151878095777898
Trained batch 725 in epoch 7, gen_loss = 0.7997386155460163, disc_loss = 0.09144131183372836
Trained batch 726 in epoch 7, gen_loss = 0.8000670132397621, disc_loss = 0.09136085946912245
Trained batch 727 in epoch 7, gen_loss = 0.8002872788398475, disc_loss = 0.091253156561384
Trained batch 728 in epoch 7, gen_loss = 0.8001283274347727, disc_loss = 0.09123269451426953
Trained batch 729 in epoch 7, gen_loss = 0.8001311416087086, disc_loss = 0.0913699846383031
Trained batch 730 in epoch 7, gen_loss = 0.8001039999698973, disc_loss = 0.09133775832154438
Trained batch 731 in epoch 7, gen_loss = 0.7999797888059433, disc_loss = 0.09133154218202162
Trained batch 732 in epoch 7, gen_loss = 0.8001901459807751, disc_loss = 0.09123875497551927
Trained batch 733 in epoch 7, gen_loss = 0.8004239780133037, disc_loss = 0.09116044400478092
Trained batch 734 in epoch 7, gen_loss = 0.8008127487030159, disc_loss = 0.0911686497024533
Trained batch 735 in epoch 7, gen_loss = 0.8011611170823807, disc_loss = 0.09109034921224836
Trained batch 736 in epoch 7, gen_loss = 0.8007558733427056, disc_loss = 0.09133917559822832
Trained batch 737 in epoch 7, gen_loss = 0.8009894367882876, disc_loss = 0.09125098803138668
Trained batch 738 in epoch 7, gen_loss = 0.8010288991931327, disc_loss = 0.09121996141133354
Trained batch 739 in epoch 7, gen_loss = 0.800791419075953, disc_loss = 0.09119179959635476
Trained batch 740 in epoch 7, gen_loss = 0.800848997435589, disc_loss = 0.09109573244203922
Trained batch 741 in epoch 7, gen_loss = 0.8009612873959734, disc_loss = 0.09122985718907371
Trained batch 742 in epoch 7, gen_loss = 0.8010737068479828, disc_loss = 0.09113887973219999
Trained batch 743 in epoch 7, gen_loss = 0.8008502785476946, disc_loss = 0.09115518664600708
Trained batch 744 in epoch 7, gen_loss = 0.8009597587505443, disc_loss = 0.09119795395823933
Trained batch 745 in epoch 7, gen_loss = 0.8010414155255055, disc_loss = 0.09115131915953939
Trained batch 746 in epoch 7, gen_loss = 0.8011359465090306, disc_loss = 0.09132428933558374
Trained batch 747 in epoch 7, gen_loss = 0.800535619338566, disc_loss = 0.09193869191595418
Trained batch 748 in epoch 7, gen_loss = 0.8008565624979374, disc_loss = 0.09191268620308791
Trained batch 749 in epoch 7, gen_loss = 0.8014166994889578, disc_loss = 0.09192792641619842
Trained batch 750 in epoch 7, gen_loss = 0.8015940428256354, disc_loss = 0.09188843913842612
Trained batch 751 in epoch 7, gen_loss = 0.8015230076902724, disc_loss = 0.09190801061947454
Trained batch 752 in epoch 7, gen_loss = 0.801228646817277, disc_loss = 0.09193004201231883
Trained batch 753 in epoch 7, gen_loss = 0.8011891266395306, disc_loss = 0.09198248954069867
Trained batch 754 in epoch 7, gen_loss = 0.8013447974691328, disc_loss = 0.09189724461329694
Trained batch 755 in epoch 7, gen_loss = 0.8014997787891872, disc_loss = 0.09193012318401425
Trained batch 756 in epoch 7, gen_loss = 0.8012572515121067, disc_loss = 0.09195835350014889
Trained batch 757 in epoch 7, gen_loss = 0.8010938033894058, disc_loss = 0.09194858686747841
Trained batch 758 in epoch 7, gen_loss = 0.8009102552618748, disc_loss = 0.0919429202795971
Trained batch 759 in epoch 7, gen_loss = 0.801052140640585, disc_loss = 0.09198327024320238
Trained batch 760 in epoch 7, gen_loss = 0.8006594711314989, disc_loss = 0.09218581973449003
Trained batch 761 in epoch 7, gen_loss = 0.8004359085885245, disc_loss = 0.0922556060251445
Trained batch 762 in epoch 7, gen_loss = 0.8004661165714889, disc_loss = 0.09217255185132414
Trained batch 763 in epoch 7, gen_loss = 0.8004926861268687, disc_loss = 0.09210892158185
Trained batch 764 in epoch 7, gen_loss = 0.8003700650595372, disc_loss = 0.09209772247114992
Trained batch 765 in epoch 7, gen_loss = 0.8008767268365108, disc_loss = 0.0921287844176392
Trained batch 766 in epoch 7, gen_loss = 0.8007979621476891, disc_loss = 0.09208531993425499
Trained batch 767 in epoch 7, gen_loss = 0.8006641565977285, disc_loss = 0.09208428292186
Trained batch 768 in epoch 7, gen_loss = 0.8004965897654371, disc_loss = 0.09210480095622443
Trained batch 769 in epoch 7, gen_loss = 0.8005251632882403, disc_loss = 0.09214646927528568
Trained batch 770 in epoch 7, gen_loss = 0.8004263432264018, disc_loss = 0.09208784302172339
Trained batch 771 in epoch 7, gen_loss = 0.8004886243164231, disc_loss = 0.09202311990464135
Trained batch 772 in epoch 7, gen_loss = 0.8006493786945071, disc_loss = 0.09193926329157022
Trained batch 773 in epoch 7, gen_loss = 0.8010155533173288, disc_loss = 0.09193796123009781
Trained batch 774 in epoch 7, gen_loss = 0.8008776991598068, disc_loss = 0.09189346669181701
Trained batch 775 in epoch 7, gen_loss = 0.8008322873220002, disc_loss = 0.09187087597152621
Trained batch 776 in epoch 7, gen_loss = 0.8006242743023267, disc_loss = 0.09188100220000268
Trained batch 777 in epoch 7, gen_loss = 0.8007682471471458, disc_loss = 0.0918279331474347
Trained batch 778 in epoch 7, gen_loss = 0.8009478009099067, disc_loss = 0.09188317002510994
Trained batch 779 in epoch 7, gen_loss = 0.8006918678681055, disc_loss = 0.09194070099829099
Trained batch 780 in epoch 7, gen_loss = 0.8007197240403306, disc_loss = 0.0918635715862853
Trained batch 781 in epoch 7, gen_loss = 0.8011833725835357, disc_loss = 0.09182675530576645
Trained batch 782 in epoch 7, gen_loss = 0.8015210417647624, disc_loss = 0.09174856075619753
Trained batch 783 in epoch 7, gen_loss = 0.8012374371898418, disc_loss = 0.09184846426692925
Trained batch 784 in epoch 7, gen_loss = 0.80176966357383, disc_loss = 0.09193627268882694
Trained batch 785 in epoch 7, gen_loss = 0.8016922609648328, disc_loss = 0.09190349698152023
Trained batch 786 in epoch 7, gen_loss = 0.8015904993841275, disc_loss = 0.09185447741011123
Trained batch 787 in epoch 7, gen_loss = 0.8020576702307929, disc_loss = 0.09195513763526444
Trained batch 788 in epoch 7, gen_loss = 0.8021101353286337, disc_loss = 0.09190420086137922
Trained batch 789 in epoch 7, gen_loss = 0.8019442113139962, disc_loss = 0.0919105457849329
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.7669321298599243, disc_loss = 0.05313427001237869
Trained batch 1 in epoch 8, gen_loss = 0.9030815958976746, disc_loss = 0.08996813371777534
Trained batch 2 in epoch 8, gen_loss = 0.781181275844574, disc_loss = 0.14017354200283685
Trained batch 3 in epoch 8, gen_loss = 0.8283642679452896, disc_loss = 0.11210935655981302
Trained batch 4 in epoch 8, gen_loss = 0.8929508805274964, disc_loss = 0.10164473354816436
Trained batch 5 in epoch 8, gen_loss = 0.8561038076877594, disc_loss = 0.10588780293862025
Trained batch 6 in epoch 8, gen_loss = 0.8126756719180516, disc_loss = 0.12009353509971074
Trained batch 7 in epoch 8, gen_loss = 0.808577761054039, disc_loss = 0.11227167584002018
Trained batch 8 in epoch 8, gen_loss = 0.8071300188700358, disc_loss = 0.109144007994069
Trained batch 9 in epoch 8, gen_loss = 0.8383569478988647, disc_loss = 0.11148792132735252
Trained batch 10 in epoch 8, gen_loss = 0.8196728446266868, disc_loss = 0.11132749237797478
Trained batch 11 in epoch 8, gen_loss = 0.8321398148934046, disc_loss = 0.10593843646347523
Trained batch 12 in epoch 8, gen_loss = 0.8499212861061096, disc_loss = 0.09970680695886795
Trained batch 13 in epoch 8, gen_loss = 0.8369943712438855, disc_loss = 0.10136274421321494
Trained batch 14 in epoch 8, gen_loss = 0.8437562028566996, disc_loss = 0.09829209359983603
Trained batch 15 in epoch 8, gen_loss = 0.8326124474406242, disc_loss = 0.09509301267098635
Trained batch 16 in epoch 8, gen_loss = 0.834709693403805, disc_loss = 0.09108677692711353
Trained batch 17 in epoch 8, gen_loss = 0.8296232554647658, disc_loss = 0.08867780088136594
Trained batch 18 in epoch 8, gen_loss = 0.8342598676681519, disc_loss = 0.08974954613337391
Trained batch 19 in epoch 8, gen_loss = 0.828555303812027, disc_loss = 0.08817250626161695
Trained batch 20 in epoch 8, gen_loss = 0.8245734316962106, disc_loss = 0.08544236412715345
Trained batch 21 in epoch 8, gen_loss = 0.8274415297941728, disc_loss = 0.09015712268989194
Trained batch 22 in epoch 8, gen_loss = 0.8282194293063619, disc_loss = 0.08746369207358878
Trained batch 23 in epoch 8, gen_loss = 0.8148001233736674, disc_loss = 0.0930537732783705
Trained batch 24 in epoch 8, gen_loss = 0.8254913806915283, disc_loss = 0.09775253795087338
Trained batch 25 in epoch 8, gen_loss = 0.8322068819632897, disc_loss = 0.09553185943514109
Trained batch 26 in epoch 8, gen_loss = 0.8262184725867378, disc_loss = 0.09460419340542069
Trained batch 27 in epoch 8, gen_loss = 0.824719956942967, disc_loss = 0.09356701806453722
Trained batch 28 in epoch 8, gen_loss = 0.8289716922003647, disc_loss = 0.0918450444808294
Trained batch 29 in epoch 8, gen_loss = 0.8306900302569071, disc_loss = 0.09170432109385729
Trained batch 30 in epoch 8, gen_loss = 0.8266736268997192, disc_loss = 0.09174645373657826
Trained batch 31 in epoch 8, gen_loss = 0.821352157741785, disc_loss = 0.09252225182717666
Trained batch 32 in epoch 8, gen_loss = 0.8308695915973547, disc_loss = 0.09354852811630929
Trained batch 33 in epoch 8, gen_loss = 0.8284868615515092, disc_loss = 0.0926681478124331
Trained batch 34 in epoch 8, gen_loss = 0.8217835749898638, disc_loss = 0.09280706511012145
Trained batch 35 in epoch 8, gen_loss = 0.8239666869242986, disc_loss = 0.09079609195598298
Trained batch 36 in epoch 8, gen_loss = 0.8346415903117206, disc_loss = 0.09125504305435193
Trained batch 37 in epoch 8, gen_loss = 0.8346630021145469, disc_loss = 0.08941741341626958
Trained batch 38 in epoch 8, gen_loss = 0.8325395156175662, disc_loss = 0.08868538774549961
Trained batch 39 in epoch 8, gen_loss = 0.8384752839803695, disc_loss = 0.08841025824658573
Trained batch 40 in epoch 8, gen_loss = 0.8352480719729167, disc_loss = 0.08862832620194773
Trained batch 41 in epoch 8, gen_loss = 0.8305831196762267, disc_loss = 0.08920581900470313
Trained batch 42 in epoch 8, gen_loss = 0.8315572419831919, disc_loss = 0.09110321360098761
Trained batch 43 in epoch 8, gen_loss = 0.8363692123781551, disc_loss = 0.09016296144744212
Trained batch 44 in epoch 8, gen_loss = 0.8365247633722094, disc_loss = 0.09066281331082185
Trained batch 45 in epoch 8, gen_loss = 0.837442837331606, disc_loss = 0.09303036149915146
Trained batch 46 in epoch 8, gen_loss = 0.8347153574862378, disc_loss = 0.09295331207203104
Trained batch 47 in epoch 8, gen_loss = 0.8332326759894689, disc_loss = 0.09233132233687986
Trained batch 48 in epoch 8, gen_loss = 0.832999129684604, disc_loss = 0.09257188648441617
Trained batch 49 in epoch 8, gen_loss = 0.8293296706676483, disc_loss = 0.09172717977315187
Trained batch 50 in epoch 8, gen_loss = 0.8290293064771914, disc_loss = 0.09335643275841779
Trained batch 51 in epoch 8, gen_loss = 0.8264435609945884, disc_loss = 0.0935338088311255
Trained batch 52 in epoch 8, gen_loss = 0.8252679829327565, disc_loss = 0.09328726050004645
Trained batch 53 in epoch 8, gen_loss = 0.8209558350068552, disc_loss = 0.09383683848298258
Trained batch 54 in epoch 8, gen_loss = 0.8183125008236278, disc_loss = 0.09407084465704181
Trained batch 55 in epoch 8, gen_loss = 0.8189411961606571, disc_loss = 0.09417165553064219
Trained batch 56 in epoch 8, gen_loss = 0.8139432815083286, disc_loss = 0.09527642949762051
Trained batch 57 in epoch 8, gen_loss = 0.81736663908794, disc_loss = 0.09550158207401119
Trained batch 58 in epoch 8, gen_loss = 0.8154577905848875, disc_loss = 0.09513852319096104
Trained batch 59 in epoch 8, gen_loss = 0.8145988901456197, disc_loss = 0.09417775313680371
Trained batch 60 in epoch 8, gen_loss = 0.8141244767142124, disc_loss = 0.0930608332340346
Trained batch 61 in epoch 8, gen_loss = 0.8151298684458579, disc_loss = 0.09270083600835453
Trained batch 62 in epoch 8, gen_loss = 0.8163718817726014, disc_loss = 0.09141462772256798
Trained batch 63 in epoch 8, gen_loss = 0.8167315796017647, disc_loss = 0.09049799622152932
Trained batch 64 in epoch 8, gen_loss = 0.8147700850780194, disc_loss = 0.08971148995825877
Trained batch 65 in epoch 8, gen_loss = 0.8160527592355554, disc_loss = 0.08919316194387096
Trained batch 66 in epoch 8, gen_loss = 0.8180304525503471, disc_loss = 0.08823561012300092
Trained batch 67 in epoch 8, gen_loss = 0.8168011246358647, disc_loss = 0.08735415558604633
Trained batch 68 in epoch 8, gen_loss = 0.8134313744047413, disc_loss = 0.08844044048717056
Trained batch 69 in epoch 8, gen_loss = 0.8142182631152016, disc_loss = 0.08760079555213451
Trained batch 70 in epoch 8, gen_loss = 0.8146098927712776, disc_loss = 0.08772847901137781
Trained batch 71 in epoch 8, gen_loss = 0.815179742872715, disc_loss = 0.08726568463154966
Trained batch 72 in epoch 8, gen_loss = 0.8142370973547844, disc_loss = 0.0872361479862912
Trained batch 73 in epoch 8, gen_loss = 0.8141996127528113, disc_loss = 0.0868285916040878
Trained batch 74 in epoch 8, gen_loss = 0.8115740489959716, disc_loss = 0.08639849498867988
Trained batch 75 in epoch 8, gen_loss = 0.8147927554030168, disc_loss = 0.08824574648353614
Trained batch 76 in epoch 8, gen_loss = 0.8168038547813118, disc_loss = 0.0874159075803571
Trained batch 77 in epoch 8, gen_loss = 0.8167373637358347, disc_loss = 0.08709671653998204
Trained batch 78 in epoch 8, gen_loss = 0.8147821856450431, disc_loss = 0.08750864853964577
Trained batch 79 in epoch 8, gen_loss = 0.8146564744412899, disc_loss = 0.08861312018707394
Trained batch 80 in epoch 8, gen_loss = 0.8166214919384615, disc_loss = 0.08900884078976548
Trained batch 81 in epoch 8, gen_loss = 0.8145565296091685, disc_loss = 0.08907897279756825
Trained batch 82 in epoch 8, gen_loss = 0.8121471907719072, disc_loss = 0.08892593990607434
Trained batch 83 in epoch 8, gen_loss = 0.8125647221292768, disc_loss = 0.08819008126322712
Trained batch 84 in epoch 8, gen_loss = 0.8145664691925049, disc_loss = 0.08747567188213853
Trained batch 85 in epoch 8, gen_loss = 0.8154645243356394, disc_loss = 0.08675761737449225
Trained batch 86 in epoch 8, gen_loss = 0.8123035451461529, disc_loss = 0.08791805572550872
Trained batch 87 in epoch 8, gen_loss = 0.8118690516461026, disc_loss = 0.0874418354677883
Trained batch 88 in epoch 8, gen_loss = 0.8128405608487933, disc_loss = 0.08798305983288904
Trained batch 89 in epoch 8, gen_loss = 0.8128035406271616, disc_loss = 0.08754260465502739
Trained batch 90 in epoch 8, gen_loss = 0.8136094716879038, disc_loss = 0.08702414163521358
Trained batch 91 in epoch 8, gen_loss = 0.8157952609269515, disc_loss = 0.0873631968608369
Trained batch 92 in epoch 8, gen_loss = 0.8119254999904222, disc_loss = 0.09290959798200156
Trained batch 93 in epoch 8, gen_loss = 0.8124436625140778, disc_loss = 0.0928330493575715
Trained batch 94 in epoch 8, gen_loss = 0.8147067826045187, disc_loss = 0.09442268194336641
Trained batch 95 in epoch 8, gen_loss = 0.8113520098850131, disc_loss = 0.0949916741034637
Trained batch 96 in epoch 8, gen_loss = 0.8111946954555118, disc_loss = 0.09456281797941198
Trained batch 97 in epoch 8, gen_loss = 0.8088647312655741, disc_loss = 0.09479076571154352
Trained batch 98 in epoch 8, gen_loss = 0.8075751099321578, disc_loss = 0.09483068470250476
Trained batch 99 in epoch 8, gen_loss = 0.8079637721180916, disc_loss = 0.09434064496308565
Trained batch 100 in epoch 8, gen_loss = 0.807017327830343, disc_loss = 0.09437777267971842
Trained batch 101 in epoch 8, gen_loss = 0.8081026676238752, disc_loss = 0.09373673042465075
Trained batch 102 in epoch 8, gen_loss = 0.8088619248959624, disc_loss = 0.093432873360885
Trained batch 103 in epoch 8, gen_loss = 0.8068469771398947, disc_loss = 0.0929367072486247
Trained batch 104 in epoch 8, gen_loss = 0.8058212413674309, disc_loss = 0.09274715839752129
Trained batch 105 in epoch 8, gen_loss = 0.8082365941888882, disc_loss = 0.09427663404494524
Trained batch 106 in epoch 8, gen_loss = 0.8085605276522235, disc_loss = 0.09416057331330865
Trained batch 107 in epoch 8, gen_loss = 0.8057093369188132, disc_loss = 0.09538194228446593
Trained batch 108 in epoch 8, gen_loss = 0.8030442067789375, disc_loss = 0.09565838783500938
Trained batch 109 in epoch 8, gen_loss = 0.8045230716466903, disc_loss = 0.09569933869960633
Trained batch 110 in epoch 8, gen_loss = 0.8066602249940237, disc_loss = 0.09674774481168201
Trained batch 111 in epoch 8, gen_loss = 0.8044448029249907, disc_loss = 0.09690484918454396
Trained batch 112 in epoch 8, gen_loss = 0.8018584043051289, disc_loss = 0.09734188107592343
Trained batch 113 in epoch 8, gen_loss = 0.8048896677138513, disc_loss = 0.09900399854635461
Trained batch 114 in epoch 8, gen_loss = 0.8034797484460084, disc_loss = 0.09915254383307437
Trained batch 115 in epoch 8, gen_loss = 0.8019348549945601, disc_loss = 0.09903783513361523
Trained batch 116 in epoch 8, gen_loss = 0.8010333916570387, disc_loss = 0.09863341537614663
Trained batch 117 in epoch 8, gen_loss = 0.8012645418866206, disc_loss = 0.09809320216398623
Trained batch 118 in epoch 8, gen_loss = 0.8016717706908699, disc_loss = 0.09803995206764266
Trained batch 119 in epoch 8, gen_loss = 0.8028563601275285, disc_loss = 0.0973365562967956
Trained batch 120 in epoch 8, gen_loss = 0.8009855129009436, disc_loss = 0.09754620304654453
Trained batch 121 in epoch 8, gen_loss = 0.8004072921686485, disc_loss = 0.09731292684913659
Trained batch 122 in epoch 8, gen_loss = 0.8000807289670153, disc_loss = 0.09701442945657707
Trained batch 123 in epoch 8, gen_loss = 0.8035351396087678, disc_loss = 0.09755467344075441
Trained batch 124 in epoch 8, gen_loss = 0.8036585438251496, disc_loss = 0.09700076660513877
Trained batch 125 in epoch 8, gen_loss = 0.802146501247845, disc_loss = 0.09683148938393782
Trained batch 126 in epoch 8, gen_loss = 0.8024050924252337, disc_loss = 0.09669089314388478
Trained batch 127 in epoch 8, gen_loss = 0.8006341129075736, disc_loss = 0.09657752115163021
Trained batch 128 in epoch 8, gen_loss = 0.7984015084514322, disc_loss = 0.09690140184852504
Trained batch 129 in epoch 8, gen_loss = 0.7995707835142429, disc_loss = 0.09854980669915676
Trained batch 130 in epoch 8, gen_loss = 0.7983469938048879, disc_loss = 0.09890854458203753
Trained batch 131 in epoch 8, gen_loss = 0.7985929103963303, disc_loss = 0.09836015664041042
Trained batch 132 in epoch 8, gen_loss = 0.7991539753021154, disc_loss = 0.0977824049112492
Trained batch 133 in epoch 8, gen_loss = 0.7995056245309203, disc_loss = 0.09749359851564045
Trained batch 134 in epoch 8, gen_loss = 0.7998163596347526, disc_loss = 0.09696482520688463
Trained batch 135 in epoch 8, gen_loss = 0.7994299094904872, disc_loss = 0.09677469293477342
Trained batch 136 in epoch 8, gen_loss = 0.7991097106115661, disc_loss = 0.09661404719154765
Trained batch 137 in epoch 8, gen_loss = 0.8009020653755768, disc_loss = 0.09619295468850844
Trained batch 138 in epoch 8, gen_loss = 0.8013054331858381, disc_loss = 0.09576138442636822
Trained batch 139 in epoch 8, gen_loss = 0.7995514084185873, disc_loss = 0.09698966184098806
Trained batch 140 in epoch 8, gen_loss = 0.8033598490217899, disc_loss = 0.09812634820052495
Trained batch 141 in epoch 8, gen_loss = 0.8017688987540527, disc_loss = 0.09848777221804353
Trained batch 142 in epoch 8, gen_loss = 0.8017920228567991, disc_loss = 0.09830620266184524
Trained batch 143 in epoch 8, gen_loss = 0.8008875244607528, disc_loss = 0.09879530238039377
Trained batch 144 in epoch 8, gen_loss = 0.8000763977396077, disc_loss = 0.09879729302021964
Trained batch 145 in epoch 8, gen_loss = 0.7999312055029281, disc_loss = 0.09850683988212314
Trained batch 146 in epoch 8, gen_loss = 0.8003008801515411, disc_loss = 0.0981595020893277
Trained batch 147 in epoch 8, gen_loss = 0.7989478789874025, disc_loss = 0.09794275939615595
Trained batch 148 in epoch 8, gen_loss = 0.7988942819553734, disc_loss = 0.09760778076046665
Trained batch 149 in epoch 8, gen_loss = 0.7989477191368739, disc_loss = 0.09792940570662419
Trained batch 150 in epoch 8, gen_loss = 0.7994610815253479, disc_loss = 0.09744965644022882
Trained batch 151 in epoch 8, gen_loss = 0.7989364115423278, disc_loss = 0.0971159449116768
Trained batch 152 in epoch 8, gen_loss = 0.7981253178680644, disc_loss = 0.09725773343025079
Trained batch 153 in epoch 8, gen_loss = 0.7986668717938584, disc_loss = 0.09700199326669628
Trained batch 154 in epoch 8, gen_loss = 0.8020149536671177, disc_loss = 0.09677467597348074
Trained batch 155 in epoch 8, gen_loss = 0.8028918357613759, disc_loss = 0.09630372635542582
Trained batch 156 in epoch 8, gen_loss = 0.802083583584257, disc_loss = 0.09658606172462178
Trained batch 157 in epoch 8, gen_loss = 0.8019552677869797, disc_loss = 0.09622893121706534
Trained batch 158 in epoch 8, gen_loss = 0.8040948448316106, disc_loss = 0.09611299837816437
Trained batch 159 in epoch 8, gen_loss = 0.8052581729367375, disc_loss = 0.09582724350038915
Trained batch 160 in epoch 8, gen_loss = 0.804929339552518, disc_loss = 0.09549830208376328
Trained batch 161 in epoch 8, gen_loss = 0.804908631944362, disc_loss = 0.09532260538343294
Trained batch 162 in epoch 8, gen_loss = 0.8053008714702232, disc_loss = 0.09498058600019824
Trained batch 163 in epoch 8, gen_loss = 0.8052122078654242, disc_loss = 0.09457971423682643
Trained batch 164 in epoch 8, gen_loss = 0.8083173153978406, disc_loss = 0.09616134397008202
Trained batch 165 in epoch 8, gen_loss = 0.8064662119351238, disc_loss = 0.09643488848604352
Trained batch 166 in epoch 8, gen_loss = 0.805520219181826, disc_loss = 0.09657929382638303
Trained batch 167 in epoch 8, gen_loss = 0.8046838923224381, disc_loss = 0.09662414351034732
Trained batch 168 in epoch 8, gen_loss = 0.8050734197952338, disc_loss = 0.09657787580109208
Trained batch 169 in epoch 8, gen_loss = 0.8042337507009506, disc_loss = 0.0966038159587804
Trained batch 170 in epoch 8, gen_loss = 0.8051341784279249, disc_loss = 0.09629054374077864
Trained batch 171 in epoch 8, gen_loss = 0.8069784965279491, disc_loss = 0.09738996622780728
Trained batch 172 in epoch 8, gen_loss = 0.805646861736485, disc_loss = 0.09802602117375142
Trained batch 173 in epoch 8, gen_loss = 0.8059182857302414, disc_loss = 0.09775830524834409
Trained batch 174 in epoch 8, gen_loss = 0.8061563360691071, disc_loss = 0.09752304841365134
Trained batch 175 in epoch 8, gen_loss = 0.8072572037238966, disc_loss = 0.09776824287308211
Trained batch 176 in epoch 8, gen_loss = 0.8082553395780466, disc_loss = 0.09755117380938962
Trained batch 177 in epoch 8, gen_loss = 0.8079195436132088, disc_loss = 0.09755870421532165
Trained batch 178 in epoch 8, gen_loss = 0.8073385759105896, disc_loss = 0.0973379547869027
Trained batch 179 in epoch 8, gen_loss = 0.8088520849744479, disc_loss = 0.09724968228903082
Trained batch 180 in epoch 8, gen_loss = 0.8088119871379262, disc_loss = 0.09689643900862056
Trained batch 181 in epoch 8, gen_loss = 0.8074594780311479, disc_loss = 0.09721523118051854
Trained batch 182 in epoch 8, gen_loss = 0.8098722140971428, disc_loss = 0.09755938337311719
Trained batch 183 in epoch 8, gen_loss = 0.8108747107503207, disc_loss = 0.09715343321390126
Trained batch 184 in epoch 8, gen_loss = 0.8094316468045518, disc_loss = 0.09746262646607451
Trained batch 185 in epoch 8, gen_loss = 0.8106556924120072, disc_loss = 0.09712575109655498
Trained batch 186 in epoch 8, gen_loss = 0.8119464862474146, disc_loss = 0.09690565442576765
Trained batch 187 in epoch 8, gen_loss = 0.811182347225382, disc_loss = 0.09674455144224649
Trained batch 188 in epoch 8, gen_loss = 0.8103667745199153, disc_loss = 0.09658944265788826
Trained batch 189 in epoch 8, gen_loss = 0.8109069439925646, disc_loss = 0.09647287681306663
Trained batch 190 in epoch 8, gen_loss = 0.8101731153370823, disc_loss = 0.09634481754680578
Trained batch 191 in epoch 8, gen_loss = 0.8094631208417317, disc_loss = 0.09611698463171099
Trained batch 192 in epoch 8, gen_loss = 0.8095998743963982, disc_loss = 0.09577125888028293
Trained batch 193 in epoch 8, gen_loss = 0.8091738259362191, disc_loss = 0.09575583146328163
Trained batch 194 in epoch 8, gen_loss = 0.8078745650939453, disc_loss = 0.09612675704635107
Trained batch 195 in epoch 8, gen_loss = 0.8076704903220644, disc_loss = 0.09585386391120906
Trained batch 196 in epoch 8, gen_loss = 0.8088785408414559, disc_loss = 0.09583446003383186
Trained batch 197 in epoch 8, gen_loss = 0.8084149262820831, disc_loss = 0.09561209117222313
Trained batch 198 in epoch 8, gen_loss = 0.8086642900004459, disc_loss = 0.09555791119984047
Trained batch 199 in epoch 8, gen_loss = 0.8083108116686344, disc_loss = 0.0952701304666698
Trained batch 200 in epoch 8, gen_loss = 0.8078811413316584, disc_loss = 0.0949487044146998
Trained batch 201 in epoch 8, gen_loss = 0.8078593093864989, disc_loss = 0.09462768763377524
Trained batch 202 in epoch 8, gen_loss = 0.8078038188917883, disc_loss = 0.09460786060232834
Trained batch 203 in epoch 8, gen_loss = 0.807302266505419, disc_loss = 0.09437712104808466
Trained batch 204 in epoch 8, gen_loss = 0.807379916382999, disc_loss = 0.09407071823753961
Trained batch 205 in epoch 8, gen_loss = 0.8063656755732101, disc_loss = 0.09414148775553241
Trained batch 206 in epoch 8, gen_loss = 0.8062152777605011, disc_loss = 0.09464139080997827
Trained batch 207 in epoch 8, gen_loss = 0.8062064121835507, disc_loss = 0.09440935947574101
Trained batch 208 in epoch 8, gen_loss = 0.8050666264654917, disc_loss = 0.09449248475748956
Trained batch 209 in epoch 8, gen_loss = 0.8060401114679518, disc_loss = 0.0943945183285645
Trained batch 210 in epoch 8, gen_loss = 0.806337135804208, disc_loss = 0.09408071262859055
Trained batch 211 in epoch 8, gen_loss = 0.8065759046178944, disc_loss = 0.09384764852177985
Trained batch 212 in epoch 8, gen_loss = 0.8062267427992933, disc_loss = 0.09373965280506533
Trained batch 213 in epoch 8, gen_loss = 0.8055457593960182, disc_loss = 0.09372009436173417
Trained batch 214 in epoch 8, gen_loss = 0.8049103657866633, disc_loss = 0.09367098934775175
Trained batch 215 in epoch 8, gen_loss = 0.8065788275389759, disc_loss = 0.09378899304472187
Trained batch 216 in epoch 8, gen_loss = 0.8065758997119516, disc_loss = 0.09362067232414874
Trained batch 217 in epoch 8, gen_loss = 0.8055080980609316, disc_loss = 0.09354871892532625
Trained batch 218 in epoch 8, gen_loss = 0.8051519139444447, disc_loss = 0.09357246292168148
Trained batch 219 in epoch 8, gen_loss = 0.8057680524208329, disc_loss = 0.09322016294198958
Trained batch 220 in epoch 8, gen_loss = 0.8058404799769906, disc_loss = 0.09301958446353
Trained batch 221 in epoch 8, gen_loss = 0.8065356753162436, disc_loss = 0.0929894694085191
Trained batch 222 in epoch 8, gen_loss = 0.805510804391228, disc_loss = 0.09284859032875487
Trained batch 223 in epoch 8, gen_loss = 0.8054737109424812, disc_loss = 0.09283424460694992
Trained batch 224 in epoch 8, gen_loss = 0.8045933051904043, disc_loss = 0.0927312609139416
Trained batch 225 in epoch 8, gen_loss = 0.8058187219157683, disc_loss = 0.09267477505733218
Trained batch 226 in epoch 8, gen_loss = 0.8071441861763925, disc_loss = 0.09238069194332094
Trained batch 227 in epoch 8, gen_loss = 0.8060273979055254, disc_loss = 0.0925702732546549
Trained batch 228 in epoch 8, gen_loss = 0.8064205093415023, disc_loss = 0.09223589580912778
Trained batch 229 in epoch 8, gen_loss = 0.8064182394224665, disc_loss = 0.09203084038327569
Trained batch 230 in epoch 8, gen_loss = 0.8059071249518044, disc_loss = 0.09193240862452623
Trained batch 231 in epoch 8, gen_loss = 0.8056000161530643, disc_loss = 0.09181606536731124
Trained batch 232 in epoch 8, gen_loss = 0.8050888801081498, disc_loss = 0.0915494980410445
Trained batch 233 in epoch 8, gen_loss = 0.8050667002924488, disc_loss = 0.09155097142116636
Trained batch 234 in epoch 8, gen_loss = 0.8047246787142246, disc_loss = 0.09154558853900178
Trained batch 235 in epoch 8, gen_loss = 0.806022649725615, disc_loss = 0.09144014034862236
Trained batch 236 in epoch 8, gen_loss = 0.8073941535839049, disc_loss = 0.09122593820346558
Trained batch 237 in epoch 8, gen_loss = 0.8064588632653741, disc_loss = 0.09154375755235929
Trained batch 238 in epoch 8, gen_loss = 0.8059289022719012, disc_loss = 0.09137110444853495
Trained batch 239 in epoch 8, gen_loss = 0.806194830313325, disc_loss = 0.09158065444789827
Trained batch 240 in epoch 8, gen_loss = 0.8069467172335787, disc_loss = 0.09159989687478888
Trained batch 241 in epoch 8, gen_loss = 0.806803058371071, disc_loss = 0.09133596867630797
Trained batch 242 in epoch 8, gen_loss = 0.8062197304802177, disc_loss = 0.0913244962477635
Trained batch 243 in epoch 8, gen_loss = 0.8056424940462972, disc_loss = 0.09119630672159743
Trained batch 244 in epoch 8, gen_loss = 0.8060884554775394, disc_loss = 0.09091681663175019
Trained batch 245 in epoch 8, gen_loss = 0.8064676960551642, disc_loss = 0.09078111286025221
Trained batch 246 in epoch 8, gen_loss = 0.8074543930982289, disc_loss = 0.09048414719008241
Trained batch 247 in epoch 8, gen_loss = 0.8067995243735852, disc_loss = 0.09049722936845594
Trained batch 248 in epoch 8, gen_loss = 0.8064420243583051, disc_loss = 0.09066695770824769
Trained batch 249 in epoch 8, gen_loss = 0.8076272078752518, disc_loss = 0.09037309843301773
Trained batch 250 in epoch 8, gen_loss = 0.8084911113953686, disc_loss = 0.09016087210451464
Trained batch 251 in epoch 8, gen_loss = 0.8087175276780886, disc_loss = 0.08995753921390999
Trained batch 252 in epoch 8, gen_loss = 0.8077568047838248, disc_loss = 0.09023797516471783
Trained batch 253 in epoch 8, gen_loss = 0.8079346396087661, disc_loss = 0.09010668829318107
Trained batch 254 in epoch 8, gen_loss = 0.8078953342110503, disc_loss = 0.08987023637575262
Trained batch 255 in epoch 8, gen_loss = 0.8094686499098316, disc_loss = 0.09044387511676177
Trained batch 256 in epoch 8, gen_loss = 0.8085947571329569, disc_loss = 0.09057081487856022
Trained batch 257 in epoch 8, gen_loss = 0.8076498904662539, disc_loss = 0.09061875096125196
Trained batch 258 in epoch 8, gen_loss = 0.8074578611777096, disc_loss = 0.09052177952983664
Trained batch 259 in epoch 8, gen_loss = 0.8078928242509181, disc_loss = 0.09086694723138443
Trained batch 260 in epoch 8, gen_loss = 0.8076865856903266, disc_loss = 0.09085159069391047
Trained batch 261 in epoch 8, gen_loss = 0.8077004241351863, disc_loss = 0.09073494701781346
Trained batch 262 in epoch 8, gen_loss = 0.8075742661499705, disc_loss = 0.09060811401546681
Trained batch 263 in epoch 8, gen_loss = 0.8068349010339289, disc_loss = 0.09096312212447326
Trained batch 264 in epoch 8, gen_loss = 0.8069300189333142, disc_loss = 0.09078358943169972
Trained batch 265 in epoch 8, gen_loss = 0.8072954999997204, disc_loss = 0.09050152606253785
Trained batch 266 in epoch 8, gen_loss = 0.8066667056039032, disc_loss = 0.0906010696364476
Trained batch 267 in epoch 8, gen_loss = 0.8085463919968747, disc_loss = 0.09097153558604308
Trained batch 268 in epoch 8, gen_loss = 0.8080220837353773, disc_loss = 0.09100794214686053
Trained batch 269 in epoch 8, gen_loss = 0.8076186858945422, disc_loss = 0.09083701757093271
Trained batch 270 in epoch 8, gen_loss = 0.8080688377368054, disc_loss = 0.09059304383847987
Trained batch 271 in epoch 8, gen_loss = 0.80960711540983, disc_loss = 0.09099013971931794
Trained batch 272 in epoch 8, gen_loss = 0.8083176492771387, disc_loss = 0.09209443426830864
Trained batch 273 in epoch 8, gen_loss = 0.8087206341489388, disc_loss = 0.09191911153658464
Trained batch 274 in epoch 8, gen_loss = 0.808730813589963, disc_loss = 0.0920950476418842
Trained batch 275 in epoch 8, gen_loss = 0.8084328232899957, disc_loss = 0.09218611184885536
Trained batch 276 in epoch 8, gen_loss = 0.8073279737135133, disc_loss = 0.0924143225815322
Trained batch 277 in epoch 8, gen_loss = 0.8084934692588641, disc_loss = 0.09241627767789277
Trained batch 278 in epoch 8, gen_loss = 0.8081456286078286, disc_loss = 0.09221970108354391
Trained batch 279 in epoch 8, gen_loss = 0.8091359989983695, disc_loss = 0.09204334414431027
Trained batch 280 in epoch 8, gen_loss = 0.8084824176445551, disc_loss = 0.09239488850708959
Trained batch 281 in epoch 8, gen_loss = 0.8088118968703223, disc_loss = 0.09244120472394829
Trained batch 282 in epoch 8, gen_loss = 0.8090026250155149, disc_loss = 0.09231231012792974
Trained batch 283 in epoch 8, gen_loss = 0.8084893581313146, disc_loss = 0.09220731182312461
Trained batch 284 in epoch 8, gen_loss = 0.808217241680413, disc_loss = 0.09216278043755313
Trained batch 285 in epoch 8, gen_loss = 0.808943458995619, disc_loss = 0.09199467821085787
Trained batch 286 in epoch 8, gen_loss = 0.8092498033719611, disc_loss = 0.09173113486051351
Trained batch 287 in epoch 8, gen_loss = 0.8088003610157304, disc_loss = 0.09155593666946515
Trained batch 288 in epoch 8, gen_loss = 0.8085749046200287, disc_loss = 0.09137996837213172
Trained batch 289 in epoch 8, gen_loss = 0.8088330698424372, disc_loss = 0.09145717525148186
Trained batch 290 in epoch 8, gen_loss = 0.808704581662142, disc_loss = 0.09140639057658177
Trained batch 291 in epoch 8, gen_loss = 0.8083155034747842, disc_loss = 0.09122313554590084
Trained batch 292 in epoch 8, gen_loss = 0.8079171502142636, disc_loss = 0.09108626291333816
Trained batch 293 in epoch 8, gen_loss = 0.8087303176218149, disc_loss = 0.09090332330210882
Trained batch 294 in epoch 8, gen_loss = 0.8084025362790641, disc_loss = 0.09076929274883311
Trained batch 295 in epoch 8, gen_loss = 0.8083544389621632, disc_loss = 0.090585760665252
Trained batch 296 in epoch 8, gen_loss = 0.8090415916057548, disc_loss = 0.09040403817012053
Trained batch 297 in epoch 8, gen_loss = 0.8095231596255462, disc_loss = 0.09014681680440503
Trained batch 298 in epoch 8, gen_loss = 0.8100501591943977, disc_loss = 0.09002720962051165
Trained batch 299 in epoch 8, gen_loss = 0.8091924685239792, disc_loss = 0.0901791812106967
Trained batch 300 in epoch 8, gen_loss = 0.8091629729714505, disc_loss = 0.09010418711162088
Trained batch 301 in epoch 8, gen_loss = 0.8092612416933704, disc_loss = 0.08990897531220257
Trained batch 302 in epoch 8, gen_loss = 0.8109585021195238, disc_loss = 0.0898734986622243
Trained batch 303 in epoch 8, gen_loss = 0.8116157437233549, disc_loss = 0.08966439904179424
Trained batch 304 in epoch 8, gen_loss = 0.811593858531264, disc_loss = 0.08941080329603836
Trained batch 305 in epoch 8, gen_loss = 0.8108676905725517, disc_loss = 0.08947060962079786
Trained batch 306 in epoch 8, gen_loss = 0.8112776273624904, disc_loss = 0.08924769173324691
Trained batch 307 in epoch 8, gen_loss = 0.8122041955009683, disc_loss = 0.08909099643396867
Trained batch 308 in epoch 8, gen_loss = 0.8124267294954713, disc_loss = 0.0888525930151922
Trained batch 309 in epoch 8, gen_loss = 0.8122009650353462, disc_loss = 0.08884595552940042
Trained batch 310 in epoch 8, gen_loss = 0.8126385363351877, disc_loss = 0.08858795505663877
Trained batch 311 in epoch 8, gen_loss = 0.8129017754242971, disc_loss = 0.0884066766145854
Trained batch 312 in epoch 8, gen_loss = 0.8137530431198997, disc_loss = 0.08825366312977129
Trained batch 313 in epoch 8, gen_loss = 0.814098757923029, disc_loss = 0.08806646251932355
Trained batch 314 in epoch 8, gen_loss = 0.813433351403191, disc_loss = 0.08807187602810916
Trained batch 315 in epoch 8, gen_loss = 0.8128343392399293, disc_loss = 0.08794449750463702
Trained batch 316 in epoch 8, gen_loss = 0.8134021629294387, disc_loss = 0.0877166997600194
Trained batch 317 in epoch 8, gen_loss = 0.8141640973915844, disc_loss = 0.08782942350309506
Trained batch 318 in epoch 8, gen_loss = 0.8144143522719978, disc_loss = 0.08765261274321606
Trained batch 319 in epoch 8, gen_loss = 0.8139488773420454, disc_loss = 0.08762758264492732
Trained batch 320 in epoch 8, gen_loss = 0.8135036592171571, disc_loss = 0.08748691289676963
Trained batch 321 in epoch 8, gen_loss = 0.8155138242688978, disc_loss = 0.08775389240476193
Trained batch 322 in epoch 8, gen_loss = 0.8144548193958152, disc_loss = 0.08813448466833439
Trained batch 323 in epoch 8, gen_loss = 0.8144110525831764, disc_loss = 0.08811223350269835
Trained batch 324 in epoch 8, gen_loss = 0.8142360551540668, disc_loss = 0.08798274701317915
Trained batch 325 in epoch 8, gen_loss = 0.8145902103807298, disc_loss = 0.08889195918065547
Trained batch 326 in epoch 8, gen_loss = 0.8139058408022656, disc_loss = 0.0888291213302574
Trained batch 327 in epoch 8, gen_loss = 0.8131856204169553, disc_loss = 0.08900189200677432
Trained batch 328 in epoch 8, gen_loss = 0.8136852880017011, disc_loss = 0.08924387699689455
Trained batch 329 in epoch 8, gen_loss = 0.8130098613825711, disc_loss = 0.08935370608656244
Trained batch 330 in epoch 8, gen_loss = 0.8126971633412686, disc_loss = 0.08934078625265475
Trained batch 331 in epoch 8, gen_loss = 0.812879382307271, disc_loss = 0.08920444994435522
Trained batch 332 in epoch 8, gen_loss = 0.8132348703192519, disc_loss = 0.08905973169930256
Trained batch 333 in epoch 8, gen_loss = 0.8130742459596988, disc_loss = 0.08903572387982182
Trained batch 334 in epoch 8, gen_loss = 0.8133824296851656, disc_loss = 0.08911431194630577
Trained batch 335 in epoch 8, gen_loss = 0.8133916562157018, disc_loss = 0.08897830056680721
Trained batch 336 in epoch 8, gen_loss = 0.8128042969222592, disc_loss = 0.08903836086116046
Trained batch 337 in epoch 8, gen_loss = 0.8134722743161331, disc_loss = 0.08881277077109415
Trained batch 338 in epoch 8, gen_loss = 0.8136263029061939, disc_loss = 0.08859712659356604
Trained batch 339 in epoch 8, gen_loss = 0.813643206743633, disc_loss = 0.08840575665509438
Trained batch 340 in epoch 8, gen_loss = 0.814383040949746, disc_loss = 0.08819457970810862
Trained batch 341 in epoch 8, gen_loss = 0.8141965505323912, disc_loss = 0.08811220396255627
Trained batch 342 in epoch 8, gen_loss = 0.8154784828511341, disc_loss = 0.08805888224632069
Trained batch 343 in epoch 8, gen_loss = 0.8154158211031626, disc_loss = 0.08795039060384814
Trained batch 344 in epoch 8, gen_loss = 0.8151431415392005, disc_loss = 0.08784363406129937
Trained batch 345 in epoch 8, gen_loss = 0.8149846247854949, disc_loss = 0.087759287147702
Trained batch 346 in epoch 8, gen_loss = 0.8144752481141764, disc_loss = 0.08772969472702453
Trained batch 347 in epoch 8, gen_loss = 0.814550806736124, disc_loss = 0.08762705796291174
Trained batch 348 in epoch 8, gen_loss = 0.8146075401401793, disc_loss = 0.08789148943013056
Trained batch 349 in epoch 8, gen_loss = 0.8139095498834338, disc_loss = 0.08811025124841503
Trained batch 350 in epoch 8, gen_loss = 0.813633537360406, disc_loss = 0.08798519797103102
Trained batch 351 in epoch 8, gen_loss = 0.8143778873438184, disc_loss = 0.08846668333122083
Trained batch 352 in epoch 8, gen_loss = 0.8138397639939198, disc_loss = 0.08847148244984174
Trained batch 353 in epoch 8, gen_loss = 0.8135091627048234, disc_loss = 0.08837232525370974
Trained batch 354 in epoch 8, gen_loss = 0.8135440169925421, disc_loss = 0.08853578392521176
Trained batch 355 in epoch 8, gen_loss = 0.8131126388070289, disc_loss = 0.08849298206074269
Trained batch 356 in epoch 8, gen_loss = 0.8137014992430764, disc_loss = 0.0883142337469118
Trained batch 357 in epoch 8, gen_loss = 0.8133783447009891, disc_loss = 0.08837875353130797
Trained batch 358 in epoch 8, gen_loss = 0.8135041719027548, disc_loss = 0.08821424281271305
Trained batch 359 in epoch 8, gen_loss = 0.8146733979384104, disc_loss = 0.08832315193851376
Trained batch 360 in epoch 8, gen_loss = 0.8148172061859406, disc_loss = 0.08815634582150428
Trained batch 361 in epoch 8, gen_loss = 0.8143737897359206, disc_loss = 0.08823182081124482
Trained batch 362 in epoch 8, gen_loss = 0.8143703952308529, disc_loss = 0.08810802429308986
Trained batch 363 in epoch 8, gen_loss = 0.8141215261849728, disc_loss = 0.08803686487570322
Trained batch 364 in epoch 8, gen_loss = 0.8145075829061743, disc_loss = 0.08789416118078444
Trained batch 365 in epoch 8, gen_loss = 0.8140290690575792, disc_loss = 0.08783778036522165
Trained batch 366 in epoch 8, gen_loss = 0.8135484861418077, disc_loss = 0.08787701672009048
Trained batch 367 in epoch 8, gen_loss = 0.8136686272919178, disc_loss = 0.08808781074248659
Trained batch 368 in epoch 8, gen_loss = 0.8132841895589338, disc_loss = 0.08804986968404313
Trained batch 369 in epoch 8, gen_loss = 0.8129541037855922, disc_loss = 0.08804160277233333
Trained batch 370 in epoch 8, gen_loss = 0.8130803238349462, disc_loss = 0.08789060139561679
Trained batch 371 in epoch 8, gen_loss = 0.8122079079189608, disc_loss = 0.08816234816757021
Trained batch 372 in epoch 8, gen_loss = 0.8119922056594419, disc_loss = 0.0881376617760385
Trained batch 373 in epoch 8, gen_loss = 0.8116694821074685, disc_loss = 0.08815209738123306
Trained batch 374 in epoch 8, gen_loss = 0.8109519578615825, disc_loss = 0.0883286067172885
Trained batch 375 in epoch 8, gen_loss = 0.8115477205273953, disc_loss = 0.08836095819021872
Trained batch 376 in epoch 8, gen_loss = 0.810814868391983, disc_loss = 0.08866644398968875
Trained batch 377 in epoch 8, gen_loss = 0.8108977834699015, disc_loss = 0.0887978331915167
Trained batch 378 in epoch 8, gen_loss = 0.8107324527247285, disc_loss = 0.08905893418013971
Trained batch 379 in epoch 8, gen_loss = 0.8116476090330826, disc_loss = 0.08971258985417846
Trained batch 380 in epoch 8, gen_loss = 0.811517419464632, disc_loss = 0.08967940809738058
Trained batch 381 in epoch 8, gen_loss = 0.8110817522590698, disc_loss = 0.08984488138870497
Trained batch 382 in epoch 8, gen_loss = 0.8115379035317244, disc_loss = 0.08977894161343963
Trained batch 383 in epoch 8, gen_loss = 0.8113055160890023, disc_loss = 0.0897504873695046
Trained batch 384 in epoch 8, gen_loss = 0.8111491416955923, disc_loss = 0.08984701212785848
Trained batch 385 in epoch 8, gen_loss = 0.8109202985627664, disc_loss = 0.08988264791059447
Trained batch 386 in epoch 8, gen_loss = 0.8102144669808775, disc_loss = 0.09000475921497249
Trained batch 387 in epoch 8, gen_loss = 0.8099912683066633, disc_loss = 0.09014741562969368
Trained batch 388 in epoch 8, gen_loss = 0.8103527248978308, disc_loss = 0.0901664524892187
Trained batch 389 in epoch 8, gen_loss = 0.8098420405999208, disc_loss = 0.09035523338243365
Trained batch 390 in epoch 8, gen_loss = 0.8096541590093042, disc_loss = 0.0901850599323964
Trained batch 391 in epoch 8, gen_loss = 0.8093419810947107, disc_loss = 0.09018911191081742
Trained batch 392 in epoch 8, gen_loss = 0.808947518884984, disc_loss = 0.09021572430994902
Trained batch 393 in epoch 8, gen_loss = 0.8088527923913171, disc_loss = 0.09015487975719844
Trained batch 394 in epoch 8, gen_loss = 0.8096626049355615, disc_loss = 0.09059502272807722
Trained batch 395 in epoch 8, gen_loss = 0.8089828966843962, disc_loss = 0.09082918672239164
Trained batch 396 in epoch 8, gen_loss = 0.8089826700068842, disc_loss = 0.09071463205492691
Trained batch 397 in epoch 8, gen_loss = 0.8094110175892336, disc_loss = 0.09065688418074694
Trained batch 398 in epoch 8, gen_loss = 0.8090140051710277, disc_loss = 0.09058365371208965
Trained batch 399 in epoch 8, gen_loss = 0.8088487058877945, disc_loss = 0.09042805207660422
Trained batch 400 in epoch 8, gen_loss = 0.8080272132024503, disc_loss = 0.09049352653965614
Trained batch 401 in epoch 8, gen_loss = 0.8083396473927285, disc_loss = 0.09069583672260986
Trained batch 402 in epoch 8, gen_loss = 0.8088898164758611, disc_loss = 0.09060643537307421
Trained batch 403 in epoch 8, gen_loss = 0.8083326937538562, disc_loss = 0.09060261486845073
Trained batch 404 in epoch 8, gen_loss = 0.8076650484108631, disc_loss = 0.0907367583019314
Trained batch 405 in epoch 8, gen_loss = 0.8073537381999011, disc_loss = 0.0905953211035451
Trained batch 406 in epoch 8, gen_loss = 0.8081548152450262, disc_loss = 0.09053413263071301
Trained batch 407 in epoch 8, gen_loss = 0.8090728717107399, disc_loss = 0.09049433194712608
Trained batch 408 in epoch 8, gen_loss = 0.8085053248335505, disc_loss = 0.09067827061246762
Trained batch 409 in epoch 8, gen_loss = 0.8082146332031344, disc_loss = 0.09070391410325722
Trained batch 410 in epoch 8, gen_loss = 0.8078246148543347, disc_loss = 0.09082594512760131
Trained batch 411 in epoch 8, gen_loss = 0.8072987119260343, disc_loss = 0.09089989517815411
Trained batch 412 in epoch 8, gen_loss = 0.8072583875990953, disc_loss = 0.09103998703065781
Trained batch 413 in epoch 8, gen_loss = 0.8070116496604421, disc_loss = 0.09094468484169259
Trained batch 414 in epoch 8, gen_loss = 0.807034110735698, disc_loss = 0.09078913432242999
Trained batch 415 in epoch 8, gen_loss = 0.8068413374802241, disc_loss = 0.09084107086304218
Trained batch 416 in epoch 8, gen_loss = 0.8068200958718499, disc_loss = 0.0908355619155353
Trained batch 417 in epoch 8, gen_loss = 0.8069372530759237, disc_loss = 0.09066377950689652
Trained batch 418 in epoch 8, gen_loss = 0.8066513309330815, disc_loss = 0.09067863844521788
Trained batch 419 in epoch 8, gen_loss = 0.8061097745384489, disc_loss = 0.09074679749485637
Trained batch 420 in epoch 8, gen_loss = 0.8063428426015405, disc_loss = 0.09068979708491128
Trained batch 421 in epoch 8, gen_loss = 0.8066336200418065, disc_loss = 0.09051340050615758
Trained batch 422 in epoch 8, gen_loss = 0.8066109589369302, disc_loss = 0.09037118438789819
Trained batch 423 in epoch 8, gen_loss = 0.8060250280881828, disc_loss = 0.09052050117412055
Trained batch 424 in epoch 8, gen_loss = 0.8063808624884662, disc_loss = 0.09048313228742165
Trained batch 425 in epoch 8, gen_loss = 0.8066291824472902, disc_loss = 0.09037317346318018
Trained batch 426 in epoch 8, gen_loss = 0.8062865057092081, disc_loss = 0.09035891340064012
Trained batch 427 in epoch 8, gen_loss = 0.8057422395621505, disc_loss = 0.090337338467851
Trained batch 428 in epoch 8, gen_loss = 0.8059096394718944, disc_loss = 0.09019600565486646
Trained batch 429 in epoch 8, gen_loss = 0.8064879758413448, disc_loss = 0.09020600326056051
Trained batch 430 in epoch 8, gen_loss = 0.8058739836973823, disc_loss = 0.09032548186336828
Trained batch 431 in epoch 8, gen_loss = 0.805692706671026, disc_loss = 0.09030367565315424
Trained batch 432 in epoch 8, gen_loss = 0.8054822424542821, disc_loss = 0.09042954273031505
Trained batch 433 in epoch 8, gen_loss = 0.8052733940188237, disc_loss = 0.09030789996321369
Trained batch 434 in epoch 8, gen_loss = 0.8051870185753395, disc_loss = 0.09037260707125239
Trained batch 435 in epoch 8, gen_loss = 0.8047945621090198, disc_loss = 0.09028038529704811
Trained batch 436 in epoch 8, gen_loss = 0.8047451682439931, disc_loss = 0.09014191140273684
Trained batch 437 in epoch 8, gen_loss = 0.8056242608860748, disc_loss = 0.09009590543610933
Trained batch 438 in epoch 8, gen_loss = 0.8055145673979931, disc_loss = 0.08995377558977226
Trained batch 439 in epoch 8, gen_loss = 0.8056418492035432, disc_loss = 0.08983533289918506
Trained batch 440 in epoch 8, gen_loss = 0.8057930800649855, disc_loss = 0.08968022158010408
Trained batch 441 in epoch 8, gen_loss = 0.8061814527975488, disc_loss = 0.08959756686870532
Trained batch 442 in epoch 8, gen_loss = 0.8063051700592041, disc_loss = 0.08965970491506917
Trained batch 443 in epoch 8, gen_loss = 0.8060459483851183, disc_loss = 0.0895923548566832
Trained batch 444 in epoch 8, gen_loss = 0.8059676098019889, disc_loss = 0.08955374644504169
Trained batch 445 in epoch 8, gen_loss = 0.8063062481548754, disc_loss = 0.0895884629368214
Trained batch 446 in epoch 8, gen_loss = 0.8057589642953553, disc_loss = 0.08974939411176865
Trained batch 447 in epoch 8, gen_loss = 0.8061327296974403, disc_loss = 0.08958737232647504
Trained batch 448 in epoch 8, gen_loss = 0.8062584789133815, disc_loss = 0.08960956998609156
Trained batch 449 in epoch 8, gen_loss = 0.8061733569039239, disc_loss = 0.08947961356697812
Trained batch 450 in epoch 8, gen_loss = 0.8055453053334864, disc_loss = 0.08960982099662797
Trained batch 451 in epoch 8, gen_loss = 0.8055633542548238, disc_loss = 0.08966727246349035
Trained batch 452 in epoch 8, gen_loss = 0.8062975600065775, disc_loss = 0.08952983059030166
Trained batch 453 in epoch 8, gen_loss = 0.8057975358112268, disc_loss = 0.08956641811951338
Trained batch 454 in epoch 8, gen_loss = 0.8056667165441828, disc_loss = 0.08952066875216398
Trained batch 455 in epoch 8, gen_loss = 0.805930374745737, disc_loss = 0.08969461378486206
Trained batch 456 in epoch 8, gen_loss = 0.805747410661543, disc_loss = 0.08960286012485917
Trained batch 457 in epoch 8, gen_loss = 0.8052724935602413, disc_loss = 0.08964655265073784
Trained batch 458 in epoch 8, gen_loss = 0.8052623001838302, disc_loss = 0.08970979591202567
Trained batch 459 in epoch 8, gen_loss = 0.806083266372266, disc_loss = 0.0898036597357334
Trained batch 460 in epoch 8, gen_loss = 0.8058338306213925, disc_loss = 0.08975021002729325
Trained batch 461 in epoch 8, gen_loss = 0.8055267403652142, disc_loss = 0.08972614588925526
Trained batch 462 in epoch 8, gen_loss = 0.8052726524437478, disc_loss = 0.08965747973823328
Trained batch 463 in epoch 8, gen_loss = 0.8058288540562679, disc_loss = 0.08967881479324645
Trained batch 464 in epoch 8, gen_loss = 0.8055542599770331, disc_loss = 0.0897213286750259
Trained batch 465 in epoch 8, gen_loss = 0.8054156644917353, disc_loss = 0.08969990758609042
Trained batch 466 in epoch 8, gen_loss = 0.8057580996121277, disc_loss = 0.08964623517019782
Trained batch 467 in epoch 8, gen_loss = 0.8052824100113323, disc_loss = 0.08960277206487317
Trained batch 468 in epoch 8, gen_loss = 0.8050270330931332, disc_loss = 0.08962353193230911
Trained batch 469 in epoch 8, gen_loss = 0.8054911315441131, disc_loss = 0.08946330781748638
Trained batch 470 in epoch 8, gen_loss = 0.8059011383927299, disc_loss = 0.08933957127336167
Trained batch 471 in epoch 8, gen_loss = 0.8055791756359197, disc_loss = 0.08926987462337681
Trained batch 472 in epoch 8, gen_loss = 0.8062341901263022, disc_loss = 0.08912042868038124
Trained batch 473 in epoch 8, gen_loss = 0.8056144112021612, disc_loss = 0.08923593865518895
Trained batch 474 in epoch 8, gen_loss = 0.8063026409400137, disc_loss = 0.08927956669934486
Trained batch 475 in epoch 8, gen_loss = 0.806242559762562, disc_loss = 0.08920896930831383
Trained batch 476 in epoch 8, gen_loss = 0.8058752077680463, disc_loss = 0.08918075167634515
Trained batch 477 in epoch 8, gen_loss = 0.8062198091002188, disc_loss = 0.08935268030981201
Trained batch 478 in epoch 8, gen_loss = 0.8061910953551593, disc_loss = 0.08924660423580005
Trained batch 479 in epoch 8, gen_loss = 0.8058569531887769, disc_loss = 0.08929659563776417
Trained batch 480 in epoch 8, gen_loss = 0.8059716343631863, disc_loss = 0.08952327290445318
Trained batch 481 in epoch 8, gen_loss = 0.8057633357671287, disc_loss = 0.08950891278691868
Trained batch 482 in epoch 8, gen_loss = 0.8059758284817571, disc_loss = 0.08965415991341413
Trained batch 483 in epoch 8, gen_loss = 0.8057911503167192, disc_loss = 0.08955920029870304
Trained batch 484 in epoch 8, gen_loss = 0.806040008412194, disc_loss = 0.08982731203174162
Trained batch 485 in epoch 8, gen_loss = 0.8058285758573822, disc_loss = 0.08974010187082392
Trained batch 486 in epoch 8, gen_loss = 0.8052641849743023, disc_loss = 0.0897285219308685
Trained batch 487 in epoch 8, gen_loss = 0.805092491575929, disc_loss = 0.08965194558335438
Trained batch 488 in epoch 8, gen_loss = 0.8046586969391213, disc_loss = 0.08963755303555776
Trained batch 489 in epoch 8, gen_loss = 0.8047360550384133, disc_loss = 0.08965699589260075
Trained batch 490 in epoch 8, gen_loss = 0.8045300529347903, disc_loss = 0.08990365905827576
Trained batch 491 in epoch 8, gen_loss = 0.8041968755121154, disc_loss = 0.08990223949767528
Trained batch 492 in epoch 8, gen_loss = 0.8041409662722574, disc_loss = 0.08987917550263311
Trained batch 493 in epoch 8, gen_loss = 0.8038902000377053, disc_loss = 0.08986831890977165
Trained batch 494 in epoch 8, gen_loss = 0.8043497307131989, disc_loss = 0.08989657360985122
Trained batch 495 in epoch 8, gen_loss = 0.8046988421870817, disc_loss = 0.08982556534277636
Trained batch 496 in epoch 8, gen_loss = 0.8043909972342447, disc_loss = 0.08997666459695494
Trained batch 497 in epoch 8, gen_loss = 0.8045292584053484, disc_loss = 0.0899034349423605
Trained batch 498 in epoch 8, gen_loss = 0.8044158379157225, disc_loss = 0.08994774204046131
Trained batch 499 in epoch 8, gen_loss = 0.8045857105255126, disc_loss = 0.09051900741644203
Trained batch 500 in epoch 8, gen_loss = 0.8042938802056684, disc_loss = 0.09066103166991663
Trained batch 501 in epoch 8, gen_loss = 0.8044040312330086, disc_loss = 0.09062633712579352
Trained batch 502 in epoch 8, gen_loss = 0.8046628874291483, disc_loss = 0.09050052072556604
Trained batch 503 in epoch 8, gen_loss = 0.8055894237662119, disc_loss = 0.09047195340676736
Trained batch 504 in epoch 8, gen_loss = 0.8055810705269918, disc_loss = 0.09038326243252152
Trained batch 505 in epoch 8, gen_loss = 0.805485307110157, disc_loss = 0.0903236581686251
Trained batch 506 in epoch 8, gen_loss = 0.8054049651063171, disc_loss = 0.09029290600472242
Trained batch 507 in epoch 8, gen_loss = 0.8053716006945437, disc_loss = 0.09031971752474921
Trained batch 508 in epoch 8, gen_loss = 0.8054526621559982, disc_loss = 0.0902557744715941
Trained batch 509 in epoch 8, gen_loss = 0.804854248084274, disc_loss = 0.09052109594329023
Trained batch 510 in epoch 8, gen_loss = 0.8048561294718032, disc_loss = 0.09078563614374796
Trained batch 511 in epoch 8, gen_loss = 0.8052674733335152, disc_loss = 0.0906737897767016
Trained batch 512 in epoch 8, gen_loss = 0.8049304944265191, disc_loss = 0.09065958957930348
Trained batch 513 in epoch 8, gen_loss = 0.8050106141121934, disc_loss = 0.09059992684993588
Trained batch 514 in epoch 8, gen_loss = 0.8047051710989869, disc_loss = 0.09069009869024881
Trained batch 515 in epoch 8, gen_loss = 0.8049719094537026, disc_loss = 0.09055638196517157
Trained batch 516 in epoch 8, gen_loss = 0.8048687157594028, disc_loss = 0.09052019210521499
Trained batch 517 in epoch 8, gen_loss = 0.8044479913923271, disc_loss = 0.09050386226610155
Trained batch 518 in epoch 8, gen_loss = 0.8042663433418568, disc_loss = 0.09047000797964302
Trained batch 519 in epoch 8, gen_loss = 0.8043615711423067, disc_loss = 0.09052542931077859
Trained batch 520 in epoch 8, gen_loss = 0.8040865912547267, disc_loss = 0.09059650039268147
Trained batch 521 in epoch 8, gen_loss = 0.8043281173340662, disc_loss = 0.09049666515405208
Trained batch 522 in epoch 8, gen_loss = 0.8040566123010552, disc_loss = 0.0905892614713277
Trained batch 523 in epoch 8, gen_loss = 0.8045392439110588, disc_loss = 0.09049584069075987
Trained batch 524 in epoch 8, gen_loss = 0.8041130031858171, disc_loss = 0.09057879579386541
Trained batch 525 in epoch 8, gen_loss = 0.803996773047139, disc_loss = 0.09067871974880308
Trained batch 526 in epoch 8, gen_loss = 0.8042453188145183, disc_loss = 0.09068196529321075
Trained batch 527 in epoch 8, gen_loss = 0.8041263630218578, disc_loss = 0.090595371380914
Trained batch 528 in epoch 8, gen_loss = 0.8036072565161664, disc_loss = 0.09074363403465945
Trained batch 529 in epoch 8, gen_loss = 0.8033514308479597, disc_loss = 0.09077236989231885
Trained batch 530 in epoch 8, gen_loss = 0.8039249118887547, disc_loss = 0.09081472687444277
Trained batch 531 in epoch 8, gen_loss = 0.8038056697836495, disc_loss = 0.09071959169490501
Trained batch 532 in epoch 8, gen_loss = 0.803375978854539, disc_loss = 0.0906879928113288
Trained batch 533 in epoch 8, gen_loss = 0.8039292742250564, disc_loss = 0.09060072502093425
Trained batch 534 in epoch 8, gen_loss = 0.8034269862085859, disc_loss = 0.09068567184122088
Trained batch 535 in epoch 8, gen_loss = 0.8032044104453343, disc_loss = 0.09064477227051367
Trained batch 536 in epoch 8, gen_loss = 0.8041621700789453, disc_loss = 0.09101891629501928
Trained batch 537 in epoch 8, gen_loss = 0.804117299034693, disc_loss = 0.0909338007771088
Trained batch 538 in epoch 8, gen_loss = 0.803868500885583, disc_loss = 0.09092566763018024
Trained batch 539 in epoch 8, gen_loss = 0.8038410027821858, disc_loss = 0.0909696204053169
Trained batch 540 in epoch 8, gen_loss = 0.8035846543179863, disc_loss = 0.0909638604073477
Trained batch 541 in epoch 8, gen_loss = 0.8036160198524869, disc_loss = 0.09087860521884478
Trained batch 542 in epoch 8, gen_loss = 0.8036989132782811, disc_loss = 0.09077179512355484
Trained batch 543 in epoch 8, gen_loss = 0.8036440537475488, disc_loss = 0.09078306252280634
Trained batch 544 in epoch 8, gen_loss = 0.8033914131855746, disc_loss = 0.09078614793273561
Trained batch 545 in epoch 8, gen_loss = 0.8029117670469669, disc_loss = 0.0909145933971655
Trained batch 546 in epoch 8, gen_loss = 0.8029015302876014, disc_loss = 0.09088933132282395
Trained batch 547 in epoch 8, gen_loss = 0.8028023095026503, disc_loss = 0.0908927639800185
Trained batch 548 in epoch 8, gen_loss = 0.8027235905763664, disc_loss = 0.09083498323095356
Trained batch 549 in epoch 8, gen_loss = 0.8023940361629833, disc_loss = 0.09086245189505544
Trained batch 550 in epoch 8, gen_loss = 0.8028137519441801, disc_loss = 0.09082134681400554
Trained batch 551 in epoch 8, gen_loss = 0.8027411941168965, disc_loss = 0.09075242871641302
Trained batch 552 in epoch 8, gen_loss = 0.8027753302891474, disc_loss = 0.09072137855256067
Trained batch 553 in epoch 8, gen_loss = 0.8025766075302978, disc_loss = 0.0907322979928919
Trained batch 554 in epoch 8, gen_loss = 0.8026686882113552, disc_loss = 0.09084407991419235
Trained batch 555 in epoch 8, gen_loss = 0.802899081179564, disc_loss = 0.09082915535591972
Trained batch 556 in epoch 8, gen_loss = 0.8024478362107406, disc_loss = 0.09102734592467332
Trained batch 557 in epoch 8, gen_loss = 0.8023082063830455, disc_loss = 0.09098252831160435
Trained batch 558 in epoch 8, gen_loss = 0.8026152951559569, disc_loss = 0.09092409516416476
Trained batch 559 in epoch 8, gen_loss = 0.8025174047265734, disc_loss = 0.09081164881021582
Trained batch 560 in epoch 8, gen_loss = 0.802341347284708, disc_loss = 0.09081644742000922
Trained batch 561 in epoch 8, gen_loss = 0.8024549598795664, disc_loss = 0.09070518797634707
Trained batch 562 in epoch 8, gen_loss = 0.802444257596458, disc_loss = 0.09069332564299261
Trained batch 563 in epoch 8, gen_loss = 0.8023753454710575, disc_loss = 0.09105818416652474
Trained batch 564 in epoch 8, gen_loss = 0.8018181072399679, disc_loss = 0.09117311024791108
Trained batch 565 in epoch 8, gen_loss = 0.8013476568797452, disc_loss = 0.091201696273387
Trained batch 566 in epoch 8, gen_loss = 0.8028581654899335, disc_loss = 0.09182799102104477
Trained batch 567 in epoch 8, gen_loss = 0.8022156582856682, disc_loss = 0.09197090301682359
Trained batch 568 in epoch 8, gen_loss = 0.8020810220384011, disc_loss = 0.09192677253860529
Trained batch 569 in epoch 8, gen_loss = 0.8023325975003995, disc_loss = 0.09188503687547749
Trained batch 570 in epoch 8, gen_loss = 0.8020916687106084, disc_loss = 0.09190977318293941
Trained batch 571 in epoch 8, gen_loss = 0.8019931582616759, disc_loss = 0.09196796751958872
Trained batch 572 in epoch 8, gen_loss = 0.8023336959863, disc_loss = 0.09204762936594131
Trained batch 573 in epoch 8, gen_loss = 0.8018820403656478, disc_loss = 0.09238267413953818
Trained batch 574 in epoch 8, gen_loss = 0.8013341760635376, disc_loss = 0.0928147286095697
Trained batch 575 in epoch 8, gen_loss = 0.8016135338693857, disc_loss = 0.09299782815408737
Trained batch 576 in epoch 8, gen_loss = 0.8020045815142229, disc_loss = 0.09301199099497685
Trained batch 577 in epoch 8, gen_loss = 0.8015297513107115, disc_loss = 0.09311287693363521
Trained batch 578 in epoch 8, gen_loss = 0.801479889630036, disc_loss = 0.09305553511911054
Trained batch 579 in epoch 8, gen_loss = 0.8014912552874663, disc_loss = 0.09298479595414266
Trained batch 580 in epoch 8, gen_loss = 0.8012679572154651, disc_loss = 0.09306009849709765
Trained batch 581 in epoch 8, gen_loss = 0.8013846137884146, disc_loss = 0.09307167950307124
Trained batch 582 in epoch 8, gen_loss = 0.8011047907595364, disc_loss = 0.09307700566672696
Trained batch 583 in epoch 8, gen_loss = 0.8006971694835244, disc_loss = 0.09308083504534084
Trained batch 584 in epoch 8, gen_loss = 0.8011172777567155, disc_loss = 0.09305816031514834
Trained batch 585 in epoch 8, gen_loss = 0.8012039508835854, disc_loss = 0.09302232004924592
Trained batch 586 in epoch 8, gen_loss = 0.8013648702501235, disc_loss = 0.09292073604798347
Trained batch 587 in epoch 8, gen_loss = 0.8015916738785854, disc_loss = 0.09284913619555736
Trained batch 588 in epoch 8, gen_loss = 0.8019508815580799, disc_loss = 0.09274892602432108
Trained batch 589 in epoch 8, gen_loss = 0.8018001654390562, disc_loss = 0.09274116357851583
Trained batch 590 in epoch 8, gen_loss = 0.8016116689707825, disc_loss = 0.0927179224785991
Trained batch 591 in epoch 8, gen_loss = 0.8012851224960508, disc_loss = 0.09274413610172987
Trained batch 592 in epoch 8, gen_loss = 0.8009970798259239, disc_loss = 0.09273475021419145
Trained batch 593 in epoch 8, gen_loss = 0.8008780887833348, disc_loss = 0.09265147501866174
Trained batch 594 in epoch 8, gen_loss = 0.801176873976443, disc_loss = 0.0925850402454243
Trained batch 595 in epoch 8, gen_loss = 0.8013868530924688, disc_loss = 0.0924927749274136
Trained batch 596 in epoch 8, gen_loss = 0.8013792592077399, disc_loss = 0.09237610157641583
Trained batch 597 in epoch 8, gen_loss = 0.8009144833255373, disc_loss = 0.09251950518773203
Trained batch 598 in epoch 8, gen_loss = 0.8015337444107998, disc_loss = 0.09265804138556993
Trained batch 599 in epoch 8, gen_loss = 0.8016019214193026, disc_loss = 0.09254771900208046
Trained batch 600 in epoch 8, gen_loss = 0.8011070326243384, disc_loss = 0.09271917671442478
Trained batch 601 in epoch 8, gen_loss = 0.8008747175088357, disc_loss = 0.09269845042148747
Trained batch 602 in epoch 8, gen_loss = 0.8007775004428022, disc_loss = 0.09265208804816205
Trained batch 603 in epoch 8, gen_loss = 0.800750472391678, disc_loss = 0.09257181131416647
Trained batch 604 in epoch 8, gen_loss = 0.8005639960943175, disc_loss = 0.09259855248003213
Trained batch 605 in epoch 8, gen_loss = 0.800502083679237, disc_loss = 0.09251846887152826
Trained batch 606 in epoch 8, gen_loss = 0.8001444261195828, disc_loss = 0.09256523187368912
Trained batch 607 in epoch 8, gen_loss = 0.7999912657235798, disc_loss = 0.09261643093869727
Trained batch 608 in epoch 8, gen_loss = 0.7997559700497657, disc_loss = 0.09264815029992503
Trained batch 609 in epoch 8, gen_loss = 0.7996291146903741, disc_loss = 0.09265032387567593
Trained batch 610 in epoch 8, gen_loss = 0.7997109605130509, disc_loss = 0.0925930181195054
Trained batch 611 in epoch 8, gen_loss = 0.7995360895893933, disc_loss = 0.09264398006010144
Trained batch 612 in epoch 8, gen_loss = 0.7993318364631877, disc_loss = 0.09270937004404638
Trained batch 613 in epoch 8, gen_loss = 0.7995037735479275, disc_loss = 0.09268257704014353
Trained batch 614 in epoch 8, gen_loss = 0.7996997409719762, disc_loss = 0.09257242647037515
Trained batch 615 in epoch 8, gen_loss = 0.7996151163787036, disc_loss = 0.09253660425114409
Trained batch 616 in epoch 8, gen_loss = 0.7997988548425646, disc_loss = 0.09246459840744058
Trained batch 617 in epoch 8, gen_loss = 0.8000536766445753, disc_loss = 0.09244023643970538
Trained batch 618 in epoch 8, gen_loss = 0.7995950112627859, disc_loss = 0.09257250376232269
Trained batch 619 in epoch 8, gen_loss = 0.7998984513744232, disc_loss = 0.09254648329299545
Trained batch 620 in epoch 8, gen_loss = 0.8003961863341155, disc_loss = 0.09257295232974053
Trained batch 621 in epoch 8, gen_loss = 0.8000190631752996, disc_loss = 0.0928536482421843
Trained batch 622 in epoch 8, gen_loss = 0.8008913754651481, disc_loss = 0.09276215301118014
Trained batch 623 in epoch 8, gen_loss = 0.8007636366364284, disc_loss = 0.09270943949172178
Trained batch 624 in epoch 8, gen_loss = 0.8014066951751709, disc_loss = 0.09294482984095812
Trained batch 625 in epoch 8, gen_loss = 0.801135392139514, disc_loss = 0.09290161906940916
Trained batch 626 in epoch 8, gen_loss = 0.8007936972940557, disc_loss = 0.09298512816839098
Trained batch 627 in epoch 8, gen_loss = 0.8009004231281341, disc_loss = 0.09307079144848428
Trained batch 628 in epoch 8, gen_loss = 0.8012224582685765, disc_loss = 0.09303562688553893
Trained batch 629 in epoch 8, gen_loss = 0.8011467688613467, disc_loss = 0.092956296521579
Trained batch 630 in epoch 8, gen_loss = 0.8012695464581582, disc_loss = 0.0929371710828315
Trained batch 631 in epoch 8, gen_loss = 0.8014306314761126, disc_loss = 0.09288851982955172
Trained batch 632 in epoch 8, gen_loss = 0.8016380027383802, disc_loss = 0.0928382720771771
Trained batch 633 in epoch 8, gen_loss = 0.8016921249849939, disc_loss = 0.09273096147707255
Trained batch 634 in epoch 8, gen_loss = 0.8015865533370671, disc_loss = 0.0926941945635545
Trained batch 635 in epoch 8, gen_loss = 0.8016531526480081, disc_loss = 0.09264007852260468
Trained batch 636 in epoch 8, gen_loss = 0.8017344226829672, disc_loss = 0.09257184948737103
Trained batch 637 in epoch 8, gen_loss = 0.8017678786781515, disc_loss = 0.09247561719788233
Trained batch 638 in epoch 8, gen_loss = 0.8022812270036139, disc_loss = 0.09237986665906994
Trained batch 639 in epoch 8, gen_loss = 0.8023082461208105, disc_loss = 0.09229755792039214
Trained batch 640 in epoch 8, gen_loss = 0.8023573387059704, disc_loss = 0.09221118586733588
Trained batch 641 in epoch 8, gen_loss = 0.8025937929888752, disc_loss = 0.09208624134553928
Trained batch 642 in epoch 8, gen_loss = 0.8027365561777474, disc_loss = 0.09196143816797349
Trained batch 643 in epoch 8, gen_loss = 0.8030231668156866, disc_loss = 0.09187638104071852
Trained batch 644 in epoch 8, gen_loss = 0.8034688080004019, disc_loss = 0.09197545572970958
Trained batch 645 in epoch 8, gen_loss = 0.8032404111450302, disc_loss = 0.09202289653238452
Trained batch 646 in epoch 8, gen_loss = 0.8031358232453949, disc_loss = 0.09199810368217631
Trained batch 647 in epoch 8, gen_loss = 0.8038010749919915, disc_loss = 0.0921652847484191
Trained batch 648 in epoch 8, gen_loss = 0.8040081986293587, disc_loss = 0.09204363394299026
Trained batch 649 in epoch 8, gen_loss = 0.8038563488079952, disc_loss = 0.09211556086889826
Trained batch 650 in epoch 8, gen_loss = 0.804003669644281, disc_loss = 0.09204933421111189
Trained batch 651 in epoch 8, gen_loss = 0.8042553688850871, disc_loss = 0.0919525135277079
Trained batch 652 in epoch 8, gen_loss = 0.804122378413564, disc_loss = 0.0918696579661728
Trained batch 653 in epoch 8, gen_loss = 0.8039723004040733, disc_loss = 0.09189279310388165
Trained batch 654 in epoch 8, gen_loss = 0.8040636790617731, disc_loss = 0.09177831295195199
Trained batch 655 in epoch 8, gen_loss = 0.8041479006046202, disc_loss = 0.0916621610891392
Trained batch 656 in epoch 8, gen_loss = 0.8042714648413695, disc_loss = 0.09159563030747064
Trained batch 657 in epoch 8, gen_loss = 0.8038768355244924, disc_loss = 0.09163210340874627
Trained batch 658 in epoch 8, gen_loss = 0.8038699228955328, disc_loss = 0.09154011286817751
Trained batch 659 in epoch 8, gen_loss = 0.8041575081420668, disc_loss = 0.0916027094858388
Trained batch 660 in epoch 8, gen_loss = 0.8043069938668325, disc_loss = 0.0914903467749323
Trained batch 661 in epoch 8, gen_loss = 0.8041884322901147, disc_loss = 0.09151449553060748
Trained batch 662 in epoch 8, gen_loss = 0.8038063181471501, disc_loss = 0.09150579577342777
Trained batch 663 in epoch 8, gen_loss = 0.8044325399650148, disc_loss = 0.09165975968746176
Trained batch 664 in epoch 8, gen_loss = 0.8045545200656231, disc_loss = 0.09157492983946226
Trained batch 665 in epoch 8, gen_loss = 0.8041443743326284, disc_loss = 0.091694043870937
Trained batch 666 in epoch 8, gen_loss = 0.8041304844072734, disc_loss = 0.0917829137234048
Trained batch 667 in epoch 8, gen_loss = 0.8040463209687593, disc_loss = 0.09174521961723438
Trained batch 668 in epoch 8, gen_loss = 0.8038425441992835, disc_loss = 0.09173489436061749
Trained batch 669 in epoch 8, gen_loss = 0.8038035526204464, disc_loss = 0.0917819687624031
Trained batch 670 in epoch 8, gen_loss = 0.8037163391376216, disc_loss = 0.09173415433587687
Trained batch 671 in epoch 8, gen_loss = 0.8037164341658354, disc_loss = 0.09166704974181596
Trained batch 672 in epoch 8, gen_loss = 0.8033538622806543, disc_loss = 0.09165818623943811
Trained batch 673 in epoch 8, gen_loss = 0.8033070295430079, disc_loss = 0.09156521071765561
Trained batch 674 in epoch 8, gen_loss = 0.8037025584114923, disc_loss = 0.09156478290480596
Trained batch 675 in epoch 8, gen_loss = 0.8034194099479879, disc_loss = 0.09158743841066604
Trained batch 676 in epoch 8, gen_loss = 0.8039431700502224, disc_loss = 0.09173497313597793
Trained batch 677 in epoch 8, gen_loss = 0.8037268630171244, disc_loss = 0.0917039511637394
Trained batch 678 in epoch 8, gen_loss = 0.8036733289881554, disc_loss = 0.09164985550487954
Trained batch 679 in epoch 8, gen_loss = 0.8040464627392152, disc_loss = 0.09181644164080567
Trained batch 680 in epoch 8, gen_loss = 0.8037543043866207, disc_loss = 0.09196498065847745
Trained batch 681 in epoch 8, gen_loss = 0.8036983208048029, disc_loss = 0.09202075150147998
Trained batch 682 in epoch 8, gen_loss = 0.8038697969686583, disc_loss = 0.0919798040356198
Trained batch 683 in epoch 8, gen_loss = 0.8035168305300829, disc_loss = 0.09206822146634348
Trained batch 684 in epoch 8, gen_loss = 0.8035035165557026, disc_loss = 0.09206260414726107
Trained batch 685 in epoch 8, gen_loss = 0.8035351901638265, disc_loss = 0.09206581039967847
Trained batch 686 in epoch 8, gen_loss = 0.8035273669067949, disc_loss = 0.09202483780356734
Trained batch 687 in epoch 8, gen_loss = 0.8033123284058515, disc_loss = 0.09203018296001003
Trained batch 688 in epoch 8, gen_loss = 0.8035622060904483, disc_loss = 0.09197856215232948
Trained batch 689 in epoch 8, gen_loss = 0.8039564549922943, disc_loss = 0.0919569654174257
Trained batch 690 in epoch 8, gen_loss = 0.8037996096307393, disc_loss = 0.09193659746040915
Trained batch 691 in epoch 8, gen_loss = 0.8037688087004458, disc_loss = 0.09195521261510735
Trained batch 692 in epoch 8, gen_loss = 0.8034837835966938, disc_loss = 0.0919076937934838
Trained batch 693 in epoch 8, gen_loss = 0.8033174498795775, disc_loss = 0.09196116060007804
Trained batch 694 in epoch 8, gen_loss = 0.8032083388712766, disc_loss = 0.09200537523938168
Trained batch 695 in epoch 8, gen_loss = 0.8033680053449225, disc_loss = 0.09189841288527281
Trained batch 696 in epoch 8, gen_loss = 0.8030975799649483, disc_loss = 0.09194210217931606
Trained batch 697 in epoch 8, gen_loss = 0.8031711501515014, disc_loss = 0.09208777511924676
Trained batch 698 in epoch 8, gen_loss = 0.802941385256886, disc_loss = 0.09215378195569665
Trained batch 699 in epoch 8, gen_loss = 0.8030189832619258, disc_loss = 0.09211390163483364
Trained batch 700 in epoch 8, gen_loss = 0.8029833161371751, disc_loss = 0.09205702165362244
Trained batch 701 in epoch 8, gen_loss = 0.8032082637660524, disc_loss = 0.09207252833588934
Trained batch 702 in epoch 8, gen_loss = 0.8030414434618834, disc_loss = 0.09202343783742757
Trained batch 703 in epoch 8, gen_loss = 0.8026768884367563, disc_loss = 0.09208112314544534
Trained batch 704 in epoch 8, gen_loss = 0.8026388219907774, disc_loss = 0.09206795660475045
Trained batch 705 in epoch 8, gen_loss = 0.8025845995874648, disc_loss = 0.09196433422047508
Trained batch 706 in epoch 8, gen_loss = 0.8026669108884507, disc_loss = 0.09186670877028895
Trained batch 707 in epoch 8, gen_loss = 0.8031919934486939, disc_loss = 0.09184116176145393
Trained batch 708 in epoch 8, gen_loss = 0.8028606014964611, disc_loss = 0.09191374380367431
Trained batch 709 in epoch 8, gen_loss = 0.8034110534359032, disc_loss = 0.09184177713599843
Trained batch 710 in epoch 8, gen_loss = 0.8034488245237058, disc_loss = 0.09181293661269961
Trained batch 711 in epoch 8, gen_loss = 0.8032906802182787, disc_loss = 0.09176213677784198
Trained batch 712 in epoch 8, gen_loss = 0.8030507944074955, disc_loss = 0.09176859855756352
Trained batch 713 in epoch 8, gen_loss = 0.8034100006608402, disc_loss = 0.09167421290896186
Trained batch 714 in epoch 8, gen_loss = 0.8035147800312176, disc_loss = 0.09165643509868142
Trained batch 715 in epoch 8, gen_loss = 0.8035620384376142, disc_loss = 0.0915996216695402
Trained batch 716 in epoch 8, gen_loss = 0.8032694147221713, disc_loss = 0.0916807091842968
Trained batch 717 in epoch 8, gen_loss = 0.8036100218555057, disc_loss = 0.09162055639275103
Trained batch 718 in epoch 8, gen_loss = 0.8038454665925473, disc_loss = 0.09152090634181785
Trained batch 719 in epoch 8, gen_loss = 0.8041835074623426, disc_loss = 0.09143447754128525
Trained batch 720 in epoch 8, gen_loss = 0.8041809541011815, disc_loss = 0.09133251448744462
Trained batch 721 in epoch 8, gen_loss = 0.8038264407345462, disc_loss = 0.09145219354965102
Trained batch 722 in epoch 8, gen_loss = 0.8042555866069978, disc_loss = 0.09141401895276821
Trained batch 723 in epoch 8, gen_loss = 0.8042703126016901, disc_loss = 0.0913459219537593
Trained batch 724 in epoch 8, gen_loss = 0.804297534843971, disc_loss = 0.09133423310158581
Trained batch 725 in epoch 8, gen_loss = 0.8046123886239759, disc_loss = 0.09128641823342598
Trained batch 726 in epoch 8, gen_loss = 0.80472287990696, disc_loss = 0.091195000750634
Trained batch 727 in epoch 8, gen_loss = 0.8050880073518544, disc_loss = 0.09109751982512054
Trained batch 728 in epoch 8, gen_loss = 0.8049641175525178, disc_loss = 0.09108856822196676
Trained batch 729 in epoch 8, gen_loss = 0.8053261791190056, disc_loss = 0.09103259777981941
Trained batch 730 in epoch 8, gen_loss = 0.8053713194648805, disc_loss = 0.09092754654321315
Trained batch 731 in epoch 8, gen_loss = 0.8053968819926997, disc_loss = 0.09084095963393975
Trained batch 732 in epoch 8, gen_loss = 0.805355966091156, disc_loss = 0.09075190349752629
Trained batch 733 in epoch 8, gen_loss = 0.8058900091726059, disc_loss = 0.09067778178422181
Trained batch 734 in epoch 8, gen_loss = 0.805616904845854, disc_loss = 0.0906426887300347
Trained batch 735 in epoch 8, gen_loss = 0.8053253773275925, disc_loss = 0.09065067304207174
Trained batch 736 in epoch 8, gen_loss = 0.80574735898014, disc_loss = 0.09072592534792068
Trained batch 737 in epoch 8, gen_loss = 0.8053732572532282, disc_loss = 0.09093513319314253
Trained batch 738 in epoch 8, gen_loss = 0.8057331761423403, disc_loss = 0.09084257111205381
Trained batch 739 in epoch 8, gen_loss = 0.8059638688693176, disc_loss = 0.0907650111822059
Trained batch 740 in epoch 8, gen_loss = 0.8059892895733297, disc_loss = 0.09073931506901536
Trained batch 741 in epoch 8, gen_loss = 0.805848226714327, disc_loss = 0.09068684115493796
Trained batch 742 in epoch 8, gen_loss = 0.8059196590093712, disc_loss = 0.09058121963332672
Trained batch 743 in epoch 8, gen_loss = 0.8060637226188054, disc_loss = 0.09048946341499686
Trained batch 744 in epoch 8, gen_loss = 0.8061298666384397, disc_loss = 0.09041798302291223
Trained batch 745 in epoch 8, gen_loss = 0.8060352592941263, disc_loss = 0.09036526258225895
Trained batch 746 in epoch 8, gen_loss = 0.8059211785853947, disc_loss = 0.09031074400866526
Trained batch 747 in epoch 8, gen_loss = 0.8060570808655438, disc_loss = 0.09023737241538929
Trained batch 748 in epoch 8, gen_loss = 0.8064733461958067, disc_loss = 0.09020359262585322
Trained batch 749 in epoch 8, gen_loss = 0.8061311273574829, disc_loss = 0.09027505556245645
Trained batch 750 in epoch 8, gen_loss = 0.806183917147818, disc_loss = 0.09018043841616054
Trained batch 751 in epoch 8, gen_loss = 0.8066892046085063, disc_loss = 0.09037137042701324
Trained batch 752 in epoch 8, gen_loss = 0.8065892022602745, disc_loss = 0.09029582653634972
Trained batch 753 in epoch 8, gen_loss = 0.8064507838901853, disc_loss = 0.09024859417664673
Trained batch 754 in epoch 8, gen_loss = 0.8063569163644551, disc_loss = 0.09020598350425825
Trained batch 755 in epoch 8, gen_loss = 0.8070421363941576, disc_loss = 0.09032785126978837
Trained batch 756 in epoch 8, gen_loss = 0.8070257436016591, disc_loss = 0.09027024729317608
Trained batch 757 in epoch 8, gen_loss = 0.8070050816108181, disc_loss = 0.09023876576426397
Trained batch 758 in epoch 8, gen_loss = 0.8074085508253578, disc_loss = 0.09018665111141479
Trained batch 759 in epoch 8, gen_loss = 0.8077181477295725, disc_loss = 0.09008664963031678
Trained batch 760 in epoch 8, gen_loss = 0.8076955376880711, disc_loss = 0.09004306632403711
Trained batch 761 in epoch 8, gen_loss = 0.807814968539661, disc_loss = 0.0899660644632351
Trained batch 762 in epoch 8, gen_loss = 0.8079935834104706, disc_loss = 0.08987274401983537
Trained batch 763 in epoch 8, gen_loss = 0.8078764648961771, disc_loss = 0.0898551782861313
Trained batch 764 in epoch 8, gen_loss = 0.8078109122569265, disc_loss = 0.08980182929609726
Trained batch 765 in epoch 8, gen_loss = 0.8075522108893481, disc_loss = 0.08980426697337675
Trained batch 766 in epoch 8, gen_loss = 0.8077753106960261, disc_loss = 0.08991561194024543
Trained batch 767 in epoch 8, gen_loss = 0.8075679055570314, disc_loss = 0.08989492179292331
Trained batch 768 in epoch 8, gen_loss = 0.8075059133016241, disc_loss = 0.08984443874513762
Trained batch 769 in epoch 8, gen_loss = 0.8075286877619756, disc_loss = 0.08977625573948993
Trained batch 770 in epoch 8, gen_loss = 0.8076880916701835, disc_loss = 0.08972712298166659
Trained batch 771 in epoch 8, gen_loss = 0.8079536759482764, disc_loss = 0.08962536728916777
Trained batch 772 in epoch 8, gen_loss = 0.8080635221161787, disc_loss = 0.08957224848401886
Trained batch 773 in epoch 8, gen_loss = 0.8078437271968338, disc_loss = 0.08960399381306206
Trained batch 774 in epoch 8, gen_loss = 0.8078635860258533, disc_loss = 0.08951349657149084
Trained batch 775 in epoch 8, gen_loss = 0.8082313689681673, disc_loss = 0.08948151499138589
Trained batch 776 in epoch 8, gen_loss = 0.80813674791746, disc_loss = 0.08944201267814621
Trained batch 777 in epoch 8, gen_loss = 0.8076954845214565, disc_loss = 0.08950235361142377
Trained batch 778 in epoch 8, gen_loss = 0.808113554131541, disc_loss = 0.08950190828331245
Trained batch 779 in epoch 8, gen_loss = 0.8082818744656367, disc_loss = 0.08940379730760097
Trained batch 780 in epoch 8, gen_loss = 0.8084355899909089, disc_loss = 0.0893217773044365
Trained batch 781 in epoch 8, gen_loss = 0.8081108903717202, disc_loss = 0.08938930934780966
Trained batch 782 in epoch 8, gen_loss = 0.8085231715920328, disc_loss = 0.08943602085318107
Trained batch 783 in epoch 8, gen_loss = 0.8087985216430864, disc_loss = 0.08935750175946944
Trained batch 784 in epoch 8, gen_loss = 0.8087033489327522, disc_loss = 0.0893163367049994
Trained batch 785 in epoch 8, gen_loss = 0.8083920423083633, disc_loss = 0.08937538538303501
Trained batch 786 in epoch 8, gen_loss = 0.8087703068722916, disc_loss = 0.08930917015462508
Trained batch 787 in epoch 8, gen_loss = 0.8090545715489968, disc_loss = 0.08923331579444031
Trained batch 788 in epoch 8, gen_loss = 0.8090970523381565, disc_loss = 0.08915343321033568
Trained batch 789 in epoch 8, gen_loss = 0.8090532130455669, disc_loss = 0.089070448532842
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.8715811967849731, disc_loss = 0.2211807817220688
Trained batch 1 in epoch 9, gen_loss = 0.7447766065597534, disc_loss = 0.15045153722167015
Trained batch 2 in epoch 9, gen_loss = 0.7308400472005209, disc_loss = 0.11983221645156543
Trained batch 3 in epoch 9, gen_loss = 0.7697141170501709, disc_loss = 0.10072742030024529
Trained batch 4 in epoch 9, gen_loss = 0.9246813774108886, disc_loss = 0.13135137259960175
Trained batch 5 in epoch 9, gen_loss = 0.8854294617970785, disc_loss = 0.14113901307185492
Trained batch 6 in epoch 9, gen_loss = 0.8567592331341335, disc_loss = 0.12680972207869803
Trained batch 7 in epoch 9, gen_loss = 0.8490243479609489, disc_loss = 0.11547890538349748
Trained batch 8 in epoch 9, gen_loss = 0.8691647781266106, disc_loss = 0.10612212245663007
Trained batch 9 in epoch 9, gen_loss = 0.8557041645050049, disc_loss = 0.09953440688550472
Trained batch 10 in epoch 9, gen_loss = 0.8534975973042574, disc_loss = 0.09459784423763101
Trained batch 11 in epoch 9, gen_loss = 0.8468934694925944, disc_loss = 0.09074677092333634
Trained batch 12 in epoch 9, gen_loss = 0.8434382860477154, disc_loss = 0.09651304609500445
Trained batch 13 in epoch 9, gen_loss = 0.830564728804997, disc_loss = 0.09209819324314594
Trained batch 14 in epoch 9, gen_loss = 0.8397038300832113, disc_loss = 0.08679935826609532
Trained batch 15 in epoch 9, gen_loss = 0.8361122794449329, disc_loss = 0.08420722157461569
Trained batch 16 in epoch 9, gen_loss = 0.8253392156432656, disc_loss = 0.08309163739356924
Trained batch 17 in epoch 9, gen_loss = 0.8250748945607079, disc_loss = 0.07991834114202195
Trained batch 18 in epoch 9, gen_loss = 0.8203997988449899, disc_loss = 0.07972535848813622
Trained batch 19 in epoch 9, gen_loss = 0.814904859662056, disc_loss = 0.08102178541012109
Trained batch 20 in epoch 9, gen_loss = 0.836442110084352, disc_loss = 0.0829912850278474
Trained batch 21 in epoch 9, gen_loss = 0.8385965363545851, disc_loss = 0.07995655104009942
Trained batch 22 in epoch 9, gen_loss = 0.8258134437643964, disc_loss = 0.08363422674491354
Trained batch 23 in epoch 9, gen_loss = 0.8342291961113611, disc_loss = 0.08277251311422636
Trained batch 24 in epoch 9, gen_loss = 0.8419695281982422, disc_loss = 0.08272901732474565
Trained batch 25 in epoch 9, gen_loss = 0.8338567706254812, disc_loss = 0.0821052103733214
Trained batch 26 in epoch 9, gen_loss = 0.8275204455410993, disc_loss = 0.08224285549173753
Trained batch 27 in epoch 9, gen_loss = 0.8245385757514408, disc_loss = 0.08094568194688431
Trained batch 28 in epoch 9, gen_loss = 0.8263872080835802, disc_loss = 0.08364050671586702
Trained batch 29 in epoch 9, gen_loss = 0.829375433921814, disc_loss = 0.08144433333848913
Trained batch 30 in epoch 9, gen_loss = 0.8220572317800214, disc_loss = 0.08333249423172205
Trained batch 31 in epoch 9, gen_loss = 0.8159864712506533, disc_loss = 0.08290036753169261
Trained batch 32 in epoch 9, gen_loss = 0.8204234657865582, disc_loss = 0.08313600411356399
Trained batch 33 in epoch 9, gen_loss = 0.8178676401867586, disc_loss = 0.082482065211105
Trained batch 34 in epoch 9, gen_loss = 0.8130396297999791, disc_loss = 0.08215687836387328
Trained batch 35 in epoch 9, gen_loss = 0.8204301529460483, disc_loss = 0.0808330724378013
Trained batch 36 in epoch 9, gen_loss = 0.8226110387492824, disc_loss = 0.0796712174558559
Trained batch 37 in epoch 9, gen_loss = 0.8126501974306608, disc_loss = 0.0815180717281213
Trained batch 38 in epoch 9, gen_loss = 0.8139726626567352, disc_loss = 0.07981190737336874
Trained batch 39 in epoch 9, gen_loss = 0.8163337975740432, disc_loss = 0.07810977103654296
Trained batch 40 in epoch 9, gen_loss = 0.8211158455871954, disc_loss = 0.07798288292365103
Trained batch 41 in epoch 9, gen_loss = 0.8159223312423343, disc_loss = 0.07862928032963759
Trained batch 42 in epoch 9, gen_loss = 0.8156736617864564, disc_loss = 0.07821168492786414
Trained batch 43 in epoch 9, gen_loss = 0.8138655640862205, disc_loss = 0.0773243219380013
Trained batch 44 in epoch 9, gen_loss = 0.8150761577818129, disc_loss = 0.07600505718340476
Trained batch 45 in epoch 9, gen_loss = 0.812029066293136, disc_loss = 0.0757128142994707
Trained batch 46 in epoch 9, gen_loss = 0.813045064185528, disc_loss = 0.07534548285555967
Trained batch 47 in epoch 9, gen_loss = 0.8096507204075655, disc_loss = 0.07621452284123127
Trained batch 48 in epoch 9, gen_loss = 0.809881752851058, disc_loss = 0.07537250747257958
Trained batch 49 in epoch 9, gen_loss = 0.8120750677585602, disc_loss = 0.07990580091252923
Trained batch 50 in epoch 9, gen_loss = 0.8122376963204029, disc_loss = 0.07896554157795276
Trained batch 51 in epoch 9, gen_loss = 0.8105208518413397, disc_loss = 0.07822115219628009
Trained batch 52 in epoch 9, gen_loss = 0.8074991849233519, disc_loss = 0.07847485369739104
Trained batch 53 in epoch 9, gen_loss = 0.8015487238212868, disc_loss = 0.07901825923127709
Trained batch 54 in epoch 9, gen_loss = 0.803860867023468, disc_loss = 0.07801396740092473
Trained batch 55 in epoch 9, gen_loss = 0.8025615311094693, disc_loss = 0.07730717692590718
Trained batch 56 in epoch 9, gen_loss = 0.8023963110488758, disc_loss = 0.08142012045637034
Trained batch 57 in epoch 9, gen_loss = 0.7973649296267279, disc_loss = 0.08220505741713889
Trained batch 58 in epoch 9, gen_loss = 0.796102263159671, disc_loss = 0.08168956714729636
Trained batch 59 in epoch 9, gen_loss = 0.7963790088891983, disc_loss = 0.08126277689201136
Trained batch 60 in epoch 9, gen_loss = 0.7954808014338134, disc_loss = 0.08076423316522212
Trained batch 61 in epoch 9, gen_loss = 0.7967131147461552, disc_loss = 0.0823357793382339
Trained batch 62 in epoch 9, gen_loss = 0.7979694235892523, disc_loss = 0.0818437242821332
Trained batch 63 in epoch 9, gen_loss = 0.7959848819300532, disc_loss = 0.08194800217461307
Trained batch 64 in epoch 9, gen_loss = 0.796945792895097, disc_loss = 0.08140479029657749
Trained batch 65 in epoch 9, gen_loss = 0.7993431109370608, disc_loss = 0.08093314630572092
Trained batch 66 in epoch 9, gen_loss = 0.7978870477249373, disc_loss = 0.08109013303947538
Trained batch 67 in epoch 9, gen_loss = 0.7964960880139295, disc_loss = 0.08087150030769408
Trained batch 68 in epoch 9, gen_loss = 0.7965187836384428, disc_loss = 0.08074088395991619
Trained batch 69 in epoch 9, gen_loss = 0.7938374161720276, disc_loss = 0.08089596864634327
Trained batch 70 in epoch 9, gen_loss = 0.7984144654072506, disc_loss = 0.08033379514924657
Trained batch 71 in epoch 9, gen_loss = 0.795107803410954, disc_loss = 0.08134709962178022
Trained batch 72 in epoch 9, gen_loss = 0.7972799212965247, disc_loss = 0.0818248129998372
Trained batch 73 in epoch 9, gen_loss = 0.8019207538785161, disc_loss = 0.08271891665267381
Trained batch 74 in epoch 9, gen_loss = 0.7980080223083497, disc_loss = 0.08545605521649122
Trained batch 75 in epoch 9, gen_loss = 0.7979954763462669, disc_loss = 0.08537652678052454
Trained batch 76 in epoch 9, gen_loss = 0.7964728644915989, disc_loss = 0.0857570551747045
Trained batch 77 in epoch 9, gen_loss = 0.7926373814161007, disc_loss = 0.08661394691667877
Trained batch 78 in epoch 9, gen_loss = 0.7969135962709596, disc_loss = 0.08666914183929374
Trained batch 79 in epoch 9, gen_loss = 0.7935542706400156, disc_loss = 0.08768889281200246
Trained batch 80 in epoch 9, gen_loss = 0.7944831130681215, disc_loss = 0.08769974444797378
Trained batch 81 in epoch 9, gen_loss = 0.7945439237646941, disc_loss = 0.08730958748563397
Trained batch 82 in epoch 9, gen_loss = 0.7914137298084167, disc_loss = 0.08765316190175622
Trained batch 83 in epoch 9, gen_loss = 0.7914911015402704, disc_loss = 0.08720001947533872
Trained batch 84 in epoch 9, gen_loss = 0.7902151118306553, disc_loss = 0.08676451980410253
Trained batch 85 in epoch 9, gen_loss = 0.791898139340933, disc_loss = 0.08626647857775868
Trained batch 86 in epoch 9, gen_loss = 0.7917617562858538, disc_loss = 0.08562964127109997
Trained batch 87 in epoch 9, gen_loss = 0.7893112169748003, disc_loss = 0.08568291386208413
Trained batch 88 in epoch 9, gen_loss = 0.788465938206469, disc_loss = 0.08517804694770092
Trained batch 89 in epoch 9, gen_loss = 0.7912177950143814, disc_loss = 0.08677433483923475
Trained batch 90 in epoch 9, gen_loss = 0.7917383978000054, disc_loss = 0.0863196568481706
Trained batch 91 in epoch 9, gen_loss = 0.7894320102489513, disc_loss = 0.08691930741517116
Trained batch 92 in epoch 9, gen_loss = 0.7903020128767978, disc_loss = 0.08866223631807232
Trained batch 93 in epoch 9, gen_loss = 0.7906658024863994, disc_loss = 0.08835574333615442
Trained batch 94 in epoch 9, gen_loss = 0.7897104090765903, disc_loss = 0.08837358252586502
Trained batch 95 in epoch 9, gen_loss = 0.7880904652799169, disc_loss = 0.08868557788082398
Trained batch 96 in epoch 9, gen_loss = 0.7870078802723246, disc_loss = 0.0883858786780656
Trained batch 97 in epoch 9, gen_loss = 0.7858735222597512, disc_loss = 0.08792989890148141
Trained batch 98 in epoch 9, gen_loss = 0.7851295865545369, disc_loss = 0.08791965139898086
Trained batch 99 in epoch 9, gen_loss = 0.7863498511910438, disc_loss = 0.08785550280474126
Trained batch 100 in epoch 9, gen_loss = 0.7857126354581059, disc_loss = 0.08746237137198153
Trained batch 101 in epoch 9, gen_loss = 0.7859040735399022, disc_loss = 0.08892073335272133
Trained batch 102 in epoch 9, gen_loss = 0.7847302113343211, disc_loss = 0.08902327541840598
Trained batch 103 in epoch 9, gen_loss = 0.782748168764206, disc_loss = 0.08982367440162656
Trained batch 104 in epoch 9, gen_loss = 0.7862887737296876, disc_loss = 0.09013108851476795
Trained batch 105 in epoch 9, gen_loss = 0.7876262273990883, disc_loss = 0.09005561350616363
Trained batch 106 in epoch 9, gen_loss = 0.7880907830233886, disc_loss = 0.08943204483382891
Trained batch 107 in epoch 9, gen_loss = 0.787427840685403, disc_loss = 0.08916747438100477
Trained batch 108 in epoch 9, gen_loss = 0.787842585679588, disc_loss = 0.08885963287614627
Trained batch 109 in epoch 9, gen_loss = 0.7873647372830997, disc_loss = 0.08850002000108362
Trained batch 110 in epoch 9, gen_loss = 0.7860471136398144, disc_loss = 0.0884761403793016
Trained batch 111 in epoch 9, gen_loss = 0.7869366857090166, disc_loss = 0.08840566636562082
Trained batch 112 in epoch 9, gen_loss = 0.7867308077031532, disc_loss = 0.08807543209399533
Trained batch 113 in epoch 9, gen_loss = 0.786076390168123, disc_loss = 0.08773255697043057
Trained batch 114 in epoch 9, gen_loss = 0.7859096426030864, disc_loss = 0.08737206390208524
Trained batch 115 in epoch 9, gen_loss = 0.7857241987668234, disc_loss = 0.08697516261599958
Trained batch 116 in epoch 9, gen_loss = 0.7886700902739142, disc_loss = 0.08674360705842064
Trained batch 117 in epoch 9, gen_loss = 0.7870418820845879, disc_loss = 0.0867045163334805
Trained batch 118 in epoch 9, gen_loss = 0.7871070897378841, disc_loss = 0.08638919203565652
Trained batch 119 in epoch 9, gen_loss = 0.7872901412347952, disc_loss = 0.08587326131916294
Trained batch 120 in epoch 9, gen_loss = 0.7869140099395405, disc_loss = 0.08559412309853745
Trained batch 121 in epoch 9, gen_loss = 0.7862946637829796, disc_loss = 0.08571419648856657
Trained batch 122 in epoch 9, gen_loss = 0.783485989502775, disc_loss = 0.08624823528485812
Trained batch 123 in epoch 9, gen_loss = 0.7863344023785284, disc_loss = 0.08664257047067006
Trained batch 124 in epoch 9, gen_loss = 0.7854560577869415, disc_loss = 0.08634239218384028
Trained batch 125 in epoch 9, gen_loss = 0.7859698749250836, disc_loss = 0.08690591189744216
Trained batch 126 in epoch 9, gen_loss = 0.7854105776219856, disc_loss = 0.08681733722204533
Trained batch 127 in epoch 9, gen_loss = 0.7834438120480627, disc_loss = 0.08724972341588
Trained batch 128 in epoch 9, gen_loss = 0.7847068196581316, disc_loss = 0.08676391179391811
Trained batch 129 in epoch 9, gen_loss = 0.7845452265097544, disc_loss = 0.08677581070850675
Trained batch 130 in epoch 9, gen_loss = 0.7848337035597736, disc_loss = 0.08630871472041343
Trained batch 131 in epoch 9, gen_loss = 0.7879814733610009, disc_loss = 0.08653299629716485
Trained batch 132 in epoch 9, gen_loss = 0.7861467382513491, disc_loss = 0.08741397691428437
Trained batch 133 in epoch 9, gen_loss = 0.7864301580546508, disc_loss = 0.08798625737901276
Trained batch 134 in epoch 9, gen_loss = 0.78563469670437, disc_loss = 0.08791202059084618
Trained batch 135 in epoch 9, gen_loss = 0.785448425613782, disc_loss = 0.08779506829758997
Trained batch 136 in epoch 9, gen_loss = 0.7869627021089958, disc_loss = 0.08774614633897143
Trained batch 137 in epoch 9, gen_loss = 0.7880650065515352, disc_loss = 0.08761472865750176
Trained batch 138 in epoch 9, gen_loss = 0.7870696485042572, disc_loss = 0.08813606637442926
Trained batch 139 in epoch 9, gen_loss = 0.784936987715108, disc_loss = 0.08848249332846275
Trained batch 140 in epoch 9, gen_loss = 0.7856188059275877, disc_loss = 0.08869205183408996
Trained batch 141 in epoch 9, gen_loss = 0.787683720529919, disc_loss = 0.08949410265416537
Trained batch 142 in epoch 9, gen_loss = 0.7862859766383271, disc_loss = 0.08977136756391167
Trained batch 143 in epoch 9, gen_loss = 0.786695367967089, disc_loss = 0.0897781629076538
Trained batch 144 in epoch 9, gen_loss = 0.7845932485728428, disc_loss = 0.09055537751651016
Trained batch 145 in epoch 9, gen_loss = 0.7860537826606672, disc_loss = 0.09080175081370016
Trained batch 146 in epoch 9, gen_loss = 0.7860600188070413, disc_loss = 0.09058088313179966
Trained batch 147 in epoch 9, gen_loss = 0.7855863122118486, disc_loss = 0.09042752429062652
Trained batch 148 in epoch 9, gen_loss = 0.7850481681775727, disc_loss = 0.09025699665907445
Trained batch 149 in epoch 9, gen_loss = 0.7843642383813858, disc_loss = 0.09037546069050828
Trained batch 150 in epoch 9, gen_loss = 0.785314949735111, disc_loss = 0.09069112407672682
Trained batch 151 in epoch 9, gen_loss = 0.7842612562603072, disc_loss = 0.0909415123751387
Trained batch 152 in epoch 9, gen_loss = 0.7849225349286023, disc_loss = 0.090955525155794
Trained batch 153 in epoch 9, gen_loss = 0.7843569252011063, disc_loss = 0.09066161296221537
Trained batch 154 in epoch 9, gen_loss = 0.7833188131932289, disc_loss = 0.09091536350428096
Trained batch 155 in epoch 9, gen_loss = 0.7845359809505634, disc_loss = 0.0905530132078685
Trained batch 156 in epoch 9, gen_loss = 0.7838409476599116, disc_loss = 0.09063290152698755
Trained batch 157 in epoch 9, gen_loss = 0.78476912820641, disc_loss = 0.09111140713779421
Trained batch 158 in epoch 9, gen_loss = 0.7845269379750738, disc_loss = 0.0910489850929417
Trained batch 159 in epoch 9, gen_loss = 0.7838504588231444, disc_loss = 0.09093398156692274
Trained batch 160 in epoch 9, gen_loss = 0.7843529272893941, disc_loss = 0.0909894514447136
Trained batch 161 in epoch 9, gen_loss = 0.7852795571088791, disc_loss = 0.09074647472251529
Trained batch 162 in epoch 9, gen_loss = 0.7856708386558696, disc_loss = 0.09101366453398407
Trained batch 163 in epoch 9, gen_loss = 0.7848678469294454, disc_loss = 0.09138721051035313
Trained batch 164 in epoch 9, gen_loss = 0.7846219834053155, disc_loss = 0.091012092188678
Trained batch 165 in epoch 9, gen_loss = 0.7854904699397375, disc_loss = 0.09095498863944268
Trained batch 166 in epoch 9, gen_loss = 0.7847510378160877, disc_loss = 0.09118427325620088
Trained batch 167 in epoch 9, gen_loss = 0.7858228791682493, disc_loss = 0.0909179666667201
Trained batch 168 in epoch 9, gen_loss = 0.7851900802208827, disc_loss = 0.09068032310581242
Trained batch 169 in epoch 9, gen_loss = 0.7853159285643522, disc_loss = 0.09037822288296679
Trained batch 170 in epoch 9, gen_loss = 0.7872647589061692, disc_loss = 0.09021061977469608
Trained batch 171 in epoch 9, gen_loss = 0.7885851712767468, disc_loss = 0.08982515101710897
Trained batch 172 in epoch 9, gen_loss = 0.7880672318053383, disc_loss = 0.08958268032619202
Trained batch 173 in epoch 9, gen_loss = 0.787859980231044, disc_loss = 0.08943130397612507
Trained batch 174 in epoch 9, gen_loss = 0.7867004818575722, disc_loss = 0.08960263039916753
Trained batch 175 in epoch 9, gen_loss = 0.7877648399973457, disc_loss = 0.08916384134632112
Trained batch 176 in epoch 9, gen_loss = 0.7880172626783619, disc_loss = 0.0888918856748164
Trained batch 177 in epoch 9, gen_loss = 0.7883172924264094, disc_loss = 0.0887054348981866
Trained batch 178 in epoch 9, gen_loss = 0.7884482779649383, disc_loss = 0.088561350287214
Trained batch 179 in epoch 9, gen_loss = 0.788192467391491, disc_loss = 0.08838865413951377
Trained batch 180 in epoch 9, gen_loss = 0.789268233664128, disc_loss = 0.08814235023886624
Trained batch 181 in epoch 9, gen_loss = 0.7903862515321145, disc_loss = 0.08781236937719879
Trained batch 182 in epoch 9, gen_loss = 0.7904541308436889, disc_loss = 0.08753963956314195
Trained batch 183 in epoch 9, gen_loss = 0.7898540410982526, disc_loss = 0.08723176284389489
Trained batch 184 in epoch 9, gen_loss = 0.7893071926928855, disc_loss = 0.08704678892988611
Trained batch 185 in epoch 9, gen_loss = 0.7894328622728266, disc_loss = 0.08688809073239726
Trained batch 186 in epoch 9, gen_loss = 0.7898836615570088, disc_loss = 0.08657636178189261
Trained batch 187 in epoch 9, gen_loss = 0.7903198106808865, disc_loss = 0.08701890595554512
Trained batch 188 in epoch 9, gen_loss = 0.789634292876279, disc_loss = 0.08723659071795366
Trained batch 189 in epoch 9, gen_loss = 0.7883570007587734, disc_loss = 0.08733695250886836
Trained batch 190 in epoch 9, gen_loss = 0.7884740880958697, disc_loss = 0.08706882652090327
Trained batch 191 in epoch 9, gen_loss = 0.7899526247444252, disc_loss = 0.08734466726794683
Trained batch 192 in epoch 9, gen_loss = 0.7897261969474931, disc_loss = 0.08735473347354893
Trained batch 193 in epoch 9, gen_loss = 0.7892639681543272, disc_loss = 0.08739552298829574
Trained batch 194 in epoch 9, gen_loss = 0.7889114384467785, disc_loss = 0.08751741553632877
Trained batch 195 in epoch 9, gen_loss = 0.7883947496207393, disc_loss = 0.08738389751417752
Trained batch 196 in epoch 9, gen_loss = 0.7902424061661444, disc_loss = 0.08731390614781132
Trained batch 197 in epoch 9, gen_loss = 0.7909797073313685, disc_loss = 0.08703826081402825
Trained batch 198 in epoch 9, gen_loss = 0.7907557405119565, disc_loss = 0.08687325379338547
Trained batch 199 in epoch 9, gen_loss = 0.792089668661356, disc_loss = 0.08704912807326765
Trained batch 200 in epoch 9, gen_loss = 0.7908225078784411, disc_loss = 0.08730211204835284
Trained batch 201 in epoch 9, gen_loss = 0.7900200573229553, disc_loss = 0.08764448425833984
Trained batch 202 in epoch 9, gen_loss = 0.7908920664799037, disc_loss = 0.0878066293886069
Trained batch 203 in epoch 9, gen_loss = 0.7902612150007603, disc_loss = 0.08776990630590886
Trained batch 204 in epoch 9, gen_loss = 0.7897139123300226, disc_loss = 0.08748814759367123
Trained batch 205 in epoch 9, gen_loss = 0.7914114176358992, disc_loss = 0.08766674989545085
Trained batch 206 in epoch 9, gen_loss = 0.7915244003136953, disc_loss = 0.08747673394149484
Trained batch 207 in epoch 9, gen_loss = 0.7914860613930684, disc_loss = 0.08728705630906355
Trained batch 208 in epoch 9, gen_loss = 0.7918621536932493, disc_loss = 0.08694537282079173
Trained batch 209 in epoch 9, gen_loss = 0.7929491600819997, disc_loss = 0.08722509648207398
Trained batch 210 in epoch 9, gen_loss = 0.7919448036435656, disc_loss = 0.08716251646826194
Trained batch 211 in epoch 9, gen_loss = 0.7926144533843364, disc_loss = 0.08681505174323353
Trained batch 212 in epoch 9, gen_loss = 0.7938368668858434, disc_loss = 0.08684514274934368
Trained batch 213 in epoch 9, gen_loss = 0.7944641972535125, disc_loss = 0.08660944729660437
Trained batch 214 in epoch 9, gen_loss = 0.793389634891998, disc_loss = 0.08666475682930891
Trained batch 215 in epoch 9, gen_loss = 0.7928835762043794, disc_loss = 0.08691010587089867
Trained batch 216 in epoch 9, gen_loss = 0.7926890291101921, disc_loss = 0.08678952164192628
Trained batch 217 in epoch 9, gen_loss = 0.7927090335603154, disc_loss = 0.08663116616769395
Trained batch 218 in epoch 9, gen_loss = 0.7940849333865457, disc_loss = 0.08629951659232786
Trained batch 219 in epoch 9, gen_loss = 0.7957717181606726, disc_loss = 0.08624326616356319
Trained batch 220 in epoch 9, gen_loss = 0.7957436548908372, disc_loss = 0.08615090950008701
Trained batch 221 in epoch 9, gen_loss = 0.7947018918421891, disc_loss = 0.08633212643667115
Trained batch 222 in epoch 9, gen_loss = 0.7963423936089058, disc_loss = 0.08653795912093379
Trained batch 223 in epoch 9, gen_loss = 0.7970990606450609, disc_loss = 0.08761431216095973
Trained batch 224 in epoch 9, gen_loss = 0.7960585200786591, disc_loss = 0.08765782391859425
Trained batch 225 in epoch 9, gen_loss = 0.7961400368836073, disc_loss = 0.08748457883278617
Trained batch 226 in epoch 9, gen_loss = 0.7962355446973036, disc_loss = 0.08814741289530294
Trained batch 227 in epoch 9, gen_loss = 0.7954304969885893, disc_loss = 0.088540979571183
Trained batch 228 in epoch 9, gen_loss = 0.7951733424413673, disc_loss = 0.0886413892202372
Trained batch 229 in epoch 9, gen_loss = 0.7954268695219703, disc_loss = 0.08861989740930173
Trained batch 230 in epoch 9, gen_loss = 0.7953983154389765, disc_loss = 0.08868424116242758
Trained batch 231 in epoch 9, gen_loss = 0.795740718086218, disc_loss = 0.08873754257239916
Trained batch 232 in epoch 9, gen_loss = 0.7949433256372361, disc_loss = 0.0885514461799113
Trained batch 233 in epoch 9, gen_loss = 0.795011251528039, disc_loss = 0.0883726860738845
Trained batch 234 in epoch 9, gen_loss = 0.7964727149364796, disc_loss = 0.0882184209579483
Trained batch 235 in epoch 9, gen_loss = 0.7962852460095438, disc_loss = 0.08810089395176303
Trained batch 236 in epoch 9, gen_loss = 0.7959590007232714, disc_loss = 0.08799134989422333
Trained batch 237 in epoch 9, gen_loss = 0.7959727748852818, disc_loss = 0.08771599748586657
Trained batch 238 in epoch 9, gen_loss = 0.7959186171637419, disc_loss = 0.08763771623404205
Trained batch 239 in epoch 9, gen_loss = 0.7951802510768176, disc_loss = 0.08786817066526662
Trained batch 240 in epoch 9, gen_loss = 0.7956679363221054, disc_loss = 0.08766988460051815
Trained batch 241 in epoch 9, gen_loss = 0.7966183720787695, disc_loss = 0.08828618724576452
Trained batch 242 in epoch 9, gen_loss = 0.7963776665705221, disc_loss = 0.08832627972549617
Trained batch 243 in epoch 9, gen_loss = 0.7957275230132166, disc_loss = 0.08839484593510384
Trained batch 244 in epoch 9, gen_loss = 0.7952215626531718, disc_loss = 0.08835811556449959
Trained batch 245 in epoch 9, gen_loss = 0.7957823367380514, disc_loss = 0.0888298675645052
Trained batch 246 in epoch 9, gen_loss = 0.7970701966449799, disc_loss = 0.08856299432816535
Trained batch 247 in epoch 9, gen_loss = 0.7963905482282562, disc_loss = 0.08848507561901163
Trained batch 248 in epoch 9, gen_loss = 0.7958991717861359, disc_loss = 0.08844111363841109
Trained batch 249 in epoch 9, gen_loss = 0.7950766633749008, disc_loss = 0.08877580363303422
Trained batch 250 in epoch 9, gen_loss = 0.7960367785744458, disc_loss = 0.08914008042756542
Trained batch 251 in epoch 9, gen_loss = 0.7954938147985746, disc_loss = 0.08932213947206499
Trained batch 252 in epoch 9, gen_loss = 0.7962579148795765, disc_loss = 0.08917981967064939
Trained batch 253 in epoch 9, gen_loss = 0.7953956301991395, disc_loss = 0.08949555841633888
Trained batch 254 in epoch 9, gen_loss = 0.7952183885901583, disc_loss = 0.08927546041999378
Trained batch 255 in epoch 9, gen_loss = 0.7958515108330175, disc_loss = 0.08933443428395549
Trained batch 256 in epoch 9, gen_loss = 0.7956563608887595, disc_loss = 0.08920738414828648
Trained batch 257 in epoch 9, gen_loss = 0.7956994297199471, disc_loss = 0.08912696144290903
Trained batch 258 in epoch 9, gen_loss = 0.7962799114840371, disc_loss = 0.08886345758545122
Trained batch 259 in epoch 9, gen_loss = 0.7969326231342095, disc_loss = 0.08860417844441075
Trained batch 260 in epoch 9, gen_loss = 0.7965416877434172, disc_loss = 0.08854951523244381
Trained batch 261 in epoch 9, gen_loss = 0.7962399899732066, disc_loss = 0.08854158881710458
Trained batch 262 in epoch 9, gen_loss = 0.7960599322056136, disc_loss = 0.08832727245873145
Trained batch 263 in epoch 9, gen_loss = 0.7971718944609165, disc_loss = 0.08833898618732663
Trained batch 264 in epoch 9, gen_loss = 0.796230512632514, disc_loss = 0.08876356227358558
Trained batch 265 in epoch 9, gen_loss = 0.7971421156386683, disc_loss = 0.08895046945269171
Trained batch 266 in epoch 9, gen_loss = 0.7970170638757699, disc_loss = 0.08888737249714829
Trained batch 267 in epoch 9, gen_loss = 0.79619013228968, disc_loss = 0.08928650829579625
Trained batch 268 in epoch 9, gen_loss = 0.7956187533401645, disc_loss = 0.08934505603044228
Trained batch 269 in epoch 9, gen_loss = 0.7956460874389719, disc_loss = 0.08912814052568542
Trained batch 270 in epoch 9, gen_loss = 0.7955808957344491, disc_loss = 0.08906434396646119
Trained batch 271 in epoch 9, gen_loss = 0.7960999828270253, disc_loss = 0.08893513070035945
Trained batch 272 in epoch 9, gen_loss = 0.7960688422669421, disc_loss = 0.0887010224340927
Trained batch 273 in epoch 9, gen_loss = 0.7967859938414428, disc_loss = 0.08841354928801964
Trained batch 274 in epoch 9, gen_loss = 0.7972878088734366, disc_loss = 0.08815617663616483
Trained batch 275 in epoch 9, gen_loss = 0.7970381829401721, disc_loss = 0.08797963586487416
Trained batch 276 in epoch 9, gen_loss = 0.7975431505308255, disc_loss = 0.08797381658927413
Trained batch 277 in epoch 9, gen_loss = 0.797903281428831, disc_loss = 0.08850609941957452
Trained batch 278 in epoch 9, gen_loss = 0.7968030479005588, disc_loss = 0.08924035238616142
Trained batch 279 in epoch 9, gen_loss = 0.7972718039793628, disc_loss = 0.08896918990316667
Trained batch 280 in epoch 9, gen_loss = 0.7975552554020254, disc_loss = 0.08892519206299158
Trained batch 281 in epoch 9, gen_loss = 0.7990460494097243, disc_loss = 0.08881254828739779
Trained batch 282 in epoch 9, gen_loss = 0.7993562302614691, disc_loss = 0.08858714222763221
Trained batch 283 in epoch 9, gen_loss = 0.7991723881011278, disc_loss = 0.08840327089796708
Trained batch 284 in epoch 9, gen_loss = 0.7989655953750275, disc_loss = 0.08823233772592064
Trained batch 285 in epoch 9, gen_loss = 0.7986116733375963, disc_loss = 0.08812848256145428
Trained batch 286 in epoch 9, gen_loss = 0.7990537162234144, disc_loss = 0.08839730478706365
Trained batch 287 in epoch 9, gen_loss = 0.7992304107174277, disc_loss = 0.08822078264590043
Trained batch 288 in epoch 9, gen_loss = 0.7991914669741397, disc_loss = 0.08809833366836334
Trained batch 289 in epoch 9, gen_loss = 0.7989550007828351, disc_loss = 0.08803794072170196
Trained batch 290 in epoch 9, gen_loss = 0.7982314314014723, disc_loss = 0.08817670493357882
Trained batch 291 in epoch 9, gen_loss = 0.799098731414096, disc_loss = 0.0884276765417818
Trained batch 292 in epoch 9, gen_loss = 0.7989904259048631, disc_loss = 0.08823187057717159
Trained batch 293 in epoch 9, gen_loss = 0.7991311463977204, disc_loss = 0.08800127626821196
Trained batch 294 in epoch 9, gen_loss = 0.798247833878307, disc_loss = 0.08824441383387578
Trained batch 295 in epoch 9, gen_loss = 0.7982505212563116, disc_loss = 0.08819906681310385
Trained batch 296 in epoch 9, gen_loss = 0.7984173238678813, disc_loss = 0.08811899521372435
Trained batch 297 in epoch 9, gen_loss = 0.7991673999384745, disc_loss = 0.08787501073011116
Trained batch 298 in epoch 9, gen_loss = 0.7990298290117129, disc_loss = 0.08768845987148009
Trained batch 299 in epoch 9, gen_loss = 0.7985094792644183, disc_loss = 0.08780196820385754
Trained batch 300 in epoch 9, gen_loss = 0.7991866003041251, disc_loss = 0.08763839547952446
Trained batch 301 in epoch 9, gen_loss = 0.7990474103894455, disc_loss = 0.08753940200013731
Trained batch 302 in epoch 9, gen_loss = 0.7980332816197927, disc_loss = 0.08803476194970973
Trained batch 303 in epoch 9, gen_loss = 0.798919550780403, disc_loss = 0.08786856538407799
Trained batch 304 in epoch 9, gen_loss = 0.7998728843008885, disc_loss = 0.08782105930454907
Trained batch 305 in epoch 9, gen_loss = 0.7998414237320034, disc_loss = 0.08761672563303043
Trained batch 306 in epoch 9, gen_loss = 0.8004528679172068, disc_loss = 0.08737654694892975
Trained batch 307 in epoch 9, gen_loss = 0.8002192187425378, disc_loss = 0.08724071539926355
Trained batch 308 in epoch 9, gen_loss = 0.8007445527318998, disc_loss = 0.08722648906753576
Trained batch 309 in epoch 9, gen_loss = 0.8003097137135844, disc_loss = 0.08716124091597814
Trained batch 310 in epoch 9, gen_loss = 0.8002663564260366, disc_loss = 0.08698024040453399
Trained batch 311 in epoch 9, gen_loss = 0.8012577976362828, disc_loss = 0.08684512353442514
Trained batch 312 in epoch 9, gen_loss = 0.8008621189350518, disc_loss = 0.08683003858029366
Trained batch 313 in epoch 9, gen_loss = 0.8003005756504217, disc_loss = 0.0867563469163409
Trained batch 314 in epoch 9, gen_loss = 0.8006947383994147, disc_loss = 0.08656635803303549
Trained batch 315 in epoch 9, gen_loss = 0.8013609929741183, disc_loss = 0.08634177504307768
Trained batch 316 in epoch 9, gen_loss = 0.8017830044877265, disc_loss = 0.08626750787009106
Trained batch 317 in epoch 9, gen_loss = 0.8021728909053143, disc_loss = 0.08619516500734589
Trained batch 318 in epoch 9, gen_loss = 0.8028445687600437, disc_loss = 0.08596087569154823
Trained batch 319 in epoch 9, gen_loss = 0.802655718382448, disc_loss = 0.0857962168956874
Trained batch 320 in epoch 9, gen_loss = 0.8024522538682753, disc_loss = 0.0856430435239851
Trained batch 321 in epoch 9, gen_loss = 0.8018879504492564, disc_loss = 0.08567668065741103
Trained batch 322 in epoch 9, gen_loss = 0.8023929126306953, disc_loss = 0.08544604049205504
Trained batch 323 in epoch 9, gen_loss = 0.8022069179533441, disc_loss = 0.0853716888965142
Trained batch 324 in epoch 9, gen_loss = 0.8030952320649074, disc_loss = 0.0853435623101317
Trained batch 325 in epoch 9, gen_loss = 0.8027085896832812, disc_loss = 0.08529328288898969
Trained batch 326 in epoch 9, gen_loss = 0.8028251170565229, disc_loss = 0.08510758251874545
Trained batch 327 in epoch 9, gen_loss = 0.8034548131612743, disc_loss = 0.08487479179734136
Trained batch 328 in epoch 9, gen_loss = 0.8033536264055768, disc_loss = 0.08499689499839098
Trained batch 329 in epoch 9, gen_loss = 0.8035729242996736, disc_loss = 0.08481986958985076
Trained batch 330 in epoch 9, gen_loss = 0.8039628295199749, disc_loss = 0.08465444432217009
Trained batch 331 in epoch 9, gen_loss = 0.804353625569717, disc_loss = 0.08444977738524237
Trained batch 332 in epoch 9, gen_loss = 0.8047677587281477, disc_loss = 0.08422924876884297
Trained batch 333 in epoch 9, gen_loss = 0.8048523063966614, disc_loss = 0.08429052501158443
Trained batch 334 in epoch 9, gen_loss = 0.8041640234527303, disc_loss = 0.08460647013427607
Trained batch 335 in epoch 9, gen_loss = 0.8046694952285006, disc_loss = 0.08439945247733877
Trained batch 336 in epoch 9, gen_loss = 0.8064603067116497, disc_loss = 0.08504256292160611
Trained batch 337 in epoch 9, gen_loss = 0.8055160379797749, disc_loss = 0.0854050501211155
Trained batch 338 in epoch 9, gen_loss = 0.8050033551225971, disc_loss = 0.08554554047134422
Trained batch 339 in epoch 9, gen_loss = 0.805214680380681, disc_loss = 0.08544453052694306
Trained batch 340 in epoch 9, gen_loss = 0.8045698090557478, disc_loss = 0.08552662751847698
Trained batch 341 in epoch 9, gen_loss = 0.8046148784502208, disc_loss = 0.0857760767555899
Trained batch 342 in epoch 9, gen_loss = 0.8039301582571369, disc_loss = 0.08597502858532761
Trained batch 343 in epoch 9, gen_loss = 0.8045406612719215, disc_loss = 0.08590036121651877
Trained batch 344 in epoch 9, gen_loss = 0.8038684206596319, disc_loss = 0.08602988234032756
Trained batch 345 in epoch 9, gen_loss = 0.8045339585211925, disc_loss = 0.0861788471956129
Trained batch 346 in epoch 9, gen_loss = 0.8039724868896715, disc_loss = 0.08631282269697024
Trained batch 347 in epoch 9, gen_loss = 0.8043480351909824, disc_loss = 0.08614441254122675
Trained batch 348 in epoch 9, gen_loss = 0.8040845101234906, disc_loss = 0.0861373594388323
Trained batch 349 in epoch 9, gen_loss = 0.8052658378226416, disc_loss = 0.0861130214855075
Trained batch 350 in epoch 9, gen_loss = 0.805024434103925, disc_loss = 0.08603799737395554
Trained batch 351 in epoch 9, gen_loss = 0.8049628786234693, disc_loss = 0.0858991316636093
Trained batch 352 in epoch 9, gen_loss = 0.806239209583731, disc_loss = 0.08590691791525475
Trained batch 353 in epoch 9, gen_loss = 0.8059543294590071, disc_loss = 0.08586968045344966
Trained batch 354 in epoch 9, gen_loss = 0.805424913805975, disc_loss = 0.0858678978461195
Trained batch 355 in epoch 9, gen_loss = 0.8053064469373628, disc_loss = 0.08571450250599993
Trained batch 356 in epoch 9, gen_loss = 0.8060178645685607, disc_loss = 0.08556774108871526
Trained batch 357 in epoch 9, gen_loss = 0.8061987979951517, disc_loss = 0.08539337865155003
Trained batch 358 in epoch 9, gen_loss = 0.8056170297034272, disc_loss = 0.08550207580966372
Trained batch 359 in epoch 9, gen_loss = 0.8058229089611106, disc_loss = 0.08546570568966369
Trained batch 360 in epoch 9, gen_loss = 0.8059089518154757, disc_loss = 0.08540426019754602
Trained batch 361 in epoch 9, gen_loss = 0.8059257437675698, disc_loss = 0.08579013445697602
Trained batch 362 in epoch 9, gen_loss = 0.8060319306272449, disc_loss = 0.0856052043157586
Trained batch 363 in epoch 9, gen_loss = 0.8063038717750665, disc_loss = 0.08544922613917472
Trained batch 364 in epoch 9, gen_loss = 0.8067468452943515, disc_loss = 0.08529364836644636
Trained batch 365 in epoch 9, gen_loss = 0.8067250285155135, disc_loss = 0.08530151272508127
Trained batch 366 in epoch 9, gen_loss = 0.8076061251540275, disc_loss = 0.0857080990849545
Trained batch 367 in epoch 9, gen_loss = 0.8069928209904743, disc_loss = 0.08627473990655625
Trained batch 368 in epoch 9, gen_loss = 0.8065891381363236, disc_loss = 0.08637530274366137
Trained batch 369 in epoch 9, gen_loss = 0.8069543346359923, disc_loss = 0.08625277911589758
Trained batch 370 in epoch 9, gen_loss = 0.8064584437245629, disc_loss = 0.08623521646981773
Trained batch 371 in epoch 9, gen_loss = 0.8062706205953833, disc_loss = 0.08626904533374855
Trained batch 372 in epoch 9, gen_loss = 0.80620258223595, disc_loss = 0.08611525052374394
Trained batch 373 in epoch 9, gen_loss = 0.8057983475413552, disc_loss = 0.08597217913079548
Trained batch 374 in epoch 9, gen_loss = 0.8060281024773915, disc_loss = 0.08609553744892279
Trained batch 375 in epoch 9, gen_loss = 0.8061689858899471, disc_loss = 0.08595292780924826
Trained batch 376 in epoch 9, gen_loss = 0.8064596750217661, disc_loss = 0.08610068818440646
Trained batch 377 in epoch 9, gen_loss = 0.8059825849123102, disc_loss = 0.08621975373003692
Trained batch 378 in epoch 9, gen_loss = 0.8060343777441412, disc_loss = 0.08631763606772103
Trained batch 379 in epoch 9, gen_loss = 0.8061126736433882, disc_loss = 0.08618820358165785
Trained batch 380 in epoch 9, gen_loss = 0.8054122847365582, disc_loss = 0.08621008750393479
Trained batch 381 in epoch 9, gen_loss = 0.8050379062666319, disc_loss = 0.08616238590134843
Trained batch 382 in epoch 9, gen_loss = 0.8055203982650767, disc_loss = 0.08600140566750389
Trained batch 383 in epoch 9, gen_loss = 0.8063165446898589, disc_loss = 0.0858321398118278
Trained batch 384 in epoch 9, gen_loss = 0.8067956107777434, disc_loss = 0.08567791013651854
Trained batch 385 in epoch 9, gen_loss = 0.806910182913968, disc_loss = 0.08555423639656812
Trained batch 386 in epoch 9, gen_loss = 0.8066979056026893, disc_loss = 0.08553357743381376
Trained batch 387 in epoch 9, gen_loss = 0.8063963260693648, disc_loss = 0.0854422820530371
Trained batch 388 in epoch 9, gen_loss = 0.8066307497055181, disc_loss = 0.08526165012969303
Trained batch 389 in epoch 9, gen_loss = 0.8065403980322373, disc_loss = 0.08526695761829614
Trained batch 390 in epoch 9, gen_loss = 0.8058760988590358, disc_loss = 0.08532948568558602
Trained batch 391 in epoch 9, gen_loss = 0.8060048788937987, disc_loss = 0.08523156802284018
Trained batch 392 in epoch 9, gen_loss = 0.805567751631482, disc_loss = 0.08520501717906113
Trained batch 393 in epoch 9, gen_loss = 0.8063395092178722, disc_loss = 0.08541543061755182
Trained batch 394 in epoch 9, gen_loss = 0.8056921571870393, disc_loss = 0.08550451226721081
Trained batch 395 in epoch 9, gen_loss = 0.8057251595939049, disc_loss = 0.085351248182394
Trained batch 396 in epoch 9, gen_loss = 0.8055557300071572, disc_loss = 0.0854650309980291
Trained batch 397 in epoch 9, gen_loss = 0.8053489311705881, disc_loss = 0.08537556784667412
Trained batch 398 in epoch 9, gen_loss = 0.8050723090058282, disc_loss = 0.08525686022501093
Trained batch 399 in epoch 9, gen_loss = 0.805234474465251, disc_loss = 0.08508274792693556
Trained batch 400 in epoch 9, gen_loss = 0.8056718144482211, disc_loss = 0.08493922991757084
Trained batch 401 in epoch 9, gen_loss = 0.8052514208045172, disc_loss = 0.08489574175976698
Trained batch 402 in epoch 9, gen_loss = 0.805211985895119, disc_loss = 0.08480035975834276
Trained batch 403 in epoch 9, gen_loss = 0.8050648539815799, disc_loss = 0.0847330652269544
Trained batch 404 in epoch 9, gen_loss = 0.8052528449782619, disc_loss = 0.08456690954849308
Trained batch 405 in epoch 9, gen_loss = 0.8055990588635646, disc_loss = 0.08445473459865806
Trained batch 406 in epoch 9, gen_loss = 0.805070992257144, disc_loss = 0.08457232067585724
Trained batch 407 in epoch 9, gen_loss = 0.8047744733299694, disc_loss = 0.08461289707224305
Trained batch 408 in epoch 9, gen_loss = 0.8048054888516591, disc_loss = 0.08460657242548932
Trained batch 409 in epoch 9, gen_loss = 0.8053709706882152, disc_loss = 0.08449363285539353
Trained batch 410 in epoch 9, gen_loss = 0.8054377263334835, disc_loss = 0.08438531101348191
Trained batch 411 in epoch 9, gen_loss = 0.8046200788281497, disc_loss = 0.08467428954499005
Trained batch 412 in epoch 9, gen_loss = 0.8047275972568383, disc_loss = 0.0845475148896689
Trained batch 413 in epoch 9, gen_loss = 0.8050828428516066, disc_loss = 0.0846801968201419
Trained batch 414 in epoch 9, gen_loss = 0.8058723977531296, disc_loss = 0.08459691037704428
Trained batch 415 in epoch 9, gen_loss = 0.8053498561135851, disc_loss = 0.08455426996806636
Trained batch 416 in epoch 9, gen_loss = 0.8052246712809272, disc_loss = 0.08461832897000604
Trained batch 417 in epoch 9, gen_loss = 0.8046588851361753, disc_loss = 0.08464355439250691
Trained batch 418 in epoch 9, gen_loss = 0.8045774358980411, disc_loss = 0.08479178869798958
Trained batch 419 in epoch 9, gen_loss = 0.8045904544847352, disc_loss = 0.08471427633027945
Trained batch 420 in epoch 9, gen_loss = 0.8045032782537637, disc_loss = 0.08475065612258509
Trained batch 421 in epoch 9, gen_loss = 0.8040498611627597, disc_loss = 0.08470092482988445
Trained batch 422 in epoch 9, gen_loss = 0.8039461194623446, disc_loss = 0.08463032071172627
Trained batch 423 in epoch 9, gen_loss = 0.804204384884182, disc_loss = 0.08456207635671885
Trained batch 424 in epoch 9, gen_loss = 0.8037474217835595, disc_loss = 0.08470080084222205
Trained batch 425 in epoch 9, gen_loss = 0.8035046610054276, disc_loss = 0.08509538721013377
Trained batch 426 in epoch 9, gen_loss = 0.8032149236291577, disc_loss = 0.08515807745031646
Trained batch 427 in epoch 9, gen_loss = 0.8027018459740086, disc_loss = 0.08519049200760288
Trained batch 428 in epoch 9, gen_loss = 0.8029113953069096, disc_loss = 0.08524800338163659
Trained batch 429 in epoch 9, gen_loss = 0.8026031742955363, disc_loss = 0.08528104616372391
Trained batch 430 in epoch 9, gen_loss = 0.8022708301616103, disc_loss = 0.08530935739748301
Trained batch 431 in epoch 9, gen_loss = 0.8026747186840685, disc_loss = 0.08520155400468933
Trained batch 432 in epoch 9, gen_loss = 0.8033633481960649, disc_loss = 0.08522530502745103
Trained batch 433 in epoch 9, gen_loss = 0.8028164807415228, disc_loss = 0.08541071381042217
Trained batch 434 in epoch 9, gen_loss = 0.8035078549522093, disc_loss = 0.08534659657241969
Trained batch 435 in epoch 9, gen_loss = 0.8040092329776615, disc_loss = 0.08538946997664801
Trained batch 436 in epoch 9, gen_loss = 0.8037173280863249, disc_loss = 0.08547878771321316
Trained batch 437 in epoch 9, gen_loss = 0.8031421217335958, disc_loss = 0.08562539318431867
Trained batch 438 in epoch 9, gen_loss = 0.8043988512018547, disc_loss = 0.08609740518814203
Trained batch 439 in epoch 9, gen_loss = 0.8055227459154346, disc_loss = 0.08611920257098973
Trained batch 440 in epoch 9, gen_loss = 0.8051954427408794, disc_loss = 0.08638877086679275
Trained batch 441 in epoch 9, gen_loss = 0.8050988015141423, disc_loss = 0.0862849685510966
Trained batch 442 in epoch 9, gen_loss = 0.8054359811557873, disc_loss = 0.08620339818298817
Trained batch 443 in epoch 9, gen_loss = 0.805159820294058, disc_loss = 0.08631367368522931
Trained batch 444 in epoch 9, gen_loss = 0.8051147651806306, disc_loss = 0.0865262468334999
Trained batch 445 in epoch 9, gen_loss = 0.8046849918606035, disc_loss = 0.08654773702652865
Trained batch 446 in epoch 9, gen_loss = 0.8053963582387706, disc_loss = 0.08647835981809186
Trained batch 447 in epoch 9, gen_loss = 0.8056363353638777, disc_loss = 0.08633362079854123
Trained batch 448 in epoch 9, gen_loss = 0.8061116749964207, disc_loss = 0.08627073435664576
Trained batch 449 in epoch 9, gen_loss = 0.8054548628462685, disc_loss = 0.0865402609316839
Trained batch 450 in epoch 9, gen_loss = 0.80566109317105, disc_loss = 0.08645581353678804
Trained batch 451 in epoch 9, gen_loss = 0.8061131384652273, disc_loss = 0.08641348202688108
Trained batch 452 in epoch 9, gen_loss = 0.8061388647451043, disc_loss = 0.0863397048938419
Trained batch 453 in epoch 9, gen_loss = 0.805760379732968, disc_loss = 0.086468940645883
Trained batch 454 in epoch 9, gen_loss = 0.8054350054526067, disc_loss = 0.08650701481971768
Trained batch 455 in epoch 9, gen_loss = 0.8060969028687268, disc_loss = 0.0865596477636708
Trained batch 456 in epoch 9, gen_loss = 0.8062802299498468, disc_loss = 0.08650425362198957
Trained batch 457 in epoch 9, gen_loss = 0.8061019713831781, disc_loss = 0.08643610921472832
Trained batch 458 in epoch 9, gen_loss = 0.8056329292019987, disc_loss = 0.08655038261319427
Trained batch 459 in epoch 9, gen_loss = 0.8059376626558926, disc_loss = 0.08665231064204937
Trained batch 460 in epoch 9, gen_loss = 0.8060034263289155, disc_loss = 0.08658325102042867
Trained batch 461 in epoch 9, gen_loss = 0.8052514351549602, disc_loss = 0.0870437610338067
Trained batch 462 in epoch 9, gen_loss = 0.8058502013688469, disc_loss = 0.08753001585715404
Trained batch 463 in epoch 9, gen_loss = 0.8063572649041126, disc_loss = 0.08740160104433267
Trained batch 464 in epoch 9, gen_loss = 0.8062191990114027, disc_loss = 0.08738005460109761
Trained batch 465 in epoch 9, gen_loss = 0.8061422251580611, disc_loss = 0.08743393767321314
Trained batch 466 in epoch 9, gen_loss = 0.8054858433357909, disc_loss = 0.08747889231531472
Trained batch 467 in epoch 9, gen_loss = 0.8056655136438516, disc_loss = 0.08743858357302399
Trained batch 468 in epoch 9, gen_loss = 0.8056465922388186, disc_loss = 0.08755845836262459
Trained batch 469 in epoch 9, gen_loss = 0.8052068456690362, disc_loss = 0.08775480729626849
Trained batch 470 in epoch 9, gen_loss = 0.8046645695489936, disc_loss = 0.08782247699907884
Trained batch 471 in epoch 9, gen_loss = 0.8053251229605433, disc_loss = 0.08793020921648811
Trained batch 472 in epoch 9, gen_loss = 0.8052076746495027, disc_loss = 0.08786955441940915
Trained batch 473 in epoch 9, gen_loss = 0.8048014628233285, disc_loss = 0.08798762065857522
Trained batch 474 in epoch 9, gen_loss = 0.8046997436724211, disc_loss = 0.08796077431032533
Trained batch 475 in epoch 9, gen_loss = 0.8053003379276821, disc_loss = 0.08809342499071059
Trained batch 476 in epoch 9, gen_loss = 0.8051464872540168, disc_loss = 0.08799448491423635
Trained batch 477 in epoch 9, gen_loss = 0.8047690087282507, disc_loss = 0.08811028573708804
Trained batch 478 in epoch 9, gen_loss = 0.8047107487979164, disc_loss = 0.0880426408991311
Trained batch 479 in epoch 9, gen_loss = 0.8047387182712555, disc_loss = 0.08800376387468228
Trained batch 480 in epoch 9, gen_loss = 0.8043689403117571, disc_loss = 0.08794817152644145
Trained batch 481 in epoch 9, gen_loss = 0.804425974851822, disc_loss = 0.08802705330009035
Trained batch 482 in epoch 9, gen_loss = 0.8046970858583786, disc_loss = 0.08802544614820747
Trained batch 483 in epoch 9, gen_loss = 0.8040905046807832, disc_loss = 0.0880933255803856
Trained batch 484 in epoch 9, gen_loss = 0.8040002272301113, disc_loss = 0.0879848638223004
Trained batch 485 in epoch 9, gen_loss = 0.803821825196223, disc_loss = 0.0882686751323595
Trained batch 486 in epoch 9, gen_loss = 0.8035843519214732, disc_loss = 0.08822116807286744
Trained batch 487 in epoch 9, gen_loss = 0.8040616160533467, disc_loss = 0.08811564284727955
Trained batch 488 in epoch 9, gen_loss = 0.803877307349675, disc_loss = 0.08809561822525319
Trained batch 489 in epoch 9, gen_loss = 0.8036149728054903, disc_loss = 0.08802730107337844
Trained batch 490 in epoch 9, gen_loss = 0.8036185021070259, disc_loss = 0.0879114322296046
Trained batch 491 in epoch 9, gen_loss = 0.80390296076856, disc_loss = 0.087762760325918
Trained batch 492 in epoch 9, gen_loss = 0.8038137840450899, disc_loss = 0.08773361534280721
Trained batch 493 in epoch 9, gen_loss = 0.8040959337944926, disc_loss = 0.0876723162486757
Trained batch 494 in epoch 9, gen_loss = 0.8040430728835289, disc_loss = 0.08760835231291224
Trained batch 495 in epoch 9, gen_loss = 0.8036382152668892, disc_loss = 0.08767438437526805
Trained batch 496 in epoch 9, gen_loss = 0.8039553149845039, disc_loss = 0.08752160112915085
Trained batch 497 in epoch 9, gen_loss = 0.8042720956017214, disc_loss = 0.08737212735935147
Trained batch 498 in epoch 9, gen_loss = 0.8043188889901003, disc_loss = 0.08742181924666335
Trained batch 499 in epoch 9, gen_loss = 0.804732564330101, disc_loss = 0.08735424544662238
Trained batch 500 in epoch 9, gen_loss = 0.8040202204100863, disc_loss = 0.08766594617636855
Trained batch 501 in epoch 9, gen_loss = 0.8041614619384249, disc_loss = 0.08759370551581877
Trained batch 502 in epoch 9, gen_loss = 0.8042067099755137, disc_loss = 0.08752346241746697
Trained batch 503 in epoch 9, gen_loss = 0.8037049971402638, disc_loss = 0.08762182970900857
Trained batch 504 in epoch 9, gen_loss = 0.8035724219709339, disc_loss = 0.08757757187479794
Trained batch 505 in epoch 9, gen_loss = 0.8037088911523932, disc_loss = 0.08773568896908063
Trained batch 506 in epoch 9, gen_loss = 0.8039800699881078, disc_loss = 0.08758841419713737
Trained batch 507 in epoch 9, gen_loss = 0.8038139931094928, disc_loss = 0.08752453240646621
Trained batch 508 in epoch 9, gen_loss = 0.8033784348041931, disc_loss = 0.0875364988310398
Trained batch 509 in epoch 9, gen_loss = 0.8039128554802315, disc_loss = 0.08770527429148263
Trained batch 510 in epoch 9, gen_loss = 0.8039605026142471, disc_loss = 0.08761891046877943
Trained batch 511 in epoch 9, gen_loss = 0.8037629866739735, disc_loss = 0.08769271715573268
Trained batch 512 in epoch 9, gen_loss = 0.8036692961614732, disc_loss = 0.08768097741881542
Trained batch 513 in epoch 9, gen_loss = 0.8037133652876324, disc_loss = 0.08757009573918605
Trained batch 514 in epoch 9, gen_loss = 0.8040205799260186, disc_loss = 0.08752391898950326
Trained batch 515 in epoch 9, gen_loss = 0.8037344375553057, disc_loss = 0.08747453292355288
Trained batch 516 in epoch 9, gen_loss = 0.8038449528369498, disc_loss = 0.0873326116333386
Trained batch 517 in epoch 9, gen_loss = 0.8036959213869912, disc_loss = 0.08722231955299851
Trained batch 518 in epoch 9, gen_loss = 0.80397607492344, disc_loss = 0.08710054402564417
Trained batch 519 in epoch 9, gen_loss = 0.8035197484951753, disc_loss = 0.08721646845269089
Trained batch 520 in epoch 9, gen_loss = 0.804246680292653, disc_loss = 0.08742145574410337
Trained batch 521 in epoch 9, gen_loss = 0.8043150336577974, disc_loss = 0.08736632591277589
Trained batch 522 in epoch 9, gen_loss = 0.8041784261882191, disc_loss = 0.08734421891803153
Trained batch 523 in epoch 9, gen_loss = 0.8040857532324682, disc_loss = 0.08727284452259426
Trained batch 524 in epoch 9, gen_loss = 0.8039403758730207, disc_loss = 0.08719733635229723
Trained batch 525 in epoch 9, gen_loss = 0.804027264902347, disc_loss = 0.08706511698394108
Trained batch 526 in epoch 9, gen_loss = 0.8047504224858655, disc_loss = 0.08696180077683202
Trained batch 527 in epoch 9, gen_loss = 0.8045090548694134, disc_loss = 0.08704089355358685
Trained batch 528 in epoch 9, gen_loss = 0.804545659311327, disc_loss = 0.08693574474233648
Trained batch 529 in epoch 9, gen_loss = 0.8049860294135112, disc_loss = 0.08689128924864081
Trained batch 530 in epoch 9, gen_loss = 0.8053724946499768, disc_loss = 0.08691665323594981
Trained batch 531 in epoch 9, gen_loss = 0.8050599008574522, disc_loss = 0.0869572496048658
Trained batch 532 in epoch 9, gen_loss = 0.8058050976014272, disc_loss = 0.08685505387022056
Trained batch 533 in epoch 9, gen_loss = 0.8054334917541747, disc_loss = 0.08691139716989874
Trained batch 534 in epoch 9, gen_loss = 0.8052033643856227, disc_loss = 0.08687931608025716
Trained batch 535 in epoch 9, gen_loss = 0.8048845544012625, disc_loss = 0.08702280688961384
Trained batch 536 in epoch 9, gen_loss = 0.8053075668976072, disc_loss = 0.08695200020083169
Trained batch 537 in epoch 9, gen_loss = 0.805421274169227, disc_loss = 0.08681689890198492
Trained batch 538 in epoch 9, gen_loss = 0.8052935595857411, disc_loss = 0.08681155022938696
Trained batch 539 in epoch 9, gen_loss = 0.8058024459415012, disc_loss = 0.08673204957438564
Trained batch 540 in epoch 9, gen_loss = 0.8057318594230962, disc_loss = 0.08674412220544328
Trained batch 541 in epoch 9, gen_loss = 0.8056973138638528, disc_loss = 0.08669435918654188
Trained batch 542 in epoch 9, gen_loss = 0.8063557177617405, disc_loss = 0.08678483656859694
Trained batch 543 in epoch 9, gen_loss = 0.8061024145606686, disc_loss = 0.08687340107794359
Trained batch 544 in epoch 9, gen_loss = 0.8059381323123197, disc_loss = 0.08679532515859112
Trained batch 545 in epoch 9, gen_loss = 0.8058595163918241, disc_loss = 0.08676807786211808
Trained batch 546 in epoch 9, gen_loss = 0.8055819879938088, disc_loss = 0.08693292962261212
Trained batch 547 in epoch 9, gen_loss = 0.806224570113377, disc_loss = 0.08682559403237364
Trained batch 548 in epoch 9, gen_loss = 0.8063370400873473, disc_loss = 0.08678458453086502
Trained batch 549 in epoch 9, gen_loss = 0.806367927572944, disc_loss = 0.08666997861625118
Trained batch 550 in epoch 9, gen_loss = 0.8062580708150638, disc_loss = 0.086570590384602
Trained batch 551 in epoch 9, gen_loss = 0.8068097314756849, disc_loss = 0.08653604126015706
Trained batch 552 in epoch 9, gen_loss = 0.8072887121229879, disc_loss = 0.08640227332596699
Trained batch 553 in epoch 9, gen_loss = 0.8074994914583351, disc_loss = 0.0862986399987141
Trained batch 554 in epoch 9, gen_loss = 0.8069012580154178, disc_loss = 0.08686508850639199
Trained batch 555 in epoch 9, gen_loss = 0.8069913463948442, disc_loss = 0.0868202096752474
Trained batch 556 in epoch 9, gen_loss = 0.8075571104589869, disc_loss = 0.08718867826859067
Trained batch 557 in epoch 9, gen_loss = 0.807602982741103, disc_loss = 0.08712114795114458
Trained batch 558 in epoch 9, gen_loss = 0.807140449558473, disc_loss = 0.08713702839667607
Trained batch 559 in epoch 9, gen_loss = 0.8073717759656055, disc_loss = 0.08712053762782099
Trained batch 560 in epoch 9, gen_loss = 0.8072320663249004, disc_loss = 0.08714811083712945
Trained batch 561 in epoch 9, gen_loss = 0.8074470644425668, disc_loss = 0.08715175506675424
Trained batch 562 in epoch 9, gen_loss = 0.8070888600277435, disc_loss = 0.08715713107015534
Trained batch 563 in epoch 9, gen_loss = 0.8068268933723158, disc_loss = 0.08717104187070109
Trained batch 564 in epoch 9, gen_loss = 0.8073003402325959, disc_loss = 0.08706805378165657
Trained batch 565 in epoch 9, gen_loss = 0.8074705178977744, disc_loss = 0.0870048589395629
Trained batch 566 in epoch 9, gen_loss = 0.8074117360186535, disc_loss = 0.08688516619022299
Trained batch 567 in epoch 9, gen_loss = 0.8071099874943914, disc_loss = 0.08690887929471604
Trained batch 568 in epoch 9, gen_loss = 0.8071614999867491, disc_loss = 0.08681994417161797
Trained batch 569 in epoch 9, gen_loss = 0.8069129454984999, disc_loss = 0.08679855409519453
Trained batch 570 in epoch 9, gen_loss = 0.8072354796158244, disc_loss = 0.08672400948064705
Trained batch 571 in epoch 9, gen_loss = 0.8070620239510403, disc_loss = 0.08666405303019484
Trained batch 572 in epoch 9, gen_loss = 0.8069875173231694, disc_loss = 0.08656796499482156
Trained batch 573 in epoch 9, gen_loss = 0.8072546478036389, disc_loss = 0.08652120063289065
Trained batch 574 in epoch 9, gen_loss = 0.8074030076420825, disc_loss = 0.08654675165434246
Trained batch 575 in epoch 9, gen_loss = 0.8069811054091487, disc_loss = 0.08656582721838883
Trained batch 576 in epoch 9, gen_loss = 0.8071507175729015, disc_loss = 0.08668256202870835
Trained batch 577 in epoch 9, gen_loss = 0.8071628612527385, disc_loss = 0.08665552407109975
Trained batch 578 in epoch 9, gen_loss = 0.8070936521614978, disc_loss = 0.08662854850980645
Trained batch 579 in epoch 9, gen_loss = 0.8074409992016595, disc_loss = 0.08659394198932267
Trained batch 580 in epoch 9, gen_loss = 0.8072782749255635, disc_loss = 0.08647383750607092
Trained batch 581 in epoch 9, gen_loss = 0.8074363741985301, disc_loss = 0.08638786937868626
Trained batch 582 in epoch 9, gen_loss = 0.8071675901245294, disc_loss = 0.08642107246868555
Trained batch 583 in epoch 9, gen_loss = 0.8069475585569258, disc_loss = 0.08641420877442937
Trained batch 584 in epoch 9, gen_loss = 0.8072909047970405, disc_loss = 0.08640538125306878
Trained batch 585 in epoch 9, gen_loss = 0.8068066530768782, disc_loss = 0.08652772944986363
Trained batch 586 in epoch 9, gen_loss = 0.8066801902484244, disc_loss = 0.08648905195962174
Trained batch 587 in epoch 9, gen_loss = 0.8070493123056938, disc_loss = 0.08644916560519866
Trained batch 588 in epoch 9, gen_loss = 0.807096547151462, disc_loss = 0.08645382313396155
Trained batch 589 in epoch 9, gen_loss = 0.8069252520799637, disc_loss = 0.08646121410084731
Trained batch 590 in epoch 9, gen_loss = 0.8064417440173186, disc_loss = 0.08661368727375156
Trained batch 591 in epoch 9, gen_loss = 0.8067737580654589, disc_loss = 0.08649108800848292
Trained batch 592 in epoch 9, gen_loss = 0.8070007565150172, disc_loss = 0.08637414106543209
Trained batch 593 in epoch 9, gen_loss = 0.8074438528280066, disc_loss = 0.08644469975735303
Trained batch 594 in epoch 9, gen_loss = 0.8073052448885781, disc_loss = 0.0864199008667419
Trained batch 595 in epoch 9, gen_loss = 0.8070127840510151, disc_loss = 0.08639715605996699
Trained batch 596 in epoch 9, gen_loss = 0.8074682110817588, disc_loss = 0.0862916852792154
Trained batch 597 in epoch 9, gen_loss = 0.8072592670403197, disc_loss = 0.08631299252008216
Trained batch 598 in epoch 9, gen_loss = 0.807602777753728, disc_loss = 0.08634344285947951
Trained batch 599 in epoch 9, gen_loss = 0.807782267878453, disc_loss = 0.08627215213142335
Trained batch 600 in epoch 9, gen_loss = 0.8076396469962775, disc_loss = 0.0862077817897283
Trained batch 601 in epoch 9, gen_loss = 0.8074747601715829, disc_loss = 0.08612934000901507
Trained batch 602 in epoch 9, gen_loss = 0.8078875765575105, disc_loss = 0.08614490514506846
Trained batch 603 in epoch 9, gen_loss = 0.8076184725031158, disc_loss = 0.08621838652769363
Trained batch 604 in epoch 9, gen_loss = 0.8080386527806274, disc_loss = 0.0861880959034705
Trained batch 605 in epoch 9, gen_loss = 0.8081938675036131, disc_loss = 0.08608435525592699
Trained batch 606 in epoch 9, gen_loss = 0.8082642315148915, disc_loss = 0.08602146635866145
Trained batch 607 in epoch 9, gen_loss = 0.807999834173212, disc_loss = 0.086086606125862
Trained batch 608 in epoch 9, gen_loss = 0.8083332956620234, disc_loss = 0.08612823536182174
Trained batch 609 in epoch 9, gen_loss = 0.8083646461123326, disc_loss = 0.0860737057952363
Trained batch 610 in epoch 9, gen_loss = 0.8081487549404857, disc_loss = 0.08612665052048606
Trained batch 611 in epoch 9, gen_loss = 0.8078143574735698, disc_loss = 0.08623454569735461
Trained batch 612 in epoch 9, gen_loss = 0.808362431228647, disc_loss = 0.08628092105477611
Trained batch 613 in epoch 9, gen_loss = 0.8080596358360608, disc_loss = 0.08630786422057629
Trained batch 614 in epoch 9, gen_loss = 0.8078690045732793, disc_loss = 0.08642024796122942
Trained batch 615 in epoch 9, gen_loss = 0.8080896518930987, disc_loss = 0.086361602889132
Trained batch 616 in epoch 9, gen_loss = 0.8078379872069367, disc_loss = 0.08650985473353337
Trained batch 617 in epoch 9, gen_loss = 0.8078955633258357, disc_loss = 0.08643380634209388
Trained batch 618 in epoch 9, gen_loss = 0.8075590361397178, disc_loss = 0.08644059090687019
Trained batch 619 in epoch 9, gen_loss = 0.8078185562645236, disc_loss = 0.08647755568005866
Trained batch 620 in epoch 9, gen_loss = 0.8073558694594533, disc_loss = 0.0866555844474098
Trained batch 621 in epoch 9, gen_loss = 0.8074458500675833, disc_loss = 0.08661813921088479
Trained batch 622 in epoch 9, gen_loss = 0.8073412484667274, disc_loss = 0.08659614380718139
Trained batch 623 in epoch 9, gen_loss = 0.8079887472379667, disc_loss = 0.0869471686742961
Trained batch 624 in epoch 9, gen_loss = 0.8075389544963837, disc_loss = 0.08759265498816968
Trained batch 625 in epoch 9, gen_loss = 0.8076571973082357, disc_loss = 0.08768080050845782
Trained batch 626 in epoch 9, gen_loss = 0.8076162977557053, disc_loss = 0.08790284181028557
Trained batch 627 in epoch 9, gen_loss = 0.8077511085541385, disc_loss = 0.08790183476332551
Trained batch 628 in epoch 9, gen_loss = 0.8074611185180743, disc_loss = 0.08804283617730645
Trained batch 629 in epoch 9, gen_loss = 0.8072457681099574, disc_loss = 0.0880927145569807
Trained batch 630 in epoch 9, gen_loss = 0.8073010828623493, disc_loss = 0.08818284176266421
Trained batch 631 in epoch 9, gen_loss = 0.8072822502802445, disc_loss = 0.08811808339485168
Trained batch 632 in epoch 9, gen_loss = 0.8072172655219338, disc_loss = 0.08808748356668399
Trained batch 633 in epoch 9, gen_loss = 0.807112013268922, disc_loss = 0.08801566487125324
Trained batch 634 in epoch 9, gen_loss = 0.8069790605015642, disc_loss = 0.08817479933986044
Trained batch 635 in epoch 9, gen_loss = 0.8069794441825189, disc_loss = 0.0881141923022392
Trained batch 636 in epoch 9, gen_loss = 0.8067663304004788, disc_loss = 0.08807788210594954
Trained batch 637 in epoch 9, gen_loss = 0.8063697044658811, disc_loss = 0.08824751803178492
Trained batch 638 in epoch 9, gen_loss = 0.80600353739631, disc_loss = 0.08829713326256507
Trained batch 639 in epoch 9, gen_loss = 0.805633212486282, disc_loss = 0.0883695133641595
Trained batch 640 in epoch 9, gen_loss = 0.8059825613141618, disc_loss = 0.08859239052835846
Trained batch 641 in epoch 9, gen_loss = 0.8062445562669421, disc_loss = 0.08853342378007195
Trained batch 642 in epoch 9, gen_loss = 0.8058775272654893, disc_loss = 0.08869916871248007
Trained batch 643 in epoch 9, gen_loss = 0.8052441667048087, disc_loss = 0.08900985745018962
Trained batch 644 in epoch 9, gen_loss = 0.8056188253007194, disc_loss = 0.08904722861714603
Trained batch 645 in epoch 9, gen_loss = 0.8058025699005038, disc_loss = 0.08917885856997025
Trained batch 646 in epoch 9, gen_loss = 0.8056147638852298, disc_loss = 0.0891328202891617
Trained batch 647 in epoch 9, gen_loss = 0.8059330768883228, disc_loss = 0.08908583023470401
Trained batch 648 in epoch 9, gen_loss = 0.8060319459034224, disc_loss = 0.0890162058651034
Trained batch 649 in epoch 9, gen_loss = 0.805703753553904, disc_loss = 0.08911882377874393
Trained batch 650 in epoch 9, gen_loss = 0.8056349806064101, disc_loss = 0.08906443941531368
Trained batch 651 in epoch 9, gen_loss = 0.8061704981637878, disc_loss = 0.08938748453760896
Trained batch 652 in epoch 9, gen_loss = 0.8056194324497059, disc_loss = 0.08958129808706036
Trained batch 653 in epoch 9, gen_loss = 0.8058252612111765, disc_loss = 0.08974153860913596
Trained batch 654 in epoch 9, gen_loss = 0.8057091441318279, disc_loss = 0.08975672213687697
Trained batch 655 in epoch 9, gen_loss = 0.8057194634272558, disc_loss = 0.0896893193712458
Trained batch 656 in epoch 9, gen_loss = 0.8058423450276188, disc_loss = 0.08965370286669996
Trained batch 657 in epoch 9, gen_loss = 0.8057324006292957, disc_loss = 0.08964745503054836
Trained batch 658 in epoch 9, gen_loss = 0.8055027258866474, disc_loss = 0.08965054315787617
Trained batch 659 in epoch 9, gen_loss = 0.805844488333572, disc_loss = 0.08974551913808242
Trained batch 660 in epoch 9, gen_loss = 0.8055305443535054, disc_loss = 0.08980810487538621
Trained batch 661 in epoch 9, gen_loss = 0.8054619301391872, disc_loss = 0.08977074887085808
Trained batch 662 in epoch 9, gen_loss = 0.8055948362001646, disc_loss = 0.0897797613768511
Trained batch 663 in epoch 9, gen_loss = 0.8054528510624386, disc_loss = 0.08983648902489748
Trained batch 664 in epoch 9, gen_loss = 0.805449259505236, disc_loss = 0.08976883948465487
Trained batch 665 in epoch 9, gen_loss = 0.8055766340759065, disc_loss = 0.08966128129019842
Trained batch 666 in epoch 9, gen_loss = 0.8052195302103234, disc_loss = 0.0896585435820171
Trained batch 667 in epoch 9, gen_loss = 0.8051188850920358, disc_loss = 0.08962552383553214
Trained batch 668 in epoch 9, gen_loss = 0.8053004842791679, disc_loss = 0.08966053651732091
Trained batch 669 in epoch 9, gen_loss = 0.8050604303826147, disc_loss = 0.08969685665762692
Trained batch 670 in epoch 9, gen_loss = 0.8052605672582607, disc_loss = 0.08960972089270454
Trained batch 671 in epoch 9, gen_loss = 0.8052590295583719, disc_loss = 0.08958541091054767
Trained batch 672 in epoch 9, gen_loss = 0.8052510534583371, disc_loss = 0.08952877303809592
Trained batch 673 in epoch 9, gen_loss = 0.8053792178719263, disc_loss = 0.08942800996001556
Trained batch 674 in epoch 9, gen_loss = 0.8053778087209772, disc_loss = 0.08956629787606221
Trained batch 675 in epoch 9, gen_loss = 0.8054277641621567, disc_loss = 0.08950423265493215
Trained batch 676 in epoch 9, gen_loss = 0.8051562962098875, disc_loss = 0.08957522624671635
Trained batch 677 in epoch 9, gen_loss = 0.8053150288211209, disc_loss = 0.08953045862713131
Trained batch 678 in epoch 9, gen_loss = 0.805454152366023, disc_loss = 0.08942733465012201
Trained batch 679 in epoch 9, gen_loss = 0.8053645493791384, disc_loss = 0.08935228161349454
Trained batch 680 in epoch 9, gen_loss = 0.8054536836175317, disc_loss = 0.08925083627248738
Trained batch 681 in epoch 9, gen_loss = 0.8054003914342948, disc_loss = 0.08916776352821469
Trained batch 682 in epoch 9, gen_loss = 0.80567722269068, disc_loss = 0.08906040301663722
Trained batch 683 in epoch 9, gen_loss = 0.8054859387682892, disc_loss = 0.08904726510562481
Trained batch 684 in epoch 9, gen_loss = 0.8054821904993406, disc_loss = 0.08900641705704866
Trained batch 685 in epoch 9, gen_loss = 0.8059513260862917, disc_loss = 0.08915530095479665
Trained batch 686 in epoch 9, gen_loss = 0.8056785469058646, disc_loss = 0.08923636962764041
Trained batch 687 in epoch 9, gen_loss = 0.806020250024144, disc_loss = 0.08920340109237491
Trained batch 688 in epoch 9, gen_loss = 0.8059035040903161, disc_loss = 0.08916546265136434
Trained batch 689 in epoch 9, gen_loss = 0.8059590523225674, disc_loss = 0.0890923779754751
Trained batch 690 in epoch 9, gen_loss = 0.8057012166800961, disc_loss = 0.08905452734881045
Trained batch 691 in epoch 9, gen_loss = 0.8058315024985744, disc_loss = 0.08909489657202294
Trained batch 692 in epoch 9, gen_loss = 0.8056563270126414, disc_loss = 0.0891408036458931
Trained batch 693 in epoch 9, gen_loss = 0.8052410429681756, disc_loss = 0.08924295902735305
Trained batch 694 in epoch 9, gen_loss = 0.8056576453953338, disc_loss = 0.08952644151374162
Trained batch 695 in epoch 9, gen_loss = 0.8055706809906439, disc_loss = 0.0895058071032038
Trained batch 696 in epoch 9, gen_loss = 0.8054579109423814, disc_loss = 0.08943400765840001
Trained batch 697 in epoch 9, gen_loss = 0.8054121934667358, disc_loss = 0.08941612886611831
Trained batch 698 in epoch 9, gen_loss = 0.8054543902860349, disc_loss = 0.08940365985941905
Trained batch 699 in epoch 9, gen_loss = 0.805193769122873, disc_loss = 0.08946463500548686
Trained batch 700 in epoch 9, gen_loss = 0.805128247651156, disc_loss = 0.08950856028021062
Trained batch 701 in epoch 9, gen_loss = 0.8046928921401331, disc_loss = 0.08964529832787918
Trained batch 702 in epoch 9, gen_loss = 0.8049344117322653, disc_loss = 0.08967441267163027
Trained batch 703 in epoch 9, gen_loss = 0.804882660465823, disc_loss = 0.08962224423091604
Trained batch 704 in epoch 9, gen_loss = 0.8050095875635215, disc_loss = 0.08959085194407203
Trained batch 705 in epoch 9, gen_loss = 0.8050025900345686, disc_loss = 0.08954658695145724
Trained batch 706 in epoch 9, gen_loss = 0.8044879223619189, disc_loss = 0.08968119262394929
Trained batch 707 in epoch 9, gen_loss = 0.8048199753219125, disc_loss = 0.08964211269318637
Trained batch 708 in epoch 9, gen_loss = 0.8050781180307122, disc_loss = 0.08957726937917039
Trained batch 709 in epoch 9, gen_loss = 0.8048826271799249, disc_loss = 0.08955669164605123
Trained batch 710 in epoch 9, gen_loss = 0.8050626213289012, disc_loss = 0.08952280222772295
Trained batch 711 in epoch 9, gen_loss = 0.8049295542531469, disc_loss = 0.08949738069897874
Trained batch 712 in epoch 9, gen_loss = 0.8046876257716523, disc_loss = 0.08954834633704072
Trained batch 713 in epoch 9, gen_loss = 0.8050192366210687, disc_loss = 0.08974628153332725
Trained batch 714 in epoch 9, gen_loss = 0.8052620728949567, disc_loss = 0.08964069304219284
Trained batch 715 in epoch 9, gen_loss = 0.8048700030539289, disc_loss = 0.08974193560880447
Trained batch 716 in epoch 9, gen_loss = 0.8048856041837105, disc_loss = 0.08969079986645878
Trained batch 717 in epoch 9, gen_loss = 0.8048239376468579, disc_loss = 0.08970043055770249
Trained batch 718 in epoch 9, gen_loss = 0.8049020298415994, disc_loss = 0.08960511569990692
Trained batch 719 in epoch 9, gen_loss = 0.8053667444735766, disc_loss = 0.08954006312803055
Trained batch 720 in epoch 9, gen_loss = 0.8049815549681818, disc_loss = 0.08966400551166638
Trained batch 721 in epoch 9, gen_loss = 0.8049345857301247, disc_loss = 0.0895994527515674
Trained batch 722 in epoch 9, gen_loss = 0.8052010185408559, disc_loss = 0.08956145463616975
Trained batch 723 in epoch 9, gen_loss = 0.8053461763163956, disc_loss = 0.08947235299917504
Trained batch 724 in epoch 9, gen_loss = 0.8054616427010504, disc_loss = 0.08939700337704913
Trained batch 725 in epoch 9, gen_loss = 0.805311731850477, disc_loss = 0.08937081208544945
Trained batch 726 in epoch 9, gen_loss = 0.8053091456588394, disc_loss = 0.08929955951505669
Trained batch 727 in epoch 9, gen_loss = 0.8058614104085571, disc_loss = 0.08941439396297497
Trained batch 728 in epoch 9, gen_loss = 0.8060560467230112, disc_loss = 0.08937727330209091
Trained batch 729 in epoch 9, gen_loss = 0.8058369952113661, disc_loss = 0.08936916034898325
Trained batch 730 in epoch 9, gen_loss = 0.8055691518878154, disc_loss = 0.08942928435675872
Trained batch 731 in epoch 9, gen_loss = 0.8061360497373701, disc_loss = 0.08940714826079625
Trained batch 732 in epoch 9, gen_loss = 0.806612225094401, disc_loss = 0.08937819810688373
Trained batch 733 in epoch 9, gen_loss = 0.8065306387171758, disc_loss = 0.08939202241878703
Trained batch 734 in epoch 9, gen_loss = 0.8061354676476952, disc_loss = 0.08957846949675254
Trained batch 735 in epoch 9, gen_loss = 0.8060338779393098, disc_loss = 0.08958199476878888
Trained batch 736 in epoch 9, gen_loss = 0.8064347670958194, disc_loss = 0.08984723588479544
Trained batch 737 in epoch 9, gen_loss = 0.8063063663922674, disc_loss = 0.08980207954253244
Trained batch 738 in epoch 9, gen_loss = 0.8060198483915548, disc_loss = 0.09001059367804107
Trained batch 739 in epoch 9, gen_loss = 0.8063139664562973, disc_loss = 0.09000368336140102
Trained batch 740 in epoch 9, gen_loss = 0.8067778585812985, disc_loss = 0.09017893020817747
Trained batch 741 in epoch 9, gen_loss = 0.8065923060769984, disc_loss = 0.09017381028239578
Trained batch 742 in epoch 9, gen_loss = 0.8065720601245501, disc_loss = 0.09007732774861768
Trained batch 743 in epoch 9, gen_loss = 0.8064469206797821, disc_loss = 0.09006552132953119
Trained batch 744 in epoch 9, gen_loss = 0.8063934486584375, disc_loss = 0.09004448013342667
Trained batch 745 in epoch 9, gen_loss = 0.8062050816760306, disc_loss = 0.09013965651118284
Trained batch 746 in epoch 9, gen_loss = 0.8059526853053924, disc_loss = 0.09014508773608898
Trained batch 747 in epoch 9, gen_loss = 0.8062377805139291, disc_loss = 0.0902086760422942
Trained batch 748 in epoch 9, gen_loss = 0.8059352000103455, disc_loss = 0.09025456535646093
Trained batch 749 in epoch 9, gen_loss = 0.8058788748979568, disc_loss = 0.09028247717147073
Trained batch 750 in epoch 9, gen_loss = 0.8055196159609783, disc_loss = 0.09030318181941933
Trained batch 751 in epoch 9, gen_loss = 0.805494928336207, disc_loss = 0.09028238167198613
Trained batch 752 in epoch 9, gen_loss = 0.8056761542085316, disc_loss = 0.09019420216921198
Trained batch 753 in epoch 9, gen_loss = 0.8056985163166921, disc_loss = 0.09015265375558554
Trained batch 754 in epoch 9, gen_loss = 0.8058974508812885, disc_loss = 0.09010928325626431
Trained batch 755 in epoch 9, gen_loss = 0.8059629619358077, disc_loss = 0.09001814726143878
Trained batch 756 in epoch 9, gen_loss = 0.8057908045332215, disc_loss = 0.08997274730895871
Trained batch 757 in epoch 9, gen_loss = 0.805988473006792, disc_loss = 0.08987632022413737
Trained batch 758 in epoch 9, gen_loss = 0.8058788195664703, disc_loss = 0.08981815878331308
Trained batch 759 in epoch 9, gen_loss = 0.805897259359297, disc_loss = 0.08973237187969253
Trained batch 760 in epoch 9, gen_loss = 0.8063112263532255, disc_loss = 0.08965399756210118
Trained batch 761 in epoch 9, gen_loss = 0.8063157635332718, disc_loss = 0.08959442002239229
Trained batch 762 in epoch 9, gen_loss = 0.806456314119099, disc_loss = 0.08960353114018473
Trained batch 763 in epoch 9, gen_loss = 0.8062435864856106, disc_loss = 0.08964929728359179
Trained batch 764 in epoch 9, gen_loss = 0.8066170917227378, disc_loss = 0.08964741115695705
Trained batch 765 in epoch 9, gen_loss = 0.8066807450342427, disc_loss = 0.08954937929438316
Trained batch 766 in epoch 9, gen_loss = 0.806724559724564, disc_loss = 0.08945670034469262
Trained batch 767 in epoch 9, gen_loss = 0.8064987867837772, disc_loss = 0.08942154948939181
Trained batch 768 in epoch 9, gen_loss = 0.8061839671919343, disc_loss = 0.08947906807617263
Trained batch 769 in epoch 9, gen_loss = 0.8064324229181586, disc_loss = 0.08947474793712427
Trained batch 770 in epoch 9, gen_loss = 0.8068717325785126, disc_loss = 0.08940172823322345
Trained batch 771 in epoch 9, gen_loss = 0.8068272015514152, disc_loss = 0.08934250579895983
Trained batch 772 in epoch 9, gen_loss = 0.8063384990411465, disc_loss = 0.08943219054707195
Trained batch 773 in epoch 9, gen_loss = 0.8066701512081063, disc_loss = 0.08943845623098218
Trained batch 774 in epoch 9, gen_loss = 0.8068167816823528, disc_loss = 0.08937157292279505
Trained batch 775 in epoch 9, gen_loss = 0.8067226152982294, disc_loss = 0.08935843293612689
Trained batch 776 in epoch 9, gen_loss = 0.8065522515252137, disc_loss = 0.08940539343889078
Trained batch 777 in epoch 9, gen_loss = 0.8065460735314303, disc_loss = 0.08936193305520211
Trained batch 778 in epoch 9, gen_loss = 0.8066530590721517, disc_loss = 0.0893136294384096
Trained batch 779 in epoch 9, gen_loss = 0.8068251465757688, disc_loss = 0.08926256386181101
Trained batch 780 in epoch 9, gen_loss = 0.8065387425364666, disc_loss = 0.08925389827833667
Trained batch 781 in epoch 9, gen_loss = 0.8067337637743377, disc_loss = 0.08924133785288124
Trained batch 782 in epoch 9, gen_loss = 0.806745029081939, disc_loss = 0.08915823973515481
Trained batch 783 in epoch 9, gen_loss = 0.8066384613285867, disc_loss = 0.08908637345065268
Trained batch 784 in epoch 9, gen_loss = 0.8063511684821669, disc_loss = 0.08916958566683872
Trained batch 785 in epoch 9, gen_loss = 0.8067150980840809, disc_loss = 0.08920852201054721
Trained batch 786 in epoch 9, gen_loss = 0.8070374012675037, disc_loss = 0.08913009862499513
Trained batch 787 in epoch 9, gen_loss = 0.8068232593424429, disc_loss = 0.08917556982723816
Trained batch 788 in epoch 9, gen_loss = 0.8067534410681562, disc_loss = 0.0890945870788114
Trained batch 789 in epoch 9, gen_loss = 0.8068484444784213, disc_loss = 0.08905430190218024
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.9872052669525146, disc_loss = 0.03414338082075119
Trained batch 1 in epoch 10, gen_loss = 0.8699320554733276, disc_loss = 0.040185507386922836
Trained batch 2 in epoch 10, gen_loss = 0.9892530043919882, disc_loss = 0.07863779614369075
Trained batch 3 in epoch 10, gen_loss = 0.9499115645885468, disc_loss = 0.06356808263808489
Trained batch 4 in epoch 10, gen_loss = 0.9070341110229492, disc_loss = 0.05897243991494179
Trained batch 5 in epoch 10, gen_loss = 0.8463083306948344, disc_loss = 0.08120535872876644
Trained batch 6 in epoch 10, gen_loss = 0.839013227394649, disc_loss = 0.08958567519273077
Trained batch 7 in epoch 10, gen_loss = 0.8695901557803154, disc_loss = 0.0918790684081614
Trained batch 8 in epoch 10, gen_loss = 0.8764806191126505, disc_loss = 0.0831405074439115
Trained batch 9 in epoch 10, gen_loss = 0.8638459146022797, disc_loss = 0.07780520552769303
Trained batch 10 in epoch 10, gen_loss = 0.8379051739519293, disc_loss = 0.08159750437533314
Trained batch 11 in epoch 10, gen_loss = 0.8472926119963328, disc_loss = 0.0764042785546432
Trained batch 12 in epoch 10, gen_loss = 0.8652494870699369, disc_loss = 0.08142817715326181
Trained batch 13 in epoch 10, gen_loss = 0.8691018564360482, disc_loss = 0.08341292671060987
Trained batch 14 in epoch 10, gen_loss = 0.8545393546422323, disc_loss = 0.08597797409941753
Trained batch 15 in epoch 10, gen_loss = 0.8390329107642174, disc_loss = 0.0866788393468596
Trained batch 16 in epoch 10, gen_loss = 0.8664469999425551, disc_loss = 0.0909733746529502
Trained batch 17 in epoch 10, gen_loss = 0.8603768514262305, disc_loss = 0.08825239771977067
Trained batch 18 in epoch 10, gen_loss = 0.8496226762470446, disc_loss = 0.09261291890748237
Trained batch 19 in epoch 10, gen_loss = 0.8458833575248719, disc_loss = 0.09773767874576152
Trained batch 20 in epoch 10, gen_loss = 0.8403560434068952, disc_loss = 0.0950949497609621
Trained batch 21 in epoch 10, gen_loss = 0.8451541716402228, disc_loss = 0.09217407338490541
Trained batch 22 in epoch 10, gen_loss = 0.8356721634450166, disc_loss = 0.09389093506109455
Trained batch 23 in epoch 10, gen_loss = 0.8277594372630119, disc_loss = 0.09298586926888674
Trained batch 24 in epoch 10, gen_loss = 0.8321468710899353, disc_loss = 0.09300108660012484
Trained batch 25 in epoch 10, gen_loss = 0.8343575161236984, disc_loss = 0.09060708157574901
Trained batch 26 in epoch 10, gen_loss = 0.8357559597050702, disc_loss = 0.08766234807532143
Trained batch 27 in epoch 10, gen_loss = 0.8305380152804511, disc_loss = 0.08698907125342105
Trained batch 28 in epoch 10, gen_loss = 0.8274085377824718, disc_loss = 0.08496401783335826
Trained batch 29 in epoch 10, gen_loss = 0.820670356353124, disc_loss = 0.0842438694400092
Trained batch 30 in epoch 10, gen_loss = 0.8253281481804386, disc_loss = 0.08235327547956858
Trained batch 31 in epoch 10, gen_loss = 0.8267870023846626, disc_loss = 0.08027175950701348
Trained batch 32 in epoch 10, gen_loss = 0.8282951694546323, disc_loss = 0.07840831732998292
Trained batch 33 in epoch 10, gen_loss = 0.8250037887517143, disc_loss = 0.0773590714122881
Trained batch 34 in epoch 10, gen_loss = 0.8256134186472212, disc_loss = 0.07578137849590608
Trained batch 35 in epoch 10, gen_loss = 0.8271816753678851, disc_loss = 0.07488588132481608
Trained batch 36 in epoch 10, gen_loss = 0.829416937119252, disc_loss = 0.07418016739491676
Trained batch 37 in epoch 10, gen_loss = 0.8342620620602056, disc_loss = 0.07307071103959491
Trained batch 38 in epoch 10, gen_loss = 0.8283730653616098, disc_loss = 0.07283783973887181
Trained batch 39 in epoch 10, gen_loss = 0.8281277716159821, disc_loss = 0.07210343882907182
Trained batch 40 in epoch 10, gen_loss = 0.8242617758308969, disc_loss = 0.07256471304359233
Trained batch 41 in epoch 10, gen_loss = 0.8452713092168173, disc_loss = 0.07628702046349645
Trained batch 42 in epoch 10, gen_loss = 0.8421486699303915, disc_loss = 0.07620618035367062
Trained batch 43 in epoch 10, gen_loss = 0.8369505297053944, disc_loss = 0.07668885396031494
Trained batch 44 in epoch 10, gen_loss = 0.8430418305926852, disc_loss = 0.07621494277069966
Trained batch 45 in epoch 10, gen_loss = 0.8450896299403646, disc_loss = 0.07600159953226862
Trained batch 46 in epoch 10, gen_loss = 0.841375856957537, disc_loss = 0.07695464181535422
Trained batch 47 in epoch 10, gen_loss = 0.8413865069548289, disc_loss = 0.07597178529249504
Trained batch 48 in epoch 10, gen_loss = 0.8419791508694084, disc_loss = 0.07569749012817534
Trained batch 49 in epoch 10, gen_loss = 0.8435844492912292, disc_loss = 0.07441048357635736
Trained batch 50 in epoch 10, gen_loss = 0.8362369893812666, disc_loss = 0.07560176625117368
Trained batch 51 in epoch 10, gen_loss = 0.8364521133211943, disc_loss = 0.07611346047801468
Trained batch 52 in epoch 10, gen_loss = 0.83487187860147, disc_loss = 0.07596734057198155
Trained batch 53 in epoch 10, gen_loss = 0.8329118782723391, disc_loss = 0.07579530613427912
Trained batch 54 in epoch 10, gen_loss = 0.8319323230873454, disc_loss = 0.07522974830459464
Trained batch 55 in epoch 10, gen_loss = 0.8367814075733934, disc_loss = 0.08044896171694356
Trained batch 56 in epoch 10, gen_loss = 0.8331751023468218, disc_loss = 0.08183171067452222
Trained batch 57 in epoch 10, gen_loss = 0.8358451605870806, disc_loss = 0.08175974483762322
Trained batch 58 in epoch 10, gen_loss = 0.832841451390315, disc_loss = 0.08285400160919812
Trained batch 59 in epoch 10, gen_loss = 0.8306377197305361, disc_loss = 0.08322288310155272
Trained batch 60 in epoch 10, gen_loss = 0.831003437765309, disc_loss = 0.08275069971187193
Trained batch 61 in epoch 10, gen_loss = 0.8288796702700276, disc_loss = 0.082247456265313
Trained batch 62 in epoch 10, gen_loss = 0.8296376953995417, disc_loss = 0.08249131533952933
Trained batch 63 in epoch 10, gen_loss = 0.8310017981566489, disc_loss = 0.08172131262836047
Trained batch 64 in epoch 10, gen_loss = 0.8315615511857546, disc_loss = 0.08086266652322732
Trained batch 65 in epoch 10, gen_loss = 0.8309847807342355, disc_loss = 0.08071036396943258
Trained batch 66 in epoch 10, gen_loss = 0.8269465063045274, disc_loss = 0.08150948859306413
Trained batch 67 in epoch 10, gen_loss = 0.8278380417648483, disc_loss = 0.08140526040840675
Trained batch 68 in epoch 10, gen_loss = 0.8274144646914109, disc_loss = 0.08150461950487849
Trained batch 69 in epoch 10, gen_loss = 0.8284088343381881, disc_loss = 0.08061378286885364
Trained batch 70 in epoch 10, gen_loss = 0.8260565320370903, disc_loss = 0.08070550499562647
Trained batch 71 in epoch 10, gen_loss = 0.8248667216135396, disc_loss = 0.0808700120024797
Trained batch 72 in epoch 10, gen_loss = 0.8247407670706919, disc_loss = 0.08042769315206025
Trained batch 73 in epoch 10, gen_loss = 0.8237743309220752, disc_loss = 0.08001746713007624
Trained batch 74 in epoch 10, gen_loss = 0.8247697055339813, disc_loss = 0.07915745907773575
Trained batch 75 in epoch 10, gen_loss = 0.8274774884707049, disc_loss = 0.07825057545529776
Trained batch 76 in epoch 10, gen_loss = 0.8291307552294298, disc_loss = 0.07739097040823915
Trained batch 77 in epoch 10, gen_loss = 0.8296319937858826, disc_loss = 0.07660392558393188
Trained batch 78 in epoch 10, gen_loss = 0.8311746177039568, disc_loss = 0.0758909820402159
Trained batch 79 in epoch 10, gen_loss = 0.8305251020938158, disc_loss = 0.07525150704896078
Trained batch 80 in epoch 10, gen_loss = 0.8290763692355451, disc_loss = 0.07514313234729164
Trained batch 81 in epoch 10, gen_loss = 0.8279093042379473, disc_loss = 0.07506625593935208
Trained batch 82 in epoch 10, gen_loss = 0.8288913667201996, disc_loss = 0.07472112953258925
Trained batch 83 in epoch 10, gen_loss = 0.8281448636026609, disc_loss = 0.07419421990579438
Trained batch 84 in epoch 10, gen_loss = 0.8256500394905315, disc_loss = 0.07464317912783693
Trained batch 85 in epoch 10, gen_loss = 0.8269597870665927, disc_loss = 0.07519881883202943
Trained batch 86 in epoch 10, gen_loss = 0.8276041448116302, disc_loss = 0.07513657996923416
Trained batch 87 in epoch 10, gen_loss = 0.8257608044553887, disc_loss = 0.07484327621800317
Trained batch 88 in epoch 10, gen_loss = 0.8241166114137414, disc_loss = 0.07526318470455623
Trained batch 89 in epoch 10, gen_loss = 0.8275502969821295, disc_loss = 0.07496551445995768
Trained batch 90 in epoch 10, gen_loss = 0.8274037893656846, disc_loss = 0.07442579912738158
Trained batch 91 in epoch 10, gen_loss = 0.8269001954923505, disc_loss = 0.07381447269986181
Trained batch 92 in epoch 10, gen_loss = 0.8237077302189284, disc_loss = 0.07474283228117612
Trained batch 93 in epoch 10, gen_loss = 0.824994074220353, disc_loss = 0.07418647435236167
Trained batch 94 in epoch 10, gen_loss = 0.8251371361707386, disc_loss = 0.07429992379130501
Trained batch 95 in epoch 10, gen_loss = 0.8280460378155112, disc_loss = 0.07415982214539933
Trained batch 96 in epoch 10, gen_loss = 0.8263485655956662, disc_loss = 0.0746341482400126
Trained batch 97 in epoch 10, gen_loss = 0.8262368370683826, disc_loss = 0.07506007437917347
Trained batch 98 in epoch 10, gen_loss = 0.8269573410954139, disc_loss = 0.07471225334500725
Trained batch 99 in epoch 10, gen_loss = 0.8268935212492943, disc_loss = 0.0744809931050986
Trained batch 100 in epoch 10, gen_loss = 0.8256502561640031, disc_loss = 0.07505247464385068
Trained batch 101 in epoch 10, gen_loss = 0.8269708410781973, disc_loss = 0.07564424105244232
Trained batch 102 in epoch 10, gen_loss = 0.8244552933475346, disc_loss = 0.07626113102961223
Trained batch 103 in epoch 10, gen_loss = 0.823857053827781, disc_loss = 0.07617280742404266
Trained batch 104 in epoch 10, gen_loss = 0.8255472838878631, disc_loss = 0.07658424543305523
Trained batch 105 in epoch 10, gen_loss = 0.8227731526460288, disc_loss = 0.07724021497305553
Trained batch 106 in epoch 10, gen_loss = 0.8246388321167955, disc_loss = 0.07693555034592608
Trained batch 107 in epoch 10, gen_loss = 0.8249369923163343, disc_loss = 0.07685740791364676
Trained batch 108 in epoch 10, gen_loss = 0.8232711162589011, disc_loss = 0.07674602127779241
Trained batch 109 in epoch 10, gen_loss = 0.8225742169401863, disc_loss = 0.07656257182190364
Trained batch 110 in epoch 10, gen_loss = 0.8235076303417618, disc_loss = 0.07603164759741442
Trained batch 111 in epoch 10, gen_loss = 0.823833870834538, disc_loss = 0.07582594072612535
Trained batch 112 in epoch 10, gen_loss = 0.8231756652878449, disc_loss = 0.07624697794857542
Trained batch 113 in epoch 10, gen_loss = 0.8240944332720941, disc_loss = 0.07573283662235267
Trained batch 114 in epoch 10, gen_loss = 0.8224018317201863, disc_loss = 0.076107260155613
Trained batch 115 in epoch 10, gen_loss = 0.8217461132283869, disc_loss = 0.07634914533941653
Trained batch 116 in epoch 10, gen_loss = 0.82305999724274, disc_loss = 0.07608122756688768
Trained batch 117 in epoch 10, gen_loss = 0.8235822857941612, disc_loss = 0.07616914413332687
Trained batch 118 in epoch 10, gen_loss = 0.8218980569298527, disc_loss = 0.07681863306544158
Trained batch 119 in epoch 10, gen_loss = 0.8213530364135901, disc_loss = 0.07662589819325755
Trained batch 120 in epoch 10, gen_loss = 0.8219750210765965, disc_loss = 0.0769631357955908
Trained batch 121 in epoch 10, gen_loss = 0.8241305036134408, disc_loss = 0.0772275846741605
Trained batch 122 in epoch 10, gen_loss = 0.8220626384746738, disc_loss = 0.07830858475157643
Trained batch 123 in epoch 10, gen_loss = 0.8255250230431557, disc_loss = 0.07879158844720692
Trained batch 124 in epoch 10, gen_loss = 0.8261808650493622, disc_loss = 0.07831584989279508
Trained batch 125 in epoch 10, gen_loss = 0.8267758694433031, disc_loss = 0.07826031885656809
Trained batch 126 in epoch 10, gen_loss = 0.824635535009264, disc_loss = 0.07894918791157758
Trained batch 127 in epoch 10, gen_loss = 0.8247980021405965, disc_loss = 0.07863798972539371
Trained batch 128 in epoch 10, gen_loss = 0.8241506101087083, disc_loss = 0.07824106317360041
Trained batch 129 in epoch 10, gen_loss = 0.8243928851989599, disc_loss = 0.07807298940964616
Trained batch 130 in epoch 10, gen_loss = 0.8229517811582289, disc_loss = 0.07820276093477284
Trained batch 131 in epoch 10, gen_loss = 0.8226293576034632, disc_loss = 0.07816759448244491
Trained batch 132 in epoch 10, gen_loss = 0.8224277480652458, disc_loss = 0.07777381170877165
Trained batch 133 in epoch 10, gen_loss = 0.8235319890637895, disc_loss = 0.07734382506320948
Trained batch 134 in epoch 10, gen_loss = 0.8229990992281172, disc_loss = 0.07713591343964692
Trained batch 135 in epoch 10, gen_loss = 0.8224257035728764, disc_loss = 0.07694742747116834
Trained batch 136 in epoch 10, gen_loss = 0.8233766196853053, disc_loss = 0.0768189864015601
Trained batch 137 in epoch 10, gen_loss = 0.8219585658415504, disc_loss = 0.07654211176829277
Trained batch 138 in epoch 10, gen_loss = 0.8215887012670366, disc_loss = 0.07630571576250757
Trained batch 139 in epoch 10, gen_loss = 0.8203176113111632, disc_loss = 0.07616834838076361
Trained batch 140 in epoch 10, gen_loss = 0.8199022676505096, disc_loss = 0.07647293267758391
Trained batch 141 in epoch 10, gen_loss = 0.8189737714931998, disc_loss = 0.07691724063881056
Trained batch 142 in epoch 10, gen_loss = 0.818127964968448, disc_loss = 0.07674359757505306
Trained batch 143 in epoch 10, gen_loss = 0.8179812325785557, disc_loss = 0.07678544069252287
Trained batch 144 in epoch 10, gen_loss = 0.8174019445633066, disc_loss = 0.07664232624630476
Trained batch 145 in epoch 10, gen_loss = 0.818564797305081, disc_loss = 0.07702646160192073
Trained batch 146 in epoch 10, gen_loss = 0.8200075336459542, disc_loss = 0.07680664120913566
Trained batch 147 in epoch 10, gen_loss = 0.8194640393595438, disc_loss = 0.07667155685280827
Trained batch 148 in epoch 10, gen_loss = 0.8181425579042243, disc_loss = 0.07719365783010754
Trained batch 149 in epoch 10, gen_loss = 0.8213689428567886, disc_loss = 0.0777939424974223
Trained batch 150 in epoch 10, gen_loss = 0.8222046922768979, disc_loss = 0.07743199732746707
Trained batch 151 in epoch 10, gen_loss = 0.8212744795570248, disc_loss = 0.07752996031807638
Trained batch 152 in epoch 10, gen_loss = 0.8197165359469021, disc_loss = 0.07765954051751132
Trained batch 153 in epoch 10, gen_loss = 0.8228729984589985, disc_loss = 0.07894468714495177
Trained batch 154 in epoch 10, gen_loss = 0.8235063281751448, disc_loss = 0.07854288401262415
Trained batch 155 in epoch 10, gen_loss = 0.8209608199122624, disc_loss = 0.07994535477617039
Trained batch 156 in epoch 10, gen_loss = 0.8219104179531146, disc_loss = 0.0806870376809862
Trained batch 157 in epoch 10, gen_loss = 0.8205956384728227, disc_loss = 0.08090222922236293
Trained batch 158 in epoch 10, gen_loss = 0.8195986520944152, disc_loss = 0.08093503181406725
Trained batch 159 in epoch 10, gen_loss = 0.8197266573086381, disc_loss = 0.08103137335856445
Trained batch 160 in epoch 10, gen_loss = 0.8188499725013045, disc_loss = 0.08118887743710176
Trained batch 161 in epoch 10, gen_loss = 0.8188401193898401, disc_loss = 0.08097321014092476
Trained batch 162 in epoch 10, gen_loss = 0.8188084830170029, disc_loss = 0.08068273180490074
Trained batch 163 in epoch 10, gen_loss = 0.8181615491829267, disc_loss = 0.08064951452926346
Trained batch 164 in epoch 10, gen_loss = 0.8171548436988484, disc_loss = 0.08051861378392487
Trained batch 165 in epoch 10, gen_loss = 0.8166078420647656, disc_loss = 0.08033041398501001
Trained batch 166 in epoch 10, gen_loss = 0.8166903287707689, disc_loss = 0.08044954334123584
Trained batch 167 in epoch 10, gen_loss = 0.8151317822436491, disc_loss = 0.08082376866756628
Trained batch 168 in epoch 10, gen_loss = 0.8137736498604159, disc_loss = 0.08099717786260081
Trained batch 169 in epoch 10, gen_loss = 0.8156853123622783, disc_loss = 0.08163525499951313
Trained batch 170 in epoch 10, gen_loss = 0.814728815130323, disc_loss = 0.08181535860534474
Trained batch 171 in epoch 10, gen_loss = 0.8128746808614842, disc_loss = 0.08232821977350774
Trained batch 172 in epoch 10, gen_loss = 0.8137516536120045, disc_loss = 0.08249990687829394
Trained batch 173 in epoch 10, gen_loss = 0.8135981725892801, disc_loss = 0.08260892574065204
Trained batch 174 in epoch 10, gen_loss = 0.8137673073155539, disc_loss = 0.08254037446741547
Trained batch 175 in epoch 10, gen_loss = 0.8122675169936635, disc_loss = 0.08304663576630199
Trained batch 176 in epoch 10, gen_loss = 0.8131832344047094, disc_loss = 0.08296310685385587
Trained batch 177 in epoch 10, gen_loss = 0.8125243687562729, disc_loss = 0.08285024371312073
Trained batch 178 in epoch 10, gen_loss = 0.8123412490224039, disc_loss = 0.08317465158751723
Trained batch 179 in epoch 10, gen_loss = 0.8115990769531992, disc_loss = 0.08322200893631412
Trained batch 180 in epoch 10, gen_loss = 0.8122451682446411, disc_loss = 0.08283747170758511
Trained batch 181 in epoch 10, gen_loss = 0.8122929932324441, disc_loss = 0.08275472522191293
Trained batch 182 in epoch 10, gen_loss = 0.8132044664823292, disc_loss = 0.08240717977203958
Trained batch 183 in epoch 10, gen_loss = 0.8125744726022949, disc_loss = 0.08243118366226554
Trained batch 184 in epoch 10, gen_loss = 0.8130549519448667, disc_loss = 0.08214401378220804
Trained batch 185 in epoch 10, gen_loss = 0.814604548837549, disc_loss = 0.08192925951293399
Trained batch 186 in epoch 10, gen_loss = 0.8145534085398689, disc_loss = 0.0816961878183532
Trained batch 187 in epoch 10, gen_loss = 0.8156555572405775, disc_loss = 0.0817196143969418
Trained batch 188 in epoch 10, gen_loss = 0.8147508125141184, disc_loss = 0.08166032815697016
Trained batch 189 in epoch 10, gen_loss = 0.8137714356184006, disc_loss = 0.0814418294221947
Trained batch 190 in epoch 10, gen_loss = 0.813678962553983, disc_loss = 0.0815407479211142
Trained batch 191 in epoch 10, gen_loss = 0.8152039499642948, disc_loss = 0.08130893899942748
Trained batch 192 in epoch 10, gen_loss = 0.814187602212392, disc_loss = 0.08159476531177295
Trained batch 193 in epoch 10, gen_loss = 0.8143647041210195, disc_loss = 0.08154937122785247
Trained batch 194 in epoch 10, gen_loss = 0.8158747200782482, disc_loss = 0.08191931604001766
Trained batch 195 in epoch 10, gen_loss = 0.8152561082827802, disc_loss = 0.08165599608185645
Trained batch 196 in epoch 10, gen_loss = 0.8150636658148112, disc_loss = 0.08146224875324572
Trained batch 197 in epoch 10, gen_loss = 0.8137299690884773, disc_loss = 0.08175336356001972
Trained batch 198 in epoch 10, gen_loss = 0.8161331422664412, disc_loss = 0.08248230939422121
Trained batch 199 in epoch 10, gen_loss = 0.8159747345745564, disc_loss = 0.08227289169095457
Trained batch 200 in epoch 10, gen_loss = 0.8153268823872751, disc_loss = 0.08217874105408121
Trained batch 201 in epoch 10, gen_loss = 0.8146010376144164, disc_loss = 0.0822167168140854
Trained batch 202 in epoch 10, gen_loss = 0.813244823604969, disc_loss = 0.08244939907247503
Trained batch 203 in epoch 10, gen_loss = 0.8148113861680031, disc_loss = 0.08350446019504293
Trained batch 204 in epoch 10, gen_loss = 0.8138542266880594, disc_loss = 0.0837216344821017
Trained batch 205 in epoch 10, gen_loss = 0.8132685433024341, disc_loss = 0.08363271847331119
Trained batch 206 in epoch 10, gen_loss = 0.8128649553527003, disc_loss = 0.08337374577739677
Trained batch 207 in epoch 10, gen_loss = 0.8147341275157837, disc_loss = 0.08345865611380969
Trained batch 208 in epoch 10, gen_loss = 0.8147814520523309, disc_loss = 0.08320247855162222
Trained batch 209 in epoch 10, gen_loss = 0.8140910660936719, disc_loss = 0.08340468533514511
Trained batch 210 in epoch 10, gen_loss = 0.8139239734665478, disc_loss = 0.08332580662557582
Trained batch 211 in epoch 10, gen_loss = 0.8164825376193479, disc_loss = 0.08340278646539685
Trained batch 212 in epoch 10, gen_loss = 0.8166798027188565, disc_loss = 0.08309956450242671
Trained batch 213 in epoch 10, gen_loss = 0.8161021257950881, disc_loss = 0.08309600107963676
Trained batch 214 in epoch 10, gen_loss = 0.8159160285495048, disc_loss = 0.08293179241550523
Trained batch 215 in epoch 10, gen_loss = 0.8171593054301209, disc_loss = 0.08278638171894406
Trained batch 216 in epoch 10, gen_loss = 0.8169354135814351, disc_loss = 0.08302288340224374
Trained batch 217 in epoch 10, gen_loss = 0.8171410280356713, disc_loss = 0.0829724992685225
Trained batch 218 in epoch 10, gen_loss = 0.8181742978150441, disc_loss = 0.08275417115148072
Trained batch 219 in epoch 10, gen_loss = 0.8194109010425481, disc_loss = 0.08253555650907483
Trained batch 220 in epoch 10, gen_loss = 0.819573943566413, disc_loss = 0.08228429915105326
Trained batch 221 in epoch 10, gen_loss = 0.8189767433984859, disc_loss = 0.08250655803560943
Trained batch 222 in epoch 10, gen_loss = 0.8209580184365601, disc_loss = 0.0825186809065497
Trained batch 223 in epoch 10, gen_loss = 0.8202842573768326, disc_loss = 0.08247408136958256
Trained batch 224 in epoch 10, gen_loss = 0.8204768579536014, disc_loss = 0.08221665616664621
Trained batch 225 in epoch 10, gen_loss = 0.8219408663236989, disc_loss = 0.08200077617755241
Trained batch 226 in epoch 10, gen_loss = 0.8210861531910917, disc_loss = 0.08201398720989406
Trained batch 227 in epoch 10, gen_loss = 0.8211514940648749, disc_loss = 0.08181798400095942
Trained batch 228 in epoch 10, gen_loss = 0.8220874140096023, disc_loss = 0.08180037014772018
Trained batch 229 in epoch 10, gen_loss = 0.8222783807827079, disc_loss = 0.08153361279679382
Trained batch 230 in epoch 10, gen_loss = 0.8221396836109491, disc_loss = 0.08137978995581727
Trained batch 231 in epoch 10, gen_loss = 0.8220439999011057, disc_loss = 0.08134142404165247
Trained batch 232 in epoch 10, gen_loss = 0.8223355623529705, disc_loss = 0.08113537237943498
Trained batch 233 in epoch 10, gen_loss = 0.8233782398140329, disc_loss = 0.08092444292946249
Trained batch 234 in epoch 10, gen_loss = 0.8239117702271076, disc_loss = 0.08072692731276472
Trained batch 235 in epoch 10, gen_loss = 0.8240891049726534, disc_loss = 0.080659755821324
Trained batch 236 in epoch 10, gen_loss = 0.8232649400012906, disc_loss = 0.08087365805536886
Trained batch 237 in epoch 10, gen_loss = 0.8237165043584439, disc_loss = 0.08105908382777907
Trained batch 238 in epoch 10, gen_loss = 0.824807702871546, disc_loss = 0.08078034085739856
Trained batch 239 in epoch 10, gen_loss = 0.8239796113222837, disc_loss = 0.08076500083164623
Trained batch 240 in epoch 10, gen_loss = 0.8244316826470165, disc_loss = 0.08056776006841314
Trained batch 241 in epoch 10, gen_loss = 0.8244271969253366, disc_loss = 0.08031336134222668
Trained batch 242 in epoch 10, gen_loss = 0.8249255137924304, disc_loss = 0.08003233726531145
Trained batch 243 in epoch 10, gen_loss = 0.8245809514258728, disc_loss = 0.07980937127512498
Trained batch 244 in epoch 10, gen_loss = 0.8262389753546033, disc_loss = 0.07963640016256547
Trained batch 245 in epoch 10, gen_loss = 0.8267665855525955, disc_loss = 0.0794003838673234
Trained batch 246 in epoch 10, gen_loss = 0.826799078629567, disc_loss = 0.07919246379874255
Trained batch 247 in epoch 10, gen_loss = 0.8275271213102725, disc_loss = 0.07893658738072601
Trained batch 248 in epoch 10, gen_loss = 0.8269747860699772, disc_loss = 0.0788842020070098
Trained batch 249 in epoch 10, gen_loss = 0.8278714438676834, disc_loss = 0.07902735047787428
Trained batch 250 in epoch 10, gen_loss = 0.82758081612359, disc_loss = 0.07894576274867789
Trained batch 251 in epoch 10, gen_loss = 0.8273267631256391, disc_loss = 0.07877422142626038
Trained batch 252 in epoch 10, gen_loss = 0.8282447595134554, disc_loss = 0.07872841652232432
Trained batch 253 in epoch 10, gen_loss = 0.827840284217061, disc_loss = 0.07853195130619711
Trained batch 254 in epoch 10, gen_loss = 0.8270106618310891, disc_loss = 0.07855086879549074
Trained batch 255 in epoch 10, gen_loss = 0.8272426921175793, disc_loss = 0.07841778857255122
Trained batch 256 in epoch 10, gen_loss = 0.8273307849229078, disc_loss = 0.07825058764607758
Trained batch 257 in epoch 10, gen_loss = 0.8273939831081287, disc_loss = 0.07807633769517952
Trained batch 258 in epoch 10, gen_loss = 0.8284823893350064, disc_loss = 0.07785046097020615
Trained batch 259 in epoch 10, gen_loss = 0.8280812454911378, disc_loss = 0.0779023564993762
Trained batch 260 in epoch 10, gen_loss = 0.8280649124662538, disc_loss = 0.07774168046698031
Trained batch 261 in epoch 10, gen_loss = 0.8279532313574361, disc_loss = 0.07761416884978081
Trained batch 262 in epoch 10, gen_loss = 0.8285553982275974, disc_loss = 0.07764706496475088
Trained batch 263 in epoch 10, gen_loss = 0.828466702929952, disc_loss = 0.0775147009937262
Trained batch 264 in epoch 10, gen_loss = 0.828948923664273, disc_loss = 0.07727544472535264
Trained batch 265 in epoch 10, gen_loss = 0.8283731028773731, disc_loss = 0.07732363523131139
Trained batch 266 in epoch 10, gen_loss = 0.8278744012005766, disc_loss = 0.07720324463012178
Trained batch 267 in epoch 10, gen_loss = 0.8270121148940343, disc_loss = 0.07716420800564115
Trained batch 268 in epoch 10, gen_loss = 0.8281727948374907, disc_loss = 0.07700344729393056
Trained batch 269 in epoch 10, gen_loss = 0.8297194457716413, disc_loss = 0.07710603682876185
Trained batch 270 in epoch 10, gen_loss = 0.829689413748984, disc_loss = 0.07692981142605693
Trained batch 271 in epoch 10, gen_loss = 0.8296568546005908, disc_loss = 0.07685551805736716
Trained batch 272 in epoch 10, gen_loss = 0.8302461783309559, disc_loss = 0.07661243065877821
Trained batch 273 in epoch 10, gen_loss = 0.8298287871327713, disc_loss = 0.0766067390302944
Trained batch 274 in epoch 10, gen_loss = 0.8301701184836301, disc_loss = 0.07676302510567687
Trained batch 275 in epoch 10, gen_loss = 0.8299899678947269, disc_loss = 0.07663290630823569
Trained batch 276 in epoch 10, gen_loss = 0.8299212118994028, disc_loss = 0.07656654851706127
Trained batch 277 in epoch 10, gen_loss = 0.8310258250227935, disc_loss = 0.07648821897710935
Trained batch 278 in epoch 10, gen_loss = 0.8303881500143304, disc_loss = 0.076832767338976
Trained batch 279 in epoch 10, gen_loss = 0.8293375748608793, disc_loss = 0.07706967511413886
Trained batch 280 in epoch 10, gen_loss = 0.8302459344532991, disc_loss = 0.07688766437851131
Trained batch 281 in epoch 10, gen_loss = 0.8311297843853632, disc_loss = 0.07691047426167849
Trained batch 282 in epoch 10, gen_loss = 0.8307177743515783, disc_loss = 0.07688208594062619
Trained batch 283 in epoch 10, gen_loss = 0.8302654455035505, disc_loss = 0.07687204190477415
Trained batch 284 in epoch 10, gen_loss = 0.8296658489787788, disc_loss = 0.07680447583593297
Trained batch 285 in epoch 10, gen_loss = 0.8291317129676993, disc_loss = 0.07675889867416524
Trained batch 286 in epoch 10, gen_loss = 0.8297220756160257, disc_loss = 0.07662274971124083
Trained batch 287 in epoch 10, gen_loss = 0.8301506641631325, disc_loss = 0.07639311736824715
Trained batch 288 in epoch 10, gen_loss = 0.8295655070085427, disc_loss = 0.07657651620301512
Trained batch 289 in epoch 10, gen_loss = 0.8301411699632119, disc_loss = 0.07647822169458558
Trained batch 290 in epoch 10, gen_loss = 0.8299959024408019, disc_loss = 0.07643409405236494
Trained batch 291 in epoch 10, gen_loss = 0.8301094271344681, disc_loss = 0.07632460092092315
Trained batch 292 in epoch 10, gen_loss = 0.8302092640676596, disc_loss = 0.07617777991887348
Trained batch 293 in epoch 10, gen_loss = 0.8305135404779798, disc_loss = 0.07607119679007501
Trained batch 294 in epoch 10, gen_loss = 0.8308750095003742, disc_loss = 0.07593196277206732
Trained batch 295 in epoch 10, gen_loss = 0.8308164983786441, disc_loss = 0.07581142929219012
Trained batch 296 in epoch 10, gen_loss = 0.8327512162100987, disc_loss = 0.07582146274584411
Trained batch 297 in epoch 10, gen_loss = 0.8322742566366323, disc_loss = 0.07579312872629138
Trained batch 298 in epoch 10, gen_loss = 0.832107952107554, disc_loss = 0.07564973197316745
Trained batch 299 in epoch 10, gen_loss = 0.8317120741804441, disc_loss = 0.07554341448160509
Trained batch 300 in epoch 10, gen_loss = 0.8316079638527081, disc_loss = 0.07561369468318763
Trained batch 301 in epoch 10, gen_loss = 0.8329980984231494, disc_loss = 0.0758542017363604
Trained batch 302 in epoch 10, gen_loss = 0.832595817621785, disc_loss = 0.07619518307483333
Trained batch 303 in epoch 10, gen_loss = 0.8322415125409239, disc_loss = 0.07612405460340117
Trained batch 304 in epoch 10, gen_loss = 0.8325021123299833, disc_loss = 0.07596081612234722
Trained batch 305 in epoch 10, gen_loss = 0.8331640036472308, disc_loss = 0.07669468749667598
Trained batch 306 in epoch 10, gen_loss = 0.832099539934618, disc_loss = 0.07727042597442477
Trained batch 307 in epoch 10, gen_loss = 0.8314245682838676, disc_loss = 0.07738526704624392
Trained batch 308 in epoch 10, gen_loss = 0.8320591734258103, disc_loss = 0.0775042028892725
Trained batch 309 in epoch 10, gen_loss = 0.8323881077189599, disc_loss = 0.07733915433467876
Trained batch 310 in epoch 10, gen_loss = 0.8319781689973507, disc_loss = 0.07730479645947072
Trained batch 311 in epoch 10, gen_loss = 0.8322313067813715, disc_loss = 0.07715851661617844
Trained batch 312 in epoch 10, gen_loss = 0.8310861258080211, disc_loss = 0.0774476555869364
Trained batch 313 in epoch 10, gen_loss = 0.8327193170975727, disc_loss = 0.07768136980367979
Trained batch 314 in epoch 10, gen_loss = 0.8340133536429633, disc_loss = 0.07766321758843131
Trained batch 315 in epoch 10, gen_loss = 0.8336121102299872, disc_loss = 0.07779677604513738
Trained batch 316 in epoch 10, gen_loss = 0.8332335665022913, disc_loss = 0.07799002120112677
Trained batch 317 in epoch 10, gen_loss = 0.8331384214590181, disc_loss = 0.07779814594325686
Trained batch 318 in epoch 10, gen_loss = 0.8329137081636531, disc_loss = 0.07771791649404271
Trained batch 319 in epoch 10, gen_loss = 0.8328311894088983, disc_loss = 0.07759404686221387
Trained batch 320 in epoch 10, gen_loss = 0.8331956276641085, disc_loss = 0.07741831313540166
Trained batch 321 in epoch 10, gen_loss = 0.8335348724948693, disc_loss = 0.07747216750318127
Trained batch 322 in epoch 10, gen_loss = 0.8336002822999984, disc_loss = 0.0772694439739681
Trained batch 323 in epoch 10, gen_loss = 0.8329322205649482, disc_loss = 0.0772112011478317
Trained batch 324 in epoch 10, gen_loss = 0.833282233935136, disc_loss = 0.07706432780680748
Trained batch 325 in epoch 10, gen_loss = 0.8334823998571174, disc_loss = 0.0769363480528668
Trained batch 326 in epoch 10, gen_loss = 0.8336417432589633, disc_loss = 0.07679535997376438
Trained batch 327 in epoch 10, gen_loss = 0.8337785716100437, disc_loss = 0.076678582418869
Trained batch 328 in epoch 10, gen_loss = 0.833548708708453, disc_loss = 0.07658053055620755
Trained batch 329 in epoch 10, gen_loss = 0.8339221753857352, disc_loss = 0.0771001515486701
Trained batch 330 in epoch 10, gen_loss = 0.8331434094653749, disc_loss = 0.07740427341784865
Trained batch 331 in epoch 10, gen_loss = 0.8340085430676678, disc_loss = 0.07752091513598809
Trained batch 332 in epoch 10, gen_loss = 0.8338892452709668, disc_loss = 0.07744232440708547
Trained batch 333 in epoch 10, gen_loss = 0.8332070547663523, disc_loss = 0.07762088741226021
Trained batch 334 in epoch 10, gen_loss = 0.8340008881554675, disc_loss = 0.07768411661651152
Trained batch 335 in epoch 10, gen_loss = 0.8342097014898345, disc_loss = 0.0775042544146778
Trained batch 336 in epoch 10, gen_loss = 0.8338237618834046, disc_loss = 0.07752149475003298
Trained batch 337 in epoch 10, gen_loss = 0.8334498144465791, disc_loss = 0.07759863607993228
Trained batch 338 in epoch 10, gen_loss = 0.8340067135549225, disc_loss = 0.0780922772505686
Trained batch 339 in epoch 10, gen_loss = 0.8340506381848279, disc_loss = 0.0779161469271297
Trained batch 340 in epoch 10, gen_loss = 0.8333182530668823, disc_loss = 0.07791029032909713
Trained batch 341 in epoch 10, gen_loss = 0.833810007363035, disc_loss = 0.07775419967096539
Trained batch 342 in epoch 10, gen_loss = 0.8337220646897141, disc_loss = 0.0776990918095058
Trained batch 343 in epoch 10, gen_loss = 0.8334751054644585, disc_loss = 0.07758117286585878
Trained batch 344 in epoch 10, gen_loss = 0.8327633607214776, disc_loss = 0.07768398306561985
Trained batch 345 in epoch 10, gen_loss = 0.8336367922366699, disc_loss = 0.07829457098575082
Trained batch 346 in epoch 10, gen_loss = 0.8328910164255917, disc_loss = 0.07837312276977026
Trained batch 347 in epoch 10, gen_loss = 0.8322536683288114, disc_loss = 0.07842914414613497
Trained batch 348 in epoch 10, gen_loss = 0.8321232107443932, disc_loss = 0.0785239877414097
Trained batch 349 in epoch 10, gen_loss = 0.831764874288014, disc_loss = 0.07839373288676142
Trained batch 350 in epoch 10, gen_loss = 0.8312753717444221, disc_loss = 0.07848459921851542
Trained batch 351 in epoch 10, gen_loss = 0.8315930650992827, disc_loss = 0.07843933159496043
Trained batch 352 in epoch 10, gen_loss = 0.8314785671977079, disc_loss = 0.07851382053955841
Trained batch 353 in epoch 10, gen_loss = 0.8308865433022127, disc_loss = 0.07857072616711595
Trained batch 354 in epoch 10, gen_loss = 0.8306529644509436, disc_loss = 0.07844819426798905
Trained batch 355 in epoch 10, gen_loss = 0.8307143263937382, disc_loss = 0.07838367453378657
Trained batch 356 in epoch 10, gen_loss = 0.8308981359839773, disc_loss = 0.07833323536143333
Trained batch 357 in epoch 10, gen_loss = 0.8309856067156659, disc_loss = 0.07827911576172909
Trained batch 358 in epoch 10, gen_loss = 0.8298271551603726, disc_loss = 0.07876110703925651
Trained batch 359 in epoch 10, gen_loss = 0.8297969572246074, disc_loss = 0.0788152997304375
Trained batch 360 in epoch 10, gen_loss = 0.83037065790961, disc_loss = 0.07867644269308308
Trained batch 361 in epoch 10, gen_loss = 0.829887477156207, disc_loss = 0.07873284191315098
Trained batch 362 in epoch 10, gen_loss = 0.8294903853543862, disc_loss = 0.0787626453611189
Trained batch 363 in epoch 10, gen_loss = 0.8289280295535758, disc_loss = 0.07881835991629287
Trained batch 364 in epoch 10, gen_loss = 0.8297681672115849, disc_loss = 0.07907665290499795
Trained batch 365 in epoch 10, gen_loss = 0.8294295592874777, disc_loss = 0.07897610524974641
Trained batch 366 in epoch 10, gen_loss = 0.8299294280583592, disc_loss = 0.07909964266859949
Trained batch 367 in epoch 10, gen_loss = 0.8289159146825904, disc_loss = 0.07971151750382927
Trained batch 368 in epoch 10, gen_loss = 0.8292564929823888, disc_loss = 0.07958983708940305
Trained batch 369 in epoch 10, gen_loss = 0.8297020515074601, disc_loss = 0.07967376111175965
Trained batch 370 in epoch 10, gen_loss = 0.8294088611544946, disc_loss = 0.07957538721626098
Trained batch 371 in epoch 10, gen_loss = 0.8301957498795243, disc_loss = 0.07947283226405821
Trained batch 372 in epoch 10, gen_loss = 0.8301381351321376, disc_loss = 0.07942827829177274
Trained batch 373 in epoch 10, gen_loss = 0.830245407427696, disc_loss = 0.07935621641466722
Trained batch 374 in epoch 10, gen_loss = 0.8298500726222992, disc_loss = 0.07935499445845684
Trained batch 375 in epoch 10, gen_loss = 0.8295649777543037, disc_loss = 0.07928790874590978
Trained batch 376 in epoch 10, gen_loss = 0.8304552714925862, disc_loss = 0.07916207936906135
Trained batch 377 in epoch 10, gen_loss = 0.8311338808643755, disc_loss = 0.07929265200746832
Trained batch 378 in epoch 10, gen_loss = 0.8309082081418553, disc_loss = 0.07914866733372133
Trained batch 379 in epoch 10, gen_loss = 0.8302846107827989, disc_loss = 0.07922607321341178
Trained batch 380 in epoch 10, gen_loss = 0.8304014702637991, disc_loss = 0.07913548737187476
Trained batch 381 in epoch 10, gen_loss = 0.8314520956177986, disc_loss = 0.07909247701675558
Trained batch 382 in epoch 10, gen_loss = 0.8309036990525517, disc_loss = 0.07909455371402963
Trained batch 383 in epoch 10, gen_loss = 0.8307501340750605, disc_loss = 0.07902501016360475
Trained batch 384 in epoch 10, gen_loss = 0.830964747419605, disc_loss = 0.07892585166717891
Trained batch 385 in epoch 10, gen_loss = 0.8317772101398577, disc_loss = 0.07912113921176353
Trained batch 386 in epoch 10, gen_loss = 0.8317096149428562, disc_loss = 0.07907256085752902
Trained batch 387 in epoch 10, gen_loss = 0.8312398395741109, disc_loss = 0.07914515755849785
Trained batch 388 in epoch 10, gen_loss = 0.8313151727452069, disc_loss = 0.07914151353067252
Trained batch 389 in epoch 10, gen_loss = 0.8307183804420325, disc_loss = 0.0790994935334684
Trained batch 390 in epoch 10, gen_loss = 0.8316585182991174, disc_loss = 0.07920841175510222
Trained batch 391 in epoch 10, gen_loss = 0.8311098758511397, disc_loss = 0.07919843263249388
Trained batch 392 in epoch 10, gen_loss = 0.8306066898140895, disc_loss = 0.07953598864291234
Trained batch 393 in epoch 10, gen_loss = 0.8308692333208123, disc_loss = 0.0795095424914761
Trained batch 394 in epoch 10, gen_loss = 0.8312187883672835, disc_loss = 0.07935992064591073
Trained batch 395 in epoch 10, gen_loss = 0.8313509342495842, disc_loss = 0.07922192169776694
Trained batch 396 in epoch 10, gen_loss = 0.8310955684040896, disc_loss = 0.07918237693729795
Trained batch 397 in epoch 10, gen_loss = 0.8309554340102565, disc_loss = 0.07908422611981406
Trained batch 398 in epoch 10, gen_loss = 0.8310263814932123, disc_loss = 0.07893475433368058
Trained batch 399 in epoch 10, gen_loss = 0.8311413616687059, disc_loss = 0.07883096255129203
Trained batch 400 in epoch 10, gen_loss = 0.8314656492629253, disc_loss = 0.0787254898156274
Trained batch 401 in epoch 10, gen_loss = 0.8312604998919502, disc_loss = 0.0786471208302647
Trained batch 402 in epoch 10, gen_loss = 0.8312713939409989, disc_loss = 0.07850070474969764
Trained batch 403 in epoch 10, gen_loss = 0.8314889478358892, disc_loss = 0.07846295154690373
Trained batch 404 in epoch 10, gen_loss = 0.832162234886193, disc_loss = 0.07833577752987175
Trained batch 405 in epoch 10, gen_loss = 0.8316302727449116, disc_loss = 0.07831532627188147
Trained batch 406 in epoch 10, gen_loss = 0.8322154865657375, disc_loss = 0.07816697836736862
Trained batch 407 in epoch 10, gen_loss = 0.8323528390450805, disc_loss = 0.07803376592631799
Trained batch 408 in epoch 10, gen_loss = 0.8325120787020126, disc_loss = 0.07804568106659249
Trained batch 409 in epoch 10, gen_loss = 0.8328357564966853, disc_loss = 0.07787934721606533
Trained batch 410 in epoch 10, gen_loss = 0.8321750801410118, disc_loss = 0.07787131521751121
Trained batch 411 in epoch 10, gen_loss = 0.8320963191031252, disc_loss = 0.07778046399499607
Trained batch 412 in epoch 10, gen_loss = 0.8324267948655182, disc_loss = 0.0777164430021518
Trained batch 413 in epoch 10, gen_loss = 0.8329872253580369, disc_loss = 0.07758792536558161
Trained batch 414 in epoch 10, gen_loss = 0.8326086684163795, disc_loss = 0.07760229290249836
Trained batch 415 in epoch 10, gen_loss = 0.8320508181618956, disc_loss = 0.07779930148703548
Trained batch 416 in epoch 10, gen_loss = 0.8326937578421988, disc_loss = 0.07766948639006495
Trained batch 417 in epoch 10, gen_loss = 0.8329860317792619, disc_loss = 0.07753215370583905
Trained batch 418 in epoch 10, gen_loss = 0.8327384852139649, disc_loss = 0.07742506693737461
Trained batch 419 in epoch 10, gen_loss = 0.8331651526547613, disc_loss = 0.07727548008607257
Trained batch 420 in epoch 10, gen_loss = 0.8333420370508543, disc_loss = 0.07722392847712845
Trained batch 421 in epoch 10, gen_loss = 0.8329571618994266, disc_loss = 0.07717826485333708
Trained batch 422 in epoch 10, gen_loss = 0.832933783742553, disc_loss = 0.07703172167142232
Trained batch 423 in epoch 10, gen_loss = 0.8333727115027185, disc_loss = 0.0769848858779472
Trained batch 424 in epoch 10, gen_loss = 0.8329565069955938, disc_loss = 0.07695047491613556
Trained batch 425 in epoch 10, gen_loss = 0.8331477112473457, disc_loss = 0.0769338295510817
Trained batch 426 in epoch 10, gen_loss = 0.8327614432615196, disc_loss = 0.0768693430693842
Trained batch 427 in epoch 10, gen_loss = 0.8337433625743768, disc_loss = 0.07681122309937377
Trained batch 428 in epoch 10, gen_loss = 0.8344092450358651, disc_loss = 0.07667009953609158
Trained batch 429 in epoch 10, gen_loss = 0.8346595549999282, disc_loss = 0.07655013797501492
Trained batch 430 in epoch 10, gen_loss = 0.8349889347420492, disc_loss = 0.07640484299104479
Trained batch 431 in epoch 10, gen_loss = 0.8347762042863501, disc_loss = 0.07627902812048516
Trained batch 432 in epoch 10, gen_loss = 0.8351271111888092, disc_loss = 0.07640315617238952
Trained batch 433 in epoch 10, gen_loss = 0.8347949016890768, disc_loss = 0.07631728055668043
Trained batch 434 in epoch 10, gen_loss = 0.8349327273067386, disc_loss = 0.0761716855561425
Trained batch 435 in epoch 10, gen_loss = 0.8350234691292868, disc_loss = 0.0760575527167204
Trained batch 436 in epoch 10, gen_loss = 0.83522880466088, disc_loss = 0.075992034716229
Trained batch 437 in epoch 10, gen_loss = 0.8351392880014089, disc_loss = 0.07603551310244692
Trained batch 438 in epoch 10, gen_loss = 0.8355650063391971, disc_loss = 0.0758954179229253
Trained batch 439 in epoch 10, gen_loss = 0.8352799391881987, disc_loss = 0.07589713759212331
Trained batch 440 in epoch 10, gen_loss = 0.8351153065693352, disc_loss = 0.07580030637702434
Trained batch 441 in epoch 10, gen_loss = 0.8354432458116997, disc_loss = 0.07571350956731791
Trained batch 442 in epoch 10, gen_loss = 0.8353424706658176, disc_loss = 0.07564124996452246
Trained batch 443 in epoch 10, gen_loss = 0.8357013890200907, disc_loss = 0.0755133263867449
Trained batch 444 in epoch 10, gen_loss = 0.8355804386433591, disc_loss = 0.0754195822088906
Trained batch 445 in epoch 10, gen_loss = 0.8352696862856903, disc_loss = 0.07539927885938653
Trained batch 446 in epoch 10, gen_loss = 0.8360771326810722, disc_loss = 0.07532896411498921
Trained batch 447 in epoch 10, gen_loss = 0.836288519403232, disc_loss = 0.07518743482484881
Trained batch 448 in epoch 10, gen_loss = 0.8357149242425549, disc_loss = 0.0752638160087218
Trained batch 449 in epoch 10, gen_loss = 0.835960392885738, disc_loss = 0.07546441669265429
Trained batch 450 in epoch 10, gen_loss = 0.835688823012185, disc_loss = 0.07542132644061239
Trained batch 451 in epoch 10, gen_loss = 0.8354142344499056, disc_loss = 0.07537524060107174
Trained batch 452 in epoch 10, gen_loss = 0.8358629233395027, disc_loss = 0.07530334133811081
Trained batch 453 in epoch 10, gen_loss = 0.8361885673017754, disc_loss = 0.07525067920858114
Trained batch 454 in epoch 10, gen_loss = 0.8360361969732977, disc_loss = 0.07515882742437688
Trained batch 455 in epoch 10, gen_loss = 0.8361182925863224, disc_loss = 0.07507002135542662
Trained batch 456 in epoch 10, gen_loss = 0.8362983945814212, disc_loss = 0.07495105778900356
Trained batch 457 in epoch 10, gen_loss = 0.836292185051993, disc_loss = 0.0748348631469053
Trained batch 458 in epoch 10, gen_loss = 0.8362891883761795, disc_loss = 0.07471973153565704
Trained batch 459 in epoch 10, gen_loss = 0.8367345109581947, disc_loss = 0.0746758579397979
Trained batch 460 in epoch 10, gen_loss = 0.8369614226569839, disc_loss = 0.07459791711735622
Trained batch 461 in epoch 10, gen_loss = 0.8365989284210907, disc_loss = 0.07466419862817118
Trained batch 462 in epoch 10, gen_loss = 0.8369301868437691, disc_loss = 0.07454368961697393
Trained batch 463 in epoch 10, gen_loss = 0.8371212493371347, disc_loss = 0.07439796164519442
Trained batch 464 in epoch 10, gen_loss = 0.8366277212096799, disc_loss = 0.07444015386043697
Trained batch 465 in epoch 10, gen_loss = 0.8373693160616789, disc_loss = 0.0745423496640867
Trained batch 466 in epoch 10, gen_loss = 0.8386385810324161, disc_loss = 0.0745907687727657
Trained batch 467 in epoch 10, gen_loss = 0.8379630486552532, disc_loss = 0.07476339567627789
Trained batch 468 in epoch 10, gen_loss = 0.8378522162879708, disc_loss = 0.07471668619765783
Trained batch 469 in epoch 10, gen_loss = 0.8385694499345536, disc_loss = 0.07465418554604687
Trained batch 470 in epoch 10, gen_loss = 0.8384215567901636, disc_loss = 0.07461501959703404
Trained batch 471 in epoch 10, gen_loss = 0.8384234701299061, disc_loss = 0.07461323549229083
Trained batch 472 in epoch 10, gen_loss = 0.8381294249606183, disc_loss = 0.07453727660342327
Trained batch 473 in epoch 10, gen_loss = 0.8380999359526212, disc_loss = 0.0744499867341878
Trained batch 474 in epoch 10, gen_loss = 0.8385011347344047, disc_loss = 0.07431992443768602
Trained batch 475 in epoch 10, gen_loss = 0.8383936967794635, disc_loss = 0.07423164520976173
Trained batch 476 in epoch 10, gen_loss = 0.838565154457992, disc_loss = 0.07439839753246158
Trained batch 477 in epoch 10, gen_loss = 0.8385270923126692, disc_loss = 0.0743148185265987
Trained batch 478 in epoch 10, gen_loss = 0.8389393406645987, disc_loss = 0.07424409855507112
Trained batch 479 in epoch 10, gen_loss = 0.8387786412611604, disc_loss = 0.07414042990421876
Trained batch 480 in epoch 10, gen_loss = 0.838609660179848, disc_loss = 0.07410532887831424
Trained batch 481 in epoch 10, gen_loss = 0.8386932233680828, disc_loss = 0.07403491467963981
Trained batch 482 in epoch 10, gen_loss = 0.8386236550768463, disc_loss = 0.07395361260921689
Trained batch 483 in epoch 10, gen_loss = 0.8387009784086676, disc_loss = 0.07393613187134389
Trained batch 484 in epoch 10, gen_loss = 0.8390140699971582, disc_loss = 0.0738094283863134
Trained batch 485 in epoch 10, gen_loss = 0.8392265659178235, disc_loss = 0.07367923912504082
Trained batch 486 in epoch 10, gen_loss = 0.8396653827333352, disc_loss = 0.07358473665186145
Trained batch 487 in epoch 10, gen_loss = 0.8398137305725794, disc_loss = 0.07349739113792045
Trained batch 488 in epoch 10, gen_loss = 0.8392974060859173, disc_loss = 0.07361688009312792
Trained batch 489 in epoch 10, gen_loss = 0.8398544008026317, disc_loss = 0.07359406504856081
Trained batch 490 in epoch 10, gen_loss = 0.8398961239701133, disc_loss = 0.07391519544839616
Trained batch 491 in epoch 10, gen_loss = 0.8395735120506791, disc_loss = 0.07389556388635703
Trained batch 492 in epoch 10, gen_loss = 0.8395981304423079, disc_loss = 0.07381062981111525
Trained batch 493 in epoch 10, gen_loss = 0.8395948799153571, disc_loss = 0.07371293004556947
Trained batch 494 in epoch 10, gen_loss = 0.8397591041194068, disc_loss = 0.0737796783522524
Trained batch 495 in epoch 10, gen_loss = 0.8393604794457075, disc_loss = 0.07398403773174411
Trained batch 496 in epoch 10, gen_loss = 0.8399968128688858, disc_loss = 0.07398445647157414
Trained batch 497 in epoch 10, gen_loss = 0.8399359871704416, disc_loss = 0.07389020662470515
Trained batch 498 in epoch 10, gen_loss = 0.8404224425972344, disc_loss = 0.07379392548678872
Trained batch 499 in epoch 10, gen_loss = 0.8401957818865776, disc_loss = 0.07373173231631518
Trained batch 500 in epoch 10, gen_loss = 0.8398809758370032, disc_loss = 0.07372420461859532
Trained batch 501 in epoch 10, gen_loss = 0.8399944002053652, disc_loss = 0.07359678049263844
Trained batch 502 in epoch 10, gen_loss = 0.8401080581468806, disc_loss = 0.07353868644691959
Trained batch 503 in epoch 10, gen_loss = 0.8404673830502563, disc_loss = 0.07350357959327834
Trained batch 504 in epoch 10, gen_loss = 0.8403591114105564, disc_loss = 0.07343582388861934
Trained batch 505 in epoch 10, gen_loss = 0.8403721718566691, disc_loss = 0.0733385810834676
Trained batch 506 in epoch 10, gen_loss = 0.840681418805903, disc_loss = 0.07325521168433115
Trained batch 507 in epoch 10, gen_loss = 0.8403738416203363, disc_loss = 0.0732850946126667
Trained batch 508 in epoch 10, gen_loss = 0.8403550084892565, disc_loss = 0.07321555452505474
Trained batch 509 in epoch 10, gen_loss = 0.8404564507451712, disc_loss = 0.07320857824867262
Trained batch 510 in epoch 10, gen_loss = 0.8399045470292787, disc_loss = 0.0733227714597304
Trained batch 511 in epoch 10, gen_loss = 0.8405648265616037, disc_loss = 0.07321044196214643
Trained batch 512 in epoch 10, gen_loss = 0.8410417211566985, disc_loss = 0.07319171774994444
Trained batch 513 in epoch 10, gen_loss = 0.8412947989275483, disc_loss = 0.07308652727042075
Trained batch 514 in epoch 10, gen_loss = 0.8408255358922829, disc_loss = 0.07310471773075247
Trained batch 515 in epoch 10, gen_loss = 0.8408986577807471, disc_loss = 0.07303125404413471
Trained batch 516 in epoch 10, gen_loss = 0.841083133993112, disc_loss = 0.07291234980339123
Trained batch 517 in epoch 10, gen_loss = 0.8409900562298344, disc_loss = 0.07285268998499887
Trained batch 518 in epoch 10, gen_loss = 0.8408898056012817, disc_loss = 0.07279839042595701
Trained batch 519 in epoch 10, gen_loss = 0.84084012605823, disc_loss = 0.07290657104279559
Trained batch 520 in epoch 10, gen_loss = 0.8404414469015118, disc_loss = 0.0730864478171501
Trained batch 521 in epoch 10, gen_loss = 0.8406624541086255, disc_loss = 0.07297938650695186
Trained batch 522 in epoch 10, gen_loss = 0.8406988433054711, disc_loss = 0.07285836074380186
Trained batch 523 in epoch 10, gen_loss = 0.8407903233443508, disc_loss = 0.07276341927998507
Trained batch 524 in epoch 10, gen_loss = 0.8406650256542932, disc_loss = 0.07269680728869779
Trained batch 525 in epoch 10, gen_loss = 0.8408657859146822, disc_loss = 0.07261711060859177
Trained batch 526 in epoch 10, gen_loss = 0.8409291334464383, disc_loss = 0.0724977482520256
Trained batch 527 in epoch 10, gen_loss = 0.8407355482040932, disc_loss = 0.07246259327935563
Trained batch 528 in epoch 10, gen_loss = 0.8404206051605636, disc_loss = 0.07246111830897164
Trained batch 529 in epoch 10, gen_loss = 0.8413584999880701, disc_loss = 0.07250711905576711
Trained batch 530 in epoch 10, gen_loss = 0.8419525495918008, disc_loss = 0.0724333107310107
Trained batch 531 in epoch 10, gen_loss = 0.8415888010671264, disc_loss = 0.07243054247062121
Trained batch 532 in epoch 10, gen_loss = 0.8412872439365673, disc_loss = 0.07243377879247992
Trained batch 533 in epoch 10, gen_loss = 0.841682248403517, disc_loss = 0.0723621862302168
Trained batch 534 in epoch 10, gen_loss = 0.8419921175898792, disc_loss = 0.07225039936776195
Trained batch 535 in epoch 10, gen_loss = 0.841988736290985, disc_loss = 0.07214110241264605
Trained batch 536 in epoch 10, gen_loss = 0.8414588442394854, disc_loss = 0.07219261450786664
Trained batch 537 in epoch 10, gen_loss = 0.8417767456362238, disc_loss = 0.07209948811257694
Trained batch 538 in epoch 10, gen_loss = 0.8422144763655477, disc_loss = 0.07225546402016962
Trained batch 539 in epoch 10, gen_loss = 0.8419307835124157, disc_loss = 0.07225209271224836
Trained batch 540 in epoch 10, gen_loss = 0.8417168311953765, disc_loss = 0.0722778513975951
Trained batch 541 in epoch 10, gen_loss = 0.8417765681264145, disc_loss = 0.07219184303614981
Trained batch 542 in epoch 10, gen_loss = 0.8420177462680564, disc_loss = 0.07219267335529979
Trained batch 543 in epoch 10, gen_loss = 0.8420089699656648, disc_loss = 0.0722138910119504
Trained batch 544 in epoch 10, gen_loss = 0.8414683719840619, disc_loss = 0.07237259444327802
Trained batch 545 in epoch 10, gen_loss = 0.8424685114360118, disc_loss = 0.07247184860543945
Trained batch 546 in epoch 10, gen_loss = 0.842306378173218, disc_loss = 0.07240001635431861
Trained batch 547 in epoch 10, gen_loss = 0.8424403375408945, disc_loss = 0.07245956112657857
Trained batch 548 in epoch 10, gen_loss = 0.8418259051219579, disc_loss = 0.07249634468822803
Trained batch 549 in epoch 10, gen_loss = 0.8415487641096115, disc_loss = 0.07242599172517657
Trained batch 550 in epoch 10, gen_loss = 0.8418301025341297, disc_loss = 0.07246569440803219
Trained batch 551 in epoch 10, gen_loss = 0.8418445381457391, disc_loss = 0.07237201040792886
Trained batch 552 in epoch 10, gen_loss = 0.8416390556431161, disc_loss = 0.0723106779046963
Trained batch 553 in epoch 10, gen_loss = 0.8420529885735323, disc_loss = 0.07223101927048194
Trained batch 554 in epoch 10, gen_loss = 0.8418445140928835, disc_loss = 0.07219600943798149
Trained batch 555 in epoch 10, gen_loss = 0.8415343125196669, disc_loss = 0.07218776887664638
Trained batch 556 in epoch 10, gen_loss = 0.8415687395062438, disc_loss = 0.07214515302263375
Trained batch 557 in epoch 10, gen_loss = 0.8419901316845289, disc_loss = 0.07212992603172912
Trained batch 558 in epoch 10, gen_loss = 0.8419742302199382, disc_loss = 0.07205539886308218
Trained batch 559 in epoch 10, gen_loss = 0.8416946997067758, disc_loss = 0.07204848068067804
Trained batch 560 in epoch 10, gen_loss = 0.8417621813249673, disc_loss = 0.07196301250235441
Trained batch 561 in epoch 10, gen_loss = 0.8418560798588173, disc_loss = 0.07203482875428113
Trained batch 562 in epoch 10, gen_loss = 0.8417349245472022, disc_loss = 0.0719871027362045
Trained batch 563 in epoch 10, gen_loss = 0.8416404967718091, disc_loss = 0.07199822918260933
Trained batch 564 in epoch 10, gen_loss = 0.8413000726594334, disc_loss = 0.07191720584621736
Trained batch 565 in epoch 10, gen_loss = 0.8407944443474389, disc_loss = 0.07193719241077035
Trained batch 566 in epoch 10, gen_loss = 0.8404973217103847, disc_loss = 0.07194151350410369
Trained batch 567 in epoch 10, gen_loss = 0.8412738918313678, disc_loss = 0.07220729388801617
Trained batch 568 in epoch 10, gen_loss = 0.8415788931146866, disc_loss = 0.07238707360967024
Trained batch 569 in epoch 10, gen_loss = 0.8410515345502318, disc_loss = 0.07255871552941308
Trained batch 570 in epoch 10, gen_loss = 0.8407876057821063, disc_loss = 0.07252450098957207
Trained batch 571 in epoch 10, gen_loss = 0.8407005818261133, disc_loss = 0.07249449578543696
Trained batch 572 in epoch 10, gen_loss = 0.8407787966166491, disc_loss = 0.07242015388226998
Trained batch 573 in epoch 10, gen_loss = 0.8408791571855545, disc_loss = 0.07236765457953258
Trained batch 574 in epoch 10, gen_loss = 0.8406145675804304, disc_loss = 0.07238533584158058
Trained batch 575 in epoch 10, gen_loss = 0.8404812203823693, disc_loss = 0.07235950257260508
Trained batch 576 in epoch 10, gen_loss = 0.8402589922657873, disc_loss = 0.07236065907787977
Trained batch 577 in epoch 10, gen_loss = 0.8402422051425623, disc_loss = 0.07226788598534918
Trained batch 578 in epoch 10, gen_loss = 0.8402539077303365, disc_loss = 0.07218287175678888
Trained batch 579 in epoch 10, gen_loss = 0.8406555874080494, disc_loss = 0.07208588730447509
Trained batch 580 in epoch 10, gen_loss = 0.8410732355770268, disc_loss = 0.0722316232511514
Trained batch 581 in epoch 10, gen_loss = 0.8412597502527368, disc_loss = 0.07217733710012127
Trained batch 582 in epoch 10, gen_loss = 0.8408068884196044, disc_loss = 0.07229314110118826
Trained batch 583 in epoch 10, gen_loss = 0.8407809805278093, disc_loss = 0.0722400422019833
Trained batch 584 in epoch 10, gen_loss = 0.841351889901691, disc_loss = 0.07230044109985614
Trained batch 585 in epoch 10, gen_loss = 0.8412572410428076, disc_loss = 0.07223576563648854
Trained batch 586 in epoch 10, gen_loss = 0.840970111918815, disc_loss = 0.07225659753162623
Trained batch 587 in epoch 10, gen_loss = 0.8408827686897752, disc_loss = 0.07219729746919962
Trained batch 588 in epoch 10, gen_loss = 0.840502860742433, disc_loss = 0.07232521291733648
Trained batch 589 in epoch 10, gen_loss = 0.8400735505051532, disc_loss = 0.0724020883393616
Trained batch 590 in epoch 10, gen_loss = 0.8400759381792066, disc_loss = 0.07243615203078477
Trained batch 591 in epoch 10, gen_loss = 0.8400553408003336, disc_loss = 0.07237529184046276
Trained batch 592 in epoch 10, gen_loss = 0.8404662865912934, disc_loss = 0.07237658673083852
Trained batch 593 in epoch 10, gen_loss = 0.8400501500978212, disc_loss = 0.07252957513367739
Trained batch 594 in epoch 10, gen_loss = 0.8399226537772587, disc_loss = 0.07246022570815658
Trained batch 595 in epoch 10, gen_loss = 0.839961274908293, disc_loss = 0.0723992270564398
Trained batch 596 in epoch 10, gen_loss = 0.8403316156648512, disc_loss = 0.07231107792993337
Trained batch 597 in epoch 10, gen_loss = 0.8399178354337462, disc_loss = 0.07229652716295426
Trained batch 598 in epoch 10, gen_loss = 0.8397409092504313, disc_loss = 0.07224743809700261
Trained batch 599 in epoch 10, gen_loss = 0.839700871159633, disc_loss = 0.0721598722366616
Trained batch 600 in epoch 10, gen_loss = 0.8395309271213417, disc_loss = 0.07210443623382568
Trained batch 601 in epoch 10, gen_loss = 0.8399910674835757, disc_loss = 0.07231274667502291
Trained batch 602 in epoch 10, gen_loss = 0.8400720499740113, disc_loss = 0.07223747832357735
Trained batch 603 in epoch 10, gen_loss = 0.8400739671674785, disc_loss = 0.07222680616599587
Trained batch 604 in epoch 10, gen_loss = 0.8400205217609721, disc_loss = 0.07217555661678068
Trained batch 605 in epoch 10, gen_loss = 0.8397059701751954, disc_loss = 0.07217522083379009
Trained batch 606 in epoch 10, gen_loss = 0.8398092084209844, disc_loss = 0.07251087660691048
Trained batch 607 in epoch 10, gen_loss = 0.8397119620226716, disc_loss = 0.0724721016763636
Trained batch 608 in epoch 10, gen_loss = 0.8396379663341347, disc_loss = 0.07243617395725108
Trained batch 609 in epoch 10, gen_loss = 0.8399374935959206, disc_loss = 0.0725395142589314
Trained batch 610 in epoch 10, gen_loss = 0.8397567100005923, disc_loss = 0.07249803136753714
Trained batch 611 in epoch 10, gen_loss = 0.839719731774595, disc_loss = 0.07247480127832615
Trained batch 612 in epoch 10, gen_loss = 0.8401628051554787, disc_loss = 0.07243952721351268
Trained batch 613 in epoch 10, gen_loss = 0.8401785294376678, disc_loss = 0.07241291245627626
Trained batch 614 in epoch 10, gen_loss = 0.8400648791130966, disc_loss = 0.07235854743427135
Trained batch 615 in epoch 10, gen_loss = 0.8398729176200056, disc_loss = 0.07229286978813493
Trained batch 616 in epoch 10, gen_loss = 0.839914224570922, disc_loss = 0.07221125086959651
Trained batch 617 in epoch 10, gen_loss = 0.8395284781274672, disc_loss = 0.07227434392891896
Trained batch 618 in epoch 10, gen_loss = 0.8396024523432305, disc_loss = 0.07219641386216841
Trained batch 619 in epoch 10, gen_loss = 0.8401718911144042, disc_loss = 0.07222981747510213
Trained batch 620 in epoch 10, gen_loss = 0.8399265404196753, disc_loss = 0.0722918377397357
Trained batch 621 in epoch 10, gen_loss = 0.8401988020759686, disc_loss = 0.07221765050940047
Trained batch 622 in epoch 10, gen_loss = 0.8402065662951186, disc_loss = 0.07213873842381312
Trained batch 623 in epoch 10, gen_loss = 0.8404076817230537, disc_loss = 0.07225627986302313
Trained batch 624 in epoch 10, gen_loss = 0.8405604727268219, disc_loss = 0.07221253893822431
Trained batch 625 in epoch 10, gen_loss = 0.8403036264470591, disc_loss = 0.0723868211234411
Trained batch 626 in epoch 10, gen_loss = 0.8404692270253834, disc_loss = 0.07229508811004899
Trained batch 627 in epoch 10, gen_loss = 0.8405009404204453, disc_loss = 0.07228580398105416
Trained batch 628 in epoch 10, gen_loss = 0.8405093306672592, disc_loss = 0.07219639208185559
Trained batch 629 in epoch 10, gen_loss = 0.840204636587037, disc_loss = 0.07218193261337186
Trained batch 630 in epoch 10, gen_loss = 0.8406055968744819, disc_loss = 0.07225261202079086
Trained batch 631 in epoch 10, gen_loss = 0.8405389343918879, disc_loss = 0.072191396754683
Trained batch 632 in epoch 10, gen_loss = 0.8404708503264386, disc_loss = 0.07214782102471938
Trained batch 633 in epoch 10, gen_loss = 0.8405761443760117, disc_loss = 0.07223307690656618
Trained batch 634 in epoch 10, gen_loss = 0.840181536514928, disc_loss = 0.07229913546168429
Trained batch 635 in epoch 10, gen_loss = 0.8401336348937742, disc_loss = 0.07226717102768943
Trained batch 636 in epoch 10, gen_loss = 0.8398153398718152, disc_loss = 0.07239814964378928
Trained batch 637 in epoch 10, gen_loss = 0.840101303211574, disc_loss = 0.07232268802167667
Trained batch 638 in epoch 10, gen_loss = 0.8400945179805696, disc_loss = 0.07223870083747988
Trained batch 639 in epoch 10, gen_loss = 0.8396845479961484, disc_loss = 0.07231529007840436
Trained batch 640 in epoch 10, gen_loss = 0.8397980563447182, disc_loss = 0.07229876907341845
Trained batch 641 in epoch 10, gen_loss = 0.8400191445124112, disc_loss = 0.07244088666403312
Trained batch 642 in epoch 10, gen_loss = 0.8395911989556871, disc_loss = 0.07252087786758947
Trained batch 643 in epoch 10, gen_loss = 0.8394552703877414, disc_loss = 0.07246431147517718
Trained batch 644 in epoch 10, gen_loss = 0.8400495027848917, disc_loss = 0.07284486389957195
Trained batch 645 in epoch 10, gen_loss = 0.8398236445505922, disc_loss = 0.07294195598919787
Trained batch 646 in epoch 10, gen_loss = 0.8395396629017324, disc_loss = 0.07295016752386112
Trained batch 647 in epoch 10, gen_loss = 0.8394761995676859, disc_loss = 0.07298874090724614
Trained batch 648 in epoch 10, gen_loss = 0.8397160134348554, disc_loss = 0.07296954584128593
Trained batch 649 in epoch 10, gen_loss = 0.8395777650521352, disc_loss = 0.07296994974693427
Trained batch 650 in epoch 10, gen_loss = 0.839530742067712, disc_loss = 0.07290701464264898
Trained batch 651 in epoch 10, gen_loss = 0.8395840225318458, disc_loss = 0.0728950310938426
Trained batch 652 in epoch 10, gen_loss = 0.8395397151502314, disc_loss = 0.07282246329506452
Trained batch 653 in epoch 10, gen_loss = 0.8397103239545763, disc_loss = 0.072748037658928
Trained batch 654 in epoch 10, gen_loss = 0.8394281497893442, disc_loss = 0.07273627588425884
Trained batch 655 in epoch 10, gen_loss = 0.8393825687377191, disc_loss = 0.07293860957866943
Trained batch 656 in epoch 10, gen_loss = 0.8391895742811931, disc_loss = 0.07289750600174137
Trained batch 657 in epoch 10, gen_loss = 0.838746120366282, disc_loss = 0.07294216421984794
Trained batch 658 in epoch 10, gen_loss = 0.8387627225815798, disc_loss = 0.0728543205709622
Trained batch 659 in epoch 10, gen_loss = 0.8387644163135326, disc_loss = 0.07292564827102152
Trained batch 660 in epoch 10, gen_loss = 0.8384074506077932, disc_loss = 0.07297871732709538
Trained batch 661 in epoch 10, gen_loss = 0.8383354708057156, disc_loss = 0.07292291875703548
Trained batch 662 in epoch 10, gen_loss = 0.8384216292501395, disc_loss = 0.0729182488783677
Trained batch 663 in epoch 10, gen_loss = 0.8383097674203924, disc_loss = 0.07286727046089089
Trained batch 664 in epoch 10, gen_loss = 0.83798186460832, disc_loss = 0.07295462810959583
Trained batch 665 in epoch 10, gen_loss = 0.8379592743811307, disc_loss = 0.07294333204011749
Trained batch 666 in epoch 10, gen_loss = 0.8379360576351543, disc_loss = 0.07297661488616038
Trained batch 667 in epoch 10, gen_loss = 0.8377984486921819, disc_loss = 0.07298404795067485
Trained batch 668 in epoch 10, gen_loss = 0.8385517518349292, disc_loss = 0.07303200911880876
Trained batch 669 in epoch 10, gen_loss = 0.8382319914316063, disc_loss = 0.07306986875109263
Trained batch 670 in epoch 10, gen_loss = 0.8382297767168008, disc_loss = 0.07298692568703576
Trained batch 671 in epoch 10, gen_loss = 0.838005736691966, disc_loss = 0.07300963523032676
Trained batch 672 in epoch 10, gen_loss = 0.8380464549670424, disc_loss = 0.07303682826237994
Trained batch 673 in epoch 10, gen_loss = 0.8384199132286123, disc_loss = 0.07300781791073543
Trained batch 674 in epoch 10, gen_loss = 0.838104194049482, disc_loss = 0.07301878230163344
Trained batch 675 in epoch 10, gen_loss = 0.8377342590478045, disc_loss = 0.07303689742879667
Trained batch 676 in epoch 10, gen_loss = 0.8383161882089899, disc_loss = 0.07296387893883745
Trained batch 677 in epoch 10, gen_loss = 0.8380500819742855, disc_loss = 0.07293700578191199
Trained batch 678 in epoch 10, gen_loss = 0.838317712689359, disc_loss = 0.0729781863566307
Trained batch 679 in epoch 10, gen_loss = 0.838042889579254, disc_loss = 0.07301061809446444
Trained batch 680 in epoch 10, gen_loss = 0.8380764484317993, disc_loss = 0.0729481372599341
Trained batch 681 in epoch 10, gen_loss = 0.8379118744491482, disc_loss = 0.07287386497291477
Trained batch 682 in epoch 10, gen_loss = 0.8381550681625941, disc_loss = 0.0728386905737014
Trained batch 683 in epoch 10, gen_loss = 0.8382910142777956, disc_loss = 0.07277125284369838
Trained batch 684 in epoch 10, gen_loss = 0.8382318236096932, disc_loss = 0.07274196817655199
Trained batch 685 in epoch 10, gen_loss = 0.8383151175068697, disc_loss = 0.07268240602290578
Trained batch 686 in epoch 10, gen_loss = 0.838378523591651, disc_loss = 0.07260938387044219
Trained batch 687 in epoch 10, gen_loss = 0.8384724446074214, disc_loss = 0.07267536749511004
Trained batch 688 in epoch 10, gen_loss = 0.8383478765823326, disc_loss = 0.07265379408263589
Trained batch 689 in epoch 10, gen_loss = 0.8380000264316365, disc_loss = 0.0726833804011129
Trained batch 690 in epoch 10, gen_loss = 0.837757298596171, disc_loss = 0.07262844089068224
Trained batch 691 in epoch 10, gen_loss = 0.8380556192270593, disc_loss = 0.07266044820459679
Trained batch 692 in epoch 10, gen_loss = 0.8379731600160722, disc_loss = 0.07260148945663657
Trained batch 693 in epoch 10, gen_loss = 0.8380950817714851, disc_loss = 0.07258343877759292
Trained batch 694 in epoch 10, gen_loss = 0.837762608931219, disc_loss = 0.07262339265816074
Trained batch 695 in epoch 10, gen_loss = 0.837640856060831, disc_loss = 0.07260205599094002
Trained batch 696 in epoch 10, gen_loss = 0.8375810944452519, disc_loss = 0.07253457544641395
Trained batch 697 in epoch 10, gen_loss = 0.8377196012134197, disc_loss = 0.07261217979815679
Trained batch 698 in epoch 10, gen_loss = 0.8380971478887211, disc_loss = 0.07272670042563832
Trained batch 699 in epoch 10, gen_loss = 0.8376368460059166, disc_loss = 0.07292255234239357
Trained batch 700 in epoch 10, gen_loss = 0.8374222831192099, disc_loss = 0.07298084046324972
Trained batch 701 in epoch 10, gen_loss = 0.8372669543890532, disc_loss = 0.07292265943026016
Trained batch 702 in epoch 10, gen_loss = 0.8374436877954057, disc_loss = 0.07285107940880536
Trained batch 703 in epoch 10, gen_loss = 0.837668564974923, disc_loss = 0.07287021229488098
Trained batch 704 in epoch 10, gen_loss = 0.8375307628871701, disc_loss = 0.07290424344704506
Trained batch 705 in epoch 10, gen_loss = 0.8373297476988001, disc_loss = 0.07289872953283044
Trained batch 706 in epoch 10, gen_loss = 0.8376227541809541, disc_loss = 0.07295705692623933
Trained batch 707 in epoch 10, gen_loss = 0.8375098475881215, disc_loss = 0.07289610383242874
Trained batch 708 in epoch 10, gen_loss = 0.8373325596995683, disc_loss = 0.07289003442095432
Trained batch 709 in epoch 10, gen_loss = 0.8373180582909517, disc_loss = 0.07286433710808485
Trained batch 710 in epoch 10, gen_loss = 0.8373416774970402, disc_loss = 0.0728776824939603
Trained batch 711 in epoch 10, gen_loss = 0.8375740098568161, disc_loss = 0.07314623522917542
Trained batch 712 in epoch 10, gen_loss = 0.8375217705170871, disc_loss = 0.07321805686678158
Trained batch 713 in epoch 10, gen_loss = 0.8374658041224092, disc_loss = 0.07320330663471997
Trained batch 714 in epoch 10, gen_loss = 0.8374500937811978, disc_loss = 0.07328199512891836
Trained batch 715 in epoch 10, gen_loss = 0.83744776461211, disc_loss = 0.07330522532236643
Trained batch 716 in epoch 10, gen_loss = 0.8374524817722778, disc_loss = 0.07331118629816685
Trained batch 717 in epoch 10, gen_loss = 0.8373086442107278, disc_loss = 0.0733181891501116
Trained batch 718 in epoch 10, gen_loss = 0.8368583306234967, disc_loss = 0.07343492197890938
Trained batch 719 in epoch 10, gen_loss = 0.836608905552162, disc_loss = 0.0734661801200774
Trained batch 720 in epoch 10, gen_loss = 0.8367968886553332, disc_loss = 0.07341043294075458
Trained batch 721 in epoch 10, gen_loss = 0.8369000925169097, disc_loss = 0.07340051928777609
Trained batch 722 in epoch 10, gen_loss = 0.8371136184797248, disc_loss = 0.0733665560486818
Trained batch 723 in epoch 10, gen_loss = 0.8366271240523507, disc_loss = 0.07347844672281274
Trained batch 724 in epoch 10, gen_loss = 0.8362511015349421, disc_loss = 0.07365833057925619
Trained batch 725 in epoch 10, gen_loss = 0.8363324799074614, disc_loss = 0.07365404125354343
Trained batch 726 in epoch 10, gen_loss = 0.8362577125081662, disc_loss = 0.073712703844909
Trained batch 727 in epoch 10, gen_loss = 0.836296101397538, disc_loss = 0.07366175299182862
Trained batch 728 in epoch 10, gen_loss = 0.8366192846222996, disc_loss = 0.07371204632075072
Trained batch 729 in epoch 10, gen_loss = 0.8364733957672772, disc_loss = 0.07369622246757762
Trained batch 730 in epoch 10, gen_loss = 0.8360685568746236, disc_loss = 0.07383169310750942
Trained batch 731 in epoch 10, gen_loss = 0.8358355627441015, disc_loss = 0.07387375386299494
Trained batch 732 in epoch 10, gen_loss = 0.8362431019178679, disc_loss = 0.0740057652483289
Trained batch 733 in epoch 10, gen_loss = 0.8360530343871025, disc_loss = 0.07397791807735161
Trained batch 734 in epoch 10, gen_loss = 0.8360632652733602, disc_loss = 0.07389966255548049
Trained batch 735 in epoch 10, gen_loss = 0.8360445824573222, disc_loss = 0.07382692689197543
Trained batch 736 in epoch 10, gen_loss = 0.8358637534860355, disc_loss = 0.07388129252106396
Trained batch 737 in epoch 10, gen_loss = 0.8358010497438876, disc_loss = 0.07399436948583701
Trained batch 738 in epoch 10, gen_loss = 0.8353740291843879, disc_loss = 0.07407573268765202
Trained batch 739 in epoch 10, gen_loss = 0.8356848428780969, disc_loss = 0.07406584599332229
Trained batch 740 in epoch 10, gen_loss = 0.8355509242628589, disc_loss = 0.07400234290442646
Trained batch 741 in epoch 10, gen_loss = 0.835106208036852, disc_loss = 0.07415271985703561
Trained batch 742 in epoch 10, gen_loss = 0.8352698787625673, disc_loss = 0.0741058337836856
Trained batch 743 in epoch 10, gen_loss = 0.8354877070473727, disc_loss = 0.07410755792572614
Trained batch 744 in epoch 10, gen_loss = 0.835177308961049, disc_loss = 0.07412322668621205
Trained batch 745 in epoch 10, gen_loss = 0.8351873588066638, disc_loss = 0.07405210253420529
Trained batch 746 in epoch 10, gen_loss = 0.8355717295543895, disc_loss = 0.07412007087006307
Trained batch 747 in epoch 10, gen_loss = 0.8351888730325163, disc_loss = 0.07419032455088302
Trained batch 748 in epoch 10, gen_loss = 0.8349348878430747, disc_loss = 0.0742520230594719
Trained batch 749 in epoch 10, gen_loss = 0.8351021798849105, disc_loss = 0.07423262559870879
Trained batch 750 in epoch 10, gen_loss = 0.8352643393089229, disc_loss = 0.07416330796285729
Trained batch 751 in epoch 10, gen_loss = 0.8353150609405117, disc_loss = 0.07408532552034693
Trained batch 752 in epoch 10, gen_loss = 0.8350501581729646, disc_loss = 0.07408700416614097
Trained batch 753 in epoch 10, gen_loss = 0.8351456569977085, disc_loss = 0.07437598782613755
Trained batch 754 in epoch 10, gen_loss = 0.8349965305123108, disc_loss = 0.07438028954364212
Trained batch 755 in epoch 10, gen_loss = 0.8349216425466159, disc_loss = 0.07432092445848322
Trained batch 756 in epoch 10, gen_loss = 0.834853936651109, disc_loss = 0.07427151590251073
Trained batch 757 in epoch 10, gen_loss = 0.8348903326922168, disc_loss = 0.07418826716708751
Trained batch 758 in epoch 10, gen_loss = 0.8349154854244866, disc_loss = 0.07417324459123792
Trained batch 759 in epoch 10, gen_loss = 0.8349425100574368, disc_loss = 0.07414649477302047
Trained batch 760 in epoch 10, gen_loss = 0.8348414499640622, disc_loss = 0.07414767255152376
Trained batch 761 in epoch 10, gen_loss = 0.8345787193127504, disc_loss = 0.07408914608841767
Trained batch 762 in epoch 10, gen_loss = 0.8346285030616846, disc_loss = 0.07402066539162538
Trained batch 763 in epoch 10, gen_loss = 0.8347605277652516, disc_loss = 0.07394040526739316
Trained batch 764 in epoch 10, gen_loss = 0.8345726954002006, disc_loss = 0.07388513332318052
Trained batch 765 in epoch 10, gen_loss = 0.8347429612520159, disc_loss = 0.0738136136610129
Trained batch 766 in epoch 10, gen_loss = 0.834925536809409, disc_loss = 0.07374567485680364
Trained batch 767 in epoch 10, gen_loss = 0.8347492333268747, disc_loss = 0.07375675373502115
Trained batch 768 in epoch 10, gen_loss = 0.8350394612713505, disc_loss = 0.07393695733428815
Trained batch 769 in epoch 10, gen_loss = 0.8350968724334394, disc_loss = 0.07385816248012828
Trained batch 770 in epoch 10, gen_loss = 0.8347507367724729, disc_loss = 0.07393602005431933
Trained batch 771 in epoch 10, gen_loss = 0.8350828000069282, disc_loss = 0.07387020882856044
Trained batch 772 in epoch 10, gen_loss = 0.8350916526064681, disc_loss = 0.07388089852646128
Trained batch 773 in epoch 10, gen_loss = 0.8349122003452414, disc_loss = 0.07387322043995216
Trained batch 774 in epoch 10, gen_loss = 0.8347262080638639, disc_loss = 0.07387601614959778
Trained batch 775 in epoch 10, gen_loss = 0.8346801669404065, disc_loss = 0.07381021484406185
Trained batch 776 in epoch 10, gen_loss = 0.8346575445266611, disc_loss = 0.07375129200805798
Trained batch 777 in epoch 10, gen_loss = 0.8343696032284464, disc_loss = 0.07374246218086132
Trained batch 778 in epoch 10, gen_loss = 0.8346693898731692, disc_loss = 0.07369734857360496
Trained batch 779 in epoch 10, gen_loss = 0.8347605561216672, disc_loss = 0.07364575504922331
Trained batch 780 in epoch 10, gen_loss = 0.8345552267323078, disc_loss = 0.0736698056195556
Trained batch 781 in epoch 10, gen_loss = 0.8343284894971896, disc_loss = 0.07369400684000052
Trained batch 782 in epoch 10, gen_loss = 0.834608034117773, disc_loss = 0.07371495009696118
Trained batch 783 in epoch 10, gen_loss = 0.8343664425596291, disc_loss = 0.07370213923111026
Trained batch 784 in epoch 10, gen_loss = 0.834911768565512, disc_loss = 0.07381496972576448
Trained batch 785 in epoch 10, gen_loss = 0.8344636943200769, disc_loss = 0.07406768976514046
Trained batch 786 in epoch 10, gen_loss = 0.8348074890909837, disc_loss = 0.07400086763275851
Trained batch 787 in epoch 10, gen_loss = 0.8346911585573012, disc_loss = 0.07396451865800369
Trained batch 788 in epoch 10, gen_loss = 0.8347183887496195, disc_loss = 0.07393757544495684
Trained batch 789 in epoch 10, gen_loss = 0.8348752620853955, disc_loss = 0.07388955798660275
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.9700614809989929, disc_loss = 0.026062676683068275
Trained batch 1 in epoch 11, gen_loss = 0.9026679396629333, disc_loss = 0.039293001405894756
Trained batch 2 in epoch 11, gen_loss = 0.8375248114267985, disc_loss = 0.044544231767455734
Trained batch 3 in epoch 11, gen_loss = 0.8157584071159363, disc_loss = 0.06616738578304648
Trained batch 4 in epoch 11, gen_loss = 0.8344345331192017, disc_loss = 0.05730575695633888
Trained batch 5 in epoch 11, gen_loss = 0.8324932555357615, disc_loss = 0.0541180744767189
Trained batch 6 in epoch 11, gen_loss = 0.8603744081088475, disc_loss = 0.0609424923147474
Trained batch 7 in epoch 11, gen_loss = 0.8432711288332939, disc_loss = 0.064872813411057
Trained batch 8 in epoch 11, gen_loss = 0.8446398774782816, disc_loss = 0.06011998177402549
Trained batch 9 in epoch 11, gen_loss = 0.8548254549503327, disc_loss = 0.05916749034076929
Trained batch 10 in epoch 11, gen_loss = 0.855100767178969, disc_loss = 0.07076598517596722
Trained batch 11 in epoch 11, gen_loss = 0.8416603108247122, disc_loss = 0.07402902670825522
Trained batch 12 in epoch 11, gen_loss = 0.8259076246848474, disc_loss = 0.07603588714622535
Trained batch 13 in epoch 11, gen_loss = 0.8392076662608555, disc_loss = 0.07402462738433055
Trained batch 14 in epoch 11, gen_loss = 0.8545786301294963, disc_loss = 0.07068942300975323
Trained batch 15 in epoch 11, gen_loss = 0.8464090302586555, disc_loss = 0.07036906585562974
Trained batch 16 in epoch 11, gen_loss = 0.8496428973534528, disc_loss = 0.06682089951765888
Trained batch 17 in epoch 11, gen_loss = 0.8443386124240028, disc_loss = 0.06694983830675483
Trained batch 18 in epoch 11, gen_loss = 0.86755738446587, disc_loss = 0.06810508565487046
Trained batch 19 in epoch 11, gen_loss = 0.869046351313591, disc_loss = 0.06682395352981985
Trained batch 20 in epoch 11, gen_loss = 0.8828097950844538, disc_loss = 0.06671179773374683
Trained batch 21 in epoch 11, gen_loss = 0.8684226409955458, disc_loss = 0.07017665165899829
Trained batch 22 in epoch 11, gen_loss = 0.8564709191736968, disc_loss = 0.07372724633339954
Trained batch 23 in epoch 11, gen_loss = 0.8613886535167694, disc_loss = 0.07302770061263193
Trained batch 24 in epoch 11, gen_loss = 0.8708419799804688, disc_loss = 0.07436815988272429
Trained batch 25 in epoch 11, gen_loss = 0.8594530683297378, disc_loss = 0.07639533234760165
Trained batch 26 in epoch 11, gen_loss = 0.8524027621304547, disc_loss = 0.07525350067212626
Trained batch 27 in epoch 11, gen_loss = 0.8445014527865818, disc_loss = 0.07652374433486589
Trained batch 28 in epoch 11, gen_loss = 0.8471594761157858, disc_loss = 0.07658843384606057
Trained batch 29 in epoch 11, gen_loss = 0.8506239652633667, disc_loss = 0.07758294390514493
Trained batch 30 in epoch 11, gen_loss = 0.8400014773491891, disc_loss = 0.0797436953251881
Trained batch 31 in epoch 11, gen_loss = 0.8336594142019749, disc_loss = 0.08018526082742028
Trained batch 32 in epoch 11, gen_loss = 0.8377057675159338, disc_loss = 0.07838664026084272
Trained batch 33 in epoch 11, gen_loss = 0.8452043638509863, disc_loss = 0.07702262132592938
Trained batch 34 in epoch 11, gen_loss = 0.8458449602127075, disc_loss = 0.07519084249756165
Trained batch 35 in epoch 11, gen_loss = 0.847630156411065, disc_loss = 0.0744551833356834
Trained batch 36 in epoch 11, gen_loss = 0.846835196018219, disc_loss = 0.07301252327758719
Trained batch 37 in epoch 11, gen_loss = 0.8481463146837134, disc_loss = 0.0731542248916077
Trained batch 38 in epoch 11, gen_loss = 0.8428535064061483, disc_loss = 0.07380057883281739
Trained batch 39 in epoch 11, gen_loss = 0.8381544321775436, disc_loss = 0.0731208639452234
Trained batch 40 in epoch 11, gen_loss = 0.83351166946132, disc_loss = 0.0727980107114446
Trained batch 41 in epoch 11, gen_loss = 0.833904885110401, disc_loss = 0.07260585001980265
Trained batch 42 in epoch 11, gen_loss = 0.8344517613566199, disc_loss = 0.07146152539915124
Trained batch 43 in epoch 11, gen_loss = 0.8346390507437966, disc_loss = 0.07043123370121149
Trained batch 44 in epoch 11, gen_loss = 0.8287079254786174, disc_loss = 0.0705671657083763
Trained batch 45 in epoch 11, gen_loss = 0.8312601343445156, disc_loss = 0.06964177409510898
Trained batch 46 in epoch 11, gen_loss = 0.8333428337218913, disc_loss = 0.06911671191374673
Trained batch 47 in epoch 11, gen_loss = 0.8379516204198202, disc_loss = 0.06821478738371904
Trained batch 48 in epoch 11, gen_loss = 0.8307837193109551, disc_loss = 0.07032641789362747
Trained batch 49 in epoch 11, gen_loss = 0.829763314127922, disc_loss = 0.07034004589542747
Trained batch 50 in epoch 11, gen_loss = 0.8289109485990861, disc_loss = 0.07046573862944748
Trained batch 51 in epoch 11, gen_loss = 0.8301081330730364, disc_loss = 0.07002941588871181
Trained batch 52 in epoch 11, gen_loss = 0.8326742890870796, disc_loss = 0.06892648140706543
Trained batch 53 in epoch 11, gen_loss = 0.8288868461494092, disc_loss = 0.06967530687581058
Trained batch 54 in epoch 11, gen_loss = 0.8324101377617229, disc_loss = 0.0696874004704031
Trained batch 55 in epoch 11, gen_loss = 0.8324460190321717, disc_loss = 0.06872344507636237
Trained batch 56 in epoch 11, gen_loss = 0.8324247697989146, disc_loss = 0.06846608742744777
Trained batch 57 in epoch 11, gen_loss = 0.827357729447299, disc_loss = 0.07020301036215548
Trained batch 58 in epoch 11, gen_loss = 0.8327546235868486, disc_loss = 0.0705104775695225
Trained batch 59 in epoch 11, gen_loss = 0.8307799741625785, disc_loss = 0.07085449433264633
Trained batch 60 in epoch 11, gen_loss = 0.8303114180682135, disc_loss = 0.07108812985300529
Trained batch 61 in epoch 11, gen_loss = 0.8305319937006119, disc_loss = 0.07122058419871234
Trained batch 62 in epoch 11, gen_loss = 0.8323035462508126, disc_loss = 0.07146197508665778
Trained batch 63 in epoch 11, gen_loss = 0.830670069437474, disc_loss = 0.07088373925944325
Trained batch 64 in epoch 11, gen_loss = 0.8330626959984119, disc_loss = 0.07014690584574755
Trained batch 65 in epoch 11, gen_loss = 0.8359037777691176, disc_loss = 0.06944748628037897
Trained batch 66 in epoch 11, gen_loss = 0.8325275658671536, disc_loss = 0.07046297263465266
Trained batch 67 in epoch 11, gen_loss = 0.8349689363556749, disc_loss = 0.0703023796873715
Trained batch 68 in epoch 11, gen_loss = 0.8356288304363472, disc_loss = 0.07006989698857069
Trained batch 69 in epoch 11, gen_loss = 0.8347301751375198, disc_loss = 0.06977847541815468
Trained batch 70 in epoch 11, gen_loss = 0.8350669779408146, disc_loss = 0.0708923520730205
Trained batch 71 in epoch 11, gen_loss = 0.8323808283441596, disc_loss = 0.07102553198476219
Trained batch 72 in epoch 11, gen_loss = 0.8314807957982364, disc_loss = 0.07178982259220865
Trained batch 73 in epoch 11, gen_loss = 0.8294520293538635, disc_loss = 0.07188235871443474
Trained batch 74 in epoch 11, gen_loss = 0.826694902976354, disc_loss = 0.07252536290635665
Trained batch 75 in epoch 11, gen_loss = 0.8284306145812336, disc_loss = 0.07176991231053283
Trained batch 76 in epoch 11, gen_loss = 0.8314039393678888, disc_loss = 0.07354094912963254
Trained batch 77 in epoch 11, gen_loss = 0.8303097528524888, disc_loss = 0.07319899655591983
Trained batch 78 in epoch 11, gen_loss = 0.8325536488732205, disc_loss = 0.07245958577605742
Trained batch 79 in epoch 11, gen_loss = 0.8296988490968943, disc_loss = 0.07516311453655362
Trained batch 80 in epoch 11, gen_loss = 0.8321218052763998, disc_loss = 0.07579646277942775
Trained batch 81 in epoch 11, gen_loss = 0.8289696635996423, disc_loss = 0.0758274434724959
Trained batch 82 in epoch 11, gen_loss = 0.832435761948666, disc_loss = 0.0759247511804822
Trained batch 83 in epoch 11, gen_loss = 0.8364095592073032, disc_loss = 0.0759139811354024
Trained batch 84 in epoch 11, gen_loss = 0.8340220251504112, disc_loss = 0.07727025659645305
Trained batch 85 in epoch 11, gen_loss = 0.8305083080086597, disc_loss = 0.07812669353429662
Trained batch 86 in epoch 11, gen_loss = 0.8313523986558805, disc_loss = 0.07892997031924369
Trained batch 87 in epoch 11, gen_loss = 0.8273058455776084, disc_loss = 0.07940585987473076
Trained batch 88 in epoch 11, gen_loss = 0.8310946684874846, disc_loss = 0.08025907942753159
Trained batch 89 in epoch 11, gen_loss = 0.8295948932568232, disc_loss = 0.08067823805742794
Trained batch 90 in epoch 11, gen_loss = 0.8304686064903553, disc_loss = 0.08009689270549424
Trained batch 91 in epoch 11, gen_loss = 0.8312682778291081, disc_loss = 0.0803060369849529
Trained batch 92 in epoch 11, gen_loss = 0.8315940432010158, disc_loss = 0.08012512856994265
Trained batch 93 in epoch 11, gen_loss = 0.8293202598678305, disc_loss = 0.07998815196704992
Trained batch 94 in epoch 11, gen_loss = 0.8293572843074799, disc_loss = 0.08003461041340702
Trained batch 95 in epoch 11, gen_loss = 0.8272911449894309, disc_loss = 0.07981694270468627
Trained batch 96 in epoch 11, gen_loss = 0.8292105999804035, disc_loss = 0.07933981395950637
Trained batch 97 in epoch 11, gen_loss = 0.8285771611393714, disc_loss = 0.07868065678381495
Trained batch 98 in epoch 11, gen_loss = 0.828252939563809, disc_loss = 0.07808604197708344
Trained batch 99 in epoch 11, gen_loss = 0.829086603820324, disc_loss = 0.07741779771633446
Trained batch 100 in epoch 11, gen_loss = 0.8285237990393497, disc_loss = 0.07693845650531572
Trained batch 101 in epoch 11, gen_loss = 0.8325841897258571, disc_loss = 0.07655754149434905
Trained batch 102 in epoch 11, gen_loss = 0.8306847518508874, disc_loss = 0.07634981740627764
Trained batch 103 in epoch 11, gen_loss = 0.8318038614323506, disc_loss = 0.07592779323637772
Trained batch 104 in epoch 11, gen_loss = 0.831012054000582, disc_loss = 0.07538195948693015
Trained batch 105 in epoch 11, gen_loss = 0.8331590803726664, disc_loss = 0.07478770983563561
Trained batch 106 in epoch 11, gen_loss = 0.8319496119690832, disc_loss = 0.07473704132695343
Trained batch 107 in epoch 11, gen_loss = 0.8351803800022161, disc_loss = 0.07448018570775511
Trained batch 108 in epoch 11, gen_loss = 0.8362925706106589, disc_loss = 0.07512256797881575
Trained batch 109 in epoch 11, gen_loss = 0.8339747469533574, disc_loss = 0.07524384877390482
Trained batch 110 in epoch 11, gen_loss = 0.8331432463349523, disc_loss = 0.07520452149313044
Trained batch 111 in epoch 11, gen_loss = 0.8319382915007216, disc_loss = 0.07492427528736048
Trained batch 112 in epoch 11, gen_loss = 0.8375466189025778, disc_loss = 0.07663433953493307
Trained batch 113 in epoch 11, gen_loss = 0.8371765940335759, disc_loss = 0.07620203240954301
Trained batch 114 in epoch 11, gen_loss = 0.8351275845714238, disc_loss = 0.07704505746293328
Trained batch 115 in epoch 11, gen_loss = 0.8357588224883737, disc_loss = 0.07810808763967762
Trained batch 116 in epoch 11, gen_loss = 0.8363589142632281, disc_loss = 0.07785389601834054
Trained batch 117 in epoch 11, gen_loss = 0.8383510943691609, disc_loss = 0.07759261861348808
Trained batch 118 in epoch 11, gen_loss = 0.8366674658130197, disc_loss = 0.0776013027986183
Trained batch 119 in epoch 11, gen_loss = 0.8356173031032086, disc_loss = 0.07749514968600124
Trained batch 120 in epoch 11, gen_loss = 0.8358070498163049, disc_loss = 0.0771189383192619
Trained batch 121 in epoch 11, gen_loss = 0.8354059797329981, disc_loss = 0.07687152602297605
Trained batch 122 in epoch 11, gen_loss = 0.8374657890176386, disc_loss = 0.07673175588280447
Trained batch 123 in epoch 11, gen_loss = 0.8369318614563634, disc_loss = 0.07668749264801943
Trained batch 124 in epoch 11, gen_loss = 0.8355820829868317, disc_loss = 0.07665004686266184
Trained batch 125 in epoch 11, gen_loss = 0.8339946646065939, disc_loss = 0.07703157447071539
Trained batch 126 in epoch 11, gen_loss = 0.8358292887060661, disc_loss = 0.079502827223889
Trained batch 127 in epoch 11, gen_loss = 0.8340106883551925, disc_loss = 0.07968299717322225
Trained batch 128 in epoch 11, gen_loss = 0.8328617924405622, disc_loss = 0.07966317257360202
Trained batch 129 in epoch 11, gen_loss = 0.8318921403242991, disc_loss = 0.07958492542831944
Trained batch 130 in epoch 11, gen_loss = 0.8320755437585233, disc_loss = 0.07919467653624201
Trained batch 131 in epoch 11, gen_loss = 0.8327166891910813, disc_loss = 0.07868635613527714
Trained batch 132 in epoch 11, gen_loss = 0.8320822377402083, disc_loss = 0.07853422281717447
Trained batch 133 in epoch 11, gen_loss = 0.833105172906349, disc_loss = 0.07855003662129391
Trained batch 134 in epoch 11, gen_loss = 0.8316583556157572, disc_loss = 0.07851785229587996
Trained batch 135 in epoch 11, gen_loss = 0.8311073764720384, disc_loss = 0.07844702961087666
Trained batch 136 in epoch 11, gen_loss = 0.830177891210918, disc_loss = 0.0782944215393632
Trained batch 137 in epoch 11, gen_loss = 0.8309997149567673, disc_loss = 0.07828352855437476
Trained batch 138 in epoch 11, gen_loss = 0.8310696025975317, disc_loss = 0.07825833823022654
Trained batch 139 in epoch 11, gen_loss = 0.8307992571166584, disc_loss = 0.07815861517031278
Trained batch 140 in epoch 11, gen_loss = 0.8293719750346867, disc_loss = 0.07811471107845189
Trained batch 141 in epoch 11, gen_loss = 0.8291743055615627, disc_loss = 0.07788216890636045
Trained batch 142 in epoch 11, gen_loss = 0.8292310081578634, disc_loss = 0.07751001059435882
Trained batch 143 in epoch 11, gen_loss = 0.8295593462470505, disc_loss = 0.07761658656980014
Trained batch 144 in epoch 11, gen_loss = 0.8292868386054861, disc_loss = 0.07741395945435968
Trained batch 145 in epoch 11, gen_loss = 0.8284713048232745, disc_loss = 0.07729646814859485
Trained batch 146 in epoch 11, gen_loss = 0.8296987063625232, disc_loss = 0.07697353629889536
Trained batch 147 in epoch 11, gen_loss = 0.8293041741928538, disc_loss = 0.07679442591914856
Trained batch 148 in epoch 11, gen_loss = 0.8273866206607563, disc_loss = 0.07716784755005532
Trained batch 149 in epoch 11, gen_loss = 0.8298229787747066, disc_loss = 0.07758201016734044
Trained batch 150 in epoch 11, gen_loss = 0.8306396747661742, disc_loss = 0.07748468238737015
Trained batch 151 in epoch 11, gen_loss = 0.8290609142890102, disc_loss = 0.07734994258192417
Trained batch 152 in epoch 11, gen_loss = 0.8301699389429653, disc_loss = 0.0770236554805165
Trained batch 153 in epoch 11, gen_loss = 0.828701959221394, disc_loss = 0.07774818312473498
Trained batch 154 in epoch 11, gen_loss = 0.8305721815555326, disc_loss = 0.07775703780353069
Trained batch 155 in epoch 11, gen_loss = 0.8307352006817476, disc_loss = 0.07749334306050187
Trained batch 156 in epoch 11, gen_loss = 0.8300301172551076, disc_loss = 0.07752124655540961
Trained batch 157 in epoch 11, gen_loss = 0.8288751702897156, disc_loss = 0.07730250099461668
Trained batch 158 in epoch 11, gen_loss = 0.8310273951329525, disc_loss = 0.07694779017811301
Trained batch 159 in epoch 11, gen_loss = 0.830643124319613, disc_loss = 0.07663069769041612
Trained batch 160 in epoch 11, gen_loss = 0.8310724432053773, disc_loss = 0.07631363639874118
Trained batch 161 in epoch 11, gen_loss = 0.8304878280118659, disc_loss = 0.07612531950674307
Trained batch 162 in epoch 11, gen_loss = 0.8303316866327648, disc_loss = 0.07574783484422905
Trained batch 163 in epoch 11, gen_loss = 0.8323688170895344, disc_loss = 0.07585594666235876
Trained batch 164 in epoch 11, gen_loss = 0.8328998881759065, disc_loss = 0.07552308888936585
Trained batch 165 in epoch 11, gen_loss = 0.831709525850882, disc_loss = 0.07563271025105951
Trained batch 166 in epoch 11, gen_loss = 0.8314100834066996, disc_loss = 0.07536063387343091
Trained batch 167 in epoch 11, gen_loss = 0.8317263688714731, disc_loss = 0.07519045731030582
Trained batch 168 in epoch 11, gen_loss = 0.8345066606998444, disc_loss = 0.07561527899626268
Trained batch 169 in epoch 11, gen_loss = 0.8347494477734846, disc_loss = 0.07530339348732548
Trained batch 170 in epoch 11, gen_loss = 0.8338881056559714, disc_loss = 0.07547295604946844
Trained batch 171 in epoch 11, gen_loss = 0.8344635660218638, disc_loss = 0.07567816346255672
Trained batch 172 in epoch 11, gen_loss = 0.8356020273156248, disc_loss = 0.07535013011145282
Trained batch 173 in epoch 11, gen_loss = 0.8353611472351797, disc_loss = 0.07518985817722719
Trained batch 174 in epoch 11, gen_loss = 0.833107122864042, disc_loss = 0.07566616076976061
Trained batch 175 in epoch 11, gen_loss = 0.8326688143001362, disc_loss = 0.07554813852766529
Trained batch 176 in epoch 11, gen_loss = 0.8326883081999202, disc_loss = 0.0756490504327046
Trained batch 177 in epoch 11, gen_loss = 0.8329843863677443, disc_loss = 0.0753652384933712
Trained batch 178 in epoch 11, gen_loss = 0.8328887302449296, disc_loss = 0.07522709644269511
Trained batch 179 in epoch 11, gen_loss = 0.8324295194612609, disc_loss = 0.07509318984941477
Trained batch 180 in epoch 11, gen_loss = 0.8324187692686997, disc_loss = 0.07498786698779843
Trained batch 181 in epoch 11, gen_loss = 0.8316903450004347, disc_loss = 0.07479431624984839
Trained batch 182 in epoch 11, gen_loss = 0.8320077261963829, disc_loss = 0.07467574967692296
Trained batch 183 in epoch 11, gen_loss = 0.831887830696676, disc_loss = 0.07449238698261426
Trained batch 184 in epoch 11, gen_loss = 0.8313656035307292, disc_loss = 0.07431532003086161
Trained batch 185 in epoch 11, gen_loss = 0.8303737879119893, disc_loss = 0.0744678676879454
Trained batch 186 in epoch 11, gen_loss = 0.832126971393983, disc_loss = 0.07432770134911021
Trained batch 187 in epoch 11, gen_loss = 0.8323620616438541, disc_loss = 0.07403686354828483
Trained batch 188 in epoch 11, gen_loss = 0.8326072470536308, disc_loss = 0.0738553970648104
Trained batch 189 in epoch 11, gen_loss = 0.8314282657284485, disc_loss = 0.07401335182060537
Trained batch 190 in epoch 11, gen_loss = 0.8326474816699303, disc_loss = 0.07410682286794117
Trained batch 191 in epoch 11, gen_loss = 0.8315652517291406, disc_loss = 0.07413862033960565
Trained batch 192 in epoch 11, gen_loss = 0.8303803491160042, disc_loss = 0.07445702884693683
Trained batch 193 in epoch 11, gen_loss = 0.8317495751933953, disc_loss = 0.07530453748828203
Trained batch 194 in epoch 11, gen_loss = 0.8319485788161938, disc_loss = 0.07513422646488134
Trained batch 195 in epoch 11, gen_loss = 0.8308112850906898, disc_loss = 0.07614788688168082
Trained batch 196 in epoch 11, gen_loss = 0.8314285325217368, disc_loss = 0.07620837790466051
Trained batch 197 in epoch 11, gen_loss = 0.8313976684302995, disc_loss = 0.07612390253184871
Trained batch 198 in epoch 11, gen_loss = 0.8324248528660242, disc_loss = 0.07609754644952078
Trained batch 199 in epoch 11, gen_loss = 0.8324152208864689, disc_loss = 0.07582201312761754
Trained batch 200 in epoch 11, gen_loss = 0.8307276071600653, disc_loss = 0.07692195596961092
Trained batch 201 in epoch 11, gen_loss = 0.8308538824024767, disc_loss = 0.07709391967919056
Trained batch 202 in epoch 11, gen_loss = 0.8333230464916511, disc_loss = 0.07725797828029969
Trained batch 203 in epoch 11, gen_loss = 0.8344256649999058, disc_loss = 0.07738246129113524
Trained batch 204 in epoch 11, gen_loss = 0.8337861950804547, disc_loss = 0.07787540500029558
Trained batch 205 in epoch 11, gen_loss = 0.8332337039766959, disc_loss = 0.07847431211198852
Trained batch 206 in epoch 11, gen_loss = 0.8334839525430099, disc_loss = 0.07898210150590121
Trained batch 207 in epoch 11, gen_loss = 0.8337957770205461, disc_loss = 0.0797715359322655
Trained batch 208 in epoch 11, gen_loss = 0.8331072678406273, disc_loss = 0.0798091296614571
Trained batch 209 in epoch 11, gen_loss = 0.8333422010853178, disc_loss = 0.07969110593465822
Trained batch 210 in epoch 11, gen_loss = 0.8337414826827027, disc_loss = 0.07957503068485955
Trained batch 211 in epoch 11, gen_loss = 0.8328590010696987, disc_loss = 0.07962106705537804
Trained batch 212 in epoch 11, gen_loss = 0.8334132849890301, disc_loss = 0.07932298295986905
Trained batch 213 in epoch 11, gen_loss = 0.8327817290185768, disc_loss = 0.07930940300417698
Trained batch 214 in epoch 11, gen_loss = 0.8331955643587334, disc_loss = 0.07950538075853919
Trained batch 215 in epoch 11, gen_loss = 0.8335967982808749, disc_loss = 0.07932186272874889
Trained batch 216 in epoch 11, gen_loss = 0.8334892702542143, disc_loss = 0.07916834546587846
Trained batch 217 in epoch 11, gen_loss = 0.833924673292615, disc_loss = 0.07888870456879703
Trained batch 218 in epoch 11, gen_loss = 0.8327492671470119, disc_loss = 0.0790312506862359
Trained batch 219 in epoch 11, gen_loss = 0.8335498631000519, disc_loss = 0.07898295213129711
Trained batch 220 in epoch 11, gen_loss = 0.8352638617899623, disc_loss = 0.07881879114979937
Trained batch 221 in epoch 11, gen_loss = 0.8359812063139838, disc_loss = 0.07856209592490986
Trained batch 222 in epoch 11, gen_loss = 0.8353060900897723, disc_loss = 0.07854069257781511
Trained batch 223 in epoch 11, gen_loss = 0.834538049729807, disc_loss = 0.07865884809871204
Trained batch 224 in epoch 11, gen_loss = 0.8356994281874762, disc_loss = 0.07897107643799649
Trained batch 225 in epoch 11, gen_loss = 0.8373951983135358, disc_loss = 0.07884247333586084
Trained batch 226 in epoch 11, gen_loss = 0.8376682671156224, disc_loss = 0.07861405172455022
Trained batch 227 in epoch 11, gen_loss = 0.8365526646375656, disc_loss = 0.07899868404574431
Trained batch 228 in epoch 11, gen_loss = 0.8368862698171857, disc_loss = 0.07878675706700856
Trained batch 229 in epoch 11, gen_loss = 0.8380249539147253, disc_loss = 0.0785678274727062
Trained batch 230 in epoch 11, gen_loss = 0.8378058354575912, disc_loss = 0.0784108265710277
Trained batch 231 in epoch 11, gen_loss = 0.8391531826607113, disc_loss = 0.07846796597305943
Trained batch 232 in epoch 11, gen_loss = 0.8387157556325069, disc_loss = 0.07860476591988055
Trained batch 233 in epoch 11, gen_loss = 0.8384969463715186, disc_loss = 0.0785474812046776
Trained batch 234 in epoch 11, gen_loss = 0.8388280016310672, disc_loss = 0.07827438923351943
Trained batch 235 in epoch 11, gen_loss = 0.8389437092562854, disc_loss = 0.07813621503774519
Trained batch 236 in epoch 11, gen_loss = 0.8385205190895982, disc_loss = 0.07790765382019402
Trained batch 237 in epoch 11, gen_loss = 0.8372484673472012, disc_loss = 0.07786775773641567
Trained batch 238 in epoch 11, gen_loss = 0.8378804321069597, disc_loss = 0.07767884980762478
Trained batch 239 in epoch 11, gen_loss = 0.8374329489966233, disc_loss = 0.07781391490328436
Trained batch 240 in epoch 11, gen_loss = 0.8367960705302069, disc_loss = 0.07777717838226142
Trained batch 241 in epoch 11, gen_loss = 0.836854733957732, disc_loss = 0.07786279306015816
Trained batch 242 in epoch 11, gen_loss = 0.8368951089588212, disc_loss = 0.07768961928646874
Trained batch 243 in epoch 11, gen_loss = 0.8367894216150534, disc_loss = 0.07751843199271281
Trained batch 244 in epoch 11, gen_loss = 0.836798623873263, disc_loss = 0.0773070370018178
Trained batch 245 in epoch 11, gen_loss = 0.8378192227545792, disc_loss = 0.07708658092859678
Trained batch 246 in epoch 11, gen_loss = 0.837249546398518, disc_loss = 0.07700139900616668
Trained batch 247 in epoch 11, gen_loss = 0.8373814056957921, disc_loss = 0.07680684560534334
Trained batch 248 in epoch 11, gen_loss = 0.8375256999908202, disc_loss = 0.07660324028113401
Trained batch 249 in epoch 11, gen_loss = 0.8375225496292115, disc_loss = 0.0763618874065578
Trained batch 250 in epoch 11, gen_loss = 0.8372083009476681, disc_loss = 0.07633650149645439
Trained batch 251 in epoch 11, gen_loss = 0.8376515505332796, disc_loss = 0.07642291413457503
Trained batch 252 in epoch 11, gen_loss = 0.8377302359686538, disc_loss = 0.07626410922322702
Trained batch 253 in epoch 11, gen_loss = 0.8369323343742551, disc_loss = 0.07664682356435365
Trained batch 254 in epoch 11, gen_loss = 0.8370221970128078, disc_loss = 0.07642748373031032
Trained batch 255 in epoch 11, gen_loss = 0.8375473520718515, disc_loss = 0.07632340056807152
Trained batch 256 in epoch 11, gen_loss = 0.8366375593359833, disc_loss = 0.07670775290346679
Trained batch 257 in epoch 11, gen_loss = 0.8359933590242105, disc_loss = 0.07688499712421334
Trained batch 258 in epoch 11, gen_loss = 0.8360975292658713, disc_loss = 0.07686083044310218
Trained batch 259 in epoch 11, gen_loss = 0.8355854976635713, disc_loss = 0.07693445750942024
Trained batch 260 in epoch 11, gen_loss = 0.8360426364273861, disc_loss = 0.07686298542880807
Trained batch 261 in epoch 11, gen_loss = 0.8364671900982165, disc_loss = 0.07701915778034857
Trained batch 262 in epoch 11, gen_loss = 0.8351589463962802, disc_loss = 0.07733925601587889
Trained batch 263 in epoch 11, gen_loss = 0.8353724328405929, disc_loss = 0.07712472541695178
Trained batch 264 in epoch 11, gen_loss = 0.8364691439664589, disc_loss = 0.07713300603670331
Trained batch 265 in epoch 11, gen_loss = 0.8360802125661893, disc_loss = 0.07703911872664676
Trained batch 266 in epoch 11, gen_loss = 0.835395202208101, disc_loss = 0.0771872860934125
Trained batch 267 in epoch 11, gen_loss = 0.8350701349884716, disc_loss = 0.07737882272340357
Trained batch 268 in epoch 11, gen_loss = 0.8353920002852231, disc_loss = 0.07714945606568821
Trained batch 269 in epoch 11, gen_loss = 0.834843588758398, disc_loss = 0.07710022139535458
Trained batch 270 in epoch 11, gen_loss = 0.8350072296343166, disc_loss = 0.076896234848485
Trained batch 271 in epoch 11, gen_loss = 0.834369588205043, disc_loss = 0.07696710805997581
Trained batch 272 in epoch 11, gen_loss = 0.8336673038346427, disc_loss = 0.07698802878882313
Trained batch 273 in epoch 11, gen_loss = 0.8347968578773693, disc_loss = 0.07707485727571549
Trained batch 274 in epoch 11, gen_loss = 0.8344069138440219, disc_loss = 0.07688404445959764
Trained batch 275 in epoch 11, gen_loss = 0.8333822024473245, disc_loss = 0.07699120854216533
Trained batch 276 in epoch 11, gen_loss = 0.8340146139210312, disc_loss = 0.07681682622161044
Trained batch 277 in epoch 11, gen_loss = 0.833993083495888, disc_loss = 0.07662158111351536
Trained batch 278 in epoch 11, gen_loss = 0.8339757406583397, disc_loss = 0.0767818455981578
Trained batch 279 in epoch 11, gen_loss = 0.8337254549775804, disc_loss = 0.076655778611478
Trained batch 280 in epoch 11, gen_loss = 0.8334045418640897, disc_loss = 0.07661218580945636
Trained batch 281 in epoch 11, gen_loss = 0.8320329686005911, disc_loss = 0.07685917204060981
Trained batch 282 in epoch 11, gen_loss = 0.832205526609724, disc_loss = 0.076752255802362
Trained batch 283 in epoch 11, gen_loss = 0.8334924165211933, disc_loss = 0.07672939764689916
Trained batch 284 in epoch 11, gen_loss = 0.8340026087928236, disc_loss = 0.07677429444238282
Trained batch 285 in epoch 11, gen_loss = 0.833311995426258, disc_loss = 0.0770099335024459
Trained batch 286 in epoch 11, gen_loss = 0.832919504999699, disc_loss = 0.07689794420689759
Trained batch 287 in epoch 11, gen_loss = 0.8321362831112411, disc_loss = 0.07718907121064451
Trained batch 288 in epoch 11, gen_loss = 0.8322930742300093, disc_loss = 0.07715557838200389
Trained batch 289 in epoch 11, gen_loss = 0.8330774416183603, disc_loss = 0.07701597305271646
Trained batch 290 in epoch 11, gen_loss = 0.8332948019004769, disc_loss = 0.07695023029645796
Trained batch 291 in epoch 11, gen_loss = 0.8321956567568322, disc_loss = 0.07782853389962589
Trained batch 292 in epoch 11, gen_loss = 0.8332973031053771, disc_loss = 0.07781163181270451
Trained batch 293 in epoch 11, gen_loss = 0.8337371531797915, disc_loss = 0.07772931188256257
Trained batch 294 in epoch 11, gen_loss = 0.8338993593797845, disc_loss = 0.07758674486777035
Trained batch 295 in epoch 11, gen_loss = 0.8334006300649127, disc_loss = 0.07758105774347142
Trained batch 296 in epoch 11, gen_loss = 0.8334132400827375, disc_loss = 0.07741855102769955
Trained batch 297 in epoch 11, gen_loss = 0.8339838577596933, disc_loss = 0.0779678148792544
Trained batch 298 in epoch 11, gen_loss = 0.8332186125991337, disc_loss = 0.07826101448835437
Trained batch 299 in epoch 11, gen_loss = 0.8327135781447093, disc_loss = 0.07845322338553766
Trained batch 300 in epoch 11, gen_loss = 0.8323969650902225, disc_loss = 0.07843938762278752
Trained batch 301 in epoch 11, gen_loss = 0.8316985828592288, disc_loss = 0.0792643513240611
Trained batch 302 in epoch 11, gen_loss = 0.8306196414598144, disc_loss = 0.07981797969491274
Trained batch 303 in epoch 11, gen_loss = 0.8313210702648288, disc_loss = 0.08024589472609621
Trained batch 304 in epoch 11, gen_loss = 0.8311582792000692, disc_loss = 0.08007774153022004
Trained batch 305 in epoch 11, gen_loss = 0.8308415821954316, disc_loss = 0.08004927815674664
Trained batch 306 in epoch 11, gen_loss = 0.8300070189886062, disc_loss = 0.08013744887983858
Trained batch 307 in epoch 11, gen_loss = 0.8292299607744464, disc_loss = 0.08031763240707095
Trained batch 308 in epoch 11, gen_loss = 0.8290469636809092, disc_loss = 0.08027007134516745
Trained batch 309 in epoch 11, gen_loss = 0.8297809664280184, disc_loss = 0.08023154918525008
Trained batch 310 in epoch 11, gen_loss = 0.829128672455668, disc_loss = 0.08018144321031988
Trained batch 311 in epoch 11, gen_loss = 0.8303009099685229, disc_loss = 0.08013356909549867
Trained batch 312 in epoch 11, gen_loss = 0.8295584216285438, disc_loss = 0.08033268427708373
Trained batch 313 in epoch 11, gen_loss = 0.8295076591953351, disc_loss = 0.08019310958790267
Trained batch 314 in epoch 11, gen_loss = 0.82929166441872, disc_loss = 0.08008009922941998
Trained batch 315 in epoch 11, gen_loss = 0.8298480007090147, disc_loss = 0.07994251944938133
Trained batch 316 in epoch 11, gen_loss = 0.8298511875540676, disc_loss = 0.07995935446327135
Trained batch 317 in epoch 11, gen_loss = 0.8293957734632792, disc_loss = 0.0799843863548957
Trained batch 318 in epoch 11, gen_loss = 0.8288374389974301, disc_loss = 0.08002334942042734
Trained batch 319 in epoch 11, gen_loss = 0.8281700821593404, disc_loss = 0.0800197502510855
Trained batch 320 in epoch 11, gen_loss = 0.8286148092457067, disc_loss = 0.08023693112256093
Trained batch 321 in epoch 11, gen_loss = 0.828473585918083, disc_loss = 0.08010888681891634
Trained batch 322 in epoch 11, gen_loss = 0.8295258532736692, disc_loss = 0.07999276398931955
Trained batch 323 in epoch 11, gen_loss = 0.8285451581080755, disc_loss = 0.08032388128857645
Trained batch 324 in epoch 11, gen_loss = 0.8289223966231712, disc_loss = 0.08017374837914339
Trained batch 325 in epoch 11, gen_loss = 0.8290408858858003, disc_loss = 0.08017761979332091
Trained batch 326 in epoch 11, gen_loss = 0.828390258350139, disc_loss = 0.08016076468967973
Trained batch 327 in epoch 11, gen_loss = 0.8281516619935269, disc_loss = 0.08002414696611374
Trained batch 328 in epoch 11, gen_loss = 0.8280121238398335, disc_loss = 0.08000289636598985
Trained batch 329 in epoch 11, gen_loss = 0.8274063363219752, disc_loss = 0.07988950613829675
Trained batch 330 in epoch 11, gen_loss = 0.827326060241803, disc_loss = 0.07973658201478849
Trained batch 331 in epoch 11, gen_loss = 0.8275377389537283, disc_loss = 0.0796562718053584
Trained batch 332 in epoch 11, gen_loss = 0.8270284440424349, disc_loss = 0.0795282151343094
Trained batch 333 in epoch 11, gen_loss = 0.827379646237025, disc_loss = 0.0794248142625445
Trained batch 334 in epoch 11, gen_loss = 0.8265967153791172, disc_loss = 0.07965663046812388
Trained batch 335 in epoch 11, gen_loss = 0.82756475305983, disc_loss = 0.08005557535493392
Trained batch 336 in epoch 11, gen_loss = 0.8277052490576792, disc_loss = 0.07994797159516935
Trained batch 337 in epoch 11, gen_loss = 0.8273676977707789, disc_loss = 0.07981673935869124
Trained batch 338 in epoch 11, gen_loss = 0.8275864790674508, disc_loss = 0.0796122746322315
Trained batch 339 in epoch 11, gen_loss = 0.827668500121902, disc_loss = 0.0794833519085146
Trained batch 340 in epoch 11, gen_loss = 0.8270247998125742, disc_loss = 0.07949107779118934
Trained batch 341 in epoch 11, gen_loss = 0.826287355339318, disc_loss = 0.07958018209796115
Trained batch 342 in epoch 11, gen_loss = 0.8268498164919306, disc_loss = 0.07949603178182688
Trained batch 343 in epoch 11, gen_loss = 0.8269392932916797, disc_loss = 0.07937790272313408
Trained batch 344 in epoch 11, gen_loss = 0.8271169621011485, disc_loss = 0.07925035921937745
Trained batch 345 in epoch 11, gen_loss = 0.8268930727691319, disc_loss = 0.0791844546746441
Trained batch 346 in epoch 11, gen_loss = 0.8264908543237691, disc_loss = 0.07916636510298558
Trained batch 347 in epoch 11, gen_loss = 0.8269623668714502, disc_loss = 0.07948781437261951
Trained batch 348 in epoch 11, gen_loss = 0.8271293694788542, disc_loss = 0.07933829186009217
Trained batch 349 in epoch 11, gen_loss = 0.8271942894799369, disc_loss = 0.07915781536006501
Trained batch 350 in epoch 11, gen_loss = 0.8273217768071384, disc_loss = 0.07900558983869957
Trained batch 351 in epoch 11, gen_loss = 0.8280145192349498, disc_loss = 0.0788243270045231
Trained batch 352 in epoch 11, gen_loss = 0.8281676298160391, disc_loss = 0.0786678828140747
Trained batch 353 in epoch 11, gen_loss = 0.8278157975377336, disc_loss = 0.07856572726162644
Trained batch 354 in epoch 11, gen_loss = 0.8284016839215453, disc_loss = 0.07839934260807407
Trained batch 355 in epoch 11, gen_loss = 0.828420688597004, disc_loss = 0.07830066927133149
Trained batch 356 in epoch 11, gen_loss = 0.8283794607434954, disc_loss = 0.07818426523117625
Trained batch 357 in epoch 11, gen_loss = 0.827948063112504, disc_loss = 0.07813171051213695
Trained batch 358 in epoch 11, gen_loss = 0.827525547952041, disc_loss = 0.07801422461722056
Trained batch 359 in epoch 11, gen_loss = 0.8286606709162394, disc_loss = 0.07818714174855915
Trained batch 360 in epoch 11, gen_loss = 0.8280862408001337, disc_loss = 0.07828744081393338
Trained batch 361 in epoch 11, gen_loss = 0.8277363973098565, disc_loss = 0.07815535650048303
Trained batch 362 in epoch 11, gen_loss = 0.8283494068899759, disc_loss = 0.07823943947608641
Trained batch 363 in epoch 11, gen_loss = 0.8282927499040142, disc_loss = 0.07825506850565364
Trained batch 364 in epoch 11, gen_loss = 0.8276593846817539, disc_loss = 0.07851740223393865
Trained batch 365 in epoch 11, gen_loss = 0.8276444680052377, disc_loss = 0.07883643049013908
Trained batch 366 in epoch 11, gen_loss = 0.827532622729725, disc_loss = 0.07874769982894532
Trained batch 367 in epoch 11, gen_loss = 0.8275017663836479, disc_loss = 0.07864905834582675
Trained batch 368 in epoch 11, gen_loss = 0.8271097227486814, disc_loss = 0.0787387336970264
Trained batch 369 in epoch 11, gen_loss = 0.8267355472654909, disc_loss = 0.07867750805878156
Trained batch 370 in epoch 11, gen_loss = 0.827212154543946, disc_loss = 0.07852994171134385
Trained batch 371 in epoch 11, gen_loss = 0.8277109542521097, disc_loss = 0.07844618224709105
Trained batch 372 in epoch 11, gen_loss = 0.828277607545776, disc_loss = 0.07851700036818955
Trained batch 373 in epoch 11, gen_loss = 0.828114819877288, disc_loss = 0.07858585605626917
Trained batch 374 in epoch 11, gen_loss = 0.8277832644780477, disc_loss = 0.07880163231988747
Trained batch 375 in epoch 11, gen_loss = 0.827154796174232, disc_loss = 0.07915065476690676
Trained batch 376 in epoch 11, gen_loss = 0.8270406014723234, disc_loss = 0.0793487117316979
Trained batch 377 in epoch 11, gen_loss = 0.8266454236532645, disc_loss = 0.07952319976021216
Trained batch 378 in epoch 11, gen_loss = 0.8262917779995458, disc_loss = 0.07949411392821329
Trained batch 379 in epoch 11, gen_loss = 0.8264455850187101, disc_loss = 0.07950740479619095
Trained batch 380 in epoch 11, gen_loss = 0.8262115668436987, disc_loss = 0.07941312213328097
Trained batch 381 in epoch 11, gen_loss = 0.8256271094551886, disc_loss = 0.07943639962285445
Trained batch 382 in epoch 11, gen_loss = 0.8253640745700807, disc_loss = 0.07936404555471853
Trained batch 383 in epoch 11, gen_loss = 0.8258667622382442, disc_loss = 0.07925028320460115
Trained batch 384 in epoch 11, gen_loss = 0.8261716763694565, disc_loss = 0.07918098716476521
Trained batch 385 in epoch 11, gen_loss = 0.825982898782572, disc_loss = 0.07906015588385608
Trained batch 386 in epoch 11, gen_loss = 0.8252495921551412, disc_loss = 0.07925945139689809
Trained batch 387 in epoch 11, gen_loss = 0.8257442497715508, disc_loss = 0.07918960695663832
Trained batch 388 in epoch 11, gen_loss = 0.8258213733339678, disc_loss = 0.0790531025112518
Trained batch 389 in epoch 11, gen_loss = 0.8257538474523104, disc_loss = 0.07895761211044514
Trained batch 390 in epoch 11, gen_loss = 0.8251709739875306, disc_loss = 0.07903754984116768
Trained batch 391 in epoch 11, gen_loss = 0.8247543623556897, disc_loss = 0.07902568117335286
Trained batch 392 in epoch 11, gen_loss = 0.8257706145597171, disc_loss = 0.07908548595284233
Trained batch 393 in epoch 11, gen_loss = 0.8253138357310126, disc_loss = 0.07913319296132641
Trained batch 394 in epoch 11, gen_loss = 0.8250198350677007, disc_loss = 0.07911487435332581
Trained batch 395 in epoch 11, gen_loss = 0.8253850017232124, disc_loss = 0.07900131325886557
Trained batch 396 in epoch 11, gen_loss = 0.8260023544357166, disc_loss = 0.07890953969501278
Trained batch 397 in epoch 11, gen_loss = 0.8257311985420821, disc_loss = 0.07889420750209285
Trained batch 398 in epoch 11, gen_loss = 0.8252708465234379, disc_loss = 0.07887561301371657
Trained batch 399 in epoch 11, gen_loss = 0.8252182333171367, disc_loss = 0.07878318385686725
Trained batch 400 in epoch 11, gen_loss = 0.8249980822168383, disc_loss = 0.07872194461896087
Trained batch 401 in epoch 11, gen_loss = 0.8251957399631614, disc_loss = 0.07859948807076286
Trained batch 402 in epoch 11, gen_loss = 0.8265106975292745, disc_loss = 0.07859517590930828
Trained batch 403 in epoch 11, gen_loss = 0.8259653304473008, disc_loss = 0.07865443137372927
Trained batch 404 in epoch 11, gen_loss = 0.8253216943623107, disc_loss = 0.0787645884640055
Trained batch 405 in epoch 11, gen_loss = 0.8254925414846448, disc_loss = 0.07868314250441168
Trained batch 406 in epoch 11, gen_loss = 0.8257325719263982, disc_loss = 0.07852267033216848
Trained batch 407 in epoch 11, gen_loss = 0.8256532611215815, disc_loss = 0.07849576346594475
Trained batch 408 in epoch 11, gen_loss = 0.82616433829142, disc_loss = 0.07834455850909858
Trained batch 409 in epoch 11, gen_loss = 0.8265311155377365, disc_loss = 0.07819016803192293
Trained batch 410 in epoch 11, gen_loss = 0.8272098817674493, disc_loss = 0.07814387817824046
Trained batch 411 in epoch 11, gen_loss = 0.8266708195498846, disc_loss = 0.07827687748364236
Trained batch 412 in epoch 11, gen_loss = 0.8265028857145702, disc_loss = 0.07819375055943577
Trained batch 413 in epoch 11, gen_loss = 0.8273123384673814, disc_loss = 0.07848528807910816
Trained batch 414 in epoch 11, gen_loss = 0.8275110332362623, disc_loss = 0.0783664789118142
Trained batch 415 in epoch 11, gen_loss = 0.8270457007277471, disc_loss = 0.07828489775420167
Trained batch 416 in epoch 11, gen_loss = 0.8271218448234119, disc_loss = 0.07816132910022561
Trained batch 417 in epoch 11, gen_loss = 0.8274153113079984, disc_loss = 0.07803563510500001
Trained batch 418 in epoch 11, gen_loss = 0.8273222004030086, disc_loss = 0.07792706781140304
Trained batch 419 in epoch 11, gen_loss = 0.8280345236971265, disc_loss = 0.07822479152209347
Trained batch 420 in epoch 11, gen_loss = 0.8275085890094911, disc_loss = 0.07820192903873119
Trained batch 421 in epoch 11, gen_loss = 0.8271472478082394, disc_loss = 0.07819646895946979
Trained batch 422 in epoch 11, gen_loss = 0.8270490520389367, disc_loss = 0.07817680449236017
Trained batch 423 in epoch 11, gen_loss = 0.8272718650833616, disc_loss = 0.07830188197373711
Trained batch 424 in epoch 11, gen_loss = 0.8269262203048258, disc_loss = 0.07844129252740566
Trained batch 425 in epoch 11, gen_loss = 0.8280955330586769, disc_loss = 0.07854923146597587
Trained batch 426 in epoch 11, gen_loss = 0.8275356214554583, disc_loss = 0.07858574473074434
Trained batch 427 in epoch 11, gen_loss = 0.8272039945994583, disc_loss = 0.07851046622974502
Trained batch 428 in epoch 11, gen_loss = 0.8279723170753959, disc_loss = 0.0786206939676668
Trained batch 429 in epoch 11, gen_loss = 0.8272981631201367, disc_loss = 0.07881322759311907
Trained batch 430 in epoch 11, gen_loss = 0.8271522913344221, disc_loss = 0.07881226604739572
Trained batch 431 in epoch 11, gen_loss = 0.827089944233497, disc_loss = 0.07869137162816953
Trained batch 432 in epoch 11, gen_loss = 0.8267809857397102, disc_loss = 0.07865637432198808
Trained batch 433 in epoch 11, gen_loss = 0.8270006336374767, disc_loss = 0.07865269705095256
Trained batch 434 in epoch 11, gen_loss = 0.8268594656867543, disc_loss = 0.07884571798702424
Trained batch 435 in epoch 11, gen_loss = 0.8273077303663307, disc_loss = 0.07869409417537032
Trained batch 436 in epoch 11, gen_loss = 0.8267768757839771, disc_loss = 0.07882204406108341
Trained batch 437 in epoch 11, gen_loss = 0.8266192218756567, disc_loss = 0.07880479209422725
Trained batch 438 in epoch 11, gen_loss = 0.8273806684652603, disc_loss = 0.07868975080795806
Trained batch 439 in epoch 11, gen_loss = 0.827084998244589, disc_loss = 0.07862887233284048
Trained batch 440 in epoch 11, gen_loss = 0.827169384140006, disc_loss = 0.078576541505754
Trained batch 441 in epoch 11, gen_loss = 0.8270543982270616, disc_loss = 0.07850423015072537
Trained batch 442 in epoch 11, gen_loss = 0.8275177964507592, disc_loss = 0.07875865621967389
Trained batch 443 in epoch 11, gen_loss = 0.827291865472321, disc_loss = 0.07873022703764339
Trained batch 444 in epoch 11, gen_loss = 0.8269615023323659, disc_loss = 0.07871589260280468
Trained batch 445 in epoch 11, gen_loss = 0.82719839995752, disc_loss = 0.07865361379659964
Trained batch 446 in epoch 11, gen_loss = 0.8269368936818184, disc_loss = 0.07860498087609841
Trained batch 447 in epoch 11, gen_loss = 0.8275255346670747, disc_loss = 0.07872112345441044
Trained batch 448 in epoch 11, gen_loss = 0.8272396137560396, disc_loss = 0.07900792895245858
Trained batch 449 in epoch 11, gen_loss = 0.8277415267626445, disc_loss = 0.07899477932809128
Trained batch 450 in epoch 11, gen_loss = 0.8274067883480943, disc_loss = 0.07902972932756278
Trained batch 451 in epoch 11, gen_loss = 0.8278546446720055, disc_loss = 0.07893381973901616
Trained batch 452 in epoch 11, gen_loss = 0.8279265841637753, disc_loss = 0.07881672703609627
Trained batch 453 in epoch 11, gen_loss = 0.8282229108694892, disc_loss = 0.0788205241074679
Trained batch 454 in epoch 11, gen_loss = 0.8278442004224756, disc_loss = 0.07891098889880456
Trained batch 455 in epoch 11, gen_loss = 0.8277544598830374, disc_loss = 0.07888085793973387
Trained batch 456 in epoch 11, gen_loss = 0.8278529192738773, disc_loss = 0.07880103496194733
Trained batch 457 in epoch 11, gen_loss = 0.8277155470639858, disc_loss = 0.07885729659177916
Trained batch 458 in epoch 11, gen_loss = 0.8274901881976325, disc_loss = 0.07881198868293453
Trained batch 459 in epoch 11, gen_loss = 0.8281456452348958, disc_loss = 0.07870421527237025
Trained batch 460 in epoch 11, gen_loss = 0.8283809007119202, disc_loss = 0.07857756091407025
Trained batch 461 in epoch 11, gen_loss = 0.8280831979208695, disc_loss = 0.07853040933101015
Trained batch 462 in epoch 11, gen_loss = 0.8281176957919325, disc_loss = 0.07843686107015056
Trained batch 463 in epoch 11, gen_loss = 0.8283987261098007, disc_loss = 0.0783088762606173
Trained batch 464 in epoch 11, gen_loss = 0.8288439063615697, disc_loss = 0.07817054687328236
Trained batch 465 in epoch 11, gen_loss = 0.8284276245489652, disc_loss = 0.07813112507274478
Trained batch 466 in epoch 11, gen_loss = 0.8282420750093153, disc_loss = 0.0781021820704355
Trained batch 467 in epoch 11, gen_loss = 0.8285154617495007, disc_loss = 0.07842048317289506
Trained batch 468 in epoch 11, gen_loss = 0.8281064807479062, disc_loss = 0.07846690281463076
Trained batch 469 in epoch 11, gen_loss = 0.8277772770283071, disc_loss = 0.07841749683498069
Trained batch 470 in epoch 11, gen_loss = 0.8275433159937524, disc_loss = 0.0784078685926657
Trained batch 471 in epoch 11, gen_loss = 0.8276708314226846, disc_loss = 0.0785039521643292
Trained batch 472 in epoch 11, gen_loss = 0.8276704137723492, disc_loss = 0.07839112029456186
Trained batch 473 in epoch 11, gen_loss = 0.8272398336778714, disc_loss = 0.07851267774208186
Trained batch 474 in epoch 11, gen_loss = 0.8268968198173925, disc_loss = 0.078547191980638
Trained batch 475 in epoch 11, gen_loss = 0.8270602208726546, disc_loss = 0.07844706603224162
Trained batch 476 in epoch 11, gen_loss = 0.8278578514822874, disc_loss = 0.07839977586997256
Trained batch 477 in epoch 11, gen_loss = 0.8273545310337673, disc_loss = 0.07851448809829342
Trained batch 478 in epoch 11, gen_loss = 0.8269728276575283, disc_loss = 0.07845523709621832
Trained batch 479 in epoch 11, gen_loss = 0.827099471911788, disc_loss = 0.07838358941565578
Trained batch 480 in epoch 11, gen_loss = 0.8269921030671086, disc_loss = 0.07850486387473506
Trained batch 481 in epoch 11, gen_loss = 0.8266156877224871, disc_loss = 0.0785249827228703
Trained batch 482 in epoch 11, gen_loss = 0.8261998292081845, disc_loss = 0.07847508197692733
Trained batch 483 in epoch 11, gen_loss = 0.826519666255013, disc_loss = 0.07835115698620307
Trained batch 484 in epoch 11, gen_loss = 0.8263862380047434, disc_loss = 0.0782619911908489
Trained batch 485 in epoch 11, gen_loss = 0.8265370001763473, disc_loss = 0.07824493496230354
Trained batch 486 in epoch 11, gen_loss = 0.8263010900368191, disc_loss = 0.07820333474654192
Trained batch 487 in epoch 11, gen_loss = 0.8263797443665442, disc_loss = 0.07818412991454367
Trained batch 488 in epoch 11, gen_loss = 0.8259805980879349, disc_loss = 0.0782727599143982
Trained batch 489 in epoch 11, gen_loss = 0.8253605026371625, disc_loss = 0.07853106013974365
Trained batch 490 in epoch 11, gen_loss = 0.826132419031652, disc_loss = 0.07893983552387922
Trained batch 491 in epoch 11, gen_loss = 0.8263448603996416, disc_loss = 0.07883879004379477
Trained batch 492 in epoch 11, gen_loss = 0.826272679753526, disc_loss = 0.07876940832887049
Trained batch 493 in epoch 11, gen_loss = 0.8260591125440019, disc_loss = 0.07876461469436344
Trained batch 494 in epoch 11, gen_loss = 0.8254523326652219, disc_loss = 0.07881901054596058
Trained batch 495 in epoch 11, gen_loss = 0.8258396796882153, disc_loss = 0.07880399913542092
Trained batch 496 in epoch 11, gen_loss = 0.825429247058853, disc_loss = 0.0789577152610005
Trained batch 497 in epoch 11, gen_loss = 0.8256314546468267, disc_loss = 0.07917125175621016
Trained batch 498 in epoch 11, gen_loss = 0.8253147099204436, disc_loss = 0.07916934384716179
Trained batch 499 in epoch 11, gen_loss = 0.8249690024852753, disc_loss = 0.07927392533048988
Trained batch 500 in epoch 11, gen_loss = 0.824493959397375, disc_loss = 0.07954444478594971
Trained batch 501 in epoch 11, gen_loss = 0.824765516704772, disc_loss = 0.0794937881451857
Trained batch 502 in epoch 11, gen_loss = 0.8248593586813622, disc_loss = 0.0794639289490212
Trained batch 503 in epoch 11, gen_loss = 0.8247044691963802, disc_loss = 0.07937101530103338
Trained batch 504 in epoch 11, gen_loss = 0.8247486066110064, disc_loss = 0.07932124152263202
Trained batch 505 in epoch 11, gen_loss = 0.824528810888411, disc_loss = 0.07929056426031669
Trained batch 506 in epoch 11, gen_loss = 0.8246542734977527, disc_loss = 0.07931727435094482
Trained batch 507 in epoch 11, gen_loss = 0.8244326644995081, disc_loss = 0.07923331805028197
Trained batch 508 in epoch 11, gen_loss = 0.8242390078505271, disc_loss = 0.07922696248648325
Trained batch 509 in epoch 11, gen_loss = 0.8238240132144853, disc_loss = 0.07927507399855291
Trained batch 510 in epoch 11, gen_loss = 0.8241048497229873, disc_loss = 0.07915005337359446
Trained batch 511 in epoch 11, gen_loss = 0.8242092774016783, disc_loss = 0.07918752265868534
Trained batch 512 in epoch 11, gen_loss = 0.8246038953463236, disc_loss = 0.0791476143516789
Trained batch 513 in epoch 11, gen_loss = 0.8243835221700632, disc_loss = 0.07909277449851196
Trained batch 514 in epoch 11, gen_loss = 0.8240985329868724, disc_loss = 0.07909568195384972
Trained batch 515 in epoch 11, gen_loss = 0.8237696421700854, disc_loss = 0.0790968939477881
Trained batch 516 in epoch 11, gen_loss = 0.8244399339594739, disc_loss = 0.07961004334222706
Trained batch 517 in epoch 11, gen_loss = 0.8241262214984673, disc_loss = 0.0796527706795016
Trained batch 518 in epoch 11, gen_loss = 0.8242285093131093, disc_loss = 0.07965670042421834
Trained batch 519 in epoch 11, gen_loss = 0.8239499288109633, disc_loss = 0.07961873035483923
Trained batch 520 in epoch 11, gen_loss = 0.8238367198067297, disc_loss = 0.0796513590200191
Trained batch 521 in epoch 11, gen_loss = 0.8234668525927825, disc_loss = 0.07962687800449259
Trained batch 522 in epoch 11, gen_loss = 0.8236460819071155, disc_loss = 0.0796738416686597
Trained batch 523 in epoch 11, gen_loss = 0.823382222356687, disc_loss = 0.07977313404895707
Trained batch 524 in epoch 11, gen_loss = 0.823338669027601, disc_loss = 0.07979864800437575
Trained batch 525 in epoch 11, gen_loss = 0.8230451126742272, disc_loss = 0.07978486316632692
Trained batch 526 in epoch 11, gen_loss = 0.8227896197244836, disc_loss = 0.07972732995171984
Trained batch 527 in epoch 11, gen_loss = 0.8236344989502069, disc_loss = 0.07984239328829007
Trained batch 528 in epoch 11, gen_loss = 0.8233208965038307, disc_loss = 0.07991026491384481
Trained batch 529 in epoch 11, gen_loss = 0.8228518897632383, disc_loss = 0.08006807802034155
Trained batch 530 in epoch 11, gen_loss = 0.8227014411416207, disc_loss = 0.0800478546818799
Trained batch 531 in epoch 11, gen_loss = 0.8231000317666763, disc_loss = 0.0799801351968199
Trained batch 532 in epoch 11, gen_loss = 0.8228808407711938, disc_loss = 0.07993114930638733
Trained batch 533 in epoch 11, gen_loss = 0.8232115394390478, disc_loss = 0.07991228397231033
Trained batch 534 in epoch 11, gen_loss = 0.822826384495352, disc_loss = 0.07998189642920951
Trained batch 535 in epoch 11, gen_loss = 0.8225381537827093, disc_loss = 0.08004365954026858
Trained batch 536 in epoch 11, gen_loss = 0.8241313887930005, disc_loss = 0.08035933436718344
Trained batch 537 in epoch 11, gen_loss = 0.8241069743402829, disc_loss = 0.0802848118558166
Trained batch 538 in epoch 11, gen_loss = 0.8235744347377699, disc_loss = 0.08047387791289524
Trained batch 539 in epoch 11, gen_loss = 0.8238300167851977, disc_loss = 0.08068319875919433
Trained batch 540 in epoch 11, gen_loss = 0.823456471266015, disc_loss = 0.08072043784038471
Trained batch 541 in epoch 11, gen_loss = 0.8230524278654824, disc_loss = 0.0809615175995797
Trained batch 542 in epoch 11, gen_loss = 0.8224501324402473, disc_loss = 0.08112614995132768
Trained batch 543 in epoch 11, gen_loss = 0.8230204376227716, disc_loss = 0.08130514991010868
Trained batch 544 in epoch 11, gen_loss = 0.8223915873317543, disc_loss = 0.08136504535315507
Trained batch 545 in epoch 11, gen_loss = 0.8221813239457406, disc_loss = 0.08131375474404993
Trained batch 546 in epoch 11, gen_loss = 0.8218871946744553, disc_loss = 0.08135329849738798
Trained batch 547 in epoch 11, gen_loss = 0.8220292204705468, disc_loss = 0.08170462166720553
Trained batch 548 in epoch 11, gen_loss = 0.8224847771648066, disc_loss = 0.08173540010132262
Trained batch 549 in epoch 11, gen_loss = 0.8217247337644751, disc_loss = 0.08248516828668388
Trained batch 550 in epoch 11, gen_loss = 0.8228085667381702, disc_loss = 0.08281318860436146
Trained batch 551 in epoch 11, gen_loss = 0.8225758543265038, disc_loss = 0.08277684897758013
Trained batch 552 in epoch 11, gen_loss = 0.8226973762563944, disc_loss = 0.08272510009294015
Trained batch 553 in epoch 11, gen_loss = 0.8222497498300532, disc_loss = 0.08287127514534533
Trained batch 554 in epoch 11, gen_loss = 0.8221706659944208, disc_loss = 0.08282863881170481
Trained batch 555 in epoch 11, gen_loss = 0.82173150209643, disc_loss = 0.08285686401348802
Trained batch 556 in epoch 11, gen_loss = 0.821485241503861, disc_loss = 0.08286560834611179
Trained batch 557 in epoch 11, gen_loss = 0.8212083918860309, disc_loss = 0.08282340547123317
Trained batch 558 in epoch 11, gen_loss = 0.8210905384079075, disc_loss = 0.08275787103321397
Trained batch 559 in epoch 11, gen_loss = 0.8212628861623151, disc_loss = 0.08274783218179696
Trained batch 560 in epoch 11, gen_loss = 0.8209370105874305, disc_loss = 0.08269092263471262
Trained batch 561 in epoch 11, gen_loss = 0.8205223491819728, disc_loss = 0.0826991440751507
Trained batch 562 in epoch 11, gen_loss = 0.820657059523818, disc_loss = 0.08288831072718858
Trained batch 563 in epoch 11, gen_loss = 0.8206921934236026, disc_loss = 0.08277376802433414
Trained batch 564 in epoch 11, gen_loss = 0.8203574029745254, disc_loss = 0.08292371491382343
Trained batch 565 in epoch 11, gen_loss = 0.8206094552897732, disc_loss = 0.08283072605880484
Trained batch 566 in epoch 11, gen_loss = 0.8204111215088523, disc_loss = 0.08284384620456416
Trained batch 567 in epoch 11, gen_loss = 0.820632510097094, disc_loss = 0.08287090228208091
Trained batch 568 in epoch 11, gen_loss = 0.8203200787986729, disc_loss = 0.08290537163739621
Trained batch 569 in epoch 11, gen_loss = 0.8199338853359223, disc_loss = 0.08300045366448007
Trained batch 570 in epoch 11, gen_loss = 0.8200560405250189, disc_loss = 0.08288880591419397
Trained batch 571 in epoch 11, gen_loss = 0.8207959193032939, disc_loss = 0.08295568267463127
Trained batch 572 in epoch 11, gen_loss = 0.8211375932626908, disc_loss = 0.08290233155371163
Trained batch 573 in epoch 11, gen_loss = 0.8206704422987297, disc_loss = 0.08305706343863432
Trained batch 574 in epoch 11, gen_loss = 0.8207678247534711, disc_loss = 0.08298218001328085
Trained batch 575 in epoch 11, gen_loss = 0.8207704989860455, disc_loss = 0.08290364169483332
Trained batch 576 in epoch 11, gen_loss = 0.8207186024565011, disc_loss = 0.08284806559407887
Trained batch 577 in epoch 11, gen_loss = 0.8205393756962153, disc_loss = 0.08285864658982438
Trained batch 578 in epoch 11, gen_loss = 0.8207848497211212, disc_loss = 0.08278409732483161
Trained batch 579 in epoch 11, gen_loss = 0.8210395984608552, disc_loss = 0.08266938562376488
Trained batch 580 in epoch 11, gen_loss = 0.8206446159522012, disc_loss = 0.08292589796844889
Trained batch 581 in epoch 11, gen_loss = 0.8202637347978415, disc_loss = 0.0831135378756858
Trained batch 582 in epoch 11, gen_loss = 0.8202390078819431, disc_loss = 0.08308004752587445
Trained batch 583 in epoch 11, gen_loss = 0.820900502372278, disc_loss = 0.08301074458254272
Trained batch 584 in epoch 11, gen_loss = 0.8205897519731115, disc_loss = 0.08303719209905108
Trained batch 585 in epoch 11, gen_loss = 0.8215492142955598, disc_loss = 0.08336335828578666
Trained batch 586 in epoch 11, gen_loss = 0.8212360544748972, disc_loss = 0.08346383881420405
Trained batch 587 in epoch 11, gen_loss = 0.8210216745430109, disc_loss = 0.08345585678653399
Trained batch 588 in epoch 11, gen_loss = 0.8208730652903053, disc_loss = 0.08353355266185436
Trained batch 589 in epoch 11, gen_loss = 0.8210761228860435, disc_loss = 0.08360408365063496
Trained batch 590 in epoch 11, gen_loss = 0.8211685796276164, disc_loss = 0.08358175333828843
Trained batch 591 in epoch 11, gen_loss = 0.8208603880091293, disc_loss = 0.0835774140668454
Trained batch 592 in epoch 11, gen_loss = 0.8209514489262342, disc_loss = 0.08349390538852242
Trained batch 593 in epoch 11, gen_loss = 0.8212643942046246, disc_loss = 0.08339016233737069
Trained batch 594 in epoch 11, gen_loss = 0.8209991499155509, disc_loss = 0.08342077585735491
Trained batch 595 in epoch 11, gen_loss = 0.8213852735973844, disc_loss = 0.08357970457955345
Trained batch 596 in epoch 11, gen_loss = 0.821193757867893, disc_loss = 0.08354059659362688
Trained batch 597 in epoch 11, gen_loss = 0.8209318775795774, disc_loss = 0.08352483684558384
Trained batch 598 in epoch 11, gen_loss = 0.8207909708628074, disc_loss = 0.08345884851060298
Trained batch 599 in epoch 11, gen_loss = 0.8211327191193899, disc_loss = 0.08340733659919351
Trained batch 600 in epoch 11, gen_loss = 0.8213422139750146, disc_loss = 0.08329567586082637
Trained batch 601 in epoch 11, gen_loss = 0.8211032212572636, disc_loss = 0.08326996627891826
Trained batch 602 in epoch 11, gen_loss = 0.8210018639936179, disc_loss = 0.08324228041955142
Trained batch 603 in epoch 11, gen_loss = 0.8211209130602957, disc_loss = 0.0832870946410698
Trained batch 604 in epoch 11, gen_loss = 0.8215388826102265, disc_loss = 0.08330105095024197
Trained batch 605 in epoch 11, gen_loss = 0.8213316253309596, disc_loss = 0.0832613826600263
Trained batch 606 in epoch 11, gen_loss = 0.8212477787715403, disc_loss = 0.08319452132636918
Trained batch 607 in epoch 11, gen_loss = 0.8210554628780014, disc_loss = 0.08316853518848993
Trained batch 608 in epoch 11, gen_loss = 0.8210008805021277, disc_loss = 0.08321512970241468
Trained batch 609 in epoch 11, gen_loss = 0.8215903785385069, disc_loss = 0.08333828157485752
Trained batch 610 in epoch 11, gen_loss = 0.8213403153731663, disc_loss = 0.08347667830671548
Trained batch 611 in epoch 11, gen_loss = 0.8211806553835962, disc_loss = 0.08344125315041762
Trained batch 612 in epoch 11, gen_loss = 0.8217068374837592, disc_loss = 0.08341720342472025
Trained batch 613 in epoch 11, gen_loss = 0.8218263497375898, disc_loss = 0.08368122856305603
Trained batch 614 in epoch 11, gen_loss = 0.8215617785608865, disc_loss = 0.08367534499857726
Trained batch 615 in epoch 11, gen_loss = 0.8213716384458851, disc_loss = 0.08367380382063762
Trained batch 616 in epoch 11, gen_loss = 0.821472730107207, disc_loss = 0.08358440449313416
Trained batch 617 in epoch 11, gen_loss = 0.8217383066620256, disc_loss = 0.08355945353712706
Trained batch 618 in epoch 11, gen_loss = 0.8215950103491689, disc_loss = 0.08352821076105263
Trained batch 619 in epoch 11, gen_loss = 0.8217205008191447, disc_loss = 0.08345134754725281
Trained batch 620 in epoch 11, gen_loss = 0.8213923681953295, disc_loss = 0.08340198255253539
Trained batch 621 in epoch 11, gen_loss = 0.8217110616601165, disc_loss = 0.08332846657046598
Trained batch 622 in epoch 11, gen_loss = 0.8218437797759165, disc_loss = 0.08345860654987503
Trained batch 623 in epoch 11, gen_loss = 0.8214532291659942, disc_loss = 0.08366694416737375
Trained batch 624 in epoch 11, gen_loss = 0.8216064129829407, disc_loss = 0.08361264105588198
Trained batch 625 in epoch 11, gen_loss = 0.8212568370488506, disc_loss = 0.08360753323400792
Trained batch 626 in epoch 11, gen_loss = 0.8217005076590908, disc_loss = 0.08356647580368905
Trained batch 627 in epoch 11, gen_loss = 0.8217373546331551, disc_loss = 0.08346312052783834
Trained batch 628 in epoch 11, gen_loss = 0.8212644874765308, disc_loss = 0.08347311492606595
Trained batch 629 in epoch 11, gen_loss = 0.8216474732709309, disc_loss = 0.08336846967272106
Trained batch 630 in epoch 11, gen_loss = 0.8214704316882815, disc_loss = 0.08337766295018505
Trained batch 631 in epoch 11, gen_loss = 0.8217678335082682, disc_loss = 0.08335130696355872
Trained batch 632 in epoch 11, gen_loss = 0.8216848315974171, disc_loss = 0.0834156618649243
Trained batch 633 in epoch 11, gen_loss = 0.8211319865864534, disc_loss = 0.08361270527093898
Trained batch 634 in epoch 11, gen_loss = 0.8212539355585894, disc_loss = 0.08352808987091141
Trained batch 635 in epoch 11, gen_loss = 0.821709727153838, disc_loss = 0.08353000515691186
Trained batch 636 in epoch 11, gen_loss = 0.821437004503313, disc_loss = 0.08353285797472511
Trained batch 637 in epoch 11, gen_loss = 0.8211457098726195, disc_loss = 0.08353826070356192
Trained batch 638 in epoch 11, gen_loss = 0.8213782445738946, disc_loss = 0.08354261719967138
Trained batch 639 in epoch 11, gen_loss = 0.8219394811429084, disc_loss = 0.08357279458577978
Trained batch 640 in epoch 11, gen_loss = 0.8215777108710195, disc_loss = 0.08376725191939129
Trained batch 641 in epoch 11, gen_loss = 0.8215348187636735, disc_loss = 0.08388388149492512
Trained batch 642 in epoch 11, gen_loss = 0.8217808678398607, disc_loss = 0.08402033689725871
Trained batch 643 in epoch 11, gen_loss = 0.8216484454662903, disc_loss = 0.08396214808001883
Trained batch 644 in epoch 11, gen_loss = 0.8217456710431003, disc_loss = 0.08386883454527273
Trained batch 645 in epoch 11, gen_loss = 0.8216016323020214, disc_loss = 0.0838186346966162
Trained batch 646 in epoch 11, gen_loss = 0.821792829994809, disc_loss = 0.08382750607284227
Trained batch 647 in epoch 11, gen_loss = 0.8218124643152143, disc_loss = 0.08372803983410797
Trained batch 648 in epoch 11, gen_loss = 0.821755066858418, disc_loss = 0.08371025506544784
Trained batch 649 in epoch 11, gen_loss = 0.8217291733851799, disc_loss = 0.08368512395626078
Trained batch 650 in epoch 11, gen_loss = 0.8216006362126903, disc_loss = 0.08362154316546226
Trained batch 651 in epoch 11, gen_loss = 0.8212852354612818, disc_loss = 0.08357682676865874
Trained batch 652 in epoch 11, gen_loss = 0.8217702033326235, disc_loss = 0.08352582409527227
Trained batch 653 in epoch 11, gen_loss = 0.8219732262125803, disc_loss = 0.0834242178950265
Trained batch 654 in epoch 11, gen_loss = 0.8222544257877438, disc_loss = 0.08336622560155073
Trained batch 655 in epoch 11, gen_loss = 0.8221104647509936, disc_loss = 0.0832866456788374
Trained batch 656 in epoch 11, gen_loss = 0.8218273843441561, disc_loss = 0.0832741133673074
Trained batch 657 in epoch 11, gen_loss = 0.8214238667379397, disc_loss = 0.08329703119133336
Trained batch 658 in epoch 11, gen_loss = 0.821673607790054, disc_loss = 0.08321444321796863
Trained batch 659 in epoch 11, gen_loss = 0.8224099244132187, disc_loss = 0.08348083871021642
Trained batch 660 in epoch 11, gen_loss = 0.8222849789257309, disc_loss = 0.08343720312812189
Trained batch 661 in epoch 11, gen_loss = 0.8222648440170864, disc_loss = 0.08341458696011014
Trained batch 662 in epoch 11, gen_loss = 0.8219982966398581, disc_loss = 0.08343118862536923
Trained batch 663 in epoch 11, gen_loss = 0.8221684716731669, disc_loss = 0.08352295369476484
Trained batch 664 in epoch 11, gen_loss = 0.8224567423189493, disc_loss = 0.08341959627639306
Trained batch 665 in epoch 11, gen_loss = 0.8224568802852172, disc_loss = 0.08333389955927974
Trained batch 666 in epoch 11, gen_loss = 0.8221377494453133, disc_loss = 0.08334337013342168
Trained batch 667 in epoch 11, gen_loss = 0.8221115286121825, disc_loss = 0.08331016597092643
Trained batch 668 in epoch 11, gen_loss = 0.8219429733863682, disc_loss = 0.08329944505101496
Trained batch 669 in epoch 11, gen_loss = 0.8225097099346901, disc_loss = 0.08325715874975075
Trained batch 670 in epoch 11, gen_loss = 0.822175651921956, disc_loss = 0.08322450258087606
Trained batch 671 in epoch 11, gen_loss = 0.8223528046870515, disc_loss = 0.083226755975158
Trained batch 672 in epoch 11, gen_loss = 0.8225367199435808, disc_loss = 0.08313443697020301
Trained batch 673 in epoch 11, gen_loss = 0.8221580045690169, disc_loss = 0.08312640244483903
Trained batch 674 in epoch 11, gen_loss = 0.82189041879442, disc_loss = 0.08309771898030131
Trained batch 675 in epoch 11, gen_loss = 0.8219676356343828, disc_loss = 0.0830017462381046
Trained batch 676 in epoch 11, gen_loss = 0.8219328435520302, disc_loss = 0.08297577116121173
Trained batch 677 in epoch 11, gen_loss = 0.8218406451135258, disc_loss = 0.08292975426022414
Trained batch 678 in epoch 11, gen_loss = 0.8221462756088099, disc_loss = 0.08284116372197252
Trained batch 679 in epoch 11, gen_loss = 0.8221135856474147, disc_loss = 0.08276670521316941
Trained batch 680 in epoch 11, gen_loss = 0.8219462319792805, disc_loss = 0.08271381995680355
Trained batch 681 in epoch 11, gen_loss = 0.822146741088884, disc_loss = 0.08275700666835187
Trained batch 682 in epoch 11, gen_loss = 0.8220309314930248, disc_loss = 0.08271110886203378
Trained batch 683 in epoch 11, gen_loss = 0.8219786190498642, disc_loss = 0.08278759507249975
Trained batch 684 in epoch 11, gen_loss = 0.8219571576501331, disc_loss = 0.08270379376536521
Trained batch 685 in epoch 11, gen_loss = 0.8215886681142424, disc_loss = 0.08268766806653698
Trained batch 686 in epoch 11, gen_loss = 0.8215014852984677, disc_loss = 0.08261331769311055
Trained batch 687 in epoch 11, gen_loss = 0.8214398151220277, disc_loss = 0.0825855431653191
Trained batch 688 in epoch 11, gen_loss = 0.8214291121340282, disc_loss = 0.08249994376687811
Trained batch 689 in epoch 11, gen_loss = 0.8211438916731572, disc_loss = 0.08250694918054817
Trained batch 690 in epoch 11, gen_loss = 0.8209783929129241, disc_loss = 0.08245651239688291
Trained batch 691 in epoch 11, gen_loss = 0.8208803135707888, disc_loss = 0.08243551977500965
Trained batch 692 in epoch 11, gen_loss = 0.8208708502513505, disc_loss = 0.08236877537032786
Trained batch 693 in epoch 11, gen_loss = 0.8210161023421658, disc_loss = 0.08227720970599255
Trained batch 694 in epoch 11, gen_loss = 0.8210517469927562, disc_loss = 0.0821883314014446
Trained batch 695 in epoch 11, gen_loss = 0.8209478255661055, disc_loss = 0.0822159130214553
Trained batch 696 in epoch 11, gen_loss = 0.8210889079649445, disc_loss = 0.08217003406660159
Trained batch 697 in epoch 11, gen_loss = 0.8206256380395425, disc_loss = 0.08234182629536806
Trained batch 698 in epoch 11, gen_loss = 0.8204797078270428, disc_loss = 0.0823012505416813
Trained batch 699 in epoch 11, gen_loss = 0.8209806976999555, disc_loss = 0.08230184346038316
Trained batch 700 in epoch 11, gen_loss = 0.8208449170864938, disc_loss = 0.08220754582009752
Trained batch 701 in epoch 11, gen_loss = 0.8211395563902678, disc_loss = 0.08217145419915729
Trained batch 702 in epoch 11, gen_loss = 0.8209851143370313, disc_loss = 0.08213136611297027
Trained batch 703 in epoch 11, gen_loss = 0.8204616810279813, disc_loss = 0.08234297945719762
Trained batch 704 in epoch 11, gen_loss = 0.821431359247113, disc_loss = 0.0828507039154358
Trained batch 705 in epoch 11, gen_loss = 0.8210700293607145, disc_loss = 0.08310971846118063
Trained batch 706 in epoch 11, gen_loss = 0.8219522070007917, disc_loss = 0.08349630675150826
Trained batch 707 in epoch 11, gen_loss = 0.8215235684719463, disc_loss = 0.08365357764154714
Trained batch 708 in epoch 11, gen_loss = 0.8216204249808415, disc_loss = 0.08359294921837547
Trained batch 709 in epoch 11, gen_loss = 0.8215220072739561, disc_loss = 0.08357345052719325
Trained batch 710 in epoch 11, gen_loss = 0.8212921370433856, disc_loss = 0.083637139256965
Trained batch 711 in epoch 11, gen_loss = 0.8212411165069998, disc_loss = 0.0836590919447435
Trained batch 712 in epoch 11, gen_loss = 0.820880265757546, disc_loss = 0.08368687793680403
Trained batch 713 in epoch 11, gen_loss = 0.8211491109610272, disc_loss = 0.08358498007001705
Trained batch 714 in epoch 11, gen_loss = 0.8212734250755577, disc_loss = 0.08358806779777461
Trained batch 715 in epoch 11, gen_loss = 0.8214178511550306, disc_loss = 0.08351138852115242
Trained batch 716 in epoch 11, gen_loss = 0.8210641158175768, disc_loss = 0.08360162661949919
Trained batch 717 in epoch 11, gen_loss = 0.8211653062394071, disc_loss = 0.08359181019542401
Trained batch 718 in epoch 11, gen_loss = 0.8210362682587912, disc_loss = 0.08355071339549001
Trained batch 719 in epoch 11, gen_loss = 0.8213336347705789, disc_loss = 0.08381047785773667
Trained batch 720 in epoch 11, gen_loss = 0.8209862596615012, disc_loss = 0.08390820393114042
Trained batch 721 in epoch 11, gen_loss = 0.8208205445651533, disc_loss = 0.08392389245470598
Trained batch 722 in epoch 11, gen_loss = 0.8207644657805088, disc_loss = 0.08384369221357513
Trained batch 723 in epoch 11, gen_loss = 0.8205780819964014, disc_loss = 0.08380567691885758
Trained batch 724 in epoch 11, gen_loss = 0.8205870092326197, disc_loss = 0.08372788898261457
Trained batch 725 in epoch 11, gen_loss = 0.8205149856809085, disc_loss = 0.08389640801019208
Trained batch 726 in epoch 11, gen_loss = 0.8205953999595432, disc_loss = 0.08385261061487327
Trained batch 727 in epoch 11, gen_loss = 0.8203938090047993, disc_loss = 0.0838577092489596
Trained batch 728 in epoch 11, gen_loss = 0.8204463016349102, disc_loss = 0.08389071396977445
Trained batch 729 in epoch 11, gen_loss = 0.8204296117776061, disc_loss = 0.08384131986060983
Trained batch 730 in epoch 11, gen_loss = 0.8204555081766706, disc_loss = 0.08385629697018666
Trained batch 731 in epoch 11, gen_loss = 0.8205205271315705, disc_loss = 0.08384409178267208
Trained batch 732 in epoch 11, gen_loss = 0.8207259987256049, disc_loss = 0.083764276634978
Trained batch 733 in epoch 11, gen_loss = 0.8204018999023074, disc_loss = 0.08384116734847508
Trained batch 734 in epoch 11, gen_loss = 0.8205214906711967, disc_loss = 0.08375694295454796
Trained batch 735 in epoch 11, gen_loss = 0.8207816935913719, disc_loss = 0.08375154741224833
Trained batch 736 in epoch 11, gen_loss = 0.8207110443949861, disc_loss = 0.08370508504159536
Trained batch 737 in epoch 11, gen_loss = 0.8206883692321415, disc_loss = 0.08364514519806275
Trained batch 738 in epoch 11, gen_loss = 0.8207573807610549, disc_loss = 0.08363921927094096
Trained batch 739 in epoch 11, gen_loss = 0.8205501660301878, disc_loss = 0.08369174751553785
Trained batch 740 in epoch 11, gen_loss = 0.8207479161128663, disc_loss = 0.08364810946795903
Trained batch 741 in epoch 11, gen_loss = 0.8209789196114656, disc_loss = 0.08358234291484534
Trained batch 742 in epoch 11, gen_loss = 0.8210053569856595, disc_loss = 0.08351388891399268
Trained batch 743 in epoch 11, gen_loss = 0.8208962037999142, disc_loss = 0.08350540826632892
Trained batch 744 in epoch 11, gen_loss = 0.820834345305526, disc_loss = 0.08343583128771326
Trained batch 745 in epoch 11, gen_loss = 0.8209753299366693, disc_loss = 0.0835022227351751
Trained batch 746 in epoch 11, gen_loss = 0.8208984458143292, disc_loss = 0.08350953007293953
Trained batch 747 in epoch 11, gen_loss = 0.8205682856832596, disc_loss = 0.08351159423843703
Trained batch 748 in epoch 11, gen_loss = 0.8205919287233391, disc_loss = 0.08346891196665959
Trained batch 749 in epoch 11, gen_loss = 0.820352486928304, disc_loss = 0.08351021057739853
Trained batch 750 in epoch 11, gen_loss = 0.8200409507624478, disc_loss = 0.08354813948189331
Trained batch 751 in epoch 11, gen_loss = 0.8202315526122742, disc_loss = 0.08346715290966306
Trained batch 752 in epoch 11, gen_loss = 0.8199961425298714, disc_loss = 0.08350570245483917
Trained batch 753 in epoch 11, gen_loss = 0.8200745977046319, disc_loss = 0.08346093008640551
Trained batch 754 in epoch 11, gen_loss = 0.8200586117656026, disc_loss = 0.0835093766882621
Trained batch 755 in epoch 11, gen_loss = 0.8199654086714699, disc_loss = 0.0834601491421126
Trained batch 756 in epoch 11, gen_loss = 0.8201081399243606, disc_loss = 0.08341083762111681
Trained batch 757 in epoch 11, gen_loss = 0.8198595799525369, disc_loss = 0.08340881270354018
Trained batch 758 in epoch 11, gen_loss = 0.8198123103073934, disc_loss = 0.0833612979133276
Trained batch 759 in epoch 11, gen_loss = 0.8197255849838256, disc_loss = 0.08334163619376915
Trained batch 760 in epoch 11, gen_loss = 0.819412143252369, disc_loss = 0.08335035266758539
Trained batch 761 in epoch 11, gen_loss = 0.8196918088307218, disc_loss = 0.08327371008288399
Trained batch 762 in epoch 11, gen_loss = 0.8199065560438373, disc_loss = 0.08322222101798728
Trained batch 763 in epoch 11, gen_loss = 0.8198197654872664, disc_loss = 0.08316387526851869
Trained batch 764 in epoch 11, gen_loss = 0.819564663117228, disc_loss = 0.08313705759622107
Trained batch 765 in epoch 11, gen_loss = 0.8195993396849919, disc_loss = 0.08339481158960153
Trained batch 766 in epoch 11, gen_loss = 0.8192714041650218, disc_loss = 0.08346016466195029
Trained batch 767 in epoch 11, gen_loss = 0.8190791580515603, disc_loss = 0.08341519409077591
Trained batch 768 in epoch 11, gen_loss = 0.8191249349647443, disc_loss = 0.08334090754569003
Trained batch 769 in epoch 11, gen_loss = 0.8192789696253739, disc_loss = 0.08337786608049041
Trained batch 770 in epoch 11, gen_loss = 0.8194841920324492, disc_loss = 0.08328907720106817
Trained batch 771 in epoch 11, gen_loss = 0.8192580009525922, disc_loss = 0.08325856934914394
Trained batch 772 in epoch 11, gen_loss = 0.819435501006103, disc_loss = 0.08321362753358957
Trained batch 773 in epoch 11, gen_loss = 0.8191821005301266, disc_loss = 0.08318888604188535
Trained batch 774 in epoch 11, gen_loss = 0.819248020572047, disc_loss = 0.08311161407780263
Trained batch 775 in epoch 11, gen_loss = 0.8189833359312766, disc_loss = 0.08311705491217525
Trained batch 776 in epoch 11, gen_loss = 0.8187981311572258, disc_loss = 0.08317273861202418
Trained batch 777 in epoch 11, gen_loss = 0.8192156922541425, disc_loss = 0.08310222887412518
Trained batch 778 in epoch 11, gen_loss = 0.819495222381817, disc_loss = 0.08307693456090384
Trained batch 779 in epoch 11, gen_loss = 0.8191937208175659, disc_loss = 0.08302241580274243
Trained batch 780 in epoch 11, gen_loss = 0.8188547368391528, disc_loss = 0.08309056087326683
Trained batch 781 in epoch 11, gen_loss = 0.818709432697662, disc_loss = 0.083049889703941
Trained batch 782 in epoch 11, gen_loss = 0.8187760164150029, disc_loss = 0.0830316295725975
Trained batch 783 in epoch 11, gen_loss = 0.8187879425074372, disc_loss = 0.082954186029086
Trained batch 784 in epoch 11, gen_loss = 0.818806233983131, disc_loss = 0.08298740115040427
Trained batch 785 in epoch 11, gen_loss = 0.8187921121526918, disc_loss = 0.08299041127563281
Trained batch 786 in epoch 11, gen_loss = 0.818740305179562, disc_loss = 0.0829325643388183
Trained batch 787 in epoch 11, gen_loss = 0.8185163439832969, disc_loss = 0.08294091754247845
Trained batch 788 in epoch 11, gen_loss = 0.8187989901529368, disc_loss = 0.08287101704509237
Trained batch 789 in epoch 11, gen_loss = 0.8188294217556338, disc_loss = 0.08281469511080392
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.6322515606880188, disc_loss = 0.06220150738954544
Trained batch 1 in epoch 12, gen_loss = 0.7524320185184479, disc_loss = 0.06244858354330063
Trained batch 2 in epoch 12, gen_loss = 0.7633333802223206, disc_loss = 0.05040403952201208
Trained batch 3 in epoch 12, gen_loss = 0.8226573914289474, disc_loss = 0.040823948103934526
Trained batch 4 in epoch 12, gen_loss = 0.8116683959960938, disc_loss = 0.03641231246292591
Trained batch 5 in epoch 12, gen_loss = 0.8562441468238831, disc_loss = 0.036312468660374485
Trained batch 6 in epoch 12, gen_loss = 0.847318342753819, disc_loss = 0.034340898639389446
Trained batch 7 in epoch 12, gen_loss = 0.8187274485826492, disc_loss = 0.0516608317848295
Trained batch 8 in epoch 12, gen_loss = 0.8437426487604777, disc_loss = 0.050132393630014524
Trained batch 9 in epoch 12, gen_loss = 0.8545817494392395, disc_loss = 0.059526133351027966
Trained batch 10 in epoch 12, gen_loss = 0.83909687128934, disc_loss = 0.05712247284298593
Trained batch 11 in epoch 12, gen_loss = 0.8361358046531677, disc_loss = 0.056001529252777495
Trained batch 12 in epoch 12, gen_loss = 0.8228206359423124, disc_loss = 0.0604001829543939
Trained batch 13 in epoch 12, gen_loss = 0.8322910836764744, disc_loss = 0.05916080929871116
Trained batch 14 in epoch 12, gen_loss = 0.8348251620928446, disc_loss = 0.05654018297791481
Trained batch 15 in epoch 12, gen_loss = 0.8452890031039715, disc_loss = 0.06338625750504434
Trained batch 16 in epoch 12, gen_loss = 0.8266367561676923, disc_loss = 0.06578788051710409
Trained batch 17 in epoch 12, gen_loss = 0.8315437601672279, disc_loss = 0.0640513605127732
Trained batch 18 in epoch 12, gen_loss = 0.8307523852900455, disc_loss = 0.062370463617538154
Trained batch 19 in epoch 12, gen_loss = 0.8214164197444915, disc_loss = 0.0640240790322423
Trained batch 20 in epoch 12, gen_loss = 0.8302842605681646, disc_loss = 0.06219375027077539
Trained batch 21 in epoch 12, gen_loss = 0.8463987870649858, disc_loss = 0.07029423219236461
Trained batch 22 in epoch 12, gen_loss = 0.8401113230249156, disc_loss = 0.07148362955321437
Trained batch 23 in epoch 12, gen_loss = 0.8326355268557867, disc_loss = 0.07349199242889881
Trained batch 24 in epoch 12, gen_loss = 0.8258868980407715, disc_loss = 0.0727634671330452
Trained batch 25 in epoch 12, gen_loss = 0.8223527990854703, disc_loss = 0.0727903232551538
Trained batch 26 in epoch 12, gen_loss = 0.8216180072890388, disc_loss = 0.07532821954400451
Trained batch 27 in epoch 12, gen_loss = 0.8212660018886838, disc_loss = 0.07417124842426606
Trained batch 28 in epoch 12, gen_loss = 0.8173418271130529, disc_loss = 0.07418257704582708
Trained batch 29 in epoch 12, gen_loss = 0.8233483731746674, disc_loss = 0.07356282162169615
Trained batch 30 in epoch 12, gen_loss = 0.8210514072448977, disc_loss = 0.07300694575232844
Trained batch 31 in epoch 12, gen_loss = 0.8135744575411081, disc_loss = 0.07524731243029237
Trained batch 32 in epoch 12, gen_loss = 0.8101671265833306, disc_loss = 0.07616815129012773
Trained batch 33 in epoch 12, gen_loss = 0.820868185337852, disc_loss = 0.07920115243862658
Trained batch 34 in epoch 12, gen_loss = 0.8121189611298697, disc_loss = 0.08221339391810553
Trained batch 35 in epoch 12, gen_loss = 0.8140407486094369, disc_loss = 0.08122921134862635
Trained batch 36 in epoch 12, gen_loss = 0.8142317984555218, disc_loss = 0.08000213672985902
Trained batch 37 in epoch 12, gen_loss = 0.8075388889563712, disc_loss = 0.08101215566459455
Trained batch 38 in epoch 12, gen_loss = 0.8063315183688433, disc_loss = 0.08113351960976918
Trained batch 39 in epoch 12, gen_loss = 0.8056648999452591, disc_loss = 0.08120002709329129
Trained batch 40 in epoch 12, gen_loss = 0.8072673140502558, disc_loss = 0.08047218893359347
Trained batch 41 in epoch 12, gen_loss = 0.802761435508728, disc_loss = 0.08178891046416192
Trained batch 42 in epoch 12, gen_loss = 0.8061343736426775, disc_loss = 0.08110703597235125
Trained batch 43 in epoch 12, gen_loss = 0.8155650821599093, disc_loss = 0.08005166942761703
Trained batch 44 in epoch 12, gen_loss = 0.8138177686267429, disc_loss = 0.07960921534233623
Trained batch 45 in epoch 12, gen_loss = 0.8093584698179493, disc_loss = 0.08164765467138393
Trained batch 46 in epoch 12, gen_loss = 0.8075920977491013, disc_loss = 0.0807964934155028
Trained batch 47 in epoch 12, gen_loss = 0.8139282564322153, disc_loss = 0.08005406451411545
Trained batch 48 in epoch 12, gen_loss = 0.8135657164515281, disc_loss = 0.08010324417632453
Trained batch 49 in epoch 12, gen_loss = 0.8107728111743927, disc_loss = 0.07989080436527729
Trained batch 50 in epoch 12, gen_loss = 0.8150716213619008, disc_loss = 0.07980883596282379
Trained batch 51 in epoch 12, gen_loss = 0.8101575833100539, disc_loss = 0.0811227704040133
Trained batch 52 in epoch 12, gen_loss = 0.8094089885927597, disc_loss = 0.08290260025071648
Trained batch 53 in epoch 12, gen_loss = 0.8116457263628641, disc_loss = 0.0817882729763234
Trained batch 54 in epoch 12, gen_loss = 0.8065456878055226, disc_loss = 0.08362323526631701
Trained batch 55 in epoch 12, gen_loss = 0.803914738552911, disc_loss = 0.08330369268410973
Trained batch 56 in epoch 12, gen_loss = 0.8036934869331226, disc_loss = 0.08525708873282399
Trained batch 57 in epoch 12, gen_loss = 0.8065280153833586, disc_loss = 0.08921436380980344
Trained batch 58 in epoch 12, gen_loss = 0.8022911487999609, disc_loss = 0.09191579264351878
Trained batch 59 in epoch 12, gen_loss = 0.8059908250967661, disc_loss = 0.09101874294380347
Trained batch 60 in epoch 12, gen_loss = 0.8071008764329504, disc_loss = 0.09078495118950235
Trained batch 61 in epoch 12, gen_loss = 0.8058978569123053, disc_loss = 0.09104673864860688
Trained batch 62 in epoch 12, gen_loss = 0.8060382008552551, disc_loss = 0.09042903242839707
Trained batch 63 in epoch 12, gen_loss = 0.8079395871609449, disc_loss = 0.09002213965868577
Trained batch 64 in epoch 12, gen_loss = 0.8036725557767428, disc_loss = 0.09082636506511615
Trained batch 65 in epoch 12, gen_loss = 0.803556805307215, disc_loss = 0.08994518485710476
Trained batch 66 in epoch 12, gen_loss = 0.8018850435071917, disc_loss = 0.09007821726932455
Trained batch 67 in epoch 12, gen_loss = 0.8063620512976366, disc_loss = 0.08920912099454333
Trained batch 68 in epoch 12, gen_loss = 0.8038589168285978, disc_loss = 0.09002496329122696
Trained batch 69 in epoch 12, gen_loss = 0.8068193376064301, disc_loss = 0.08922140688768455
Trained batch 70 in epoch 12, gen_loss = 0.8100515998585124, disc_loss = 0.08831375026681894
Trained batch 71 in epoch 12, gen_loss = 0.8106936506099172, disc_loss = 0.08741025675812529
Trained batch 72 in epoch 12, gen_loss = 0.8093332011405736, disc_loss = 0.08742721121094815
Trained batch 73 in epoch 12, gen_loss = 0.8082515146281268, disc_loss = 0.08704845599729467
Trained batch 74 in epoch 12, gen_loss = 0.8091589879989624, disc_loss = 0.08603369199981292
Trained batch 75 in epoch 12, gen_loss = 0.8118171550725636, disc_loss = 0.08728334487807986
Trained batch 76 in epoch 12, gen_loss = 0.8155215142609237, disc_loss = 0.08719028836092005
Trained batch 77 in epoch 12, gen_loss = 0.812212830934769, disc_loss = 0.08884475698981148
Trained batch 78 in epoch 12, gen_loss = 0.8108088517490821, disc_loss = 0.08898144633851096
Trained batch 79 in epoch 12, gen_loss = 0.8107246160507202, disc_loss = 0.0896391767426394
Trained batch 80 in epoch 12, gen_loss = 0.8125810689396329, disc_loss = 0.08934191958173926
Trained batch 81 in epoch 12, gen_loss = 0.8108834108201469, disc_loss = 0.08938310934775849
Trained batch 82 in epoch 12, gen_loss = 0.8118869963898716, disc_loss = 0.08862845571599452
Trained batch 83 in epoch 12, gen_loss = 0.8141994625329971, disc_loss = 0.08774354216820072
Trained batch 84 in epoch 12, gen_loss = 0.8133357559933382, disc_loss = 0.08752027089324067
Trained batch 85 in epoch 12, gen_loss = 0.8132971074692038, disc_loss = 0.0876702913732896
Trained batch 86 in epoch 12, gen_loss = 0.8134358765064985, disc_loss = 0.0874079256586131
Trained batch 87 in epoch 12, gen_loss = 0.8137120963497595, disc_loss = 0.08693414711689745
Trained batch 88 in epoch 12, gen_loss = 0.8197712824585732, disc_loss = 0.08881907639083232
Trained batch 89 in epoch 12, gen_loss = 0.8171641621324751, disc_loss = 0.08906664638262655
Trained batch 90 in epoch 12, gen_loss = 0.8183238912414719, disc_loss = 0.08829554089519022
Trained batch 91 in epoch 12, gen_loss = 0.818658858537674, disc_loss = 0.08761804195566346
Trained batch 92 in epoch 12, gen_loss = 0.8179787993431091, disc_loss = 0.0874609477036903
Trained batch 93 in epoch 12, gen_loss = 0.8171923610758274, disc_loss = 0.08761037260967683
Trained batch 94 in epoch 12, gen_loss = 0.8158325879197371, disc_loss = 0.08823010820503298
Trained batch 95 in epoch 12, gen_loss = 0.8152622474978367, disc_loss = 0.08766309716156684
Trained batch 96 in epoch 12, gen_loss = 0.8112773326868864, disc_loss = 0.08978662802117694
Trained batch 97 in epoch 12, gen_loss = 0.8177216694671281, disc_loss = 0.09561405818415236
Trained batch 98 in epoch 12, gen_loss = 0.818515645434158, disc_loss = 0.09536965538493612
Trained batch 99 in epoch 12, gen_loss = 0.815857929289341, disc_loss = 0.09751509637571872
Trained batch 100 in epoch 12, gen_loss = 0.8161389883792046, disc_loss = 0.09713307307977782
Trained batch 101 in epoch 12, gen_loss = 0.8195252006544786, disc_loss = 0.09792625368116241
Trained batch 102 in epoch 12, gen_loss = 0.8197997012763347, disc_loss = 0.09748670076318447
Trained batch 103 in epoch 12, gen_loss = 0.81648386699649, disc_loss = 0.09851826477545099
Trained batch 104 in epoch 12, gen_loss = 0.8170645330633436, disc_loss = 0.09795156476930493
Trained batch 105 in epoch 12, gen_loss = 0.8178025829904484, disc_loss = 0.0984810096000866
Trained batch 106 in epoch 12, gen_loss = 0.8158887878199604, disc_loss = 0.09857117935632155
Trained batch 107 in epoch 12, gen_loss = 0.8157456762812756, disc_loss = 0.09812027396185806
Trained batch 108 in epoch 12, gen_loss = 0.816673926530628, disc_loss = 0.09866418451104962
Trained batch 109 in epoch 12, gen_loss = 0.8155606196685271, disc_loss = 0.09849979207766327
Trained batch 110 in epoch 12, gen_loss = 0.8138301439650424, disc_loss = 0.09826970866436625
Trained batch 111 in epoch 12, gen_loss = 0.8151337645415749, disc_loss = 0.09791378185452361
Trained batch 112 in epoch 12, gen_loss = 0.8161332261773337, disc_loss = 0.09734894936096615
Trained batch 113 in epoch 12, gen_loss = 0.8146474886881677, disc_loss = 0.09752608182954423
Trained batch 114 in epoch 12, gen_loss = 0.8129891579565794, disc_loss = 0.09743506060508282
Trained batch 115 in epoch 12, gen_loss = 0.8152982518076897, disc_loss = 0.09876548737319636
Trained batch 116 in epoch 12, gen_loss = 0.8149897071540865, disc_loss = 0.09815682490698548
Trained batch 117 in epoch 12, gen_loss = 0.8129465668383291, disc_loss = 0.09837531513865974
Trained batch 118 in epoch 12, gen_loss = 0.811830560950672, disc_loss = 0.09807308682655337
Trained batch 119 in epoch 12, gen_loss = 0.8123115402956803, disc_loss = 0.09742524615333727
Trained batch 120 in epoch 12, gen_loss = 0.8128414186071758, disc_loss = 0.09681091170511709
Trained batch 121 in epoch 12, gen_loss = 0.8130750370318772, disc_loss = 0.0962479638286912
Trained batch 122 in epoch 12, gen_loss = 0.8131940061968517, disc_loss = 0.09619639320980485
Trained batch 123 in epoch 12, gen_loss = 0.8122928659281423, disc_loss = 0.09596448203158234
Trained batch 124 in epoch 12, gen_loss = 0.8138236424922943, disc_loss = 0.09544602423161268
Trained batch 125 in epoch 12, gen_loss = 0.8127424217878826, disc_loss = 0.09553432434294669
Trained batch 126 in epoch 12, gen_loss = 0.8120052281796463, disc_loss = 0.09545531885801103
Trained batch 127 in epoch 12, gen_loss = 0.8114736706484109, disc_loss = 0.09503114019025816
Trained batch 128 in epoch 12, gen_loss = 0.8112786382205727, disc_loss = 0.09542190525391998
Trained batch 129 in epoch 12, gen_loss = 0.811807823410401, disc_loss = 0.0948180521121965
Trained batch 130 in epoch 12, gen_loss = 0.8111652088074284, disc_loss = 0.09452344850416629
Trained batch 131 in epoch 12, gen_loss = 0.8119130701278195, disc_loss = 0.09448133497216711
Trained batch 132 in epoch 12, gen_loss = 0.8116415799560404, disc_loss = 0.0940031105988568
Trained batch 133 in epoch 12, gen_loss = 0.8112531382201323, disc_loss = 0.09364241292811375
Trained batch 134 in epoch 12, gen_loss = 0.8098196588180683, disc_loss = 0.0936114479891128
Trained batch 135 in epoch 12, gen_loss = 0.8097970680717159, disc_loss = 0.09372498542207348
Trained batch 136 in epoch 12, gen_loss = 0.8107605069658183, disc_loss = 0.09380850204722072
Trained batch 137 in epoch 12, gen_loss = 0.8078065089125565, disc_loss = 0.09498294484059232
Trained batch 138 in epoch 12, gen_loss = 0.8061490438396125, disc_loss = 0.09542368554088065
Trained batch 139 in epoch 12, gen_loss = 0.8082667105964252, disc_loss = 0.09598473095601158
Trained batch 140 in epoch 12, gen_loss = 0.8065877732232953, disc_loss = 0.0961658670137643
Trained batch 141 in epoch 12, gen_loss = 0.8060138899255807, disc_loss = 0.09612143021995123
Trained batch 142 in epoch 12, gen_loss = 0.8072841773916791, disc_loss = 0.09689013871618292
Trained batch 143 in epoch 12, gen_loss = 0.8073523415045606, disc_loss = 0.09641520840038235
Trained batch 144 in epoch 12, gen_loss = 0.8066092300003973, disc_loss = 0.09617817114781717
Trained batch 145 in epoch 12, gen_loss = 0.8062749045760664, disc_loss = 0.09574464757684363
Trained batch 146 in epoch 12, gen_loss = 0.8067334328784423, disc_loss = 0.0953569897849645
Trained batch 147 in epoch 12, gen_loss = 0.8082149429498492, disc_loss = 0.09546243269122331
Trained batch 148 in epoch 12, gen_loss = 0.8068632465480958, disc_loss = 0.09523980795162036
Trained batch 149 in epoch 12, gen_loss = 0.8071887054045995, disc_loss = 0.09523278530066212
Trained batch 150 in epoch 12, gen_loss = 0.8055547008056514, disc_loss = 0.09576057988706212
Trained batch 151 in epoch 12, gen_loss = 0.8066807132410375, disc_loss = 0.09536217112020638
Trained batch 152 in epoch 12, gen_loss = 0.8079186083834156, disc_loss = 0.09544645603502692
Trained batch 153 in epoch 12, gen_loss = 0.8066408318745626, disc_loss = 0.09547235674599742
Trained batch 154 in epoch 12, gen_loss = 0.8071858934817776, disc_loss = 0.09499340678054478
Trained batch 155 in epoch 12, gen_loss = 0.8080531009114705, disc_loss = 0.09455799541245095
Trained batch 156 in epoch 12, gen_loss = 0.8064864739111275, disc_loss = 0.09476914660779724
Trained batch 157 in epoch 12, gen_loss = 0.8053639668829834, disc_loss = 0.09474155580907871
Trained batch 158 in epoch 12, gen_loss = 0.8059768757355288, disc_loss = 0.09445415831422843
Trained batch 159 in epoch 12, gen_loss = 0.8073443485423922, disc_loss = 0.0939678417344112
Trained batch 160 in epoch 12, gen_loss = 0.8088341364579171, disc_loss = 0.09345559870118494
Trained batch 161 in epoch 12, gen_loss = 0.8084838627665131, disc_loss = 0.09321091495983211
Trained batch 162 in epoch 12, gen_loss = 0.8114126125362022, disc_loss = 0.093035034029716
Trained batch 163 in epoch 12, gen_loss = 0.8099661482180037, disc_loss = 0.09311233031018297
Trained batch 164 in epoch 12, gen_loss = 0.8106542679396542, disc_loss = 0.09270743849038175
Trained batch 165 in epoch 12, gen_loss = 0.8097220434840903, disc_loss = 0.09258650440206549
Trained batch 166 in epoch 12, gen_loss = 0.8103681972283803, disc_loss = 0.0924475691309143
Trained batch 167 in epoch 12, gen_loss = 0.8105951233633927, disc_loss = 0.09209627799490201
Trained batch 168 in epoch 12, gen_loss = 0.810074952050779, disc_loss = 0.09202294509593376
Trained batch 169 in epoch 12, gen_loss = 0.8108006661429125, disc_loss = 0.09164750476860825
Trained batch 170 in epoch 12, gen_loss = 0.812642732036044, disc_loss = 0.09120959625715575
Trained batch 171 in epoch 12, gen_loss = 0.8127453204157741, disc_loss = 0.09082013893287716
Trained batch 172 in epoch 12, gen_loss = 0.8126176824803987, disc_loss = 0.0904567969338484
Trained batch 173 in epoch 12, gen_loss = 0.8135119870133783, disc_loss = 0.09008229620776129
Trained batch 174 in epoch 12, gen_loss = 0.8130132067203522, disc_loss = 0.08982979313071285
Trained batch 175 in epoch 12, gen_loss = 0.8141457003287293, disc_loss = 0.08945240889443085
Trained batch 176 in epoch 12, gen_loss = 0.8166201469925164, disc_loss = 0.08917414418574275
Trained batch 177 in epoch 12, gen_loss = 0.815542582213209, disc_loss = 0.08933069360745924
Trained batch 178 in epoch 12, gen_loss = 0.8159749159932802, disc_loss = 0.08943359591795245
Trained batch 179 in epoch 12, gen_loss = 0.815670788122548, disc_loss = 0.08908469593669806
Trained batch 180 in epoch 12, gen_loss = 0.8155535826696216, disc_loss = 0.08883118268761023
Trained batch 181 in epoch 12, gen_loss = 0.8179580430080603, disc_loss = 0.08865573481851063
Trained batch 182 in epoch 12, gen_loss = 0.8194056793314511, disc_loss = 0.08829620442368456
Trained batch 183 in epoch 12, gen_loss = 0.8199999230387418, disc_loss = 0.08788580157409381
Trained batch 184 in epoch 12, gen_loss = 0.8203337799858402, disc_loss = 0.08753794405005268
Trained batch 185 in epoch 12, gen_loss = 0.821399585053485, disc_loss = 0.08745961593744415
Trained batch 186 in epoch 12, gen_loss = 0.8222248326329624, disc_loss = 0.08706444387329135
Trained batch 187 in epoch 12, gen_loss = 0.8206764806775336, disc_loss = 0.08711244915909272
Trained batch 188 in epoch 12, gen_loss = 0.8204728533666601, disc_loss = 0.08686018598182176
Trained batch 189 in epoch 12, gen_loss = 0.8206644285666315, disc_loss = 0.08659026057116295
Trained batch 190 in epoch 12, gen_loss = 0.8210534146006819, disc_loss = 0.08629890178276606
Trained batch 191 in epoch 12, gen_loss = 0.821521057592084, disc_loss = 0.08598659909330308
Trained batch 192 in epoch 12, gen_loss = 0.8227401269223406, disc_loss = 0.08559189173224059
Trained batch 193 in epoch 12, gen_loss = 0.8238864014136422, disc_loss = 0.08562085009420041
Trained batch 194 in epoch 12, gen_loss = 0.8242372538798894, disc_loss = 0.08547840359119269
Trained batch 195 in epoch 12, gen_loss = 0.8231553485503003, disc_loss = 0.08592008202507788
Trained batch 196 in epoch 12, gen_loss = 0.8227300630305624, disc_loss = 0.08591344449574573
Trained batch 197 in epoch 12, gen_loss = 0.8227991785364922, disc_loss = 0.0856583324270417
Trained batch 198 in epoch 12, gen_loss = 0.8237313653655987, disc_loss = 0.08567395780104489
Trained batch 199 in epoch 12, gen_loss = 0.8231713442504406, disc_loss = 0.08556145962327719
Trained batch 200 in epoch 12, gen_loss = 0.8226788534750393, disc_loss = 0.08551498543267226
Trained batch 201 in epoch 12, gen_loss = 0.8244298358659933, disc_loss = 0.0851979835032679
Trained batch 202 in epoch 12, gen_loss = 0.8234291697664214, disc_loss = 0.08526869062242542
Trained batch 203 in epoch 12, gen_loss = 0.8241013026997155, disc_loss = 0.0849695561691096
Trained batch 204 in epoch 12, gen_loss = 0.8259152361532537, disc_loss = 0.0847204205375619
Trained batch 205 in epoch 12, gen_loss = 0.825214731317122, disc_loss = 0.08446416435130302
Trained batch 206 in epoch 12, gen_loss = 0.8266939672007076, disc_loss = 0.08422821644099726
Trained batch 207 in epoch 12, gen_loss = 0.8253128060068076, disc_loss = 0.08455939418098961
Trained batch 208 in epoch 12, gen_loss = 0.8250641852759859, disc_loss = 0.08455472463590391
Trained batch 209 in epoch 12, gen_loss = 0.8257376970279784, disc_loss = 0.08429055021454891
Trained batch 210 in epoch 12, gen_loss = 0.825541099524611, disc_loss = 0.08464162184976005
Trained batch 211 in epoch 12, gen_loss = 0.8243312766810633, disc_loss = 0.08494200458187821
Trained batch 212 in epoch 12, gen_loss = 0.8242689792259198, disc_loss = 0.08501108801385886
Trained batch 213 in epoch 12, gen_loss = 0.8234737037776787, disc_loss = 0.08479679975589023
Trained batch 214 in epoch 12, gen_loss = 0.8234458281550296, disc_loss = 0.08475897961057896
Trained batch 215 in epoch 12, gen_loss = 0.8260507264898883, disc_loss = 0.08485211750182013
Trained batch 216 in epoch 12, gen_loss = 0.8245229749910293, disc_loss = 0.08549432903699886
Trained batch 217 in epoch 12, gen_loss = 0.8259791011383774, disc_loss = 0.08523838865408383
Trained batch 218 in epoch 12, gen_loss = 0.8267539817176454, disc_loss = 0.08501896337865422
Trained batch 219 in epoch 12, gen_loss = 0.8263583989305929, disc_loss = 0.08509988338601861
Trained batch 220 in epoch 12, gen_loss = 0.826602731220323, disc_loss = 0.08484176490708714
Trained batch 221 in epoch 12, gen_loss = 0.8266790250131676, disc_loss = 0.08456670638878604
Trained batch 222 in epoch 12, gen_loss = 0.8267677438366039, disc_loss = 0.08434973311330705
Trained batch 223 in epoch 12, gen_loss = 0.8256259894530688, disc_loss = 0.08474643064463246
Trained batch 224 in epoch 12, gen_loss = 0.8255819176303015, disc_loss = 0.08454141429728931
Trained batch 225 in epoch 12, gen_loss = 0.8265001524602418, disc_loss = 0.08437588001576672
Trained batch 226 in epoch 12, gen_loss = 0.8279420388165024, disc_loss = 0.08427072695501575
Trained batch 227 in epoch 12, gen_loss = 0.827568859254059, disc_loss = 0.08438342357087031
Trained batch 228 in epoch 12, gen_loss = 0.8280342563531284, disc_loss = 0.0842397148724987
Trained batch 229 in epoch 12, gen_loss = 0.827509556516357, disc_loss = 0.08406559463752353
Trained batch 230 in epoch 12, gen_loss = 0.8280800440352717, disc_loss = 0.08400730612925637
Trained batch 231 in epoch 12, gen_loss = 0.827722525416777, disc_loss = 0.08373776088661418
Trained batch 232 in epoch 12, gen_loss = 0.8272924744264251, disc_loss = 0.08370212638998492
Trained batch 233 in epoch 12, gen_loss = 0.8281586663081095, disc_loss = 0.08343487384163925
Trained batch 234 in epoch 12, gen_loss = 0.8302692721498773, disc_loss = 0.08345268627113485
Trained batch 235 in epoch 12, gen_loss = 0.8311082128498514, disc_loss = 0.08332705339890416
Trained batch 236 in epoch 12, gen_loss = 0.829983179453556, disc_loss = 0.08363515798804126
Trained batch 237 in epoch 12, gen_loss = 0.8293236522864895, disc_loss = 0.0836815378558235
Trained batch 238 in epoch 12, gen_loss = 0.8312335312366486, disc_loss = 0.0840472128538407
Trained batch 239 in epoch 12, gen_loss = 0.8315464063237111, disc_loss = 0.08385949820900956
Trained batch 240 in epoch 12, gen_loss = 0.8324084547792727, disc_loss = 0.08358020495422401
Trained batch 241 in epoch 12, gen_loss = 0.8318076322147668, disc_loss = 0.08413787841150337
Trained batch 242 in epoch 12, gen_loss = 0.8327202390986705, disc_loss = 0.08409207589433762
Trained batch 243 in epoch 12, gen_loss = 0.8333022747127736, disc_loss = 0.08388397476987028
Trained batch 244 in epoch 12, gen_loss = 0.8325245182124936, disc_loss = 0.0837460389018667
Trained batch 245 in epoch 12, gen_loss = 0.8327691132217888, disc_loss = 0.08360196432719628
Trained batch 246 in epoch 12, gen_loss = 0.8332972288855657, disc_loss = 0.08342866723987497
Trained batch 247 in epoch 12, gen_loss = 0.8333132323478499, disc_loss = 0.08320060036625833
Trained batch 248 in epoch 12, gen_loss = 0.8337492127734495, disc_loss = 0.0829129225189188
Trained batch 249 in epoch 12, gen_loss = 0.8329504379034043, disc_loss = 0.0831370582729578
Trained batch 250 in epoch 12, gen_loss = 0.8336033126509997, disc_loss = 0.08300185445473489
Trained batch 251 in epoch 12, gen_loss = 0.8337744312390448, disc_loss = 0.08309382515116817
Trained batch 252 in epoch 12, gen_loss = 0.8329467084332417, disc_loss = 0.0831793234076189
Trained batch 253 in epoch 12, gen_loss = 0.8331719138256208, disc_loss = 0.0831205278312362
Trained batch 254 in epoch 12, gen_loss = 0.8339359459923763, disc_loss = 0.08297170285208552
Trained batch 255 in epoch 12, gen_loss = 0.8340185930719599, disc_loss = 0.08279818065057043
Trained batch 256 in epoch 12, gen_loss = 0.8330285793844364, disc_loss = 0.08272902950180644
Trained batch 257 in epoch 12, gen_loss = 0.8329949398604475, disc_loss = 0.08255993424690972
Trained batch 258 in epoch 12, gen_loss = 0.8334540318568241, disc_loss = 0.0825034542491077
Trained batch 259 in epoch 12, gen_loss = 0.8332015212911826, disc_loss = 0.08248828059205641
Trained batch 260 in epoch 12, gen_loss = 0.8329858269499636, disc_loss = 0.0823179077770975
Trained batch 261 in epoch 12, gen_loss = 0.83334112906729, disc_loss = 0.08229121307039079
Trained batch 262 in epoch 12, gen_loss = 0.8324663309316671, disc_loss = 0.08240456216235578
Trained batch 263 in epoch 12, gen_loss = 0.8326825132649956, disc_loss = 0.08220044036649844
Trained batch 264 in epoch 12, gen_loss = 0.8327833327482331, disc_loss = 0.08217741530740036
Trained batch 265 in epoch 12, gen_loss = 0.8334602416682064, disc_loss = 0.08230632827862312
Trained batch 266 in epoch 12, gen_loss = 0.8318582842412513, disc_loss = 0.08293649681219448
Trained batch 267 in epoch 12, gen_loss = 0.8323189040173345, disc_loss = 0.0828263125757673
Trained batch 268 in epoch 12, gen_loss = 0.833478385409458, disc_loss = 0.08272890612261447
Trained batch 269 in epoch 12, gen_loss = 0.83266390937346, disc_loss = 0.08272045176062319
Trained batch 270 in epoch 12, gen_loss = 0.8320544274090841, disc_loss = 0.08269076201913542
Trained batch 271 in epoch 12, gen_loss = 0.832247591632254, disc_loss = 0.08244381962097524
Trained batch 272 in epoch 12, gen_loss = 0.8332201888709715, disc_loss = 0.0823691550696835
Trained batch 273 in epoch 12, gen_loss = 0.8329983244847207, disc_loss = 0.08224731906024861
Trained batch 274 in epoch 12, gen_loss = 0.8321011419729752, disc_loss = 0.08235600226982073
Trained batch 275 in epoch 12, gen_loss = 0.8318201277566992, disc_loss = 0.08225378811872308
Trained batch 276 in epoch 12, gen_loss = 0.8329042613721497, disc_loss = 0.0822001694758769
Trained batch 277 in epoch 12, gen_loss = 0.8332367642320317, disc_loss = 0.08201546075907971
Trained batch 278 in epoch 12, gen_loss = 0.8330229678888902, disc_loss = 0.08184396319331662
Trained batch 279 in epoch 12, gen_loss = 0.8324532789843423, disc_loss = 0.0817080236439194
Trained batch 280 in epoch 12, gen_loss = 0.8336011642238847, disc_loss = 0.08180201066876645
Trained batch 281 in epoch 12, gen_loss = 0.8332136670748392, disc_loss = 0.08170636402482682
Trained batch 282 in epoch 12, gen_loss = 0.833061430563775, disc_loss = 0.08155164609633571
Trained batch 283 in epoch 12, gen_loss = 0.8332295359020502, disc_loss = 0.08137036621255773
Trained batch 284 in epoch 12, gen_loss = 0.8327324689480297, disc_loss = 0.08129407598784096
Trained batch 285 in epoch 12, gen_loss = 0.832370510676524, disc_loss = 0.08119321400885815
Trained batch 286 in epoch 12, gen_loss = 0.8328593632900756, disc_loss = 0.08127544147939217
Trained batch 287 in epoch 12, gen_loss = 0.8337971311476495, disc_loss = 0.08107073670382509
Trained batch 288 in epoch 12, gen_loss = 0.8326350332956413, disc_loss = 0.08171443546442218
Trained batch 289 in epoch 12, gen_loss = 0.8323555931962769, disc_loss = 0.08159539188932756
Trained batch 290 in epoch 12, gen_loss = 0.8336250349828058, disc_loss = 0.08204658757703207
Trained batch 291 in epoch 12, gen_loss = 0.8341027283913469, disc_loss = 0.08180621460922165
Trained batch 292 in epoch 12, gen_loss = 0.8332946855867275, disc_loss = 0.08189132573788686
Trained batch 293 in epoch 12, gen_loss = 0.832841541896872, disc_loss = 0.0817326577253589
Trained batch 294 in epoch 12, gen_loss = 0.8339005054053613, disc_loss = 0.08159090998440476
Trained batch 295 in epoch 12, gen_loss = 0.83370880661784, disc_loss = 0.08143770468824015
Trained batch 296 in epoch 12, gen_loss = 0.8337211173391502, disc_loss = 0.0813597301052576
Trained batch 297 in epoch 12, gen_loss = 0.8334545865154906, disc_loss = 0.08121980959862071
Trained batch 298 in epoch 12, gen_loss = 0.8339661497336167, disc_loss = 0.08114566358061738
Trained batch 299 in epoch 12, gen_loss = 0.8335485400756201, disc_loss = 0.08108413043742378
Trained batch 300 in epoch 12, gen_loss = 0.8335848640761898, disc_loss = 0.08088163609471036
Trained batch 301 in epoch 12, gen_loss = 0.8335598389439235, disc_loss = 0.08077513420374582
Trained batch 302 in epoch 12, gen_loss = 0.8344584748689884, disc_loss = 0.08074069530902916
Trained batch 303 in epoch 12, gen_loss = 0.8343526652376902, disc_loss = 0.08054856175409728
Trained batch 304 in epoch 12, gen_loss = 0.8350873644234704, disc_loss = 0.08037409185141814
Trained batch 305 in epoch 12, gen_loss = 0.8342680800584407, disc_loss = 0.08062150308655368
Trained batch 306 in epoch 12, gen_loss = 0.8345953950276204, disc_loss = 0.0804495837430224
Trained batch 307 in epoch 12, gen_loss = 0.8349281597834128, disc_loss = 0.08026254699601755
Trained batch 308 in epoch 12, gen_loss = 0.8345163360382747, disc_loss = 0.08012329101032038
Trained batch 309 in epoch 12, gen_loss = 0.8348215362718029, disc_loss = 0.07989282873308946
Trained batch 310 in epoch 12, gen_loss = 0.8347590119125758, disc_loss = 0.07973675443895664
Trained batch 311 in epoch 12, gen_loss = 0.8344258616367976, disc_loss = 0.07965345500120655
Trained batch 312 in epoch 12, gen_loss = 0.8338083390610668, disc_loss = 0.07967715585134186
Trained batch 313 in epoch 12, gen_loss = 0.8342683620893272, disc_loss = 0.07977031376272155
Trained batch 314 in epoch 12, gen_loss = 0.8350958939582582, disc_loss = 0.07965654739962211
Trained batch 315 in epoch 12, gen_loss = 0.8354978497269787, disc_loss = 0.07958647995137999
Trained batch 316 in epoch 12, gen_loss = 0.83417306807515, disc_loss = 0.0802308504296355
Trained batch 317 in epoch 12, gen_loss = 0.8345829400251497, disc_loss = 0.08001797371280361
Trained batch 318 in epoch 12, gen_loss = 0.8361570235330109, disc_loss = 0.08030788573877284
Trained batch 319 in epoch 12, gen_loss = 0.8354527613148093, disc_loss = 0.08042318661755417
Trained batch 320 in epoch 12, gen_loss = 0.8342600596656681, disc_loss = 0.08069366178652301
Trained batch 321 in epoch 12, gen_loss = 0.8335381461226422, disc_loss = 0.08075709940911913
Trained batch 322 in epoch 12, gen_loss = 0.8326874786855266, disc_loss = 0.08086037831006128
Trained batch 323 in epoch 12, gen_loss = 0.8330299631680971, disc_loss = 0.0808826759831267
Trained batch 324 in epoch 12, gen_loss = 0.833478921193343, disc_loss = 0.0812856033587685
Trained batch 325 in epoch 12, gen_loss = 0.832440208986493, disc_loss = 0.08159077052381232
Trained batch 326 in epoch 12, gen_loss = 0.8323271487830975, disc_loss = 0.0815150417894444
Trained batch 327 in epoch 12, gen_loss = 0.8320834923808168, disc_loss = 0.08150429730928253
Trained batch 328 in epoch 12, gen_loss = 0.8323731585476536, disc_loss = 0.08135154126863077
Trained batch 329 in epoch 12, gen_loss = 0.8321140428384145, disc_loss = 0.08144587040455505
Trained batch 330 in epoch 12, gen_loss = 0.8318287949907816, disc_loss = 0.08159013183961912
Trained batch 331 in epoch 12, gen_loss = 0.831469008901033, disc_loss = 0.08175754813331527
Trained batch 332 in epoch 12, gen_loss = 0.831137707104554, disc_loss = 0.08170428137398428
Trained batch 333 in epoch 12, gen_loss = 0.8309324137464968, disc_loss = 0.08159956117690413
Trained batch 334 in epoch 12, gen_loss = 0.8309811905248842, disc_loss = 0.08145483456718833
Trained batch 335 in epoch 12, gen_loss = 0.8310047583211035, disc_loss = 0.08155845558281899
Trained batch 336 in epoch 12, gen_loss = 0.8309312590151937, disc_loss = 0.08146289740730553
Trained batch 337 in epoch 12, gen_loss = 0.8306234501875364, disc_loss = 0.08143595939215559
Trained batch 338 in epoch 12, gen_loss = 0.8304542950120999, disc_loss = 0.08142597523070103
Trained batch 339 in epoch 12, gen_loss = 0.83007052155102, disc_loss = 0.08148489371216035
Trained batch 340 in epoch 12, gen_loss = 0.8295983446658182, disc_loss = 0.08143959448145718
Trained batch 341 in epoch 12, gen_loss = 0.8291784591144986, disc_loss = 0.08163419926038001
Trained batch 342 in epoch 12, gen_loss = 0.8304091858794321, disc_loss = 0.08208987080158106
Trained batch 343 in epoch 12, gen_loss = 0.8295080147163812, disc_loss = 0.08264791157887165
Trained batch 344 in epoch 12, gen_loss = 0.8297888638316722, disc_loss = 0.08256479530068843
Trained batch 345 in epoch 12, gen_loss = 0.8296471785947767, disc_loss = 0.08242189867228183
Trained batch 346 in epoch 12, gen_loss = 0.8298741754262523, disc_loss = 0.08231164158861386
Trained batch 347 in epoch 12, gen_loss = 0.8293752899800224, disc_loss = 0.08241349369041279
Trained batch 348 in epoch 12, gen_loss = 0.829175245112881, disc_loss = 0.08254946952146668
Trained batch 349 in epoch 12, gen_loss = 0.8294327756336757, disc_loss = 0.08251568822190165
Trained batch 350 in epoch 12, gen_loss = 0.8290844602122945, disc_loss = 0.0825678579047577
Trained batch 351 in epoch 12, gen_loss = 0.8284697795117443, disc_loss = 0.08271001425666989
Trained batch 352 in epoch 12, gen_loss = 0.8285429246364842, disc_loss = 0.08269364904169067
Trained batch 353 in epoch 12, gen_loss = 0.8283472871039547, disc_loss = 0.08269950707764023
Trained batch 354 in epoch 12, gen_loss = 0.8278961935513456, disc_loss = 0.0825973449904524
Trained batch 355 in epoch 12, gen_loss = 0.8281569328535808, disc_loss = 0.08258065322068718
Trained batch 356 in epoch 12, gen_loss = 0.8274945553277387, disc_loss = 0.08276887760035881
Trained batch 357 in epoch 12, gen_loss = 0.8274839333981775, disc_loss = 0.082697780961535
Trained batch 358 in epoch 12, gen_loss = 0.8285406641973426, disc_loss = 0.08266101854601693
Trained batch 359 in epoch 12, gen_loss = 0.8278003570106295, disc_loss = 0.08290901720368614
Trained batch 360 in epoch 12, gen_loss = 0.8274755276471294, disc_loss = 0.0829781339919179
Trained batch 361 in epoch 12, gen_loss = 0.8271993316339524, disc_loss = 0.08286297320547766
Trained batch 362 in epoch 12, gen_loss = 0.8274936216265045, disc_loss = 0.08299391163826071
Trained batch 363 in epoch 12, gen_loss = 0.8271377905384525, disc_loss = 0.08281924673049086
Trained batch 364 in epoch 12, gen_loss = 0.8272898564599964, disc_loss = 0.08266342773982516
Trained batch 365 in epoch 12, gen_loss = 0.8271763033228494, disc_loss = 0.08252067931881937
Trained batch 366 in epoch 12, gen_loss = 0.8268155874608323, disc_loss = 0.0825372816060926
Trained batch 367 in epoch 12, gen_loss = 0.8267546890546447, disc_loss = 0.08241213673634616
Trained batch 368 in epoch 12, gen_loss = 0.8266127787954439, disc_loss = 0.0822545495010448
Trained batch 369 in epoch 12, gen_loss = 0.8268770960537163, disc_loss = 0.08208774994505015
Trained batch 370 in epoch 12, gen_loss = 0.8264701679710429, disc_loss = 0.08205882397372366
Trained batch 371 in epoch 12, gen_loss = 0.82635872194203, disc_loss = 0.08193516078084627
Trained batch 372 in epoch 12, gen_loss = 0.8266674952916102, disc_loss = 0.08185088757085976
Trained batch 373 in epoch 12, gen_loss = 0.8281302342121614, disc_loss = 0.08197896774947883
Trained batch 374 in epoch 12, gen_loss = 0.8282921862602234, disc_loss = 0.08182003832111756
Trained batch 375 in epoch 12, gen_loss = 0.8274961216969693, disc_loss = 0.0819039116737413
Trained batch 376 in epoch 12, gen_loss = 0.8271909757697614, disc_loss = 0.08184619245195973
Trained batch 377 in epoch 12, gen_loss = 0.8275234148931251, disc_loss = 0.08176986833975192
Trained batch 378 in epoch 12, gen_loss = 0.8271956379306662, disc_loss = 0.08179056241685687
Trained batch 379 in epoch 12, gen_loss = 0.8273030608892441, disc_loss = 0.08169517676149936
Trained batch 380 in epoch 12, gen_loss = 0.8271150878408137, disc_loss = 0.0816182805606582
Trained batch 381 in epoch 12, gen_loss = 0.8273134092697922, disc_loss = 0.08151035303620534
Trained batch 382 in epoch 12, gen_loss = 0.8273005399940531, disc_loss = 0.08134190998631032
Trained batch 383 in epoch 12, gen_loss = 0.8268403167215487, disc_loss = 0.08128726562669424
Trained batch 384 in epoch 12, gen_loss = 0.8269970842770168, disc_loss = 0.08112053665780015
Trained batch 385 in epoch 12, gen_loss = 0.827284236491653, disc_loss = 0.081096196670201
Trained batch 386 in epoch 12, gen_loss = 0.827214665037101, disc_loss = 0.0809952499999518
Trained batch 387 in epoch 12, gen_loss = 0.8266393178209817, disc_loss = 0.08108717427569796
Trained batch 388 in epoch 12, gen_loss = 0.8269758970694554, disc_loss = 0.0810117583439367
Trained batch 389 in epoch 12, gen_loss = 0.8266302853058546, disc_loss = 0.08098599155887197
Trained batch 390 in epoch 12, gen_loss = 0.8265474818246749, disc_loss = 0.08095911030640916
Trained batch 391 in epoch 12, gen_loss = 0.8259800800255367, disc_loss = 0.08116695254195329
Trained batch 392 in epoch 12, gen_loss = 0.8261485689772298, disc_loss = 0.08109836223234278
Trained batch 393 in epoch 12, gen_loss = 0.8265714745231086, disc_loss = 0.08092424996565971
Trained batch 394 in epoch 12, gen_loss = 0.8268185630629334, disc_loss = 0.08081622728960046
Trained batch 395 in epoch 12, gen_loss = 0.8264744217046583, disc_loss = 0.08069725518792191
Trained batch 396 in epoch 12, gen_loss = 0.8263229495031708, disc_loss = 0.08061403047143287
Trained batch 397 in epoch 12, gen_loss = 0.8259241943383336, disc_loss = 0.08063688909578788
Trained batch 398 in epoch 12, gen_loss = 0.826116070562138, disc_loss = 0.08062418398767113
Trained batch 399 in epoch 12, gen_loss = 0.826130410283804, disc_loss = 0.08059815427055582
Trained batch 400 in epoch 12, gen_loss = 0.8254070169016012, disc_loss = 0.08081699195933387
Trained batch 401 in epoch 12, gen_loss = 0.8253369608625251, disc_loss = 0.0808282425020131
Trained batch 402 in epoch 12, gen_loss = 0.8259480799693919, disc_loss = 0.0807565974959036
Trained batch 403 in epoch 12, gen_loss = 0.8261288447250233, disc_loss = 0.08068986266325827
Trained batch 404 in epoch 12, gen_loss = 0.8258663829462027, disc_loss = 0.08058637601127963
Trained batch 405 in epoch 12, gen_loss = 0.8261066711888525, disc_loss = 0.08042086122942896
Trained batch 406 in epoch 12, gen_loss = 0.8257024746562105, disc_loss = 0.08048177327210179
Trained batch 407 in epoch 12, gen_loss = 0.8251045343338275, disc_loss = 0.08055361705220432
Trained batch 408 in epoch 12, gen_loss = 0.8266379498036391, disc_loss = 0.08084514141219389
Trained batch 409 in epoch 12, gen_loss = 0.826998597238122, disc_loss = 0.08080129210678179
Trained batch 410 in epoch 12, gen_loss = 0.8266594757998946, disc_loss = 0.08083531515867678
Trained batch 411 in epoch 12, gen_loss = 0.8267625105901829, disc_loss = 0.08066833404670425
Trained batch 412 in epoch 12, gen_loss = 0.8268337492215432, disc_loss = 0.08052441480707098
Trained batch 413 in epoch 12, gen_loss = 0.8267793966376263, disc_loss = 0.08054646447633848
Trained batch 414 in epoch 12, gen_loss = 0.8261470457157457, disc_loss = 0.08071236913148538
Trained batch 415 in epoch 12, gen_loss = 0.8264186774881986, disc_loss = 0.08070857732673176
Trained batch 416 in epoch 12, gen_loss = 0.8273900990291752, disc_loss = 0.08066377877447602
Trained batch 417 in epoch 12, gen_loss = 0.8270374482328241, disc_loss = 0.08070252451858523
Trained batch 418 in epoch 12, gen_loss = 0.8262668304625446, disc_loss = 0.08094258266134378
Trained batch 419 in epoch 12, gen_loss = 0.8263104748158228, disc_loss = 0.08082221344423791
Trained batch 420 in epoch 12, gen_loss = 0.8271442170380979, disc_loss = 0.08084041376392448
Trained batch 421 in epoch 12, gen_loss = 0.8271900084911364, disc_loss = 0.08088469583655915
Trained batch 422 in epoch 12, gen_loss = 0.8268189612009846, disc_loss = 0.08103756519171011
Trained batch 423 in epoch 12, gen_loss = 0.826511579723853, disc_loss = 0.08097948848032656
Trained batch 424 in epoch 12, gen_loss = 0.8260609762808856, disc_loss = 0.08097059758927892
Trained batch 425 in epoch 12, gen_loss = 0.8261814863189285, disc_loss = 0.08117420083576454
Trained batch 426 in epoch 12, gen_loss = 0.8260797806590168, disc_loss = 0.08103576416599038
Trained batch 427 in epoch 12, gen_loss = 0.8254222791885661, disc_loss = 0.08114568362334551
Trained batch 428 in epoch 12, gen_loss = 0.8259358517217747, disc_loss = 0.0810542382660272
Trained batch 429 in epoch 12, gen_loss = 0.8259950050087862, disc_loss = 0.0809448372984175
Trained batch 430 in epoch 12, gen_loss = 0.8263358195807153, disc_loss = 0.08086136387760498
Trained batch 431 in epoch 12, gen_loss = 0.8261000456081496, disc_loss = 0.08083003386639541
Trained batch 432 in epoch 12, gen_loss = 0.8258617385430369, disc_loss = 0.08074034304588207
Trained batch 433 in epoch 12, gen_loss = 0.8257830482199445, disc_loss = 0.08065875046907962
Trained batch 434 in epoch 12, gen_loss = 0.8261313690536324, disc_loss = 0.0805440002666979
Trained batch 435 in epoch 12, gen_loss = 0.8261262525659089, disc_loss = 0.08039274234153809
Trained batch 436 in epoch 12, gen_loss = 0.8259363474507626, disc_loss = 0.08030907564223222
Trained batch 437 in epoch 12, gen_loss = 0.8258793412550399, disc_loss = 0.08034259550375482
Trained batch 438 in epoch 12, gen_loss = 0.8256337532692999, disc_loss = 0.08027696572159308
Trained batch 439 in epoch 12, gen_loss = 0.8255102256482297, disc_loss = 0.08019521525976332
Trained batch 440 in epoch 12, gen_loss = 0.8259389996528625, disc_loss = 0.08006536279743762
Trained batch 441 in epoch 12, gen_loss = 0.8261472100046425, disc_loss = 0.07992092343426532
Trained batch 442 in epoch 12, gen_loss = 0.8259739369893989, disc_loss = 0.07983322874232958
Trained batch 443 in epoch 12, gen_loss = 0.8257497774588095, disc_loss = 0.07992135468652253
Trained batch 444 in epoch 12, gen_loss = 0.825959215137396, disc_loss = 0.07976416966176769
Trained batch 445 in epoch 12, gen_loss = 0.8258329596487396, disc_loss = 0.07967192465606492
Trained batch 446 in epoch 12, gen_loss = 0.825840604651961, disc_loss = 0.07965391879105395
Trained batch 447 in epoch 12, gen_loss = 0.8257130458950996, disc_loss = 0.07959894296904427
Trained batch 448 in epoch 12, gen_loss = 0.8254877194795417, disc_loss = 0.07953157843212973
Trained batch 449 in epoch 12, gen_loss = 0.82563013487392, disc_loss = 0.07938646241815554
Trained batch 450 in epoch 12, gen_loss = 0.8269929242239823, disc_loss = 0.07985132805251427
Trained batch 451 in epoch 12, gen_loss = 0.8267083812867646, disc_loss = 0.07985526900037926
Trained batch 452 in epoch 12, gen_loss = 0.8259614834985459, disc_loss = 0.08006047353633652
Trained batch 453 in epoch 12, gen_loss = 0.8261970598004463, disc_loss = 0.07995463328206263
Trained batch 454 in epoch 12, gen_loss = 0.8260723903938965, disc_loss = 0.08015463392935938
Trained batch 455 in epoch 12, gen_loss = 0.8257014397204968, disc_loss = 0.08009248764229644
Trained batch 456 in epoch 12, gen_loss = 0.8258693661679324, disc_loss = 0.08023656104004552
Trained batch 457 in epoch 12, gen_loss = 0.8257629889588168, disc_loss = 0.08013228294297271
Trained batch 458 in epoch 12, gen_loss = 0.8256648681522195, disc_loss = 0.08003516168757656
Trained batch 459 in epoch 12, gen_loss = 0.8256436014952867, disc_loss = 0.07996682219166795
Trained batch 460 in epoch 12, gen_loss = 0.825873349726588, disc_loss = 0.07996892932915571
Trained batch 461 in epoch 12, gen_loss = 0.8257167802486585, disc_loss = 0.07987140068881117
Trained batch 462 in epoch 12, gen_loss = 0.8260416116879259, disc_loss = 0.07972276151043485
Trained batch 463 in epoch 12, gen_loss = 0.8259037413216871, disc_loss = 0.07968618124843864
Trained batch 464 in epoch 12, gen_loss = 0.8259548118037562, disc_loss = 0.07956346660171465
Trained batch 465 in epoch 12, gen_loss = 0.8262661736410575, disc_loss = 0.07947553579731496
Trained batch 466 in epoch 12, gen_loss = 0.8257468300662153, disc_loss = 0.07957410139711753
Trained batch 467 in epoch 12, gen_loss = 0.8261342104683574, disc_loss = 0.0794509591984475
Trained batch 468 in epoch 12, gen_loss = 0.8267119683182316, disc_loss = 0.0793646350125673
Trained batch 469 in epoch 12, gen_loss = 0.8263890847246698, disc_loss = 0.07942352774652078
Trained batch 470 in epoch 12, gen_loss = 0.8259732014560902, disc_loss = 0.07938424794640067
Trained batch 471 in epoch 12, gen_loss = 0.8262555004429009, disc_loss = 0.07945386425520973
Trained batch 472 in epoch 12, gen_loss = 0.8261224541805259, disc_loss = 0.07939188814983875
Trained batch 473 in epoch 12, gen_loss = 0.8257324945826068, disc_loss = 0.07934705825239609
Trained batch 474 in epoch 12, gen_loss = 0.8260747511763322, disc_loss = 0.0792369846548689
Trained batch 475 in epoch 12, gen_loss = 0.8262190950267455, disc_loss = 0.07927030746965912
Trained batch 476 in epoch 12, gen_loss = 0.8264317613727642, disc_loss = 0.07916140373390114
Trained batch 477 in epoch 12, gen_loss = 0.8265556866404402, disc_loss = 0.07915155908918967
Trained batch 478 in epoch 12, gen_loss = 0.8261417563623575, disc_loss = 0.07927357666544414
Trained batch 479 in epoch 12, gen_loss = 0.8264897843201955, disc_loss = 0.07932152588036842
Trained batch 480 in epoch 12, gen_loss = 0.8264163091871694, disc_loss = 0.07927643670168029
Trained batch 481 in epoch 12, gen_loss = 0.8265510066663576, disc_loss = 0.07923649244311873
Trained batch 482 in epoch 12, gen_loss = 0.82656018605637, disc_loss = 0.07927812577859647
Trained batch 483 in epoch 12, gen_loss = 0.8262577319194463, disc_loss = 0.07928753583230201
Trained batch 484 in epoch 12, gen_loss = 0.8259101986885071, disc_loss = 0.07930282287338038
Trained batch 485 in epoch 12, gen_loss = 0.8263017121901728, disc_loss = 0.07958056229461798
Trained batch 486 in epoch 12, gen_loss = 0.8260953966107457, disc_loss = 0.07948790739808667
Trained batch 487 in epoch 12, gen_loss = 0.8254998787993291, disc_loss = 0.07954662816682984
Trained batch 488 in epoch 12, gen_loss = 0.8253655768854731, disc_loss = 0.07953043545430606
Trained batch 489 in epoch 12, gen_loss = 0.8255633180238763, disc_loss = 0.07943291244268114
Trained batch 490 in epoch 12, gen_loss = 0.8260506147522547, disc_loss = 0.07929653787981651
Trained batch 491 in epoch 12, gen_loss = 0.8260697304475598, disc_loss = 0.07920512362247015
Trained batch 492 in epoch 12, gen_loss = 0.8258270531832326, disc_loss = 0.07915834817869125
Trained batch 493 in epoch 12, gen_loss = 0.8257445255030504, disc_loss = 0.0791018809953531
Trained batch 494 in epoch 12, gen_loss = 0.8255991249373464, disc_loss = 0.0790521227331324
Trained batch 495 in epoch 12, gen_loss = 0.825862794513664, disc_loss = 0.07897322247698603
Trained batch 496 in epoch 12, gen_loss = 0.8263029376985561, disc_loss = 0.0788660873106158
Trained batch 497 in epoch 12, gen_loss = 0.8254741125078087, disc_loss = 0.07911525242382204
Trained batch 498 in epoch 12, gen_loss = 0.8257379012260743, disc_loss = 0.07942980259679303
Trained batch 499 in epoch 12, gen_loss = 0.8258232407569885, disc_loss = 0.07932230409793556
Trained batch 500 in epoch 12, gen_loss = 0.8258543313144447, disc_loss = 0.0792635244311776
Trained batch 501 in epoch 12, gen_loss = 0.8257887882302957, disc_loss = 0.07919053756168105
Trained batch 502 in epoch 12, gen_loss = 0.8258305303382115, disc_loss = 0.07909834351405412
Trained batch 503 in epoch 12, gen_loss = 0.8251877489780622, disc_loss = 0.07920258269563968
Trained batch 504 in epoch 12, gen_loss = 0.8256806400742861, disc_loss = 0.07932537843353382
Trained batch 505 in epoch 12, gen_loss = 0.8252997856601896, disc_loss = 0.07941376961760312
Trained batch 506 in epoch 12, gen_loss = 0.8250977431058414, disc_loss = 0.07944986352575778
Trained batch 507 in epoch 12, gen_loss = 0.8256596901754695, disc_loss = 0.07959262345272197
Trained batch 508 in epoch 12, gen_loss = 0.8255847589440336, disc_loss = 0.07965126694207517
Trained batch 509 in epoch 12, gen_loss = 0.8252208086789823, disc_loss = 0.07964952629534346
Trained batch 510 in epoch 12, gen_loss = 0.8249638597326036, disc_loss = 0.07981189222798597
Trained batch 511 in epoch 12, gen_loss = 0.8254603032255545, disc_loss = 0.07977291160023015
Trained batch 512 in epoch 12, gen_loss = 0.825436697252545, disc_loss = 0.07972517439489185
Trained batch 513 in epoch 12, gen_loss = 0.8252651531408733, disc_loss = 0.07973136501894097
Trained batch 514 in epoch 12, gen_loss = 0.8253292243457535, disc_loss = 0.07977467834479311
Trained batch 515 in epoch 12, gen_loss = 0.8256525734598322, disc_loss = 0.07969341089754084
Trained batch 516 in epoch 12, gen_loss = 0.8255108684820179, disc_loss = 0.07967861175962239
Trained batch 517 in epoch 12, gen_loss = 0.8251728426995885, disc_loss = 0.07965120317011669
Trained batch 518 in epoch 12, gen_loss = 0.8251485258398258, disc_loss = 0.07960954176976215
Trained batch 519 in epoch 12, gen_loss = 0.8257937881809014, disc_loss = 0.08018039190389503
Trained batch 520 in epoch 12, gen_loss = 0.8256212381392203, disc_loss = 0.08008279521804797
Trained batch 521 in epoch 12, gen_loss = 0.8251025165177853, disc_loss = 0.08036512530933337
Trained batch 522 in epoch 12, gen_loss = 0.8259450470740207, disc_loss = 0.08074571754085345
Trained batch 523 in epoch 12, gen_loss = 0.8257829313742295, disc_loss = 0.08076000947839375
Trained batch 524 in epoch 12, gen_loss = 0.8253958563577561, disc_loss = 0.08083070081436917
Trained batch 525 in epoch 12, gen_loss = 0.8257223358625695, disc_loss = 0.08080023044663634
Trained batch 526 in epoch 12, gen_loss = 0.8253114812740565, disc_loss = 0.0808630578230494
Trained batch 527 in epoch 12, gen_loss = 0.825671575173284, disc_loss = 0.08092530257117962
Trained batch 528 in epoch 12, gen_loss = 0.8255715319474839, disc_loss = 0.08100322535919952
Trained batch 529 in epoch 12, gen_loss = 0.8252015155441356, disc_loss = 0.08106258178902966
Trained batch 530 in epoch 12, gen_loss = 0.825214918499388, disc_loss = 0.08103877716222445
Trained batch 531 in epoch 12, gen_loss = 0.8251273221987531, disc_loss = 0.08099860378499038
Trained batch 532 in epoch 12, gen_loss = 0.8254298819386265, disc_loss = 0.08086904816637008
Trained batch 533 in epoch 12, gen_loss = 0.8256213665008545, disc_loss = 0.08075325722956143
Trained batch 534 in epoch 12, gen_loss = 0.8253509911421304, disc_loss = 0.08079358040241995
Trained batch 535 in epoch 12, gen_loss = 0.8250512164920124, disc_loss = 0.08099473030445402
Trained batch 536 in epoch 12, gen_loss = 0.8248753301258194, disc_loss = 0.08090401487685116
Trained batch 537 in epoch 12, gen_loss = 0.8247422270172148, disc_loss = 0.08087655009708772
Trained batch 538 in epoch 12, gen_loss = 0.8248372533546972, disc_loss = 0.08075837890491415
Trained batch 539 in epoch 12, gen_loss = 0.8255636709707754, disc_loss = 0.08074248153026457
Trained batch 540 in epoch 12, gen_loss = 0.8252397100277616, disc_loss = 0.08074286588348875
Trained batch 541 in epoch 12, gen_loss = 0.8254714977697253, disc_loss = 0.08061671793302762
Trained batch 542 in epoch 12, gen_loss = 0.8254374634495097, disc_loss = 0.0805707135928956
Trained batch 543 in epoch 12, gen_loss = 0.8258287071743432, disc_loss = 0.08044624554767164
Trained batch 544 in epoch 12, gen_loss = 0.8259380861159858, disc_loss = 0.0803553969334435
Trained batch 545 in epoch 12, gen_loss = 0.8258966504435836, disc_loss = 0.08023928342414371
Trained batch 546 in epoch 12, gen_loss = 0.8254861837113361, disc_loss = 0.08025494620197161
Trained batch 547 in epoch 12, gen_loss = 0.8252298913515397, disc_loss = 0.08017291107391734
Trained batch 548 in epoch 12, gen_loss = 0.825539581545498, disc_loss = 0.0800561990829792
Trained batch 549 in epoch 12, gen_loss = 0.826067478873513, disc_loss = 0.08010968632488089
Trained batch 550 in epoch 12, gen_loss = 0.8257637558312252, disc_loss = 0.08011391982199546
Trained batch 551 in epoch 12, gen_loss = 0.8257986991733745, disc_loss = 0.08005189846532987
Trained batch 552 in epoch 12, gen_loss = 0.8256199295223298, disc_loss = 0.08006042667292396
Trained batch 553 in epoch 12, gen_loss = 0.8258504069238793, disc_loss = 0.07999433187216466
Trained batch 554 in epoch 12, gen_loss = 0.8259854036408502, disc_loss = 0.07989075441450418
Trained batch 555 in epoch 12, gen_loss = 0.8261650729951241, disc_loss = 0.07985858026751243
Trained batch 556 in epoch 12, gen_loss = 0.8261670088211552, disc_loss = 0.07979041773866012
Trained batch 557 in epoch 12, gen_loss = 0.8256154361591544, disc_loss = 0.07998421219240967
Trained batch 558 in epoch 12, gen_loss = 0.8262773952671795, disc_loss = 0.08024242949340499
Trained batch 559 in epoch 12, gen_loss = 0.8259203314781189, disc_loss = 0.08029461862086984
Trained batch 560 in epoch 12, gen_loss = 0.8259926966379884, disc_loss = 0.08033491729355273
Trained batch 561 in epoch 12, gen_loss = 0.8256343749494315, disc_loss = 0.08034865466506615
Trained batch 562 in epoch 12, gen_loss = 0.8256598427282981, disc_loss = 0.08025356257238407
Trained batch 563 in epoch 12, gen_loss = 0.8264196200150971, disc_loss = 0.08028601660353547
Trained batch 564 in epoch 12, gen_loss = 0.8260007750671522, disc_loss = 0.08033221465065679
Trained batch 565 in epoch 12, gen_loss = 0.8256488813107089, disc_loss = 0.08031617294068945
Trained batch 566 in epoch 12, gen_loss = 0.8258317338936754, disc_loss = 0.08022080040397205
Trained batch 567 in epoch 12, gen_loss = 0.8255279603558527, disc_loss = 0.08027636370470774
Trained batch 568 in epoch 12, gen_loss = 0.8255023958393894, disc_loss = 0.08019820891274876
Trained batch 569 in epoch 12, gen_loss = 0.8258428726279945, disc_loss = 0.08019214397819158
Trained batch 570 in epoch 12, gen_loss = 0.82569262672431, disc_loss = 0.08015026977928372
Trained batch 571 in epoch 12, gen_loss = 0.8258618679079976, disc_loss = 0.08012711304773974
Trained batch 572 in epoch 12, gen_loss = 0.8259315211943515, disc_loss = 0.08002997113531536
Trained batch 573 in epoch 12, gen_loss = 0.8257387243081469, disc_loss = 0.08003078871455291
Trained batch 574 in epoch 12, gen_loss = 0.8256497420435367, disc_loss = 0.07994170908856651
Trained batch 575 in epoch 12, gen_loss = 0.8259897256890932, disc_loss = 0.08000935047069409
Trained batch 576 in epoch 12, gen_loss = 0.8256638795912162, disc_loss = 0.08009377369363396
Trained batch 577 in epoch 12, gen_loss = 0.8257013672775876, disc_loss = 0.0799902695662964
Trained batch 578 in epoch 12, gen_loss = 0.8254763257524098, disc_loss = 0.07997812971067397
Trained batch 579 in epoch 12, gen_loss = 0.8258308534992153, disc_loss = 0.07993569449393143
Trained batch 580 in epoch 12, gen_loss = 0.825604534087616, disc_loss = 0.07987664158579456
Trained batch 581 in epoch 12, gen_loss = 0.8252468417395431, disc_loss = 0.0799037458973575
Trained batch 582 in epoch 12, gen_loss = 0.8252664453782921, disc_loss = 0.07983007783782677
Trained batch 583 in epoch 12, gen_loss = 0.8256374292381822, disc_loss = 0.0797889616853902
Trained batch 584 in epoch 12, gen_loss = 0.8255891177389357, disc_loss = 0.07968826869773304
Trained batch 585 in epoch 12, gen_loss = 0.825527165835221, disc_loss = 0.07963429511057486
Trained batch 586 in epoch 12, gen_loss = 0.8256386064589532, disc_loss = 0.0796925068628265
Trained batch 587 in epoch 12, gen_loss = 0.8250298546690519, disc_loss = 0.07978620922642754
Trained batch 588 in epoch 12, gen_loss = 0.8249524786233497, disc_loss = 0.07970790284984636
Trained batch 589 in epoch 12, gen_loss = 0.825241419420404, disc_loss = 0.07973139552020674
Trained batch 590 in epoch 12, gen_loss = 0.8255584143139989, disc_loss = 0.079649385526562
Trained batch 591 in epoch 12, gen_loss = 0.8254077162694287, disc_loss = 0.07958186084461222
Trained batch 592 in epoch 12, gen_loss = 0.8255631133637581, disc_loss = 0.07951485301080533
Trained batch 593 in epoch 12, gen_loss = 0.8257024964499554, disc_loss = 0.07955378940742877
Trained batch 594 in epoch 12, gen_loss = 0.8255117145906977, disc_loss = 0.07951835811044239
Trained batch 595 in epoch 12, gen_loss = 0.8252888919923129, disc_loss = 0.0794901465075153
Trained batch 596 in epoch 12, gen_loss = 0.8257926496828422, disc_loss = 0.07946342067758691
Trained batch 597 in epoch 12, gen_loss = 0.8259807499156748, disc_loss = 0.07949596249894006
Trained batch 598 in epoch 12, gen_loss = 0.8257846852176774, disc_loss = 0.0794616821665124
Trained batch 599 in epoch 12, gen_loss = 0.8255042899648348, disc_loss = 0.07942927978467196
Trained batch 600 in epoch 12, gen_loss = 0.8253113077999946, disc_loss = 0.07952367552337601
Trained batch 601 in epoch 12, gen_loss = 0.8250935747971962, disc_loss = 0.07950249494539197
Trained batch 602 in epoch 12, gen_loss = 0.8254621425275976, disc_loss = 0.07961284187135857
Trained batch 603 in epoch 12, gen_loss = 0.82557074883521, disc_loss = 0.07954591315467872
Trained batch 604 in epoch 12, gen_loss = 0.8256415209494347, disc_loss = 0.0794783082644432
Trained batch 605 in epoch 12, gen_loss = 0.8252917149476092, disc_loss = 0.07946098095617525
Trained batch 606 in epoch 12, gen_loss = 0.825015964284171, disc_loss = 0.07945934146845213
Trained batch 607 in epoch 12, gen_loss = 0.8256116884907609, disc_loss = 0.07959217222952775
Trained batch 608 in epoch 12, gen_loss = 0.825522580463898, disc_loss = 0.07955092643899919
Trained batch 609 in epoch 12, gen_loss = 0.8252375484490003, disc_loss = 0.07955175270097421
Trained batch 610 in epoch 12, gen_loss = 0.8250379331178244, disc_loss = 0.07957770345723424
Trained batch 611 in epoch 12, gen_loss = 0.825285926071647, disc_loss = 0.07955675391522936
Trained batch 612 in epoch 12, gen_loss = 0.825231071105789, disc_loss = 0.07950465676038972
Trained batch 613 in epoch 12, gen_loss = 0.8251369782884268, disc_loss = 0.07946720237142925
Trained batch 614 in epoch 12, gen_loss = 0.8249070027010228, disc_loss = 0.07950958084557357
Trained batch 615 in epoch 12, gen_loss = 0.8254782854543103, disc_loss = 0.07956332121461679
Trained batch 616 in epoch 12, gen_loss = 0.8256927676486815, disc_loss = 0.07949646846866733
Trained batch 617 in epoch 12, gen_loss = 0.8254272891479788, disc_loss = 0.07954129751042303
Trained batch 618 in epoch 12, gen_loss = 0.8255465907888767, disc_loss = 0.07946584686811453
Trained batch 619 in epoch 12, gen_loss = 0.8251328343345273, disc_loss = 0.07949945452142387
Trained batch 620 in epoch 12, gen_loss = 0.8254715156248035, disc_loss = 0.07939309230443216
Trained batch 621 in epoch 12, gen_loss = 0.8256239795224843, disc_loss = 0.07934395365950044
Trained batch 622 in epoch 12, gen_loss = 0.8254161827254257, disc_loss = 0.07932769882240083
Trained batch 623 in epoch 12, gen_loss = 0.8256210437378823, disc_loss = 0.07922927411541772
Trained batch 624 in epoch 12, gen_loss = 0.8264314496040345, disc_loss = 0.07944776718169451
Trained batch 625 in epoch 12, gen_loss = 0.8259866138616689, disc_loss = 0.07945955220532541
Trained batch 626 in epoch 12, gen_loss = 0.8258298502394267, disc_loss = 0.07954542122133658
Trained batch 627 in epoch 12, gen_loss = 0.8256471559500239, disc_loss = 0.07948547561510591
Trained batch 628 in epoch 12, gen_loss = 0.8256721362021466, disc_loss = 0.07956736607237205
Trained batch 629 in epoch 12, gen_loss = 0.8257498655054304, disc_loss = 0.07948267447008263
Trained batch 630 in epoch 12, gen_loss = 0.8254903686216629, disc_loss = 0.07949060486355079
Trained batch 631 in epoch 12, gen_loss = 0.8256269930095612, disc_loss = 0.07947245063525447
Trained batch 632 in epoch 12, gen_loss = 0.8253310770031776, disc_loss = 0.07950574937784136
Trained batch 633 in epoch 12, gen_loss = 0.8252839542901854, disc_loss = 0.07950091483188963
Trained batch 634 in epoch 12, gen_loss = 0.8253366176537641, disc_loss = 0.07943071364095126
Trained batch 635 in epoch 12, gen_loss = 0.8256056399652792, disc_loss = 0.07931882146974358
Trained batch 636 in epoch 12, gen_loss = 0.8253224157089342, disc_loss = 0.07936459657366225
Trained batch 637 in epoch 12, gen_loss = 0.8248904538939366, disc_loss = 0.07946648569427267
Trained batch 638 in epoch 12, gen_loss = 0.8249515948907497, disc_loss = 0.07941005569452737
Trained batch 639 in epoch 12, gen_loss = 0.8254650178365409, disc_loss = 0.07939976907073287
Trained batch 640 in epoch 12, gen_loss = 0.8260857849708771, disc_loss = 0.07934364310194057
Trained batch 641 in epoch 12, gen_loss = 0.8257477874882124, disc_loss = 0.07951997493094884
Trained batch 642 in epoch 12, gen_loss = 0.8262087014933952, disc_loss = 0.0794280077842054
Trained batch 643 in epoch 12, gen_loss = 0.8262091873225218, disc_loss = 0.07938046896431063
Trained batch 644 in epoch 12, gen_loss = 0.8269240286923194, disc_loss = 0.07945101565659739
Trained batch 645 in epoch 12, gen_loss = 0.826643647516475, disc_loss = 0.0794821781965532
Trained batch 646 in epoch 12, gen_loss = 0.826661906894613, disc_loss = 0.07949508788349133
Trained batch 647 in epoch 12, gen_loss = 0.8264179486367438, disc_loss = 0.07941918782918587
Trained batch 648 in epoch 12, gen_loss = 0.8260770048860041, disc_loss = 0.07948605706613907
Trained batch 649 in epoch 12, gen_loss = 0.8263328445874728, disc_loss = 0.07940783880221156
Trained batch 650 in epoch 12, gen_loss = 0.8273293972015381, disc_loss = 0.07948552421258388
Trained batch 651 in epoch 12, gen_loss = 0.8271594445215412, disc_loss = 0.07946760389251074
Trained batch 652 in epoch 12, gen_loss = 0.8269737902315616, disc_loss = 0.07941976365466441
Trained batch 653 in epoch 12, gen_loss = 0.8268913469912444, disc_loss = 0.07942140369109285
Trained batch 654 in epoch 12, gen_loss = 0.8267726707094498, disc_loss = 0.07939130188541785
Trained batch 655 in epoch 12, gen_loss = 0.8268557062781439, disc_loss = 0.07945318063635878
Trained batch 656 in epoch 12, gen_loss = 0.8272665616584151, disc_loss = 0.07938503170785703
Trained batch 657 in epoch 12, gen_loss = 0.8271164365090136, disc_loss = 0.07936420378425246
Trained batch 658 in epoch 12, gen_loss = 0.8271249212516819, disc_loss = 0.07936387700883725
Trained batch 659 in epoch 12, gen_loss = 0.8270194579254497, disc_loss = 0.07934903529133987
Trained batch 660 in epoch 12, gen_loss = 0.8271328353304725, disc_loss = 0.07938660968252868
Trained batch 661 in epoch 12, gen_loss = 0.8274223536162938, disc_loss = 0.07929328434715144
Trained batch 662 in epoch 12, gen_loss = 0.8272157741168326, disc_loss = 0.07930080999014828
Trained batch 663 in epoch 12, gen_loss = 0.8266973058322826, disc_loss = 0.07939484039551567
Trained batch 664 in epoch 12, gen_loss = 0.827929739575637, disc_loss = 0.0801923436063685
Trained batch 665 in epoch 12, gen_loss = 0.8275137792478453, disc_loss = 0.08022111983880312
Trained batch 666 in epoch 12, gen_loss = 0.8272421561974636, disc_loss = 0.08026788396707762
Trained batch 667 in epoch 12, gen_loss = 0.8272274010731074, disc_loss = 0.08037582036068741
Trained batch 668 in epoch 12, gen_loss = 0.8274314706457392, disc_loss = 0.08028932370841281
Trained batch 669 in epoch 12, gen_loss = 0.8272783786503237, disc_loss = 0.080291272662302
Trained batch 670 in epoch 12, gen_loss = 0.8270388413470477, disc_loss = 0.08033934818100512
Trained batch 671 in epoch 12, gen_loss = 0.8268940436343352, disc_loss = 0.08034727849493113
Trained batch 672 in epoch 12, gen_loss = 0.8271372066741536, disc_loss = 0.08030943942420948
Trained batch 673 in epoch 12, gen_loss = 0.8270925820227547, disc_loss = 0.08027236744656452
Trained batch 674 in epoch 12, gen_loss = 0.8271546852147138, disc_loss = 0.08017879931049214
Trained batch 675 in epoch 12, gen_loss = 0.8268559851060958, disc_loss = 0.08017378971779708
Trained batch 676 in epoch 12, gen_loss = 0.8270624607493289, disc_loss = 0.0801911158404661
Trained batch 677 in epoch 12, gen_loss = 0.8274243432687799, disc_loss = 0.08014453972956292
Trained batch 678 in epoch 12, gen_loss = 0.827289533281537, disc_loss = 0.0800949155376327
Trained batch 679 in epoch 12, gen_loss = 0.8270291100530064, disc_loss = 0.08019352956428466
Trained batch 680 in epoch 12, gen_loss = 0.8273456926387838, disc_loss = 0.0801451923599174
Trained batch 681 in epoch 12, gen_loss = 0.8278123773088204, disc_loss = 0.08009993842778361
Trained batch 682 in epoch 12, gen_loss = 0.8273437616591223, disc_loss = 0.08017921448435694
Trained batch 683 in epoch 12, gen_loss = 0.8275802729771151, disc_loss = 0.08019668612852475
Trained batch 684 in epoch 12, gen_loss = 0.8272603333431439, disc_loss = 0.08030735699827
Trained batch 685 in epoch 12, gen_loss = 0.8272341513251424, disc_loss = 0.08022752187673665
Trained batch 686 in epoch 12, gen_loss = 0.8274237647153752, disc_loss = 0.08024097044899343
Trained batch 687 in epoch 12, gen_loss = 0.8272037307710148, disc_loss = 0.08026520741783992
Trained batch 688 in epoch 12, gen_loss = 0.826982007663378, disc_loss = 0.08025458546595969
Trained batch 689 in epoch 12, gen_loss = 0.8269829905551412, disc_loss = 0.08036099128776054
Trained batch 690 in epoch 12, gen_loss = 0.8265964917612145, disc_loss = 0.08045901994958153
Trained batch 691 in epoch 12, gen_loss = 0.8264139523740449, disc_loss = 0.0804635970624476
Trained batch 692 in epoch 12, gen_loss = 0.8268029627861915, disc_loss = 0.08071873524773215
Trained batch 693 in epoch 12, gen_loss = 0.8265148491440314, disc_loss = 0.08070844994396272
Trained batch 694 in epoch 12, gen_loss = 0.8260119650003721, disc_loss = 0.08085209708660841
Trained batch 695 in epoch 12, gen_loss = 0.8258439152576458, disc_loss = 0.08092990023720924
Trained batch 696 in epoch 12, gen_loss = 0.826073665016864, disc_loss = 0.08098676416573984
Trained batch 697 in epoch 12, gen_loss = 0.8256560379591235, disc_loss = 0.08116721556812824
Trained batch 698 in epoch 12, gen_loss = 0.8257845757856901, disc_loss = 0.08107607231711242
Trained batch 699 in epoch 12, gen_loss = 0.8258497483389718, disc_loss = 0.0811187242064625
Trained batch 700 in epoch 12, gen_loss = 0.8261923813785874, disc_loss = 0.08104309854835016
Trained batch 701 in epoch 12, gen_loss = 0.8261582416686577, disc_loss = 0.08101083014155087
Trained batch 702 in epoch 12, gen_loss = 0.8256882836520248, disc_loss = 0.08126586708101109
Trained batch 703 in epoch 12, gen_loss = 0.8257781609638848, disc_loss = 0.08127752124908677
Trained batch 704 in epoch 12, gen_loss = 0.825881358790905, disc_loss = 0.08140940770427597
Trained batch 705 in epoch 12, gen_loss = 0.8258451714309687, disc_loss = 0.0813526407308961
Trained batch 706 in epoch 12, gen_loss = 0.8259241857066687, disc_loss = 0.08142085819830525
Trained batch 707 in epoch 12, gen_loss = 0.8255468436469466, disc_loss = 0.08157418947798427
Trained batch 708 in epoch 12, gen_loss = 0.8253728061788341, disc_loss = 0.08170448962010558
Trained batch 709 in epoch 12, gen_loss = 0.8259087793843847, disc_loss = 0.08176798778126987
Trained batch 710 in epoch 12, gen_loss = 0.8257673777189268, disc_loss = 0.08174698917868478
Trained batch 711 in epoch 12, gen_loss = 0.8253922750022304, disc_loss = 0.08173081987887998
Trained batch 712 in epoch 12, gen_loss = 0.8254124189911183, disc_loss = 0.08194711204189781
Trained batch 713 in epoch 12, gen_loss = 0.8252963673751227, disc_loss = 0.0819335905613289
Trained batch 714 in epoch 12, gen_loss = 0.8252212974991832, disc_loss = 0.08187849578558357
Trained batch 715 in epoch 12, gen_loss = 0.8251564103548087, disc_loss = 0.08184860710330391
Trained batch 716 in epoch 12, gen_loss = 0.8247306608339068, disc_loss = 0.08188478624892409
Trained batch 717 in epoch 12, gen_loss = 0.8247516198825703, disc_loss = 0.08180352211294276
Trained batch 718 in epoch 12, gen_loss = 0.8250119834102079, disc_loss = 0.08178085597654253
Trained batch 719 in epoch 12, gen_loss = 0.8249405386133326, disc_loss = 0.08175208812915824
Trained batch 720 in epoch 12, gen_loss = 0.8246598533469661, disc_loss = 0.08180700518557706
Trained batch 721 in epoch 12, gen_loss = 0.8245947799771777, disc_loss = 0.08175849654631807
Trained batch 722 in epoch 12, gen_loss = 0.8246154621511409, disc_loss = 0.0817960057817245
Trained batch 723 in epoch 12, gen_loss = 0.8245021688921675, disc_loss = 0.08185510445535389
Trained batch 724 in epoch 12, gen_loss = 0.8245671839138558, disc_loss = 0.08184029510437414
Trained batch 725 in epoch 12, gen_loss = 0.8243876795384509, disc_loss = 0.0818737639696658
Trained batch 726 in epoch 12, gen_loss = 0.824763407856431, disc_loss = 0.08186077180112286
Trained batch 727 in epoch 12, gen_loss = 0.8244950181425927, disc_loss = 0.08185889410330904
Trained batch 728 in epoch 12, gen_loss = 0.8244472084303779, disc_loss = 0.08192075926054203
Trained batch 729 in epoch 12, gen_loss = 0.8242915994092209, disc_loss = 0.08198768768127855
Trained batch 730 in epoch 12, gen_loss = 0.8240780019482901, disc_loss = 0.08199355266249335
Trained batch 731 in epoch 12, gen_loss = 0.8243480169626533, disc_loss = 0.08205345107237376
Trained batch 732 in epoch 12, gen_loss = 0.8240816883874947, disc_loss = 0.0820301142095564
Trained batch 733 in epoch 12, gen_loss = 0.8236581466746915, disc_loss = 0.08210108820120589
Trained batch 734 in epoch 12, gen_loss = 0.8240104512697985, disc_loss = 0.08200982572498168
Trained batch 735 in epoch 12, gen_loss = 0.8237638809191792, disc_loss = 0.08221305237257974
Trained batch 736 in epoch 12, gen_loss = 0.8234062531667292, disc_loss = 0.08223340910666065
Trained batch 737 in epoch 12, gen_loss = 0.8235967779951043, disc_loss = 0.08216464957777603
Trained batch 738 in epoch 12, gen_loss = 0.8238272360035789, disc_loss = 0.08211763551098286
Trained batch 739 in epoch 12, gen_loss = 0.8238140440067729, disc_loss = 0.0820491244626307
Trained batch 740 in epoch 12, gen_loss = 0.8238554606955705, disc_loss = 0.08199524933374241
Trained batch 741 in epoch 12, gen_loss = 0.82381751285891, disc_loss = 0.08192549396000019
Trained batch 742 in epoch 12, gen_loss = 0.8237083028415331, disc_loss = 0.0818724413872427
Trained batch 743 in epoch 12, gen_loss = 0.8235501237213612, disc_loss = 0.08181700271789626
Trained batch 744 in epoch 12, gen_loss = 0.8238180151321743, disc_loss = 0.08178359849765997
Trained batch 745 in epoch 12, gen_loss = 0.8239253138169527, disc_loss = 0.08171040202358652
Trained batch 746 in epoch 12, gen_loss = 0.8238100809664771, disc_loss = 0.08165585768933956
Trained batch 747 in epoch 12, gen_loss = 0.8236659910669302, disc_loss = 0.08173917588170239
Trained batch 748 in epoch 12, gen_loss = 0.8236925719338202, disc_loss = 0.08169345509569262
Trained batch 749 in epoch 12, gen_loss = 0.8242906554142634, disc_loss = 0.08177905592943231
Trained batch 750 in epoch 12, gen_loss = 0.8242897598864076, disc_loss = 0.0817288677462348
Trained batch 751 in epoch 12, gen_loss = 0.8239319188559943, disc_loss = 0.08179689583769861
Trained batch 752 in epoch 12, gen_loss = 0.8237381588969415, disc_loss = 0.0818231657783131
Trained batch 753 in epoch 12, gen_loss = 0.824123913753254, disc_loss = 0.08190421161886591
Trained batch 754 in epoch 12, gen_loss = 0.8245159199300981, disc_loss = 0.08189729959981529
Trained batch 755 in epoch 12, gen_loss = 0.8241328185907116, disc_loss = 0.08200116479823553
Trained batch 756 in epoch 12, gen_loss = 0.8237327052627246, disc_loss = 0.08213788582580447
Trained batch 757 in epoch 12, gen_loss = 0.823798012725596, disc_loss = 0.08208468363381981
Trained batch 758 in epoch 12, gen_loss = 0.8239443732108994, disc_loss = 0.08222051520067437
Trained batch 759 in epoch 12, gen_loss = 0.8240324768973024, disc_loss = 0.08218429211257516
Trained batch 760 in epoch 12, gen_loss = 0.8236679807990672, disc_loss = 0.08228837808474174
Trained batch 761 in epoch 12, gen_loss = 0.8234295189145981, disc_loss = 0.08232529701058829
Trained batch 762 in epoch 12, gen_loss = 0.8231885185951018, disc_loss = 0.08236865561728904
Trained batch 763 in epoch 12, gen_loss = 0.823516601628346, disc_loss = 0.08228632616469178
Trained batch 764 in epoch 12, gen_loss = 0.8236703904236065, disc_loss = 0.08226732626143429
Trained batch 765 in epoch 12, gen_loss = 0.8234833555573272, disc_loss = 0.08223989129664654
Trained batch 766 in epoch 12, gen_loss = 0.8231746816650675, disc_loss = 0.08223826192790519
Trained batch 767 in epoch 12, gen_loss = 0.8231792805794006, disc_loss = 0.08218564473281731
Trained batch 768 in epoch 12, gen_loss = 0.8231785720982074, disc_loss = 0.08212484325244732
Trained batch 769 in epoch 12, gen_loss = 0.8232466599770955, disc_loss = 0.0820990070156366
Trained batch 770 in epoch 12, gen_loss = 0.8231708983734888, disc_loss = 0.08207191793965575
Trained batch 771 in epoch 12, gen_loss = 0.8232959847453345, disc_loss = 0.08199150181240329
Trained batch 772 in epoch 12, gen_loss = 0.8232717230665422, disc_loss = 0.08196669625525603
Trained batch 773 in epoch 12, gen_loss = 0.8233616426394583, disc_loss = 0.08195866477249782
Trained batch 774 in epoch 12, gen_loss = 0.8235281508584177, disc_loss = 0.08189140627340924
Trained batch 775 in epoch 12, gen_loss = 0.8234723242210973, disc_loss = 0.08186007825748938
Trained batch 776 in epoch 12, gen_loss = 0.8238036658236112, disc_loss = 0.08178084183896639
Trained batch 777 in epoch 12, gen_loss = 0.8241767335903368, disc_loss = 0.08178343522723927
Trained batch 778 in epoch 12, gen_loss = 0.824618139032834, disc_loss = 0.0818162503017445
Trained batch 779 in epoch 12, gen_loss = 0.824275357562762, disc_loss = 0.08203585976376557
Trained batch 780 in epoch 12, gen_loss = 0.8241088106064424, disc_loss = 0.08201743623601909
Trained batch 781 in epoch 12, gen_loss = 0.8245259306543623, disc_loss = 0.08218705567800443
Trained batch 782 in epoch 12, gen_loss = 0.8244677434555263, disc_loss = 0.08214240427346636
Trained batch 783 in epoch 12, gen_loss = 0.8244288053971772, disc_loss = 0.08207361695560988
Trained batch 784 in epoch 12, gen_loss = 0.8243886368669522, disc_loss = 0.08208570849435155
Trained batch 785 in epoch 12, gen_loss = 0.8243060980665168, disc_loss = 0.0820793425107408
Trained batch 786 in epoch 12, gen_loss = 0.8247337913498036, disc_loss = 0.08200578737454879
Trained batch 787 in epoch 12, gen_loss = 0.8244900841473928, disc_loss = 0.08204768869794224
Trained batch 788 in epoch 12, gen_loss = 0.8247436478790675, disc_loss = 0.08204962056677868
Trained batch 789 in epoch 12, gen_loss = 0.8247344218854663, disc_loss = 0.08200902132836135
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.7061856985092163, disc_loss = 0.02588769979774952
Trained batch 1 in epoch 13, gen_loss = 0.865483283996582, disc_loss = 0.03395717125386
Trained batch 2 in epoch 13, gen_loss = 0.8555788596471151, disc_loss = 0.03702459794779619
Trained batch 3 in epoch 13, gen_loss = 0.8884468525648117, disc_loss = 0.030232909601181746
Trained batch 4 in epoch 13, gen_loss = 0.9282457947731018, disc_loss = 0.045073194429278374
Trained batch 5 in epoch 13, gen_loss = 0.8736935953299204, disc_loss = 0.051146767723063626
Trained batch 6 in epoch 13, gen_loss = 0.876892123903547, disc_loss = 0.04849621893039772
Trained batch 7 in epoch 13, gen_loss = 0.8512004613876343, disc_loss = 0.05062866141088307
Trained batch 8 in epoch 13, gen_loss = 0.867112954457601, disc_loss = 0.04740210519068771
Trained batch 9 in epoch 13, gen_loss = 0.8830658078193665, disc_loss = 0.06748886983841658
Trained batch 10 in epoch 13, gen_loss = 0.8703601360321045, disc_loss = 0.06747073595496741
Trained batch 11 in epoch 13, gen_loss = 0.8657253086566925, disc_loss = 0.06681597341472904
Trained batch 12 in epoch 13, gen_loss = 0.8962686795454758, disc_loss = 0.07478866081398267
Trained batch 13 in epoch 13, gen_loss = 0.890052820955004, disc_loss = 0.07328275152082954
Trained batch 14 in epoch 13, gen_loss = 0.8918835401535035, disc_loss = 0.07201683906217417
Trained batch 15 in epoch 13, gen_loss = 0.8863493204116821, disc_loss = 0.07195056590717286
Trained batch 16 in epoch 13, gen_loss = 0.8918197435491225, disc_loss = 0.07020447764764814
Trained batch 17 in epoch 13, gen_loss = 0.8955372240808275, disc_loss = 0.0680925263505843
Trained batch 18 in epoch 13, gen_loss = 0.903508230259544, disc_loss = 0.0665639502633559
Trained batch 19 in epoch 13, gen_loss = 0.8984339982271194, disc_loss = 0.06543895089998841
Trained batch 20 in epoch 13, gen_loss = 0.8938808639844259, disc_loss = 0.06424393903996263
Trained batch 21 in epoch 13, gen_loss = 0.887643735517155, disc_loss = 0.0625738762319088
Trained batch 22 in epoch 13, gen_loss = 0.8921003834061001, disc_loss = 0.06057541444897652
Trained batch 23 in epoch 13, gen_loss = 0.8829065536459287, disc_loss = 0.06072576359535257
Trained batch 24 in epoch 13, gen_loss = 0.8860112595558166, disc_loss = 0.06013400509953499
Trained batch 25 in epoch 13, gen_loss = 0.8882587827168978, disc_loss = 0.058373286961936034
Trained batch 26 in epoch 13, gen_loss = 0.8812997628141332, disc_loss = 0.05856046487611753
Trained batch 27 in epoch 13, gen_loss = 0.8951177703482764, disc_loss = 0.06419838080182672
Trained batch 28 in epoch 13, gen_loss = 0.8861410638381695, disc_loss = 0.06464697105874276
Trained batch 29 in epoch 13, gen_loss = 0.8920591731866201, disc_loss = 0.06317029253890118
Trained batch 30 in epoch 13, gen_loss = 0.8910051584243774, disc_loss = 0.062173385112997026
Trained batch 31 in epoch 13, gen_loss = 0.8940485119819641, disc_loss = 0.062280784419272095
Trained batch 32 in epoch 13, gen_loss = 0.889489800641031, disc_loss = 0.06286300182568305
Trained batch 33 in epoch 13, gen_loss = 0.8966454530463499, disc_loss = 0.06340284037458546
Trained batch 34 in epoch 13, gen_loss = 0.8975743447031294, disc_loss = 0.06268924735486507
Trained batch 35 in epoch 13, gen_loss = 0.8977725108464559, disc_loss = 0.06145519551096691
Trained batch 36 in epoch 13, gen_loss = 0.89600630225362, disc_loss = 0.06043532888430196
Trained batch 37 in epoch 13, gen_loss = 0.8934036791324615, disc_loss = 0.0597779331728816
Trained batch 38 in epoch 13, gen_loss = 0.8975294385200892, disc_loss = 0.058521647818195514
Trained batch 39 in epoch 13, gen_loss = 0.8980037853121757, disc_loss = 0.06038521635346115
Trained batch 40 in epoch 13, gen_loss = 0.8972945925666065, disc_loss = 0.05922331863151091
Trained batch 41 in epoch 13, gen_loss = 0.8995229757967449, disc_loss = 0.058939944354018996
Trained batch 42 in epoch 13, gen_loss = 0.8981806594271993, disc_loss = 0.05946652376807706
Trained batch 43 in epoch 13, gen_loss = 0.8976450372825969, disc_loss = 0.0596824521410533
Trained batch 44 in epoch 13, gen_loss = 0.8957077291276719, disc_loss = 0.05922898809529013
Trained batch 45 in epoch 13, gen_loss = 0.8938708434934202, disc_loss = 0.058969652948334166
Trained batch 46 in epoch 13, gen_loss = 0.8916713176889622, disc_loss = 0.058627014880643244
Trained batch 47 in epoch 13, gen_loss = 0.8920893805722395, disc_loss = 0.058174030641869955
Trained batch 48 in epoch 13, gen_loss = 0.8939572670021836, disc_loss = 0.05720676958789023
Trained batch 49 in epoch 13, gen_loss = 0.8973175024986267, disc_loss = 0.05625399628654122
Trained batch 50 in epoch 13, gen_loss = 0.8970995942751566, disc_loss = 0.05541455822394175
Trained batch 51 in epoch 13, gen_loss = 0.8963446571276739, disc_loss = 0.054686155349302754
Trained batch 52 in epoch 13, gen_loss = 0.8976873215639366, disc_loss = 0.055010543433281614
Trained batch 53 in epoch 13, gen_loss = 0.8956702318456438, disc_loss = 0.05491915472817642
Trained batch 54 in epoch 13, gen_loss = 0.8955863118171692, disc_loss = 0.054074396040629254
Trained batch 55 in epoch 13, gen_loss = 0.8928091345088822, disc_loss = 0.053874817793257535
Trained batch 56 in epoch 13, gen_loss = 0.8929914058300487, disc_loss = 0.05316321950471192
Trained batch 57 in epoch 13, gen_loss = 0.9001242631468279, disc_loss = 0.053658584132790565
Trained batch 58 in epoch 13, gen_loss = 0.8988929997056218, disc_loss = 0.053842969175617574
Trained batch 59 in epoch 13, gen_loss = 0.8945055276155471, disc_loss = 0.05462660510092974
Trained batch 60 in epoch 13, gen_loss = 0.8966846260868135, disc_loss = 0.054073902427173054
Trained batch 61 in epoch 13, gen_loss = 0.900079341665391, disc_loss = 0.05522249999546235
Trained batch 62 in epoch 13, gen_loss = 0.896605320393093, disc_loss = 0.055675735904110804
Trained batch 63 in epoch 13, gen_loss = 0.8945033261552453, disc_loss = 0.05518696771468967
Trained batch 64 in epoch 13, gen_loss = 0.8967181545037489, disc_loss = 0.05597786628282987
Trained batch 65 in epoch 13, gen_loss = 0.8965045593001626, disc_loss = 0.05588215504857627
Trained batch 66 in epoch 13, gen_loss = 0.8940345707224376, disc_loss = 0.055604186854255735
Trained batch 67 in epoch 13, gen_loss = 0.8927092613542781, disc_loss = 0.05511364989968784
Trained batch 68 in epoch 13, gen_loss = 0.8944887778033381, disc_loss = 0.05453690921590812
Trained batch 69 in epoch 13, gen_loss = 0.8920493287699564, disc_loss = 0.055346413834818774
Trained batch 70 in epoch 13, gen_loss = 0.8910884286316347, disc_loss = 0.056371017477252115
Trained batch 71 in epoch 13, gen_loss = 0.8911995788415273, disc_loss = 0.05673812673841086
Trained batch 72 in epoch 13, gen_loss = 0.886484154283184, disc_loss = 0.05827771895246146
Trained batch 73 in epoch 13, gen_loss = 0.885584308488949, disc_loss = 0.057653205720959486
Trained batch 74 in epoch 13, gen_loss = 0.8894525710741679, disc_loss = 0.060556289851665494
Trained batch 75 in epoch 13, gen_loss = 0.8877950318549809, disc_loss = 0.06094276385479852
Trained batch 76 in epoch 13, gen_loss = 0.8868981979110024, disc_loss = 0.060796672792790774
Trained batch 77 in epoch 13, gen_loss = 0.8864989288342304, disc_loss = 0.06019334650288025
Trained batch 78 in epoch 13, gen_loss = 0.8836576908449584, disc_loss = 0.060531237575260896
Trained batch 79 in epoch 13, gen_loss = 0.8832032375037671, disc_loss = 0.06186885714996606
Trained batch 80 in epoch 13, gen_loss = 0.8818580839369032, disc_loss = 0.0617522693204659
Trained batch 81 in epoch 13, gen_loss = 0.8846781951625172, disc_loss = 0.06118872080270837
Trained batch 82 in epoch 13, gen_loss = 0.8832476031349366, disc_loss = 0.06149194622973362
Trained batch 83 in epoch 13, gen_loss = 0.879602021404675, disc_loss = 0.062349319724099975
Trained batch 84 in epoch 13, gen_loss = 0.8774686336517334, disc_loss = 0.062038018510622135
Trained batch 85 in epoch 13, gen_loss = 0.8742230492968892, disc_loss = 0.06235638702678126
Trained batch 86 in epoch 13, gen_loss = 0.8751180521373091, disc_loss = 0.06204299778602589
Trained batch 87 in epoch 13, gen_loss = 0.876039328222925, disc_loss = 0.06188585384833542
Trained batch 88 in epoch 13, gen_loss = 0.8739963910552893, disc_loss = 0.061910677952377986
Trained batch 89 in epoch 13, gen_loss = 0.8750300308068594, disc_loss = 0.061724697177608805
Trained batch 90 in epoch 13, gen_loss = 0.873984755395533, disc_loss = 0.06178179043498668
Trained batch 91 in epoch 13, gen_loss = 0.8711845997882925, disc_loss = 0.062322780692383
Trained batch 92 in epoch 13, gen_loss = 0.873787587047905, disc_loss = 0.06510864490623115
Trained batch 93 in epoch 13, gen_loss = 0.8782856381954031, disc_loss = 0.06561689447373786
Trained batch 94 in epoch 13, gen_loss = 0.8747195877526935, disc_loss = 0.06718119888713485
Trained batch 95 in epoch 13, gen_loss = 0.8722272521505753, disc_loss = 0.0670083361134554
Trained batch 96 in epoch 13, gen_loss = 0.8723121359176242, disc_loss = 0.06691794669658867
Trained batch 97 in epoch 13, gen_loss = 0.8715430151443092, disc_loss = 0.06706984284124812
Trained batch 98 in epoch 13, gen_loss = 0.8668962030699758, disc_loss = 0.06802810958088046
Trained batch 99 in epoch 13, gen_loss = 0.8664283502101898, disc_loss = 0.06763966938480735
Trained batch 100 in epoch 13, gen_loss = 0.8672473100152346, disc_loss = 0.06731913701658791
Trained batch 101 in epoch 13, gen_loss = 0.8683956954993454, disc_loss = 0.06685621941498682
Trained batch 102 in epoch 13, gen_loss = 0.8666221678835674, disc_loss = 0.06678672460387054
Trained batch 103 in epoch 13, gen_loss = 0.8659662931011274, disc_loss = 0.0664605010444155
Trained batch 104 in epoch 13, gen_loss = 0.8652168915385292, disc_loss = 0.06600133553147317
Trained batch 105 in epoch 13, gen_loss = 0.8635766016987135, disc_loss = 0.06627661632901093
Trained batch 106 in epoch 13, gen_loss = 0.8654899313071064, disc_loss = 0.0669306441097059
Trained batch 107 in epoch 13, gen_loss = 0.8655299947217658, disc_loss = 0.06826967977125335
Trained batch 108 in epoch 13, gen_loss = 0.8626785338471789, disc_loss = 0.06885566169378954
Trained batch 109 in epoch 13, gen_loss = 0.8643701125275005, disc_loss = 0.0683369079858742
Trained batch 110 in epoch 13, gen_loss = 0.8641207105404621, disc_loss = 0.06787220335792045
Trained batch 111 in epoch 13, gen_loss = 0.8641923288149493, disc_loss = 0.06789110116161672
Trained batch 112 in epoch 13, gen_loss = 0.861686631114082, disc_loss = 0.06840293578374966
Trained batch 113 in epoch 13, gen_loss = 0.8634247032173893, disc_loss = 0.06807748980722145
Trained batch 114 in epoch 13, gen_loss = 0.8619012666785199, disc_loss = 0.0682557273251207
Trained batch 115 in epoch 13, gen_loss = 0.8618289406957298, disc_loss = 0.06899021104267188
Trained batch 116 in epoch 13, gen_loss = 0.8621697125271854, disc_loss = 0.0685612505588394
Trained batch 117 in epoch 13, gen_loss = 0.8613871755236286, disc_loss = 0.06833279259913301
Trained batch 118 in epoch 13, gen_loss = 0.8606997603127936, disc_loss = 0.06861497687974147
Trained batch 119 in epoch 13, gen_loss = 0.8583456024527549, disc_loss = 0.06893213988126566
Trained batch 120 in epoch 13, gen_loss = 0.8584824288186949, disc_loss = 0.06879462924408765
Trained batch 121 in epoch 13, gen_loss = 0.8588217428473176, disc_loss = 0.06840869217164448
Trained batch 122 in epoch 13, gen_loss = 0.8584042453184361, disc_loss = 0.06821475608834648
Trained batch 123 in epoch 13, gen_loss = 0.8553482909356395, disc_loss = 0.06997453626395474
Trained batch 124 in epoch 13, gen_loss = 0.8545440983772278, disc_loss = 0.07023155654221773
Trained batch 125 in epoch 13, gen_loss = 0.8564532924266088, disc_loss = 0.07110051551301565
Trained batch 126 in epoch 13, gen_loss = 0.8538893475307254, disc_loss = 0.0716339431952421
Trained batch 127 in epoch 13, gen_loss = 0.8531629904173315, disc_loss = 0.07135970186936902
Trained batch 128 in epoch 13, gen_loss = 0.8547336255857186, disc_loss = 0.07096376955191526
Trained batch 129 in epoch 13, gen_loss = 0.855169062431042, disc_loss = 0.0714505642437591
Trained batch 130 in epoch 13, gen_loss = 0.8535078672962334, disc_loss = 0.07191482457183017
Trained batch 131 in epoch 13, gen_loss = 0.8524181815710935, disc_loss = 0.07178108586760407
Trained batch 132 in epoch 13, gen_loss = 0.8507678105418843, disc_loss = 0.07237781450516523
Trained batch 133 in epoch 13, gen_loss = 0.8512402239130504, disc_loss = 0.07282562565697885
Trained batch 134 in epoch 13, gen_loss = 0.851095426524127, disc_loss = 0.07254129135636268
Trained batch 135 in epoch 13, gen_loss = 0.8512067040976357, disc_loss = 0.072589476380552
Trained batch 136 in epoch 13, gen_loss = 0.8496595838644209, disc_loss = 0.07263641641985108
Trained batch 137 in epoch 13, gen_loss = 0.8480232003806294, disc_loss = 0.07255641868391978
Trained batch 138 in epoch 13, gen_loss = 0.847110080633232, disc_loss = 0.07240910780542403
Trained batch 139 in epoch 13, gen_loss = 0.84720205111163, disc_loss = 0.07273213661807988
Trained batch 140 in epoch 13, gen_loss = 0.8470586922997279, disc_loss = 0.07253620990862449
Trained batch 141 in epoch 13, gen_loss = 0.8470675680838841, disc_loss = 0.07220479437399288
Trained batch 142 in epoch 13, gen_loss = 0.8474426248690465, disc_loss = 0.07177484841118534
Trained batch 143 in epoch 13, gen_loss = 0.8469823478824563, disc_loss = 0.07150212642348681
Trained batch 144 in epoch 13, gen_loss = 0.8473541995574688, disc_loss = 0.07108976267406653
Trained batch 145 in epoch 13, gen_loss = 0.8481689622140911, disc_loss = 0.07074226346504811
Trained batch 146 in epoch 13, gen_loss = 0.8481493190843232, disc_loss = 0.07061652275955393
Trained batch 147 in epoch 13, gen_loss = 0.8487218960716918, disc_loss = 0.07021794361817474
Trained batch 148 in epoch 13, gen_loss = 0.8485131259732599, disc_loss = 0.06987948573800741
Trained batch 149 in epoch 13, gen_loss = 0.850641994078954, disc_loss = 0.06961151066546639
Trained batch 150 in epoch 13, gen_loss = 0.8496300589959354, disc_loss = 0.06952187266595514
Trained batch 151 in epoch 13, gen_loss = 0.8486815989017487, disc_loss = 0.06936158583573017
Trained batch 152 in epoch 13, gen_loss = 0.8485310599694844, disc_loss = 0.06951830867872713
Trained batch 153 in epoch 13, gen_loss = 0.8482175554547992, disc_loss = 0.06918339798372093
Trained batch 154 in epoch 13, gen_loss = 0.8484087790212324, disc_loss = 0.0691590825336114
Trained batch 155 in epoch 13, gen_loss = 0.8477843484053245, disc_loss = 0.06934407744437265
Trained batch 156 in epoch 13, gen_loss = 0.8455363238693043, disc_loss = 0.07007194257631993
Trained batch 157 in epoch 13, gen_loss = 0.8487036326263524, disc_loss = 0.07053607154661153
Trained batch 158 in epoch 13, gen_loss = 0.8480801488618431, disc_loss = 0.07027144252715058
Trained batch 159 in epoch 13, gen_loss = 0.8478035289794207, disc_loss = 0.07036204212927259
Trained batch 160 in epoch 13, gen_loss = 0.846575469333933, disc_loss = 0.07037426777160871
Trained batch 161 in epoch 13, gen_loss = 0.8463072887173405, disc_loss = 0.07022768733333107
Trained batch 162 in epoch 13, gen_loss = 0.8457699414411205, disc_loss = 0.07012536247015182
Trained batch 163 in epoch 13, gen_loss = 0.8466936284449043, disc_loss = 0.07012699070250297
Trained batch 164 in epoch 13, gen_loss = 0.8452826532450589, disc_loss = 0.07058463808374875
Trained batch 165 in epoch 13, gen_loss = 0.8450456821774862, disc_loss = 0.07105205215356615
Trained batch 166 in epoch 13, gen_loss = 0.8466533736554448, disc_loss = 0.07104325011751787
Trained batch 167 in epoch 13, gen_loss = 0.845410677648726, disc_loss = 0.07097201129709858
Trained batch 168 in epoch 13, gen_loss = 0.8459431581948635, disc_loss = 0.07075335372503869
Trained batch 169 in epoch 13, gen_loss = 0.8458820251857533, disc_loss = 0.07054938499213141
Trained batch 170 in epoch 13, gen_loss = 0.846122085699561, disc_loss = 0.07026657541091853
Trained batch 171 in epoch 13, gen_loss = 0.8466830620932024, disc_loss = 0.0699820892159762
Trained batch 172 in epoch 13, gen_loss = 0.8460519944312256, disc_loss = 0.06978979870956929
Trained batch 173 in epoch 13, gen_loss = 0.8448255031273283, disc_loss = 0.06992543403637307
Trained batch 174 in epoch 13, gen_loss = 0.845384407384055, disc_loss = 0.06963055694209677
Trained batch 175 in epoch 13, gen_loss = 0.846068392761729, disc_loss = 0.06946583643068814
Trained batch 176 in epoch 13, gen_loss = 0.8465077863574701, disc_loss = 0.06933565463576108
Trained batch 177 in epoch 13, gen_loss = 0.8459097803308723, disc_loss = 0.06935353703231792
Trained batch 178 in epoch 13, gen_loss = 0.8474274880393258, disc_loss = 0.06932822461422096
Trained batch 179 in epoch 13, gen_loss = 0.8466895725991991, disc_loss = 0.06922824644069704
Trained batch 180 in epoch 13, gen_loss = 0.8467738832558057, disc_loss = 0.06901155439467885
Trained batch 181 in epoch 13, gen_loss = 0.846347430905143, disc_loss = 0.0689251412903624
Trained batch 182 in epoch 13, gen_loss = 0.8467559514801359, disc_loss = 0.06933786885436279
Trained batch 183 in epoch 13, gen_loss = 0.845187849972559, disc_loss = 0.06968322791584322
Trained batch 184 in epoch 13, gen_loss = 0.8446830156687144, disc_loss = 0.06980199892879338
Trained batch 185 in epoch 13, gen_loss = 0.8436620802648606, disc_loss = 0.06990624642280001
Trained batch 186 in epoch 13, gen_loss = 0.8446253177953914, disc_loss = 0.0698069287663236
Trained batch 187 in epoch 13, gen_loss = 0.8437356653999775, disc_loss = 0.06974654330158646
Trained batch 188 in epoch 13, gen_loss = 0.8442838589350382, disc_loss = 0.06969418631442797
Trained batch 189 in epoch 13, gen_loss = 0.8447890846352828, disc_loss = 0.06954258008320865
Trained batch 190 in epoch 13, gen_loss = 0.8441646111573224, disc_loss = 0.06947219567324635
Trained batch 191 in epoch 13, gen_loss = 0.8426584918051958, disc_loss = 0.0695850898482604
Trained batch 192 in epoch 13, gen_loss = 0.8434075466091768, disc_loss = 0.06945639434198178
Trained batch 193 in epoch 13, gen_loss = 0.8439581667639545, disc_loss = 0.06923397685660376
Trained batch 194 in epoch 13, gen_loss = 0.8459339487246978, disc_loss = 0.06907036619213147
Trained batch 195 in epoch 13, gen_loss = 0.844193240513607, disc_loss = 0.06961950874051118
Trained batch 196 in epoch 13, gen_loss = 0.8450979735645546, disc_loss = 0.06934900010278836
Trained batch 197 in epoch 13, gen_loss = 0.8448414513559053, disc_loss = 0.06942551465930813
Trained batch 198 in epoch 13, gen_loss = 0.844372035870001, disc_loss = 0.06932297236187823
Trained batch 199 in epoch 13, gen_loss = 0.8446014988422393, disc_loss = 0.0691516713378951
Trained batch 200 in epoch 13, gen_loss = 0.8434501628377544, disc_loss = 0.0692969294061041
Trained batch 201 in epoch 13, gen_loss = 0.8435672577654961, disc_loss = 0.06937270275418564
Trained batch 202 in epoch 13, gen_loss = 0.843913797380889, disc_loss = 0.06950827548050968
Trained batch 203 in epoch 13, gen_loss = 0.8430801539444456, disc_loss = 0.06946541510942374
Trained batch 204 in epoch 13, gen_loss = 0.8423826133332601, disc_loss = 0.0693692078268746
Trained batch 205 in epoch 13, gen_loss = 0.8431570191406509, disc_loss = 0.06939366423226531
Trained batch 206 in epoch 13, gen_loss = 0.8422031313324896, disc_loss = 0.06951028867602205
Trained batch 207 in epoch 13, gen_loss = 0.8427632276255351, disc_loss = 0.06943411675120632
Trained batch 208 in epoch 13, gen_loss = 0.8425264136072551, disc_loss = 0.06927786264390323
Trained batch 209 in epoch 13, gen_loss = 0.8430470841271537, disc_loss = 0.06905695361839163
Trained batch 210 in epoch 13, gen_loss = 0.8422177685380547, disc_loss = 0.06909958473119832
Trained batch 211 in epoch 13, gen_loss = 0.8432653394510161, disc_loss = 0.06923169852234423
Trained batch 212 in epoch 13, gen_loss = 0.8451611922940178, disc_loss = 0.06911004224940785
Trained batch 213 in epoch 13, gen_loss = 0.8441709931765762, disc_loss = 0.06918240131845123
Trained batch 214 in epoch 13, gen_loss = 0.8446424096129661, disc_loss = 0.06905733151577934
Trained batch 215 in epoch 13, gen_loss = 0.8447925459455561, disc_loss = 0.06898024863201296
Trained batch 216 in epoch 13, gen_loss = 0.8439503117091095, disc_loss = 0.06906497566467194
Trained batch 217 in epoch 13, gen_loss = 0.8438838559006332, disc_loss = 0.06887918474460276
Trained batch 218 in epoch 13, gen_loss = 0.8432026666049, disc_loss = 0.06915675882318112
Trained batch 219 in epoch 13, gen_loss = 0.8433136593211781, disc_loss = 0.06894785137423738
Trained batch 220 in epoch 13, gen_loss = 0.8430100080654093, disc_loss = 0.06901917851433091
Trained batch 221 in epoch 13, gen_loss = 0.8427837389009493, disc_loss = 0.06895094518004372
Trained batch 222 in epoch 13, gen_loss = 0.8412646819657809, disc_loss = 0.06947867744790198
Trained batch 223 in epoch 13, gen_loss = 0.8432944592620645, disc_loss = 0.06960222922082591
Trained batch 224 in epoch 13, gen_loss = 0.8425844950146145, disc_loss = 0.06999403912574052
Trained batch 225 in epoch 13, gen_loss = 0.8418823348737396, disc_loss = 0.06985625264078246
Trained batch 226 in epoch 13, gen_loss = 0.8414383648775747, disc_loss = 0.06979244148629483
Trained batch 227 in epoch 13, gen_loss = 0.8404822820111325, disc_loss = 0.0698750612056373
Trained batch 228 in epoch 13, gen_loss = 0.8404834705148722, disc_loss = 0.06966203903803789
Trained batch 229 in epoch 13, gen_loss = 0.8420168112153592, disc_loss = 0.06964575933778415
Trained batch 230 in epoch 13, gen_loss = 0.8419748139587832, disc_loss = 0.06948608186224968
Trained batch 231 in epoch 13, gen_loss = 0.8414436303849878, disc_loss = 0.06956013292475635
Trained batch 232 in epoch 13, gen_loss = 0.8436577312424459, disc_loss = 0.06966703673305046
Trained batch 233 in epoch 13, gen_loss = 0.8433009600028013, disc_loss = 0.06953807532166441
Trained batch 234 in epoch 13, gen_loss = 0.8430116222259846, disc_loss = 0.069408959344505
Trained batch 235 in epoch 13, gen_loss = 0.8427628124669447, disc_loss = 0.06936085047752802
Trained batch 236 in epoch 13, gen_loss = 0.842082426769321, disc_loss = 0.06927120363740605
Trained batch 237 in epoch 13, gen_loss = 0.8432891336308808, disc_loss = 0.06938613555589769
Trained batch 238 in epoch 13, gen_loss = 0.8425472807684703, disc_loss = 0.06931459023441855
Trained batch 239 in epoch 13, gen_loss = 0.8427891463041306, disc_loss = 0.06908713258259619
Trained batch 240 in epoch 13, gen_loss = 0.8426318294774447, disc_loss = 0.06890209104587552
Trained batch 241 in epoch 13, gen_loss = 0.8420237265835123, disc_loss = 0.06889163024246323
Trained batch 242 in epoch 13, gen_loss = 0.843809588210573, disc_loss = 0.06871698623898712
Trained batch 243 in epoch 13, gen_loss = 0.8446226288549236, disc_loss = 0.06847265825729024
Trained batch 244 in epoch 13, gen_loss = 0.8443433048773785, disc_loss = 0.06849821658843026
Trained batch 245 in epoch 13, gen_loss = 0.8445900448454104, disc_loss = 0.06825673024026238
Trained batch 246 in epoch 13, gen_loss = 0.844595743335693, disc_loss = 0.06833046289756592
Trained batch 247 in epoch 13, gen_loss = 0.844128149651712, disc_loss = 0.06825293963699933
Trained batch 248 in epoch 13, gen_loss = 0.8439522151008667, disc_loss = 0.06807781878230443
Trained batch 249 in epoch 13, gen_loss = 0.844868246793747, disc_loss = 0.06816385313495994
Trained batch 250 in epoch 13, gen_loss = 0.8441741836973395, disc_loss = 0.06808191461792862
Trained batch 251 in epoch 13, gen_loss = 0.8432249048399547, disc_loss = 0.06833556928257975
Trained batch 252 in epoch 13, gen_loss = 0.8441307393929703, disc_loss = 0.06820874906737696
Trained batch 253 in epoch 13, gen_loss = 0.8440079731265391, disc_loss = 0.06818210674948462
Trained batch 254 in epoch 13, gen_loss = 0.8432195364260207, disc_loss = 0.06826454717665911
Trained batch 255 in epoch 13, gen_loss = 0.8442387878894806, disc_loss = 0.06845508310289006
Trained batch 256 in epoch 13, gen_loss = 0.843367528358786, disc_loss = 0.06860383409745846
Trained batch 257 in epoch 13, gen_loss = 0.8431194951367933, disc_loss = 0.06875909066058752
Trained batch 258 in epoch 13, gen_loss = 0.8435383869414164, disc_loss = 0.06862665981442657
Trained batch 259 in epoch 13, gen_loss = 0.8444200401122753, disc_loss = 0.06857807555665764
Trained batch 260 in epoch 13, gen_loss = 0.8438393092246804, disc_loss = 0.06881206959014995
Trained batch 261 in epoch 13, gen_loss = 0.8437494449033082, disc_loss = 0.06876209545667276
Trained batch 262 in epoch 13, gen_loss = 0.8436044080629095, disc_loss = 0.06866984583168316
Trained batch 263 in epoch 13, gen_loss = 0.8431349848255967, disc_loss = 0.06855282593504385
Trained batch 264 in epoch 13, gen_loss = 0.8427514580060851, disc_loss = 0.06873836817817305
Trained batch 265 in epoch 13, gen_loss = 0.8441311882850819, disc_loss = 0.06864475469714157
Trained batch 266 in epoch 13, gen_loss = 0.8427303142092201, disc_loss = 0.06961569842648752
Trained batch 267 in epoch 13, gen_loss = 0.8433306204961307, disc_loss = 0.06956881649945099
Trained batch 268 in epoch 13, gen_loss = 0.8437321672430712, disc_loss = 0.06978373122522712
Trained batch 269 in epoch 13, gen_loss = 0.8432620480104729, disc_loss = 0.06977811244281906
Trained batch 270 in epoch 13, gen_loss = 0.842044778965496, disc_loss = 0.07021877151395012
Trained batch 271 in epoch 13, gen_loss = 0.8428262556519579, disc_loss = 0.07010012089535046
Trained batch 272 in epoch 13, gen_loss = 0.8422097029921772, disc_loss = 0.07008413495257115
Trained batch 273 in epoch 13, gen_loss = 0.8411985397556402, disc_loss = 0.07015913052919463
Trained batch 274 in epoch 13, gen_loss = 0.8417510835690932, disc_loss = 0.07067241627722978
Trained batch 275 in epoch 13, gen_loss = 0.8412683823186419, disc_loss = 0.07057847411614722
Trained batch 276 in epoch 13, gen_loss = 0.8406318702637504, disc_loss = 0.07067342360406469
Trained batch 277 in epoch 13, gen_loss = 0.8414228482426499, disc_loss = 0.07080487177620153
Trained batch 278 in epoch 13, gen_loss = 0.840248340880999, disc_loss = 0.07110575834576267
Trained batch 279 in epoch 13, gen_loss = 0.8395888133772782, disc_loss = 0.07114817180471229
Trained batch 280 in epoch 13, gen_loss = 0.8404516911803616, disc_loss = 0.07145081179090561
Trained batch 281 in epoch 13, gen_loss = 0.8400611724202515, disc_loss = 0.07150720614371887
Trained batch 282 in epoch 13, gen_loss = 0.8393971097553576, disc_loss = 0.07159150512592848
Trained batch 283 in epoch 13, gen_loss = 0.8411076919923366, disc_loss = 0.07186972011129936
Trained batch 284 in epoch 13, gen_loss = 0.8400707331665775, disc_loss = 0.07201706625586539
Trained batch 285 in epoch 13, gen_loss = 0.8396348785478752, disc_loss = 0.07195361794487058
Trained batch 286 in epoch 13, gen_loss = 0.8397578870170208, disc_loss = 0.07255298773780829
Trained batch 287 in epoch 13, gen_loss = 0.8402234602512585, disc_loss = 0.0723735309277092
Trained batch 288 in epoch 13, gen_loss = 0.8396574053591098, disc_loss = 0.07226058001272304
Trained batch 289 in epoch 13, gen_loss = 0.8394043376733517, disc_loss = 0.07209841374885934
Trained batch 290 in epoch 13, gen_loss = 0.8397449333848003, disc_loss = 0.07188968214164793
Trained batch 291 in epoch 13, gen_loss = 0.8405869718487948, disc_loss = 0.0718423390014684
Trained batch 292 in epoch 13, gen_loss = 0.840516093749642, disc_loss = 0.07179917172296767
Trained batch 293 in epoch 13, gen_loss = 0.840204848825526, disc_loss = 0.07168115592770735
Trained batch 294 in epoch 13, gen_loss = 0.840710646924326, disc_loss = 0.07148300491083982
Trained batch 295 in epoch 13, gen_loss = 0.8412474475398257, disc_loss = 0.0713058481515209
Trained batch 296 in epoch 13, gen_loss = 0.8410152643417268, disc_loss = 0.07137247929757191
Trained batch 297 in epoch 13, gen_loss = 0.8404551649453657, disc_loss = 0.07142430253564411
Trained batch 298 in epoch 13, gen_loss = 0.840634297666741, disc_loss = 0.0713956904469874
Trained batch 299 in epoch 13, gen_loss = 0.8409157330791156, disc_loss = 0.07130765540835758
Trained batch 300 in epoch 13, gen_loss = 0.8407731776023624, disc_loss = 0.07118992395760906
Trained batch 301 in epoch 13, gen_loss = 0.8410010435525944, disc_loss = 0.07106993764034467
Trained batch 302 in epoch 13, gen_loss = 0.8407597965729905, disc_loss = 0.07093013391181482
Trained batch 303 in epoch 13, gen_loss = 0.8413220219510166, disc_loss = 0.07084422951600955
Trained batch 304 in epoch 13, gen_loss = 0.84124128163838, disc_loss = 0.07071599985671337
Trained batch 305 in epoch 13, gen_loss = 0.8413769184958702, disc_loss = 0.07077364592806869
Trained batch 306 in epoch 13, gen_loss = 0.8409577535301545, disc_loss = 0.07081881571706712
Trained batch 307 in epoch 13, gen_loss = 0.8410778679437452, disc_loss = 0.07083366088895732
Trained batch 308 in epoch 13, gen_loss = 0.8413639210381554, disc_loss = 0.07074653577589969
Trained batch 309 in epoch 13, gen_loss = 0.8406703990313315, disc_loss = 0.07098410039118701
Trained batch 310 in epoch 13, gen_loss = 0.8408817670927937, disc_loss = 0.07083957760004848
Trained batch 311 in epoch 13, gen_loss = 0.8408636784133239, disc_loss = 0.07087770524995927
Trained batch 312 in epoch 13, gen_loss = 0.8407367186995741, disc_loss = 0.07082070992551387
Trained batch 313 in epoch 13, gen_loss = 0.8412280899893706, disc_loss = 0.07066182778839758
Trained batch 314 in epoch 13, gen_loss = 0.8406055547888317, disc_loss = 0.07067386385881239
Trained batch 315 in epoch 13, gen_loss = 0.8410200377619719, disc_loss = 0.07052726949612269
Trained batch 316 in epoch 13, gen_loss = 0.8410436203615147, disc_loss = 0.0704336299087958
Trained batch 317 in epoch 13, gen_loss = 0.8410305514837961, disc_loss = 0.07031091271296332
Trained batch 318 in epoch 13, gen_loss = 0.8404360586386116, disc_loss = 0.07042553856513437
Trained batch 319 in epoch 13, gen_loss = 0.841120224352926, disc_loss = 0.0707239144394407
Trained batch 320 in epoch 13, gen_loss = 0.8416286498029656, disc_loss = 0.0705359874879274
Trained batch 321 in epoch 13, gen_loss = 0.8408105914822276, disc_loss = 0.07069692528164535
Trained batch 322 in epoch 13, gen_loss = 0.840491011877178, disc_loss = 0.07057817337959543
Trained batch 323 in epoch 13, gen_loss = 0.8411933306006738, disc_loss = 0.07050228555813248
Trained batch 324 in epoch 13, gen_loss = 0.8414781919809489, disc_loss = 0.07032763294875621
Trained batch 325 in epoch 13, gen_loss = 0.8418001601118251, disc_loss = 0.0702064294379456
Trained batch 326 in epoch 13, gen_loss = 0.8417966038626633, disc_loss = 0.07014114083295021
Trained batch 327 in epoch 13, gen_loss = 0.8414102164892162, disc_loss = 0.07015543698514926
Trained batch 328 in epoch 13, gen_loss = 0.8422452023869952, disc_loss = 0.07017136760916572
Trained batch 329 in epoch 13, gen_loss = 0.8414461248751842, disc_loss = 0.07034487823080836
Trained batch 330 in epoch 13, gen_loss = 0.8417873621167012, disc_loss = 0.0702409385520616
Trained batch 331 in epoch 13, gen_loss = 0.8421247412102768, disc_loss = 0.07052017614267857
Trained batch 332 in epoch 13, gen_loss = 0.8416453235679202, disc_loss = 0.07075172336632246
Trained batch 333 in epoch 13, gen_loss = 0.841096453770192, disc_loss = 0.07091043916848784
Trained batch 334 in epoch 13, gen_loss = 0.8413426962361407, disc_loss = 0.07078262779361276
Trained batch 335 in epoch 13, gen_loss = 0.841004193272619, disc_loss = 0.07089134292965311
Trained batch 336 in epoch 13, gen_loss = 0.8406628730212192, disc_loss = 0.07076843344891107
Trained batch 337 in epoch 13, gen_loss = 0.8408803639150936, disc_loss = 0.07065817733576311
Trained batch 338 in epoch 13, gen_loss = 0.8404977204701191, disc_loss = 0.07059168371654893
Trained batch 339 in epoch 13, gen_loss = 0.8405980617684476, disc_loss = 0.07043200404766728
Trained batch 340 in epoch 13, gen_loss = 0.8409055236322789, disc_loss = 0.07040647529830331
Trained batch 341 in epoch 13, gen_loss = 0.8409638083294818, disc_loss = 0.07033100784129916
Trained batch 342 in epoch 13, gen_loss = 0.8406303626629076, disc_loss = 0.07038785950565825
Trained batch 343 in epoch 13, gen_loss = 0.840532727626174, disc_loss = 0.0704060242901188
Trained batch 344 in epoch 13, gen_loss = 0.8407070501127105, disc_loss = 0.07024300485525442
Trained batch 345 in epoch 13, gen_loss = 0.8406958872010942, disc_loss = 0.0701373476653516
Trained batch 346 in epoch 13, gen_loss = 0.8398182937494273, disc_loss = 0.07019802091122533
Trained batch 347 in epoch 13, gen_loss = 0.8406259567401875, disc_loss = 0.07014012400424857
Trained batch 348 in epoch 13, gen_loss = 0.8412582016093683, disc_loss = 0.07022108922693825
Trained batch 349 in epoch 13, gen_loss = 0.8425759713138853, disc_loss = 0.07013022610651595
Trained batch 350 in epoch 13, gen_loss = 0.8415130840407478, disc_loss = 0.07046973421384296
Trained batch 351 in epoch 13, gen_loss = 0.8411869149316441, disc_loss = 0.07045387303647162
Trained batch 352 in epoch 13, gen_loss = 0.8408419623253366, disc_loss = 0.07036954486906191
Trained batch 353 in epoch 13, gen_loss = 0.8408295657001646, disc_loss = 0.0707575392746235
Trained batch 354 in epoch 13, gen_loss = 0.8408946666919009, disc_loss = 0.0706175440056643
Trained batch 355 in epoch 13, gen_loss = 0.8399126521322164, disc_loss = 0.07083250379733992
Trained batch 356 in epoch 13, gen_loss = 0.8399109778617945, disc_loss = 0.07071574275441864
Trained batch 357 in epoch 13, gen_loss = 0.8399716515780827, disc_loss = 0.07062951703269721
Trained batch 358 in epoch 13, gen_loss = 0.840113696447654, disc_loss = 0.07048940874407883
Trained batch 359 in epoch 13, gen_loss = 0.8396301784449154, disc_loss = 0.07048016178111235
Trained batch 360 in epoch 13, gen_loss = 0.8395727678018924, disc_loss = 0.0704109516727462
Trained batch 361 in epoch 13, gen_loss = 0.8400180030264248, disc_loss = 0.0705967955805814
Trained batch 362 in epoch 13, gen_loss = 0.8394390403731795, disc_loss = 0.07064468716335362
Trained batch 363 in epoch 13, gen_loss = 0.8389541578816844, disc_loss = 0.07063916083015911
Trained batch 364 in epoch 13, gen_loss = 0.8390314219749138, disc_loss = 0.07061568629251767
Trained batch 365 in epoch 13, gen_loss = 0.8397795206210652, disc_loss = 0.07069597965299758
Trained batch 366 in epoch 13, gen_loss = 0.8400358825678397, disc_loss = 0.07063093272923449
Trained batch 367 in epoch 13, gen_loss = 0.8392943798199944, disc_loss = 0.07099507298603978
Trained batch 368 in epoch 13, gen_loss = 0.8394460287197496, disc_loss = 0.0709305811057569
Trained batch 369 in epoch 13, gen_loss = 0.8401622820544887, disc_loss = 0.07082383265165058
Trained batch 370 in epoch 13, gen_loss = 0.8396792119404055, disc_loss = 0.0709090962744948
Trained batch 371 in epoch 13, gen_loss = 0.8403071668199313, disc_loss = 0.07110883408696742
Trained batch 372 in epoch 13, gen_loss = 0.8400712825018344, disc_loss = 0.07103837001819073
Trained batch 373 in epoch 13, gen_loss = 0.8399163723629426, disc_loss = 0.07095751652424348
Trained batch 374 in epoch 13, gen_loss = 0.83977530225118, disc_loss = 0.07083683091402054
Trained batch 375 in epoch 13, gen_loss = 0.8403389587047252, disc_loss = 0.07084499868227447
Trained batch 376 in epoch 13, gen_loss = 0.8400308135649887, disc_loss = 0.07078381352106836
Trained batch 377 in epoch 13, gen_loss = 0.8398670095299917, disc_loss = 0.07074095282171454
Trained batch 378 in epoch 13, gen_loss = 0.8391745170691397, disc_loss = 0.07091495659113874
Trained batch 379 in epoch 13, gen_loss = 0.8397122412919998, disc_loss = 0.07087917132793288
Trained batch 380 in epoch 13, gen_loss = 0.840253598264509, disc_loss = 0.07076659527291933
Trained batch 381 in epoch 13, gen_loss = 0.8396399358180181, disc_loss = 0.07082087650446524
Trained batch 382 in epoch 13, gen_loss = 0.8390779244681874, disc_loss = 0.071076670009886
Trained batch 383 in epoch 13, gen_loss = 0.8390755465564629, disc_loss = 0.07099663914899186
Trained batch 384 in epoch 13, gen_loss = 0.8398216153120066, disc_loss = 0.07115621162796175
Trained batch 385 in epoch 13, gen_loss = 0.8395898528976143, disc_loss = 0.07114024711724544
Trained batch 386 in epoch 13, gen_loss = 0.8392835268678591, disc_loss = 0.07113640759746696
Trained batch 387 in epoch 13, gen_loss = 0.8393871887135751, disc_loss = 0.07102538599661484
Trained batch 388 in epoch 13, gen_loss = 0.8388291853252597, disc_loss = 0.07108442010812864
Trained batch 389 in epoch 13, gen_loss = 0.839738364250232, disc_loss = 0.07112469610590966
Trained batch 390 in epoch 13, gen_loss = 0.8395832787694224, disc_loss = 0.07109669463999589
Trained batch 391 in epoch 13, gen_loss = 0.8390266889212082, disc_loss = 0.07125287802832923
Trained batch 392 in epoch 13, gen_loss = 0.8396459469055099, disc_loss = 0.07130839567129091
Trained batch 393 in epoch 13, gen_loss = 0.8388104245142283, disc_loss = 0.07150097622011367
Trained batch 394 in epoch 13, gen_loss = 0.8396834494192389, disc_loss = 0.07145229128625574
Trained batch 395 in epoch 13, gen_loss = 0.8395121877241616, disc_loss = 0.07147928020173702
Trained batch 396 in epoch 13, gen_loss = 0.8394509083978475, disc_loss = 0.07146515024905692
Trained batch 397 in epoch 13, gen_loss = 0.8398365505676174, disc_loss = 0.07135730138488451
Trained batch 398 in epoch 13, gen_loss = 0.8396513309693874, disc_loss = 0.07137029131589677
Trained batch 399 in epoch 13, gen_loss = 0.8399406206607819, disc_loss = 0.07126069274265319
Trained batch 400 in epoch 13, gen_loss = 0.8409932902328986, disc_loss = 0.0711885766634843
Trained batch 401 in epoch 13, gen_loss = 0.8409576181748614, disc_loss = 0.07108764334197216
Trained batch 402 in epoch 13, gen_loss = 0.8405454848007884, disc_loss = 0.07115287733525408
Trained batch 403 in epoch 13, gen_loss = 0.8400032033424566, disc_loss = 0.0714738339342472
Trained batch 404 in epoch 13, gen_loss = 0.8400095242041129, disc_loss = 0.0713998596287436
Trained batch 405 in epoch 13, gen_loss = 0.8402485182426246, disc_loss = 0.0713935242323526
Trained batch 406 in epoch 13, gen_loss = 0.8401734265121253, disc_loss = 0.07131625290420043
Trained batch 407 in epoch 13, gen_loss = 0.8405435447599373, disc_loss = 0.0712043902078899
Trained batch 408 in epoch 13, gen_loss = 0.8407067483095202, disc_loss = 0.07106281605191657
Trained batch 409 in epoch 13, gen_loss = 0.8403291394070881, disc_loss = 0.07110243319283899
Trained batch 410 in epoch 13, gen_loss = 0.8399888961564596, disc_loss = 0.07101196052909912
Trained batch 411 in epoch 13, gen_loss = 0.8395396592547593, disc_loss = 0.07119362991646801
Trained batch 412 in epoch 13, gen_loss = 0.8399091527479324, disc_loss = 0.07107673627358227
Trained batch 413 in epoch 13, gen_loss = 0.8406865575175354, disc_loss = 0.07094426197112326
Trained batch 414 in epoch 13, gen_loss = 0.8413081739322249, disc_loss = 0.07085471180637917
Trained batch 415 in epoch 13, gen_loss = 0.8406399859545323, disc_loss = 0.07104324444215028
Trained batch 416 in epoch 13, gen_loss = 0.8405458765635959, disc_loss = 0.07092836090504266
Trained batch 417 in epoch 13, gen_loss = 0.8409520289259094, disc_loss = 0.07080243892397321
Trained batch 418 in epoch 13, gen_loss = 0.8409830738650301, disc_loss = 0.07089027580149418
Trained batch 419 in epoch 13, gen_loss = 0.8409713718153181, disc_loss = 0.07085617630786839
Trained batch 420 in epoch 13, gen_loss = 0.8407856708750872, disc_loss = 0.07080447583541168
Trained batch 421 in epoch 13, gen_loss = 0.8407927937982207, disc_loss = 0.07069643200220654
Trained batch 422 in epoch 13, gen_loss = 0.8410517932675409, disc_loss = 0.07065625200774653
Trained batch 423 in epoch 13, gen_loss = 0.8409043834456857, disc_loss = 0.07062996828155417
Trained batch 424 in epoch 13, gen_loss = 0.8418083636900958, disc_loss = 0.07053313105421907
Trained batch 425 in epoch 13, gen_loss = 0.8419167295867849, disc_loss = 0.07045052024785062
Trained batch 426 in epoch 13, gen_loss = 0.8420341295436617, disc_loss = 0.0703388872650175
Trained batch 427 in epoch 13, gen_loss = 0.8420315759482785, disc_loss = 0.07024113791690112
Trained batch 428 in epoch 13, gen_loss = 0.8420625916727773, disc_loss = 0.07014280412615317
Trained batch 429 in epoch 13, gen_loss = 0.8423120893711268, disc_loss = 0.07016183149156183
Trained batch 430 in epoch 13, gen_loss = 0.842027547326276, disc_loss = 0.07020532347590354
Trained batch 431 in epoch 13, gen_loss = 0.8424774208278568, disc_loss = 0.07017785756572804
Trained batch 432 in epoch 13, gen_loss = 0.8431974251606172, disc_loss = 0.07010533174555791
Trained batch 433 in epoch 13, gen_loss = 0.8431916507433087, disc_loss = 0.07001601471157942
Trained batch 434 in epoch 13, gen_loss = 0.8429938388966965, disc_loss = 0.06998260431419843
Trained batch 435 in epoch 13, gen_loss = 0.8429813914069342, disc_loss = 0.06986793042630504
Trained batch 436 in epoch 13, gen_loss = 0.8441941821329654, disc_loss = 0.0700556669358667
Trained batch 437 in epoch 13, gen_loss = 0.8438065684821507, disc_loss = 0.07025510719956056
Trained batch 438 in epoch 13, gen_loss = 0.8439757170872699, disc_loss = 0.0701777711934951
Trained batch 439 in epoch 13, gen_loss = 0.8451980177651752, disc_loss = 0.07026161848652092
Trained batch 440 in epoch 13, gen_loss = 0.8453801937925032, disc_loss = 0.07015777283396715
Trained batch 441 in epoch 13, gen_loss = 0.8448242640872886, disc_loss = 0.0703725237020068
Trained batch 442 in epoch 13, gen_loss = 0.8453703993599248, disc_loss = 0.07026126628434685
Trained batch 443 in epoch 13, gen_loss = 0.8457199118964307, disc_loss = 0.07034906640078302
Trained batch 444 in epoch 13, gen_loss = 0.8451266926326109, disc_loss = 0.07042231672767843
Trained batch 445 in epoch 13, gen_loss = 0.8444802691583676, disc_loss = 0.07047105489524223
Trained batch 446 in epoch 13, gen_loss = 0.8444790669468959, disc_loss = 0.07034278680805858
Trained batch 447 in epoch 13, gen_loss = 0.8443631080112287, disc_loss = 0.07025119243397578
Trained batch 448 in epoch 13, gen_loss = 0.8446626052559086, disc_loss = 0.07017470521433383
Trained batch 449 in epoch 13, gen_loss = 0.8440681343608433, disc_loss = 0.07028051866632369
Trained batch 450 in epoch 13, gen_loss = 0.8444997547999719, disc_loss = 0.07020027318684396
Trained batch 451 in epoch 13, gen_loss = 0.8448032219853021, disc_loss = 0.07006418932254006
Trained batch 452 in epoch 13, gen_loss = 0.8443449535643555, disc_loss = 0.07003247690804418
Trained batch 453 in epoch 13, gen_loss = 0.8445071530762223, disc_loss = 0.07001585394989224
Trained batch 454 in epoch 13, gen_loss = 0.8442915050538031, disc_loss = 0.06999919141673452
Trained batch 455 in epoch 13, gen_loss = 0.8443282219140154, disc_loss = 0.06991030638343082
Trained batch 456 in epoch 13, gen_loss = 0.8449724569623267, disc_loss = 0.070205767088747
Trained batch 457 in epoch 13, gen_loss = 0.8446412673423384, disc_loss = 0.07027813648870093
Trained batch 458 in epoch 13, gen_loss = 0.8443077128697065, disc_loss = 0.07035740563739294
Trained batch 459 in epoch 13, gen_loss = 0.8442538718814435, disc_loss = 0.07054794236167293
Trained batch 460 in epoch 13, gen_loss = 0.8442932153989333, disc_loss = 0.07063634250587794
Trained batch 461 in epoch 13, gen_loss = 0.844373473486343, disc_loss = 0.07054835822215522
Trained batch 462 in epoch 13, gen_loss = 0.8440266134414508, disc_loss = 0.07054682357385594
Trained batch 463 in epoch 13, gen_loss = 0.8441833887120773, disc_loss = 0.0707446031155996
Trained batch 464 in epoch 13, gen_loss = 0.8437417212352958, disc_loss = 0.07071975477400326
Trained batch 465 in epoch 13, gen_loss = 0.8440353701554655, disc_loss = 0.07059577170783422
Trained batch 466 in epoch 13, gen_loss = 0.8439914718174577, disc_loss = 0.07054574439218328
Trained batch 467 in epoch 13, gen_loss = 0.8436384911720569, disc_loss = 0.07049177887324148
Trained batch 468 in epoch 13, gen_loss = 0.8438279082271845, disc_loss = 0.0706069404418185
Trained batch 469 in epoch 13, gen_loss = 0.8443250795628162, disc_loss = 0.07051450286972079
Trained batch 470 in epoch 13, gen_loss = 0.8439860451499874, disc_loss = 0.07045533238552242
Trained batch 471 in epoch 13, gen_loss = 0.8444521832516638, disc_loss = 0.07043231309636228
Trained batch 472 in epoch 13, gen_loss = 0.8448637689898937, disc_loss = 0.07030558828697649
Trained batch 473 in epoch 13, gen_loss = 0.844566726357625, disc_loss = 0.07033663871796322
Trained batch 474 in epoch 13, gen_loss = 0.8441590586461519, disc_loss = 0.07030895710775727
Trained batch 475 in epoch 13, gen_loss = 0.8447032832548398, disc_loss = 0.07062762688469737
Trained batch 476 in epoch 13, gen_loss = 0.8447860960440565, disc_loss = 0.07058194520213569
Trained batch 477 in epoch 13, gen_loss = 0.8441706101515303, disc_loss = 0.07080437853994728
Trained batch 478 in epoch 13, gen_loss = 0.8445678109415886, disc_loss = 0.07070468141773176
Trained batch 479 in epoch 13, gen_loss = 0.8449145082384348, disc_loss = 0.07058336922976499
Trained batch 480 in epoch 13, gen_loss = 0.84518205462771, disc_loss = 0.07049061116721798
Trained batch 481 in epoch 13, gen_loss = 0.8444966908807082, disc_loss = 0.07068642794977703
Trained batch 482 in epoch 13, gen_loss = 0.844643813729533, disc_loss = 0.07059811748271157
Trained batch 483 in epoch 13, gen_loss = 0.844674836382393, disc_loss = 0.07062652922612576
Trained batch 484 in epoch 13, gen_loss = 0.8442270973294052, disc_loss = 0.07061605865193396
Trained batch 485 in epoch 13, gen_loss = 0.8442694682152674, disc_loss = 0.07056269258138084
Trained batch 486 in epoch 13, gen_loss = 0.8441942582629789, disc_loss = 0.0704551402640049
Trained batch 487 in epoch 13, gen_loss = 0.844629743304409, disc_loss = 0.07036318407455062
Trained batch 488 in epoch 13, gen_loss = 0.8441498113799925, disc_loss = 0.07036518133750112
Trained batch 489 in epoch 13, gen_loss = 0.8444047570228577, disc_loss = 0.0703638477783118
Trained batch 490 in epoch 13, gen_loss = 0.8447595737616544, disc_loss = 0.07024700592922582
Trained batch 491 in epoch 13, gen_loss = 0.8444814742580662, disc_loss = 0.07030254126170545
Trained batch 492 in epoch 13, gen_loss = 0.8440616644662002, disc_loss = 0.07036201135230838
Trained batch 493 in epoch 13, gen_loss = 0.8445329611841966, disc_loss = 0.07037007703864381
Trained batch 494 in epoch 13, gen_loss = 0.8441177439207983, disc_loss = 0.07038901018524411
Trained batch 495 in epoch 13, gen_loss = 0.8440437947790469, disc_loss = 0.07040280532542496
Trained batch 496 in epoch 13, gen_loss = 0.8441429519557377, disc_loss = 0.07030611624660146
Trained batch 497 in epoch 13, gen_loss = 0.8441677275431683, disc_loss = 0.07021771786906514
Trained batch 498 in epoch 13, gen_loss = 0.8444123090149644, disc_loss = 0.07014262474296924
Trained batch 499 in epoch 13, gen_loss = 0.8445614848136902, disc_loss = 0.07005366551503539
Trained batch 500 in epoch 13, gen_loss = 0.8442906743276143, disc_loss = 0.06997123031975504
Trained batch 501 in epoch 13, gen_loss = 0.8448188088804602, disc_loss = 0.06985983892021129
Trained batch 502 in epoch 13, gen_loss = 0.8451738547141225, disc_loss = 0.06975750428685552
Trained batch 503 in epoch 13, gen_loss = 0.8456363980732267, disc_loss = 0.06968716780899004
Trained batch 504 in epoch 13, gen_loss = 0.8452072654620255, disc_loss = 0.06971366423744671
Trained batch 505 in epoch 13, gen_loss = 0.8451715270756733, disc_loss = 0.06961269790615901
Trained batch 506 in epoch 13, gen_loss = 0.8447361379215232, disc_loss = 0.06961952813182769
Trained batch 507 in epoch 13, gen_loss = 0.845169701796817, disc_loss = 0.06953224736837832
Trained batch 508 in epoch 13, gen_loss = 0.8459160542207055, disc_loss = 0.06957964538203183
Trained batch 509 in epoch 13, gen_loss = 0.845619086190766, disc_loss = 0.06960818307912525
Trained batch 510 in epoch 13, gen_loss = 0.8456018264979532, disc_loss = 0.06955519546581516
Trained batch 511 in epoch 13, gen_loss = 0.8460410172119737, disc_loss = 0.06951483237753564
Trained batch 512 in epoch 13, gen_loss = 0.8463884745424951, disc_loss = 0.0697542068259845
Trained batch 513 in epoch 13, gen_loss = 0.845770866606486, disc_loss = 0.07009350474206331
Trained batch 514 in epoch 13, gen_loss = 0.8461415666978336, disc_loss = 0.0699899735471722
Trained batch 515 in epoch 13, gen_loss = 0.8461800733971041, disc_loss = 0.06990902492047338
Trained batch 516 in epoch 13, gen_loss = 0.8458815124786568, disc_loss = 0.06986074049631044
Trained batch 517 in epoch 13, gen_loss = 0.8466083617974433, disc_loss = 0.06989069867871961
Trained batch 518 in epoch 13, gen_loss = 0.8466040145225378, disc_loss = 0.06978517129967036
Trained batch 519 in epoch 13, gen_loss = 0.8464063579073319, disc_loss = 0.06976007225457578
Trained batch 520 in epoch 13, gen_loss = 0.8461383376377787, disc_loss = 0.0697071674993108
Trained batch 521 in epoch 13, gen_loss = 0.8462290208915184, disc_loss = 0.06964134175323264
Trained batch 522 in epoch 13, gen_loss = 0.8470931080513657, disc_loss = 0.06964534719298321
Trained batch 523 in epoch 13, gen_loss = 0.847362351326542, disc_loss = 0.06953310574589738
Trained batch 524 in epoch 13, gen_loss = 0.8475083817754473, disc_loss = 0.06942531886022715
Trained batch 525 in epoch 13, gen_loss = 0.847315890027543, disc_loss = 0.06944644680076735
Trained batch 526 in epoch 13, gen_loss = 0.8477769972477285, disc_loss = 0.069363628849882
Trained batch 527 in epoch 13, gen_loss = 0.8476958675592234, disc_loss = 0.0692929061937541
Trained batch 528 in epoch 13, gen_loss = 0.8476295440769376, disc_loss = 0.06918376603028217
Trained batch 529 in epoch 13, gen_loss = 0.8477646584780711, disc_loss = 0.06915011012153524
Trained batch 530 in epoch 13, gen_loss = 0.8477966620423699, disc_loss = 0.06907110835781598
Trained batch 531 in epoch 13, gen_loss = 0.8477124637903127, disc_loss = 0.06896444088324233
Trained batch 532 in epoch 13, gen_loss = 0.8478846485127204, disc_loss = 0.06886891208896606
Trained batch 533 in epoch 13, gen_loss = 0.8480343840988388, disc_loss = 0.06878179850314887
Trained batch 534 in epoch 13, gen_loss = 0.8487423999287258, disc_loss = 0.06879996536212547
Trained batch 535 in epoch 13, gen_loss = 0.8494904263695674, disc_loss = 0.06904478872945505
Trained batch 536 in epoch 13, gen_loss = 0.8490859405510475, disc_loss = 0.06939621468107572
Trained batch 537 in epoch 13, gen_loss = 0.8490177359722804, disc_loss = 0.06944646007731059
Trained batch 538 in epoch 13, gen_loss = 0.8491103985314025, disc_loss = 0.06952190596838387
Trained batch 539 in epoch 13, gen_loss = 0.8493318030127772, disc_loss = 0.06946485661384132
Trained batch 540 in epoch 13, gen_loss = 0.8493918403019085, disc_loss = 0.06938913443544105
Trained batch 541 in epoch 13, gen_loss = 0.8493946210044776, disc_loss = 0.069349901472318
Trained batch 542 in epoch 13, gen_loss = 0.8492579554545506, disc_loss = 0.06927661111314214
Trained batch 543 in epoch 13, gen_loss = 0.8491149654283243, disc_loss = 0.0692084040150375
Trained batch 544 in epoch 13, gen_loss = 0.8496403676654221, disc_loss = 0.06919361054213768
Trained batch 545 in epoch 13, gen_loss = 0.8495664607474219, disc_loss = 0.06909370748496754
Trained batch 546 in epoch 13, gen_loss = 0.8492884717650125, disc_loss = 0.06908601850707091
Trained batch 547 in epoch 13, gen_loss = 0.8494722435291666, disc_loss = 0.06898031729089953
Trained batch 548 in epoch 13, gen_loss = 0.8496993915847959, disc_loss = 0.06889093464718817
Trained batch 549 in epoch 13, gen_loss = 0.8495368425412612, disc_loss = 0.06887953263453461
Trained batch 550 in epoch 13, gen_loss = 0.8495179375806002, disc_loss = 0.06882891669098673
Trained batch 551 in epoch 13, gen_loss = 0.8498280827981838, disc_loss = 0.06873590577785196
Trained batch 552 in epoch 13, gen_loss = 0.8501491087470304, disc_loss = 0.06866089015808394
Trained batch 553 in epoch 13, gen_loss = 0.8499824684449482, disc_loss = 0.06870159550842288
Trained batch 554 in epoch 13, gen_loss = 0.8501303520288553, disc_loss = 0.06865637276556578
Trained batch 555 in epoch 13, gen_loss = 0.8501262705531909, disc_loss = 0.06855877523524888
Trained batch 556 in epoch 13, gen_loss = 0.8503924475538024, disc_loss = 0.06848690465019089
Trained batch 557 in epoch 13, gen_loss = 0.8509346233901157, disc_loss = 0.06839041528375452
Trained batch 558 in epoch 13, gen_loss = 0.8509681065948363, disc_loss = 0.06832624307112212
Trained batch 559 in epoch 13, gen_loss = 0.8504527001508645, disc_loss = 0.06843891110869922
Trained batch 560 in epoch 13, gen_loss = 0.8510150245379212, disc_loss = 0.0684311154486077
Trained batch 561 in epoch 13, gen_loss = 0.8518155218231296, disc_loss = 0.06844932380798555
Trained batch 562 in epoch 13, gen_loss = 0.8517238926506381, disc_loss = 0.06837430492797816
Trained batch 563 in epoch 13, gen_loss = 0.8514043744785565, disc_loss = 0.06844514054543477
Trained batch 564 in epoch 13, gen_loss = 0.851348721137089, disc_loss = 0.06838299236136727
Trained batch 565 in epoch 13, gen_loss = 0.8519386496434364, disc_loss = 0.06845773827258247
Trained batch 566 in epoch 13, gen_loss = 0.851629282852119, disc_loss = 0.06845383605931277
Trained batch 567 in epoch 13, gen_loss = 0.8514969857855582, disc_loss = 0.06846463197225731
Trained batch 568 in epoch 13, gen_loss = 0.8521313471408636, disc_loss = 0.06839096435854745
Trained batch 569 in epoch 13, gen_loss = 0.8523423774200574, disc_loss = 0.06830359161422964
Trained batch 570 in epoch 13, gen_loss = 0.8524190701035401, disc_loss = 0.06822380124413507
Trained batch 571 in epoch 13, gen_loss = 0.8521171255961998, disc_loss = 0.06815442029334656
Trained batch 572 in epoch 13, gen_loss = 0.8522212374272771, disc_loss = 0.06806210395969438
Trained batch 573 in epoch 13, gen_loss = 0.8521306360017132, disc_loss = 0.06800243501853237
Trained batch 574 in epoch 13, gen_loss = 0.8522719396715579, disc_loss = 0.06792411071450814
Trained batch 575 in epoch 13, gen_loss = 0.8523812868321935, disc_loss = 0.06782395353042779
Trained batch 576 in epoch 13, gen_loss = 0.8529139326391435, disc_loss = 0.0679044903044555
Trained batch 577 in epoch 13, gen_loss = 0.8528405546523296, disc_loss = 0.06790767937969533
Trained batch 578 in epoch 13, gen_loss = 0.8525596499854831, disc_loss = 0.06785798763023088
Trained batch 579 in epoch 13, gen_loss = 0.8524555816732604, disc_loss = 0.06779273664739369
Trained batch 580 in epoch 13, gen_loss = 0.8528896968253918, disc_loss = 0.06774216761937599
Trained batch 581 in epoch 13, gen_loss = 0.8530658125058073, disc_loss = 0.06772649197765591
Trained batch 582 in epoch 13, gen_loss = 0.8527270328528271, disc_loss = 0.06774326594543242
Trained batch 583 in epoch 13, gen_loss = 0.8525281794471283, disc_loss = 0.0676773864256014
Trained batch 584 in epoch 13, gen_loss = 0.8524174018802806, disc_loss = 0.06760881967428657
Trained batch 585 in epoch 13, gen_loss = 0.8522890688209404, disc_loss = 0.06754586606130716
Trained batch 586 in epoch 13, gen_loss = 0.852067258938817, disc_loss = 0.06753471292701298
Trained batch 587 in epoch 13, gen_loss = 0.8522446255902855, disc_loss = 0.06746406276190818
Trained batch 588 in epoch 13, gen_loss = 0.8524587620903559, disc_loss = 0.06739797665309066
Trained batch 589 in epoch 13, gen_loss = 0.8524756831637884, disc_loss = 0.06730210677704822
Trained batch 590 in epoch 13, gen_loss = 0.8522441005948836, disc_loss = 0.06725318493028432
Trained batch 591 in epoch 13, gen_loss = 0.8524372657207219, disc_loss = 0.06715297142383517
Trained batch 592 in epoch 13, gen_loss = 0.852450256001889, disc_loss = 0.06705848612425248
Trained batch 593 in epoch 13, gen_loss = 0.8524880108207163, disc_loss = 0.06705343486076402
Trained batch 594 in epoch 13, gen_loss = 0.8520245973803416, disc_loss = 0.06704417833854921
Trained batch 595 in epoch 13, gen_loss = 0.8519541430193306, disc_loss = 0.06699994876949529
Trained batch 596 in epoch 13, gen_loss = 0.8521344456041678, disc_loss = 0.06694492539063321
Trained batch 597 in epoch 13, gen_loss = 0.8527957805024342, disc_loss = 0.06689680654113259
Trained batch 598 in epoch 13, gen_loss = 0.852765124508853, disc_loss = 0.06688762625184949
Trained batch 599 in epoch 13, gen_loss = 0.8527284366885821, disc_loss = 0.06684390963210414
Trained batch 600 in epoch 13, gen_loss = 0.8526380942784213, disc_loss = 0.0667797328482774
Trained batch 601 in epoch 13, gen_loss = 0.8528511907373156, disc_loss = 0.06669185669826609
Trained batch 602 in epoch 13, gen_loss = 0.8527760483929965, disc_loss = 0.0666327117872772
Trained batch 603 in epoch 13, gen_loss = 0.8530306900968615, disc_loss = 0.0665508289883123
Trained batch 604 in epoch 13, gen_loss = 0.8531918188757147, disc_loss = 0.06655213290071192
Trained batch 605 in epoch 13, gen_loss = 0.8531343976263166, disc_loss = 0.06651472078064585
Trained batch 606 in epoch 13, gen_loss = 0.8533722131806111, disc_loss = 0.066426634868297
Trained batch 607 in epoch 13, gen_loss = 0.853904828723324, disc_loss = 0.06635828352974434
Trained batch 608 in epoch 13, gen_loss = 0.8537765264706855, disc_loss = 0.06634431618628243
Trained batch 609 in epoch 13, gen_loss = 0.8539205036202415, disc_loss = 0.06628433598480264
Trained batch 610 in epoch 13, gen_loss = 0.8540460869255315, disc_loss = 0.066238899552149
Trained batch 611 in epoch 13, gen_loss = 0.8538008767600153, disc_loss = 0.06620475859837789
Trained batch 612 in epoch 13, gen_loss = 0.8537614286237595, disc_loss = 0.06617935625972989
Trained batch 613 in epoch 13, gen_loss = 0.8539876900977342, disc_loss = 0.06610282609111809
Trained batch 614 in epoch 13, gen_loss = 0.8538224506184338, disc_loss = 0.0661288550381011
Trained batch 615 in epoch 13, gen_loss = 0.8536573251733532, disc_loss = 0.06611069065349345
Trained batch 616 in epoch 13, gen_loss = 0.853110617041781, disc_loss = 0.06639054756629699
Trained batch 617 in epoch 13, gen_loss = 0.8528113562891013, disc_loss = 0.06638364738281394
Trained batch 618 in epoch 13, gen_loss = 0.853018427703993, disc_loss = 0.06634223461452035
Trained batch 619 in epoch 13, gen_loss = 0.8530458440703731, disc_loss = 0.06628487526529259
Trained batch 620 in epoch 13, gen_loss = 0.8532264458192528, disc_loss = 0.06620505101222923
Trained batch 621 in epoch 13, gen_loss = 0.8531864085189782, disc_loss = 0.06612182156425389
Trained batch 622 in epoch 13, gen_loss = 0.8532424745169345, disc_loss = 0.06608245994172166
Trained batch 623 in epoch 13, gen_loss = 0.8531316408935266, disc_loss = 0.06601833374215624
Trained batch 624 in epoch 13, gen_loss = 0.8535031706809998, disc_loss = 0.06592887367755175
Trained batch 625 in epoch 13, gen_loss = 0.8531769898752816, disc_loss = 0.06593280393457689
Trained batch 626 in epoch 13, gen_loss = 0.8531845851758261, disc_loss = 0.06589879694007088
Trained batch 627 in epoch 13, gen_loss = 0.8532501908054777, disc_loss = 0.06583934426930538
Trained batch 628 in epoch 13, gen_loss = 0.853402978191315, disc_loss = 0.06586658421738018
Trained batch 629 in epoch 13, gen_loss = 0.8531323180312202, disc_loss = 0.06589116487385971
Trained batch 630 in epoch 13, gen_loss = 0.8534635500938126, disc_loss = 0.06581067150715508
Trained batch 631 in epoch 13, gen_loss = 0.8532386104328723, disc_loss = 0.06583249514415578
Trained batch 632 in epoch 13, gen_loss = 0.8531743616666085, disc_loss = 0.06576715204070248
Trained batch 633 in epoch 13, gen_loss = 0.8530188686088057, disc_loss = 0.06575550653968794
Trained batch 634 in epoch 13, gen_loss = 0.8533776855844213, disc_loss = 0.0657046223983286
Trained batch 635 in epoch 13, gen_loss = 0.853220635427619, disc_loss = 0.0656664089370027
Trained batch 636 in epoch 13, gen_loss = 0.8530005875337442, disc_loss = 0.06562440801160395
Trained batch 637 in epoch 13, gen_loss = 0.85325390941297, disc_loss = 0.06557776443485089
Trained batch 638 in epoch 13, gen_loss = 0.853540730774869, disc_loss = 0.06549094307217426
Trained batch 639 in epoch 13, gen_loss = 0.8533524729311466, disc_loss = 0.06544637954793871
Trained batch 640 in epoch 13, gen_loss = 0.8533708969256063, disc_loss = 0.06549725502543442
Trained batch 641 in epoch 13, gen_loss = 0.8534084348663734, disc_loss = 0.0654954880916998
Trained batch 642 in epoch 13, gen_loss = 0.8530383377015869, disc_loss = 0.06561804196651022
Trained batch 643 in epoch 13, gen_loss = 0.8532177593026843, disc_loss = 0.06557102367767821
Trained batch 644 in epoch 13, gen_loss = 0.8533219837403112, disc_loss = 0.06549856234197468
Trained batch 645 in epoch 13, gen_loss = 0.8536654326015213, disc_loss = 0.06545749854515581
Trained batch 646 in epoch 13, gen_loss = 0.8535391874438644, disc_loss = 0.06541837204299533
Trained batch 647 in epoch 13, gen_loss = 0.8535773515885259, disc_loss = 0.065345536859959
Trained batch 648 in epoch 13, gen_loss = 0.8537350273095587, disc_loss = 0.06526128093472384
Trained batch 649 in epoch 13, gen_loss = 0.8538764068713555, disc_loss = 0.06527347326135406
Trained batch 650 in epoch 13, gen_loss = 0.8538063601597846, disc_loss = 0.0652539644908223
Trained batch 651 in epoch 13, gen_loss = 0.85364410098345, disc_loss = 0.06521387873474577
Trained batch 652 in epoch 13, gen_loss = 0.8535728335015441, disc_loss = 0.06531867473764177
Trained batch 653 in epoch 13, gen_loss = 0.8537368332391849, disc_loss = 0.06525233406032399
Trained batch 654 in epoch 13, gen_loss = 0.8532914321841174, disc_loss = 0.06536509232979466
Trained batch 655 in epoch 13, gen_loss = 0.8533947945731443, disc_loss = 0.06531103522511109
Trained batch 656 in epoch 13, gen_loss = 0.853791534447053, disc_loss = 0.06545914924325055
Trained batch 657 in epoch 13, gen_loss = 0.8534679936420592, disc_loss = 0.06554236378956665
Trained batch 658 in epoch 13, gen_loss = 0.8529040747871891, disc_loss = 0.06576886592639189
Trained batch 659 in epoch 13, gen_loss = 0.8532492731105198, disc_loss = 0.06577263961433236
Trained batch 660 in epoch 13, gen_loss = 0.853265312679236, disc_loss = 0.06580090828651335
Trained batch 661 in epoch 13, gen_loss = 0.8530415270893955, disc_loss = 0.0658397861992732
Trained batch 662 in epoch 13, gen_loss = 0.8525691892316798, disc_loss = 0.06590675282099623
Trained batch 663 in epoch 13, gen_loss = 0.8531533955899347, disc_loss = 0.06589944207765926
Trained batch 664 in epoch 13, gen_loss = 0.8530234034348251, disc_loss = 0.06586142294809111
Trained batch 665 in epoch 13, gen_loss = 0.8528341190503524, disc_loss = 0.06582538263771583
Trained batch 666 in epoch 13, gen_loss = 0.8529723846483445, disc_loss = 0.06601181055937169
Trained batch 667 in epoch 13, gen_loss = 0.8528327580965208, disc_loss = 0.06601732123146827
Trained batch 668 in epoch 13, gen_loss = 0.8527922146968956, disc_loss = 0.06601486059242612
Trained batch 669 in epoch 13, gen_loss = 0.8525262631142317, disc_loss = 0.06613804675054862
Trained batch 670 in epoch 13, gen_loss = 0.8527829863364224, disc_loss = 0.06619463157430625
Trained batch 671 in epoch 13, gen_loss = 0.8525685944284002, disc_loss = 0.0662114866829056
Trained batch 672 in epoch 13, gen_loss = 0.8525284754131737, disc_loss = 0.06620677159116624
Trained batch 673 in epoch 13, gen_loss = 0.8526548932054984, disc_loss = 0.06618817919832087
Trained batch 674 in epoch 13, gen_loss = 0.8526011946024719, disc_loss = 0.06618269112788969
Trained batch 675 in epoch 13, gen_loss = 0.8522325431894974, disc_loss = 0.06627104705138981
Trained batch 676 in epoch 13, gen_loss = 0.8527213793297462, disc_loss = 0.06633359922764705
Trained batch 677 in epoch 13, gen_loss = 0.8526439151141496, disc_loss = 0.0662926665402861
Trained batch 678 in epoch 13, gen_loss = 0.8527616416495046, disc_loss = 0.066216434730664
Trained batch 679 in epoch 13, gen_loss = 0.8531646766645067, disc_loss = 0.06617255612029968
Trained batch 680 in epoch 13, gen_loss = 0.8527092487714014, disc_loss = 0.06625429671203031
Trained batch 681 in epoch 13, gen_loss = 0.8526274884813342, disc_loss = 0.06622683340028103
Trained batch 682 in epoch 13, gen_loss = 0.8529266691050802, disc_loss = 0.06616319464942329
Trained batch 683 in epoch 13, gen_loss = 0.8528051438648798, disc_loss = 0.066102366844105
Trained batch 684 in epoch 13, gen_loss = 0.8528233005617657, disc_loss = 0.06604663347757428
Trained batch 685 in epoch 13, gen_loss = 0.8524426031998921, disc_loss = 0.06608271521567734
Trained batch 686 in epoch 13, gen_loss = 0.8524565200010935, disc_loss = 0.06601045556295951
Trained batch 687 in epoch 13, gen_loss = 0.853157940428964, disc_loss = 0.06605453204585586
Trained batch 688 in epoch 13, gen_loss = 0.8529521103607726, disc_loss = 0.06602737824574481
Trained batch 689 in epoch 13, gen_loss = 0.8529521157344182, disc_loss = 0.06609640825620812
Trained batch 690 in epoch 13, gen_loss = 0.8530788723104424, disc_loss = 0.06602052367237085
Trained batch 691 in epoch 13, gen_loss = 0.8530455451738628, disc_loss = 0.0659970741791683
Trained batch 692 in epoch 13, gen_loss = 0.8529954812829457, disc_loss = 0.06596263568891376
Trained batch 693 in epoch 13, gen_loss = 0.8527392913783318, disc_loss = 0.06595343525685177
Trained batch 694 in epoch 13, gen_loss = 0.852982950939549, disc_loss = 0.06602343309456281
Trained batch 695 in epoch 13, gen_loss = 0.8527466995191986, disc_loss = 0.06605848963720318
Trained batch 696 in epoch 13, gen_loss = 0.8524696007264054, disc_loss = 0.0660818022751975
Trained batch 697 in epoch 13, gen_loss = 0.8524817743666876, disc_loss = 0.0661062640111285
Trained batch 698 in epoch 13, gen_loss = 0.8526960046420964, disc_loss = 0.06620468834924041
Trained batch 699 in epoch 13, gen_loss = 0.8521944415143557, disc_loss = 0.06631548626481422
Trained batch 700 in epoch 13, gen_loss = 0.8526919994731772, disc_loss = 0.06635919023443348
Trained batch 701 in epoch 13, gen_loss = 0.8522212233213957, disc_loss = 0.06656752993084723
Trained batch 702 in epoch 13, gen_loss = 0.8526475429110981, disc_loss = 0.0668279622240286
Trained batch 703 in epoch 13, gen_loss = 0.852443272374909, disc_loss = 0.06681355522728567
Trained batch 704 in epoch 13, gen_loss = 0.8521984639319967, disc_loss = 0.06681209411472082
Trained batch 705 in epoch 13, gen_loss = 0.8522548872671452, disc_loss = 0.06686830969010256
Trained batch 706 in epoch 13, gen_loss = 0.8517558485733232, disc_loss = 0.06696573977755142
Trained batch 707 in epoch 13, gen_loss = 0.8515400343106292, disc_loss = 0.06694288692689675
Trained batch 708 in epoch 13, gen_loss = 0.8520216617749004, disc_loss = 0.06695965117261297
Trained batch 709 in epoch 13, gen_loss = 0.8519023514549497, disc_loss = 0.06693027866217242
Trained batch 710 in epoch 13, gen_loss = 0.8515996261068872, disc_loss = 0.06699993299862629
Trained batch 711 in epoch 13, gen_loss = 0.8515752072163513, disc_loss = 0.06698397827319005
Trained batch 712 in epoch 13, gen_loss = 0.851429432463345, disc_loss = 0.06699578238188761
Trained batch 713 in epoch 13, gen_loss = 0.8514694653722752, disc_loss = 0.06694398334521164
Trained batch 714 in epoch 13, gen_loss = 0.8516352709773537, disc_loss = 0.0670386553474969
Trained batch 715 in epoch 13, gen_loss = 0.8512923324158072, disc_loss = 0.06704911970866417
Trained batch 716 in epoch 13, gen_loss = 0.8510638604686184, disc_loss = 0.06706341873916746
Trained batch 717 in epoch 13, gen_loss = 0.8511218685542641, disc_loss = 0.06706216340251578
Trained batch 718 in epoch 13, gen_loss = 0.8507277115412647, disc_loss = 0.06709294418398917
Trained batch 719 in epoch 13, gen_loss = 0.8505443211644887, disc_loss = 0.06711165933326507
Trained batch 720 in epoch 13, gen_loss = 0.8507362139125803, disc_loss = 0.06703845705919681
Trained batch 721 in epoch 13, gen_loss = 0.8504734582105171, disc_loss = 0.06705599698080704
Trained batch 722 in epoch 13, gen_loss = 0.8504277930632337, disc_loss = 0.06701194744217075
Trained batch 723 in epoch 13, gen_loss = 0.8503567169302076, disc_loss = 0.06697309917502764
Trained batch 724 in epoch 13, gen_loss = 0.8506673659538401, disc_loss = 0.06690490713278795
Trained batch 725 in epoch 13, gen_loss = 0.8503834177886159, disc_loss = 0.06695666694603142
Trained batch 726 in epoch 13, gen_loss = 0.8501773142503085, disc_loss = 0.06696093374379031
Trained batch 727 in epoch 13, gen_loss = 0.8505222841196662, disc_loss = 0.06691859106169912
Trained batch 728 in epoch 13, gen_loss = 0.8503914537989063, disc_loss = 0.06687089898821544
Trained batch 729 in epoch 13, gen_loss = 0.8506916814879195, disc_loss = 0.06682216834200368
Trained batch 730 in epoch 13, gen_loss = 0.8505262175190139, disc_loss = 0.06676842427332204
Trained batch 731 in epoch 13, gen_loss = 0.8502935778166427, disc_loss = 0.0667705180675626
Trained batch 732 in epoch 13, gen_loss = 0.8503049692141571, disc_loss = 0.0669103341868292
Trained batch 733 in epoch 13, gen_loss = 0.849997725774222, disc_loss = 0.06700041267021029
Trained batch 734 in epoch 13, gen_loss = 0.8500112939448584, disc_loss = 0.0669906154186243
Trained batch 735 in epoch 13, gen_loss = 0.8501315582138689, disc_loss = 0.06694192308603543
Trained batch 736 in epoch 13, gen_loss = 0.8499653902678186, disc_loss = 0.06694781075495837
Trained batch 737 in epoch 13, gen_loss = 0.8504261030818066, disc_loss = 0.06701446139710504
Trained batch 738 in epoch 13, gen_loss = 0.8501277469572421, disc_loss = 0.06705486626113502
Trained batch 739 in epoch 13, gen_loss = 0.8503840355856999, disc_loss = 0.06698594999852012
Trained batch 740 in epoch 13, gen_loss = 0.8502008511550353, disc_loss = 0.06698076501765192
Trained batch 741 in epoch 13, gen_loss = 0.8502826494267687, disc_loss = 0.06693614508098147
Trained batch 742 in epoch 13, gen_loss = 0.8506037326953292, disc_loss = 0.06701431367145212
Trained batch 743 in epoch 13, gen_loss = 0.8503047315584075, disc_loss = 0.06700750126788814
Trained batch 744 in epoch 13, gen_loss = 0.8500097659210231, disc_loss = 0.06706496901035108
Trained batch 745 in epoch 13, gen_loss = 0.8504354300591646, disc_loss = 0.06710430452270538
Trained batch 746 in epoch 13, gen_loss = 0.8504416637391929, disc_loss = 0.06704736991824116
Trained batch 747 in epoch 13, gen_loss = 0.8504163033582948, disc_loss = 0.06697584033375954
Trained batch 748 in epoch 13, gen_loss = 0.8503862400159976, disc_loss = 0.06694372393345045
Trained batch 749 in epoch 13, gen_loss = 0.8499775605599086, disc_loss = 0.06705340994521976
Trained batch 750 in epoch 13, gen_loss = 0.8502124175330136, disc_loss = 0.06730808562831023
Trained batch 751 in epoch 13, gen_loss = 0.8503077686863377, disc_loss = 0.06725275264978607
Trained batch 752 in epoch 13, gen_loss = 0.8500331049342238, disc_loss = 0.06725825619813337
Trained batch 753 in epoch 13, gen_loss = 0.8501614933383876, disc_loss = 0.06720886957419132
Trained batch 754 in epoch 13, gen_loss = 0.8500951093158975, disc_loss = 0.06713951063397902
Trained batch 755 in epoch 13, gen_loss = 0.8497830885191443, disc_loss = 0.06711206380795273
Trained batch 756 in epoch 13, gen_loss = 0.8500243147030532, disc_loss = 0.06721600014814809
Trained batch 757 in epoch 13, gen_loss = 0.8498674631511944, disc_loss = 0.06719753783722077
Trained batch 758 in epoch 13, gen_loss = 0.8499586957952251, disc_loss = 0.06714304425779422
Trained batch 759 in epoch 13, gen_loss = 0.8500727423319691, disc_loss = 0.06707886074743184
Trained batch 760 in epoch 13, gen_loss = 0.8503483556181624, disc_loss = 0.06707796313079091
Trained batch 761 in epoch 13, gen_loss = 0.850226751814677, disc_loss = 0.06706228830883391
Trained batch 762 in epoch 13, gen_loss = 0.8501134558164589, disc_loss = 0.06703365727072658
Trained batch 763 in epoch 13, gen_loss = 0.8499732913537176, disc_loss = 0.0669959056842097
Trained batch 764 in epoch 13, gen_loss = 0.8500492403320238, disc_loss = 0.067052945398476
Trained batch 765 in epoch 13, gen_loss = 0.8497296656158512, disc_loss = 0.06705421768736784
Trained batch 766 in epoch 13, gen_loss = 0.8496165896099269, disc_loss = 0.06710247914130754
Trained batch 767 in epoch 13, gen_loss = 0.8494947329551602, disc_loss = 0.06704583381482128
Trained batch 768 in epoch 13, gen_loss = 0.8495401797043487, disc_loss = 0.06697010514974323
Trained batch 769 in epoch 13, gen_loss = 0.8495140012595561, disc_loss = 0.06707860310380528
Trained batch 770 in epoch 13, gen_loss = 0.8492092894904808, disc_loss = 0.06713020632070056
Trained batch 771 in epoch 13, gen_loss = 0.8487262215098569, disc_loss = 0.06724677857016383
Trained batch 772 in epoch 13, gen_loss = 0.8487729368897644, disc_loss = 0.06725841306299357
Trained batch 773 in epoch 13, gen_loss = 0.8493636202365545, disc_loss = 0.06732984238186278
Trained batch 774 in epoch 13, gen_loss = 0.8491919152582845, disc_loss = 0.06731674912595942
Trained batch 775 in epoch 13, gen_loss = 0.8490288693496247, disc_loss = 0.06730619052391422
Trained batch 776 in epoch 13, gen_loss = 0.8493171980558982, disc_loss = 0.06724967117010204
Trained batch 777 in epoch 13, gen_loss = 0.8493219651952194, disc_loss = 0.06721822031986706
Trained batch 778 in epoch 13, gen_loss = 0.849408679848611, disc_loss = 0.06723334647318174
Trained batch 779 in epoch 13, gen_loss = 0.8498913583465112, disc_loss = 0.06726957996471379
Trained batch 780 in epoch 13, gen_loss = 0.8497493378102551, disc_loss = 0.06733188043955461
Trained batch 781 in epoch 13, gen_loss = 0.8494916957281434, disc_loss = 0.06736023966437373
Trained batch 782 in epoch 13, gen_loss = 0.8495757078530688, disc_loss = 0.0673255587120375
Trained batch 783 in epoch 13, gen_loss = 0.8499572764778015, disc_loss = 0.06727243749287018
Trained batch 784 in epoch 13, gen_loss = 0.8498187455781706, disc_loss = 0.06723745962972663
Trained batch 785 in epoch 13, gen_loss = 0.8498131966090384, disc_loss = 0.06717876069432566
Trained batch 786 in epoch 13, gen_loss = 0.8496426221603359, disc_loss = 0.06718163424570307
Trained batch 787 in epoch 13, gen_loss = 0.849323046578066, disc_loss = 0.06725315516460025
Trained batch 788 in epoch 13, gen_loss = 0.8496113210652113, disc_loss = 0.0676478324033065
Trained batch 789 in epoch 13, gen_loss = 0.8494398159694068, disc_loss = 0.06768504735200277
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.767989993095398, disc_loss = 0.04772420972585678
Trained batch 1 in epoch 14, gen_loss = 0.9115701913833618, disc_loss = 0.06870633736252785
Trained batch 2 in epoch 14, gen_loss = 0.865866482257843, disc_loss = 0.0695162018140157
Trained batch 3 in epoch 14, gen_loss = 0.7716238275170326, disc_loss = 0.1150321215391159
Trained batch 4 in epoch 14, gen_loss = 0.8823720276355743, disc_loss = 0.14468655586242676
Trained batch 5 in epoch 14, gen_loss = 0.8256766448418299, disc_loss = 0.14947342624266943
Trained batch 6 in epoch 14, gen_loss = 0.822345073734011, disc_loss = 0.13698696398309299
Trained batch 7 in epoch 14, gen_loss = 0.8407739065587521, disc_loss = 0.12201724131591618
Trained batch 8 in epoch 14, gen_loss = 0.8461174468199412, disc_loss = 0.11018374852008289
Trained batch 9 in epoch 14, gen_loss = 0.8247765809297561, disc_loss = 0.10473605543375016
Trained batch 10 in epoch 14, gen_loss = 0.8396075015718286, disc_loss = 0.10466987571933052
Trained batch 11 in epoch 14, gen_loss = 0.8114629114667574, disc_loss = 0.10636206964651744
Trained batch 12 in epoch 14, gen_loss = 0.8134477482392237, disc_loss = 0.10006801640758148
Trained batch 13 in epoch 14, gen_loss = 0.8126143451247897, disc_loss = 0.09634352502013956
Trained batch 14 in epoch 14, gen_loss = 0.8206616302331289, disc_loss = 0.10629378780722618
Trained batch 15 in epoch 14, gen_loss = 0.8048671688884497, disc_loss = 0.10307505424134433
Trained batch 16 in epoch 14, gen_loss = 0.7910270427956301, disc_loss = 0.10326851356555433
Trained batch 17 in epoch 14, gen_loss = 0.7907339682181677, disc_loss = 0.09821915564437707
Trained batch 18 in epoch 14, gen_loss = 0.8038252105838374, disc_loss = 0.09505910877334445
Trained batch 19 in epoch 14, gen_loss = 0.8009469375014305, disc_loss = 0.09421587456017733
Trained batch 20 in epoch 14, gen_loss = 0.798147569100062, disc_loss = 0.0934490520684492
Trained batch 21 in epoch 14, gen_loss = 0.8061347048390995, disc_loss = 0.09012640690938993
Trained batch 22 in epoch 14, gen_loss = 0.8019892249418341, disc_loss = 0.0892921535541182
Trained batch 23 in epoch 14, gen_loss = 0.8031208924949169, disc_loss = 0.08679888917443652
Trained batch 24 in epoch 14, gen_loss = 0.7994786465167999, disc_loss = 0.08559965260326863
Trained batch 25 in epoch 14, gen_loss = 0.7974500277867684, disc_loss = 0.0838906943368224
Trained batch 26 in epoch 14, gen_loss = 0.798951346565176, disc_loss = 0.08127675943628505
Trained batch 27 in epoch 14, gen_loss = 0.8011062688061169, disc_loss = 0.07901359282966171
Trained batch 28 in epoch 14, gen_loss = 0.8010746353659136, disc_loss = 0.07750839007825687
Trained batch 29 in epoch 14, gen_loss = 0.8075297842423121, disc_loss = 0.07709932513535023
Trained batch 30 in epoch 14, gen_loss = 0.8081888489184841, disc_loss = 0.07543917000293732
Trained batch 31 in epoch 14, gen_loss = 0.8034426951780915, disc_loss = 0.07469986518844962
Trained batch 32 in epoch 14, gen_loss = 0.797160265120593, disc_loss = 0.07524101481293187
Trained batch 33 in epoch 14, gen_loss = 0.8085297845742282, disc_loss = 0.07567850544172175
Trained batch 34 in epoch 14, gen_loss = 0.8077725946903229, disc_loss = 0.07403687941176551
Trained batch 35 in epoch 14, gen_loss = 0.8052362261546983, disc_loss = 0.07326306288854943
Trained batch 36 in epoch 14, gen_loss = 0.8070713821295146, disc_loss = 0.07187119186729998
Trained batch 37 in epoch 14, gen_loss = 0.8121943999277917, disc_loss = 0.07038794901516092
Trained batch 38 in epoch 14, gen_loss = 0.8130952601249402, disc_loss = 0.06919645740149113
Trained batch 39 in epoch 14, gen_loss = 0.8183443330228328, disc_loss = 0.0681424858281389
Trained batch 40 in epoch 14, gen_loss = 0.8175478395892353, disc_loss = 0.06710290820224256
Trained batch 41 in epoch 14, gen_loss = 0.8211308526141303, disc_loss = 0.06580678899107235
Trained batch 42 in epoch 14, gen_loss = 0.8272771481857744, disc_loss = 0.0650168277193294
Trained batch 43 in epoch 14, gen_loss = 0.8216690048575401, disc_loss = 0.06696130176582797
Trained batch 44 in epoch 14, gen_loss = 0.8228595077991485, disc_loss = 0.06614832772562901
Trained batch 45 in epoch 14, gen_loss = 0.82455496619577, disc_loss = 0.06620785944244784
Trained batch 46 in epoch 14, gen_loss = 0.8288945841028336, disc_loss = 0.06624776768953876
Trained batch 47 in epoch 14, gen_loss = 0.8239128856609265, disc_loss = 0.06769722585643952
Trained batch 48 in epoch 14, gen_loss = 0.8251913402761731, disc_loss = 0.06713931150354292
Trained batch 49 in epoch 14, gen_loss = 0.8246034008264541, disc_loss = 0.06818727353587746
Trained batch 50 in epoch 14, gen_loss = 0.8339134343698913, disc_loss = 0.06834376977720097
Trained batch 51 in epoch 14, gen_loss = 0.8316486896230624, disc_loss = 0.06879765778565063
Trained batch 52 in epoch 14, gen_loss = 0.8280695030149424, disc_loss = 0.06945347485466385
Trained batch 53 in epoch 14, gen_loss = 0.8319035045526646, disc_loss = 0.06988332029087124
Trained batch 54 in epoch 14, gen_loss = 0.8351851707155055, disc_loss = 0.0699423154138706
Trained batch 55 in epoch 14, gen_loss = 0.8312809249120099, disc_loss = 0.07051514975527036
Trained batch 56 in epoch 14, gen_loss = 0.8289750830123299, disc_loss = 0.0710558378415411
Trained batch 57 in epoch 14, gen_loss = 0.8311793254367237, disc_loss = 0.07015310968111815
Trained batch 58 in epoch 14, gen_loss = 0.8365433301966069, disc_loss = 0.06928693422637248
Trained batch 59 in epoch 14, gen_loss = 0.837458569308122, disc_loss = 0.06865606141897539
Trained batch 60 in epoch 14, gen_loss = 0.8415966273331251, disc_loss = 0.06784695052526525
Trained batch 61 in epoch 14, gen_loss = 0.8429137463531187, disc_loss = 0.0669435861280128
Trained batch 62 in epoch 14, gen_loss = 0.8430714782268282, disc_loss = 0.0663240220368145
Trained batch 63 in epoch 14, gen_loss = 0.8427782603539526, disc_loss = 0.06601834403409157
Trained batch 64 in epoch 14, gen_loss = 0.8468741018038529, disc_loss = 0.06534917765798477
Trained batch 65 in epoch 14, gen_loss = 0.845884538509629, disc_loss = 0.06505906811887116
Trained batch 66 in epoch 14, gen_loss = 0.848058872703296, disc_loss = 0.06428262239683476
Trained batch 67 in epoch 14, gen_loss = 0.850024811046965, disc_loss = 0.06355552101398215
Trained batch 68 in epoch 14, gen_loss = 0.8551838246808536, disc_loss = 0.06301886680117552
Trained batch 69 in epoch 14, gen_loss = 0.8547847087894167, disc_loss = 0.0624803685184036
Trained batch 70 in epoch 14, gen_loss = 0.8532352560842541, disc_loss = 0.06233254909305505
Trained batch 71 in epoch 14, gen_loss = 0.8548599378102355, disc_loss = 0.06224262709211972
Trained batch 72 in epoch 14, gen_loss = 0.8558615001097117, disc_loss = 0.061724750911944536
Trained batch 73 in epoch 14, gen_loss = 0.8546629608482927, disc_loss = 0.06166948383120266
Trained batch 74 in epoch 14, gen_loss = 0.8577745449543, disc_loss = 0.06102588397761186
Trained batch 75 in epoch 14, gen_loss = 0.8588281018953574, disc_loss = 0.0605525758950726
Trained batch 76 in epoch 14, gen_loss = 0.8633065653311742, disc_loss = 0.060506078305763086
Trained batch 77 in epoch 14, gen_loss = 0.8627505459082432, disc_loss = 0.06063157709267659
Trained batch 78 in epoch 14, gen_loss = 0.8642328951177718, disc_loss = 0.059994790879891645
Trained batch 79 in epoch 14, gen_loss = 0.8646119501441717, disc_loss = 0.05951125608989969
Trained batch 80 in epoch 14, gen_loss = 0.8658210609430148, disc_loss = 0.05992276999915456
Trained batch 81 in epoch 14, gen_loss = 0.864406646388333, disc_loss = 0.059678178246519185
Trained batch 82 in epoch 14, gen_loss = 0.8619665894881788, disc_loss = 0.05974936526807317
Trained batch 83 in epoch 14, gen_loss = 0.8670704261887641, disc_loss = 0.059991057662825496
Trained batch 84 in epoch 14, gen_loss = 0.8713867871200337, disc_loss = 0.06049151987056522
Trained batch 85 in epoch 14, gen_loss = 0.8702257147362066, disc_loss = 0.060515845032018976
Trained batch 86 in epoch 14, gen_loss = 0.8707353359666364, disc_loss = 0.06005215333325082
Trained batch 87 in epoch 14, gen_loss = 0.8704153383997354, disc_loss = 0.0598741673800925
Trained batch 88 in epoch 14, gen_loss = 0.8698896039068029, disc_loss = 0.06106878939513745
Trained batch 89 in epoch 14, gen_loss = 0.8698237521780862, disc_loss = 0.06055895127356052
Trained batch 90 in epoch 14, gen_loss = 0.8679032440368946, disc_loss = 0.06040492739814978
Trained batch 91 in epoch 14, gen_loss = 0.8688729292024737, disc_loss = 0.060943198228335896
Trained batch 92 in epoch 14, gen_loss = 0.8706543000154597, disc_loss = 0.06115094071594618
Trained batch 93 in epoch 14, gen_loss = 0.8697773513007672, disc_loss = 0.060962118961392565
Trained batch 94 in epoch 14, gen_loss = 0.8688087203000722, disc_loss = 0.06062275481067206
Trained batch 95 in epoch 14, gen_loss = 0.8666865567987164, disc_loss = 0.06051808064027379
Trained batch 96 in epoch 14, gen_loss = 0.8710077414193105, disc_loss = 0.060332054982787556
Trained batch 97 in epoch 14, gen_loss = 0.8707408932398777, disc_loss = 0.059975441868359944
Trained batch 98 in epoch 14, gen_loss = 0.8714354149620942, disc_loss = 0.05982154876821571
Trained batch 99 in epoch 14, gen_loss = 0.8707952263951302, disc_loss = 0.05940961120650172
Trained batch 100 in epoch 14, gen_loss = 0.8690138208394004, disc_loss = 0.059941839887806686
Trained batch 101 in epoch 14, gen_loss = 0.8728921907205208, disc_loss = 0.059733468801805786
Trained batch 102 in epoch 14, gen_loss = 0.8751937281159521, disc_loss = 0.06251385864051222
Trained batch 103 in epoch 14, gen_loss = 0.8731037770899442, disc_loss = 0.06274682890552168
Trained batch 104 in epoch 14, gen_loss = 0.8708899761949267, disc_loss = 0.06435696644087632
Trained batch 105 in epoch 14, gen_loss = 0.869274727859587, disc_loss = 0.06562519416142747
Trained batch 106 in epoch 14, gen_loss = 0.8690417907505392, disc_loss = 0.06540223160567128
Trained batch 107 in epoch 14, gen_loss = 0.8685750655002065, disc_loss = 0.06521024380776065
Trained batch 108 in epoch 14, gen_loss = 0.8681013154874154, disc_loss = 0.06488988666427792
Trained batch 109 in epoch 14, gen_loss = 0.868833512338725, disc_loss = 0.06470670552754944
Trained batch 110 in epoch 14, gen_loss = 0.8680944117876861, disc_loss = 0.06456468131829489
Trained batch 111 in epoch 14, gen_loss = 0.8688011539301702, disc_loss = 0.0648034115687811
Trained batch 112 in epoch 14, gen_loss = 0.8710820144784134, disc_loss = 0.06483645709149077
Trained batch 113 in epoch 14, gen_loss = 0.8694906336696524, disc_loss = 0.06560681980887526
Trained batch 114 in epoch 14, gen_loss = 0.8696267172046329, disc_loss = 0.06549103067297002
Trained batch 115 in epoch 14, gen_loss = 0.8675671479311483, disc_loss = 0.06552012356255076
Trained batch 116 in epoch 14, gen_loss = 0.8693988234059423, disc_loss = 0.06514173777949096
Trained batch 117 in epoch 14, gen_loss = 0.8699060903262283, disc_loss = 0.06574183809807745
Trained batch 118 in epoch 14, gen_loss = 0.8678301965989986, disc_loss = 0.06612251041566625
Trained batch 119 in epoch 14, gen_loss = 0.8707886092364788, disc_loss = 0.06601228155195712
Trained batch 120 in epoch 14, gen_loss = 0.8736082692284229, disc_loss = 0.06577741166900013
Trained batch 121 in epoch 14, gen_loss = 0.8719170608969985, disc_loss = 0.06588997817063919
Trained batch 122 in epoch 14, gen_loss = 0.870187187824792, disc_loss = 0.06606929364606617
Trained batch 123 in epoch 14, gen_loss = 0.8717794843739078, disc_loss = 0.06626952839114013
Trained batch 124 in epoch 14, gen_loss = 0.8717280094623565, disc_loss = 0.06606726190447808
Trained batch 125 in epoch 14, gen_loss = 0.8726256104215743, disc_loss = 0.0657509435559549
Trained batch 126 in epoch 14, gen_loss = 0.8724966464549537, disc_loss = 0.06557701824335602
Trained batch 127 in epoch 14, gen_loss = 0.8706053358037025, disc_loss = 0.0657123395067174
Trained batch 128 in epoch 14, gen_loss = 0.8703378117823786, disc_loss = 0.06555129680060601
Trained batch 129 in epoch 14, gen_loss = 0.870019818498538, disc_loss = 0.06530414848373486
Trained batch 130 in epoch 14, gen_loss = 0.8723457362360627, disc_loss = 0.06545525180701992
Trained batch 131 in epoch 14, gen_loss = 0.8724957124301882, disc_loss = 0.06518719710804748
Trained batch 132 in epoch 14, gen_loss = 0.8723718167695784, disc_loss = 0.06495972158373299
Trained batch 133 in epoch 14, gen_loss = 0.87085282068644, disc_loss = 0.06493912655304172
Trained batch 134 in epoch 14, gen_loss = 0.8719456926540092, disc_loss = 0.06497223588327566
Trained batch 135 in epoch 14, gen_loss = 0.8707036251092658, disc_loss = 0.06500167751630001
Trained batch 136 in epoch 14, gen_loss = 0.8708054808369519, disc_loss = 0.06483998183623282
Trained batch 137 in epoch 14, gen_loss = 0.8698612004518509, disc_loss = 0.06488752209891875
Trained batch 138 in epoch 14, gen_loss = 0.8701334464893067, disc_loss = 0.0645811009964497
Trained batch 139 in epoch 14, gen_loss = 0.8706323310732842, disc_loss = 0.06420641418413392
Trained batch 140 in epoch 14, gen_loss = 0.8712918904233486, disc_loss = 0.06404196985515086
Trained batch 141 in epoch 14, gen_loss = 0.871599865421443, disc_loss = 0.06383201466138724
Trained batch 142 in epoch 14, gen_loss = 0.8690699011712641, disc_loss = 0.06429391460480181
Trained batch 143 in epoch 14, gen_loss = 0.8679081166370047, disc_loss = 0.06424361645218192
Trained batch 144 in epoch 14, gen_loss = 0.8673047055458201, disc_loss = 0.0641156561865375
Trained batch 145 in epoch 14, gen_loss = 0.8680596435314989, disc_loss = 0.06456007016822696
Trained batch 146 in epoch 14, gen_loss = 0.8658910310592781, disc_loss = 0.06476678789853035
Trained batch 147 in epoch 14, gen_loss = 0.8688594072654441, disc_loss = 0.06531702650937478
Trained batch 148 in epoch 14, gen_loss = 0.8676264296042039, disc_loss = 0.0652676235896929
Trained batch 149 in epoch 14, gen_loss = 0.8654202876488367, disc_loss = 0.0661256994990011
Trained batch 150 in epoch 14, gen_loss = 0.8653156735644435, disc_loss = 0.0660229374821119
Trained batch 151 in epoch 14, gen_loss = 0.8663924973654119, disc_loss = 0.06581714300218185
Trained batch 152 in epoch 14, gen_loss = 0.8654964794130886, disc_loss = 0.06636744739451245
Trained batch 153 in epoch 14, gen_loss = 0.8642694069580599, disc_loss = 0.06622885846738498
Trained batch 154 in epoch 14, gen_loss = 0.8637360782392564, disc_loss = 0.06594279890940075
Trained batch 155 in epoch 14, gen_loss = 0.8651502707447761, disc_loss = 0.06603769635041364
Trained batch 156 in epoch 14, gen_loss = 0.8669938169846869, disc_loss = 0.06582652112457213
Trained batch 157 in epoch 14, gen_loss = 0.8650155710645869, disc_loss = 0.06676292338679675
Trained batch 158 in epoch 14, gen_loss = 0.8646325549614504, disc_loss = 0.06676410077104591
Trained batch 159 in epoch 14, gen_loss = 0.8641858192160725, disc_loss = 0.0668806166795548
Trained batch 160 in epoch 14, gen_loss = 0.8650759393754213, disc_loss = 0.06663602648985496
Trained batch 161 in epoch 14, gen_loss = 0.8652601781082742, disc_loss = 0.06632236587343576
Trained batch 162 in epoch 14, gen_loss = 0.8640191015656009, disc_loss = 0.06641761778619575
Trained batch 163 in epoch 14, gen_loss = 0.865605053560036, disc_loss = 0.06650056556525935
Trained batch 164 in epoch 14, gen_loss = 0.865888382991155, disc_loss = 0.0662228600263144
Trained batch 165 in epoch 14, gen_loss = 0.864799718361303, disc_loss = 0.06625256114583238
Trained batch 166 in epoch 14, gen_loss = 0.8650496400401978, disc_loss = 0.06605637764480121
Trained batch 167 in epoch 14, gen_loss = 0.8653998795364585, disc_loss = 0.06579341496052664
Trained batch 168 in epoch 14, gen_loss = 0.8649154430663092, disc_loss = 0.06563050315864163
Trained batch 169 in epoch 14, gen_loss = 0.8647807708557914, disc_loss = 0.06557285003911922
Trained batch 170 in epoch 14, gen_loss = 0.8645604198787644, disc_loss = 0.06540545782520932
Trained batch 171 in epoch 14, gen_loss = 0.8664140359953393, disc_loss = 0.06541284966975623
Trained batch 172 in epoch 14, gen_loss = 0.8648028502919082, disc_loss = 0.06548630851563174
Trained batch 173 in epoch 14, gen_loss = 0.8657683646199347, disc_loss = 0.0653001821128887
Trained batch 174 in epoch 14, gen_loss = 0.8658189983027322, disc_loss = 0.0650665030149477
Trained batch 175 in epoch 14, gen_loss = 0.8650617557154461, disc_loss = 0.06487022031797096
Trained batch 176 in epoch 14, gen_loss = 0.8655257034773207, disc_loss = 0.064807027920365
Trained batch 177 in epoch 14, gen_loss = 0.8643767313006219, disc_loss = 0.06463095833013734
Trained batch 178 in epoch 14, gen_loss = 0.8638326956906133, disc_loss = 0.06448074330851519
Trained batch 179 in epoch 14, gen_loss = 0.8642643195059564, disc_loss = 0.06429513513317539
Trained batch 180 in epoch 14, gen_loss = 0.8643019606066014, disc_loss = 0.06412187027770676
Trained batch 181 in epoch 14, gen_loss = 0.8644716155070525, disc_loss = 0.06392708309711172
Trained batch 182 in epoch 14, gen_loss = 0.8648985029895448, disc_loss = 0.06362900003546575
Trained batch 183 in epoch 14, gen_loss = 0.8643031368113082, disc_loss = 0.06353047109492448
Trained batch 184 in epoch 14, gen_loss = 0.8654580362745233, disc_loss = 0.06355768522700748
Trained batch 185 in epoch 14, gen_loss = 0.8664450249684754, disc_loss = 0.06334674699852864
Trained batch 186 in epoch 14, gen_loss = 0.8673555138595601, disc_loss = 0.06318172602291731
Trained batch 187 in epoch 14, gen_loss = 0.8666854137752918, disc_loss = 0.06318434760806725
Trained batch 188 in epoch 14, gen_loss = 0.8665590486513874, disc_loss = 0.0630210457990567
Trained batch 189 in epoch 14, gen_loss = 0.8671855670841117, disc_loss = 0.06299303351460318
Trained batch 190 in epoch 14, gen_loss = 0.8670869399427743, disc_loss = 0.06272339930572592
Trained batch 191 in epoch 14, gen_loss = 0.8661004393361509, disc_loss = 0.0628398543582686
Trained batch 192 in epoch 14, gen_loss = 0.8662509138411191, disc_loss = 0.06290534432552794
Trained batch 193 in epoch 14, gen_loss = 0.8653168461679184, disc_loss = 0.062968331365126
Trained batch 194 in epoch 14, gen_loss = 0.8652474958163041, disc_loss = 0.06284478011135107
Trained batch 195 in epoch 14, gen_loss = 0.8653180798401638, disc_loss = 0.0627719445809798
Trained batch 196 in epoch 14, gen_loss = 0.8655645280017465, disc_loss = 0.0626380099645499
Trained batch 197 in epoch 14, gen_loss = 0.864550683986057, disc_loss = 0.06267470910185666
Trained batch 198 in epoch 14, gen_loss = 0.8651762558287711, disc_loss = 0.062421673539108664
Trained batch 199 in epoch 14, gen_loss = 0.8653129701316357, disc_loss = 0.062217990080825986
Trained batch 200 in epoch 14, gen_loss = 0.8664023115563748, disc_loss = 0.06198082286493843
Trained batch 201 in epoch 14, gen_loss = 0.8661132326515595, disc_loss = 0.06185736928116715
Trained batch 202 in epoch 14, gen_loss = 0.8665478001968027, disc_loss = 0.06211275971159706
Trained batch 203 in epoch 14, gen_loss = 0.8655330680456816, disc_loss = 0.06210471341368176
Trained batch 204 in epoch 14, gen_loss = 0.8654221001194744, disc_loss = 0.06193569050420348
Trained batch 205 in epoch 14, gen_loss = 0.8655349590535303, disc_loss = 0.06170100187973201
Trained batch 206 in epoch 14, gen_loss = 0.8655986412999711, disc_loss = 0.061513909557159394
Trained batch 207 in epoch 14, gen_loss = 0.866020483036454, disc_loss = 0.06131963532131452
Trained batch 208 in epoch 14, gen_loss = 0.8674440265557413, disc_loss = 0.0611557324893737
Trained batch 209 in epoch 14, gen_loss = 0.866871789097786, disc_loss = 0.06104205965640999
Trained batch 210 in epoch 14, gen_loss = 0.8673156026697837, disc_loss = 0.06103612625556534
Trained batch 211 in epoch 14, gen_loss = 0.8682755913655713, disc_loss = 0.06102328222104401
Trained batch 212 in epoch 14, gen_loss = 0.8671687562980562, disc_loss = 0.06094288325785471
Trained batch 213 in epoch 14, gen_loss = 0.8667834945649744, disc_loss = 0.060788042173137734
Trained batch 214 in epoch 14, gen_loss = 0.8658490795035695, disc_loss = 0.06084655990260978
Trained batch 215 in epoch 14, gen_loss = 0.8648051149039356, disc_loss = 0.06101148702307708
Trained batch 216 in epoch 14, gen_loss = 0.8657974365944138, disc_loss = 0.06112415401033267
Trained batch 217 in epoch 14, gen_loss = 0.8655620784661092, disc_loss = 0.06111350994762204
Trained batch 218 in epoch 14, gen_loss = 0.8659796277954154, disc_loss = 0.06105750527862272
Trained batch 219 in epoch 14, gen_loss = 0.8647164489735256, disc_loss = 0.061271436791867015
Trained batch 220 in epoch 14, gen_loss = 0.8655513604571916, disc_loss = 0.061108464914546835
Trained batch 221 in epoch 14, gen_loss = 0.8654105796201809, disc_loss = 0.06106866977538343
Trained batch 222 in epoch 14, gen_loss = 0.8646743306931893, disc_loss = 0.061508921171317184
Trained batch 223 in epoch 14, gen_loss = 0.8639311227681381, disc_loss = 0.06158735025175182
Trained batch 224 in epoch 14, gen_loss = 0.8639439658323924, disc_loss = 0.061603144283096
Trained batch 225 in epoch 14, gen_loss = 0.8626931511459097, disc_loss = 0.061625505649212715
Trained batch 226 in epoch 14, gen_loss = 0.8635678156094404, disc_loss = 0.06165019617239546
Trained batch 227 in epoch 14, gen_loss = 0.8628198474384191, disc_loss = 0.061631142692803814
Trained batch 228 in epoch 14, gen_loss = 0.863492838810625, disc_loss = 0.06141968948693385
Trained batch 229 in epoch 14, gen_loss = 0.8639539307874182, disc_loss = 0.061233946369232045
Trained batch 230 in epoch 14, gen_loss = 0.8635724059173039, disc_loss = 0.06109867905754419
Trained batch 231 in epoch 14, gen_loss = 0.8626951021624023, disc_loss = 0.061173705155318926
Trained batch 232 in epoch 14, gen_loss = 0.8624438381246231, disc_loss = 0.061003048032873944
Trained batch 233 in epoch 14, gen_loss = 0.8624905491741295, disc_loss = 0.06082295209694749
Trained batch 234 in epoch 14, gen_loss = 0.8624344162484433, disc_loss = 0.06091881134804893
Trained batch 235 in epoch 14, gen_loss = 0.8613597246802459, disc_loss = 0.061141851062144516
Trained batch 236 in epoch 14, gen_loss = 0.8631006455371149, disc_loss = 0.061130164973123416
Trained batch 237 in epoch 14, gen_loss = 0.863969998825498, disc_loss = 0.061130900706845424
Trained batch 238 in epoch 14, gen_loss = 0.8629709525836562, disc_loss = 0.06142520155196534
Trained batch 239 in epoch 14, gen_loss = 0.8635878333201011, disc_loss = 0.06153709524078295
Trained batch 240 in epoch 14, gen_loss = 0.8635075397758563, disc_loss = 0.06144505713320496
Trained batch 241 in epoch 14, gen_loss = 0.8626986176760729, disc_loss = 0.061441636732817925
Trained batch 242 in epoch 14, gen_loss = 0.862810023895507, disc_loss = 0.06122890661696716
Trained batch 243 in epoch 14, gen_loss = 0.862577099902708, disc_loss = 0.06118334058412641
Trained batch 244 in epoch 14, gen_loss = 0.8626266067125359, disc_loss = 0.06100260732049236
Trained batch 245 in epoch 14, gen_loss = 0.8635617064508966, disc_loss = 0.06103127617464681
Trained batch 246 in epoch 14, gen_loss = 0.8626861563819622, disc_loss = 0.06109372219862605
Trained batch 247 in epoch 14, gen_loss = 0.8627880630233595, disc_loss = 0.06090393013155629
Trained batch 248 in epoch 14, gen_loss = 0.8634416885883454, disc_loss = 0.060852570792129
Trained batch 249 in epoch 14, gen_loss = 0.8635990878343582, disc_loss = 0.06068203603848815
Trained batch 250 in epoch 14, gen_loss = 0.8635526701986077, disc_loss = 0.06056356463076703
Trained batch 251 in epoch 14, gen_loss = 0.8627541120799761, disc_loss = 0.060691270626164855
Trained batch 252 in epoch 14, gen_loss = 0.8619415942623682, disc_loss = 0.060685308587557
Trained batch 253 in epoch 14, gen_loss = 0.8619304429593049, disc_loss = 0.06072118421136512
Trained batch 254 in epoch 14, gen_loss = 0.8625977772123673, disc_loss = 0.060599195230387
Trained batch 255 in epoch 14, gen_loss = 0.8611396315973252, disc_loss = 0.06087616048534983
Trained batch 256 in epoch 14, gen_loss = 0.8616972440411609, disc_loss = 0.06153624528359462
Trained batch 257 in epoch 14, gen_loss = 0.8618540163188018, disc_loss = 0.06138869148657419
Trained batch 258 in epoch 14, gen_loss = 0.8613206914493016, disc_loss = 0.06131010912862178
Trained batch 259 in epoch 14, gen_loss = 0.8606354431464122, disc_loss = 0.0615226173809228
Trained batch 260 in epoch 14, gen_loss = 0.8615122318724563, disc_loss = 0.061720913529424604
Trained batch 261 in epoch 14, gen_loss = 0.8604024639566437, disc_loss = 0.06189454175204835
Trained batch 262 in epoch 14, gen_loss = 0.8603423981158905, disc_loss = 0.061879188746582194
Trained batch 263 in epoch 14, gen_loss = 0.8609895640701959, disc_loss = 0.062044213148483046
Trained batch 264 in epoch 14, gen_loss = 0.860636763302785, disc_loss = 0.061924537204487144
Trained batch 265 in epoch 14, gen_loss = 0.8599740746326017, disc_loss = 0.06187421746229879
Trained batch 266 in epoch 14, gen_loss = 0.8593386023232107, disc_loss = 0.061859243305239564
Trained batch 267 in epoch 14, gen_loss = 0.8588795001382259, disc_loss = 0.061783736241536574
Trained batch 268 in epoch 14, gen_loss = 0.8600184640476695, disc_loss = 0.06259179716673594
Trained batch 269 in epoch 14, gen_loss = 0.859822502621898, disc_loss = 0.062448959021518625
Trained batch 270 in epoch 14, gen_loss = 0.8588540188940689, disc_loss = 0.06273144024090903
Trained batch 271 in epoch 14, gen_loss = 0.859428762074779, disc_loss = 0.0631673400365638
Trained batch 272 in epoch 14, gen_loss = 0.8586964124724978, disc_loss = 0.06331008773351654
Trained batch 273 in epoch 14, gen_loss = 0.8592118438142929, disc_loss = 0.06314945937113932
Trained batch 274 in epoch 14, gen_loss = 0.8585210990905762, disc_loss = 0.06316763876175338
Trained batch 275 in epoch 14, gen_loss = 0.859703849191251, disc_loss = 0.06320115768323666
Trained batch 276 in epoch 14, gen_loss = 0.8592953113872652, disc_loss = 0.06312634928710087
Trained batch 277 in epoch 14, gen_loss = 0.8580359068277071, disc_loss = 0.06328624927458897
Trained batch 278 in epoch 14, gen_loss = 0.8580319048256002, disc_loss = 0.06320856128048191
Trained batch 279 in epoch 14, gen_loss = 0.8582550185067314, disc_loss = 0.06305110902592008
Trained batch 280 in epoch 14, gen_loss = 0.8582846532937046, disc_loss = 0.06300235678544566
Trained batch 281 in epoch 14, gen_loss = 0.8579046022384724, disc_loss = 0.06308574571294036
Trained batch 282 in epoch 14, gen_loss = 0.857672469144154, disc_loss = 0.06308108395419673
Trained batch 283 in epoch 14, gen_loss = 0.8579745202417105, disc_loss = 0.06292496046746596
Trained batch 284 in epoch 14, gen_loss = 0.8573564895412378, disc_loss = 0.06293953047705847
Trained batch 285 in epoch 14, gen_loss = 0.8581201565432381, disc_loss = 0.06326118098259285
Trained batch 286 in epoch 14, gen_loss = 0.8580430307870127, disc_loss = 0.06312585282966962
Trained batch 287 in epoch 14, gen_loss = 0.8575635241965452, disc_loss = 0.0631341584020346
Trained batch 288 in epoch 14, gen_loss = 0.856780168506926, disc_loss = 0.0632938166281086
Trained batch 289 in epoch 14, gen_loss = 0.8572547074021964, disc_loss = 0.06324257778389186
Trained batch 290 in epoch 14, gen_loss = 0.8588153455675263, disc_loss = 0.06371212875809763
Trained batch 291 in epoch 14, gen_loss = 0.8584130659495315, disc_loss = 0.06366092485554312
Trained batch 292 in epoch 14, gen_loss = 0.8581789443110444, disc_loss = 0.06375052798666543
Trained batch 293 in epoch 14, gen_loss = 0.8581926790224451, disc_loss = 0.06388464287164158
Trained batch 294 in epoch 14, gen_loss = 0.8580950446048026, disc_loss = 0.06382350409876997
Trained batch 295 in epoch 14, gen_loss = 0.8582685205179292, disc_loss = 0.06374149433198713
Trained batch 296 in epoch 14, gen_loss = 0.8575241631931729, disc_loss = 0.0638095878083447
Trained batch 297 in epoch 14, gen_loss = 0.8573190143844426, disc_loss = 0.06382739474846913
Trained batch 298 in epoch 14, gen_loss = 0.8574336089418086, disc_loss = 0.06373603894596415
Trained batch 299 in epoch 14, gen_loss = 0.8580471316973368, disc_loss = 0.06363442883826792
Trained batch 300 in epoch 14, gen_loss = 0.8581432955605643, disc_loss = 0.06365074752907321
Trained batch 301 in epoch 14, gen_loss = 0.8580920810731042, disc_loss = 0.0638101832009852
Trained batch 302 in epoch 14, gen_loss = 0.8569564394431539, disc_loss = 0.06389551047579979
Trained batch 303 in epoch 14, gen_loss = 0.8567001627464044, disc_loss = 0.06391498496400584
Trained batch 304 in epoch 14, gen_loss = 0.8580961739430663, disc_loss = 0.0640899809260593
Trained batch 305 in epoch 14, gen_loss = 0.8578156558127185, disc_loss = 0.06405590382995072
Trained batch 306 in epoch 14, gen_loss = 0.8572580936677293, disc_loss = 0.06405707546706987
Trained batch 307 in epoch 14, gen_loss = 0.8569986644116315, disc_loss = 0.06399753579398157
Trained batch 308 in epoch 14, gen_loss = 0.857298593690866, disc_loss = 0.06384853492747136
Trained batch 309 in epoch 14, gen_loss = 0.8577567829239753, disc_loss = 0.06413290918534321
Trained batch 310 in epoch 14, gen_loss = 0.8574080714458822, disc_loss = 0.06401544789277568
Trained batch 311 in epoch 14, gen_loss = 0.8572573273991927, disc_loss = 0.06419025090797685
Trained batch 312 in epoch 14, gen_loss = 0.8570177676959541, disc_loss = 0.06420711393709096
Trained batch 313 in epoch 14, gen_loss = 0.8571472268575316, disc_loss = 0.0640682868843388
Trained batch 314 in epoch 14, gen_loss = 0.8568548832620894, disc_loss = 0.06399523636828812
Trained batch 315 in epoch 14, gen_loss = 0.8567266102078595, disc_loss = 0.06390185380366313
Trained batch 316 in epoch 14, gen_loss = 0.8575633580000243, disc_loss = 0.06406916929144495
Trained batch 317 in epoch 14, gen_loss = 0.8578141779644685, disc_loss = 0.06393756871199552
Trained batch 318 in epoch 14, gen_loss = 0.857557348509941, disc_loss = 0.06388446326925183
Trained batch 319 in epoch 14, gen_loss = 0.8581392554566264, disc_loss = 0.06374245964980219
Trained batch 320 in epoch 14, gen_loss = 0.8577729786667868, disc_loss = 0.06380698933466294
Trained batch 321 in epoch 14, gen_loss = 0.8577580322390017, disc_loss = 0.06390405218666477
Trained batch 322 in epoch 14, gen_loss = 0.8580771389391401, disc_loss = 0.06391695309315026
Trained batch 323 in epoch 14, gen_loss = 0.8587780620580838, disc_loss = 0.06382499057167199
Trained batch 324 in epoch 14, gen_loss = 0.8584108154590313, disc_loss = 0.06396796535127439
Trained batch 325 in epoch 14, gen_loss = 0.8588671830534204, disc_loss = 0.0638522381745736
Trained batch 326 in epoch 14, gen_loss = 0.859371500277738, disc_loss = 0.06391221570528884
Trained batch 327 in epoch 14, gen_loss = 0.8595109861798402, disc_loss = 0.06375126068185015
Trained batch 328 in epoch 14, gen_loss = 0.8590437177466766, disc_loss = 0.06389700598720359
Trained batch 329 in epoch 14, gen_loss = 0.8592313972386447, disc_loss = 0.06376898238491831
Trained batch 330 in epoch 14, gen_loss = 0.8597431525002793, disc_loss = 0.06374582759135619
Trained batch 331 in epoch 14, gen_loss = 0.8596761759864279, disc_loss = 0.06369167555639722
Trained batch 332 in epoch 14, gen_loss = 0.8591054357565917, disc_loss = 0.0637453585784804
Trained batch 333 in epoch 14, gen_loss = 0.8589676420488758, disc_loss = 0.06361774665799862
Trained batch 334 in epoch 14, gen_loss = 0.8592581329061024, disc_loss = 0.0635654871643924
Trained batch 335 in epoch 14, gen_loss = 0.8598783590963909, disc_loss = 0.0636853774887554
Trained batch 336 in epoch 14, gen_loss = 0.8595201399630538, disc_loss = 0.0636400418074177
Trained batch 337 in epoch 14, gen_loss = 0.8599927224351104, disc_loss = 0.0637468826521695
Trained batch 338 in epoch 14, gen_loss = 0.8596470802582822, disc_loss = 0.06397081752772
Trained batch 339 in epoch 14, gen_loss = 0.8588334642788943, disc_loss = 0.0640009504633353
Trained batch 340 in epoch 14, gen_loss = 0.8592872331219334, disc_loss = 0.06403387435698264
Trained batch 341 in epoch 14, gen_loss = 0.8591264855791951, disc_loss = 0.06394081406447796
Trained batch 342 in epoch 14, gen_loss = 0.8596534350175552, disc_loss = 0.06390066975429003
Trained batch 343 in epoch 14, gen_loss = 0.8592118002301039, disc_loss = 0.0638641471660501
Trained batch 344 in epoch 14, gen_loss = 0.8593289791673854, disc_loss = 0.06374803350671478
Trained batch 345 in epoch 14, gen_loss = 0.8595176261628983, disc_loss = 0.06366992551251988
Trained batch 346 in epoch 14, gen_loss = 0.8590030950153252, disc_loss = 0.06361989084341341
Trained batch 347 in epoch 14, gen_loss = 0.8588003319227833, disc_loss = 0.06353486626912122
Trained batch 348 in epoch 14, gen_loss = 0.8586052533207104, disc_loss = 0.06345165582816717
Trained batch 349 in epoch 14, gen_loss = 0.8595130583218166, disc_loss = 0.06348294969115939
Trained batch 350 in epoch 14, gen_loss = 0.859104587481572, disc_loss = 0.06345236261091342
Trained batch 351 in epoch 14, gen_loss = 0.8583070144734599, disc_loss = 0.06353578409603373
Trained batch 352 in epoch 14, gen_loss = 0.858857946085187, disc_loss = 0.06374563278878377
Trained batch 353 in epoch 14, gen_loss = 0.8592777450879415, disc_loss = 0.0636343029301382
Trained batch 354 in epoch 14, gen_loss = 0.859030667828842, disc_loss = 0.06353152784138498
Trained batch 355 in epoch 14, gen_loss = 0.8579433895228954, disc_loss = 0.06388365811657871
Trained batch 356 in epoch 14, gen_loss = 0.8578723054640099, disc_loss = 0.06385848770852015
Trained batch 357 in epoch 14, gen_loss = 0.8585091932525848, disc_loss = 0.0638955634805327
Trained batch 358 in epoch 14, gen_loss = 0.8595181285172784, disc_loss = 0.0643277766551397
Trained batch 359 in epoch 14, gen_loss = 0.8582553300592635, disc_loss = 0.0655649387743324
Trained batch 360 in epoch 14, gen_loss = 0.8582242832949948, disc_loss = 0.06551698489511938
Trained batch 361 in epoch 14, gen_loss = 0.8585525286790415, disc_loss = 0.0654287177359284
Trained batch 362 in epoch 14, gen_loss = 0.8586321330267536, disc_loss = 0.06543363889899957
Trained batch 363 in epoch 14, gen_loss = 0.8579864040180877, disc_loss = 0.06546585851829949
Trained batch 364 in epoch 14, gen_loss = 0.8576631575414579, disc_loss = 0.06538494243095182
Trained batch 365 in epoch 14, gen_loss = 0.857081868609444, disc_loss = 0.06552862560712412
Trained batch 366 in epoch 14, gen_loss = 0.8572378025392745, disc_loss = 0.06552699010829348
Trained batch 367 in epoch 14, gen_loss = 0.8570983856916428, disc_loss = 0.06543994850337344
Trained batch 368 in epoch 14, gen_loss = 0.8567281405777143, disc_loss = 0.06534667256058554
Trained batch 369 in epoch 14, gen_loss = 0.85609019430908, disc_loss = 0.06539709352057528
Trained batch 370 in epoch 14, gen_loss = 0.855508400262848, disc_loss = 0.06534023842500708
Trained batch 371 in epoch 14, gen_loss = 0.8555082472101334, disc_loss = 0.06536615009529777
Trained batch 372 in epoch 14, gen_loss = 0.8558127220130798, disc_loss = 0.06561316843906133
Trained batch 373 in epoch 14, gen_loss = 0.8552174848668715, disc_loss = 0.06572140488813427
Trained batch 374 in epoch 14, gen_loss = 0.8546132876078287, disc_loss = 0.06571396134793758
Trained batch 375 in epoch 14, gen_loss = 0.8546302914619446, disc_loss = 0.0656449531472506
Trained batch 376 in epoch 14, gen_loss = 0.8542993040236617, disc_loss = 0.06558530439254617
Trained batch 377 in epoch 14, gen_loss = 0.85508209719229, disc_loss = 0.06565559142461372
Trained batch 378 in epoch 14, gen_loss = 0.8548174365214748, disc_loss = 0.06568862625095492
Trained batch 379 in epoch 14, gen_loss = 0.8547691020526385, disc_loss = 0.06562546623478595
Trained batch 380 in epoch 14, gen_loss = 0.8543098370234171, disc_loss = 0.06559552847263538
Trained batch 381 in epoch 14, gen_loss = 0.8548437793841537, disc_loss = 0.06546738205467843
Trained batch 382 in epoch 14, gen_loss = 0.8552754809277487, disc_loss = 0.06546536850555759
Trained batch 383 in epoch 14, gen_loss = 0.8549982467666268, disc_loss = 0.06541153928264976
Trained batch 384 in epoch 14, gen_loss = 0.8554576870682952, disc_loss = 0.06530896888731362
Trained batch 385 in epoch 14, gen_loss = 0.8547814605767245, disc_loss = 0.0655107414687699
Trained batch 386 in epoch 14, gen_loss = 0.8550423617818866, disc_loss = 0.06540137594830467
Trained batch 387 in epoch 14, gen_loss = 0.8549778403080616, disc_loss = 0.065310724574074
Trained batch 388 in epoch 14, gen_loss = 0.8547782347870363, disc_loss = 0.06522341612199738
Trained batch 389 in epoch 14, gen_loss = 0.8548700866026756, disc_loss = 0.06513754504326827
Trained batch 390 in epoch 14, gen_loss = 0.855172094939005, disc_loss = 0.06507295621154101
Trained batch 391 in epoch 14, gen_loss = 0.8546161481312343, disc_loss = 0.06515267002396286
Trained batch 392 in epoch 14, gen_loss = 0.8548805276856167, disc_loss = 0.0650420831208314
Trained batch 393 in epoch 14, gen_loss = 0.8554847887929926, disc_loss = 0.06495152986821184
Trained batch 394 in epoch 14, gen_loss = 0.8552523096905479, disc_loss = 0.06489945358679264
Trained batch 395 in epoch 14, gen_loss = 0.8546139412757122, disc_loss = 0.06518589414543274
Trained batch 396 in epoch 14, gen_loss = 0.8557255335658863, disc_loss = 0.06538007274194989
Trained batch 397 in epoch 14, gen_loss = 0.8554902269912126, disc_loss = 0.06533093509924172
Trained batch 398 in epoch 14, gen_loss = 0.8553071371594766, disc_loss = 0.06522153325397569
Trained batch 399 in epoch 14, gen_loss = 0.8557474294304848, disc_loss = 0.06509134564548731
Trained batch 400 in epoch 14, gen_loss = 0.8566244391729112, disc_loss = 0.06509540603493812
Trained batch 401 in epoch 14, gen_loss = 0.8561336774731156, disc_loss = 0.06514941437623988
Trained batch 402 in epoch 14, gen_loss = 0.8556121907222359, disc_loss = 0.0651301371104664
Trained batch 403 in epoch 14, gen_loss = 0.8554148824498204, disc_loss = 0.06506872037886688
Trained batch 404 in epoch 14, gen_loss = 0.8553882756350953, disc_loss = 0.06496639693684785
Trained batch 405 in epoch 14, gen_loss = 0.8552611700713341, disc_loss = 0.06500292415707716
Trained batch 406 in epoch 14, gen_loss = 0.855103519683388, disc_loss = 0.06522779075625634
Trained batch 407 in epoch 14, gen_loss = 0.8549037226567081, disc_loss = 0.06519000990517146
Trained batch 408 in epoch 14, gen_loss = 0.8543172608377881, disc_loss = 0.06530299156558106
Trained batch 409 in epoch 14, gen_loss = 0.8547560927344532, disc_loss = 0.06529674276073531
Trained batch 410 in epoch 14, gen_loss = 0.8542951006088814, disc_loss = 0.06537348427639826
Trained batch 411 in epoch 14, gen_loss = 0.854236457099035, disc_loss = 0.06544730552354629
Trained batch 412 in epoch 14, gen_loss = 0.854170245206385, disc_loss = 0.06544110312895537
Trained batch 413 in epoch 14, gen_loss = 0.8536167923667005, disc_loss = 0.06566555748113255
Trained batch 414 in epoch 14, gen_loss = 0.8537594815334641, disc_loss = 0.06554396314075195
Trained batch 415 in epoch 14, gen_loss = 0.8543564026745466, disc_loss = 0.06577522368528523
Trained batch 416 in epoch 14, gen_loss = 0.8540504697701342, disc_loss = 0.06571048220320286
Trained batch 417 in epoch 14, gen_loss = 0.8536241249889849, disc_loss = 0.06585793747036366
Trained batch 418 in epoch 14, gen_loss = 0.8534576979628041, disc_loss = 0.06585683971465629
Trained batch 419 in epoch 14, gen_loss = 0.8535834580659867, disc_loss = 0.06593301350339538
Trained batch 420 in epoch 14, gen_loss = 0.8548513856183322, disc_loss = 0.06607012373711604
Trained batch 421 in epoch 14, gen_loss = 0.8542943430172889, disc_loss = 0.06612037320872902
Trained batch 422 in epoch 14, gen_loss = 0.8545030045452975, disc_loss = 0.06602815836756083
Trained batch 423 in epoch 14, gen_loss = 0.8543669024728379, disc_loss = 0.06597021595082896
Trained batch 424 in epoch 14, gen_loss = 0.8547023060742547, disc_loss = 0.06593920816831729
Trained batch 425 in epoch 14, gen_loss = 0.8549618368417444, disc_loss = 0.06587299944596811
Trained batch 426 in epoch 14, gen_loss = 0.8543144743671461, disc_loss = 0.06591117117266046
Trained batch 427 in epoch 14, gen_loss = 0.8543290275836659, disc_loss = 0.06581599582160745
Trained batch 428 in epoch 14, gen_loss = 0.8552539629258198, disc_loss = 0.0659594211058739
Trained batch 429 in epoch 14, gen_loss = 0.8549121695895527, disc_loss = 0.06596497305950454
Trained batch 430 in epoch 14, gen_loss = 0.8545763269931147, disc_loss = 0.06603380849286741
Trained batch 431 in epoch 14, gen_loss = 0.8541173948733894, disc_loss = 0.06638248842554512
Trained batch 432 in epoch 14, gen_loss = 0.854672612549251, disc_loss = 0.06645447027807147
Trained batch 433 in epoch 14, gen_loss = 0.8550565750917531, disc_loss = 0.06633755951810817
Trained batch 434 in epoch 14, gen_loss = 0.8545425478069262, disc_loss = 0.06635769686993512
Trained batch 435 in epoch 14, gen_loss = 0.8543216556037238, disc_loss = 0.06626229205621628
Trained batch 436 in epoch 14, gen_loss = 0.8548785922729178, disc_loss = 0.06617559636229099
Trained batch 437 in epoch 14, gen_loss = 0.8553673271174844, disc_loss = 0.06609978301867367
Trained batch 438 in epoch 14, gen_loss = 0.8549968550036872, disc_loss = 0.06614698589713672
Trained batch 439 in epoch 14, gen_loss = 0.8549681322141127, disc_loss = 0.06606927450153638
Trained batch 440 in epoch 14, gen_loss = 0.8552642509239872, disc_loss = 0.06623592618388248
Trained batch 441 in epoch 14, gen_loss = 0.8550646124382364, disc_loss = 0.06618645330848871
Trained batch 442 in epoch 14, gen_loss = 0.8543915705540918, disc_loss = 0.06639138034399826
Trained batch 443 in epoch 14, gen_loss = 0.8549543667483974, disc_loss = 0.06651179051563681
Trained batch 444 in epoch 14, gen_loss = 0.8562517184889719, disc_loss = 0.06688566226721479
Trained batch 445 in epoch 14, gen_loss = 0.8560971108519978, disc_loss = 0.06690285081302773
Trained batch 446 in epoch 14, gen_loss = 0.8561859834914239, disc_loss = 0.06682838496629157
Trained batch 447 in epoch 14, gen_loss = 0.8564023936965636, disc_loss = 0.06670957241814383
Trained batch 448 in epoch 14, gen_loss = 0.8561419532665431, disc_loss = 0.06662312476275559
Trained batch 449 in epoch 14, gen_loss = 0.8561704349517822, disc_loss = 0.06651151878345343
Trained batch 450 in epoch 14, gen_loss = 0.8561469017798514, disc_loss = 0.06667623838446952
Trained batch 451 in epoch 14, gen_loss = 0.8560712617055505, disc_loss = 0.06661303424836854
Trained batch 452 in epoch 14, gen_loss = 0.856060028339327, disc_loss = 0.06654606920113956
Trained batch 453 in epoch 14, gen_loss = 0.8552547099831871, disc_loss = 0.06672024732816653
Trained batch 454 in epoch 14, gen_loss = 0.8567974572653299, disc_loss = 0.0670680160644454
Trained batch 455 in epoch 14, gen_loss = 0.8569843267139635, disc_loss = 0.067619469598867
Trained batch 456 in epoch 14, gen_loss = 0.8564508540364272, disc_loss = 0.0677497013527044
Trained batch 457 in epoch 14, gen_loss = 0.8563003515312245, disc_loss = 0.0677286532674977
Trained batch 458 in epoch 14, gen_loss = 0.8559331739390338, disc_loss = 0.06766858210174412
Trained batch 459 in epoch 14, gen_loss = 0.8559369917797006, disc_loss = 0.06754355578197409
Trained batch 460 in epoch 14, gen_loss = 0.8560858637805616, disc_loss = 0.06743376080043727
Trained batch 461 in epoch 14, gen_loss = 0.8566797147323559, disc_loss = 0.0673650538496415
Trained batch 462 in epoch 14, gen_loss = 0.8570180815960368, disc_loss = 0.06727371944746176
Trained batch 463 in epoch 14, gen_loss = 0.8565807939860327, disc_loss = 0.06727766848353926
Trained batch 464 in epoch 14, gen_loss = 0.856105330810752, disc_loss = 0.0673260728738481
Trained batch 465 in epoch 14, gen_loss = 0.8563158895836368, disc_loss = 0.0672465570954518
Trained batch 466 in epoch 14, gen_loss = 0.8573105118259373, disc_loss = 0.06743594976760271
Trained batch 467 in epoch 14, gen_loss = 0.8574668393175826, disc_loss = 0.06735316367668664
Trained batch 468 in epoch 14, gen_loss = 0.8569003864646212, disc_loss = 0.0674111407810151
Trained batch 469 in epoch 14, gen_loss = 0.8563679360328836, disc_loss = 0.06754256391580751
Trained batch 470 in epoch 14, gen_loss = 0.8564094251887814, disc_loss = 0.06754239819224157
Trained batch 471 in epoch 14, gen_loss = 0.8567838517286009, disc_loss = 0.06742628232252358
Trained batch 472 in epoch 14, gen_loss = 0.8566576823371661, disc_loss = 0.067340885572545
Trained batch 473 in epoch 14, gen_loss = 0.8570093257266258, disc_loss = 0.06724648051679072
Trained batch 474 in epoch 14, gen_loss = 0.8570536440297177, disc_loss = 0.06713860365317056
Trained batch 475 in epoch 14, gen_loss = 0.8570932723393961, disc_loss = 0.06703571625985205
Trained batch 476 in epoch 14, gen_loss = 0.8566902207378572, disc_loss = 0.06709720670544314
Trained batch 477 in epoch 14, gen_loss = 0.8566094003461894, disc_loss = 0.06704007647736739
Trained batch 478 in epoch 14, gen_loss = 0.8568913631747809, disc_loss = 0.06695277842504434
Trained batch 479 in epoch 14, gen_loss = 0.8573813586185376, disc_loss = 0.06700449914787895
Trained batch 480 in epoch 14, gen_loss = 0.8574147865083263, disc_loss = 0.06688679367683348
Trained batch 481 in epoch 14, gen_loss = 0.8569971397209959, disc_loss = 0.06681639095381892
Trained batch 482 in epoch 14, gen_loss = 0.856552177087614, disc_loss = 0.06685401021269599
Trained batch 483 in epoch 14, gen_loss = 0.8565856641974331, disc_loss = 0.06674260587608519
Trained batch 484 in epoch 14, gen_loss = 0.857321431710548, disc_loss = 0.06682538967771628
Trained batch 485 in epoch 14, gen_loss = 0.8576906019277534, disc_loss = 0.06706332550249963
Trained batch 486 in epoch 14, gen_loss = 0.8572004304039894, disc_loss = 0.06732008237491154
Trained batch 487 in epoch 14, gen_loss = 0.8567706771561356, disc_loss = 0.06752278484770509
Trained batch 488 in epoch 14, gen_loss = 0.8576347062436593, disc_loss = 0.06770903128056438
Trained batch 489 in epoch 14, gen_loss = 0.8582152663444986, disc_loss = 0.06791003693123253
Trained batch 490 in epoch 14, gen_loss = 0.8579272905823655, disc_loss = 0.06787559969726259
Trained batch 491 in epoch 14, gen_loss = 0.8581054988430767, disc_loss = 0.06782698118680619
Trained batch 492 in epoch 14, gen_loss = 0.8581092227061429, disc_loss = 0.06775132362290642
Trained batch 493 in epoch 14, gen_loss = 0.8576227255195741, disc_loss = 0.06795666930510809
Trained batch 494 in epoch 14, gen_loss = 0.8571921211300474, disc_loss = 0.06795483189023505
Trained batch 495 in epoch 14, gen_loss = 0.8568932438089002, disc_loss = 0.06791513388781177
Trained batch 496 in epoch 14, gen_loss = 0.8572742253002267, disc_loss = 0.06785449305815357
Trained batch 497 in epoch 14, gen_loss = 0.8578350625363699, disc_loss = 0.06786849817642605
Trained batch 498 in epoch 14, gen_loss = 0.8572029416451235, disc_loss = 0.06812099582013602
Trained batch 499 in epoch 14, gen_loss = 0.8574455440044403, disc_loss = 0.06800813834369182
Trained batch 500 in epoch 14, gen_loss = 0.8571704302481311, disc_loss = 0.06804340939500375
Trained batch 501 in epoch 14, gen_loss = 0.8572666452700398, disc_loss = 0.06800304192203686
Trained batch 502 in epoch 14, gen_loss = 0.8571452921474905, disc_loss = 0.0679070639348113
Trained batch 503 in epoch 14, gen_loss = 0.8571940936029904, disc_loss = 0.06781813578813203
Trained batch 504 in epoch 14, gen_loss = 0.8579837540588756, disc_loss = 0.06784856941661623
Trained batch 505 in epoch 14, gen_loss = 0.8577582414442372, disc_loss = 0.06790899446697927
Trained batch 506 in epoch 14, gen_loss = 0.8573375251401341, disc_loss = 0.06789156380504428
Trained batch 507 in epoch 14, gen_loss = 0.857876850394752, disc_loss = 0.06797466056392067
Trained batch 508 in epoch 14, gen_loss = 0.8581216469963313, disc_loss = 0.06789058648518237
Trained batch 509 in epoch 14, gen_loss = 0.8581881555856443, disc_loss = 0.0678268586413241
Trained batch 510 in epoch 14, gen_loss = 0.858210611833285, disc_loss = 0.06771119323662991
Trained batch 511 in epoch 14, gen_loss = 0.8581006360473111, disc_loss = 0.06762564065684273
Trained batch 512 in epoch 14, gen_loss = 0.8575341586481061, disc_loss = 0.06770239887871647
Trained batch 513 in epoch 14, gen_loss = 0.8576769623543038, disc_loss = 0.06775883134229811
Trained batch 514 in epoch 14, gen_loss = 0.8576761581365344, disc_loss = 0.06765218490680444
Trained batch 515 in epoch 14, gen_loss = 0.8576634661402813, disc_loss = 0.06756829961686749
Trained batch 516 in epoch 14, gen_loss = 0.8580016018804775, disc_loss = 0.06745805148741436
Trained batch 517 in epoch 14, gen_loss = 0.8577965325370258, disc_loss = 0.06744667389843627
Trained batch 518 in epoch 14, gen_loss = 0.8574370999097365, disc_loss = 0.06748405061410974
Trained batch 519 in epoch 14, gen_loss = 0.8578252229553003, disc_loss = 0.06747034336619366
Trained batch 520 in epoch 14, gen_loss = 0.8575415411059549, disc_loss = 0.06753700808398497
Trained batch 521 in epoch 14, gen_loss = 0.8578344954613069, disc_loss = 0.06746948847789817
Trained batch 522 in epoch 14, gen_loss = 0.8579933642201396, disc_loss = 0.06744074995805782
Trained batch 523 in epoch 14, gen_loss = 0.8580560532917503, disc_loss = 0.06733520674512132
Trained batch 524 in epoch 14, gen_loss = 0.8581594284375509, disc_loss = 0.0672245571567189
Trained batch 525 in epoch 14, gen_loss = 0.8582748479489591, disc_loss = 0.06713359895562435
Trained batch 526 in epoch 14, gen_loss = 0.8585554048051418, disc_loss = 0.06702564476655205
Trained batch 527 in epoch 14, gen_loss = 0.8586758747696877, disc_loss = 0.06713731980099427
Trained batch 528 in epoch 14, gen_loss = 0.8587894205334957, disc_loss = 0.06705349654008569
Trained batch 529 in epoch 14, gen_loss = 0.8586214892144474, disc_loss = 0.0670311300663875
Trained batch 530 in epoch 14, gen_loss = 0.858965450424259, disc_loss = 0.06692455404327582
Trained batch 531 in epoch 14, gen_loss = 0.8590244840186342, disc_loss = 0.06689294317520146
Trained batch 532 in epoch 14, gen_loss = 0.859365053181353, disc_loss = 0.06681556406817059
Trained batch 533 in epoch 14, gen_loss = 0.8591160168138783, disc_loss = 0.06674184958705127
Trained batch 534 in epoch 14, gen_loss = 0.8589340110805547, disc_loss = 0.06669489138489851
Trained batch 535 in epoch 14, gen_loss = 0.8588377125005224, disc_loss = 0.06669127014152873
Trained batch 536 in epoch 14, gen_loss = 0.8592553810256376, disc_loss = 0.06661002654443518
Trained batch 537 in epoch 14, gen_loss = 0.8591042414695357, disc_loss = 0.06661312996849529
Trained batch 538 in epoch 14, gen_loss = 0.858651890051387, disc_loss = 0.06659472989633762
Trained batch 539 in epoch 14, gen_loss = 0.8587582986663889, disc_loss = 0.06663391355735561
Trained batch 540 in epoch 14, gen_loss = 0.8591365687507798, disc_loss = 0.06654452134694994
Trained batch 541 in epoch 14, gen_loss = 0.8590284519969758, disc_loss = 0.06645008434826763
Trained batch 542 in epoch 14, gen_loss = 0.8587340586312787, disc_loss = 0.06659306519755727
Trained batch 543 in epoch 14, gen_loss = 0.859245997360524, disc_loss = 0.06658667996902402
Trained batch 544 in epoch 14, gen_loss = 0.8591485573611128, disc_loss = 0.06652632170963452
Trained batch 545 in epoch 14, gen_loss = 0.858690117195849, disc_loss = 0.0665389543361689
Trained batch 546 in epoch 14, gen_loss = 0.8589256242380717, disc_loss = 0.0665576731874667
Trained batch 547 in epoch 14, gen_loss = 0.8587361496947977, disc_loss = 0.06652366814380307
Trained batch 548 in epoch 14, gen_loss = 0.8586835420413964, disc_loss = 0.06646658110182957
Trained batch 549 in epoch 14, gen_loss = 0.8590702837163752, disc_loss = 0.06644648406146603
Trained batch 550 in epoch 14, gen_loss = 0.8586903804010575, disc_loss = 0.06648835510576648
Trained batch 551 in epoch 14, gen_loss = 0.8587617957289668, disc_loss = 0.06639575949647343
Trained batch 552 in epoch 14, gen_loss = 0.8592649707958021, disc_loss = 0.06640231042972364
Trained batch 553 in epoch 14, gen_loss = 0.8596134328885199, disc_loss = 0.06632298303243539
Trained batch 554 in epoch 14, gen_loss = 0.8592055201530456, disc_loss = 0.06628565378319304
Trained batch 555 in epoch 14, gen_loss = 0.8593952508924676, disc_loss = 0.06624640911154235
Trained batch 556 in epoch 14, gen_loss = 0.8603771191953115, disc_loss = 0.06636926955317735
Trained batch 557 in epoch 14, gen_loss = 0.8600353306980544, disc_loss = 0.06634285083494573
Trained batch 558 in epoch 14, gen_loss = 0.8604116466476154, disc_loss = 0.0662514321915872
Trained batch 559 in epoch 14, gen_loss = 0.8604264511593751, disc_loss = 0.06616973629986335
Trained batch 560 in epoch 14, gen_loss = 0.8604983025481144, disc_loss = 0.06609610469311264
Trained batch 561 in epoch 14, gen_loss = 0.8609107261874922, disc_loss = 0.06600015692154336
Trained batch 562 in epoch 14, gen_loss = 0.860935643235913, disc_loss = 0.06590890600039999
Trained batch 563 in epoch 14, gen_loss = 0.8610757699249484, disc_loss = 0.06585211970130021
Trained batch 564 in epoch 14, gen_loss = 0.8610251242080621, disc_loss = 0.06576767011125267
Trained batch 565 in epoch 14, gen_loss = 0.8609425546634324, disc_loss = 0.06570527604995
Trained batch 566 in epoch 14, gen_loss = 0.8606164376571696, disc_loss = 0.06568504777791166
Trained batch 567 in epoch 14, gen_loss = 0.8604878244895331, disc_loss = 0.06560855110759624
Trained batch 568 in epoch 14, gen_loss = 0.8606330773323407, disc_loss = 0.06558294531926906
Trained batch 569 in epoch 14, gen_loss = 0.8607767184575399, disc_loss = 0.06558564405136726
Trained batch 570 in epoch 14, gen_loss = 0.8607960773432943, disc_loss = 0.06554087634229357
Trained batch 571 in epoch 14, gen_loss = 0.8610175769854259, disc_loss = 0.06546435083939948
Trained batch 572 in epoch 14, gen_loss = 0.8606437160706645, disc_loss = 0.06548966262749613
Trained batch 573 in epoch 14, gen_loss = 0.8609453743966199, disc_loss = 0.06546923578051585
Trained batch 574 in epoch 14, gen_loss = 0.8612963242116182, disc_loss = 0.06544494115302096
Trained batch 575 in epoch 14, gen_loss = 0.861023906721837, disc_loss = 0.06546310418990389
Trained batch 576 in epoch 14, gen_loss = 0.8608098952567763, disc_loss = 0.06537032346410654
Trained batch 577 in epoch 14, gen_loss = 0.8610343265904687, disc_loss = 0.06528146317306016
Trained batch 578 in epoch 14, gen_loss = 0.8613337139391528, disc_loss = 0.06527319998160287
Trained batch 579 in epoch 14, gen_loss = 0.8615774371500673, disc_loss = 0.06518082355534466
Trained batch 580 in epoch 14, gen_loss = 0.8610578766172806, disc_loss = 0.06523893163307039
Trained batch 581 in epoch 14, gen_loss = 0.8614930972405725, disc_loss = 0.0651735440872712
Trained batch 582 in epoch 14, gen_loss = 0.8613086698599173, disc_loss = 0.06520825080848323
Trained batch 583 in epoch 14, gen_loss = 0.8613661120403303, disc_loss = 0.06519328135110387
Trained batch 584 in epoch 14, gen_loss = 0.8613752113448249, disc_loss = 0.06517134435697754
Trained batch 585 in epoch 14, gen_loss = 0.8614910987456911, disc_loss = 0.06516592997466389
Trained batch 586 in epoch 14, gen_loss = 0.861550172000768, disc_loss = 0.0651539937248755
Trained batch 587 in epoch 14, gen_loss = 0.8614772875495509, disc_loss = 0.06505881572541382
Trained batch 588 in epoch 14, gen_loss = 0.8611017948297977, disc_loss = 0.06509771275987093
Trained batch 589 in epoch 14, gen_loss = 0.8612007154246508, disc_loss = 0.06500771747333771
Trained batch 590 in epoch 14, gen_loss = 0.8611996067962066, disc_loss = 0.0649268190611261
Trained batch 591 in epoch 14, gen_loss = 0.861465827335377, disc_loss = 0.06492345776515887
Trained batch 592 in epoch 14, gen_loss = 0.8610981161035535, disc_loss = 0.06492042344402754
Trained batch 593 in epoch 14, gen_loss = 0.8610996600955424, disc_loss = 0.06483389613899067
Trained batch 594 in epoch 14, gen_loss = 0.8613491101425235, disc_loss = 0.06474673904697685
Trained batch 595 in epoch 14, gen_loss = 0.8613021098727348, disc_loss = 0.06471521415022645
Trained batch 596 in epoch 14, gen_loss = 0.8614961435048025, disc_loss = 0.06467201351851125
Trained batch 597 in epoch 14, gen_loss = 0.8618986990340178, disc_loss = 0.06458093988612593
Trained batch 598 in epoch 14, gen_loss = 0.8617007466707882, disc_loss = 0.06460117555078809
Trained batch 599 in epoch 14, gen_loss = 0.8615412756800651, disc_loss = 0.06463707401261976
Trained batch 600 in epoch 14, gen_loss = 0.8618690990370245, disc_loss = 0.06454582781857887
Trained batch 601 in epoch 14, gen_loss = 0.8617471034740689, disc_loss = 0.06446862517951979
Trained batch 602 in epoch 14, gen_loss = 0.8617381344782574, disc_loss = 0.06443868882824384
Trained batch 603 in epoch 14, gen_loss = 0.8619274117101897, disc_loss = 0.0643607809976212
Trained batch 604 in epoch 14, gen_loss = 0.8615140277492114, disc_loss = 0.06434318365852448
Trained batch 605 in epoch 14, gen_loss = 0.8616315079207467, disc_loss = 0.06427744516131557
Trained batch 606 in epoch 14, gen_loss = 0.8619938167747988, disc_loss = 0.06425137986786529
Trained batch 607 in epoch 14, gen_loss = 0.8618692440029821, disc_loss = 0.06419302335186665
Trained batch 608 in epoch 14, gen_loss = 0.8621654880457911, disc_loss = 0.06410873562177072
Trained batch 609 in epoch 14, gen_loss = 0.8624238772470443, disc_loss = 0.06401669261366373
Trained batch 610 in epoch 14, gen_loss = 0.8623880176224217, disc_loss = 0.06395295191458662
Trained batch 611 in epoch 14, gen_loss = 0.8620318644771389, disc_loss = 0.06399826388775669
Trained batch 612 in epoch 14, gen_loss = 0.8623959914117225, disc_loss = 0.06392126775773616
Trained batch 613 in epoch 14, gen_loss = 0.8623042456101905, disc_loss = 0.06385575250513148
Trained batch 614 in epoch 14, gen_loss = 0.8624279256758651, disc_loss = 0.06379823919264524
Trained batch 615 in epoch 14, gen_loss = 0.8624877201078774, disc_loss = 0.06373250063405941
Trained batch 616 in epoch 14, gen_loss = 0.8618834861576847, disc_loss = 0.06402620813104429
Trained batch 617 in epoch 14, gen_loss = 0.8621806020586236, disc_loss = 0.06399451688528784
Trained batch 618 in epoch 14, gen_loss = 0.8632903552113134, disc_loss = 0.06427114205780968
Trained batch 619 in epoch 14, gen_loss = 0.8630210591420051, disc_loss = 0.06430125848630504
Trained batch 620 in epoch 14, gen_loss = 0.8626376175938021, disc_loss = 0.06434602602782409
Trained batch 621 in epoch 14, gen_loss = 0.8629304215168263, disc_loss = 0.06428465434766324
Trained batch 622 in epoch 14, gen_loss = 0.863039456487276, disc_loss = 0.06419681663061365
Trained batch 623 in epoch 14, gen_loss = 0.8629585288178462, disc_loss = 0.06414466348136418
Trained batch 624 in epoch 14, gen_loss = 0.8628725267887115, disc_loss = 0.06410773676484824
Trained batch 625 in epoch 14, gen_loss = 0.8628121585415575, disc_loss = 0.06405214631941895
Trained batch 626 in epoch 14, gen_loss = 0.8625838586873416, disc_loss = 0.06402926887140463
Trained batch 627 in epoch 14, gen_loss = 0.8629760848014218, disc_loss = 0.06401252932698247
Trained batch 628 in epoch 14, gen_loss = 0.8630837755002354, disc_loss = 0.0639808526949658
Trained batch 629 in epoch 14, gen_loss = 0.8627892129478001, disc_loss = 0.06393175970556007
Trained batch 630 in epoch 14, gen_loss = 0.8625053052573499, disc_loss = 0.0639066397007289
Trained batch 631 in epoch 14, gen_loss = 0.8627682834203485, disc_loss = 0.06381803546601883
Trained batch 632 in epoch 14, gen_loss = 0.8626367213884236, disc_loss = 0.06376587237727256
Trained batch 633 in epoch 14, gen_loss = 0.8626540249172445, disc_loss = 0.0637167990927464
Trained batch 634 in epoch 14, gen_loss = 0.8625623349599012, disc_loss = 0.0637670107845833
Trained batch 635 in epoch 14, gen_loss = 0.8621279374702172, disc_loss = 0.06386608057713968
Trained batch 636 in epoch 14, gen_loss = 0.8621823630022292, disc_loss = 0.06385879856176101
Trained batch 637 in epoch 14, gen_loss = 0.862934367923901, disc_loss = 0.0638949356660784
Trained batch 638 in epoch 14, gen_loss = 0.8630562943751823, disc_loss = 0.0638391277439461
Trained batch 639 in epoch 14, gen_loss = 0.8630487275775522, disc_loss = 0.0637755372634274
Trained batch 640 in epoch 14, gen_loss = 0.862586008916593, disc_loss = 0.06381049861059221
Trained batch 641 in epoch 14, gen_loss = 0.8622100834627389, disc_loss = 0.06400083601503775
Trained batch 642 in epoch 14, gen_loss = 0.8625311761121172, disc_loss = 0.06411071821126049
Trained batch 643 in epoch 14, gen_loss = 0.862786318065587, disc_loss = 0.06403926002897137
Trained batch 644 in epoch 14, gen_loss = 0.8628567592580189, disc_loss = 0.0639612602214365
Trained batch 645 in epoch 14, gen_loss = 0.8623775363245246, disc_loss = 0.06404285550826797
Trained batch 646 in epoch 14, gen_loss = 0.8626587506516087, disc_loss = 0.06408439498751711
Trained batch 647 in epoch 14, gen_loss = 0.8630200979058389, disc_loss = 0.0640093364542994
Trained batch 648 in epoch 14, gen_loss = 0.8626453756643186, disc_loss = 0.06403638267364405
Trained batch 649 in epoch 14, gen_loss = 0.8625744620194802, disc_loss = 0.0639708989729675
Trained batch 650 in epoch 14, gen_loss = 0.8631579841611572, disc_loss = 0.06394648023046977
Trained batch 651 in epoch 14, gen_loss = 0.8634206377015523, disc_loss = 0.06391379165611705
Trained batch 652 in epoch 14, gen_loss = 0.8633720363172236, disc_loss = 0.06390955219698491
Trained batch 653 in epoch 14, gen_loss = 0.8628737864053213, disc_loss = 0.0640600008266303
Trained batch 654 in epoch 14, gen_loss = 0.8630325488006796, disc_loss = 0.06399424458135858
Trained batch 655 in epoch 14, gen_loss = 0.8632103905717774, disc_loss = 0.06398133769284979
Trained batch 656 in epoch 14, gen_loss = 0.8631079469550872, disc_loss = 0.06396948584019457
Trained batch 657 in epoch 14, gen_loss = 0.862996580979382, disc_loss = 0.06395007125710599
Trained batch 658 in epoch 14, gen_loss = 0.8626261533934719, disc_loss = 0.06395035557454518
Trained batch 659 in epoch 14, gen_loss = 0.8627145810109196, disc_loss = 0.06391177874933364
Trained batch 660 in epoch 14, gen_loss = 0.8629798289957638, disc_loss = 0.06389583010823888
Trained batch 661 in epoch 14, gen_loss = 0.8629233154195313, disc_loss = 0.0638515912770122
Trained batch 662 in epoch 14, gen_loss = 0.8632220457312209, disc_loss = 0.06377585839232933
Trained batch 663 in epoch 14, gen_loss = 0.8635106242475021, disc_loss = 0.06371153520941959
Trained batch 664 in epoch 14, gen_loss = 0.8633070581389549, disc_loss = 0.06370770317411288
Trained batch 665 in epoch 14, gen_loss = 0.8630090584536573, disc_loss = 0.06368838157364959
Trained batch 666 in epoch 14, gen_loss = 0.8631147415652268, disc_loss = 0.06362552981756661
Trained batch 667 in epoch 14, gen_loss = 0.8633443491455324, disc_loss = 0.06356316354421307
Trained batch 668 in epoch 14, gen_loss = 0.8631768457825408, disc_loss = 0.06353187196998006
Trained batch 669 in epoch 14, gen_loss = 0.8633835105308846, disc_loss = 0.0634997528727486
Trained batch 670 in epoch 14, gen_loss = 0.8634033435414339, disc_loss = 0.06344118049915119
Trained batch 671 in epoch 14, gen_loss = 0.8631665314148579, disc_loss = 0.06343348718032107
Trained batch 672 in epoch 14, gen_loss = 0.8634589507976578, disc_loss = 0.06342474058032434
Trained batch 673 in epoch 14, gen_loss = 0.8631598653620004, disc_loss = 0.06358929876188363
Trained batch 674 in epoch 14, gen_loss = 0.8628826840277072, disc_loss = 0.06358679553562845
Trained batch 675 in epoch 14, gen_loss = 0.8626277835146915, disc_loss = 0.06357628336457326
Trained batch 676 in epoch 14, gen_loss = 0.8627526945430384, disc_loss = 0.06353959834761642
Trained batch 677 in epoch 14, gen_loss = 0.8628330328735279, disc_loss = 0.06352668743069588
Trained batch 678 in epoch 14, gen_loss = 0.8627634276258752, disc_loss = 0.06347702297797654
Trained batch 679 in epoch 14, gen_loss = 0.8627205946427934, disc_loss = 0.06342574018464588
Trained batch 680 in epoch 14, gen_loss = 0.8629994117128341, disc_loss = 0.06336618338611727
Trained batch 681 in epoch 14, gen_loss = 0.86293294182446, disc_loss = 0.06331739103410644
Trained batch 682 in epoch 14, gen_loss = 0.8634902600575332, disc_loss = 0.06326185470231499
Trained batch 683 in epoch 14, gen_loss = 0.8632848545560363, disc_loss = 0.06324064038416143
Trained batch 684 in epoch 14, gen_loss = 0.8632745797181651, disc_loss = 0.06317137280329518
Trained batch 685 in epoch 14, gen_loss = 0.8632624954332763, disc_loss = 0.06318858528303378
Trained batch 686 in epoch 14, gen_loss = 0.8631343579969031, disc_loss = 0.06313334956488625
Trained batch 687 in epoch 14, gen_loss = 0.8632790569735821, disc_loss = 0.06306958920999192
Trained batch 688 in epoch 14, gen_loss = 0.8634196086874548, disc_loss = 0.06302747899917845
Trained batch 689 in epoch 14, gen_loss = 0.8633667413307273, disc_loss = 0.06305033505853752
Trained batch 690 in epoch 14, gen_loss = 0.8634481303684963, disc_loss = 0.06298334005810374
Trained batch 691 in epoch 14, gen_loss = 0.8636930508679048, disc_loss = 0.06293145764882897
Trained batch 692 in epoch 14, gen_loss = 0.8631991221533193, disc_loss = 0.06309109945172742
Trained batch 693 in epoch 14, gen_loss = 0.8637739390306582, disc_loss = 0.06309308609401845
Trained batch 694 in epoch 14, gen_loss = 0.8640372510865438, disc_loss = 0.06304977429132881
Trained batch 695 in epoch 14, gen_loss = 0.8644469659133204, disc_loss = 0.062995725125342
Trained batch 696 in epoch 14, gen_loss = 0.8642710667515074, disc_loss = 0.06296529139457552
Trained batch 697 in epoch 14, gen_loss = 0.8644138267610681, disc_loss = 0.06291254769268854
Trained batch 698 in epoch 14, gen_loss = 0.8640712700432462, disc_loss = 0.06296328573923382
Trained batch 699 in epoch 14, gen_loss = 0.8640073304942676, disc_loss = 0.06294745172640043
Trained batch 700 in epoch 14, gen_loss = 0.8643685605233474, disc_loss = 0.06292547480456967
Trained batch 701 in epoch 14, gen_loss = 0.8642865614249156, disc_loss = 0.06292897353925214
Trained batch 702 in epoch 14, gen_loss = 0.8641892571961388, disc_loss = 0.06289821455008741
Trained batch 703 in epoch 14, gen_loss = 0.864431235473603, disc_loss = 0.06285030871433926
Trained batch 704 in epoch 14, gen_loss = 0.8643669696987099, disc_loss = 0.06279615450597613
Trained batch 705 in epoch 14, gen_loss = 0.8645117331412291, disc_loss = 0.0627256159396267
Trained batch 706 in epoch 14, gen_loss = 0.8646577965505052, disc_loss = 0.06264965712123115
Trained batch 707 in epoch 14, gen_loss = 0.864398453489872, disc_loss = 0.06262831428446045
Trained batch 708 in epoch 14, gen_loss = 0.8648374342531681, disc_loss = 0.06259531313514045
Trained batch 709 in epoch 14, gen_loss = 0.8648951075026686, disc_loss = 0.06252687530933132
Trained batch 710 in epoch 14, gen_loss = 0.864963955810469, disc_loss = 0.062455599646852905
Trained batch 711 in epoch 14, gen_loss = 0.8646444091887286, disc_loss = 0.06245970150869172
Trained batch 712 in epoch 14, gen_loss = 0.8646420855257989, disc_loss = 0.062402456456750924
Trained batch 713 in epoch 14, gen_loss = 0.8647128594439236, disc_loss = 0.06233875932046721
Trained batch 714 in epoch 14, gen_loss = 0.8647658608593307, disc_loss = 0.06237126195581851
Trained batch 715 in epoch 14, gen_loss = 0.8651307893282209, disc_loss = 0.06233811430638271
Trained batch 716 in epoch 14, gen_loss = 0.8648324914307773, disc_loss = 0.06240808305095471
Trained batch 717 in epoch 14, gen_loss = 0.8652007555314093, disc_loss = 0.06233914058089962
Trained batch 718 in epoch 14, gen_loss = 0.8653374156384873, disc_loss = 0.0626123307003369
Trained batch 719 in epoch 14, gen_loss = 0.8658823724008269, disc_loss = 0.06257371251704172
Trained batch 720 in epoch 14, gen_loss = 0.8654334076813289, disc_loss = 0.06281741309766341
Trained batch 721 in epoch 14, gen_loss = 0.8652762473867871, disc_loss = 0.06280277143271222
Trained batch 722 in epoch 14, gen_loss = 0.8651175563678372, disc_loss = 0.06321320265536692
Trained batch 723 in epoch 14, gen_loss = 0.8646970362047464, disc_loss = 0.0633593375565618
Trained batch 724 in epoch 14, gen_loss = 0.8644753863482639, disc_loss = 0.06344545128145095
Trained batch 725 in epoch 14, gen_loss = 0.8647853316272257, disc_loss = 0.06353065420901685
Trained batch 726 in epoch 14, gen_loss = 0.8644383568957222, disc_loss = 0.0635872535430602
Trained batch 727 in epoch 14, gen_loss = 0.8644156245166784, disc_loss = 0.06357925421184768
Trained batch 728 in epoch 14, gen_loss = 0.8646186682177178, disc_loss = 0.06360138464330686
Trained batch 729 in epoch 14, gen_loss = 0.8646099785011109, disc_loss = 0.06360595423396524
Trained batch 730 in epoch 14, gen_loss = 0.8644144936641819, disc_loss = 0.06364795308886287
Trained batch 731 in epoch 14, gen_loss = 0.8646568226439705, disc_loss = 0.06365677498693227
Trained batch 732 in epoch 14, gen_loss = 0.8647735081867176, disc_loss = 0.06367805805616335
Trained batch 733 in epoch 14, gen_loss = 0.8644511791032407, disc_loss = 0.06376239326617576
Trained batch 734 in epoch 14, gen_loss = 0.8646059539447837, disc_loss = 0.0637059361211398
Trained batch 735 in epoch 14, gen_loss = 0.8645161304055996, disc_loss = 0.06379293464756895
Trained batch 736 in epoch 14, gen_loss = 0.8643772311336797, disc_loss = 0.06391135521935681
Trained batch 737 in epoch 14, gen_loss = 0.8639563047062091, disc_loss = 0.0640225655646606
Trained batch 738 in epoch 14, gen_loss = 0.8640655652192675, disc_loss = 0.06396297434362531
Trained batch 739 in epoch 14, gen_loss = 0.8640282843161273, disc_loss = 0.06390057052233936
Trained batch 740 in epoch 14, gen_loss = 0.864196937455822, disc_loss = 0.06402987596803872
Trained batch 741 in epoch 14, gen_loss = 0.8640393641679435, disc_loss = 0.0640053601340564
Trained batch 742 in epoch 14, gen_loss = 0.8638881146907806, disc_loss = 0.06397609164609923
Trained batch 743 in epoch 14, gen_loss = 0.8639317116830297, disc_loss = 0.06392953267586367
Trained batch 744 in epoch 14, gen_loss = 0.864027231771674, disc_loss = 0.06404050083693442
Trained batch 745 in epoch 14, gen_loss = 0.8636971217937188, disc_loss = 0.0640717102152273
Trained batch 746 in epoch 14, gen_loss = 0.8635204867266587, disc_loss = 0.06408595167215131
Trained batch 747 in epoch 14, gen_loss = 0.8635571488642437, disc_loss = 0.06413823218871764
Trained batch 748 in epoch 14, gen_loss = 0.8637183097319228, disc_loss = 0.06410960189734545
Trained batch 749 in epoch 14, gen_loss = 0.863647677063942, disc_loss = 0.0640529341561099
Trained batch 750 in epoch 14, gen_loss = 0.8635218185924499, disc_loss = 0.06399309353781406
Trained batch 751 in epoch 14, gen_loss = 0.8633557441941602, disc_loss = 0.0639587816710465
Trained batch 752 in epoch 14, gen_loss = 0.8633972494646531, disc_loss = 0.06393554915425431
Trained batch 753 in epoch 14, gen_loss = 0.8631203495143895, disc_loss = 0.06395537637307529
Trained batch 754 in epoch 14, gen_loss = 0.8631815818366625, disc_loss = 0.06391910163451307
Trained batch 755 in epoch 14, gen_loss = 0.8633580408477909, disc_loss = 0.06385803451667979
Trained batch 756 in epoch 14, gen_loss = 0.8631182129112228, disc_loss = 0.0638106200447899
Trained batch 757 in epoch 14, gen_loss = 0.8628782646086726, disc_loss = 0.06377408050595337
Trained batch 758 in epoch 14, gen_loss = 0.8629104755377109, disc_loss = 0.06388295176457393
Trained batch 759 in epoch 14, gen_loss = 0.8630358183462369, disc_loss = 0.06381465688494867
Trained batch 760 in epoch 14, gen_loss = 0.862876605149481, disc_loss = 0.06380628430469355
Trained batch 761 in epoch 14, gen_loss = 0.8629226129590057, disc_loss = 0.06373984026514834
Trained batch 762 in epoch 14, gen_loss = 0.8631833418715515, disc_loss = 0.06371205807010476
Trained batch 763 in epoch 14, gen_loss = 0.8631980925096268, disc_loss = 0.06384474708191583
Trained batch 764 in epoch 14, gen_loss = 0.862979139338911, disc_loss = 0.06382206149667112
Trained batch 765 in epoch 14, gen_loss = 0.8626599730072694, disc_loss = 0.06390351291585412
Trained batch 766 in epoch 14, gen_loss = 0.8629069503547315, disc_loss = 0.06387527902504961
Trained batch 767 in epoch 14, gen_loss = 0.8630244807573035, disc_loss = 0.06382998757302023
Trained batch 768 in epoch 14, gen_loss = 0.862784531669902, disc_loss = 0.06386613278190748
Trained batch 769 in epoch 14, gen_loss = 0.8630301900885322, disc_loss = 0.0638097659975
Trained batch 770 in epoch 14, gen_loss = 0.8629609807533358, disc_loss = 0.06376801536149126
Trained batch 771 in epoch 14, gen_loss = 0.8631598001703079, disc_loss = 0.0637713250778905
Trained batch 772 in epoch 14, gen_loss = 0.863209397988671, disc_loss = 0.06371341021261617
Trained batch 773 in epoch 14, gen_loss = 0.8630998695620579, disc_loss = 0.06367530572788853
Trained batch 774 in epoch 14, gen_loss = 0.8629722251046088, disc_loss = 0.06371524515772058
Trained batch 775 in epoch 14, gen_loss = 0.8634367370497935, disc_loss = 0.06377098675860457
Trained batch 776 in epoch 14, gen_loss = 0.8629454961921564, disc_loss = 0.06406359695871403
Trained batch 777 in epoch 14, gen_loss = 0.8631488956645093, disc_loss = 0.06404288932513494
Trained batch 778 in epoch 14, gen_loss = 0.8631453350358506, disc_loss = 0.06402232650600478
Trained batch 779 in epoch 14, gen_loss = 0.8628885945448509, disc_loss = 0.06408479978473713
Trained batch 780 in epoch 14, gen_loss = 0.8630830608928401, disc_loss = 0.0642502180881388
Trained batch 781 in epoch 14, gen_loss = 0.8630617836399761, disc_loss = 0.06418761067792697
Trained batch 782 in epoch 14, gen_loss = 0.8628564743398859, disc_loss = 0.06421335821669183
Trained batch 783 in epoch 14, gen_loss = 0.8626045199225143, disc_loss = 0.06422411576174769
Trained batch 784 in epoch 14, gen_loss = 0.8624871918350269, disc_loss = 0.06438000999319896
Trained batch 785 in epoch 14, gen_loss = 0.8621261409524136, disc_loss = 0.06442251292344078
Trained batch 786 in epoch 14, gen_loss = 0.8623088822431455, disc_loss = 0.0643743269081586
Trained batch 787 in epoch 14, gen_loss = 0.8618496347804965, disc_loss = 0.06443827130907419
Trained batch 788 in epoch 14, gen_loss = 0.861915636576325, disc_loss = 0.0644856608603787
Trained batch 789 in epoch 14, gen_loss = 0.8621350664126722, disc_loss = 0.06448762072250247
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.6463892459869385, disc_loss = 0.13295286893844604
Trained batch 1 in epoch 15, gen_loss = 0.7500916421413422, disc_loss = 0.09704602137207985
Trained batch 2 in epoch 15, gen_loss = 0.7909197409947714, disc_loss = 0.07277425316472848
Trained batch 3 in epoch 15, gen_loss = 0.7841567695140839, disc_loss = 0.06073836097493768
Trained batch 4 in epoch 15, gen_loss = 0.8520042896270752, disc_loss = 0.05744499079883099
Trained batch 5 in epoch 15, gen_loss = 0.8020355602105459, disc_loss = 0.06369110165784757
Trained batch 6 in epoch 15, gen_loss = 0.8046279379299709, disc_loss = 0.060701371037534306
Trained batch 7 in epoch 15, gen_loss = 0.8003308996558189, disc_loss = 0.05849224771372974
Trained batch 8 in epoch 15, gen_loss = 0.8274332616064284, disc_loss = 0.06632115505635738
Trained batch 9 in epoch 15, gen_loss = 0.8137804090976715, disc_loss = 0.06600814443081618
Trained batch 10 in epoch 15, gen_loss = 0.8131750117648732, disc_loss = 0.06265536543320525
Trained batch 11 in epoch 15, gen_loss = 0.8294498572746912, disc_loss = 0.06068966894720992
Trained batch 12 in epoch 15, gen_loss = 0.8157347028072064, disc_loss = 0.05946784738737803
Trained batch 13 in epoch 15, gen_loss = 0.8390151475157056, disc_loss = 0.05676570973758187
Trained batch 14 in epoch 15, gen_loss = 0.8339289228121439, disc_loss = 0.05423460192978382
Trained batch 15 in epoch 15, gen_loss = 0.8241987116634846, disc_loss = 0.058214983320795
Trained batch 16 in epoch 15, gen_loss = 0.8223826534607831, disc_loss = 0.05836978740990162
Trained batch 17 in epoch 15, gen_loss = 0.8090106546878815, disc_loss = 0.061455767705208726
Trained batch 18 in epoch 15, gen_loss = 0.8221895914328726, disc_loss = 0.0636642882110257
Trained batch 19 in epoch 15, gen_loss = 0.8291842460632324, disc_loss = 0.06112642344087362
Trained batch 20 in epoch 15, gen_loss = 0.83104331720443, disc_loss = 0.0596264966187023
Trained batch 21 in epoch 15, gen_loss = 0.8324661471626975, disc_loss = 0.057912968268448654
Trained batch 22 in epoch 15, gen_loss = 0.8234462556631669, disc_loss = 0.05950532610649648
Trained batch 23 in epoch 15, gen_loss = 0.8240523214141527, disc_loss = 0.058468679431825876
Trained batch 24 in epoch 15, gen_loss = 0.8483445715904235, disc_loss = 0.06097641333937645
Trained batch 25 in epoch 15, gen_loss = 0.8521659144988427, disc_loss = 0.05924138398124622
Trained batch 26 in epoch 15, gen_loss = 0.855915124769564, disc_loss = 0.05736564199819609
Trained batch 27 in epoch 15, gen_loss = 0.8486940498862948, disc_loss = 0.05802663325864289
Trained batch 28 in epoch 15, gen_loss = 0.8435535985848, disc_loss = 0.057331780710353934
Trained batch 29 in epoch 15, gen_loss = 0.8535859207312266, disc_loss = 0.0571412304105858
Trained batch 30 in epoch 15, gen_loss = 0.8525784573247356, disc_loss = 0.05626283486884448
Trained batch 31 in epoch 15, gen_loss = 0.8490727450698614, disc_loss = 0.05713106525945477
Trained batch 32 in epoch 15, gen_loss = 0.8478780063715848, disc_loss = 0.05652109654902509
Trained batch 33 in epoch 15, gen_loss = 0.8489462575491737, disc_loss = 0.059374733088428486
Trained batch 34 in epoch 15, gen_loss = 0.8462256142071315, disc_loss = 0.05960674230009318
Trained batch 35 in epoch 15, gen_loss = 0.8557823614941703, disc_loss = 0.05944326569119261
Trained batch 36 in epoch 15, gen_loss = 0.8508129635372678, disc_loss = 0.05923273844795453
Trained batch 37 in epoch 15, gen_loss = 0.8448780931924519, disc_loss = 0.05871420429627362
Trained batch 38 in epoch 15, gen_loss = 0.8389596052658863, disc_loss = 0.05897911444592934
Trained batch 39 in epoch 15, gen_loss = 0.8388584777712822, disc_loss = 0.05911553220357746
Trained batch 40 in epoch 15, gen_loss = 0.8403061555653084, disc_loss = 0.059704102916506734
Trained batch 41 in epoch 15, gen_loss = 0.8407806072916303, disc_loss = 0.05870375301068028
Trained batch 42 in epoch 15, gen_loss = 0.8343530422033265, disc_loss = 0.059965265156744524
Trained batch 43 in epoch 15, gen_loss = 0.8318777626210992, disc_loss = 0.05993506606583568
Trained batch 44 in epoch 15, gen_loss = 0.8394212431377834, disc_loss = 0.06206416775368982
Trained batch 45 in epoch 15, gen_loss = 0.8465798419454823, disc_loss = 0.06281193011723783
Trained batch 46 in epoch 15, gen_loss = 0.8377991952794663, disc_loss = 0.06543414062879821
Trained batch 47 in epoch 15, gen_loss = 0.8364702301720778, disc_loss = 0.064827491742714
Trained batch 48 in epoch 15, gen_loss = 0.8332146977891728, disc_loss = 0.06488029801343777
Trained batch 49 in epoch 15, gen_loss = 0.8332948470115662, disc_loss = 0.06461911028251052
Trained batch 50 in epoch 15, gen_loss = 0.8365031141860813, disc_loss = 0.06473668363383588
Trained batch 51 in epoch 15, gen_loss = 0.8334006884923348, disc_loss = 0.06544925120229331
Trained batch 52 in epoch 15, gen_loss = 0.8326225415715631, disc_loss = 0.06511971528448586
Trained batch 53 in epoch 15, gen_loss = 0.8342935222166555, disc_loss = 0.06444803257990214
Trained batch 54 in epoch 15, gen_loss = 0.8326143026351929, disc_loss = 0.06386992922899398
Trained batch 55 in epoch 15, gen_loss = 0.8344463684729168, disc_loss = 0.063434982722226
Trained batch 56 in epoch 15, gen_loss = 0.8319768142281917, disc_loss = 0.06324456643574593
Trained batch 57 in epoch 15, gen_loss = 0.8315075687293348, disc_loss = 0.0627768477585552
Trained batch 58 in epoch 15, gen_loss = 0.8359656505665537, disc_loss = 0.06345031585670628
Trained batch 59 in epoch 15, gen_loss = 0.8356740961472193, disc_loss = 0.06297609543738265
Trained batch 60 in epoch 15, gen_loss = 0.8352660673563598, disc_loss = 0.06252546435924339
Trained batch 61 in epoch 15, gen_loss = 0.8338239865918313, disc_loss = 0.06269428444906108
Trained batch 62 in epoch 15, gen_loss = 0.8318880408529251, disc_loss = 0.06238538705344711
Trained batch 63 in epoch 15, gen_loss = 0.8340409575030208, disc_loss = 0.06222972057003062
Trained batch 64 in epoch 15, gen_loss = 0.835019393150623, disc_loss = 0.06170994961777559
Trained batch 65 in epoch 15, gen_loss = 0.8320694583835024, disc_loss = 0.06303233880493225
Trained batch 66 in epoch 15, gen_loss = 0.8322018118047002, disc_loss = 0.06288653974935635
Trained batch 67 in epoch 15, gen_loss = 0.8287451968473547, disc_loss = 0.06400613384047414
Trained batch 68 in epoch 15, gen_loss = 0.830772446549457, disc_loss = 0.0646185628340944
Trained batch 69 in epoch 15, gen_loss = 0.8290507614612579, disc_loss = 0.06485019354149699
Trained batch 70 in epoch 15, gen_loss = 0.8311919511204034, disc_loss = 0.0646444550308753
Trained batch 71 in epoch 15, gen_loss = 0.8302194666531351, disc_loss = 0.06488466341721101
Trained batch 72 in epoch 15, gen_loss = 0.8314710006321946, disc_loss = 0.06483469675103687
Trained batch 73 in epoch 15, gen_loss = 0.8302604161404274, disc_loss = 0.06435618266412937
Trained batch 74 in epoch 15, gen_loss = 0.8305237507820129, disc_loss = 0.06389200303703546
Trained batch 75 in epoch 15, gen_loss = 0.8346157238671654, disc_loss = 0.06338286783399158
Trained batch 76 in epoch 15, gen_loss = 0.8339333340719148, disc_loss = 0.0629218201479548
Trained batch 77 in epoch 15, gen_loss = 0.834368572021142, disc_loss = 0.06265803064721134
Trained batch 78 in epoch 15, gen_loss = 0.8340528637548036, disc_loss = 0.06319560526716936
Trained batch 79 in epoch 15, gen_loss = 0.8378832526504993, disc_loss = 0.06285799347097054
Trained batch 80 in epoch 15, gen_loss = 0.8340387248698576, disc_loss = 0.06362654228499275
Trained batch 81 in epoch 15, gen_loss = 0.8325841383236211, disc_loss = 0.06347078740278758
Trained batch 82 in epoch 15, gen_loss = 0.838215585214546, disc_loss = 0.06630096486937928
Trained batch 83 in epoch 15, gen_loss = 0.833444662746929, disc_loss = 0.06744634414402147
Trained batch 84 in epoch 15, gen_loss = 0.8322852253913879, disc_loss = 0.06718410416780149
Trained batch 85 in epoch 15, gen_loss = 0.8346864449423413, disc_loss = 0.06672422653930478
Trained batch 86 in epoch 15, gen_loss = 0.8353658626819479, disc_loss = 0.0663162514503146
Trained batch 87 in epoch 15, gen_loss = 0.833504549481652, disc_loss = 0.0664538485527208
Trained batch 88 in epoch 15, gen_loss = 0.8353136268894324, disc_loss = 0.06601485849640677
Trained batch 89 in epoch 15, gen_loss = 0.8374123573303223, disc_loss = 0.0658835199661553
Trained batch 90 in epoch 15, gen_loss = 0.8361192181870177, disc_loss = 0.06579801838353767
Trained batch 91 in epoch 15, gen_loss = 0.8369836917389994, disc_loss = 0.06518983404638003
Trained batch 92 in epoch 15, gen_loss = 0.8375294189299306, disc_loss = 0.06459474154016985
Trained batch 93 in epoch 15, gen_loss = 0.8391550836410928, disc_loss = 0.06410858604779586
Trained batch 94 in epoch 15, gen_loss = 0.8401057801748577, disc_loss = 0.06387619037965411
Trained batch 95 in epoch 15, gen_loss = 0.8411646156261364, disc_loss = 0.0634530750006282
Trained batch 96 in epoch 15, gen_loss = 0.842000283531307, disc_loss = 0.06288090199424126
Trained batch 97 in epoch 15, gen_loss = 0.8422142978833647, disc_loss = 0.06242112611059328
Trained batch 98 in epoch 15, gen_loss = 0.8430119530119077, disc_loss = 0.06197888499144653
Trained batch 99 in epoch 15, gen_loss = 0.8432338958978653, disc_loss = 0.06168051415123046
Trained batch 100 in epoch 15, gen_loss = 0.8432077753661883, disc_loss = 0.06142378562489654
Trained batch 101 in epoch 15, gen_loss = 0.8433643491829143, disc_loss = 0.06093586406980952
Trained batch 102 in epoch 15, gen_loss = 0.844243248110836, disc_loss = 0.060453995564970574
Trained batch 103 in epoch 15, gen_loss = 0.8442744561112844, disc_loss = 0.06047922380877516
Trained batch 104 in epoch 15, gen_loss = 0.8424032160214016, disc_loss = 0.060766299148755414
Trained batch 105 in epoch 15, gen_loss = 0.8457810603222757, disc_loss = 0.06067391644003538
Trained batch 106 in epoch 15, gen_loss = 0.8437746768799897, disc_loss = 0.061010535397331846
Trained batch 107 in epoch 15, gen_loss = 0.8436123629411062, disc_loss = 0.06070829899464217
Trained batch 108 in epoch 15, gen_loss = 0.8449656777425644, disc_loss = 0.060695094449462694
Trained batch 109 in epoch 15, gen_loss = 0.8443180517716842, disc_loss = 0.060632764810526915
Trained batch 110 in epoch 15, gen_loss = 0.8446337537722545, disc_loss = 0.060309103690087795
Trained batch 111 in epoch 15, gen_loss = 0.8442277599658284, disc_loss = 0.06015859681480963
Trained batch 112 in epoch 15, gen_loss = 0.8445076225078212, disc_loss = 0.05997798098168806
Trained batch 113 in epoch 15, gen_loss = 0.8465595318560015, disc_loss = 0.05964440330372829
Trained batch 114 in epoch 15, gen_loss = 0.8472582589025083, disc_loss = 0.05972782166917687
Trained batch 115 in epoch 15, gen_loss = 0.8456256939419384, disc_loss = 0.06008192942606221
Trained batch 116 in epoch 15, gen_loss = 0.8441667429402343, disc_loss = 0.059878533347868
Trained batch 117 in epoch 15, gen_loss = 0.8454791059938528, disc_loss = 0.059656924939067185
Trained batch 118 in epoch 15, gen_loss = 0.8454509267286092, disc_loss = 0.05985955375113657
Trained batch 119 in epoch 15, gen_loss = 0.8456600462396939, disc_loss = 0.05966319191114356
Trained batch 120 in epoch 15, gen_loss = 0.8458131674892646, disc_loss = 0.059488300426501384
Trained batch 121 in epoch 15, gen_loss = 0.8452496904818738, disc_loss = 0.05927209706488447
Trained batch 122 in epoch 15, gen_loss = 0.8436040514852943, disc_loss = 0.05985229605490842
Trained batch 123 in epoch 15, gen_loss = 0.8454709182823857, disc_loss = 0.061236119956799576
Trained batch 124 in epoch 15, gen_loss = 0.8458789763450623, disc_loss = 0.06085537722706795
Trained batch 125 in epoch 15, gen_loss = 0.8460024235740541, disc_loss = 0.06070075491591105
Trained batch 126 in epoch 15, gen_loss = 0.8460430911206823, disc_loss = 0.06045328350517693
Trained batch 127 in epoch 15, gen_loss = 0.8456918294541538, disc_loss = 0.060460232285549864
Trained batch 128 in epoch 15, gen_loss = 0.8444268671117088, disc_loss = 0.06185781121138455
Trained batch 129 in epoch 15, gen_loss = 0.843738087782493, disc_loss = 0.061610934826043934
Trained batch 130 in epoch 15, gen_loss = 0.843646673300794, disc_loss = 0.06162322329655858
Trained batch 131 in epoch 15, gen_loss = 0.8448712423895345, disc_loss = 0.061302878174253485
Trained batch 132 in epoch 15, gen_loss = 0.8441334299575117, disc_loss = 0.061168841611509935
Trained batch 133 in epoch 15, gen_loss = 0.8450318201264339, disc_loss = 0.06093723090615735
Trained batch 134 in epoch 15, gen_loss = 0.8430128901093095, disc_loss = 0.06142427929573589
Trained batch 135 in epoch 15, gen_loss = 0.8418664493981529, disc_loss = 0.06168812620179618
Trained batch 136 in epoch 15, gen_loss = 0.8416029197456193, disc_loss = 0.06302814650600844
Trained batch 137 in epoch 15, gen_loss = 0.842538627161496, disc_loss = 0.0626437483233926
Trained batch 138 in epoch 15, gen_loss = 0.8406274507371642, disc_loss = 0.06284727456999555
Trained batch 139 in epoch 15, gen_loss = 0.842048100914274, disc_loss = 0.06373560525077794
Trained batch 140 in epoch 15, gen_loss = 0.8411095438274085, disc_loss = 0.06406743412982699
Trained batch 141 in epoch 15, gen_loss = 0.8426456040060016, disc_loss = 0.06434235281743844
Trained batch 142 in epoch 15, gen_loss = 0.8422891343390191, disc_loss = 0.06461091902940631
Trained batch 143 in epoch 15, gen_loss = 0.839646889310744, disc_loss = 0.06634977532990484
Trained batch 144 in epoch 15, gen_loss = 0.8399758850706035, disc_loss = 0.06602127485876454
Trained batch 145 in epoch 15, gen_loss = 0.8407364640742132, disc_loss = 0.06665152082321783
Trained batch 146 in epoch 15, gen_loss = 0.840421526407709, disc_loss = 0.066502772353995
Trained batch 147 in epoch 15, gen_loss = 0.8396246334588205, disc_loss = 0.06682658762469687
Trained batch 148 in epoch 15, gen_loss = 0.8384562656783418, disc_loss = 0.06710238872883503
Trained batch 149 in epoch 15, gen_loss = 0.8402841899792354, disc_loss = 0.06693052429084977
Trained batch 150 in epoch 15, gen_loss = 0.8397182903147691, disc_loss = 0.06685664517718633
Trained batch 151 in epoch 15, gen_loss = 0.8388878885460528, disc_loss = 0.06684764850222946
Trained batch 152 in epoch 15, gen_loss = 0.8379824514092963, disc_loss = 0.06682277605351475
Trained batch 153 in epoch 15, gen_loss = 0.8377876469454208, disc_loss = 0.06651959063291743
Trained batch 154 in epoch 15, gen_loss = 0.8379535850017301, disc_loss = 0.0671952739658375
Trained batch 155 in epoch 15, gen_loss = 0.8356064987870363, disc_loss = 0.06830620563302475
Trained batch 156 in epoch 15, gen_loss = 0.8354609788982732, disc_loss = 0.06836095099355195
Trained batch 157 in epoch 15, gen_loss = 0.8362882772955713, disc_loss = 0.06853321853058436
Trained batch 158 in epoch 15, gen_loss = 0.8353972575574551, disc_loss = 0.06846878226002995
Trained batch 159 in epoch 15, gen_loss = 0.834800804592669, disc_loss = 0.06826347662718035
Trained batch 160 in epoch 15, gen_loss = 0.8341076731311609, disc_loss = 0.06814824211879732
Trained batch 161 in epoch 15, gen_loss = 0.8343192322386636, disc_loss = 0.06794290528000321
Trained batch 162 in epoch 15, gen_loss = 0.8351212602817207, disc_loss = 0.06807881569135592
Trained batch 163 in epoch 15, gen_loss = 0.8351697458363161, disc_loss = 0.06785500315926606
Trained batch 164 in epoch 15, gen_loss = 0.8334178879405513, disc_loss = 0.06807213451035998
Trained batch 165 in epoch 15, gen_loss = 0.8339268721370812, disc_loss = 0.06783926141930811
Trained batch 166 in epoch 15, gen_loss = 0.8336889652791851, disc_loss = 0.06763853744497735
Trained batch 167 in epoch 15, gen_loss = 0.8341149285080887, disc_loss = 0.0678163460466922
Trained batch 168 in epoch 15, gen_loss = 0.8353510419645253, disc_loss = 0.06749132751713138
Trained batch 169 in epoch 15, gen_loss = 0.8351274246678633, disc_loss = 0.0672409141984056
Trained batch 170 in epoch 15, gen_loss = 0.8344511304333894, disc_loss = 0.06726129233227139
Trained batch 171 in epoch 15, gen_loss = 0.8335547539037328, disc_loss = 0.06722512016029553
Trained batch 172 in epoch 15, gen_loss = 0.8350092146782516, disc_loss = 0.0681801910991269
Trained batch 173 in epoch 15, gen_loss = 0.8360958457335659, disc_loss = 0.06786951614308288
Trained batch 174 in epoch 15, gen_loss = 0.8352331922735486, disc_loss = 0.06833350338041783
Trained batch 175 in epoch 15, gen_loss = 0.8337371869182045, disc_loss = 0.06845302882985296
Trained batch 176 in epoch 15, gen_loss = 0.8337051186521175, disc_loss = 0.06880917390650612
Trained batch 177 in epoch 15, gen_loss = 0.833593980482455, disc_loss = 0.06875055792919371
Trained batch 178 in epoch 15, gen_loss = 0.8323798084725215, disc_loss = 0.06883852728044187
Trained batch 179 in epoch 15, gen_loss = 0.8319099679589271, disc_loss = 0.06860854167284237
Trained batch 180 in epoch 15, gen_loss = 0.8337190383376337, disc_loss = 0.06895155971098012
Trained batch 181 in epoch 15, gen_loss = 0.8329625128062217, disc_loss = 0.06880266466024486
Trained batch 182 in epoch 15, gen_loss = 0.8325196620219392, disc_loss = 0.06863865835459831
Trained batch 183 in epoch 15, gen_loss = 0.8337768774641596, disc_loss = 0.06902091424790738
Trained batch 184 in epoch 15, gen_loss = 0.8329158542929469, disc_loss = 0.0691191682239642
Trained batch 185 in epoch 15, gen_loss = 0.8316651481774545, disc_loss = 0.06953929125341357
Trained batch 186 in epoch 15, gen_loss = 0.8323725093813503, disc_loss = 0.069691560734163
Trained batch 187 in epoch 15, gen_loss = 0.8319896705290104, disc_loss = 0.06956925824720492
Trained batch 188 in epoch 15, gen_loss = 0.8322967175768796, disc_loss = 0.0692732633392095
Trained batch 189 in epoch 15, gen_loss = 0.831902804343324, disc_loss = 0.06908315389270062
Trained batch 190 in epoch 15, gen_loss = 0.8324939975251702, disc_loss = 0.06897147482075773
Trained batch 191 in epoch 15, gen_loss = 0.8328440060528616, disc_loss = 0.06876363662983447
Trained batch 192 in epoch 15, gen_loss = 0.8316306155271481, disc_loss = 0.06883859684102121
Trained batch 193 in epoch 15, gen_loss = 0.83069687851311, disc_loss = 0.0688365420528217
Trained batch 194 in epoch 15, gen_loss = 0.8308901494894272, disc_loss = 0.06869665414381486
Trained batch 195 in epoch 15, gen_loss = 0.83074551592676, disc_loss = 0.06869921863212117
Trained batch 196 in epoch 15, gen_loss = 0.8302922298763004, disc_loss = 0.06864068807967877
Trained batch 197 in epoch 15, gen_loss = 0.8289681292242475, disc_loss = 0.0687733733923071
Trained batch 198 in epoch 15, gen_loss = 0.8292717372053232, disc_loss = 0.06859329072805355
Trained batch 199 in epoch 15, gen_loss = 0.8286662064492702, disc_loss = 0.06874506026040762
Trained batch 200 in epoch 15, gen_loss = 0.8300488948525481, disc_loss = 0.06850626755654071
Trained batch 201 in epoch 15, gen_loss = 0.8300550593302982, disc_loss = 0.06850797729566693
Trained batch 202 in epoch 15, gen_loss = 0.8292860334436295, disc_loss = 0.06840671425033819
Trained batch 203 in epoch 15, gen_loss = 0.8280716452236269, disc_loss = 0.0684579786360629
Trained batch 204 in epoch 15, gen_loss = 0.8299596625130351, disc_loss = 0.06856815515585789
Trained batch 205 in epoch 15, gen_loss = 0.8298790971341642, disc_loss = 0.06872862568848485
Trained batch 206 in epoch 15, gen_loss = 0.8292906919251317, disc_loss = 0.0690907763839128
Trained batch 207 in epoch 15, gen_loss = 0.8304531174496963, disc_loss = 0.06905395156578518
Trained batch 208 in epoch 15, gen_loss = 0.8306545411285601, disc_loss = 0.06924596570129173
Trained batch 209 in epoch 15, gen_loss = 0.8296004574923288, disc_loss = 0.06982127582831751
Trained batch 210 in epoch 15, gen_loss = 0.8296182518604243, disc_loss = 0.07033757228510217
Trained batch 211 in epoch 15, gen_loss = 0.8299958459892363, disc_loss = 0.07027924660470267
Trained batch 212 in epoch 15, gen_loss = 0.828950930229375, disc_loss = 0.07050151016318322
Trained batch 213 in epoch 15, gen_loss = 0.8286784387358995, disc_loss = 0.07049881206024612
Trained batch 214 in epoch 15, gen_loss = 0.8281145976033322, disc_loss = 0.07051939581802417
Trained batch 215 in epoch 15, gen_loss = 0.8290220801201131, disc_loss = 0.07077285646098769
Trained batch 216 in epoch 15, gen_loss = 0.8279663427359497, disc_loss = 0.07097895308247497
Trained batch 217 in epoch 15, gen_loss = 0.827635632058896, disc_loss = 0.07098922450009973
Trained batch 218 in epoch 15, gen_loss = 0.8267110905962992, disc_loss = 0.07114154133163222
Trained batch 219 in epoch 15, gen_loss = 0.827184961465272, disc_loss = 0.07099399734711782
Trained batch 220 in epoch 15, gen_loss = 0.8274844549090614, disc_loss = 0.0712322503606456
Trained batch 221 in epoch 15, gen_loss = 0.8268566186632123, disc_loss = 0.07115540363582538
Trained batch 222 in epoch 15, gen_loss = 0.8265963665840337, disc_loss = 0.07106432310752403
Trained batch 223 in epoch 15, gen_loss = 0.8269294315416899, disc_loss = 0.07085838927637919
Trained batch 224 in epoch 15, gen_loss = 0.827397450208664, disc_loss = 0.07130714178499248
Trained batch 225 in epoch 15, gen_loss = 0.8262126998300046, disc_loss = 0.07190649165664759
Trained batch 226 in epoch 15, gen_loss = 0.8255642861259141, disc_loss = 0.07182145895362557
Trained batch 227 in epoch 15, gen_loss = 0.8259604629455951, disc_loss = 0.0720181901277484
Trained batch 228 in epoch 15, gen_loss = 0.8251170584988906, disc_loss = 0.07200423974999304
Trained batch 229 in epoch 15, gen_loss = 0.8244809058697328, disc_loss = 0.07202446660350846
Trained batch 230 in epoch 15, gen_loss = 0.8251380694634987, disc_loss = 0.07218981084708141
Trained batch 231 in epoch 15, gen_loss = 0.8254110059090729, disc_loss = 0.0724665266180668
Trained batch 232 in epoch 15, gen_loss = 0.8247996907633262, disc_loss = 0.07238127587387107
Trained batch 233 in epoch 15, gen_loss = 0.8237434744070737, disc_loss = 0.07295772772775884
Trained batch 234 in epoch 15, gen_loss = 0.8240932146285442, disc_loss = 0.07394678043003412
Trained batch 235 in epoch 15, gen_loss = 0.824362375347291, disc_loss = 0.0739757841239857
Trained batch 236 in epoch 15, gen_loss = 0.8235300742875674, disc_loss = 0.074030078810007
Trained batch 237 in epoch 15, gen_loss = 0.823715447252538, disc_loss = 0.07387363560450803
Trained batch 238 in epoch 15, gen_loss = 0.823099577651363, disc_loss = 0.0741417759047455
Trained batch 239 in epoch 15, gen_loss = 0.8218661734213432, disc_loss = 0.0748666888762576
Trained batch 240 in epoch 15, gen_loss = 0.821774450946151, disc_loss = 0.07479393253821678
Trained batch 241 in epoch 15, gen_loss = 0.8237967169728161, disc_loss = 0.07552184996172047
Trained batch 242 in epoch 15, gen_loss = 0.8236137818652416, disc_loss = 0.07533864254982751
Trained batch 243 in epoch 15, gen_loss = 0.8231636748694983, disc_loss = 0.07518207086021172
Trained batch 244 in epoch 15, gen_loss = 0.8231905746216677, disc_loss = 0.0751103989285778
Trained batch 245 in epoch 15, gen_loss = 0.8233611349894748, disc_loss = 0.07502973485147445
Trained batch 246 in epoch 15, gen_loss = 0.8242913020043238, disc_loss = 0.07530144580568258
Trained batch 247 in epoch 15, gen_loss = 0.8230401800284463, disc_loss = 0.07580229964092254
Trained batch 248 in epoch 15, gen_loss = 0.823048096464341, disc_loss = 0.07581242457795215
Trained batch 249 in epoch 15, gen_loss = 0.8223210946321488, disc_loss = 0.07587712129577995
Trained batch 250 in epoch 15, gen_loss = 0.8229124466499009, disc_loss = 0.07622001640335378
Trained batch 251 in epoch 15, gen_loss = 0.8216395327259624, disc_loss = 0.07676677053631653
Trained batch 252 in epoch 15, gen_loss = 0.8219907021098457, disc_loss = 0.07662583092087696
Trained batch 253 in epoch 15, gen_loss = 0.8229407734992936, disc_loss = 0.07644682019347633
Trained batch 254 in epoch 15, gen_loss = 0.8220400325223511, disc_loss = 0.07661573705354742
Trained batch 255 in epoch 15, gen_loss = 0.8225192696554586, disc_loss = 0.07647714357517543
Trained batch 256 in epoch 15, gen_loss = 0.8223253911803204, disc_loss = 0.07654446010851094
Trained batch 257 in epoch 15, gen_loss = 0.8228899403366932, disc_loss = 0.07635918966776063
Trained batch 258 in epoch 15, gen_loss = 0.8224666188812624, disc_loss = 0.07628706617920901
Trained batch 259 in epoch 15, gen_loss = 0.8234701795073656, disc_loss = 0.07651275868814152
Trained batch 260 in epoch 15, gen_loss = 0.8227702999252012, disc_loss = 0.0766973583084813
Trained batch 261 in epoch 15, gen_loss = 0.823561716056962, disc_loss = 0.07677519912582659
Trained batch 262 in epoch 15, gen_loss = 0.8233075235959695, disc_loss = 0.07663309194161752
Trained batch 263 in epoch 15, gen_loss = 0.8231720756174941, disc_loss = 0.07674255851077649
Trained batch 264 in epoch 15, gen_loss = 0.8224575671384919, disc_loss = 0.07667432519835683
Trained batch 265 in epoch 15, gen_loss = 0.8222807521434655, disc_loss = 0.0764664943133922
Trained batch 266 in epoch 15, gen_loss = 0.8231853310311779, disc_loss = 0.07701912750786498
Trained batch 267 in epoch 15, gen_loss = 0.8221716159092847, disc_loss = 0.07736771114156651
Trained batch 268 in epoch 15, gen_loss = 0.822605562365188, disc_loss = 0.07714766313470761
Trained batch 269 in epoch 15, gen_loss = 0.8229281905624601, disc_loss = 0.07699840722467613
Trained batch 270 in epoch 15, gen_loss = 0.8224610775379237, disc_loss = 0.07696220809009573
Trained batch 271 in epoch 15, gen_loss = 0.8230008394183481, disc_loss = 0.07674893537906054
Trained batch 272 in epoch 15, gen_loss = 0.8235719604588254, disc_loss = 0.07650847462493748
Trained batch 273 in epoch 15, gen_loss = 0.8236910458246287, disc_loss = 0.07658353520992355
Trained batch 274 in epoch 15, gen_loss = 0.8233664921197025, disc_loss = 0.07650904632088813
Trained batch 275 in epoch 15, gen_loss = 0.8231948701583821, disc_loss = 0.07634377514983973
Trained batch 276 in epoch 15, gen_loss = 0.8239735985705999, disc_loss = 0.07614152277702137
Trained batch 277 in epoch 15, gen_loss = 0.8243280215014657, disc_loss = 0.0759750392468874
Trained batch 278 in epoch 15, gen_loss = 0.8243370059356895, disc_loss = 0.07584047079500225
Trained batch 279 in epoch 15, gen_loss = 0.8247179609324251, disc_loss = 0.07578190595377236
Trained batch 280 in epoch 15, gen_loss = 0.8245417508578385, disc_loss = 0.07574193514684659
Trained batch 281 in epoch 15, gen_loss = 0.824780395584749, disc_loss = 0.07557463625789429
Trained batch 282 in epoch 15, gen_loss = 0.8253739148694298, disc_loss = 0.07541469406573491
Trained batch 283 in epoch 15, gen_loss = 0.8264262230253555, disc_loss = 0.07523900253081721
Trained batch 284 in epoch 15, gen_loss = 0.8259734562614508, disc_loss = 0.07522731196919555
Trained batch 285 in epoch 15, gen_loss = 0.8262161428069735, disc_loss = 0.07523191202809656
Trained batch 286 in epoch 15, gen_loss = 0.8265365859565004, disc_loss = 0.07511571166186694
Trained batch 287 in epoch 15, gen_loss = 0.8265121064873205, disc_loss = 0.07500896916867027
Trained batch 288 in epoch 15, gen_loss = 0.8259889067869285, disc_loss = 0.07528560336318292
Trained batch 289 in epoch 15, gen_loss = 0.8251212530095001, disc_loss = 0.07531448693560629
Trained batch 290 in epoch 15, gen_loss = 0.8266634214989508, disc_loss = 0.0753278125851988
Trained batch 291 in epoch 15, gen_loss = 0.8268044124523254, disc_loss = 0.07521773225066494
Trained batch 292 in epoch 15, gen_loss = 0.8262885909641969, disc_loss = 0.0752465513983023
Trained batch 293 in epoch 15, gen_loss = 0.8262463219109035, disc_loss = 0.07507145659187112
Trained batch 294 in epoch 15, gen_loss = 0.8261776842303196, disc_loss = 0.0750958330645147
Trained batch 295 in epoch 15, gen_loss = 0.8264023282036588, disc_loss = 0.07495132545198037
Trained batch 296 in epoch 15, gen_loss = 0.8256541748440226, disc_loss = 0.07524019724027778
Trained batch 297 in epoch 15, gen_loss = 0.8267449745595855, disc_loss = 0.07511720119744239
Trained batch 298 in epoch 15, gen_loss = 0.8275829662248043, disc_loss = 0.07512508271367953
Trained batch 299 in epoch 15, gen_loss = 0.8275623884797096, disc_loss = 0.07492438906493286
Trained batch 300 in epoch 15, gen_loss = 0.8264774948457547, disc_loss = 0.07510047100571006
Trained batch 301 in epoch 15, gen_loss = 0.8264998727484255, disc_loss = 0.07505230313561709
Trained batch 302 in epoch 15, gen_loss = 0.8271789897983224, disc_loss = 0.07483985908513907
Trained batch 303 in epoch 15, gen_loss = 0.8272370097080344, disc_loss = 0.07472990832205764
Trained batch 304 in epoch 15, gen_loss = 0.8267820777463131, disc_loss = 0.07480053529448685
Trained batch 305 in epoch 15, gen_loss = 0.8278889699893839, disc_loss = 0.07558032791465034
Trained batch 306 in epoch 15, gen_loss = 0.8277133011080154, disc_loss = 0.07558820407886167
Trained batch 307 in epoch 15, gen_loss = 0.828177068430882, disc_loss = 0.07538659726390494
Trained batch 308 in epoch 15, gen_loss = 0.8281201192669112, disc_loss = 0.07529629717210254
Trained batch 309 in epoch 15, gen_loss = 0.8275116396527137, disc_loss = 0.07529616921599354
Trained batch 310 in epoch 15, gen_loss = 0.8275488840230408, disc_loss = 0.07521400764476735
Trained batch 311 in epoch 15, gen_loss = 0.8268434148377333, disc_loss = 0.07520894604460455
Trained batch 312 in epoch 15, gen_loss = 0.827694974673061, disc_loss = 0.07502083967442806
Trained batch 313 in epoch 15, gen_loss = 0.8275348603915257, disc_loss = 0.07492154000540542
Trained batch 314 in epoch 15, gen_loss = 0.8274807936615414, disc_loss = 0.0748419971367906
Trained batch 315 in epoch 15, gen_loss = 0.827550516381294, disc_loss = 0.07463427862046357
Trained batch 316 in epoch 15, gen_loss = 0.8280273483190627, disc_loss = 0.0744375232812781
Trained batch 317 in epoch 15, gen_loss = 0.8283541565233806, disc_loss = 0.07458845645763308
Trained batch 318 in epoch 15, gen_loss = 0.8283819734676504, disc_loss = 0.07451558431032403
Trained batch 319 in epoch 15, gen_loss = 0.8280759482644499, disc_loss = 0.07459376983169932
Trained batch 320 in epoch 15, gen_loss = 0.8281975645699605, disc_loss = 0.07446879739481434
Trained batch 321 in epoch 15, gen_loss = 0.8285984725500486, disc_loss = 0.07447825123769988
Trained batch 322 in epoch 15, gen_loss = 0.8287144765580771, disc_loss = 0.0742959655423421
Trained batch 323 in epoch 15, gen_loss = 0.8281202403667532, disc_loss = 0.07417566762420774
Trained batch 324 in epoch 15, gen_loss = 0.8287633370436155, disc_loss = 0.07400151087974126
Trained batch 325 in epoch 15, gen_loss = 0.8291269265618061, disc_loss = 0.07396467927374814
Trained batch 326 in epoch 15, gen_loss = 0.8284584474308411, disc_loss = 0.07401441551733545
Trained batch 327 in epoch 15, gen_loss = 0.828501765593523, disc_loss = 0.07396813570919288
Trained batch 328 in epoch 15, gen_loss = 0.8288902213689404, disc_loss = 0.07379386582805303
Trained batch 329 in epoch 15, gen_loss = 0.8299197120196892, disc_loss = 0.07385726719812462
Trained batch 330 in epoch 15, gen_loss = 0.8296108608699637, disc_loss = 0.07388303797759588
Trained batch 331 in epoch 15, gen_loss = 0.828501915177667, disc_loss = 0.07425183400859585
Trained batch 332 in epoch 15, gen_loss = 0.8300131976425469, disc_loss = 0.07474701148779453
Trained batch 333 in epoch 15, gen_loss = 0.8293377462618365, disc_loss = 0.07472878551489846
Trained batch 334 in epoch 15, gen_loss = 0.8293462587826288, disc_loss = 0.07467328460970477
Trained batch 335 in epoch 15, gen_loss = 0.8292081283316726, disc_loss = 0.07468033705871287
Trained batch 336 in epoch 15, gen_loss = 0.8296309532680568, disc_loss = 0.07507690543844986
Trained batch 337 in epoch 15, gen_loss = 0.8291158203542586, disc_loss = 0.07516360915260467
Trained batch 338 in epoch 15, gen_loss = 0.8285469706431251, disc_loss = 0.07537149167331182
Trained batch 339 in epoch 15, gen_loss = 0.8289160386604422, disc_loss = 0.07603315489421435
Trained batch 340 in epoch 15, gen_loss = 0.829725127241129, disc_loss = 0.07588057084243931
Trained batch 341 in epoch 15, gen_loss = 0.8293702876010136, disc_loss = 0.0759105558169472
Trained batch 342 in epoch 15, gen_loss = 0.8292809090530907, disc_loss = 0.0757550425344193
Trained batch 343 in epoch 15, gen_loss = 0.8298606576268063, disc_loss = 0.07575494024718483
Trained batch 344 in epoch 15, gen_loss = 0.8292858374291572, disc_loss = 0.07576397549145032
Trained batch 345 in epoch 15, gen_loss = 0.8288704215446648, disc_loss = 0.07562977388619602
Trained batch 346 in epoch 15, gen_loss = 0.8290569139832379, disc_loss = 0.07589953045712339
Trained batch 347 in epoch 15, gen_loss = 0.8299342863176061, disc_loss = 0.07576303883327236
Trained batch 348 in epoch 15, gen_loss = 0.8296507403980353, disc_loss = 0.07570734969406978
Trained batch 349 in epoch 15, gen_loss = 0.8287331541946956, disc_loss = 0.0760164541352008
Trained batch 350 in epoch 15, gen_loss = 0.8298551311180462, disc_loss = 0.07611182840684286
Trained batch 351 in epoch 15, gen_loss = 0.8296368394724347, disc_loss = 0.07604491572287357
Trained batch 352 in epoch 15, gen_loss = 0.8300605392658676, disc_loss = 0.07618977595120668
Trained batch 353 in epoch 15, gen_loss = 0.82952190068482, disc_loss = 0.07621302040251719
Trained batch 354 in epoch 15, gen_loss = 0.8291401303989786, disc_loss = 0.07613194894675218
Trained batch 355 in epoch 15, gen_loss = 0.8285887415489454, disc_loss = 0.07614255990843509
Trained batch 356 in epoch 15, gen_loss = 0.8293366993174833, disc_loss = 0.07609506714462984
Trained batch 357 in epoch 15, gen_loss = 0.8293476767380145, disc_loss = 0.07597443094352187
Trained batch 358 in epoch 15, gen_loss = 0.8294400962946474, disc_loss = 0.07588686351210377
Trained batch 359 in epoch 15, gen_loss = 0.830092540052202, disc_loss = 0.07589783425598094
Trained batch 360 in epoch 15, gen_loss = 0.83042677205025, disc_loss = 0.07580752552350224
Trained batch 361 in epoch 15, gen_loss = 0.8298464932823708, disc_loss = 0.07596920489575405
Trained batch 362 in epoch 15, gen_loss = 0.8300365147183421, disc_loss = 0.07599056650917803
Trained batch 363 in epoch 15, gen_loss = 0.8304251740266989, disc_loss = 0.07585737604269205
Trained batch 364 in epoch 15, gen_loss = 0.8301526819189934, disc_loss = 0.07584555161070743
Trained batch 365 in epoch 15, gen_loss = 0.830631147154042, disc_loss = 0.07576313036458333
Trained batch 366 in epoch 15, gen_loss = 0.8321316623882636, disc_loss = 0.0759349248932842
Trained batch 367 in epoch 15, gen_loss = 0.8316744622652945, disc_loss = 0.07594281228249082
Trained batch 368 in epoch 15, gen_loss = 0.8312948643353574, disc_loss = 0.07601746282512499
Trained batch 369 in epoch 15, gen_loss = 0.831742623851106, disc_loss = 0.07586828899897032
Trained batch 370 in epoch 15, gen_loss = 0.8320739507032533, disc_loss = 0.07594969023942867
Trained batch 371 in epoch 15, gen_loss = 0.8323264022668203, disc_loss = 0.07580811261720154
Trained batch 372 in epoch 15, gen_loss = 0.8324021249610042, disc_loss = 0.0756789160612721
Trained batch 373 in epoch 15, gen_loss = 0.8325045636312209, disc_loss = 0.07596510465202086
Trained batch 374 in epoch 15, gen_loss = 0.8320576146443684, disc_loss = 0.07597516361624003
Trained batch 375 in epoch 15, gen_loss = 0.832000510172641, disc_loss = 0.0758261442001156
Trained batch 376 in epoch 15, gen_loss = 0.8315599246113623, disc_loss = 0.07586646305066126
Trained batch 377 in epoch 15, gen_loss = 0.8314218508503425, disc_loss = 0.07580822091007595
Trained batch 378 in epoch 15, gen_loss = 0.8315656773333184, disc_loss = 0.07588234755866681
Trained batch 379 in epoch 15, gen_loss = 0.8315144987482773, disc_loss = 0.07588053841486965
Trained batch 380 in epoch 15, gen_loss = 0.8313202260360317, disc_loss = 0.0759273175702594
Trained batch 381 in epoch 15, gen_loss = 0.8310513632147724, disc_loss = 0.07592890637619568
Trained batch 382 in epoch 15, gen_loss = 0.831124770890328, disc_loss = 0.07579148204039111
Trained batch 383 in epoch 15, gen_loss = 0.8317766870992879, disc_loss = 0.07568954845434443
Trained batch 384 in epoch 15, gen_loss = 0.8323684904482458, disc_loss = 0.07557256815156767
Trained batch 385 in epoch 15, gen_loss = 0.8330056656518748, disc_loss = 0.075440870759613
Trained batch 386 in epoch 15, gen_loss = 0.8324155978454176, disc_loss = 0.07560676796174096
Trained batch 387 in epoch 15, gen_loss = 0.8324161920043611, disc_loss = 0.07545392378713436
Trained batch 388 in epoch 15, gen_loss = 0.8330001185976141, disc_loss = 0.07545538298584578
Trained batch 389 in epoch 15, gen_loss = 0.8334117770195008, disc_loss = 0.07534756293902413
Trained batch 390 in epoch 15, gen_loss = 0.833268069702646, disc_loss = 0.07528017882657859
Trained batch 391 in epoch 15, gen_loss = 0.8330425886171204, disc_loss = 0.07520870172789282
Trained batch 392 in epoch 15, gen_loss = 0.8329358197957202, disc_loss = 0.07510351048635541
Trained batch 393 in epoch 15, gen_loss = 0.8334963085687705, disc_loss = 0.07505274004525113
Trained batch 394 in epoch 15, gen_loss = 0.8336092829704285, disc_loss = 0.07489870463179636
Trained batch 395 in epoch 15, gen_loss = 0.8333183669983738, disc_loss = 0.07489308128791927
Trained batch 396 in epoch 15, gen_loss = 0.8329964310156008, disc_loss = 0.0747853677804284
Trained batch 397 in epoch 15, gen_loss = 0.8332221572423101, disc_loss = 0.07462274638851683
Trained batch 398 in epoch 15, gen_loss = 0.8340537567485246, disc_loss = 0.07521984518918776
Trained batch 399 in epoch 15, gen_loss = 0.8335913486778737, disc_loss = 0.07539044946432114
Trained batch 400 in epoch 15, gen_loss = 0.8336407343051083, disc_loss = 0.07525542111338077
Trained batch 401 in epoch 15, gen_loss = 0.8341743686602483, disc_loss = 0.07522757516812477
Trained batch 402 in epoch 15, gen_loss = 0.834295253747746, disc_loss = 0.07521722725044852
Trained batch 403 in epoch 15, gen_loss = 0.8338863017535446, disc_loss = 0.07515221268473433
Trained batch 404 in epoch 15, gen_loss = 0.8336016122205758, disc_loss = 0.07505501257140695
Trained batch 405 in epoch 15, gen_loss = 0.8335146164071972, disc_loss = 0.075263307769347
Trained batch 406 in epoch 15, gen_loss = 0.8338762343076289, disc_loss = 0.07510526347630805
Trained batch 407 in epoch 15, gen_loss = 0.8334912161032358, disc_loss = 0.0750334384125274
Trained batch 408 in epoch 15, gen_loss = 0.8333480582552026, disc_loss = 0.07491949178998002
Trained batch 409 in epoch 15, gen_loss = 0.8334597974288754, disc_loss = 0.07476622154027587
Trained batch 410 in epoch 15, gen_loss = 0.8333105549325038, disc_loss = 0.07466185622941476
Trained batch 411 in epoch 15, gen_loss = 0.8335250561098451, disc_loss = 0.074500986822492
Trained batch 412 in epoch 15, gen_loss = 0.8335976486633245, disc_loss = 0.07447842779607663
Trained batch 413 in epoch 15, gen_loss = 0.8338334053610834, disc_loss = 0.07433932984994661
Trained batch 414 in epoch 15, gen_loss = 0.8333292963993119, disc_loss = 0.07438444133892835
Trained batch 415 in epoch 15, gen_loss = 0.8331915942522196, disc_loss = 0.07425012802167867
Trained batch 416 in epoch 15, gen_loss = 0.8334511012482129, disc_loss = 0.07412202357888507
Trained batch 417 in epoch 15, gen_loss = 0.8341160530678964, disc_loss = 0.07403729355149863
Trained batch 418 in epoch 15, gen_loss = 0.8346080390251907, disc_loss = 0.07393188041974935
Trained batch 419 in epoch 15, gen_loss = 0.8348815168653215, disc_loss = 0.0737784668936261
Trained batch 420 in epoch 15, gen_loss = 0.8350659308694037, disc_loss = 0.07365079121022639
Trained batch 421 in epoch 15, gen_loss = 0.8349016793248778, disc_loss = 0.07358937898112275
Trained batch 422 in epoch 15, gen_loss = 0.8346733394525857, disc_loss = 0.07353482478635108
Trained batch 423 in epoch 15, gen_loss = 0.834841973376724, disc_loss = 0.07352903598199054
Trained batch 424 in epoch 15, gen_loss = 0.8352039853264304, disc_loss = 0.07338439449229661
Trained batch 425 in epoch 15, gen_loss = 0.8349976977552047, disc_loss = 0.07337827379312453
Trained batch 426 in epoch 15, gen_loss = 0.8356389448011787, disc_loss = 0.07324182503448856
Trained batch 427 in epoch 15, gen_loss = 0.8356970793732973, disc_loss = 0.07331491541552627
Trained batch 428 in epoch 15, gen_loss = 0.8360939042551534, disc_loss = 0.07316875705682176
Trained batch 429 in epoch 15, gen_loss = 0.8356200988902602, disc_loss = 0.07335306202862844
Trained batch 430 in epoch 15, gen_loss = 0.8360497824277237, disc_loss = 0.0733244768246628
Trained batch 431 in epoch 15, gen_loss = 0.8356618914339278, disc_loss = 0.0733725203640966
Trained batch 432 in epoch 15, gen_loss = 0.8359314431769743, disc_loss = 0.07327552962678271
Trained batch 433 in epoch 15, gen_loss = 0.8361902856332366, disc_loss = 0.07313280580093234
Trained batch 434 in epoch 15, gen_loss = 0.8359723628252402, disc_loss = 0.07305279136046595
Trained batch 435 in epoch 15, gen_loss = 0.8356408091313249, disc_loss = 0.07309036688246859
Trained batch 436 in epoch 15, gen_loss = 0.8369623820896279, disc_loss = 0.0732723239221071
Trained batch 437 in epoch 15, gen_loss = 0.8367242347704221, disc_loss = 0.07335276653369267
Trained batch 438 in epoch 15, gen_loss = 0.8358670083428298, disc_loss = 0.07375952679502665
Trained batch 439 in epoch 15, gen_loss = 0.8363525481386618, disc_loss = 0.07362882464446804
Trained batch 440 in epoch 15, gen_loss = 0.8376260213300485, disc_loss = 0.0737994954226509
Trained batch 441 in epoch 15, gen_loss = 0.8377269780204307, disc_loss = 0.07369724260769549
Trained batch 442 in epoch 15, gen_loss = 0.8371274068985244, disc_loss = 0.07372714445398569
Trained batch 443 in epoch 15, gen_loss = 0.8368757551049327, disc_loss = 0.07373533183960496
Trained batch 444 in epoch 15, gen_loss = 0.8363909389195817, disc_loss = 0.07397144220015976
Trained batch 445 in epoch 15, gen_loss = 0.8368394342773163, disc_loss = 0.07400454556561105
Trained batch 446 in epoch 15, gen_loss = 0.837231463500584, disc_loss = 0.07412305410109643
Trained batch 447 in epoch 15, gen_loss = 0.8368693751149944, disc_loss = 0.07424383360194042
Trained batch 448 in epoch 15, gen_loss = 0.836232007213584, disc_loss = 0.07435964279391187
Trained batch 449 in epoch 15, gen_loss = 0.8359882103072273, disc_loss = 0.07440276108682156
Trained batch 450 in epoch 15, gen_loss = 0.8360474469127782, disc_loss = 0.07442660247308187
Trained batch 451 in epoch 15, gen_loss = 0.8360980244073193, disc_loss = 0.07431723125921809
Trained batch 452 in epoch 15, gen_loss = 0.8356025172911469, disc_loss = 0.07432255370513624
Trained batch 453 in epoch 15, gen_loss = 0.8354567277536519, disc_loss = 0.07428141810935368
Trained batch 454 in epoch 15, gen_loss = 0.8353455709887075, disc_loss = 0.07419870772122682
Trained batch 455 in epoch 15, gen_loss = 0.8351793314019839, disc_loss = 0.07420137653274364
Trained batch 456 in epoch 15, gen_loss = 0.8356836852933437, disc_loss = 0.07421250360522672
Trained batch 457 in epoch 15, gen_loss = 0.835111235817447, disc_loss = 0.07424494164983649
Trained batch 458 in epoch 15, gen_loss = 0.8348210963028968, disc_loss = 0.07415341913359227
Trained batch 459 in epoch 15, gen_loss = 0.8349901029597158, disc_loss = 0.07401770461026741
Trained batch 460 in epoch 15, gen_loss = 0.8350721352012452, disc_loss = 0.0739135884653591
Trained batch 461 in epoch 15, gen_loss = 0.8351748697943502, disc_loss = 0.07378035780139171
Trained batch 462 in epoch 15, gen_loss = 0.835408882368718, disc_loss = 0.07364882230477057
Trained batch 463 in epoch 15, gen_loss = 0.8352830839054338, disc_loss = 0.07360175136549013
Trained batch 464 in epoch 15, gen_loss = 0.835024829064646, disc_loss = 0.073908461712461
Trained batch 465 in epoch 15, gen_loss = 0.8350304778297571, disc_loss = 0.07392854322059791
Trained batch 466 in epoch 15, gen_loss = 0.834285315277745, disc_loss = 0.07412456354321773
Trained batch 467 in epoch 15, gen_loss = 0.8341428414623961, disc_loss = 0.07399165494622201
Trained batch 468 in epoch 15, gen_loss = 0.8341765110172442, disc_loss = 0.07394502973998152
Trained batch 469 in epoch 15, gen_loss = 0.834626844461928, disc_loss = 0.07410455875177967
Trained batch 470 in epoch 15, gen_loss = 0.8342215341620638, disc_loss = 0.0740931830991795
Trained batch 471 in epoch 15, gen_loss = 0.8334113197811579, disc_loss = 0.07425007438366064
Trained batch 472 in epoch 15, gen_loss = 0.8338807150879067, disc_loss = 0.07430042218944613
Trained batch 473 in epoch 15, gen_loss = 0.8336071389636913, disc_loss = 0.07429937763288931
Trained batch 474 in epoch 15, gen_loss = 0.8335030126571655, disc_loss = 0.07420212508032197
Trained batch 475 in epoch 15, gen_loss = 0.8340525850027549, disc_loss = 0.07421814815430831
Trained batch 476 in epoch 15, gen_loss = 0.833932865465712, disc_loss = 0.07413319538911683
Trained batch 477 in epoch 15, gen_loss = 0.8338179819005304, disc_loss = 0.07405408219313522
Trained batch 478 in epoch 15, gen_loss = 0.8338257071867368, disc_loss = 0.07400365741554034
Trained batch 479 in epoch 15, gen_loss = 0.8343778766691685, disc_loss = 0.07394937388598918
Trained batch 480 in epoch 15, gen_loss = 0.833955261414859, disc_loss = 0.07405711118743721
Trained batch 481 in epoch 15, gen_loss = 0.8341643288422422, disc_loss = 0.07396765004967135
Trained batch 482 in epoch 15, gen_loss = 0.8340357411228598, disc_loss = 0.07387372208122882
Trained batch 483 in epoch 15, gen_loss = 0.8342744056597229, disc_loss = 0.07379861049785101
Trained batch 484 in epoch 15, gen_loss = 0.8344312701028647, disc_loss = 0.07376297253001597
Trained batch 485 in epoch 15, gen_loss = 0.8345684871506789, disc_loss = 0.07363615882747765
Trained batch 486 in epoch 15, gen_loss = 0.8339491256453418, disc_loss = 0.07384153015077788
Trained batch 487 in epoch 15, gen_loss = 0.8346387312793341, disc_loss = 0.07374415143400614
Trained batch 488 in epoch 15, gen_loss = 0.8348835027778563, disc_loss = 0.07371873898214541
Trained batch 489 in epoch 15, gen_loss = 0.83501655289105, disc_loss = 0.07359482259204497
Trained batch 490 in epoch 15, gen_loss = 0.8349335024895833, disc_loss = 0.07349527161568403
Trained batch 491 in epoch 15, gen_loss = 0.8349069658575988, disc_loss = 0.07339925512224739
Trained batch 492 in epoch 15, gen_loss = 0.8353693191468353, disc_loss = 0.07328309418546682
Trained batch 493 in epoch 15, gen_loss = 0.8352409228380875, disc_loss = 0.07322051815560413
Trained batch 494 in epoch 15, gen_loss = 0.8355382129399463, disc_loss = 0.07313835093130668
Trained batch 495 in epoch 15, gen_loss = 0.835927595294291, disc_loss = 0.07303538542398583
Trained batch 496 in epoch 15, gen_loss = 0.8360214767081877, disc_loss = 0.07295018407727931
Trained batch 497 in epoch 15, gen_loss = 0.8360504839554369, disc_loss = 0.07299567401656006
Trained batch 498 in epoch 15, gen_loss = 0.83589107060958, disc_loss = 0.0729163311485328
Trained batch 499 in epoch 15, gen_loss = 0.8363630968332291, disc_loss = 0.07284323595650494
Trained batch 500 in epoch 15, gen_loss = 0.8369521303567106, disc_loss = 0.07273131344437658
Trained batch 501 in epoch 15, gen_loss = 0.8365488363452167, disc_loss = 0.07284781728793248
Trained batch 502 in epoch 15, gen_loss = 0.8371282505467682, disc_loss = 0.07273638112726019
Trained batch 503 in epoch 15, gen_loss = 0.8374967747737491, disc_loss = 0.07261594875516104
Trained batch 504 in epoch 15, gen_loss = 0.8376089039415416, disc_loss = 0.07250331263472833
Trained batch 505 in epoch 15, gen_loss = 0.8380180554898832, disc_loss = 0.07241719991903708
Trained batch 506 in epoch 15, gen_loss = 0.8385016217504497, disc_loss = 0.07234012851164598
Trained batch 507 in epoch 15, gen_loss = 0.838365206216264, disc_loss = 0.07230768871757634
Trained batch 508 in epoch 15, gen_loss = 0.8379318221144686, disc_loss = 0.07234803428928312
Trained batch 509 in epoch 15, gen_loss = 0.8377807601994159, disc_loss = 0.07261670013962715
Trained batch 510 in epoch 15, gen_loss = 0.8383427684554382, disc_loss = 0.07250129719813393
Trained batch 511 in epoch 15, gen_loss = 0.8383013390703127, disc_loss = 0.07245302998853731
Trained batch 512 in epoch 15, gen_loss = 0.8383921340659812, disc_loss = 0.07241644285851635
Trained batch 513 in epoch 15, gen_loss = 0.838181497058052, disc_loss = 0.07234201039249215
Trained batch 514 in epoch 15, gen_loss = 0.8382517135259017, disc_loss = 0.0722413185260539
Trained batch 515 in epoch 15, gen_loss = 0.8380852911130402, disc_loss = 0.07225436784774643
Trained batch 516 in epoch 15, gen_loss = 0.838345933237205, disc_loss = 0.07223351773530302
Trained batch 517 in epoch 15, gen_loss = 0.838730487814281, disc_loss = 0.07242718647849031
Trained batch 518 in epoch 15, gen_loss = 0.8385470692132939, disc_loss = 0.07240063149790658
Trained batch 519 in epoch 15, gen_loss = 0.8390619222934429, disc_loss = 0.07229613161359269
Trained batch 520 in epoch 15, gen_loss = 0.8388619706635283, disc_loss = 0.07225476303665171
Trained batch 521 in epoch 15, gen_loss = 0.83893006400587, disc_loss = 0.07224662441731755
Trained batch 522 in epoch 15, gen_loss = 0.8386337966809537, disc_loss = 0.07225381478624522
Trained batch 523 in epoch 15, gen_loss = 0.8382873465769164, disc_loss = 0.07225694637816713
Trained batch 524 in epoch 15, gen_loss = 0.8386783939316159, disc_loss = 0.07232245324268227
Trained batch 525 in epoch 15, gen_loss = 0.839053894063819, disc_loss = 0.07235405905377615
Trained batch 526 in epoch 15, gen_loss = 0.8385522778391612, disc_loss = 0.07238735676702444
Trained batch 527 in epoch 15, gen_loss = 0.8382302572329839, disc_loss = 0.07243720541891614
Trained batch 528 in epoch 15, gen_loss = 0.8380159346953683, disc_loss = 0.07251669659097952
Trained batch 529 in epoch 15, gen_loss = 0.8375543036550845, disc_loss = 0.07257321823810069
Trained batch 530 in epoch 15, gen_loss = 0.8375910641783375, disc_loss = 0.07247703357576875
Trained batch 531 in epoch 15, gen_loss = 0.8372145897911903, disc_loss = 0.07252114745823288
Trained batch 532 in epoch 15, gen_loss = 0.8372052463984176, disc_loss = 0.07243835335461105
Trained batch 533 in epoch 15, gen_loss = 0.8376640082521831, disc_loss = 0.07272330135079136
Trained batch 534 in epoch 15, gen_loss = 0.8378449423290859, disc_loss = 0.07268289732181023
Trained batch 535 in epoch 15, gen_loss = 0.8372280755594596, disc_loss = 0.07278756100211793
Trained batch 536 in epoch 15, gen_loss = 0.8369811320438065, disc_loss = 0.07278192872302937
Trained batch 537 in epoch 15, gen_loss = 0.837225283167176, disc_loss = 0.07275493262287187
Trained batch 538 in epoch 15, gen_loss = 0.8378206907265261, disc_loss = 0.0729010596885199
Trained batch 539 in epoch 15, gen_loss = 0.8376900675120177, disc_loss = 0.07291112562158593
Trained batch 540 in epoch 15, gen_loss = 0.8373719572800585, disc_loss = 0.07322853763007633
Trained batch 541 in epoch 15, gen_loss = 0.8374926089360705, disc_loss = 0.07321730036824611
Trained batch 542 in epoch 15, gen_loss = 0.8379432557915675, disc_loss = 0.07313156415044603
Trained batch 543 in epoch 15, gen_loss = 0.8374599173445912, disc_loss = 0.07319359809009578
Trained batch 544 in epoch 15, gen_loss = 0.837010721219789, disc_loss = 0.07334441738459495
Trained batch 545 in epoch 15, gen_loss = 0.8372702872578478, disc_loss = 0.07345483778556297
Trained batch 546 in epoch 15, gen_loss = 0.837585471556871, disc_loss = 0.0734944459105377
Trained batch 547 in epoch 15, gen_loss = 0.8371976882654385, disc_loss = 0.07379828135476169
Trained batch 548 in epoch 15, gen_loss = 0.8370145759078758, disc_loss = 0.07374902223262304
Trained batch 549 in epoch 15, gen_loss = 0.8375693065469916, disc_loss = 0.07405393474819985
Trained batch 550 in epoch 15, gen_loss = 0.8371879048442668, disc_loss = 0.07416839674858887
Trained batch 551 in epoch 15, gen_loss = 0.836865002370399, disc_loss = 0.07418017589109208
Trained batch 552 in epoch 15, gen_loss = 0.8368602444638396, disc_loss = 0.07414081606131458
Trained batch 553 in epoch 15, gen_loss = 0.8371869449365871, disc_loss = 0.07411058756458953
Trained batch 554 in epoch 15, gen_loss = 0.8368414840182743, disc_loss = 0.07409363647771848
Trained batch 555 in epoch 15, gen_loss = 0.8363567061132664, disc_loss = 0.07420363063796712
Trained batch 556 in epoch 15, gen_loss = 0.8359791808753296, disc_loss = 0.07416344043101507
Trained batch 557 in epoch 15, gen_loss = 0.8360696266201662, disc_loss = 0.07421326676991144
Trained batch 558 in epoch 15, gen_loss = 0.8362706419820223, disc_loss = 0.07421951151531263
Trained batch 559 in epoch 15, gen_loss = 0.8364936688116619, disc_loss = 0.07413476596785976
Trained batch 560 in epoch 15, gen_loss = 0.8361434235292322, disc_loss = 0.07413048247031456
Trained batch 561 in epoch 15, gen_loss = 0.8361269267428388, disc_loss = 0.07409009924390456
Trained batch 562 in epoch 15, gen_loss = 0.8359689781339723, disc_loss = 0.07416362304498522
Trained batch 563 in epoch 15, gen_loss = 0.8363338257615448, disc_loss = 0.07420604571317
Trained batch 564 in epoch 15, gen_loss = 0.8365908471883926, disc_loss = 0.07429305257984495
Trained batch 565 in epoch 15, gen_loss = 0.8360715606397959, disc_loss = 0.07466019064438112
Trained batch 566 in epoch 15, gen_loss = 0.8359869307521369, disc_loss = 0.07460842053923342
Trained batch 567 in epoch 15, gen_loss = 0.8366047936216207, disc_loss = 0.07467935165770771
Trained batch 568 in epoch 15, gen_loss = 0.836350710823582, disc_loss = 0.07471891818322594
Trained batch 569 in epoch 15, gen_loss = 0.8361809132391946, disc_loss = 0.07470654308991997
Trained batch 570 in epoch 15, gen_loss = 0.835654898199225, disc_loss = 0.07497871952578294
Trained batch 571 in epoch 15, gen_loss = 0.8358319992577279, disc_loss = 0.07495329858266286
Trained batch 572 in epoch 15, gen_loss = 0.8361209777637302, disc_loss = 0.07486725267978551
Trained batch 573 in epoch 15, gen_loss = 0.8358583789876944, disc_loss = 0.07487208398467884
Trained batch 574 in epoch 15, gen_loss = 0.8358880130104397, disc_loss = 0.07486917477263057
Trained batch 575 in epoch 15, gen_loss = 0.8360594708679451, disc_loss = 0.07489756389663348
Trained batch 576 in epoch 15, gen_loss = 0.8360244967495342, disc_loss = 0.07482048636383055
Trained batch 577 in epoch 15, gen_loss = 0.8355558828086589, disc_loss = 0.07490702929574622
Trained batch 578 in epoch 15, gen_loss = 0.8355928242515406, disc_loss = 0.07489591033643495
Trained batch 579 in epoch 15, gen_loss = 0.8357616909619036, disc_loss = 0.07489829855682008
Trained batch 580 in epoch 15, gen_loss = 0.8357809551201261, disc_loss = 0.07481883047228734
Trained batch 581 in epoch 15, gen_loss = 0.8353237154352706, disc_loss = 0.07492526663192052
Trained batch 582 in epoch 15, gen_loss = 0.8356347230245482, disc_loss = 0.07495995684116312
Trained batch 583 in epoch 15, gen_loss = 0.8353420513337606, disc_loss = 0.07490404758104825
Trained batch 584 in epoch 15, gen_loss = 0.8349696838957632, disc_loss = 0.07497441011170546
Trained batch 585 in epoch 15, gen_loss = 0.8350655024572444, disc_loss = 0.07494461551346775
Trained batch 586 in epoch 15, gen_loss = 0.8350588102560027, disc_loss = 0.07498734130554244
Trained batch 587 in epoch 15, gen_loss = 0.8345410616016712, disc_loss = 0.07511028786487624
Trained batch 588 in epoch 15, gen_loss = 0.8343937511355038, disc_loss = 0.07506696310318083
Trained batch 589 in epoch 15, gen_loss = 0.8346597859414957, disc_loss = 0.0750144970461221
Trained batch 590 in epoch 15, gen_loss = 0.8347029792879237, disc_loss = 0.07493190372176783
Trained batch 591 in epoch 15, gen_loss = 0.8345425466226565, disc_loss = 0.07489425520337112
Trained batch 592 in epoch 15, gen_loss = 0.8351499329730994, disc_loss = 0.07484491869279546
Trained batch 593 in epoch 15, gen_loss = 0.8352362267698101, disc_loss = 0.07474942341359075
Trained batch 594 in epoch 15, gen_loss = 0.8354843410123296, disc_loss = 0.07472320280718703
Trained batch 595 in epoch 15, gen_loss = 0.8350422960399781, disc_loss = 0.07478769493895589
Trained batch 596 in epoch 15, gen_loss = 0.8349190758700347, disc_loss = 0.07472000462338453
Trained batch 597 in epoch 15, gen_loss = 0.8351616519550017, disc_loss = 0.07462077676303012
Trained batch 598 in epoch 15, gen_loss = 0.8355516148528989, disc_loss = 0.0745219640085514
Trained batch 599 in epoch 15, gen_loss = 0.8357609717051188, disc_loss = 0.07451135409995914
Trained batch 600 in epoch 15, gen_loss = 0.8353564536908701, disc_loss = 0.0745454222125043
Trained batch 601 in epoch 15, gen_loss = 0.8353957040761396, disc_loss = 0.07447133871395624
Trained batch 602 in epoch 15, gen_loss = 0.8355312693376051, disc_loss = 0.0745525129763394
Trained batch 603 in epoch 15, gen_loss = 0.835360545985746, disc_loss = 0.07452492632082855
Trained batch 604 in epoch 15, gen_loss = 0.8349692523972062, disc_loss = 0.07467171839507651
Trained batch 605 in epoch 15, gen_loss = 0.8353880567125754, disc_loss = 0.0746180333486042
Trained batch 606 in epoch 15, gen_loss = 0.8360162458859716, disc_loss = 0.07462125888655861
Trained batch 607 in epoch 15, gen_loss = 0.8359073276974653, disc_loss = 0.07456763039992534
Trained batch 608 in epoch 15, gen_loss = 0.835756973484271, disc_loss = 0.07453258693132592
Trained batch 609 in epoch 15, gen_loss = 0.8356658936524001, disc_loss = 0.07450521569088346
Trained batch 610 in epoch 15, gen_loss = 0.835508750425423, disc_loss = 0.0744912993748186
Trained batch 611 in epoch 15, gen_loss = 0.8351274197008095, disc_loss = 0.07457484666781586
Trained batch 612 in epoch 15, gen_loss = 0.8351867347712618, disc_loss = 0.07464056749194617
Trained batch 613 in epoch 15, gen_loss = 0.8348832595426019, disc_loss = 0.0746243517233077
Trained batch 614 in epoch 15, gen_loss = 0.8354671312541496, disc_loss = 0.07461545877158642
Trained batch 615 in epoch 15, gen_loss = 0.8351968984518733, disc_loss = 0.07459015488418956
Trained batch 616 in epoch 15, gen_loss = 0.8348401867976258, disc_loss = 0.07462669430508896
Trained batch 617 in epoch 15, gen_loss = 0.8351433240480022, disc_loss = 0.0745562860549316
Trained batch 618 in epoch 15, gen_loss = 0.8347637597501567, disc_loss = 0.07461386711091429
Trained batch 619 in epoch 15, gen_loss = 0.8348671950640217, disc_loss = 0.07452524354561202
Trained batch 620 in epoch 15, gen_loss = 0.8348930761242066, disc_loss = 0.07456987257297008
Trained batch 621 in epoch 15, gen_loss = 0.8355855629375126, disc_loss = 0.07452030139421248
Trained batch 622 in epoch 15, gen_loss = 0.8358172325605757, disc_loss = 0.07442119440294048
Trained batch 623 in epoch 15, gen_loss = 0.835585289563124, disc_loss = 0.07442957685979752
Trained batch 624 in epoch 15, gen_loss = 0.83560265417099, disc_loss = 0.07440938838273287
Trained batch 625 in epoch 15, gen_loss = 0.8357436505559915, disc_loss = 0.07431365740292084
Trained batch 626 in epoch 15, gen_loss = 0.835319778660648, disc_loss = 0.07437979372031095
Trained batch 627 in epoch 15, gen_loss = 0.8352023991429882, disc_loss = 0.07431027117914929
Trained batch 628 in epoch 15, gen_loss = 0.8352671157574616, disc_loss = 0.07429007821922178
Trained batch 629 in epoch 15, gen_loss = 0.8348445942477575, disc_loss = 0.07434482358928238
Trained batch 630 in epoch 15, gen_loss = 0.8351791174211517, disc_loss = 0.07425351582892628
Trained batch 631 in epoch 15, gen_loss = 0.8347413244692585, disc_loss = 0.07431648847576278
Trained batch 632 in epoch 15, gen_loss = 0.8355799786287461, disc_loss = 0.0744855145807562
Trained batch 633 in epoch 15, gen_loss = 0.835504180907451, disc_loss = 0.07441032218984812
Trained batch 634 in epoch 15, gen_loss = 0.8353596166362912, disc_loss = 0.07444379756183137
Trained batch 635 in epoch 15, gen_loss = 0.8355058994870516, disc_loss = 0.07435416642271872
Trained batch 636 in epoch 15, gen_loss = 0.8356338592488874, disc_loss = 0.07436188938479221
Trained batch 637 in epoch 15, gen_loss = 0.8358002210672373, disc_loss = 0.07429050018888282
Trained batch 638 in epoch 15, gen_loss = 0.8356683762607067, disc_loss = 0.07425791202389952
Trained batch 639 in epoch 15, gen_loss = 0.8356662531383335, disc_loss = 0.07417305181734264
Trained batch 640 in epoch 15, gen_loss = 0.8356214611095125, disc_loss = 0.07409842760126323
Trained batch 641 in epoch 15, gen_loss = 0.8354490169112184, disc_loss = 0.07409037959782226
Trained batch 642 in epoch 15, gen_loss = 0.8354146920874552, disc_loss = 0.0741952946366131
Trained batch 643 in epoch 15, gen_loss = 0.8352099246119861, disc_loss = 0.07422545923915061
Trained batch 644 in epoch 15, gen_loss = 0.8356767598972764, disc_loss = 0.07431740101513475
Trained batch 645 in epoch 15, gen_loss = 0.8351732153826085, disc_loss = 0.07451007544313883
Trained batch 646 in epoch 15, gen_loss = 0.8354199978262417, disc_loss = 0.07446891362771645
Trained batch 647 in epoch 15, gen_loss = 0.8353411041108179, disc_loss = 0.07445759860580259
Trained batch 648 in epoch 15, gen_loss = 0.8353964507304281, disc_loss = 0.07448051122228151
Trained batch 649 in epoch 15, gen_loss = 0.8351594994618342, disc_loss = 0.07445804705700049
Trained batch 650 in epoch 15, gen_loss = 0.835333364625131, disc_loss = 0.07455450355628943
Trained batch 651 in epoch 15, gen_loss = 0.8351860029017267, disc_loss = 0.0744979648588031
Trained batch 652 in epoch 15, gen_loss = 0.8351907389634966, disc_loss = 0.07442050014449937
Trained batch 653 in epoch 15, gen_loss = 0.8349170275602137, disc_loss = 0.07442024400577359
Trained batch 654 in epoch 15, gen_loss = 0.8350072055372573, disc_loss = 0.07444277813245777
Trained batch 655 in epoch 15, gen_loss = 0.8351646152029677, disc_loss = 0.07438951046717149
Trained batch 656 in epoch 15, gen_loss = 0.8349968028939478, disc_loss = 0.07440330856727774
Trained batch 657 in epoch 15, gen_loss = 0.8352119151763279, disc_loss = 0.07440587661673505
Trained batch 658 in epoch 15, gen_loss = 0.8351028398787306, disc_loss = 0.07433901724090435
Trained batch 659 in epoch 15, gen_loss = 0.8348635670813647, disc_loss = 0.0743177838821077
Trained batch 660 in epoch 15, gen_loss = 0.8348294380212515, disc_loss = 0.07429065861078415
Trained batch 661 in epoch 15, gen_loss = 0.8353992296309629, disc_loss = 0.07431083292140431
Trained batch 662 in epoch 15, gen_loss = 0.834976228563674, disc_loss = 0.07436088615604206
Trained batch 663 in epoch 15, gen_loss = 0.834872130259692, disc_loss = 0.0743141193363636
Trained batch 664 in epoch 15, gen_loss = 0.8349385667564277, disc_loss = 0.07423842775362327
Trained batch 665 in epoch 15, gen_loss = 0.8348154368343296, disc_loss = 0.07426182428716092
Trained batch 666 in epoch 15, gen_loss = 0.8348160360170447, disc_loss = 0.07425058902013695
Trained batch 667 in epoch 15, gen_loss = 0.8353476137101293, disc_loss = 0.07424146915970002
Trained batch 668 in epoch 15, gen_loss = 0.8350704443294371, disc_loss = 0.07424605335700583
Trained batch 669 in epoch 15, gen_loss = 0.8350986137318966, disc_loss = 0.07416080504155426
Trained batch 670 in epoch 15, gen_loss = 0.8347525781384169, disc_loss = 0.07412305216397952
Trained batch 671 in epoch 15, gen_loss = 0.8348906097844953, disc_loss = 0.07408794097968244
Trained batch 672 in epoch 15, gen_loss = 0.8351072246571353, disc_loss = 0.07401131704881411
Trained batch 673 in epoch 15, gen_loss = 0.8348616853312144, disc_loss = 0.07396025659146135
Trained batch 674 in epoch 15, gen_loss = 0.8347640444614269, disc_loss = 0.07393309483649554
Trained batch 675 in epoch 15, gen_loss = 0.8350646540787093, disc_loss = 0.07384226205428103
Trained batch 676 in epoch 15, gen_loss = 0.835259274066463, disc_loss = 0.07392986967163696
Trained batch 677 in epoch 15, gen_loss = 0.8352790897750573, disc_loss = 0.07388797768729582
Trained batch 678 in epoch 15, gen_loss = 0.8350645458224245, disc_loss = 0.07394017796381891
Trained batch 679 in epoch 15, gen_loss = 0.8354030190145268, disc_loss = 0.0740048219983959
Trained batch 680 in epoch 15, gen_loss = 0.8353041737790324, disc_loss = 0.07415921838814597
Trained batch 681 in epoch 15, gen_loss = 0.835053243857325, disc_loss = 0.07429544644463054
Trained batch 682 in epoch 15, gen_loss = 0.8351498281100483, disc_loss = 0.07431828394657652
Trained batch 683 in epoch 15, gen_loss = 0.8354715589019988, disc_loss = 0.07439668151299464
Trained batch 684 in epoch 15, gen_loss = 0.8351022796039164, disc_loss = 0.07440424421598224
Trained batch 685 in epoch 15, gen_loss = 0.8351322263044797, disc_loss = 0.0743541021114514
Trained batch 686 in epoch 15, gen_loss = 0.8348590953728344, disc_loss = 0.07437020077016286
Trained batch 687 in epoch 15, gen_loss = 0.8347188204007093, disc_loss = 0.07434977451745464
Trained batch 688 in epoch 15, gen_loss = 0.8346202017087895, disc_loss = 0.07428362297978258
Trained batch 689 in epoch 15, gen_loss = 0.8348550897577535, disc_loss = 0.07432351324680275
Trained batch 690 in epoch 15, gen_loss = 0.8349018460072243, disc_loss = 0.07424667312773066
Trained batch 691 in epoch 15, gen_loss = 0.8348873434211478, disc_loss = 0.07416965722138698
Trained batch 692 in epoch 15, gen_loss = 0.8344812034528493, disc_loss = 0.0743254017404685
Trained batch 693 in epoch 15, gen_loss = 0.8356900047671898, disc_loss = 0.07464664343674735
Trained batch 694 in epoch 15, gen_loss = 0.8354750791899592, disc_loss = 0.07465409919646361
Trained batch 695 in epoch 15, gen_loss = 0.835572621431844, disc_loss = 0.07458778684717957
Trained batch 696 in epoch 15, gen_loss = 0.8355021336499382, disc_loss = 0.07452661149508429
Trained batch 697 in epoch 15, gen_loss = 0.8351209483037364, disc_loss = 0.07456996795563908
Trained batch 698 in epoch 15, gen_loss = 0.835625577211721, disc_loss = 0.07498092245768878
Trained batch 699 in epoch 15, gen_loss = 0.8355777042252677, disc_loss = 0.07491277808988733
Trained batch 700 in epoch 15, gen_loss = 0.8353405388207646, disc_loss = 0.07491703158624459
Trained batch 701 in epoch 15, gen_loss = 0.8351318771682913, disc_loss = 0.07497267456237025
Trained batch 702 in epoch 15, gen_loss = 0.8353881941072293, disc_loss = 0.07493637002882671
Trained batch 703 in epoch 15, gen_loss = 0.835258203219961, disc_loss = 0.07488283493148629
Trained batch 704 in epoch 15, gen_loss = 0.8350287456884452, disc_loss = 0.07490008240235402
Trained batch 705 in epoch 15, gen_loss = 0.8347391735224143, disc_loss = 0.07484705910144675
Trained batch 706 in epoch 15, gen_loss = 0.8346048837166696, disc_loss = 0.0748779028061319
Trained batch 707 in epoch 15, gen_loss = 0.8346559057633082, disc_loss = 0.07490745202985481
Trained batch 708 in epoch 15, gen_loss = 0.834797371425817, disc_loss = 0.07501322078703783
Trained batch 709 in epoch 15, gen_loss = 0.8344925872037109, disc_loss = 0.07525363272108453
Trained batch 710 in epoch 15, gen_loss = 0.834530465545869, disc_loss = 0.07516618663872135
Trained batch 711 in epoch 15, gen_loss = 0.834755006466019, disc_loss = 0.07514017141094494
Trained batch 712 in epoch 15, gen_loss = 0.8343438275398747, disc_loss = 0.07527811264000091
Trained batch 713 in epoch 15, gen_loss = 0.8343675232568041, disc_loss = 0.0753168826205369
Trained batch 714 in epoch 15, gen_loss = 0.8346954251502777, disc_loss = 0.07530825787152236
Trained batch 715 in epoch 15, gen_loss = 0.8347005064927, disc_loss = 0.07524939711653113
Trained batch 716 in epoch 15, gen_loss = 0.8346223518605678, disc_loss = 0.07519731377452778
Trained batch 717 in epoch 15, gen_loss = 0.8344208481916146, disc_loss = 0.07515323899743409
Trained batch 718 in epoch 15, gen_loss = 0.8342230360597497, disc_loss = 0.07511871244748006
Trained batch 719 in epoch 15, gen_loss = 0.8339555841353204, disc_loss = 0.07510360333318304
Trained batch 720 in epoch 15, gen_loss = 0.8340898813387888, disc_loss = 0.07506413198619999
Trained batch 721 in epoch 15, gen_loss = 0.8338909467831873, disc_loss = 0.07500224067104615
Trained batch 722 in epoch 15, gen_loss = 0.8338529044661779, disc_loss = 0.07500241702888805
Trained batch 723 in epoch 15, gen_loss = 0.8337993110576387, disc_loss = 0.07496678534745964
Trained batch 724 in epoch 15, gen_loss = 0.8335159438231896, disc_loss = 0.07498487256595801
Trained batch 725 in epoch 15, gen_loss = 0.8337271680680846, disc_loss = 0.07504344223446877
Trained batch 726 in epoch 15, gen_loss = 0.833476015265411, disc_loss = 0.0750118883049943
Trained batch 727 in epoch 15, gen_loss = 0.8336507769731375, disc_loss = 0.0749549433617126
Trained batch 728 in epoch 15, gen_loss = 0.8332944881114777, disc_loss = 0.0749895840216382
Trained batch 729 in epoch 15, gen_loss = 0.8333329108479904, disc_loss = 0.07497067707526969
Trained batch 730 in epoch 15, gen_loss = 0.833692541608406, disc_loss = 0.07492557875735611
Trained batch 731 in epoch 15, gen_loss = 0.833717999073977, disc_loss = 0.07514192793350362
Trained batch 732 in epoch 15, gen_loss = 0.8335077135657223, disc_loss = 0.07527389748741099
Trained batch 733 in epoch 15, gen_loss = 0.8332629401937167, disc_loss = 0.07529018412671516
Trained batch 734 in epoch 15, gen_loss = 0.8338404237007608, disc_loss = 0.07551273958390059
Trained batch 735 in epoch 15, gen_loss = 0.8335965808642947, disc_loss = 0.07557547806493897
Trained batch 736 in epoch 15, gen_loss = 0.8335297258123452, disc_loss = 0.07556847075892555
Trained batch 737 in epoch 15, gen_loss = 0.8336347226851032, disc_loss = 0.07557794187586442
Trained batch 738 in epoch 15, gen_loss = 0.8335205880327702, disc_loss = 0.07554199178961479
Trained batch 739 in epoch 15, gen_loss = 0.8333040479872678, disc_loss = 0.07553346677985344
Trained batch 740 in epoch 15, gen_loss = 0.8332307595312193, disc_loss = 0.07555571297377187
Trained batch 741 in epoch 15, gen_loss = 0.8333722961077472, disc_loss = 0.07550058697006412
Trained batch 742 in epoch 15, gen_loss = 0.8333706089657698, disc_loss = 0.07544776414612542
Trained batch 743 in epoch 15, gen_loss = 0.8332497420650656, disc_loss = 0.07541711657353106
Trained batch 744 in epoch 15, gen_loss = 0.8337019426710653, disc_loss = 0.07547327730954694
Trained batch 745 in epoch 15, gen_loss = 0.8334864819816865, disc_loss = 0.07543865382426665
Trained batch 746 in epoch 15, gen_loss = 0.8336456102060984, disc_loss = 0.07536368569112327
Trained batch 747 in epoch 15, gen_loss = 0.8337316302692189, disc_loss = 0.07529608343409146
Trained batch 748 in epoch 15, gen_loss = 0.8339260620014053, disc_loss = 0.07527840235836317
Trained batch 749 in epoch 15, gen_loss = 0.8341248842080434, disc_loss = 0.07519030724217494
Trained batch 750 in epoch 15, gen_loss = 0.8347114182502706, disc_loss = 0.07518262379665111
Trained batch 751 in epoch 15, gen_loss = 0.8344816696295079, disc_loss = 0.07518077298176494
Trained batch 752 in epoch 15, gen_loss = 0.8342853606459629, disc_loss = 0.0751929234188906
Trained batch 753 in epoch 15, gen_loss = 0.8350088824802115, disc_loss = 0.07532447142976112
Trained batch 754 in epoch 15, gen_loss = 0.8350118773662492, disc_loss = 0.07527216576434524
Trained batch 755 in epoch 15, gen_loss = 0.8347704622638289, disc_loss = 0.0753617965734549
Trained batch 756 in epoch 15, gen_loss = 0.8346980892840276, disc_loss = 0.07532543119392511
Trained batch 757 in epoch 15, gen_loss = 0.8351533984603228, disc_loss = 0.07527559839611711
Trained batch 758 in epoch 15, gen_loss = 0.8353329956610055, disc_loss = 0.0752115698877295
Trained batch 759 in epoch 15, gen_loss = 0.8350686791696047, disc_loss = 0.07517430872999524
Trained batch 760 in epoch 15, gen_loss = 0.8348556884641559, disc_loss = 0.07517559218872706
Trained batch 761 in epoch 15, gen_loss = 0.8352155027583515, disc_loss = 0.07514949100888933
Trained batch 762 in epoch 15, gen_loss = 0.8355593527441412, disc_loss = 0.0750829982809322
Trained batch 763 in epoch 15, gen_loss = 0.8357584815062777, disc_loss = 0.07500695453527632
Trained batch 764 in epoch 15, gen_loss = 0.8355181556901121, disc_loss = 0.07496383552214289
Trained batch 765 in epoch 15, gen_loss = 0.8356860560163194, disc_loss = 0.07490746254543956
Trained batch 766 in epoch 15, gen_loss = 0.8357470288892147, disc_loss = 0.07482600202140395
Trained batch 767 in epoch 15, gen_loss = 0.8360068709589541, disc_loss = 0.07474643595681603
Trained batch 768 in epoch 15, gen_loss = 0.8356901410342193, disc_loss = 0.07475250333751055
Trained batch 769 in epoch 15, gen_loss = 0.8358988218493276, disc_loss = 0.07470098847837804
Trained batch 770 in epoch 15, gen_loss = 0.8357728026256487, disc_loss = 0.07463851593550773
Trained batch 771 in epoch 15, gen_loss = 0.836097220451103, disc_loss = 0.0746170072526782
Trained batch 772 in epoch 15, gen_loss = 0.8361397885258417, disc_loss = 0.07455294092762903
Trained batch 773 in epoch 15, gen_loss = 0.83604266184553, disc_loss = 0.07453355402264561
Trained batch 774 in epoch 15, gen_loss = 0.8363822357116207, disc_loss = 0.07453820255735229
Trained batch 775 in epoch 15, gen_loss = 0.8361143168714857, disc_loss = 0.07450003824292768
Trained batch 776 in epoch 15, gen_loss = 0.8358680704078773, disc_loss = 0.07451625003634042
Trained batch 777 in epoch 15, gen_loss = 0.8358185997658952, disc_loss = 0.07445146050783004
Trained batch 778 in epoch 15, gen_loss = 0.8363370968839476, disc_loss = 0.07464283692563223
Trained batch 779 in epoch 15, gen_loss = 0.8363182229873461, disc_loss = 0.07459407182983481
Trained batch 780 in epoch 15, gen_loss = 0.8363478500467562, disc_loss = 0.07452558477083639
Trained batch 781 in epoch 15, gen_loss = 0.8357806618485, disc_loss = 0.07474182931053669
Trained batch 782 in epoch 15, gen_loss = 0.8365276381658868, disc_loss = 0.07527859366259812
Trained batch 783 in epoch 15, gen_loss = 0.8364141169479307, disc_loss = 0.07531203177510476
Trained batch 784 in epoch 15, gen_loss = 0.8364619520439464, disc_loss = 0.07529004130773484
Trained batch 785 in epoch 15, gen_loss = 0.8361545327586375, disc_loss = 0.07531813636384241
Trained batch 786 in epoch 15, gen_loss = 0.836190426478392, disc_loss = 0.07537609622772343
Trained batch 787 in epoch 15, gen_loss = 0.8363518722090625, disc_loss = 0.07551212593686157
Trained batch 788 in epoch 15, gen_loss = 0.8360641447990113, disc_loss = 0.07554672548903862
Trained batch 789 in epoch 15, gen_loss = 0.8357201145042347, disc_loss = 0.07565136866856224
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.6167623996734619, disc_loss = 0.17975997924804688
Trained batch 1 in epoch 16, gen_loss = 0.7146710753440857, disc_loss = 0.17118261754512787
Trained batch 2 in epoch 16, gen_loss = 0.6731711626052856, disc_loss = 0.15719063580036163
Trained batch 3 in epoch 16, gen_loss = 0.7403248250484467, disc_loss = 0.12064931727945805
Trained batch 4 in epoch 16, gen_loss = 0.7802423477172852, disc_loss = 0.10536917001008987
Trained batch 5 in epoch 16, gen_loss = 0.7764707108338674, disc_loss = 0.0927340059230725
Trained batch 6 in epoch 16, gen_loss = 0.7725690858704704, disc_loss = 0.08345424995890685
Trained batch 7 in epoch 16, gen_loss = 0.7655097618699074, disc_loss = 0.08263286459259689
Trained batch 8 in epoch 16, gen_loss = 0.7862869633568658, disc_loss = 0.07578353687292999
Trained batch 9 in epoch 16, gen_loss = 0.7818594872951508, disc_loss = 0.07284396309405565
Trained batch 10 in epoch 16, gen_loss = 0.7895410711115057, disc_loss = 0.07140462794764475
Trained batch 11 in epoch 16, gen_loss = 0.7818412482738495, disc_loss = 0.07034791897361477
Trained batch 12 in epoch 16, gen_loss = 0.7886697787504929, disc_loss = 0.06685000027601536
Trained batch 13 in epoch 16, gen_loss = 0.7784716870103564, disc_loss = 0.06678142558251109
Trained batch 14 in epoch 16, gen_loss = 0.7787753025690715, disc_loss = 0.06556077102820078
Trained batch 15 in epoch 16, gen_loss = 0.7708737403154373, disc_loss = 0.06532934727147222
Trained batch 16 in epoch 16, gen_loss = 0.7808724115876591, disc_loss = 0.06535190037068199
Trained batch 17 in epoch 16, gen_loss = 0.7779908213350508, disc_loss = 0.06344305475552876
Trained batch 18 in epoch 16, gen_loss = 0.7916456931515744, disc_loss = 0.0640992145789297
Trained batch 19 in epoch 16, gen_loss = 0.7924449533224106, disc_loss = 0.06467084363102912
Trained batch 20 in epoch 16, gen_loss = 0.7841200346038455, disc_loss = 0.06608560610385168
Trained batch 21 in epoch 16, gen_loss = 0.7832355716011741, disc_loss = 0.06402508973736655
Trained batch 22 in epoch 16, gen_loss = 0.7920309693916984, disc_loss = 0.06462025342752105
Trained batch 23 in epoch 16, gen_loss = 0.8000912144780159, disc_loss = 0.06351060459079842
Trained batch 24 in epoch 16, gen_loss = 0.799964427947998, disc_loss = 0.06188797332346439
Trained batch 25 in epoch 16, gen_loss = 0.7998078282062824, disc_loss = 0.06458698993978593
Trained batch 26 in epoch 16, gen_loss = 0.7921395831637912, disc_loss = 0.07043250049981806
Trained batch 27 in epoch 16, gen_loss = 0.7872460910252163, disc_loss = 0.07013765516291771
Trained batch 28 in epoch 16, gen_loss = 0.7900949223288174, disc_loss = 0.0693494553581394
Trained batch 29 in epoch 16, gen_loss = 0.792096096277237, disc_loss = 0.06756052921215693
Trained batch 30 in epoch 16, gen_loss = 0.798816317512143, disc_loss = 0.06646223234072808
Trained batch 31 in epoch 16, gen_loss = 0.7999604810029268, disc_loss = 0.0663994011702016
Trained batch 32 in epoch 16, gen_loss = 0.7957887667598147, disc_loss = 0.06878085355415489
Trained batch 33 in epoch 16, gen_loss = 0.7947674341061536, disc_loss = 0.06821355716708828
Trained batch 34 in epoch 16, gen_loss = 0.7986701948302133, disc_loss = 0.06832288514290537
Trained batch 35 in epoch 16, gen_loss = 0.794734463095665, disc_loss = 0.06871537088106076
Trained batch 36 in epoch 16, gen_loss = 0.7976915063084783, disc_loss = 0.06962464639061205
Trained batch 37 in epoch 16, gen_loss = 0.7995461037284449, disc_loss = 0.06835608512751366
Trained batch 38 in epoch 16, gen_loss = 0.8036543023891938, disc_loss = 0.06771366856992245
Trained batch 39 in epoch 16, gen_loss = 0.803597004711628, disc_loss = 0.06668418846093119
Trained batch 40 in epoch 16, gen_loss = 0.8002662251635295, disc_loss = 0.06663016915866514
Trained batch 41 in epoch 16, gen_loss = 0.805557804448264, disc_loss = 0.06619741905125834
Trained batch 42 in epoch 16, gen_loss = 0.8043278497318889, disc_loss = 0.06618488662291405
Trained batch 43 in epoch 16, gen_loss = 0.8059459599581632, disc_loss = 0.06529673823917453
Trained batch 44 in epoch 16, gen_loss = 0.8086669577492608, disc_loss = 0.06405995078384877
Trained batch 45 in epoch 16, gen_loss = 0.8112182824508004, disc_loss = 0.06563093177164378
Trained batch 46 in epoch 16, gen_loss = 0.8129475877640095, disc_loss = 0.06457773695125225
Trained batch 47 in epoch 16, gen_loss = 0.8108136591811975, disc_loss = 0.06460241045958053
Trained batch 48 in epoch 16, gen_loss = 0.8108599976617463, disc_loss = 0.06415773232524492
Trained batch 49 in epoch 16, gen_loss = 0.8087897765636444, disc_loss = 0.06381660405546427
Trained batch 50 in epoch 16, gen_loss = 0.8089237949427437, disc_loss = 0.0648884287140533
Trained batch 51 in epoch 16, gen_loss = 0.8078811993965735, disc_loss = 0.06595378501627308
Trained batch 52 in epoch 16, gen_loss = 0.8053538743055092, disc_loss = 0.06639134564067957
Trained batch 53 in epoch 16, gen_loss = 0.8022153697631977, disc_loss = 0.06633509243666022
Trained batch 54 in epoch 16, gen_loss = 0.8046058383854953, disc_loss = 0.06590746868063103
Trained batch 55 in epoch 16, gen_loss = 0.8080840376870972, disc_loss = 0.06509443189549659
Trained batch 56 in epoch 16, gen_loss = 0.8093894897845754, disc_loss = 0.0643531677166098
Trained batch 57 in epoch 16, gen_loss = 0.81309257190803, disc_loss = 0.06375963070654664
Trained batch 58 in epoch 16, gen_loss = 0.8126678658744036, disc_loss = 0.06365478654407848
Trained batch 59 in epoch 16, gen_loss = 0.8083628217379252, disc_loss = 0.06487802524740498
Trained batch 60 in epoch 16, gen_loss = 0.8109536473868323, disc_loss = 0.06497146149517083
Trained batch 61 in epoch 16, gen_loss = 0.8128882040900569, disc_loss = 0.06642320640986005
Trained batch 62 in epoch 16, gen_loss = 0.8164576547486442, disc_loss = 0.06585405583656023
Trained batch 63 in epoch 16, gen_loss = 0.8134592147544026, disc_loss = 0.06669790268642828
Trained batch 64 in epoch 16, gen_loss = 0.8100076281107389, disc_loss = 0.06802304083338151
Trained batch 65 in epoch 16, gen_loss = 0.8123955464724338, disc_loss = 0.06920173713429408
Trained batch 66 in epoch 16, gen_loss = 0.8168735174990412, disc_loss = 0.06892151068618048
Trained batch 67 in epoch 16, gen_loss = 0.827479799880701, disc_loss = 0.07098632771521807
Trained batch 68 in epoch 16, gen_loss = 0.8230383370233618, disc_loss = 0.07315314188599586
Trained batch 69 in epoch 16, gen_loss = 0.8206140662942614, disc_loss = 0.0729083805744137
Trained batch 70 in epoch 16, gen_loss = 0.8203454731215893, disc_loss = 0.0728106886463266
Trained batch 71 in epoch 16, gen_loss = 0.8231749195191596, disc_loss = 0.07230414734739396
Trained batch 72 in epoch 16, gen_loss = 0.8186285193652323, disc_loss = 0.07416963368041875
Trained batch 73 in epoch 16, gen_loss = 0.8183263290572811, disc_loss = 0.07413621362600778
Trained batch 74 in epoch 16, gen_loss = 0.8213580330212911, disc_loss = 0.07371189122398694
Trained batch 75 in epoch 16, gen_loss = 0.8176007953129316, disc_loss = 0.07429306723765637
Trained batch 76 in epoch 16, gen_loss = 0.8168863189684881, disc_loss = 0.07397264914659711
Trained batch 77 in epoch 16, gen_loss = 0.8159087323225461, disc_loss = 0.07359223425961457
Trained batch 78 in epoch 16, gen_loss = 0.8128179047681108, disc_loss = 0.07408095957546294
Trained batch 79 in epoch 16, gen_loss = 0.8174439631402493, disc_loss = 0.07580857803113758
Trained batch 80 in epoch 16, gen_loss = 0.819256396205337, disc_loss = 0.07500254603125799
Trained batch 81 in epoch 16, gen_loss = 0.8173583760494139, disc_loss = 0.07523490871280068
Trained batch 82 in epoch 16, gen_loss = 0.8186763582459415, disc_loss = 0.07445600024054208
Trained batch 83 in epoch 16, gen_loss = 0.8220346087501162, disc_loss = 0.07382292478966217
Trained batch 84 in epoch 16, gen_loss = 0.8219971397343804, disc_loss = 0.07326742527896866
Trained batch 85 in epoch 16, gen_loss = 0.8212985611239145, disc_loss = 0.07308785962807231
Trained batch 86 in epoch 16, gen_loss = 0.8205131525280832, disc_loss = 0.07291939177004428
Trained batch 87 in epoch 16, gen_loss = 0.8184889378872785, disc_loss = 0.07373676422602413
Trained batch 88 in epoch 16, gen_loss = 0.8188508856162596, disc_loss = 0.07366372936855206
Trained batch 89 in epoch 16, gen_loss = 0.8194960064358181, disc_loss = 0.07322556259524492
Trained batch 90 in epoch 16, gen_loss = 0.8191748143552424, disc_loss = 0.07299566939268466
Trained batch 91 in epoch 16, gen_loss = 0.8181580758613088, disc_loss = 0.0726977524286865
Trained batch 92 in epoch 16, gen_loss = 0.8182817697525024, disc_loss = 0.07242767952422621
Trained batch 93 in epoch 16, gen_loss = 0.8241365031993135, disc_loss = 0.07430688267018884
Trained batch 94 in epoch 16, gen_loss = 0.8254189673222994, disc_loss = 0.07385197159295019
Trained batch 95 in epoch 16, gen_loss = 0.8243284163375696, disc_loss = 0.07460113866060662
Trained batch 96 in epoch 16, gen_loss = 0.8233529095797195, disc_loss = 0.0749965869562374
Trained batch 97 in epoch 16, gen_loss = 0.8234485095861007, disc_loss = 0.07483135447932446
Trained batch 98 in epoch 16, gen_loss = 0.8263129224680891, disc_loss = 0.07532150797884572
Trained batch 99 in epoch 16, gen_loss = 0.8277917826175689, disc_loss = 0.07523375916294754
Trained batch 100 in epoch 16, gen_loss = 0.8252214618248515, disc_loss = 0.07640207391969933
Trained batch 101 in epoch 16, gen_loss = 0.8249849157006133, disc_loss = 0.07640382226593062
Trained batch 102 in epoch 16, gen_loss = 0.8244122868602716, disc_loss = 0.07596385335206117
Trained batch 103 in epoch 16, gen_loss = 0.8241936770769266, disc_loss = 0.07551553910777259
Trained batch 104 in epoch 16, gen_loss = 0.8234408866791498, disc_loss = 0.07497860758254925
Trained batch 105 in epoch 16, gen_loss = 0.8266105381947644, disc_loss = 0.07536157309341263
Trained batch 106 in epoch 16, gen_loss = 0.826149921550929, disc_loss = 0.07521867129742821
Trained batch 107 in epoch 16, gen_loss = 0.823696079077544, disc_loss = 0.07615737773098603
Trained batch 108 in epoch 16, gen_loss = 0.8265218734741211, disc_loss = 0.07593272839151664
Trained batch 109 in epoch 16, gen_loss = 0.82842750007456, disc_loss = 0.07547211366790262
Trained batch 110 in epoch 16, gen_loss = 0.8283825801299499, disc_loss = 0.07513382625640244
Trained batch 111 in epoch 16, gen_loss = 0.8286881702286857, disc_loss = 0.07477600111659351
Trained batch 112 in epoch 16, gen_loss = 0.8276348266981345, disc_loss = 0.07506197662117471
Trained batch 113 in epoch 16, gen_loss = 0.8262446392000767, disc_loss = 0.07488555334541097
Trained batch 114 in epoch 16, gen_loss = 0.8250359726988751, disc_loss = 0.0748414239562724
Trained batch 115 in epoch 16, gen_loss = 0.8282878249883652, disc_loss = 0.07471116610545793
Trained batch 116 in epoch 16, gen_loss = 0.8290201726122799, disc_loss = 0.07424945279987705
Trained batch 117 in epoch 16, gen_loss = 0.8295812258275889, disc_loss = 0.07437982603560313
Trained batch 118 in epoch 16, gen_loss = 0.8279567050332782, disc_loss = 0.074156152514913
Trained batch 119 in epoch 16, gen_loss = 0.8285039042433103, disc_loss = 0.07362180812439571
Trained batch 120 in epoch 16, gen_loss = 0.827918886153166, disc_loss = 0.07344197159371346
Trained batch 121 in epoch 16, gen_loss = 0.8259202622976459, disc_loss = 0.07355754447673432
Trained batch 122 in epoch 16, gen_loss = 0.825995490802982, disc_loss = 0.07422803612653076
Trained batch 123 in epoch 16, gen_loss = 0.8252771650591204, disc_loss = 0.07420089195722775
Trained batch 124 in epoch 16, gen_loss = 0.8235082988739013, disc_loss = 0.07433775977045298
Trained batch 125 in epoch 16, gen_loss = 0.8247120711538527, disc_loss = 0.07413800844981794
Trained batch 126 in epoch 16, gen_loss = 0.8253182369892992, disc_loss = 0.07434677318706522
Trained batch 127 in epoch 16, gen_loss = 0.8227698095142841, disc_loss = 0.07597271205304423
Trained batch 128 in epoch 16, gen_loss = 0.8258401774620825, disc_loss = 0.07562015336295662
Trained batch 129 in epoch 16, gen_loss = 0.8278366483174837, disc_loss = 0.07619695294505129
Trained batch 130 in epoch 16, gen_loss = 0.825971832712188, disc_loss = 0.0764150406013577
Trained batch 131 in epoch 16, gen_loss = 0.8247147491483977, disc_loss = 0.07639306115522755
Trained batch 132 in epoch 16, gen_loss = 0.8260494658821508, disc_loss = 0.07600691430690817
Trained batch 133 in epoch 16, gen_loss = 0.8277842571486288, disc_loss = 0.0759496097591942
Trained batch 134 in epoch 16, gen_loss = 0.826872111249853, disc_loss = 0.07583043101347155
Trained batch 135 in epoch 16, gen_loss = 0.8271910074879142, disc_loss = 0.07545965255977695
Trained batch 136 in epoch 16, gen_loss = 0.828083484277238, disc_loss = 0.07504176746129337
Trained batch 137 in epoch 16, gen_loss = 0.8282343356505685, disc_loss = 0.07461894354175615
Trained batch 138 in epoch 16, gen_loss = 0.8296551146953226, disc_loss = 0.07444401746682769
Trained batch 139 in epoch 16, gen_loss = 0.8291310582842145, disc_loss = 0.07431234980135092
Trained batch 140 in epoch 16, gen_loss = 0.827471357710818, disc_loss = 0.07445235092668458
Trained batch 141 in epoch 16, gen_loss = 0.8280030337857528, disc_loss = 0.0742427427780775
Trained batch 142 in epoch 16, gen_loss = 0.8290354972119098, disc_loss = 0.07389498376320083
Trained batch 143 in epoch 16, gen_loss = 0.8281431926621331, disc_loss = 0.07405520431671499
Trained batch 144 in epoch 16, gen_loss = 0.8293122809508752, disc_loss = 0.07425451565790793
Trained batch 145 in epoch 16, gen_loss = 0.8306087361623163, disc_loss = 0.07546004182850458
Trained batch 146 in epoch 16, gen_loss = 0.8286992072248135, disc_loss = 0.07634123804389822
Trained batch 147 in epoch 16, gen_loss = 0.8286350800378902, disc_loss = 0.07649749088906557
Trained batch 148 in epoch 16, gen_loss = 0.8275274894381529, disc_loss = 0.07656472895744464
Trained batch 149 in epoch 16, gen_loss = 0.8284444268544515, disc_loss = 0.07628366906816761
Trained batch 150 in epoch 16, gen_loss = 0.8280455892449183, disc_loss = 0.07766042757680677
Trained batch 151 in epoch 16, gen_loss = 0.8261405660917884, disc_loss = 0.0778108473413771
Trained batch 152 in epoch 16, gen_loss = 0.8249636148315629, disc_loss = 0.07782075762919156
Trained batch 153 in epoch 16, gen_loss = 0.8272862867875532, disc_loss = 0.07978554862829579
Trained batch 154 in epoch 16, gen_loss = 0.8256633973890736, disc_loss = 0.08040377468231225
Trained batch 155 in epoch 16, gen_loss = 0.8246875837063178, disc_loss = 0.0809861676564488
Trained batch 156 in epoch 16, gen_loss = 0.8233945331755718, disc_loss = 0.08141717190741543
Trained batch 157 in epoch 16, gen_loss = 0.824890747100492, disc_loss = 0.08201801455638642
Trained batch 158 in epoch 16, gen_loss = 0.8240548942074086, disc_loss = 0.08188619049347984
Trained batch 159 in epoch 16, gen_loss = 0.8224794931709767, disc_loss = 0.0821276472590398
Trained batch 160 in epoch 16, gen_loss = 0.8226047295220891, disc_loss = 0.08199531982380966
Trained batch 161 in epoch 16, gen_loss = 0.8228408690587974, disc_loss = 0.08164456526369408
Trained batch 162 in epoch 16, gen_loss = 0.8225657749761102, disc_loss = 0.08165503085870868
Trained batch 163 in epoch 16, gen_loss = 0.8219836248857219, disc_loss = 0.08146652852457653
Trained batch 164 in epoch 16, gen_loss = 0.820599435676228, disc_loss = 0.08188134044070136
Trained batch 165 in epoch 16, gen_loss = 0.8222708777490869, disc_loss = 0.08167466735018485
Trained batch 166 in epoch 16, gen_loss = 0.8217191449896304, disc_loss = 0.08215044428243073
Trained batch 167 in epoch 16, gen_loss = 0.8200846066077551, disc_loss = 0.08314524305474368
Trained batch 168 in epoch 16, gen_loss = 0.8199851999621419, disc_loss = 0.08325030939576365
Trained batch 169 in epoch 16, gen_loss = 0.8186675243517931, disc_loss = 0.08379724102971309
Trained batch 170 in epoch 16, gen_loss = 0.8189695613426075, disc_loss = 0.08404269438149811
Trained batch 171 in epoch 16, gen_loss = 0.8178330552439357, disc_loss = 0.08406772428235515
Trained batch 172 in epoch 16, gen_loss = 0.8176028883526091, disc_loss = 0.0841520252782916
Trained batch 173 in epoch 16, gen_loss = 0.8166103846040266, disc_loss = 0.08419486364863556
Trained batch 174 in epoch 16, gen_loss = 0.8178762030601502, disc_loss = 0.08401742899524314
Trained batch 175 in epoch 16, gen_loss = 0.8164275888014924, disc_loss = 0.08439097594236955
Trained batch 176 in epoch 16, gen_loss = 0.8154511704283246, disc_loss = 0.08447111771036844
Trained batch 177 in epoch 16, gen_loss = 0.8140686797292045, disc_loss = 0.0846186532073895
Trained batch 178 in epoch 16, gen_loss = 0.8150012726224335, disc_loss = 0.0844289086727873
Trained batch 179 in epoch 16, gen_loss = 0.814658882551723, disc_loss = 0.08433064854082963
Trained batch 180 in epoch 16, gen_loss = 0.8142682350142885, disc_loss = 0.08414536009115574
Trained batch 181 in epoch 16, gen_loss = 0.8136278534983541, disc_loss = 0.0839407103044073
Trained batch 182 in epoch 16, gen_loss = 0.8134662691361266, disc_loss = 0.08381737569662553
Trained batch 183 in epoch 16, gen_loss = 0.8137171799721925, disc_loss = 0.08385564290169302
Trained batch 184 in epoch 16, gen_loss = 0.8138161646353231, disc_loss = 0.08363920364126161
Trained batch 185 in epoch 16, gen_loss = 0.8144630440460738, disc_loss = 0.08346719040925946
Trained batch 186 in epoch 16, gen_loss = 0.8130445152043021, disc_loss = 0.08387446963791063
Trained batch 187 in epoch 16, gen_loss = 0.8134736301417046, disc_loss = 0.08395686621302144
Trained batch 188 in epoch 16, gen_loss = 0.8132070690866501, disc_loss = 0.0836677879597696
Trained batch 189 in epoch 16, gen_loss = 0.8148268765524814, disc_loss = 0.08424271254457141
Trained batch 190 in epoch 16, gen_loss = 0.8139477793458869, disc_loss = 0.08453827194811006
Trained batch 191 in epoch 16, gen_loss = 0.8127203515420357, disc_loss = 0.08447816847183276
Trained batch 192 in epoch 16, gen_loss = 0.812137800794809, disc_loss = 0.08486132164982779
Trained batch 193 in epoch 16, gen_loss = 0.8127804702704715, disc_loss = 0.08493506343382382
Trained batch 194 in epoch 16, gen_loss = 0.8130011561589363, disc_loss = 0.08463123259731592
Trained batch 195 in epoch 16, gen_loss = 0.8122627202953611, disc_loss = 0.08482286872399249
Trained batch 196 in epoch 16, gen_loss = 0.811398256248629, disc_loss = 0.084843890377448
Trained batch 197 in epoch 16, gen_loss = 0.8125927406128006, disc_loss = 0.0850922913723296
Trained batch 198 in epoch 16, gen_loss = 0.8120161603443586, disc_loss = 0.08504670965555475
Trained batch 199 in epoch 16, gen_loss = 0.8115288105607033, disc_loss = 0.08482235135976225
Trained batch 200 in epoch 16, gen_loss = 0.8118012559354602, disc_loss = 0.08478853357168127
Trained batch 201 in epoch 16, gen_loss = 0.8120000598454239, disc_loss = 0.08474991506076243
Trained batch 202 in epoch 16, gen_loss = 0.8110813284155183, disc_loss = 0.08496551970341082
Trained batch 203 in epoch 16, gen_loss = 0.8099419673283895, disc_loss = 0.08498839488453871
Trained batch 204 in epoch 16, gen_loss = 0.8108338812502419, disc_loss = 0.08475874559272353
Trained batch 205 in epoch 16, gen_loss = 0.8134366716574697, disc_loss = 0.08511652354856283
Trained batch 206 in epoch 16, gen_loss = 0.8131866961861578, disc_loss = 0.08499777650433606
Trained batch 207 in epoch 16, gen_loss = 0.8121655010260068, disc_loss = 0.08512959774816409
Trained batch 208 in epoch 16, gen_loss = 0.8122456952145225, disc_loss = 0.08483806448993073
Trained batch 209 in epoch 16, gen_loss = 0.8129661398274558, disc_loss = 0.08471282939204858
Trained batch 210 in epoch 16, gen_loss = 0.8120810861271139, disc_loss = 0.08474042053418278
Trained batch 211 in epoch 16, gen_loss = 0.8115932022063237, disc_loss = 0.08468119296210133
Trained batch 212 in epoch 16, gen_loss = 0.8120072232165807, disc_loss = 0.08452288511301011
Trained batch 213 in epoch 16, gen_loss = 0.8124230077890592, disc_loss = 0.08446445596778643
Trained batch 214 in epoch 16, gen_loss = 0.8119840702345205, disc_loss = 0.0842602874693829
Trained batch 215 in epoch 16, gen_loss = 0.8110928427841928, disc_loss = 0.08422921229309092
Trained batch 216 in epoch 16, gen_loss = 0.8109910172251512, disc_loss = 0.08392599868386434
Trained batch 217 in epoch 16, gen_loss = 0.8138718514814289, disc_loss = 0.08424029476650127
Trained batch 218 in epoch 16, gen_loss = 0.8143371183033947, disc_loss = 0.08398795131696006
Trained batch 219 in epoch 16, gen_loss = 0.8140746975486929, disc_loss = 0.08382997967048803
Trained batch 220 in epoch 16, gen_loss = 0.8134254686433265, disc_loss = 0.08363422015218308
Trained batch 221 in epoch 16, gen_loss = 0.8133295683173446, disc_loss = 0.08356234198436141
Trained batch 222 in epoch 16, gen_loss = 0.8128832436997794, disc_loss = 0.08401803794680289
Trained batch 223 in epoch 16, gen_loss = 0.8114491658551353, disc_loss = 0.08440825884047497
Trained batch 224 in epoch 16, gen_loss = 0.8122932354609171, disc_loss = 0.08409709431231022
Trained batch 225 in epoch 16, gen_loss = 0.8123611137930271, disc_loss = 0.083878063679203
Trained batch 226 in epoch 16, gen_loss = 0.8133931517075862, disc_loss = 0.08424966899669906
Trained batch 227 in epoch 16, gen_loss = 0.8124819782219435, disc_loss = 0.08421764757255451
Trained batch 228 in epoch 16, gen_loss = 0.8118188305713204, disc_loss = 0.08409756546490317
Trained batch 229 in epoch 16, gen_loss = 0.8122905132563217, disc_loss = 0.08388180137490449
Trained batch 230 in epoch 16, gen_loss = 0.8116105116290964, disc_loss = 0.08381122054766009
Trained batch 231 in epoch 16, gen_loss = 0.8138411689935059, disc_loss = 0.08473930033405536
Trained batch 232 in epoch 16, gen_loss = 0.8130990156799939, disc_loss = 0.08485372231018135
Trained batch 233 in epoch 16, gen_loss = 0.8125837414692609, disc_loss = 0.0846274088924894
Trained batch 234 in epoch 16, gen_loss = 0.812976836143656, disc_loss = 0.08440006202522744
Trained batch 235 in epoch 16, gen_loss = 0.812774588495998, disc_loss = 0.08436836168106834
Trained batch 236 in epoch 16, gen_loss = 0.8117482674775748, disc_loss = 0.08464448416471984
Trained batch 237 in epoch 16, gen_loss = 0.8115216666409949, disc_loss = 0.08484827337332633
Trained batch 238 in epoch 16, gen_loss = 0.812072705524237, disc_loss = 0.08455951992718495
Trained batch 239 in epoch 16, gen_loss = 0.8120627005894979, disc_loss = 0.08434999964665621
Trained batch 240 in epoch 16, gen_loss = 0.8119283501538004, disc_loss = 0.08438903431087362
Trained batch 241 in epoch 16, gen_loss = 0.8124576447423825, disc_loss = 0.08410873556555795
Trained batch 242 in epoch 16, gen_loss = 0.8124769891731043, disc_loss = 0.08387449149946863
Trained batch 243 in epoch 16, gen_loss = 0.8139437402858108, disc_loss = 0.08392385948357768
Trained batch 244 in epoch 16, gen_loss = 0.8128122076696279, disc_loss = 0.08385665172673001
Trained batch 245 in epoch 16, gen_loss = 0.8126385585079349, disc_loss = 0.08369734010288143
Trained batch 246 in epoch 16, gen_loss = 0.8116489894959608, disc_loss = 0.08388528776042133
Trained batch 247 in epoch 16, gen_loss = 0.815442134776423, disc_loss = 0.08483672495781173
Trained batch 248 in epoch 16, gen_loss = 0.8176464886071692, disc_loss = 0.08485573173377169
Trained batch 249 in epoch 16, gen_loss = 0.8166786966323852, disc_loss = 0.08509393992275
Trained batch 250 in epoch 16, gen_loss = 0.8160607100008018, disc_loss = 0.08520556849045345
Trained batch 251 in epoch 16, gen_loss = 0.816917502454349, disc_loss = 0.08521187420017899
Trained batch 252 in epoch 16, gen_loss = 0.8167013598996189, disc_loss = 0.08576078744597822
Trained batch 253 in epoch 16, gen_loss = 0.8161320278025049, disc_loss = 0.08559476659728552
Trained batch 254 in epoch 16, gen_loss = 0.8164126569149541, disc_loss = 0.08544920842875453
Trained batch 255 in epoch 16, gen_loss = 0.8157324255444109, disc_loss = 0.08543282961909426
Trained batch 256 in epoch 16, gen_loss = 0.8150785377517284, disc_loss = 0.08539733394313648
Trained batch 257 in epoch 16, gen_loss = 0.8159218721611555, disc_loss = 0.08590356814277958
Trained batch 258 in epoch 16, gen_loss = 0.8161058333849814, disc_loss = 0.08568406869517099
Trained batch 259 in epoch 16, gen_loss = 0.8163720463330929, disc_loss = 0.085445197370763
Trained batch 260 in epoch 16, gen_loss = 0.8150997092212297, disc_loss = 0.08602600608920229
Trained batch 261 in epoch 16, gen_loss = 0.8160242400779069, disc_loss = 0.08583892880448403
Trained batch 262 in epoch 16, gen_loss = 0.8176896897332296, disc_loss = 0.08592917550595994
Trained batch 263 in epoch 16, gen_loss = 0.8181795652842883, disc_loss = 0.08575122612951831
Trained batch 264 in epoch 16, gen_loss = 0.818283046304055, disc_loss = 0.08569815593226901
Trained batch 265 in epoch 16, gen_loss = 0.8179493036709333, disc_loss = 0.08568645382117956
Trained batch 266 in epoch 16, gen_loss = 0.8184003674805388, disc_loss = 0.08566194575991523
Trained batch 267 in epoch 16, gen_loss = 0.8192214250786981, disc_loss = 0.08543786623362284
Trained batch 268 in epoch 16, gen_loss = 0.818857965970128, disc_loss = 0.08543261896721936
Trained batch 269 in epoch 16, gen_loss = 0.8191214034954707, disc_loss = 0.08535452747234591
Trained batch 270 in epoch 16, gen_loss = 0.8189660793520868, disc_loss = 0.08540160360151551
Trained batch 271 in epoch 16, gen_loss = 0.8187026472433525, disc_loss = 0.08524226554779007
Trained batch 272 in epoch 16, gen_loss = 0.8183428506493132, disc_loss = 0.08517696524223128
Trained batch 273 in epoch 16, gen_loss = 0.8192611209449977, disc_loss = 0.08495424222201109
Trained batch 274 in epoch 16, gen_loss = 0.8193740401484749, disc_loss = 0.0848764142055403
Trained batch 275 in epoch 16, gen_loss = 0.8184294302178465, disc_loss = 0.08544972019971929
Trained batch 276 in epoch 16, gen_loss = 0.8192503236045906, disc_loss = 0.08554346121793835
Trained batch 277 in epoch 16, gen_loss = 0.8196837860260079, disc_loss = 0.08528244993213913
Trained batch 278 in epoch 16, gen_loss = 0.8190870559557364, disc_loss = 0.0851968692875998
Trained batch 279 in epoch 16, gen_loss = 0.8187646854136671, disc_loss = 0.08511168888237859
Trained batch 280 in epoch 16, gen_loss = 0.8191857080230509, disc_loss = 0.0848592555090732
Trained batch 281 in epoch 16, gen_loss = 0.8189864244232786, disc_loss = 0.08477704357091628
Trained batch 282 in epoch 16, gen_loss = 0.8198165174297225, disc_loss = 0.08452531228059172
Trained batch 283 in epoch 16, gen_loss = 0.8206108410803366, disc_loss = 0.08434792522760765
Trained batch 284 in epoch 16, gen_loss = 0.8207413820843947, disc_loss = 0.08427271852106379
Trained batch 285 in epoch 16, gen_loss = 0.8199141472578049, disc_loss = 0.08459134372537369
Trained batch 286 in epoch 16, gen_loss = 0.8202037253653962, disc_loss = 0.08445568585229668
Trained batch 287 in epoch 16, gen_loss = 0.8208591812807653, disc_loss = 0.08423193255698101
Trained batch 288 in epoch 16, gen_loss = 0.8220245837134061, disc_loss = 0.0841638957984926
Trained batch 289 in epoch 16, gen_loss = 0.8218171338582861, disc_loss = 0.08401611439626792
Trained batch 290 in epoch 16, gen_loss = 0.8209862370056795, disc_loss = 0.08409709875116643
Trained batch 291 in epoch 16, gen_loss = 0.8214447387073138, disc_loss = 0.08402828377199499
Trained batch 292 in epoch 16, gen_loss = 0.8214528913587433, disc_loss = 0.08393184344821415
Trained batch 293 in epoch 16, gen_loss = 0.8210874648929454, disc_loss = 0.08386487328783185
Trained batch 294 in epoch 16, gen_loss = 0.8220360908467891, disc_loss = 0.08370168725565329
Trained batch 295 in epoch 16, gen_loss = 0.8219001272038834, disc_loss = 0.08349193236790597
Trained batch 296 in epoch 16, gen_loss = 0.8209018702258165, disc_loss = 0.08375290123375778
Trained batch 297 in epoch 16, gen_loss = 0.8213713978160948, disc_loss = 0.0835564921566304
Trained batch 298 in epoch 16, gen_loss = 0.8224955798192167, disc_loss = 0.08352085237818019
Trained batch 299 in epoch 16, gen_loss = 0.8222042366862297, disc_loss = 0.08329357298091054
Trained batch 300 in epoch 16, gen_loss = 0.8214953978394353, disc_loss = 0.08346614372170842
Trained batch 301 in epoch 16, gen_loss = 0.8219149778812926, disc_loss = 0.08329237054490687
Trained batch 302 in epoch 16, gen_loss = 0.8231092403234035, disc_loss = 0.08337407083966748
Trained batch 303 in epoch 16, gen_loss = 0.8222702311253861, disc_loss = 0.08333581609430869
Trained batch 304 in epoch 16, gen_loss = 0.8221677046330249, disc_loss = 0.08326783343294605
Trained batch 305 in epoch 16, gen_loss = 0.8221495440777611, disc_loss = 0.08305096791241488
Trained batch 306 in epoch 16, gen_loss = 0.8220211169424585, disc_loss = 0.08299399727306266
Trained batch 307 in epoch 16, gen_loss = 0.8231011101758325, disc_loss = 0.0832993431657843
Trained batch 308 in epoch 16, gen_loss = 0.8221359159375472, disc_loss = 0.08336016429063764
Trained batch 309 in epoch 16, gen_loss = 0.8221806765564026, disc_loss = 0.08320620376616716
Trained batch 310 in epoch 16, gen_loss = 0.8217474740609478, disc_loss = 0.08319960136289957
Trained batch 311 in epoch 16, gen_loss = 0.8213067227640213, disc_loss = 0.08305087686182024
Trained batch 312 in epoch 16, gen_loss = 0.8223494139913553, disc_loss = 0.08300494891219436
Trained batch 313 in epoch 16, gen_loss = 0.8211967889100883, disc_loss = 0.083253057999833
Trained batch 314 in epoch 16, gen_loss = 0.8205906551035623, disc_loss = 0.08322654286665576
Trained batch 315 in epoch 16, gen_loss = 0.8211667957373813, disc_loss = 0.08303456501210038
Trained batch 316 in epoch 16, gen_loss = 0.8207942376189428, disc_loss = 0.08303922638062047
Trained batch 317 in epoch 16, gen_loss = 0.820598821688748, disc_loss = 0.0830149900097892
Trained batch 318 in epoch 16, gen_loss = 0.8199662996870597, disc_loss = 0.08302397026350505
Trained batch 319 in epoch 16, gen_loss = 0.8200588400475681, disc_loss = 0.08282049398403615
Trained batch 320 in epoch 16, gen_loss = 0.8204721304300789, disc_loss = 0.08268958507714985
Trained batch 321 in epoch 16, gen_loss = 0.8209172900974381, disc_loss = 0.08267562275301225
Trained batch 322 in epoch 16, gen_loss = 0.8204355550808803, disc_loss = 0.08262621843178206
Trained batch 323 in epoch 16, gen_loss = 0.8202739726798034, disc_loss = 0.08254244213026983
Trained batch 324 in epoch 16, gen_loss = 0.8203040536550376, disc_loss = 0.08250935433002618
Trained batch 325 in epoch 16, gen_loss = 0.8209789782031182, disc_loss = 0.08246817320950924
Trained batch 326 in epoch 16, gen_loss = 0.8211426305661508, disc_loss = 0.08234131896714551
Trained batch 327 in epoch 16, gen_loss = 0.8219003478383146, disc_loss = 0.08214869998145576
Trained batch 328 in epoch 16, gen_loss = 0.8222444572890784, disc_loss = 0.08193826513778203
Trained batch 329 in epoch 16, gen_loss = 0.8217679631529432, disc_loss = 0.08191736319356344
Trained batch 330 in epoch 16, gen_loss = 0.8220270534476485, disc_loss = 0.08171352133818893
Trained batch 331 in epoch 16, gen_loss = 0.8222112272338695, disc_loss = 0.08167550656439579
Trained batch 332 in epoch 16, gen_loss = 0.8222915069297986, disc_loss = 0.08157579855596249
Trained batch 333 in epoch 16, gen_loss = 0.8221654452071219, disc_loss = 0.08146812242294053
Trained batch 334 in epoch 16, gen_loss = 0.8224245785777249, disc_loss = 0.081284945138466
Trained batch 335 in epoch 16, gen_loss = 0.8223535089443127, disc_loss = 0.08108769141281733
Trained batch 336 in epoch 16, gen_loss = 0.8220813717438842, disc_loss = 0.08094221461033697
Trained batch 337 in epoch 16, gen_loss = 0.8223912891375242, disc_loss = 0.0808358528298607
Trained batch 338 in epoch 16, gen_loss = 0.8231008871290888, disc_loss = 0.08064026770437449
Trained batch 339 in epoch 16, gen_loss = 0.8232583961942617, disc_loss = 0.0804748827509363
Trained batch 340 in epoch 16, gen_loss = 0.8231681746996043, disc_loss = 0.0804126417712251
Trained batch 341 in epoch 16, gen_loss = 0.8233464951926505, disc_loss = 0.08035540834820845
Trained batch 342 in epoch 16, gen_loss = 0.8242147044433449, disc_loss = 0.08028368223132701
Trained batch 343 in epoch 16, gen_loss = 0.8243249827172867, disc_loss = 0.08023631210211492
Trained batch 344 in epoch 16, gen_loss = 0.8239655666593192, disc_loss = 0.08023284085472857
Trained batch 345 in epoch 16, gen_loss = 0.8233374063506981, disc_loss = 0.08028318314420092
Trained batch 346 in epoch 16, gen_loss = 0.8238512287050571, disc_loss = 0.0802817188487831
Trained batch 347 in epoch 16, gen_loss = 0.8242160469807428, disc_loss = 0.08020346553129112
Trained batch 348 in epoch 16, gen_loss = 0.8247809462185234, disc_loss = 0.08001325052114135
Trained batch 349 in epoch 16, gen_loss = 0.8245103501422064, disc_loss = 0.08005800327020032
Trained batch 350 in epoch 16, gen_loss = 0.8244685191884, disc_loss = 0.07994626257621665
Trained batch 351 in epoch 16, gen_loss = 0.8246668723665855, disc_loss = 0.07990238672672687
Trained batch 352 in epoch 16, gen_loss = 0.8258502494343279, disc_loss = 0.07995818117396014
Trained batch 353 in epoch 16, gen_loss = 0.8253060027872775, disc_loss = 0.08008401492600051
Trained batch 354 in epoch 16, gen_loss = 0.8257430445140517, disc_loss = 0.07991931488816167
Trained batch 355 in epoch 16, gen_loss = 0.8258840221534954, disc_loss = 0.07978027109893855
Trained batch 356 in epoch 16, gen_loss = 0.825721702071465, disc_loss = 0.07966918242620487
Trained batch 357 in epoch 16, gen_loss = 0.8261977171931187, disc_loss = 0.07954187718266881
Trained batch 358 in epoch 16, gen_loss = 0.8271886868231144, disc_loss = 0.07938116081162748
Trained batch 359 in epoch 16, gen_loss = 0.8267714623775747, disc_loss = 0.07942427123586336
Trained batch 360 in epoch 16, gen_loss = 0.8259603177246294, disc_loss = 0.0795455723381769
Trained batch 361 in epoch 16, gen_loss = 0.8265672634813667, disc_loss = 0.07958019609197728
Trained batch 362 in epoch 16, gen_loss = 0.82671967395081, disc_loss = 0.07961085526985899
Trained batch 363 in epoch 16, gen_loss = 0.826304048709162, disc_loss = 0.07949022841281615
Trained batch 364 in epoch 16, gen_loss = 0.8259566218069155, disc_loss = 0.07950087039642138
Trained batch 365 in epoch 16, gen_loss = 0.8259226255566696, disc_loss = 0.07939291341342236
Trained batch 366 in epoch 16, gen_loss = 0.8265259268335815, disc_loss = 0.0792547554153269
Trained batch 367 in epoch 16, gen_loss = 0.8266763679845177, disc_loss = 0.07909809911886798
Trained batch 368 in epoch 16, gen_loss = 0.8270463958826815, disc_loss = 0.07894088391991973
Trained batch 369 in epoch 16, gen_loss = 0.8267217872110573, disc_loss = 0.07879356748953059
Trained batch 370 in epoch 16, gen_loss = 0.8263437973681808, disc_loss = 0.07885965342430092
Trained batch 371 in epoch 16, gen_loss = 0.8272403601196504, disc_loss = 0.07897974986342653
Trained batch 372 in epoch 16, gen_loss = 0.8273686658760817, disc_loss = 0.07883537380928649
Trained batch 373 in epoch 16, gen_loss = 0.8270500676039069, disc_loss = 0.07891234044324268
Trained batch 374 in epoch 16, gen_loss = 0.8271627026398977, disc_loss = 0.07877747691174349
Trained batch 375 in epoch 16, gen_loss = 0.8272361649953305, disc_loss = 0.07875470633301487
Trained batch 376 in epoch 16, gen_loss = 0.8274546522518684, disc_loss = 0.0786611580435651
Trained batch 377 in epoch 16, gen_loss = 0.8273361084795503, disc_loss = 0.07854278279695089
Trained batch 378 in epoch 16, gen_loss = 0.8278279388642877, disc_loss = 0.07837015211749282
Trained batch 379 in epoch 16, gen_loss = 0.8278670335286542, disc_loss = 0.07825152299759028
Trained batch 380 in epoch 16, gen_loss = 0.8274042086181991, disc_loss = 0.07815535306158107
Trained batch 381 in epoch 16, gen_loss = 0.8268496546289683, disc_loss = 0.07815149518373515
Trained batch 382 in epoch 16, gen_loss = 0.827286736538765, disc_loss = 0.07841560600797205
Trained batch 383 in epoch 16, gen_loss = 0.8272453452615688, disc_loss = 0.07831872854391501
Trained batch 384 in epoch 16, gen_loss = 0.8268629344252797, disc_loss = 0.07838280700485814
Trained batch 385 in epoch 16, gen_loss = 0.827528329479262, disc_loss = 0.07849089776460139
Trained batch 386 in epoch 16, gen_loss = 0.8279685375764388, disc_loss = 0.0783559303437131
Trained batch 387 in epoch 16, gen_loss = 0.8280784952425465, disc_loss = 0.07819838546571735
Trained batch 388 in epoch 16, gen_loss = 0.8274274568784513, disc_loss = 0.07827474547736825
Trained batch 389 in epoch 16, gen_loss = 0.827396780023208, disc_loss = 0.07819441160760247
Trained batch 390 in epoch 16, gen_loss = 0.8274648402200635, disc_loss = 0.07817340382348623
Trained batch 391 in epoch 16, gen_loss = 0.827607484572396, disc_loss = 0.07803157958610706
Trained batch 392 in epoch 16, gen_loss = 0.8275207427470131, disc_loss = 0.0779631145170513
Trained batch 393 in epoch 16, gen_loss = 0.8278210818918829, disc_loss = 0.07782689125754583
Trained batch 394 in epoch 16, gen_loss = 0.8282656466659112, disc_loss = 0.07776922106601392
Trained batch 395 in epoch 16, gen_loss = 0.8280950422690372, disc_loss = 0.07766751456074417
Trained batch 396 in epoch 16, gen_loss = 0.8272994529240077, disc_loss = 0.07786829143021284
Trained batch 397 in epoch 16, gen_loss = 0.8279384450247539, disc_loss = 0.07776394990230699
Trained batch 398 in epoch 16, gen_loss = 0.8277157988016468, disc_loss = 0.07774993303210888
Trained batch 399 in epoch 16, gen_loss = 0.8281028506904841, disc_loss = 0.07763185564661398
Trained batch 400 in epoch 16, gen_loss = 0.8286820418965489, disc_loss = 0.0776612301591663
Trained batch 401 in epoch 16, gen_loss = 0.8278795629739761, disc_loss = 0.07791279808882234
Trained batch 402 in epoch 16, gen_loss = 0.8285737257293673, disc_loss = 0.0778350592995289
Trained batch 403 in epoch 16, gen_loss = 0.8295435504895625, disc_loss = 0.0781825123894222
Trained batch 404 in epoch 16, gen_loss = 0.8287711515102858, disc_loss = 0.07842821787214942
Trained batch 405 in epoch 16, gen_loss = 0.828460126748226, disc_loss = 0.07846854679662679
Trained batch 406 in epoch 16, gen_loss = 0.8286949455445171, disc_loss = 0.07886033548449489
Trained batch 407 in epoch 16, gen_loss = 0.8285161359783482, disc_loss = 0.0787748381901788
Trained batch 408 in epoch 16, gen_loss = 0.8280479171311068, disc_loss = 0.0789188607220144
Trained batch 409 in epoch 16, gen_loss = 0.8280076811226403, disc_loss = 0.07879202052632847
Trained batch 410 in epoch 16, gen_loss = 0.8283729272602248, disc_loss = 0.07869070610869902
Trained batch 411 in epoch 16, gen_loss = 0.8279946555645721, disc_loss = 0.07863216232553631
Trained batch 412 in epoch 16, gen_loss = 0.8276827040220865, disc_loss = 0.07851726790669106
Trained batch 413 in epoch 16, gen_loss = 0.827990541783508, disc_loss = 0.07842069251264855
Trained batch 414 in epoch 16, gen_loss = 0.8278948396803385, disc_loss = 0.07839467445365995
Trained batch 415 in epoch 16, gen_loss = 0.827788760813956, disc_loss = 0.07843795281503564
Trained batch 416 in epoch 16, gen_loss = 0.8273782625043993, disc_loss = 0.07867470632666806
Trained batch 417 in epoch 16, gen_loss = 0.8272467836666335, disc_loss = 0.0786017367781171
Trained batch 418 in epoch 16, gen_loss = 0.8271162320008426, disc_loss = 0.07874511389244072
Trained batch 419 in epoch 16, gen_loss = 0.8268755348665374, disc_loss = 0.0786500075366348
Trained batch 420 in epoch 16, gen_loss = 0.8259745806526402, disc_loss = 0.07885540154432953
Trained batch 421 in epoch 16, gen_loss = 0.8256518251805509, disc_loss = 0.07877944335473869
Trained batch 422 in epoch 16, gen_loss = 0.8261909883636673, disc_loss = 0.07893535247992892
Trained batch 423 in epoch 16, gen_loss = 0.8267627851861827, disc_loss = 0.0788261787153183
Trained batch 424 in epoch 16, gen_loss = 0.8265938110912547, disc_loss = 0.07877542001140468
Trained batch 425 in epoch 16, gen_loss = 0.8260105746172963, disc_loss = 0.07932133220372276
Trained batch 426 in epoch 16, gen_loss = 0.8264611648173187, disc_loss = 0.07939884766055144
Trained batch 427 in epoch 16, gen_loss = 0.8275799933716516, disc_loss = 0.07943700831688105
Trained batch 428 in epoch 16, gen_loss = 0.8270595489126263, disc_loss = 0.0795115522827545
Trained batch 429 in epoch 16, gen_loss = 0.8269637028838313, disc_loss = 0.07939228223810016
Trained batch 430 in epoch 16, gen_loss = 0.8268971816569636, disc_loss = 0.07939125582567155
Trained batch 431 in epoch 16, gen_loss = 0.8273123704172947, disc_loss = 0.07928164240136673
Trained batch 432 in epoch 16, gen_loss = 0.8272935712309963, disc_loss = 0.0792547265523679
Trained batch 433 in epoch 16, gen_loss = 0.8272701497726177, disc_loss = 0.07918767518393936
Trained batch 434 in epoch 16, gen_loss = 0.826914665753814, disc_loss = 0.07930036992819488
Trained batch 435 in epoch 16, gen_loss = 0.8283384946781561, disc_loss = 0.07945230169811311
Trained batch 436 in epoch 16, gen_loss = 0.8290374310393083, disc_loss = 0.07940349832509626
Trained batch 437 in epoch 16, gen_loss = 0.8288891674721077, disc_loss = 0.07940015148107796
Trained batch 438 in epoch 16, gen_loss = 0.8286888770470586, disc_loss = 0.07934293996729382
Trained batch 439 in epoch 16, gen_loss = 0.8283947371623733, disc_loss = 0.07931045628025789
Trained batch 440 in epoch 16, gen_loss = 0.8280099739833754, disc_loss = 0.07929046689205362
Trained batch 441 in epoch 16, gen_loss = 0.8291232735592855, disc_loss = 0.07943415106379541
Trained batch 442 in epoch 16, gen_loss = 0.8290949536500074, disc_loss = 0.07932469915413627
Trained batch 443 in epoch 16, gen_loss = 0.8292627113090979, disc_loss = 0.07917264747424974
Trained batch 444 in epoch 16, gen_loss = 0.8291567309518878, disc_loss = 0.07909791777642926
Trained batch 445 in epoch 16, gen_loss = 0.8289780100899427, disc_loss = 0.07904469034730587
Trained batch 446 in epoch 16, gen_loss = 0.8291831613920412, disc_loss = 0.07907793014174873
Trained batch 447 in epoch 16, gen_loss = 0.8289797031985862, disc_loss = 0.0790160108008422
Trained batch 448 in epoch 16, gen_loss = 0.829049938903885, disc_loss = 0.0789226409885825
Trained batch 449 in epoch 16, gen_loss = 0.8292006602552202, disc_loss = 0.07878763314750459
Trained batch 450 in epoch 16, gen_loss = 0.8289224087795503, disc_loss = 0.07870916337468671
Trained batch 451 in epoch 16, gen_loss = 0.8290010405852731, disc_loss = 0.07857162469948552
Trained batch 452 in epoch 16, gen_loss = 0.8295185981733646, disc_loss = 0.07856908572989847
Trained batch 453 in epoch 16, gen_loss = 0.8289783418441133, disc_loss = 0.07860802418433359
Trained batch 454 in epoch 16, gen_loss = 0.8286846578776181, disc_loss = 0.07858546676707792
Trained batch 455 in epoch 16, gen_loss = 0.8287916021388874, disc_loss = 0.07843838035325079
Trained batch 456 in epoch 16, gen_loss = 0.8286740541197278, disc_loss = 0.07852572693002433
Trained batch 457 in epoch 16, gen_loss = 0.8291147258864741, disc_loss = 0.07840661532509925
Trained batch 458 in epoch 16, gen_loss = 0.8289149299685992, disc_loss = 0.07832563819854738
Trained batch 459 in epoch 16, gen_loss = 0.8284530587818312, disc_loss = 0.07826118262322701
Trained batch 460 in epoch 16, gen_loss = 0.8283147932133292, disc_loss = 0.07817855330664915
Trained batch 461 in epoch 16, gen_loss = 0.8282643206965872, disc_loss = 0.07819914039288893
Trained batch 462 in epoch 16, gen_loss = 0.8281622626869004, disc_loss = 0.0780730783239361
Trained batch 463 in epoch 16, gen_loss = 0.8279156269955223, disc_loss = 0.07815904689326497
Trained batch 464 in epoch 16, gen_loss = 0.8282368968891841, disc_loss = 0.07802192834756708
Trained batch 465 in epoch 16, gen_loss = 0.828806556985102, disc_loss = 0.07791966165899591
Trained batch 466 in epoch 16, gen_loss = 0.8286931099932505, disc_loss = 0.0778056890235085
Trained batch 467 in epoch 16, gen_loss = 0.8285542765998433, disc_loss = 0.07769727394876318
Trained batch 468 in epoch 16, gen_loss = 0.8286719131571397, disc_loss = 0.07756922523508956
Trained batch 469 in epoch 16, gen_loss = 0.8300836073591354, disc_loss = 0.0777326439685644
Trained batch 470 in epoch 16, gen_loss = 0.8298197513932635, disc_loss = 0.07774621658739012
Trained batch 471 in epoch 16, gen_loss = 0.8292188053413972, disc_loss = 0.07773389042970741
Trained batch 472 in epoch 16, gen_loss = 0.8294613699076292, disc_loss = 0.07761869195604551
Trained batch 473 in epoch 16, gen_loss = 0.8295796033199326, disc_loss = 0.07756699082139046
Trained batch 474 in epoch 16, gen_loss = 0.8293340773331491, disc_loss = 0.0775643488098132
Trained batch 475 in epoch 16, gen_loss = 0.8296787788887986, disc_loss = 0.077443988833326
Trained batch 476 in epoch 16, gen_loss = 0.8299713950736968, disc_loss = 0.0773004941189314
Trained batch 477 in epoch 16, gen_loss = 0.8300794601191038, disc_loss = 0.07722795505279277
Trained batch 478 in epoch 16, gen_loss = 0.8293192579502353, disc_loss = 0.0774512672660744
Trained batch 479 in epoch 16, gen_loss = 0.829697015012304, disc_loss = 0.07754457133511702
Trained batch 480 in epoch 16, gen_loss = 0.830155257251803, disc_loss = 0.07742266630339523
Trained batch 481 in epoch 16, gen_loss = 0.8304416203399911, disc_loss = 0.0773061018019791
Trained batch 482 in epoch 16, gen_loss = 0.8298447970030964, disc_loss = 0.0775566329990608
Trained batch 483 in epoch 16, gen_loss = 0.8298079522926946, disc_loss = 0.07743957181160976
Trained batch 484 in epoch 16, gen_loss = 0.8296710732056922, disc_loss = 0.07735282269872955
Trained batch 485 in epoch 16, gen_loss = 0.8298755089441935, disc_loss = 0.07725554229040082
Trained batch 486 in epoch 16, gen_loss = 0.8300114686484209, disc_loss = 0.07715474237789241
Trained batch 487 in epoch 16, gen_loss = 0.8298633638464037, disc_loss = 0.07714756786227837
Trained batch 488 in epoch 16, gen_loss = 0.8299675107246041, disc_loss = 0.07706595038907538
Trained batch 489 in epoch 16, gen_loss = 0.8301255508345, disc_loss = 0.07692867052190158
Trained batch 490 in epoch 16, gen_loss = 0.8304050153238953, disc_loss = 0.07690513792567244
Trained batch 491 in epoch 16, gen_loss = 0.8306391890940628, disc_loss = 0.07677361298337336
Trained batch 492 in epoch 16, gen_loss = 0.830360336429449, disc_loss = 0.07666155744653808
Trained batch 493 in epoch 16, gen_loss = 0.8304268729831525, disc_loss = 0.07654767655032246
Trained batch 494 in epoch 16, gen_loss = 0.8306626982159084, disc_loss = 0.07642422864458176
Trained batch 495 in epoch 16, gen_loss = 0.8310319173239893, disc_loss = 0.07631990969586637
Trained batch 496 in epoch 16, gen_loss = 0.8315121268842302, disc_loss = 0.07620784570978321
Trained batch 497 in epoch 16, gen_loss = 0.8313588794455471, disc_loss = 0.07618455808370347
Trained batch 498 in epoch 16, gen_loss = 0.8307932701282845, disc_loss = 0.07624799274057449
Trained batch 499 in epoch 16, gen_loss = 0.8306306114196778, disc_loss = 0.07619840113446116
Trained batch 500 in epoch 16, gen_loss = 0.830956222649344, disc_loss = 0.07615331240266027
Trained batch 501 in epoch 16, gen_loss = 0.8319489159194596, disc_loss = 0.07623526420948872
Trained batch 502 in epoch 16, gen_loss = 0.8317518914433171, disc_loss = 0.07652053903143993
Trained batch 503 in epoch 16, gen_loss = 0.8322084593394447, disc_loss = 0.07648108102425578
Trained batch 504 in epoch 16, gen_loss = 0.8320646483119172, disc_loss = 0.07648971279585125
Trained batch 505 in epoch 16, gen_loss = 0.8321691835115078, disc_loss = 0.07640785851659393
Trained batch 506 in epoch 16, gen_loss = 0.8325194199174584, disc_loss = 0.07628777484121113
Trained batch 507 in epoch 16, gen_loss = 0.8326865952080629, disc_loss = 0.07619081388271641
Trained batch 508 in epoch 16, gen_loss = 0.8324738832260162, disc_loss = 0.07613170348759192
Trained batch 509 in epoch 16, gen_loss = 0.8319854894105125, disc_loss = 0.07609592662101575
Trained batch 510 in epoch 16, gen_loss = 0.8324655435556535, disc_loss = 0.07609982447928354
Trained batch 511 in epoch 16, gen_loss = 0.8324802616843954, disc_loss = 0.07600596409065474
Trained batch 512 in epoch 16, gen_loss = 0.8328896513459279, disc_loss = 0.07590708175227481
Trained batch 513 in epoch 16, gen_loss = 0.8325447868048449, disc_loss = 0.07597050884854527
Trained batch 514 in epoch 16, gen_loss = 0.8323975083897415, disc_loss = 0.07606678645045144
Trained batch 515 in epoch 16, gen_loss = 0.8320877870848012, disc_loss = 0.07599327945901269
Trained batch 516 in epoch 16, gen_loss = 0.832607385960031, disc_loss = 0.07593458313927257
Trained batch 517 in epoch 16, gen_loss = 0.833381597599928, disc_loss = 0.075892764228148
Trained batch 518 in epoch 16, gen_loss = 0.8331520919165859, disc_loss = 0.0758396129649642
Trained batch 519 in epoch 16, gen_loss = 0.8330738152448948, disc_loss = 0.0757195654611748
Trained batch 520 in epoch 16, gen_loss = 0.833023115220317, disc_loss = 0.07562552663835477
Trained batch 521 in epoch 16, gen_loss = 0.8331883514292853, disc_loss = 0.07550984528629373
Trained batch 522 in epoch 16, gen_loss = 0.8330597492294604, disc_loss = 0.07553513395470028
Trained batch 523 in epoch 16, gen_loss = 0.8329391492004613, disc_loss = 0.07545316732268183
Trained batch 524 in epoch 16, gen_loss = 0.8333073401451111, disc_loss = 0.07546000107058456
Trained batch 525 in epoch 16, gen_loss = 0.8330419291334914, disc_loss = 0.07546882597311708
Trained batch 526 in epoch 16, gen_loss = 0.8330568111372627, disc_loss = 0.07537869751043405
Trained batch 527 in epoch 16, gen_loss = 0.8326787634780912, disc_loss = 0.07534030365941087
Trained batch 528 in epoch 16, gen_loss = 0.8327876473644956, disc_loss = 0.07526497220680371
Trained batch 529 in epoch 16, gen_loss = 0.832531372443685, disc_loss = 0.07528639780533201
Trained batch 530 in epoch 16, gen_loss = 0.8329866541981024, disc_loss = 0.07516878206640651
Trained batch 531 in epoch 16, gen_loss = 0.8328037509568652, disc_loss = 0.07517048830334518
Trained batch 532 in epoch 16, gen_loss = 0.8325486135080206, disc_loss = 0.0751561323883218
Trained batch 533 in epoch 16, gen_loss = 0.8323301879430978, disc_loss = 0.07508587720367904
Trained batch 534 in epoch 16, gen_loss = 0.8326668974395111, disc_loss = 0.07533266926271336
Trained batch 535 in epoch 16, gen_loss = 0.833269468105551, disc_loss = 0.07535910717934481
Trained batch 536 in epoch 16, gen_loss = 0.8330101905810322, disc_loss = 0.07535487875772477
Trained batch 537 in epoch 16, gen_loss = 0.8329426044646692, disc_loss = 0.07535332413978847
Trained batch 538 in epoch 16, gen_loss = 0.8331240264073374, disc_loss = 0.07524643796591127
Trained batch 539 in epoch 16, gen_loss = 0.8328883205299025, disc_loss = 0.0752802733435399
Trained batch 540 in epoch 16, gen_loss = 0.8326542797238461, disc_loss = 0.07524173238182134
Trained batch 541 in epoch 16, gen_loss = 0.8324688502563322, disc_loss = 0.07522220731922512
Trained batch 542 in epoch 16, gen_loss = 0.8322362622064341, disc_loss = 0.07516974376421937
Trained batch 543 in epoch 16, gen_loss = 0.8330144403392777, disc_loss = 0.07523978609413676
Trained batch 544 in epoch 16, gen_loss = 0.8330232908966344, disc_loss = 0.07516132402789155
Trained batch 545 in epoch 16, gen_loss = 0.8328259048007783, disc_loss = 0.07510310950119307
Trained batch 546 in epoch 16, gen_loss = 0.832439375751851, disc_loss = 0.07513717065822381
Trained batch 547 in epoch 16, gen_loss = 0.8324823153279993, disc_loss = 0.07509844690683658
Trained batch 548 in epoch 16, gen_loss = 0.8327422542650191, disc_loss = 0.07503672338045034
Trained batch 549 in epoch 16, gen_loss = 0.832811504277316, disc_loss = 0.0749761846830899
Trained batch 550 in epoch 16, gen_loss = 0.8323416119262225, disc_loss = 0.07503548558267296
Trained batch 551 in epoch 16, gen_loss = 0.8320318480980569, disc_loss = 0.07509803447022062
Trained batch 552 in epoch 16, gen_loss = 0.8326169917423945, disc_loss = 0.07524419878062137
Trained batch 553 in epoch 16, gen_loss = 0.8328423820678077, disc_loss = 0.07517738241218165
Trained batch 554 in epoch 16, gen_loss = 0.8323506775203052, disc_loss = 0.07554552269478639
Trained batch 555 in epoch 16, gen_loss = 0.8323993951939851, disc_loss = 0.07551165802484687
Trained batch 556 in epoch 16, gen_loss = 0.8327963995334275, disc_loss = 0.07575465052236453
Trained batch 557 in epoch 16, gen_loss = 0.8322660832208545, disc_loss = 0.07590905647377708
Trained batch 558 in epoch 16, gen_loss = 0.8317939660416946, disc_loss = 0.07593180165561132
Trained batch 559 in epoch 16, gen_loss = 0.8316213832369872, disc_loss = 0.07590435423688698
Trained batch 560 in epoch 16, gen_loss = 0.8319036073438199, disc_loss = 0.07581780640385155
Trained batch 561 in epoch 16, gen_loss = 0.8318992737561358, disc_loss = 0.0757673703651093
Trained batch 562 in epoch 16, gen_loss = 0.8321154591880514, disc_loss = 0.07578834357338943
Trained batch 563 in epoch 16, gen_loss = 0.8315991217151602, disc_loss = 0.07588017050916633
Trained batch 564 in epoch 16, gen_loss = 0.8310670520352051, disc_loss = 0.07597173851280085
Trained batch 565 in epoch 16, gen_loss = 0.8314838515785473, disc_loss = 0.07605891678047896
Trained batch 566 in epoch 16, gen_loss = 0.832022153616372, disc_loss = 0.07601569598865887
Trained batch 567 in epoch 16, gen_loss = 0.8316233952490377, disc_loss = 0.07607947009891061
Trained batch 568 in epoch 16, gen_loss = 0.8312470096904909, disc_loss = 0.07607693826822279
Trained batch 569 in epoch 16, gen_loss = 0.8320266302217517, disc_loss = 0.07603012172407225
Trained batch 570 in epoch 16, gen_loss = 0.8320903113134688, disc_loss = 0.07595427269719528
Trained batch 571 in epoch 16, gen_loss = 0.8318754985824331, disc_loss = 0.0759387067681947
Trained batch 572 in epoch 16, gen_loss = 0.8315812731080446, disc_loss = 0.07592995733308751
Trained batch 573 in epoch 16, gen_loss = 0.8316928500290116, disc_loss = 0.07592629239560213
Trained batch 574 in epoch 16, gen_loss = 0.8323801134980243, disc_loss = 0.07621951448528663
Trained batch 575 in epoch 16, gen_loss = 0.8317432950975167, disc_loss = 0.0764358052272453
Trained batch 576 in epoch 16, gen_loss = 0.8312976076243449, disc_loss = 0.07652803835179818
Trained batch 577 in epoch 16, gen_loss = 0.8316297470285818, disc_loss = 0.07667700751043315
Trained batch 578 in epoch 16, gen_loss = 0.8316724620540731, disc_loss = 0.07698045349929206
Trained batch 579 in epoch 16, gen_loss = 0.8312818002084206, disc_loss = 0.07705690275620798
Trained batch 580 in epoch 16, gen_loss = 0.8313738348767187, disc_loss = 0.07704595375722739
Trained batch 581 in epoch 16, gen_loss = 0.8310877573244351, disc_loss = 0.07720488497404913
Trained batch 582 in epoch 16, gen_loss = 0.831635670739627, disc_loss = 0.07741878027700233
Trained batch 583 in epoch 16, gen_loss = 0.8313676032097372, disc_loss = 0.0774271040708337
Trained batch 584 in epoch 16, gen_loss = 0.8315072492656544, disc_loss = 0.07738086505450754
Trained batch 585 in epoch 16, gen_loss = 0.8309588518769261, disc_loss = 0.07753124594713844
Trained batch 586 in epoch 16, gen_loss = 0.8308092244032904, disc_loss = 0.07752709418814471
Trained batch 587 in epoch 16, gen_loss = 0.8307352181600065, disc_loss = 0.07746681173135635
Trained batch 588 in epoch 16, gen_loss = 0.8304400711189102, disc_loss = 0.07751213751594158
Trained batch 589 in epoch 16, gen_loss = 0.8307997717695721, disc_loss = 0.07750540214069819
Trained batch 590 in epoch 16, gen_loss = 0.8306739400889466, disc_loss = 0.07758338493491994
Trained batch 591 in epoch 16, gen_loss = 0.8306761943810695, disc_loss = 0.07752140474228843
Trained batch 592 in epoch 16, gen_loss = 0.8306055235822526, disc_loss = 0.07745612003725857
Trained batch 593 in epoch 16, gen_loss = 0.8306813796963355, disc_loss = 0.07737026648338796
Trained batch 594 in epoch 16, gen_loss = 0.8311646907269454, disc_loss = 0.07737191726430123
Trained batch 595 in epoch 16, gen_loss = 0.8310280932276041, disc_loss = 0.0774072045647858
Trained batch 596 in epoch 16, gen_loss = 0.8310980157836199, disc_loss = 0.07738783040787507
Trained batch 597 in epoch 16, gen_loss = 0.8309362251623019, disc_loss = 0.07738017358110102
Trained batch 598 in epoch 16, gen_loss = 0.8306890938039216, disc_loss = 0.07741894709795266
Trained batch 599 in epoch 16, gen_loss = 0.8305457490682602, disc_loss = 0.07739888406048219
Trained batch 600 in epoch 16, gen_loss = 0.8305408807840204, disc_loss = 0.07744645419067234
Trained batch 601 in epoch 16, gen_loss = 0.8303857763542289, disc_loss = 0.07738123764825422
Trained batch 602 in epoch 16, gen_loss = 0.8306924932038606, disc_loss = 0.0773099672735034
Trained batch 603 in epoch 16, gen_loss = 0.8307553026455128, disc_loss = 0.07723035748480567
Trained batch 604 in epoch 16, gen_loss = 0.8307816416764062, disc_loss = 0.07715898805167064
Trained batch 605 in epoch 16, gen_loss = 0.8309149231651042, disc_loss = 0.0770643872820554
Trained batch 606 in epoch 16, gen_loss = 0.8306609292006768, disc_loss = 0.07699778951287171
Trained batch 607 in epoch 16, gen_loss = 0.8308986058752788, disc_loss = 0.07691357040618498
Trained batch 608 in epoch 16, gen_loss = 0.8307700106271578, disc_loss = 0.07684919172943813
Trained batch 609 in epoch 16, gen_loss = 0.8306661030308145, disc_loss = 0.0768924653377445
Trained batch 610 in epoch 16, gen_loss = 0.830537462683239, disc_loss = 0.07687748854891466
Trained batch 611 in epoch 16, gen_loss = 0.8302341127902074, disc_loss = 0.07687292356056229
Trained batch 612 in epoch 16, gen_loss = 0.8305672670655305, disc_loss = 0.07679785968854319
Trained batch 613 in epoch 16, gen_loss = 0.8300661149553057, disc_loss = 0.07692825215101146
Trained batch 614 in epoch 16, gen_loss = 0.8301424492665422, disc_loss = 0.07692736634091149
Trained batch 615 in epoch 16, gen_loss = 0.8297690118288065, disc_loss = 0.07697564495013809
Trained batch 616 in epoch 16, gen_loss = 0.829674882865609, disc_loss = 0.07699295491692602
Trained batch 617 in epoch 16, gen_loss = 0.8303755377102824, disc_loss = 0.07700548009663627
Trained batch 618 in epoch 16, gen_loss = 0.8300686957185218, disc_loss = 0.07705084774613091
Trained batch 619 in epoch 16, gen_loss = 0.8300397935413545, disc_loss = 0.0769937639605374
Trained batch 620 in epoch 16, gen_loss = 0.8299505515758926, disc_loss = 0.07694997221243459
Trained batch 621 in epoch 16, gen_loss = 0.8297918850010998, disc_loss = 0.07699703823152175
Trained batch 622 in epoch 16, gen_loss = 0.8295099562090817, disc_loss = 0.0771463948719048
Trained batch 623 in epoch 16, gen_loss = 0.8294315453714285, disc_loss = 0.0771996076606835
Trained batch 624 in epoch 16, gen_loss = 0.829300001335144, disc_loss = 0.07715812550485134
Trained batch 625 in epoch 16, gen_loss = 0.8292742032593432, disc_loss = 0.07712443624310696
Trained batch 626 in epoch 16, gen_loss = 0.8290287995832769, disc_loss = 0.07718942656911065
Trained batch 627 in epoch 16, gen_loss = 0.8292840306356455, disc_loss = 0.07711100484582649
Trained batch 628 in epoch 16, gen_loss = 0.8291102934907085, disc_loss = 0.07708763059921599
Trained batch 629 in epoch 16, gen_loss = 0.8286135462541429, disc_loss = 0.07720014559371131
Trained batch 630 in epoch 16, gen_loss = 0.8285407113197677, disc_loss = 0.07716155734072586
Trained batch 631 in epoch 16, gen_loss = 0.8289022904030884, disc_loss = 0.07713901089457205
Trained batch 632 in epoch 16, gen_loss = 0.828681095987323, disc_loss = 0.07709950020928141
Trained batch 633 in epoch 16, gen_loss = 0.828561272718929, disc_loss = 0.07706549501616496
Trained batch 634 in epoch 16, gen_loss = 0.8285003662109375, disc_loss = 0.07702200819305548
Trained batch 635 in epoch 16, gen_loss = 0.828352614018902, disc_loss = 0.07715226661226472
Trained batch 636 in epoch 16, gen_loss = 0.8280818847883814, disc_loss = 0.0771438267894873
Trained batch 637 in epoch 16, gen_loss = 0.8281930770993606, disc_loss = 0.07718849292486252
Trained batch 638 in epoch 16, gen_loss = 0.8283053947166658, disc_loss = 0.07712151470458564
Trained batch 639 in epoch 16, gen_loss = 0.8279125350527465, disc_loss = 0.0771781407063827
Trained batch 640 in epoch 16, gen_loss = 0.8276445865631104, disc_loss = 0.07720047013482512
Trained batch 641 in epoch 16, gen_loss = 0.8277440689434515, disc_loss = 0.07713912089131889
Trained batch 642 in epoch 16, gen_loss = 0.8284005128762585, disc_loss = 0.07715503074819711
Trained batch 643 in epoch 16, gen_loss = 0.8285140902359293, disc_loss = 0.07713365740495624
Trained batch 644 in epoch 16, gen_loss = 0.8281717979630758, disc_loss = 0.07717585637010345
Trained batch 645 in epoch 16, gen_loss = 0.828475240860192, disc_loss = 0.07710759818623125
Trained batch 646 in epoch 16, gen_loss = 0.8286928345652231, disc_loss = 0.07703653023142074
Trained batch 647 in epoch 16, gen_loss = 0.8288826662817119, disc_loss = 0.07694152403870069
Trained batch 648 in epoch 16, gen_loss = 0.8286156980392562, disc_loss = 0.07690772826199309
Trained batch 649 in epoch 16, gen_loss = 0.8286406572965476, disc_loss = 0.0768486438677288
Trained batch 650 in epoch 16, gen_loss = 0.828482779306567, disc_loss = 0.07686166255699096
Trained batch 651 in epoch 16, gen_loss = 0.8282817433948165, disc_loss = 0.07680391683528896
Trained batch 652 in epoch 16, gen_loss = 0.8287477902212332, disc_loss = 0.07697350597850533
Trained batch 653 in epoch 16, gen_loss = 0.8288339420196114, disc_loss = 0.07691019073852112
Trained batch 654 in epoch 16, gen_loss = 0.82885840011917, disc_loss = 0.07685720706571832
Trained batch 655 in epoch 16, gen_loss = 0.8289167088706318, disc_loss = 0.07676061000760145
Trained batch 656 in epoch 16, gen_loss = 0.8293502991239411, disc_loss = 0.07669739075759185
Trained batch 657 in epoch 16, gen_loss = 0.829200574148752, disc_loss = 0.07668764873246427
Trained batch 658 in epoch 16, gen_loss = 0.8289804252398756, disc_loss = 0.07668812211026325
Trained batch 659 in epoch 16, gen_loss = 0.8287011392188794, disc_loss = 0.07667630411769179
Trained batch 660 in epoch 16, gen_loss = 0.8290062830776382, disc_loss = 0.07667382354404265
Trained batch 661 in epoch 16, gen_loss = 0.8289994935974974, disc_loss = 0.07658900297598581
Trained batch 662 in epoch 16, gen_loss = 0.8288005529305874, disc_loss = 0.07664337478505046
Trained batch 663 in epoch 16, gen_loss = 0.8283678286944527, disc_loss = 0.07677374278189592
Trained batch 664 in epoch 16, gen_loss = 0.8283942726321687, disc_loss = 0.07674838521454791
Trained batch 665 in epoch 16, gen_loss = 0.8292841104057816, disc_loss = 0.07685881452187449
Trained batch 666 in epoch 16, gen_loss = 0.8289942799479529, disc_loss = 0.07685820206111742
Trained batch 667 in epoch 16, gen_loss = 0.82918853629492, disc_loss = 0.0768007505364426
Trained batch 668 in epoch 16, gen_loss = 0.8297421576730873, disc_loss = 0.07721387622919719
Trained batch 669 in epoch 16, gen_loss = 0.8293149815566504, disc_loss = 0.07741982545564646
Trained batch 670 in epoch 16, gen_loss = 0.8290806759132181, disc_loss = 0.07738842114656275
Trained batch 671 in epoch 16, gen_loss = 0.8294109170812936, disc_loss = 0.07740167150456857
Trained batch 672 in epoch 16, gen_loss = 0.8296205908015791, disc_loss = 0.07733557793556714
Trained batch 673 in epoch 16, gen_loss = 0.829531047393731, disc_loss = 0.07732963243234095
Trained batch 674 in epoch 16, gen_loss = 0.8294932889938355, disc_loss = 0.07727477971740343
Trained batch 675 in epoch 16, gen_loss = 0.8293475736175063, disc_loss = 0.0772831092971603
Trained batch 676 in epoch 16, gen_loss = 0.8288902748634756, disc_loss = 0.0774964895966068
Trained batch 677 in epoch 16, gen_loss = 0.829214663983798, disc_loss = 0.07748896340292859
Trained batch 678 in epoch 16, gen_loss = 0.8298068290606514, disc_loss = 0.0774936553307525
Trained batch 679 in epoch 16, gen_loss = 0.8300150811672211, disc_loss = 0.0774031010141377
Trained batch 680 in epoch 16, gen_loss = 0.8297618168041044, disc_loss = 0.07742722355042654
Trained batch 681 in epoch 16, gen_loss = 0.8300296855637055, disc_loss = 0.07734225019730649
Trained batch 682 in epoch 16, gen_loss = 0.8303298277352251, disc_loss = 0.07738612120013853
Trained batch 683 in epoch 16, gen_loss = 0.8301903073027818, disc_loss = 0.07734623798768292
Trained batch 684 in epoch 16, gen_loss = 0.8301631537667156, disc_loss = 0.07730200518140175
Trained batch 685 in epoch 16, gen_loss = 0.8305520217203191, disc_loss = 0.07736708040406205
Trained batch 686 in epoch 16, gen_loss = 0.8302635365698535, disc_loss = 0.07739139059924532
Trained batch 687 in epoch 16, gen_loss = 0.829881761656251, disc_loss = 0.07743616754237866
Trained batch 688 in epoch 16, gen_loss = 0.8298153217195253, disc_loss = 0.07744376734574968
Trained batch 689 in epoch 16, gen_loss = 0.8296717155670774, disc_loss = 0.07744857460611325
Trained batch 690 in epoch 16, gen_loss = 0.8297865443395291, disc_loss = 0.07735570761686468
Trained batch 691 in epoch 16, gen_loss = 0.8296866629681835, disc_loss = 0.07730806260396635
Trained batch 692 in epoch 16, gen_loss = 0.8295517171616162, disc_loss = 0.07727422190004957
Trained batch 693 in epoch 16, gen_loss = 0.8297033101234381, disc_loss = 0.07753586646716945
Trained batch 694 in epoch 16, gen_loss = 0.8291953240795958, disc_loss = 0.07778002561853944
Trained batch 695 in epoch 16, gen_loss = 0.8292797714386179, disc_loss = 0.07771199657688795
Trained batch 696 in epoch 16, gen_loss = 0.8295184993418936, disc_loss = 0.07786042343456315
Trained batch 697 in epoch 16, gen_loss = 0.8295416770913882, disc_loss = 0.07779040940660972
Trained batch 698 in epoch 16, gen_loss = 0.8295658151905595, disc_loss = 0.0777125206372257
Trained batch 699 in epoch 16, gen_loss = 0.8290053763985634, disc_loss = 0.07785890547292573
Trained batch 700 in epoch 16, gen_loss = 0.8289234973649666, disc_loss = 0.07783084423327752
Trained batch 701 in epoch 16, gen_loss = 0.8292190582409203, disc_loss = 0.07787744414347869
Trained batch 702 in epoch 16, gen_loss = 0.8293408386483471, disc_loss = 0.07782731135806352
Trained batch 703 in epoch 16, gen_loss = 0.829394010107287, disc_loss = 0.07774779337341897
Trained batch 704 in epoch 16, gen_loss = 0.8293101562253127, disc_loss = 0.07767180156570377
Trained batch 705 in epoch 16, gen_loss = 0.8290890691216202, disc_loss = 0.07763614133791866
Trained batch 706 in epoch 16, gen_loss = 0.8291112235529925, disc_loss = 0.0775562723521591
Trained batch 707 in epoch 16, gen_loss = 0.8290902048265193, disc_loss = 0.07748719427134779
Trained batch 708 in epoch 16, gen_loss = 0.8296472671926441, disc_loss = 0.07750748928336818
Trained batch 709 in epoch 16, gen_loss = 0.8298716827597417, disc_loss = 0.07744054050565186
Trained batch 710 in epoch 16, gen_loss = 0.8296982830838312, disc_loss = 0.0774696839137629
Trained batch 711 in epoch 16, gen_loss = 0.8295315821770202, disc_loss = 0.0775026168930606
Trained batch 712 in epoch 16, gen_loss = 0.829675972085514, disc_loss = 0.077436679624136
Trained batch 713 in epoch 16, gen_loss = 0.8296648405429696, disc_loss = 0.07743954747988313
Trained batch 714 in epoch 16, gen_loss = 0.829564495645203, disc_loss = 0.07738775982671267
Trained batch 715 in epoch 16, gen_loss = 0.82949438279068, disc_loss = 0.07732121689068205
Trained batch 716 in epoch 16, gen_loss = 0.8290355202626317, disc_loss = 0.07742618761094212
Trained batch 717 in epoch 16, gen_loss = 0.8288828111707666, disc_loss = 0.07742747579361403
Trained batch 718 in epoch 16, gen_loss = 0.8297857049857791, disc_loss = 0.0776831679906235
Trained batch 719 in epoch 16, gen_loss = 0.8295687778542439, disc_loss = 0.07767829135474232
Trained batch 720 in epoch 16, gen_loss = 0.8293848390304761, disc_loss = 0.07768636559563767
Trained batch 721 in epoch 16, gen_loss = 0.8293349041585447, disc_loss = 0.07762345143302325
Trained batch 722 in epoch 16, gen_loss = 0.8292140105370829, disc_loss = 0.07760497933848765
Trained batch 723 in epoch 16, gen_loss = 0.8292678808227428, disc_loss = 0.07757572984086215
Trained batch 724 in epoch 16, gen_loss = 0.8291266819115343, disc_loss = 0.07752575223815852
Trained batch 725 in epoch 16, gen_loss = 0.8291589746215784, disc_loss = 0.07743851482077982
Trained batch 726 in epoch 16, gen_loss = 0.82897363941312, disc_loss = 0.07744069951631262
Trained batch 727 in epoch 16, gen_loss = 0.8289145090013414, disc_loss = 0.07737368042836641
Trained batch 728 in epoch 16, gen_loss = 0.8290849139579203, disc_loss = 0.07731040276392824
Trained batch 729 in epoch 16, gen_loss = 0.8291014683981465, disc_loss = 0.07728256723550085
Trained batch 730 in epoch 16, gen_loss = 0.8293901451553757, disc_loss = 0.07719583223954801
Trained batch 731 in epoch 16, gen_loss = 0.8293666147062035, disc_loss = 0.07712699642756068
Trained batch 732 in epoch 16, gen_loss = 0.8292529878561038, disc_loss = 0.07713532083798683
Trained batch 733 in epoch 16, gen_loss = 0.8294753044518852, disc_loss = 0.07707695853680738
Trained batch 734 in epoch 16, gen_loss = 0.8296780643414478, disc_loss = 0.07698816414795766
Trained batch 735 in epoch 16, gen_loss = 0.8298782937471634, disc_loss = 0.07689744471977263
Trained batch 736 in epoch 16, gen_loss = 0.8297522143641515, disc_loss = 0.07686071874753267
Trained batch 737 in epoch 16, gen_loss = 0.8297036901964405, disc_loss = 0.07680236932324362
Trained batch 738 in epoch 16, gen_loss = 0.8299704255770605, disc_loss = 0.07687051183416814
Trained batch 739 in epoch 16, gen_loss = 0.8299664078129304, disc_loss = 0.07678842961888861
Trained batch 740 in epoch 16, gen_loss = 0.8297260843227428, disc_loss = 0.07692779496553456
Trained batch 741 in epoch 16, gen_loss = 0.8297509504858696, disc_loss = 0.07685895018138976
Trained batch 742 in epoch 16, gen_loss = 0.8298573439807944, disc_loss = 0.07677817258928699
Trained batch 743 in epoch 16, gen_loss = 0.8299439315914466, disc_loss = 0.0767001164025597
Trained batch 744 in epoch 16, gen_loss = 0.830393898127063, disc_loss = 0.07663199547553222
Trained batch 745 in epoch 16, gen_loss = 0.8302497157861976, disc_loss = 0.07662155532125813
Trained batch 746 in epoch 16, gen_loss = 0.830319752455396, disc_loss = 0.07665797261149689
Trained batch 747 in epoch 16, gen_loss = 0.8302566380822722, disc_loss = 0.07668309098976181
Trained batch 748 in epoch 16, gen_loss = 0.8304376381341224, disc_loss = 0.07670460592642009
Trained batch 749 in epoch 16, gen_loss = 0.8301450895865758, disc_loss = 0.07676986886064212
Trained batch 750 in epoch 16, gen_loss = 0.8302375030977907, disc_loss = 0.07671266243595892
Trained batch 751 in epoch 16, gen_loss = 0.8302927360017883, disc_loss = 0.07670470573840306
Trained batch 752 in epoch 16, gen_loss = 0.8301547482748273, disc_loss = 0.0766936297297161
Trained batch 753 in epoch 16, gen_loss = 0.8301864413826155, disc_loss = 0.07670855031049853
Trained batch 754 in epoch 16, gen_loss = 0.829762442498807, disc_loss = 0.07678964411383433
Trained batch 755 in epoch 16, gen_loss = 0.8298911908395076, disc_loss = 0.07673222245402121
Trained batch 756 in epoch 16, gen_loss = 0.83021055490684, disc_loss = 0.0766806153425531
Trained batch 757 in epoch 16, gen_loss = 0.829896018695391, disc_loss = 0.07671360995394416
Trained batch 758 in epoch 16, gen_loss = 0.8302121498917716, disc_loss = 0.076834413015599
Trained batch 759 in epoch 16, gen_loss = 0.8304089844618973, disc_loss = 0.07675123112153653
Trained batch 760 in epoch 16, gen_loss = 0.8303053193039086, disc_loss = 0.07669533248109628
Trained batch 761 in epoch 16, gen_loss = 0.8304143977055712, disc_loss = 0.0766302934588664
Trained batch 762 in epoch 16, gen_loss = 0.8303618807233333, disc_loss = 0.07655783480846202
Trained batch 763 in epoch 16, gen_loss = 0.8305707181857519, disc_loss = 0.07647238983114431
Trained batch 764 in epoch 16, gen_loss = 0.8304051844512715, disc_loss = 0.07650885436123882
Trained batch 765 in epoch 16, gen_loss = 0.8305415324769506, disc_loss = 0.07647128882951665
Trained batch 766 in epoch 16, gen_loss = 0.8306484134209668, disc_loss = 0.07644987472295373
Trained batch 767 in epoch 16, gen_loss = 0.8306369736092165, disc_loss = 0.07641403611099425
Trained batch 768 in epoch 16, gen_loss = 0.830420460401803, disc_loss = 0.07650508148588424
Trained batch 769 in epoch 16, gen_loss = 0.8308092836822782, disc_loss = 0.076425940830067
Trained batch 770 in epoch 16, gen_loss = 0.8310367536529338, disc_loss = 0.07647409574787015
Trained batch 771 in epoch 16, gen_loss = 0.8309862938337993, disc_loss = 0.07643473613162771
Trained batch 772 in epoch 16, gen_loss = 0.8307385233750164, disc_loss = 0.07657066972282887
Trained batch 773 in epoch 16, gen_loss = 0.8310629088210197, disc_loss = 0.07656990941397326
Trained batch 774 in epoch 16, gen_loss = 0.8314140770896788, disc_loss = 0.07650589055231502
Trained batch 775 in epoch 16, gen_loss = 0.8314258828375143, disc_loss = 0.07650032835969336
Trained batch 776 in epoch 16, gen_loss = 0.8314323567592345, disc_loss = 0.07646106326044028
Trained batch 777 in epoch 16, gen_loss = 0.8311073427258543, disc_loss = 0.07650819521967159
Trained batch 778 in epoch 16, gen_loss = 0.8310605461621927, disc_loss = 0.07649892629441041
Trained batch 779 in epoch 16, gen_loss = 0.8316494209262041, disc_loss = 0.07652541002234778
Trained batch 780 in epoch 16, gen_loss = 0.8311629030142795, disc_loss = 0.07661297648940021
Trained batch 781 in epoch 16, gen_loss = 0.8308547944440257, disc_loss = 0.07672650861146543
Trained batch 782 in epoch 16, gen_loss = 0.8310275542553357, disc_loss = 0.07666963700081388
Trained batch 783 in epoch 16, gen_loss = 0.8311601215403299, disc_loss = 0.07659725322060248
Trained batch 784 in epoch 16, gen_loss = 0.8315867385666841, disc_loss = 0.0765470651292782
Trained batch 785 in epoch 16, gen_loss = 0.831484284830154, disc_loss = 0.07652755107128703
Trained batch 786 in epoch 16, gen_loss = 0.8313784492894383, disc_loss = 0.07677137638587775
Trained batch 787 in epoch 16, gen_loss = 0.8309514958619466, disc_loss = 0.07696395937405376
Trained batch 788 in epoch 16, gen_loss = 0.8311453771757384, disc_loss = 0.07690957054396659
Trained batch 789 in epoch 16, gen_loss = 0.8316127877823914, disc_loss = 0.0771628525992266
Testing Epoch 16

Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.5441844463348389, disc_loss = 0.14758911728858948
Trained batch 1 in epoch 17, gen_loss = 0.6252142786979675, disc_loss = 0.09716439247131348
Trained batch 2 in epoch 17, gen_loss = 0.7422481973965963, disc_loss = 0.10336477061112721
Trained batch 3 in epoch 17, gen_loss = 0.7785890400409698, disc_loss = 0.08394642593339086
Trained batch 4 in epoch 17, gen_loss = 0.7774416685104371, disc_loss = 0.08243213631212712
Trained batch 5 in epoch 17, gen_loss = 0.7876688142617544, disc_loss = 0.07742132774243753
Trained batch 6 in epoch 17, gen_loss = 0.7725381936345782, disc_loss = 0.08550993486174516
Trained batch 7 in epoch 17, gen_loss = 0.77060467004776, disc_loss = 0.07985388278029859
Trained batch 8 in epoch 17, gen_loss = 0.7673260105980767, disc_loss = 0.0858449221899112
Trained batch 9 in epoch 17, gen_loss = 0.7743002295494079, disc_loss = 0.07996272593736649
Trained batch 10 in epoch 17, gen_loss = 0.758539232340726, disc_loss = 0.08146395534276962
Trained batch 11 in epoch 17, gen_loss = 0.7509423593680064, disc_loss = 0.08048867496351401
Trained batch 12 in epoch 17, gen_loss = 0.7574989383037274, disc_loss = 0.0822422647705445
Trained batch 13 in epoch 17, gen_loss = 0.7584343595164162, disc_loss = 0.07815617136657238
Trained batch 14 in epoch 17, gen_loss = 0.7657550374666849, disc_loss = 0.07539543931682904
Trained batch 15 in epoch 17, gen_loss = 0.7693025432527065, disc_loss = 0.07618358940817416
Trained batch 16 in epoch 17, gen_loss = 0.7578104559112998, disc_loss = 0.07837548917707275
Trained batch 17 in epoch 17, gen_loss = 0.7717955145570967, disc_loss = 0.08003238071170118
Trained batch 18 in epoch 17, gen_loss = 0.7780105157902366, disc_loss = 0.07636891697582446
Trained batch 19 in epoch 17, gen_loss = 0.7673571556806564, disc_loss = 0.07811643294990063
Trained batch 20 in epoch 17, gen_loss = 0.7759718838192168, disc_loss = 0.07604082141603742
Trained batch 21 in epoch 17, gen_loss = 0.7888699228113348, disc_loss = 0.0748917582360181
Trained batch 22 in epoch 17, gen_loss = 0.7831102583719336, disc_loss = 0.07451463101998619
Trained batch 23 in epoch 17, gen_loss = 0.7882004901766777, disc_loss = 0.07614510133862495
Trained batch 24 in epoch 17, gen_loss = 0.7789849400520324, disc_loss = 0.07825114250183106
Trained batch 25 in epoch 17, gen_loss = 0.7780654545013721, disc_loss = 0.0766656080690714
Trained batch 26 in epoch 17, gen_loss = 0.7764111624823676, disc_loss = 0.07628227742733779
Trained batch 27 in epoch 17, gen_loss = 0.7719179434435708, disc_loss = 0.07532706843422991
Trained batch 28 in epoch 17, gen_loss = 0.7833093528089852, disc_loss = 0.07541208393101034
Trained batch 29 in epoch 17, gen_loss = 0.7815904796123505, disc_loss = 0.07460101755956809
Trained batch 30 in epoch 17, gen_loss = 0.7789228712358782, disc_loss = 0.07396073218795561
Trained batch 31 in epoch 17, gen_loss = 0.7967713605612516, disc_loss = 0.07657766493503004
Trained batch 32 in epoch 17, gen_loss = 0.7936943498524752, disc_loss = 0.0773929250285481
Trained batch 33 in epoch 17, gen_loss = 0.7917339591418996, disc_loss = 0.0765573784489842
Trained batch 34 in epoch 17, gen_loss = 0.7915124450411115, disc_loss = 0.07536392116120884
Trained batch 35 in epoch 17, gen_loss = 0.7951697525050905, disc_loss = 0.07660084662752019
Trained batch 36 in epoch 17, gen_loss = 0.8003959591324264, disc_loss = 0.07564325237999091
Trained batch 37 in epoch 17, gen_loss = 0.7992210858746579, disc_loss = 0.07618192475485175
Trained batch 38 in epoch 17, gen_loss = 0.8007389796085846, disc_loss = 0.07680435641071735
Trained batch 39 in epoch 17, gen_loss = 0.7999227523803711, disc_loss = 0.07579017989337444
Trained batch 40 in epoch 17, gen_loss = 0.8007734476066217, disc_loss = 0.07489159403414261
Trained batch 41 in epoch 17, gen_loss = 0.7979732127416701, disc_loss = 0.07444724493793078
Trained batch 42 in epoch 17, gen_loss = 0.795723251132078, disc_loss = 0.07383513875132383
Trained batch 43 in epoch 17, gen_loss = 0.7958825758912347, disc_loss = 0.07426542390815237
Trained batch 44 in epoch 17, gen_loss = 0.8024799413151211, disc_loss = 0.0746719137661987
Trained batch 45 in epoch 17, gen_loss = 0.8076602985029635, disc_loss = 0.07333927295859093
Trained batch 46 in epoch 17, gen_loss = 0.8065765905887523, disc_loss = 0.07360881172675401
Trained batch 47 in epoch 17, gen_loss = 0.811200895657142, disc_loss = 0.07242440403206274
Trained batch 48 in epoch 17, gen_loss = 0.8134561898757, disc_loss = 0.07143921665467169
Trained batch 49 in epoch 17, gen_loss = 0.8114610719680786, disc_loss = 0.07129572512581944
Trained batch 50 in epoch 17, gen_loss = 0.8164492658540314, disc_loss = 0.07171157223409881
Trained batch 51 in epoch 17, gen_loss = 0.8186286275203412, disc_loss = 0.07081457365375872
Trained batch 52 in epoch 17, gen_loss = 0.817025789674723, disc_loss = 0.07060944044716516
Trained batch 53 in epoch 17, gen_loss = 0.8196953314322012, disc_loss = 0.06947294545049469
Trained batch 54 in epoch 17, gen_loss = 0.8192471937699751, disc_loss = 0.06948504331098361
Trained batch 55 in epoch 17, gen_loss = 0.8218265984739576, disc_loss = 0.06846807732446385
Trained batch 56 in epoch 17, gen_loss = 0.8234964190867909, disc_loss = 0.06767705823049734
Trained batch 57 in epoch 17, gen_loss = 0.8192739209224438, disc_loss = 0.06819941342711963
Trained batch 58 in epoch 17, gen_loss = 0.8198693899785058, disc_loss = 0.06744664940604214
Trained batch 59 in epoch 17, gen_loss = 0.8275395840406418, disc_loss = 0.06791443571758767
Trained batch 60 in epoch 17, gen_loss = 0.8242868693148504, disc_loss = 0.06780761878815342
Trained batch 61 in epoch 17, gen_loss = 0.8292947872992484, disc_loss = 0.06773395267044825
Trained batch 62 in epoch 17, gen_loss = 0.8259318470954895, disc_loss = 0.06876641637571747
Trained batch 63 in epoch 17, gen_loss = 0.8274074262008071, disc_loss = 0.06850016572570894
Trained batch 64 in epoch 17, gen_loss = 0.8262158989906311, disc_loss = 0.06861697539973717
Trained batch 65 in epoch 17, gen_loss = 0.8286530980558107, disc_loss = 0.06924840301331697
Trained batch 66 in epoch 17, gen_loss = 0.8283140801671726, disc_loss = 0.07012279922448432
Trained batch 67 in epoch 17, gen_loss = 0.8287653283161276, disc_loss = 0.06950855864595402
Trained batch 68 in epoch 17, gen_loss = 0.833918829758962, disc_loss = 0.06950180520020101
Trained batch 69 in epoch 17, gen_loss = 0.832854847397123, disc_loss = 0.06882947354710528
Trained batch 70 in epoch 17, gen_loss = 0.8337553991398341, disc_loss = 0.06813720402530801
Trained batch 71 in epoch 17, gen_loss = 0.8340219731132189, disc_loss = 0.06770407857321617
Trained batch 72 in epoch 17, gen_loss = 0.8349281688259073, disc_loss = 0.06721723017167963
Trained batch 73 in epoch 17, gen_loss = 0.8323949857338054, disc_loss = 0.06746887021723229
Trained batch 74 in epoch 17, gen_loss = 0.8317271033922832, disc_loss = 0.06753548859308163
Trained batch 75 in epoch 17, gen_loss = 0.8370050027182228, disc_loss = 0.06869309374719466
Trained batch 76 in epoch 17, gen_loss = 0.8347556296881143, disc_loss = 0.06901790897132128
Trained batch 77 in epoch 17, gen_loss = 0.832723502929394, disc_loss = 0.07001966981885907
Trained batch 78 in epoch 17, gen_loss = 0.8341792965237098, disc_loss = 0.07120983980454598
Trained batch 79 in epoch 17, gen_loss = 0.8366931416094303, disc_loss = 0.07062117535388097
Trained batch 80 in epoch 17, gen_loss = 0.8394829616134549, disc_loss = 0.07009914886482337
Trained batch 81 in epoch 17, gen_loss = 0.8387796653480064, disc_loss = 0.06974816382521899
Trained batch 82 in epoch 17, gen_loss = 0.838719780904701, disc_loss = 0.06916674842541835
Trained batch 83 in epoch 17, gen_loss = 0.8377178659041723, disc_loss = 0.06885025389714255
Trained batch 84 in epoch 17, gen_loss = 0.8391666587661294, disc_loss = 0.06850879846469445
Trained batch 85 in epoch 17, gen_loss = 0.8365611468636712, disc_loss = 0.06845347640689375
Trained batch 86 in epoch 17, gen_loss = 0.837288513950918, disc_loss = 0.0680716897243227
Trained batch 87 in epoch 17, gen_loss = 0.8340759873390198, disc_loss = 0.06861486079552295
Trained batch 88 in epoch 17, gen_loss = 0.8343529955724652, disc_loss = 0.0690472527522217
Trained batch 89 in epoch 17, gen_loss = 0.8352204852634006, disc_loss = 0.06878010478491585
Trained batch 90 in epoch 17, gen_loss = 0.8375099596086439, disc_loss = 0.06816440443047783
Trained batch 91 in epoch 17, gen_loss = 0.8346735239028931, disc_loss = 0.06859869452233872
Trained batch 92 in epoch 17, gen_loss = 0.841800796088352, disc_loss = 0.06878796803654842
Trained batch 93 in epoch 17, gen_loss = 0.8397688967116336, disc_loss = 0.0686116063907901
Trained batch 94 in epoch 17, gen_loss = 0.8390964131606252, disc_loss = 0.06818270850926637
Trained batch 95 in epoch 17, gen_loss = 0.8379526982704798, disc_loss = 0.07046387044829316
Trained batch 96 in epoch 17, gen_loss = 0.8373591973609531, disc_loss = 0.07018390650256086
Trained batch 97 in epoch 17, gen_loss = 0.8365488684907252, disc_loss = 0.07001883448196614
Trained batch 98 in epoch 17, gen_loss = 0.8372874181680005, disc_loss = 0.06958864575647043
Trained batch 99 in epoch 17, gen_loss = 0.8389208132028579, disc_loss = 0.06953592530451715
Trained batch 100 in epoch 17, gen_loss = 0.8354919074785592, disc_loss = 0.07070607927139147
Trained batch 101 in epoch 17, gen_loss = 0.8367133923605377, disc_loss = 0.07029809107930929
Trained batch 102 in epoch 17, gen_loss = 0.8376404926614854, disc_loss = 0.06980650102520741
Trained batch 103 in epoch 17, gen_loss = 0.8394193683679287, disc_loss = 0.0697575677634002
Trained batch 104 in epoch 17, gen_loss = 0.836260001432328, disc_loss = 0.07107438690783012
Trained batch 105 in epoch 17, gen_loss = 0.8363417595062616, disc_loss = 0.07079766951677091
Trained batch 106 in epoch 17, gen_loss = 0.8376677827300313, disc_loss = 0.07032566128524943
Trained batch 107 in epoch 17, gen_loss = 0.8355777561664581, disc_loss = 0.07051605739009877
Trained batch 108 in epoch 17, gen_loss = 0.8368523448979089, disc_loss = 0.07095484696157756
Trained batch 109 in epoch 17, gen_loss = 0.8345101876692338, disc_loss = 0.07158338536762378
Trained batch 110 in epoch 17, gen_loss = 0.8319540678917825, disc_loss = 0.07234874140336975
Trained batch 111 in epoch 17, gen_loss = 0.8358749736632619, disc_loss = 0.07428798945121733
Trained batch 112 in epoch 17, gen_loss = 0.8350180967719154, disc_loss = 0.07409150075101484
Trained batch 113 in epoch 17, gen_loss = 0.8326138367778376, disc_loss = 0.07445895071386506
Trained batch 114 in epoch 17, gen_loss = 0.8312564341918282, disc_loss = 0.07448628947300756
Trained batch 115 in epoch 17, gen_loss = 0.8305999107401947, disc_loss = 0.07479477854413462
Trained batch 116 in epoch 17, gen_loss = 0.8315196185030489, disc_loss = 0.07427565505903246
Trained batch 117 in epoch 17, gen_loss = 0.8314651326607849, disc_loss = 0.07383353227623186
Trained batch 118 in epoch 17, gen_loss = 0.8313793620141614, disc_loss = 0.07349355439772877
Trained batch 119 in epoch 17, gen_loss = 0.8325675869981448, disc_loss = 0.07304512379535784
Trained batch 120 in epoch 17, gen_loss = 0.8310724137243161, disc_loss = 0.07279423115513295
Trained batch 121 in epoch 17, gen_loss = 0.8300494458831724, disc_loss = 0.07265672700662838
Trained batch 122 in epoch 17, gen_loss = 0.8308090916494044, disc_loss = 0.07264489004373308
Trained batch 123 in epoch 17, gen_loss = 0.8291663061226567, disc_loss = 0.07268368124571298
Trained batch 124 in epoch 17, gen_loss = 0.8301564517021179, disc_loss = 0.07221173439174891
Trained batch 125 in epoch 17, gen_loss = 0.8298061291376749, disc_loss = 0.07189909969678238
Trained batch 126 in epoch 17, gen_loss = 0.8298565360504812, disc_loss = 0.0715991955939827
Trained batch 127 in epoch 17, gen_loss = 0.8295323639176786, disc_loss = 0.07186143284343416
Trained batch 128 in epoch 17, gen_loss = 0.8313357197037039, disc_loss = 0.07150286878639645
Trained batch 129 in epoch 17, gen_loss = 0.8308035309498126, disc_loss = 0.07122583335552078
Trained batch 130 in epoch 17, gen_loss = 0.8312603057795809, disc_loss = 0.07090624362827484
Trained batch 131 in epoch 17, gen_loss = 0.8331927815169999, disc_loss = 0.0706405693905033
Trained batch 132 in epoch 17, gen_loss = 0.8358845535973857, disc_loss = 0.07049444206479125
Trained batch 133 in epoch 17, gen_loss = 0.83552855475625, disc_loss = 0.0704774291171178
Trained batch 134 in epoch 17, gen_loss = 0.8355999059147305, disc_loss = 0.07027382718882075
Trained batch 135 in epoch 17, gen_loss = 0.8349344638340613, disc_loss = 0.07007483979824054
Trained batch 136 in epoch 17, gen_loss = 0.8347908854484558, disc_loss = 0.07027509134861022
Trained batch 137 in epoch 17, gen_loss = 0.8331921528214994, disc_loss = 0.07015551783927325
Trained batch 138 in epoch 17, gen_loss = 0.8347041877053625, disc_loss = 0.06995675306124009
Trained batch 139 in epoch 17, gen_loss = 0.8343567328793662, disc_loss = 0.06970016547212643
Trained batch 140 in epoch 17, gen_loss = 0.8344836082864315, disc_loss = 0.06934698435299574
Trained batch 141 in epoch 17, gen_loss = 0.8340321481227875, disc_loss = 0.0694426760589048
Trained batch 142 in epoch 17, gen_loss = 0.8337877742894046, disc_loss = 0.0691078628211484
Trained batch 143 in epoch 17, gen_loss = 0.8346186230580012, disc_loss = 0.068777568192066
Trained batch 144 in epoch 17, gen_loss = 0.8357043960998798, disc_loss = 0.06868333949482647
Trained batch 145 in epoch 17, gen_loss = 0.833722908202916, disc_loss = 0.0694892766681334
Trained batch 146 in epoch 17, gen_loss = 0.8336538940059895, disc_loss = 0.06933229078925184
Trained batch 147 in epoch 17, gen_loss = 0.8367124131402454, disc_loss = 0.07017665670404362
Trained batch 148 in epoch 17, gen_loss = 0.8354131247373235, disc_loss = 0.07035345241002389
Trained batch 149 in epoch 17, gen_loss = 0.8348514453570048, disc_loss = 0.07023573700959483
Trained batch 150 in epoch 17, gen_loss = 0.8344686039236208, disc_loss = 0.0701280315129074
Trained batch 151 in epoch 17, gen_loss = 0.835777538387399, disc_loss = 0.06981716414692958
Trained batch 152 in epoch 17, gen_loss = 0.8352426002228183, disc_loss = 0.06963159683848323
Trained batch 153 in epoch 17, gen_loss = 0.8351313851096414, disc_loss = 0.06931303090161899
Trained batch 154 in epoch 17, gen_loss = 0.8355965295145589, disc_loss = 0.06919841054346293
Trained batch 155 in epoch 17, gen_loss = 0.835724108112164, disc_loss = 0.06892392084074135
Trained batch 156 in epoch 17, gen_loss = 0.8341634406405649, disc_loss = 0.06897943777144905
Trained batch 157 in epoch 17, gen_loss = 0.8359261249439626, disc_loss = 0.06885504465007895
Trained batch 158 in epoch 17, gen_loss = 0.8355187458812066, disc_loss = 0.0687909412297344
Trained batch 159 in epoch 17, gen_loss = 0.8394409921020269, disc_loss = 0.06954239971819334
Trained batch 160 in epoch 17, gen_loss = 0.8373115516227224, disc_loss = 0.07045713318685382
Trained batch 161 in epoch 17, gen_loss = 0.839080865184466, disc_loss = 0.07079424582030854
Trained batch 162 in epoch 17, gen_loss = 0.8367004946696978, disc_loss = 0.0712029353595493
Trained batch 163 in epoch 17, gen_loss = 0.836760319951104, disc_loss = 0.07096197528242157
Trained batch 164 in epoch 17, gen_loss = 0.8378462195396423, disc_loss = 0.07107619078209003
Trained batch 165 in epoch 17, gen_loss = 0.8373676656958569, disc_loss = 0.07112663786252399
Trained batch 166 in epoch 17, gen_loss = 0.8385727494776606, disc_loss = 0.07088307714547047
Trained batch 167 in epoch 17, gen_loss = 0.8382730217916625, disc_loss = 0.07083705000557183
Trained batch 168 in epoch 17, gen_loss = 0.8377978064604765, disc_loss = 0.0706298936918907
Trained batch 169 in epoch 17, gen_loss = 0.8390786644290475, disc_loss = 0.07039724494714071
Trained batch 170 in epoch 17, gen_loss = 0.8371076015701071, disc_loss = 0.07092255844642022
Trained batch 171 in epoch 17, gen_loss = 0.8375424773887147, disc_loss = 0.07096972280225261
Trained batch 172 in epoch 17, gen_loss = 0.837448266544783, disc_loss = 0.07117792600604324
Trained batch 173 in epoch 17, gen_loss = 0.837453258791189, disc_loss = 0.07084287392061162
Trained batch 174 in epoch 17, gen_loss = 0.8385529889379228, disc_loss = 0.07057762049670731
Trained batch 175 in epoch 17, gen_loss = 0.8373617685653947, disc_loss = 0.07048940780805424
Trained batch 176 in epoch 17, gen_loss = 0.8365671742433882, disc_loss = 0.07037314027021666
Trained batch 177 in epoch 17, gen_loss = 0.8364332840683755, disc_loss = 0.07018513202646308
Trained batch 178 in epoch 17, gen_loss = 0.8372842179996342, disc_loss = 0.07019075147245683
Trained batch 179 in epoch 17, gen_loss = 0.8363811261124081, disc_loss = 0.0702807935109983
Trained batch 180 in epoch 17, gen_loss = 0.8355573086448795, disc_loss = 0.07023624387873306
Trained batch 181 in epoch 17, gen_loss = 0.8354498694886218, disc_loss = 0.06995577696240046
Trained batch 182 in epoch 17, gen_loss = 0.8341891570169417, disc_loss = 0.07015065192830204
Trained batch 183 in epoch 17, gen_loss = 0.8350860670856808, disc_loss = 0.07001923056542063
Trained batch 184 in epoch 17, gen_loss = 0.8355140254304215, disc_loss = 0.07003777304513228
Trained batch 185 in epoch 17, gen_loss = 0.8351316881436174, disc_loss = 0.06976287591180974
Trained batch 186 in epoch 17, gen_loss = 0.8345746834647847, disc_loss = 0.06956765597018806
Trained batch 187 in epoch 17, gen_loss = 0.8344533367359892, disc_loss = 0.06940269224008823
Trained batch 188 in epoch 17, gen_loss = 0.8334756247580998, disc_loss = 0.06961392330882883
Trained batch 189 in epoch 17, gen_loss = 0.8340597999723334, disc_loss = 0.06983713248352472
Trained batch 190 in epoch 17, gen_loss = 0.8333362846474373, disc_loss = 0.06973103181756447
Trained batch 191 in epoch 17, gen_loss = 0.8328026669720808, disc_loss = 0.0696604580298299
Trained batch 192 in epoch 17, gen_loss = 0.832717043130509, disc_loss = 0.06943334269921242
Trained batch 193 in epoch 17, gen_loss = 0.833080276386025, disc_loss = 0.06919855345520623
Trained batch 194 in epoch 17, gen_loss = 0.8343343160091302, disc_loss = 0.06922251556832822
Trained batch 195 in epoch 17, gen_loss = 0.8345545104571751, disc_loss = 0.06894421054297412
Trained batch 196 in epoch 17, gen_loss = 0.8339896286804664, disc_loss = 0.0688141702159029
Trained batch 197 in epoch 17, gen_loss = 0.833206544018755, disc_loss = 0.06879637730448987
Trained batch 198 in epoch 17, gen_loss = 0.8334553187815987, disc_loss = 0.06900316294769396
Trained batch 199 in epoch 17, gen_loss = 0.834467945098877, disc_loss = 0.06872596953529865
Trained batch 200 in epoch 17, gen_loss = 0.8354842633157227, disc_loss = 0.06958237709709215
Trained batch 201 in epoch 17, gen_loss = 0.8350607758701438, disc_loss = 0.06960603997277298
Trained batch 202 in epoch 17, gen_loss = 0.8348983996020162, disc_loss = 0.06949689329643115
Trained batch 203 in epoch 17, gen_loss = 0.8356166931928373, disc_loss = 0.06925326192696743
Trained batch 204 in epoch 17, gen_loss = 0.8352588665194628, disc_loss = 0.06967573261751635
Trained batch 205 in epoch 17, gen_loss = 0.834939181804657, disc_loss = 0.06948114504350476
Trained batch 206 in epoch 17, gen_loss = 0.8339025781350435, disc_loss = 0.06966580748827993
Trained batch 207 in epoch 17, gen_loss = 0.8367423532673945, disc_loss = 0.07009764448650038
Trained batch 208 in epoch 17, gen_loss = 0.8356448665760351, disc_loss = 0.0702794941373918
Trained batch 209 in epoch 17, gen_loss = 0.835175894839423, disc_loss = 0.07033189385685892
Trained batch 210 in epoch 17, gen_loss = 0.8352449914855414, disc_loss = 0.07043634601802481
Trained batch 211 in epoch 17, gen_loss = 0.834666409301308, disc_loss = 0.0703004589436119
Trained batch 212 in epoch 17, gen_loss = 0.834565261160264, disc_loss = 0.07008045605283247
Trained batch 213 in epoch 17, gen_loss = 0.8352859332182697, disc_loss = 0.06985944839821101
Trained batch 214 in epoch 17, gen_loss = 0.8357412327167599, disc_loss = 0.0696111134275101
Trained batch 215 in epoch 17, gen_loss = 0.8358441491921743, disc_loss = 0.06937600622660722
Trained batch 216 in epoch 17, gen_loss = 0.8346853193050155, disc_loss = 0.06943152589543213
Trained batch 217 in epoch 17, gen_loss = 0.8342981628321726, disc_loss = 0.06951560068516693
Trained batch 218 in epoch 17, gen_loss = 0.8351129674476031, disc_loss = 0.06927376846489433
Trained batch 219 in epoch 17, gen_loss = 0.8349428848786787, disc_loss = 0.06934475177814338
Trained batch 220 in epoch 17, gen_loss = 0.8365467112528253, disc_loss = 0.0701400995364084
Trained batch 221 in epoch 17, gen_loss = 0.8354592664284749, disc_loss = 0.07033337387969499
Trained batch 222 in epoch 17, gen_loss = 0.8345779375645077, disc_loss = 0.07043704614794975
Trained batch 223 in epoch 17, gen_loss = 0.8357841577380896, disc_loss = 0.07031482613196463
Trained batch 224 in epoch 17, gen_loss = 0.8364603275722927, disc_loss = 0.07029809996899632
Trained batch 225 in epoch 17, gen_loss = 0.8355789733144035, disc_loss = 0.07041156429187519
Trained batch 226 in epoch 17, gen_loss = 0.8353945843973875, disc_loss = 0.0703026264914135
Trained batch 227 in epoch 17, gen_loss = 0.8349178341919916, disc_loss = 0.0704382212154502
Trained batch 228 in epoch 17, gen_loss = 0.8363468410146289, disc_loss = 0.07097129581097562
Trained batch 229 in epoch 17, gen_loss = 0.8362929468569549, disc_loss = 0.07093409481660827
Trained batch 230 in epoch 17, gen_loss = 0.8350341774168468, disc_loss = 0.07105654655871066
Trained batch 231 in epoch 17, gen_loss = 0.833813536526828, disc_loss = 0.07127174308346905
Trained batch 232 in epoch 17, gen_loss = 0.8328639335386743, disc_loss = 0.07141460126961377
Trained batch 233 in epoch 17, gen_loss = 0.8341101601592495, disc_loss = 0.07121130117637098
Trained batch 234 in epoch 17, gen_loss = 0.834248722614126, disc_loss = 0.07135529937024446
Trained batch 235 in epoch 17, gen_loss = 0.8353198860156335, disc_loss = 0.07205862653347016
Trained batch 236 in epoch 17, gen_loss = 0.834177031295712, disc_loss = 0.07244346545859857
Trained batch 237 in epoch 17, gen_loss = 0.8330401915962956, disc_loss = 0.07292692889576825
Trained batch 238 in epoch 17, gen_loss = 0.8341356413633754, disc_loss = 0.07347457186089026
Trained batch 239 in epoch 17, gen_loss = 0.8339889377355576, disc_loss = 0.07343914406762148
Trained batch 240 in epoch 17, gen_loss = 0.8349609706411718, disc_loss = 0.07338985201373263
Trained batch 241 in epoch 17, gen_loss = 0.8358348938059216, disc_loss = 0.07318718862635168
Trained batch 242 in epoch 17, gen_loss = 0.8344854960225737, disc_loss = 0.07335967998645065
Trained batch 243 in epoch 17, gen_loss = 0.834000870096879, disc_loss = 0.07336329588223799
Trained batch 244 in epoch 17, gen_loss = 0.8336686993131832, disc_loss = 0.07323584619301314
Trained batch 245 in epoch 17, gen_loss = 0.834022408578454, disc_loss = 0.07305303790296118
Trained batch 246 in epoch 17, gen_loss = 0.8341857716139511, disc_loss = 0.07296666139849887
Trained batch 247 in epoch 17, gen_loss = 0.834053295514276, disc_loss = 0.07278883906697194
Trained batch 248 in epoch 17, gen_loss = 0.833616947553244, disc_loss = 0.07284475098846548
Trained batch 249 in epoch 17, gen_loss = 0.8356532135009765, disc_loss = 0.07294388188794255
Trained batch 250 in epoch 17, gen_loss = 0.8361541066036756, disc_loss = 0.07270612332791802
Trained batch 251 in epoch 17, gen_loss = 0.8363058358903915, disc_loss = 0.07252300540650529
Trained batch 252 in epoch 17, gen_loss = 0.8363862169589921, disc_loss = 0.07258248851513086
Trained batch 253 in epoch 17, gen_loss = 0.8356314620633764, disc_loss = 0.07259073655128362
Trained batch 254 in epoch 17, gen_loss = 0.8363034673765594, disc_loss = 0.07236015659702175
Trained batch 255 in epoch 17, gen_loss = 0.8358870134688914, disc_loss = 0.07245337954736897
Trained batch 256 in epoch 17, gen_loss = 0.8362457255908952, disc_loss = 0.07222674011183967
Trained batch 257 in epoch 17, gen_loss = 0.8365522604580073, disc_loss = 0.072116437674926
Trained batch 258 in epoch 17, gen_loss = 0.8368064972884867, disc_loss = 0.0719304415846826
Trained batch 259 in epoch 17, gen_loss = 0.8367983169280566, disc_loss = 0.07171794562600553
Trained batch 260 in epoch 17, gen_loss = 0.8369865559070047, disc_loss = 0.07187228172774858
Trained batch 261 in epoch 17, gen_loss = 0.8366977993313592, disc_loss = 0.07209616512387194
Trained batch 262 in epoch 17, gen_loss = 0.8374432672112614, disc_loss = 0.07199180230654124
Trained batch 263 in epoch 17, gen_loss = 0.8377015534223933, disc_loss = 0.07178275878047288
Trained batch 264 in epoch 17, gen_loss = 0.8369550252860447, disc_loss = 0.07209432275157492
Trained batch 265 in epoch 17, gen_loss = 0.8368701663680542, disc_loss = 0.07223542635083983
Trained batch 266 in epoch 17, gen_loss = 0.8373488323965322, disc_loss = 0.0722387737318985
Trained batch 267 in epoch 17, gen_loss = 0.8366494739233558, disc_loss = 0.07225264495919778
Trained batch 268 in epoch 17, gen_loss = 0.8358620936985796, disc_loss = 0.07231984776011963
Trained batch 269 in epoch 17, gen_loss = 0.8355727032378868, disc_loss = 0.07232516891909418
Trained batch 270 in epoch 17, gen_loss = 0.8348577493231235, disc_loss = 0.07223508366455782
Trained batch 271 in epoch 17, gen_loss = 0.8357209576403394, disc_loss = 0.07213495709755294
Trained batch 272 in epoch 17, gen_loss = 0.8355253214364523, disc_loss = 0.07197830456585347
Trained batch 273 in epoch 17, gen_loss = 0.8364298356710559, disc_loss = 0.07220841752854686
Trained batch 274 in epoch 17, gen_loss = 0.8355733509497208, disc_loss = 0.07238107322630558
Trained batch 275 in epoch 17, gen_loss = 0.834724008821059, disc_loss = 0.07257438180090832
Trained batch 276 in epoch 17, gen_loss = 0.8361868739988829, disc_loss = 0.07269202351960141
Trained batch 277 in epoch 17, gen_loss = 0.8365893494739807, disc_loss = 0.07248799505864652
Trained batch 278 in epoch 17, gen_loss = 0.8360632954959801, disc_loss = 0.07242788464218164
Trained batch 279 in epoch 17, gen_loss = 0.8365769503372056, disc_loss = 0.0722743210083406
Trained batch 280 in epoch 17, gen_loss = 0.8359327131743108, disc_loss = 0.07223085177154197
Trained batch 281 in epoch 17, gen_loss = 0.8374773849409523, disc_loss = 0.07212557808449822
Trained batch 282 in epoch 17, gen_loss = 0.83736201604769, disc_loss = 0.07208813377738314
Trained batch 283 in epoch 17, gen_loss = 0.8373943533695919, disc_loss = 0.07188723156963225
Trained batch 284 in epoch 17, gen_loss = 0.8375112366258053, disc_loss = 0.0716949035985428
Trained batch 285 in epoch 17, gen_loss = 0.8378065132594609, disc_loss = 0.07152722744023675
Trained batch 286 in epoch 17, gen_loss = 0.8372928319492406, disc_loss = 0.07144337011832186
Trained batch 287 in epoch 17, gen_loss = 0.8377150777313445, disc_loss = 0.07134248234150517
Trained batch 288 in epoch 17, gen_loss = 0.839086560642018, disc_loss = 0.07140614763288969
Trained batch 289 in epoch 17, gen_loss = 0.8385866175437796, disc_loss = 0.07161257724952082
Trained batch 290 in epoch 17, gen_loss = 0.8378650148709615, disc_loss = 0.07168332004081138
Trained batch 291 in epoch 17, gen_loss = 0.8390955620840804, disc_loss = 0.0717652787148238
Trained batch 292 in epoch 17, gen_loss = 0.8387419445115959, disc_loss = 0.07173182546405865
Trained batch 293 in epoch 17, gen_loss = 0.8386169534151245, disc_loss = 0.07172674987921301
Trained batch 294 in epoch 17, gen_loss = 0.8391215841648942, disc_loss = 0.07153881179579234
Trained batch 295 in epoch 17, gen_loss = 0.8391722229284209, disc_loss = 0.07148420721342838
Trained batch 296 in epoch 17, gen_loss = 0.838885678586735, disc_loss = 0.07142363974090779
Trained batch 297 in epoch 17, gen_loss = 0.8378599818120867, disc_loss = 0.07178787295800328
Trained batch 298 in epoch 17, gen_loss = 0.8383357859774178, disc_loss = 0.07174350434671277
Trained batch 299 in epoch 17, gen_loss = 0.8389393456776937, disc_loss = 0.07169716284920771
Trained batch 300 in epoch 17, gen_loss = 0.8380057859262359, disc_loss = 0.07186896701736308
Trained batch 301 in epoch 17, gen_loss = 0.83810623690782, disc_loss = 0.07172337918240108
Trained batch 302 in epoch 17, gen_loss = 0.8390311185676272, disc_loss = 0.07160056983627895
Trained batch 303 in epoch 17, gen_loss = 0.8385042259959798, disc_loss = 0.07182114369137899
Trained batch 304 in epoch 17, gen_loss = 0.8372789537320372, disc_loss = 0.0725591453738877
Trained batch 305 in epoch 17, gen_loss = 0.8380462007195342, disc_loss = 0.07272315528122039
Trained batch 306 in epoch 17, gen_loss = 0.8379539721175203, disc_loss = 0.07275482790138124
Trained batch 307 in epoch 17, gen_loss = 0.8374771440958048, disc_loss = 0.07277004160712679
Trained batch 308 in epoch 17, gen_loss = 0.8372945789380367, disc_loss = 0.0726769374484576
Trained batch 309 in epoch 17, gen_loss = 0.8369787058522624, disc_loss = 0.0725765482192078
Trained batch 310 in epoch 17, gen_loss = 0.8366038172574672, disc_loss = 0.07255995514356438
Trained batch 311 in epoch 17, gen_loss = 0.8359289068060044, disc_loss = 0.07257644737807986
Trained batch 312 in epoch 17, gen_loss = 0.836293181862694, disc_loss = 0.07272670635828576
Trained batch 313 in epoch 17, gen_loss = 0.8366237685179255, disc_loss = 0.07256899275787317
Trained batch 314 in epoch 17, gen_loss = 0.8353302656658113, disc_loss = 0.07305257888067336
Trained batch 315 in epoch 17, gen_loss = 0.8362464452091651, disc_loss = 0.07316762180645255
Trained batch 316 in epoch 17, gen_loss = 0.8364494879163026, disc_loss = 0.07300900477528197
Trained batch 317 in epoch 17, gen_loss = 0.8365337217004044, disc_loss = 0.07310924901621146
Trained batch 318 in epoch 17, gen_loss = 0.8362638533675932, disc_loss = 0.07298567366777543
Trained batch 319 in epoch 17, gen_loss = 0.8357916994020342, disc_loss = 0.07308547034626826
Trained batch 320 in epoch 17, gen_loss = 0.8360475058496184, disc_loss = 0.0729205117175048
Trained batch 321 in epoch 17, gen_loss = 0.8361549808742097, disc_loss = 0.07278968014332078
Trained batch 322 in epoch 17, gen_loss = 0.8356382570030519, disc_loss = 0.07278162513170448
Trained batch 323 in epoch 17, gen_loss = 0.835447006755405, disc_loss = 0.07265721118928474
Trained batch 324 in epoch 17, gen_loss = 0.8350369204007663, disc_loss = 0.07266148003248069
Trained batch 325 in epoch 17, gen_loss = 0.835271245497136, disc_loss = 0.07274777917591341
Trained batch 326 in epoch 17, gen_loss = 0.8354421846728077, disc_loss = 0.07262079299794971
Trained batch 327 in epoch 17, gen_loss = 0.8353413792281617, disc_loss = 0.07249589622724892
Trained batch 328 in epoch 17, gen_loss = 0.8355222715795221, disc_loss = 0.0723358798024774
Trained batch 329 in epoch 17, gen_loss = 0.8355697826905684, disc_loss = 0.07220016840393796
Trained batch 330 in epoch 17, gen_loss = 0.8354332859422505, disc_loss = 0.07214541562756924
Trained batch 331 in epoch 17, gen_loss = 0.8354115825460617, disc_loss = 0.07201878681599376
Trained batch 332 in epoch 17, gen_loss = 0.8352251187101141, disc_loss = 0.07198086949261101
Trained batch 333 in epoch 17, gen_loss = 0.836003013535174, disc_loss = 0.07234503373414457
Trained batch 334 in epoch 17, gen_loss = 0.8362670702720756, disc_loss = 0.07220449733978777
Trained batch 335 in epoch 17, gen_loss = 0.8359070115146183, disc_loss = 0.07221641652618668
Trained batch 336 in epoch 17, gen_loss = 0.8370122768051192, disc_loss = 0.07214269914749999
Trained batch 337 in epoch 17, gen_loss = 0.8363219961612183, disc_loss = 0.07231104909029057
Trained batch 338 in epoch 17, gen_loss = 0.8363568237749173, disc_loss = 0.07228895759753949
Trained batch 339 in epoch 17, gen_loss = 0.8355519647107404, disc_loss = 0.07241810789770063
Trained batch 340 in epoch 17, gen_loss = 0.8361529851239448, disc_loss = 0.07232478443981091
Trained batch 341 in epoch 17, gen_loss = 0.8355665471818712, disc_loss = 0.07226394841785146
Trained batch 342 in epoch 17, gen_loss = 0.8358927183179049, disc_loss = 0.07223379978524526
Trained batch 343 in epoch 17, gen_loss = 0.8354801535606384, disc_loss = 0.07222026666128185
Trained batch 344 in epoch 17, gen_loss = 0.8367740876432778, disc_loss = 0.07236758377133072
Trained batch 345 in epoch 17, gen_loss = 0.8376357999840224, disc_loss = 0.07223000693420283
Trained batch 346 in epoch 17, gen_loss = 0.837200938624676, disc_loss = 0.07227515083031799
Trained batch 347 in epoch 17, gen_loss = 0.836412318307778, disc_loss = 0.07246716636843209
Trained batch 348 in epoch 17, gen_loss = 0.8367736494985214, disc_loss = 0.07264107828132574
Trained batch 349 in epoch 17, gen_loss = 0.8365261696066175, disc_loss = 0.07251713618636131
Trained batch 350 in epoch 17, gen_loss = 0.8369357686097126, disc_loss = 0.07235142200697012
Trained batch 351 in epoch 17, gen_loss = 0.8367285130714829, disc_loss = 0.07226350165332075
Trained batch 352 in epoch 17, gen_loss = 0.836392320587007, disc_loss = 0.07219991572834446
Trained batch 353 in epoch 17, gen_loss = 0.8365641355851275, disc_loss = 0.0720690537380886
Trained batch 354 in epoch 17, gen_loss = 0.8367755273698081, disc_loss = 0.07214639209420748
Trained batch 355 in epoch 17, gen_loss = 0.8361592133728306, disc_loss = 0.0722443753110475
Trained batch 356 in epoch 17, gen_loss = 0.8360074271007079, disc_loss = 0.07213050654518004
Trained batch 357 in epoch 17, gen_loss = 0.8364369133331256, disc_loss = 0.07215541036664275
Trained batch 358 in epoch 17, gen_loss = 0.8362006970102741, disc_loss = 0.07205218928126737
Trained batch 359 in epoch 17, gen_loss = 0.8364706367254258, disc_loss = 0.0719748869797008
Trained batch 360 in epoch 17, gen_loss = 0.8359169434972747, disc_loss = 0.07199518451173055
Trained batch 361 in epoch 17, gen_loss = 0.8358458501199333, disc_loss = 0.07190196012861985
Trained batch 362 in epoch 17, gen_loss = 0.836403917675176, disc_loss = 0.07186028562978772
Trained batch 363 in epoch 17, gen_loss = 0.8369778447098785, disc_loss = 0.07173704657355671
Trained batch 364 in epoch 17, gen_loss = 0.8369937653410925, disc_loss = 0.07162544330811664
Trained batch 365 in epoch 17, gen_loss = 0.837594909908993, disc_loss = 0.07147548445424096
Trained batch 366 in epoch 17, gen_loss = 0.838502127565545, disc_loss = 0.07148601070087028
Trained batch 367 in epoch 17, gen_loss = 0.8388952669566092, disc_loss = 0.07133679809150002
Trained batch 368 in epoch 17, gen_loss = 0.8382556549901885, disc_loss = 0.07178440500747382
Trained batch 369 in epoch 17, gen_loss = 0.83886997586972, disc_loss = 0.07172398029046284
Trained batch 370 in epoch 17, gen_loss = 0.8387505492431455, disc_loss = 0.07182252253945465
Trained batch 371 in epoch 17, gen_loss = 0.8388647018901764, disc_loss = 0.0717417890736733
Trained batch 372 in epoch 17, gen_loss = 0.8386992594831431, disc_loss = 0.07178943723579993
Trained batch 373 in epoch 17, gen_loss = 0.8389033074366218, disc_loss = 0.07172705682821293
Trained batch 374 in epoch 17, gen_loss = 0.8392189011573792, disc_loss = 0.07158077357709408
Trained batch 375 in epoch 17, gen_loss = 0.8385424231912227, disc_loss = 0.07170456315470027
Trained batch 376 in epoch 17, gen_loss = 0.8407976872408738, disc_loss = 0.07206540620473241
Trained batch 377 in epoch 17, gen_loss = 0.8402275039405419, disc_loss = 0.07214909346981181
Trained batch 378 in epoch 17, gen_loss = 0.8397558285881788, disc_loss = 0.07220095290377304
Trained batch 379 in epoch 17, gen_loss = 0.8393935187866813, disc_loss = 0.07215051626002318
Trained batch 380 in epoch 17, gen_loss = 0.8389829575546145, disc_loss = 0.0721908135882278
Trained batch 381 in epoch 17, gen_loss = 0.8391905881035391, disc_loss = 0.07223667105396536
Trained batch 382 in epoch 17, gen_loss = 0.8389230155758073, disc_loss = 0.07224725644461635
Trained batch 383 in epoch 17, gen_loss = 0.8391145309433341, disc_loss = 0.07216603273506432
Trained batch 384 in epoch 17, gen_loss = 0.8388120871085625, disc_loss = 0.07217902649048862
Trained batch 385 in epoch 17, gen_loss = 0.8387886403138156, disc_loss = 0.07215230559225681
Trained batch 386 in epoch 17, gen_loss = 0.8388653522314027, disc_loss = 0.07231556724766582
Trained batch 387 in epoch 17, gen_loss = 0.8380145697864061, disc_loss = 0.07257160500709697
Trained batch 388 in epoch 17, gen_loss = 0.8386496994979584, disc_loss = 0.07248145815435136
Trained batch 389 in epoch 17, gen_loss = 0.8390695526049687, disc_loss = 0.07263826753179996
Trained batch 390 in epoch 17, gen_loss = 0.8385796312176054, disc_loss = 0.0727813804326841
Trained batch 391 in epoch 17, gen_loss = 0.8387240928654768, disc_loss = 0.07270443221383101
Trained batch 392 in epoch 17, gen_loss = 0.839460453914322, disc_loss = 0.0729301684694815
Trained batch 393 in epoch 17, gen_loss = 0.8389755780926815, disc_loss = 0.07303966750594111
Trained batch 394 in epoch 17, gen_loss = 0.8392877611932875, disc_loss = 0.07312953734793995
Trained batch 395 in epoch 17, gen_loss = 0.8390658654347815, disc_loss = 0.07305350311269815
Trained batch 396 in epoch 17, gen_loss = 0.8387707814161363, disc_loss = 0.07306596338842768
Trained batch 397 in epoch 17, gen_loss = 0.8389507358397671, disc_loss = 0.07306976543842399
Trained batch 398 in epoch 17, gen_loss = 0.8386845251073813, disc_loss = 0.07300572446955923
Trained batch 399 in epoch 17, gen_loss = 0.8389021378755569, disc_loss = 0.07313829275313764
Trained batch 400 in epoch 17, gen_loss = 0.838370180486741, disc_loss = 0.07313912934588822
Trained batch 401 in epoch 17, gen_loss = 0.8377648240594722, disc_loss = 0.07317114401312165
Trained batch 402 in epoch 17, gen_loss = 0.8382361534215677, disc_loss = 0.07326293849933976
Trained batch 403 in epoch 17, gen_loss = 0.837474911814869, disc_loss = 0.07343529017715908
Trained batch 404 in epoch 17, gen_loss = 0.8380065667776414, disc_loss = 0.07357958765401516
Trained batch 405 in epoch 17, gen_loss = 0.837552464654293, disc_loss = 0.07364597094928836
Trained batch 406 in epoch 17, gen_loss = 0.837397887900069, disc_loss = 0.07355599577197718
Trained batch 407 in epoch 17, gen_loss = 0.83704427819626, disc_loss = 0.07354716019357975
Trained batch 408 in epoch 17, gen_loss = 0.837230741831959, disc_loss = 0.073488620704172
Trained batch 409 in epoch 17, gen_loss = 0.8373130789617212, disc_loss = 0.07338347162869645
Trained batch 410 in epoch 17, gen_loss = 0.8374556915023321, disc_loss = 0.07333317825484595
Trained batch 411 in epoch 17, gen_loss = 0.8373956579027824, disc_loss = 0.07335735924849376
Trained batch 412 in epoch 17, gen_loss = 0.8375821283885411, disc_loss = 0.07323325179138426
Trained batch 413 in epoch 17, gen_loss = 0.8374190699075155, disc_loss = 0.07312217194604989
Trained batch 414 in epoch 17, gen_loss = 0.8372744586094316, disc_loss = 0.07305719803973852
Trained batch 415 in epoch 17, gen_loss = 0.8376931622624397, disc_loss = 0.07298484689985904
Trained batch 416 in epoch 17, gen_loss = 0.8374207693038227, disc_loss = 0.07295709271296609
Trained batch 417 in epoch 17, gen_loss = 0.8372246489000092, disc_loss = 0.0728205346622678
Trained batch 418 in epoch 17, gen_loss = 0.836992577038403, disc_loss = 0.07290439255233312
Trained batch 419 in epoch 17, gen_loss = 0.8371589592524937, disc_loss = 0.072906187700019
Trained batch 420 in epoch 17, gen_loss = 0.8363805299983171, disc_loss = 0.0731914305258675
Trained batch 421 in epoch 17, gen_loss = 0.8370708002580851, disc_loss = 0.07323881040075661
Trained batch 422 in epoch 17, gen_loss = 0.8375133539486157, disc_loss = 0.07310196013139213
Trained batch 423 in epoch 17, gen_loss = 0.8369046695670992, disc_loss = 0.07324700105829902
Trained batch 424 in epoch 17, gen_loss = 0.837664118233849, disc_loss = 0.0732213298450498
Trained batch 425 in epoch 17, gen_loss = 0.8375814897073827, disc_loss = 0.0731384296652297
Trained batch 426 in epoch 17, gen_loss = 0.8373437340979833, disc_loss = 0.07308498419280354
Trained batch 427 in epoch 17, gen_loss = 0.8380823734207689, disc_loss = 0.07296640099957585
Trained batch 428 in epoch 17, gen_loss = 0.8376111948128903, disc_loss = 0.07305052785728222
Trained batch 429 in epoch 17, gen_loss = 0.8375871878723765, disc_loss = 0.0729705337824863
Trained batch 430 in epoch 17, gen_loss = 0.8378158827115654, disc_loss = 0.07285547322591468
Trained batch 431 in epoch 17, gen_loss = 0.8377604189294355, disc_loss = 0.0730410656693426
Trained batch 432 in epoch 17, gen_loss = 0.8377431697162689, disc_loss = 0.07291974609515546
Trained batch 433 in epoch 17, gen_loss = 0.8378790584028042, disc_loss = 0.07285173709851943
Trained batch 434 in epoch 17, gen_loss = 0.8374746351406492, disc_loss = 0.07291245959356599
Trained batch 435 in epoch 17, gen_loss = 0.8378352598039382, disc_loss = 0.07299245094641223
Trained batch 436 in epoch 17, gen_loss = 0.8375248869442012, disc_loss = 0.07308297422320265
Trained batch 437 in epoch 17, gen_loss = 0.8370698223647461, disc_loss = 0.07312807709948249
Trained batch 438 in epoch 17, gen_loss = 0.8371512204204985, disc_loss = 0.07317317129963487
Trained batch 439 in epoch 17, gen_loss = 0.8368574401194399, disc_loss = 0.07312341613102366
Trained batch 440 in epoch 17, gen_loss = 0.8364881032448507, disc_loss = 0.07314173694353661
Trained batch 441 in epoch 17, gen_loss = 0.8366462616629191, disc_loss = 0.07306893801577895
Trained batch 442 in epoch 17, gen_loss = 0.8371920595050666, disc_loss = 0.07295658376328563
Trained batch 443 in epoch 17, gen_loss = 0.8366267396523072, disc_loss = 0.07302465027214976
Trained batch 444 in epoch 17, gen_loss = 0.83696898195181, disc_loss = 0.07289705702595496
Trained batch 445 in epoch 17, gen_loss = 0.8367973361581965, disc_loss = 0.07279623054268648
Trained batch 446 in epoch 17, gen_loss = 0.8363129112544476, disc_loss = 0.07283108084727187
Trained batch 447 in epoch 17, gen_loss = 0.835960215090641, disc_loss = 0.07277614990847983
Trained batch 448 in epoch 17, gen_loss = 0.83724041226712, disc_loss = 0.07303529368808911
Trained batch 449 in epoch 17, gen_loss = 0.8374824692143334, disc_loss = 0.07295509888894028
Trained batch 450 in epoch 17, gen_loss = 0.8369883680819408, disc_loss = 0.07309238220298633
Trained batch 451 in epoch 17, gen_loss = 0.8371125993739187, disc_loss = 0.07312920159635554
Trained batch 452 in epoch 17, gen_loss = 0.8367157699519698, disc_loss = 0.07315203304881555
Trained batch 453 in epoch 17, gen_loss = 0.8363852200266548, disc_loss = 0.07316758725710115
Trained batch 454 in epoch 17, gen_loss = 0.8364149257376954, disc_loss = 0.07319949625448866
Trained batch 455 in epoch 17, gen_loss = 0.8363219994986266, disc_loss = 0.07312303176149726
Trained batch 456 in epoch 17, gen_loss = 0.835884531817238, disc_loss = 0.07313921666934402
Trained batch 457 in epoch 17, gen_loss = 0.8363670723667311, disc_loss = 0.07306079647816946
Trained batch 458 in epoch 17, gen_loss = 0.8368437642105784, disc_loss = 0.07294314927249043
Trained batch 459 in epoch 17, gen_loss = 0.8365625652282135, disc_loss = 0.07304490642298175
Trained batch 460 in epoch 17, gen_loss = 0.8367742624562112, disc_loss = 0.07312895800037524
Trained batch 461 in epoch 17, gen_loss = 0.8363026335383906, disc_loss = 0.07312768057101604
Trained batch 462 in epoch 17, gen_loss = 0.8358873412109605, disc_loss = 0.0731163567965991
Trained batch 463 in epoch 17, gen_loss = 0.8371511438283427, disc_loss = 0.07333083288214201
Trained batch 464 in epoch 17, gen_loss = 0.83672387343581, disc_loss = 0.07329713326868831
Trained batch 465 in epoch 17, gen_loss = 0.8373301082926247, disc_loss = 0.07318198584547754
Trained batch 466 in epoch 17, gen_loss = 0.8369374696396659, disc_loss = 0.07342850666979779
Trained batch 467 in epoch 17, gen_loss = 0.8371984800721846, disc_loss = 0.07337553584629782
Trained batch 468 in epoch 17, gen_loss = 0.8377564283830525, disc_loss = 0.0733350438516595
Trained batch 469 in epoch 17, gen_loss = 0.8375327379145521, disc_loss = 0.07328305946306345
Trained batch 470 in epoch 17, gen_loss = 0.8376643250196096, disc_loss = 0.0731949376855876
Trained batch 471 in epoch 17, gen_loss = 0.8373034424700979, disc_loss = 0.07326622733104406
Trained batch 472 in epoch 17, gen_loss = 0.8373235102435751, disc_loss = 0.07330536852978627
Trained batch 473 in epoch 17, gen_loss = 0.8374231071663305, disc_loss = 0.07317700791899664
Trained batch 474 in epoch 17, gen_loss = 0.8372027548990751, disc_loss = 0.07319779118424968
Trained batch 475 in epoch 17, gen_loss = 0.8373425348716623, disc_loss = 0.07309878473913595
Trained batch 476 in epoch 17, gen_loss = 0.8372887856555435, disc_loss = 0.07298858633628057
Trained batch 477 in epoch 17, gen_loss = 0.8375759434001715, disc_loss = 0.07290271926421875
Trained batch 478 in epoch 17, gen_loss = 0.8380195337944588, disc_loss = 0.07277463836933726
Trained batch 479 in epoch 17, gen_loss = 0.8381378016124169, disc_loss = 0.0727838494349271
Trained batch 480 in epoch 17, gen_loss = 0.8381781916360598, disc_loss = 0.07267691852551984
Trained batch 481 in epoch 17, gen_loss = 0.8378686122132535, disc_loss = 0.07274246159399941
Trained batch 482 in epoch 17, gen_loss = 0.8379278580347697, disc_loss = 0.0727065742463182
Trained batch 483 in epoch 17, gen_loss = 0.8381283801695532, disc_loss = 0.07342109528239354
Trained batch 484 in epoch 17, gen_loss = 0.8371630996158442, disc_loss = 0.07374277244677249
Trained batch 485 in epoch 17, gen_loss = 0.8376723025684003, disc_loss = 0.07368123911535789
Trained batch 486 in epoch 17, gen_loss = 0.8375180606602154, disc_loss = 0.07374520452972311
Trained batch 487 in epoch 17, gen_loss = 0.8379869482434187, disc_loss = 0.0739650518679228
Trained batch 488 in epoch 17, gen_loss = 0.8373710467405846, disc_loss = 0.07413275466740497
Trained batch 489 in epoch 17, gen_loss = 0.8377561746203169, disc_loss = 0.07420227650781067
Trained batch 490 in epoch 17, gen_loss = 0.8373672747927625, disc_loss = 0.07434240464583919
Trained batch 491 in epoch 17, gen_loss = 0.8373510933867315, disc_loss = 0.07442963495850563
Trained batch 492 in epoch 17, gen_loss = 0.8371693132252529, disc_loss = 0.0744319025117292
Trained batch 493 in epoch 17, gen_loss = 0.8370880727705202, disc_loss = 0.07449257100822955
Trained batch 494 in epoch 17, gen_loss = 0.8371761990918054, disc_loss = 0.07471563408170083
Trained batch 495 in epoch 17, gen_loss = 0.8370593182382083, disc_loss = 0.07481334012963119
Trained batch 496 in epoch 17, gen_loss = 0.8365213640139136, disc_loss = 0.0749089589541107
Trained batch 497 in epoch 17, gen_loss = 0.837043684110584, disc_loss = 0.07491375992156894
Trained batch 498 in epoch 17, gen_loss = 0.8365327685414431, disc_loss = 0.07494789463484694
Trained batch 499 in epoch 17, gen_loss = 0.8365596236586571, disc_loss = 0.07498923963308335
Trained batch 500 in epoch 17, gen_loss = 0.8362677447691174, disc_loss = 0.07494077550436923
Trained batch 501 in epoch 17, gen_loss = 0.8356067785822537, disc_loss = 0.07504646132785485
Trained batch 502 in epoch 17, gen_loss = 0.8356300505326235, disc_loss = 0.07505558068247487
Trained batch 503 in epoch 17, gen_loss = 0.8355051856783647, disc_loss = 0.07504668404599504
Trained batch 504 in epoch 17, gen_loss = 0.8353621005421817, disc_loss = 0.07502305826338211
Trained batch 505 in epoch 17, gen_loss = 0.8349107416133165, disc_loss = 0.07514490363861732
Trained batch 506 in epoch 17, gen_loss = 0.8349844408340943, disc_loss = 0.07511027257970335
Trained batch 507 in epoch 17, gen_loss = 0.8346300017763311, disc_loss = 0.0751562309121405
Trained batch 508 in epoch 17, gen_loss = 0.8341398845135815, disc_loss = 0.07526728644791426
Trained batch 509 in epoch 17, gen_loss = 0.8348722094998641, disc_loss = 0.07534354367822993
Trained batch 510 in epoch 17, gen_loss = 0.834303484212629, disc_loss = 0.0756485156073379
Trained batch 511 in epoch 17, gen_loss = 0.8343876934959553, disc_loss = 0.07585729059792357
Trained batch 512 in epoch 17, gen_loss = 0.83431559597772, disc_loss = 0.07577987843815812
Trained batch 513 in epoch 17, gen_loss = 0.8345603241878725, disc_loss = 0.0757150746490589
Trained batch 514 in epoch 17, gen_loss = 0.8345367780588205, disc_loss = 0.07563575822317485
Trained batch 515 in epoch 17, gen_loss = 0.8341361700679905, disc_loss = 0.0757156033285482
Trained batch 516 in epoch 17, gen_loss = 0.83412921411387, disc_loss = 0.07571066435376035
Trained batch 517 in epoch 17, gen_loss = 0.8340689485252594, disc_loss = 0.07572888052918046
Trained batch 518 in epoch 17, gen_loss = 0.8337952986732843, disc_loss = 0.0757160113769115
Trained batch 519 in epoch 17, gen_loss = 0.8335497199915922, disc_loss = 0.07573096472053574
Trained batch 520 in epoch 17, gen_loss = 0.8334559787372252, disc_loss = 0.07579890371884815
Trained batch 521 in epoch 17, gen_loss = 0.8331596757146134, disc_loss = 0.07571481697090056
Trained batch 522 in epoch 17, gen_loss = 0.8325587436414358, disc_loss = 0.07585980773798366
Trained batch 523 in epoch 17, gen_loss = 0.8328108087409544, disc_loss = 0.07585456103569906
Trained batch 524 in epoch 17, gen_loss = 0.8326481010232653, disc_loss = 0.07575842806271145
Trained batch 525 in epoch 17, gen_loss = 0.8324154950253411, disc_loss = 0.07592718844291375
Trained batch 526 in epoch 17, gen_loss = 0.832180074711226, disc_loss = 0.07586351107714072
Trained batch 527 in epoch 17, gen_loss = 0.8321817667985504, disc_loss = 0.07579607078382238
Trained batch 528 in epoch 17, gen_loss = 0.8323163129318865, disc_loss = 0.075686980383946
Trained batch 529 in epoch 17, gen_loss = 0.8319991970399641, disc_loss = 0.07574005295645515
Trained batch 530 in epoch 17, gen_loss = 0.8321765270049064, disc_loss = 0.07567700676325351
Trained batch 531 in epoch 17, gen_loss = 0.8319730683040798, disc_loss = 0.0756366836901446
Trained batch 532 in epoch 17, gen_loss = 0.831787265655471, disc_loss = 0.07565511094919959
Trained batch 533 in epoch 17, gen_loss = 0.8314435936873326, disc_loss = 0.0756098022649574
Trained batch 534 in epoch 17, gen_loss = 0.8310730917988537, disc_loss = 0.07564580994788732
Trained batch 535 in epoch 17, gen_loss = 0.8308416660041061, disc_loss = 0.07566546726582656
Trained batch 536 in epoch 17, gen_loss = 0.8307183563043286, disc_loss = 0.07564215022147923
Trained batch 537 in epoch 17, gen_loss = 0.8310305862289379, disc_loss = 0.07561014194498497
Trained batch 538 in epoch 17, gen_loss = 0.831173302567735, disc_loss = 0.07549827440308342
Trained batch 539 in epoch 17, gen_loss = 0.8309566015998523, disc_loss = 0.07551258262419314
Trained batch 540 in epoch 17, gen_loss = 0.8306349964877814, disc_loss = 0.07554405522248717
Trained batch 541 in epoch 17, gen_loss = 0.8305238869687288, disc_loss = 0.07545825680786558
Trained batch 542 in epoch 17, gen_loss = 0.8303137443012955, disc_loss = 0.07538899726321849
Trained batch 543 in epoch 17, gen_loss = 0.8312241058687077, disc_loss = 0.07547348780687624
Trained batch 544 in epoch 17, gen_loss = 0.8311067730461785, disc_loss = 0.07544134019130687
Trained batch 545 in epoch 17, gen_loss = 0.8311986531857606, disc_loss = 0.07533923397864123
Trained batch 546 in epoch 17, gen_loss = 0.8310470678579654, disc_loss = 0.07532934266120413
Trained batch 547 in epoch 17, gen_loss = 0.8321365365473024, disc_loss = 0.07561051300862791
Trained batch 548 in epoch 17, gen_loss = 0.8317965609454067, disc_loss = 0.07584678479902894
Trained batch 549 in epoch 17, gen_loss = 0.8319184371016243, disc_loss = 0.07575025192546574
Trained batch 550 in epoch 17, gen_loss = 0.8320285146227766, disc_loss = 0.07579228523848223
Trained batch 551 in epoch 17, gen_loss = 0.8320665625666362, disc_loss = 0.07579916546735373
Trained batch 552 in epoch 17, gen_loss = 0.8316029353879029, disc_loss = 0.07610279821351197
Trained batch 553 in epoch 17, gen_loss = 0.8315503436413052, disc_loss = 0.07604398083325059
Trained batch 554 in epoch 17, gen_loss = 0.831798172587747, disc_loss = 0.07595463382868885
Trained batch 555 in epoch 17, gen_loss = 0.8318923804506981, disc_loss = 0.07585815146478335
Trained batch 556 in epoch 17, gen_loss = 0.8323731463623218, disc_loss = 0.07583169075133717
Trained batch 557 in epoch 17, gen_loss = 0.8322846370892713, disc_loss = 0.07581561080624072
Trained batch 558 in epoch 17, gen_loss = 0.8315621545681586, disc_loss = 0.07609907528868674
Trained batch 559 in epoch 17, gen_loss = 0.8318010617047549, disc_loss = 0.07611190916671018
Trained batch 560 in epoch 17, gen_loss = 0.8322220855324451, disc_loss = 0.07607534423357609
Trained batch 561 in epoch 17, gen_loss = 0.8325621767294364, disc_loss = 0.07627332867272331
Trained batch 562 in epoch 17, gen_loss = 0.8321778867956164, disc_loss = 0.07628031218421132
Trained batch 563 in epoch 17, gen_loss = 0.8316735575068082, disc_loss = 0.07635120610732929
Trained batch 564 in epoch 17, gen_loss = 0.831921147192474, disc_loss = 0.07624639367470436
Trained batch 565 in epoch 17, gen_loss = 0.8321761111383303, disc_loss = 0.07616012159557256
Trained batch 566 in epoch 17, gen_loss = 0.832332012672273, disc_loss = 0.07613217751651581
Trained batch 567 in epoch 17, gen_loss = 0.8327482598243465, disc_loss = 0.07624404693619204
Trained batch 568 in epoch 17, gen_loss = 0.8326634870995956, disc_loss = 0.07621110862968833
Trained batch 569 in epoch 17, gen_loss = 0.8322262786459504, disc_loss = 0.07643778039011777
Trained batch 570 in epoch 17, gen_loss = 0.8319877539019243, disc_loss = 0.07660182694465757
Trained batch 571 in epoch 17, gen_loss = 0.8320742031181609, disc_loss = 0.07653563658355156
Trained batch 572 in epoch 17, gen_loss = 0.8323746044286259, disc_loss = 0.07663053597760815
Trained batch 573 in epoch 17, gen_loss = 0.8317588341879928, disc_loss = 0.07672419262569696
Trained batch 574 in epoch 17, gen_loss = 0.8313714044508727, disc_loss = 0.07667241810294598
Trained batch 575 in epoch 17, gen_loss = 0.8314081029449072, disc_loss = 0.0766654062818917
Trained batch 576 in epoch 17, gen_loss = 0.8314740903146138, disc_loss = 0.0765746439850697
Trained batch 577 in epoch 17, gen_loss = 0.8317627877409483, disc_loss = 0.07646811176671495
Trained batch 578 in epoch 17, gen_loss = 0.8317088042619109, disc_loss = 0.07638893683082287
Trained batch 579 in epoch 17, gen_loss = 0.8313464949357099, disc_loss = 0.0763735133640725
Trained batch 580 in epoch 17, gen_loss = 0.8314904226390918, disc_loss = 0.07627483006893768
Trained batch 581 in epoch 17, gen_loss = 0.8320278340496149, disc_loss = 0.07619340231008444
Trained batch 582 in epoch 17, gen_loss = 0.8316010141147757, disc_loss = 0.07624375431336732
Trained batch 583 in epoch 17, gen_loss = 0.8312554455885331, disc_loss = 0.07630419806092467
Trained batch 584 in epoch 17, gen_loss = 0.8317962922092177, disc_loss = 0.07628596818281544
Trained batch 585 in epoch 17, gen_loss = 0.8321361318484914, disc_loss = 0.07624397476747276
Trained batch 586 in epoch 17, gen_loss = 0.8320178207282922, disc_loss = 0.07615631604583036
Trained batch 587 in epoch 17, gen_loss = 0.8321300779982489, disc_loss = 0.07618082460763605
Trained batch 588 in epoch 17, gen_loss = 0.8319411513052488, disc_loss = 0.07615211364103193
Trained batch 589 in epoch 17, gen_loss = 0.8313301394551488, disc_loss = 0.07637137935765213
Trained batch 590 in epoch 17, gen_loss = 0.8312533236598807, disc_loss = 0.07632100102121354
Trained batch 591 in epoch 17, gen_loss = 0.831448271266512, disc_loss = 0.07632263178773527
Trained batch 592 in epoch 17, gen_loss = 0.8314009300773904, disc_loss = 0.07627553418969726
Trained batch 593 in epoch 17, gen_loss = 0.831116277059722, disc_loss = 0.07632834440793353
Trained batch 594 in epoch 17, gen_loss = 0.8317263347761972, disc_loss = 0.07637635263136956
Trained batch 595 in epoch 17, gen_loss = 0.8313153199101454, disc_loss = 0.07659133685277712
Trained batch 596 in epoch 17, gen_loss = 0.8311928587542906, disc_loss = 0.07657428777509898
Trained batch 597 in epoch 17, gen_loss = 0.8311686132065828, disc_loss = 0.07658924515293693
Trained batch 598 in epoch 17, gen_loss = 0.8316140197752314, disc_loss = 0.07670887174373975
Trained batch 599 in epoch 17, gen_loss = 0.8315723496675491, disc_loss = 0.07671182116183142
Trained batch 600 in epoch 17, gen_loss = 0.8314359505442336, disc_loss = 0.07668750424762434
Trained batch 601 in epoch 17, gen_loss = 0.8314042795338108, disc_loss = 0.076669776982371
Trained batch 602 in epoch 17, gen_loss = 0.8315778922283432, disc_loss = 0.07659110904765465
Trained batch 603 in epoch 17, gen_loss = 0.8318981947685709, disc_loss = 0.0765580914526043
Trained batch 604 in epoch 17, gen_loss = 0.8313631653785706, disc_loss = 0.07662996904970693
Trained batch 605 in epoch 17, gen_loss = 0.831697816994324, disc_loss = 0.0765558840805302
Trained batch 606 in epoch 17, gen_loss = 0.8314595350127244, disc_loss = 0.07660834516722347
Trained batch 607 in epoch 17, gen_loss = 0.8319517377960054, disc_loss = 0.07662315991106688
Trained batch 608 in epoch 17, gen_loss = 0.8317689270221541, disc_loss = 0.07659253858225588
Trained batch 609 in epoch 17, gen_loss = 0.8314391608120966, disc_loss = 0.07670647463776538
Trained batch 610 in epoch 17, gen_loss = 0.831419215557423, disc_loss = 0.07665090823512519
Trained batch 611 in epoch 17, gen_loss = 0.8310983811133827, disc_loss = 0.07667971416711321
Trained batch 612 in epoch 17, gen_loss = 0.8314884085250718, disc_loss = 0.07662756425946902
Trained batch 613 in epoch 17, gen_loss = 0.8313765614157003, disc_loss = 0.07662071349214557
Trained batch 614 in epoch 17, gen_loss = 0.8313926609551034, disc_loss = 0.07665544842498574
Trained batch 615 in epoch 17, gen_loss = 0.8308830988871587, disc_loss = 0.07689942286180501
Trained batch 616 in epoch 17, gen_loss = 0.8310787051771217, disc_loss = 0.07721554322207476
Trained batch 617 in epoch 17, gen_loss = 0.8313011962040343, disc_loss = 0.07714102925690536
Trained batch 618 in epoch 17, gen_loss = 0.8309965982960962, disc_loss = 0.0773846240554709
Trained batch 619 in epoch 17, gen_loss = 0.8310855831830732, disc_loss = 0.07733430995515758
Trained batch 620 in epoch 17, gen_loss = 0.8314827633556728, disc_loss = 0.07791494985745437
Trained batch 621 in epoch 17, gen_loss = 0.8313692665368414, disc_loss = 0.07788239663520714
Trained batch 622 in epoch 17, gen_loss = 0.8311373047997059, disc_loss = 0.07810374362211836
Trained batch 623 in epoch 17, gen_loss = 0.8311151194457824, disc_loss = 0.07810957998168679
Trained batch 624 in epoch 17, gen_loss = 0.8305848174095154, disc_loss = 0.07828307901322841
Trained batch 625 in epoch 17, gen_loss = 0.8308530909756121, disc_loss = 0.07837944571523907
Trained batch 626 in epoch 17, gen_loss = 0.8307775588887351, disc_loss = 0.07832969322598626
Trained batch 627 in epoch 17, gen_loss = 0.8302730611365312, disc_loss = 0.07853088802272443
Trained batch 628 in epoch 17, gen_loss = 0.8309150427248216, disc_loss = 0.07853077765737788
Trained batch 629 in epoch 17, gen_loss = 0.8312303948970068, disc_loss = 0.07847547663878354
Trained batch 630 in epoch 17, gen_loss = 0.8308083018296872, disc_loss = 0.07863933637017965
Trained batch 631 in epoch 17, gen_loss = 0.8306211743362343, disc_loss = 0.07862658194219103
Trained batch 632 in epoch 17, gen_loss = 0.8307335384272474, disc_loss = 0.07862123045746655
Trained batch 633 in epoch 17, gen_loss = 0.8305029261751505, disc_loss = 0.07860349956899881
Trained batch 634 in epoch 17, gen_loss = 0.830455238612618, disc_loss = 0.0785251392564905
Trained batch 635 in epoch 17, gen_loss = 0.8306353693863131, disc_loss = 0.07856426551446037
Trained batch 636 in epoch 17, gen_loss = 0.8303665699352462, disc_loss = 0.07858284051110456
Trained batch 637 in epoch 17, gen_loss = 0.8300681203884017, disc_loss = 0.07858602738235625
Trained batch 638 in epoch 17, gen_loss = 0.8298468589782715, disc_loss = 0.07852910449130808
Trained batch 639 in epoch 17, gen_loss = 0.8298295678570866, disc_loss = 0.07852057291311212
Trained batch 640 in epoch 17, gen_loss = 0.8299231941168096, disc_loss = 0.0784375069636776
Trained batch 641 in epoch 17, gen_loss = 0.8295779991372724, disc_loss = 0.07842524733533647
Trained batch 642 in epoch 17, gen_loss = 0.8299775008650998, disc_loss = 0.07836974044598373
Trained batch 643 in epoch 17, gen_loss = 0.8303038590813275, disc_loss = 0.07838968678973383
Trained batch 644 in epoch 17, gen_loss = 0.8297955569370773, disc_loss = 0.07862532310649868
Trained batch 645 in epoch 17, gen_loss = 0.8295739424117947, disc_loss = 0.07864170842991433
Trained batch 646 in epoch 17, gen_loss = 0.8293321409033845, disc_loss = 0.07887458230960406
Trained batch 647 in epoch 17, gen_loss = 0.8294201609161165, disc_loss = 0.07889945304630623
Trained batch 648 in epoch 17, gen_loss = 0.8292891176529401, disc_loss = 0.07887703543945068
Trained batch 649 in epoch 17, gen_loss = 0.8290016372387226, disc_loss = 0.07885766458912538
Trained batch 650 in epoch 17, gen_loss = 0.8290910704344648, disc_loss = 0.07881481978418549
Trained batch 651 in epoch 17, gen_loss = 0.829456097509232, disc_loss = 0.07876085531983547
Trained batch 652 in epoch 17, gen_loss = 0.8291336334500159, disc_loss = 0.07872594758628612
Trained batch 653 in epoch 17, gen_loss = 0.8289925397718354, disc_loss = 0.07870765980788783
Trained batch 654 in epoch 17, gen_loss = 0.8290753715820894, disc_loss = 0.07861035472734738
Trained batch 655 in epoch 17, gen_loss = 0.8288696453702159, disc_loss = 0.07858378085500856
Trained batch 656 in epoch 17, gen_loss = 0.8289637211795267, disc_loss = 0.07849078640182995
Trained batch 657 in epoch 17, gen_loss = 0.8292023827602073, disc_loss = 0.07840471988753345
Trained batch 658 in epoch 17, gen_loss = 0.8293260671481015, disc_loss = 0.07834884891786778
Trained batch 659 in epoch 17, gen_loss = 0.8295017388733951, disc_loss = 0.07825122378540761
Trained batch 660 in epoch 17, gen_loss = 0.8289448301478342, disc_loss = 0.07831291405768691
Trained batch 661 in epoch 17, gen_loss = 0.8288574794087885, disc_loss = 0.07825753496245134
Trained batch 662 in epoch 17, gen_loss = 0.829124032731869, disc_loss = 0.07820612804045504
Trained batch 663 in epoch 17, gen_loss = 0.8289879148444498, disc_loss = 0.07817592259204711
Trained batch 664 in epoch 17, gen_loss = 0.8290827271633578, disc_loss = 0.0781799236466562
Trained batch 665 in epoch 17, gen_loss = 0.8286925692995031, disc_loss = 0.07818873893950616
Trained batch 666 in epoch 17, gen_loss = 0.8286927345989348, disc_loss = 0.07823289771643893
Trained batch 667 in epoch 17, gen_loss = 0.8284872520469619, disc_loss = 0.07828835881465745
Trained batch 668 in epoch 17, gen_loss = 0.8285046491565904, disc_loss = 0.07826034347728585
Trained batch 669 in epoch 17, gen_loss = 0.8291719954405258, disc_loss = 0.07828534183773532
Trained batch 670 in epoch 17, gen_loss = 0.829337209152216, disc_loss = 0.07826163467080867
Trained batch 671 in epoch 17, gen_loss = 0.8289271996666988, disc_loss = 0.07831184012216649
Trained batch 672 in epoch 17, gen_loss = 0.828769583847335, disc_loss = 0.0784136810427169
Trained batch 673 in epoch 17, gen_loss = 0.8285502790520383, disc_loss = 0.07836881982444478
Trained batch 674 in epoch 17, gen_loss = 0.8281410966979132, disc_loss = 0.0784119210364642
Trained batch 675 in epoch 17, gen_loss = 0.82811638298472, disc_loss = 0.07840612325156053
Trained batch 676 in epoch 17, gen_loss = 0.8281248247077582, disc_loss = 0.07838626735825835
Trained batch 677 in epoch 17, gen_loss = 0.828454133419864, disc_loss = 0.0782992326239657
Trained batch 678 in epoch 17, gen_loss = 0.8282251193878051, disc_loss = 0.07837848282461665
Trained batch 679 in epoch 17, gen_loss = 0.8283523485064507, disc_loss = 0.07841585079646286
Trained batch 680 in epoch 17, gen_loss = 0.8285339581458754, disc_loss = 0.07833511268558656
Trained batch 681 in epoch 17, gen_loss = 0.8285083961277064, disc_loss = 0.07825273639164712
Trained batch 682 in epoch 17, gen_loss = 0.8283573793108258, disc_loss = 0.0781932864256345
Trained batch 683 in epoch 17, gen_loss = 0.8283399033267596, disc_loss = 0.0781059078300339
Trained batch 684 in epoch 17, gen_loss = 0.828127365564778, disc_loss = 0.07810033989159296
Trained batch 685 in epoch 17, gen_loss = 0.8279725128985702, disc_loss = 0.07811126344003674
Trained batch 686 in epoch 17, gen_loss = 0.8280967545127591, disc_loss = 0.07801587397050996
Trained batch 687 in epoch 17, gen_loss = 0.8284035463665806, disc_loss = 0.07809873153780435
Trained batch 688 in epoch 17, gen_loss = 0.8282378737224031, disc_loss = 0.07804941590902421
Trained batch 689 in epoch 17, gen_loss = 0.8279300619726596, disc_loss = 0.07815264427251574
Trained batch 690 in epoch 17, gen_loss = 0.8278208823521472, disc_loss = 0.07810984827933884
Trained batch 691 in epoch 17, gen_loss = 0.8281813717818673, disc_loss = 0.07820819570236123
Trained batch 692 in epoch 17, gen_loss = 0.8280018537075489, disc_loss = 0.07814533830570625
Trained batch 693 in epoch 17, gen_loss = 0.8280135192170267, disc_loss = 0.07810970995392683
Trained batch 694 in epoch 17, gen_loss = 0.8278013683909135, disc_loss = 0.07807951581885489
Trained batch 695 in epoch 17, gen_loss = 0.8283440982815863, disc_loss = 0.07800838768203881
Trained batch 696 in epoch 17, gen_loss = 0.8286499674385213, disc_loss = 0.07791799164164699
Trained batch 697 in epoch 17, gen_loss = 0.8285010796050971, disc_loss = 0.07789202598604056
Trained batch 698 in epoch 17, gen_loss = 0.8284222664410124, disc_loss = 0.07785255743859493
Trained batch 699 in epoch 17, gen_loss = 0.828487828714507, disc_loss = 0.07776966664940119
Trained batch 700 in epoch 17, gen_loss = 0.8285770792933912, disc_loss = 0.07767870540753241
Trained batch 701 in epoch 17, gen_loss = 0.8285897960859826, disc_loss = 0.07760758273982764
Trained batch 702 in epoch 17, gen_loss = 0.8288064821176814, disc_loss = 0.07751694783054366
Trained batch 703 in epoch 17, gen_loss = 0.8287509985437448, disc_loss = 0.07745105206082702
Trained batch 704 in epoch 17, gen_loss = 0.8288587412090166, disc_loss = 0.0774006598609242
Trained batch 705 in epoch 17, gen_loss = 0.829008626617048, disc_loss = 0.07732763471577855
Trained batch 706 in epoch 17, gen_loss = 0.8291945585604267, disc_loss = 0.07723431383777289
Trained batch 707 in epoch 17, gen_loss = 0.8292495845738104, disc_loss = 0.07717723653804363
Trained batch 708 in epoch 17, gen_loss = 0.8298807594772791, disc_loss = 0.07711585197855202
Trained batch 709 in epoch 17, gen_loss = 0.8299151749678061, disc_loss = 0.0770453606089446
Trained batch 710 in epoch 17, gen_loss = 0.8298732967819342, disc_loss = 0.07696418021969319
Trained batch 711 in epoch 17, gen_loss = 0.829850906234109, disc_loss = 0.07693129267250554
Trained batch 712 in epoch 17, gen_loss = 0.8297260228079465, disc_loss = 0.0769030468650737
Trained batch 713 in epoch 17, gen_loss = 0.8300931970445382, disc_loss = 0.07684497084437299
Trained batch 714 in epoch 17, gen_loss = 0.830149281108296, disc_loss = 0.07674968046481376
Trained batch 715 in epoch 17, gen_loss = 0.830184762371319, disc_loss = 0.07666764459598747
Trained batch 716 in epoch 17, gen_loss = 0.8299870485208689, disc_loss = 0.07661913247776414
Trained batch 717 in epoch 17, gen_loss = 0.8299500466555274, disc_loss = 0.07662489749543099
Trained batch 718 in epoch 17, gen_loss = 0.8299393770757736, disc_loss = 0.07657714666583691
Trained batch 719 in epoch 17, gen_loss = 0.8300026267766952, disc_loss = 0.07650518061644915
Trained batch 720 in epoch 17, gen_loss = 0.8301503508663045, disc_loss = 0.07644772623380162
Trained batch 721 in epoch 17, gen_loss = 0.8300356101296285, disc_loss = 0.07639971808620685
Trained batch 722 in epoch 17, gen_loss = 0.8303449868661239, disc_loss = 0.07634479516181955
Trained batch 723 in epoch 17, gen_loss = 0.8307245096284381, disc_loss = 0.07637277613676961
Trained batch 724 in epoch 17, gen_loss = 0.8302788161409312, disc_loss = 0.07656011375630724
Trained batch 725 in epoch 17, gen_loss = 0.8305624354805171, disc_loss = 0.07648665478232396
Trained batch 726 in epoch 17, gen_loss = 0.8305993974618767, disc_loss = 0.0764463792338537
Trained batch 727 in epoch 17, gen_loss = 0.8310320379806089, disc_loss = 0.07638549449812662
Trained batch 728 in epoch 17, gen_loss = 0.8307320334947321, disc_loss = 0.07642257552139144
Trained batch 729 in epoch 17, gen_loss = 0.8312038210156846, disc_loss = 0.0764216928168723
Trained batch 730 in epoch 17, gen_loss = 0.8310903768206752, disc_loss = 0.07641267935744143
Trained batch 731 in epoch 17, gen_loss = 0.8307788276770076, disc_loss = 0.07641793250314932
Trained batch 732 in epoch 17, gen_loss = 0.8313071930229583, disc_loss = 0.07637081074936247
Trained batch 733 in epoch 17, gen_loss = 0.8311937720964, disc_loss = 0.07636972687559898
Trained batch 734 in epoch 17, gen_loss = 0.8311718389290531, disc_loss = 0.07631370833992553
Trained batch 735 in epoch 17, gen_loss = 0.8307968953867322, disc_loss = 0.07637051668311672
Trained batch 736 in epoch 17, gen_loss = 0.8311596910697958, disc_loss = 0.07631126407336752
Trained batch 737 in epoch 17, gen_loss = 0.8310763163133689, disc_loss = 0.07624326500698399
Trained batch 738 in epoch 17, gen_loss = 0.8311687613533701, disc_loss = 0.0761610729234225
Trained batch 739 in epoch 17, gen_loss = 0.8314383059740067, disc_loss = 0.0760704464014821
Trained batch 740 in epoch 17, gen_loss = 0.8319545626318567, disc_loss = 0.07603617460566212
Trained batch 741 in epoch 17, gen_loss = 0.8314721648182187, disc_loss = 0.07619089873838979
Trained batch 742 in epoch 17, gen_loss = 0.8317615722342423, disc_loss = 0.07613158048146867
Trained batch 743 in epoch 17, gen_loss = 0.8317945817064855, disc_loss = 0.07607385844758321
Trained batch 744 in epoch 17, gen_loss = 0.8318365485476168, disc_loss = 0.0760585500202423
Trained batch 745 in epoch 17, gen_loss = 0.8318432579491157, disc_loss = 0.07604103184981777
Trained batch 746 in epoch 17, gen_loss = 0.8318521492532298, disc_loss = 0.07597757859337562
Trained batch 747 in epoch 17, gen_loss = 0.8316701407977604, disc_loss = 0.07598047613235998
Trained batch 748 in epoch 17, gen_loss = 0.8323493075068389, disc_loss = 0.07613372945354802
Trained batch 749 in epoch 17, gen_loss = 0.8324489103555679, disc_loss = 0.07606360140567024
Trained batch 750 in epoch 17, gen_loss = 0.8324649361335485, disc_loss = 0.07599923567357814
Trained batch 751 in epoch 17, gen_loss = 0.8323868519844527, disc_loss = 0.07592574875440171
Trained batch 752 in epoch 17, gen_loss = 0.8323620569262689, disc_loss = 0.07587678096124811
Trained batch 753 in epoch 17, gen_loss = 0.8327050418135974, disc_loss = 0.07591361824092048
Trained batch 754 in epoch 17, gen_loss = 0.8326268303867997, disc_loss = 0.0758757132851821
Trained batch 755 in epoch 17, gen_loss = 0.8326823729923163, disc_loss = 0.0758523054300221
Trained batch 756 in epoch 17, gen_loss = 0.8327331001645193, disc_loss = 0.07581366472994439
Trained batch 757 in epoch 17, gen_loss = 0.8327602094978015, disc_loss = 0.0758347637732673
Trained batch 758 in epoch 17, gen_loss = 0.8329544035577963, disc_loss = 0.07574995239762214
Trained batch 759 in epoch 17, gen_loss = 0.8328090032072444, disc_loss = 0.07570550989996838
Trained batch 760 in epoch 17, gen_loss = 0.8330104403912473, disc_loss = 0.07562161885622923
Trained batch 761 in epoch 17, gen_loss = 0.8333053682341663, disc_loss = 0.07554047029915209
Trained batch 762 in epoch 17, gen_loss = 0.8333606643804873, disc_loss = 0.0755023323902726
Trained batch 763 in epoch 17, gen_loss = 0.8334369829889992, disc_loss = 0.07544568299281737
Trained batch 764 in epoch 17, gen_loss = 0.8333306428264169, disc_loss = 0.07541384256012688
Trained batch 765 in epoch 17, gen_loss = 0.8334911811522965, disc_loss = 0.0753792243992652
Trained batch 766 in epoch 17, gen_loss = 0.8333907853593416, disc_loss = 0.07537755362126088
Trained batch 767 in epoch 17, gen_loss = 0.8331704009712363, disc_loss = 0.07536532981854786
Trained batch 768 in epoch 17, gen_loss = 0.8333307176402084, disc_loss = 0.07528837358455509
Trained batch 769 in epoch 17, gen_loss = 0.8334052259658838, disc_loss = 0.07522292538219458
Trained batch 770 in epoch 17, gen_loss = 0.8337405000447299, disc_loss = 0.07516705164089123
Trained batch 771 in epoch 17, gen_loss = 0.8340921059559664, disc_loss = 0.07508907288824415
Trained batch 772 in epoch 17, gen_loss = 0.8339362889721045, disc_loss = 0.07506975378566463
Trained batch 773 in epoch 17, gen_loss = 0.8340809925505049, disc_loss = 0.07517119529067469
Trained batch 774 in epoch 17, gen_loss = 0.8337199929068165, disc_loss = 0.0754760352570203
Trained batch 775 in epoch 17, gen_loss = 0.8337619329620268, disc_loss = 0.07546396317565333
Trained batch 776 in epoch 17, gen_loss = 0.8339978745315065, disc_loss = 0.0756840470583781
Trained batch 777 in epoch 17, gen_loss = 0.8338584901051533, disc_loss = 0.07568522592752712
Trained batch 778 in epoch 17, gen_loss = 0.8338207905114998, disc_loss = 0.07566177669257423
Trained batch 779 in epoch 17, gen_loss = 0.8335803229457293, disc_loss = 0.075661151495595
Trained batch 780 in epoch 17, gen_loss = 0.8343567563156465, disc_loss = 0.07595183819809048
Trained batch 781 in epoch 17, gen_loss = 0.834460906627233, disc_loss = 0.0758903371527448
Trained batch 782 in epoch 17, gen_loss = 0.8341703680207142, disc_loss = 0.07601940765558227
Trained batch 783 in epoch 17, gen_loss = 0.8341021723665145, disc_loss = 0.07602475404416267
Trained batch 784 in epoch 17, gen_loss = 0.8337255359075632, disc_loss = 0.0761146425394116
Trained batch 785 in epoch 17, gen_loss = 0.8334869852730336, disc_loss = 0.07611657026444228
Trained batch 786 in epoch 17, gen_loss = 0.8333931987515854, disc_loss = 0.07609811064987201
Trained batch 787 in epoch 17, gen_loss = 0.8335376486636056, disc_loss = 0.07606230333901298
Trained batch 788 in epoch 17, gen_loss = 0.8339718906976122, disc_loss = 0.07602032382603079
Trained batch 789 in epoch 17, gen_loss = 0.833741113996204, disc_loss = 0.07607154395384125
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.638576090335846, disc_loss = 0.10135146975517273
Trained batch 1 in epoch 18, gen_loss = 0.8637734353542328, disc_loss = 0.12749254703521729
Trained batch 2 in epoch 18, gen_loss = 0.8430804212888082, disc_loss = 0.10966816047827403
Trained batch 3 in epoch 18, gen_loss = 0.8286220282316208, disc_loss = 0.09003190696239471
Trained batch 4 in epoch 18, gen_loss = 0.8549056887626648, disc_loss = 0.08447591662406921
Trained batch 5 in epoch 18, gen_loss = 0.8414502441883087, disc_loss = 0.08489907532930374
Trained batch 6 in epoch 18, gen_loss = 0.8343396442277091, disc_loss = 0.07911725076181549
Trained batch 7 in epoch 18, gen_loss = 0.8382675424218178, disc_loss = 0.0711022773757577
Trained batch 8 in epoch 18, gen_loss = 0.8332700861824883, disc_loss = 0.06756884604692459
Trained batch 9 in epoch 18, gen_loss = 0.880090057849884, disc_loss = 0.07196688503026963
Trained batch 10 in epoch 18, gen_loss = 0.8535659529946067, disc_loss = 0.07373320920900865
Trained batch 11 in epoch 18, gen_loss = 0.8553975075483322, disc_loss = 0.06946611171588302
Trained batch 12 in epoch 18, gen_loss = 0.8665049351178683, disc_loss = 0.06666581003138652
Trained batch 13 in epoch 18, gen_loss = 0.8607205961431775, disc_loss = 0.07482870362166848
Trained batch 14 in epoch 18, gen_loss = 0.8617684880892436, disc_loss = 0.07324529228111108
Trained batch 15 in epoch 18, gen_loss = 0.8578159473836422, disc_loss = 0.07146074518095702
Trained batch 16 in epoch 18, gen_loss = 0.8670832514762878, disc_loss = 0.0681253437719801
Trained batch 17 in epoch 18, gen_loss = 0.8796618481477102, disc_loss = 0.06575830151430434
Trained batch 18 in epoch 18, gen_loss = 0.8643678081663031, disc_loss = 0.06750619014430988
Trained batch 19 in epoch 18, gen_loss = 0.8554664462804794, disc_loss = 0.06740566636435688
Trained batch 20 in epoch 18, gen_loss = 0.845806618531545, disc_loss = 0.07259708070861441
Trained batch 21 in epoch 18, gen_loss = 0.8469827527349646, disc_loss = 0.07007181623273274
Trained batch 22 in epoch 18, gen_loss = 0.8441516757011414, disc_loss = 0.06772707139506288
Trained batch 23 in epoch 18, gen_loss = 0.8530998552838961, disc_loss = 0.06598217036419858
Trained batch 24 in epoch 18, gen_loss = 0.8496338057518006, disc_loss = 0.06791064914315939
Trained batch 25 in epoch 18, gen_loss = 0.8422648058487818, disc_loss = 0.07078436529263854
Trained batch 26 in epoch 18, gen_loss = 0.8394071371467026, disc_loss = 0.07059936387533391
Trained batch 27 in epoch 18, gen_loss = 0.8365858750683921, disc_loss = 0.06920923236092287
Trained batch 28 in epoch 18, gen_loss = 0.8507747074653362, disc_loss = 0.07277384808222795
Trained batch 29 in epoch 18, gen_loss = 0.8416066547234853, disc_loss = 0.07204998952026169
Trained batch 30 in epoch 18, gen_loss = 0.835546653116903, disc_loss = 0.07157679355793423
Trained batch 31 in epoch 18, gen_loss = 0.8357586655765772, disc_loss = 0.07114037938299589
Trained batch 32 in epoch 18, gen_loss = 0.8340865391673464, disc_loss = 0.0706417632543228
Trained batch 33 in epoch 18, gen_loss = 0.8330714527298423, disc_loss = 0.06949868598295485
Trained batch 34 in epoch 18, gen_loss = 0.8382329259599958, disc_loss = 0.0680431693526251
Trained batch 35 in epoch 18, gen_loss = 0.8345672355757819, disc_loss = 0.06880869962171549
Trained batch 36 in epoch 18, gen_loss = 0.8282670443122452, disc_loss = 0.07262822016570214
Trained batch 37 in epoch 18, gen_loss = 0.8319497343740965, disc_loss = 0.0766516507995364
Trained batch 38 in epoch 18, gen_loss = 0.8349548624112055, disc_loss = 0.07528996818627302
Trained batch 39 in epoch 18, gen_loss = 0.8360600277781487, disc_loss = 0.07387129173148424
Trained batch 40 in epoch 18, gen_loss = 0.8283976505442363, disc_loss = 0.07494484608220618
Trained batch 41 in epoch 18, gen_loss = 0.8316419266519093, disc_loss = 0.07942860992625356
Trained batch 42 in epoch 18, gen_loss = 0.8290489967479262, disc_loss = 0.07913493566474943
Trained batch 43 in epoch 18, gen_loss = 0.8285514360124414, disc_loss = 0.07862207490358163
Trained batch 44 in epoch 18, gen_loss = 0.826925641960568, disc_loss = 0.07865108046680688
Trained batch 45 in epoch 18, gen_loss = 0.8244594542876534, disc_loss = 0.07789210224038233
Trained batch 46 in epoch 18, gen_loss = 0.8232819197025705, disc_loss = 0.07744635810005537
Trained batch 47 in epoch 18, gen_loss = 0.8313085958361626, disc_loss = 0.07702790901142482
Trained batch 48 in epoch 18, gen_loss = 0.8256352920921481, disc_loss = 0.07750313822180033
Trained batch 49 in epoch 18, gen_loss = 0.8267709803581238, disc_loss = 0.07626576172187924
Trained batch 50 in epoch 18, gen_loss = 0.8260273208805159, disc_loss = 0.07617363583880897
Trained batch 51 in epoch 18, gen_loss = 0.8278403889674407, disc_loss = 0.07541544078132854
Trained batch 52 in epoch 18, gen_loss = 0.8255693721321394, disc_loss = 0.07675412242775256
Trained batch 53 in epoch 18, gen_loss = 0.8263867552633639, disc_loss = 0.07591602787444438
Trained batch 54 in epoch 18, gen_loss = 0.8298207835717635, disc_loss = 0.0747904643077742
Trained batch 55 in epoch 18, gen_loss = 0.8345110937952995, disc_loss = 0.07426673689457987
Trained batch 56 in epoch 18, gen_loss = 0.8284722775743719, disc_loss = 0.07583903361177236
Trained batch 57 in epoch 18, gen_loss = 0.8316893495362381, disc_loss = 0.07494559200030976
Trained batch 58 in epoch 18, gen_loss = 0.8296616582547204, disc_loss = 0.0747429186446687
Trained batch 59 in epoch 18, gen_loss = 0.8312874486049017, disc_loss = 0.07503063104425868
Trained batch 60 in epoch 18, gen_loss = 0.8305996490306542, disc_loss = 0.0745933195423396
Trained batch 61 in epoch 18, gen_loss = 0.824399023286758, disc_loss = 0.07619036376596458
Trained batch 62 in epoch 18, gen_loss = 0.8220097186073424, disc_loss = 0.07555736894054073
Trained batch 63 in epoch 18, gen_loss = 0.8333652317523956, disc_loss = 0.0785276515816804
Trained batch 64 in epoch 18, gen_loss = 0.8307031338031475, disc_loss = 0.07825891349751216
Trained batch 65 in epoch 18, gen_loss = 0.8289810075904384, disc_loss = 0.07770808393869436
Trained batch 66 in epoch 18, gen_loss = 0.8257030586698162, disc_loss = 0.07780958258949999
Trained batch 67 in epoch 18, gen_loss = 0.8260413592352587, disc_loss = 0.07718069092644488
Trained batch 68 in epoch 18, gen_loss = 0.8232322818991067, disc_loss = 0.0773215059298968
Trained batch 69 in epoch 18, gen_loss = 0.826293363741466, disc_loss = 0.07875677291303873
Trained batch 70 in epoch 18, gen_loss = 0.8242470059596317, disc_loss = 0.07799544670737125
Trained batch 71 in epoch 18, gen_loss = 0.8232890135712094, disc_loss = 0.07761589699010882
Trained batch 72 in epoch 18, gen_loss = 0.8235740416670498, disc_loss = 0.07677017973914538
Trained batch 73 in epoch 18, gen_loss = 0.826321094422727, disc_loss = 0.07724471183846125
Trained batch 74 in epoch 18, gen_loss = 0.8227466487884522, disc_loss = 0.07823237851262092
Trained batch 75 in epoch 18, gen_loss = 0.8248332566336581, disc_loss = 0.07804873570995896
Trained batch 76 in epoch 18, gen_loss = 0.8249539678747003, disc_loss = 0.07761619656116932
Trained batch 77 in epoch 18, gen_loss = 0.8247793118158976, disc_loss = 0.07716003194069251
Trained batch 78 in epoch 18, gen_loss = 0.8242303389537183, disc_loss = 0.0783004655113703
Trained batch 79 in epoch 18, gen_loss = 0.8200482450425625, disc_loss = 0.07949763201177121
Trained batch 80 in epoch 18, gen_loss = 0.8216461347944942, disc_loss = 0.07895621726358379
Trained batch 81 in epoch 18, gen_loss = 0.8222518948520102, disc_loss = 0.0783413235643288
Trained batch 82 in epoch 18, gen_loss = 0.8209316357072577, disc_loss = 0.07843874668680041
Trained batch 83 in epoch 18, gen_loss = 0.8210083373955318, disc_loss = 0.07894489466257039
Trained batch 84 in epoch 18, gen_loss = 0.821905456571018, disc_loss = 0.07867598432828399
Trained batch 85 in epoch 18, gen_loss = 0.8238951667796733, disc_loss = 0.07788741221478165
Trained batch 86 in epoch 18, gen_loss = 0.8204135141153445, disc_loss = 0.07860018326847375
Trained batch 87 in epoch 18, gen_loss = 0.8207513805140149, disc_loss = 0.07858086357274177
Trained batch 88 in epoch 18, gen_loss = 0.8254105221019702, disc_loss = 0.0782692569381233
Trained batch 89 in epoch 18, gen_loss = 0.8240137570434146, disc_loss = 0.07820774586871267
Trained batch 90 in epoch 18, gen_loss = 0.8241981556127359, disc_loss = 0.07766290161513038
Trained batch 91 in epoch 18, gen_loss = 0.8300927061101665, disc_loss = 0.07764782178539621
Trained batch 92 in epoch 18, gen_loss = 0.8286941500120265, disc_loss = 0.07761369498386499
Trained batch 93 in epoch 18, gen_loss = 0.8277505052850601, disc_loss = 0.07764068750189022
Trained batch 94 in epoch 18, gen_loss = 0.8261516765544289, disc_loss = 0.07751803136381664
Trained batch 95 in epoch 18, gen_loss = 0.8293586391955614, disc_loss = 0.07751830493604454
Trained batch 96 in epoch 18, gen_loss = 0.8299970264287339, disc_loss = 0.07693114891149026
Trained batch 97 in epoch 18, gen_loss = 0.828185322941566, disc_loss = 0.07740690292106295
Trained batch 98 in epoch 18, gen_loss = 0.8297004525107566, disc_loss = 0.0769132569037152
Trained batch 99 in epoch 18, gen_loss = 0.8300821280479431, disc_loss = 0.0765660862531513
Trained batch 100 in epoch 18, gen_loss = 0.8299250449284469, disc_loss = 0.07658071055233774
Trained batch 101 in epoch 18, gen_loss = 0.8314830345266006, disc_loss = 0.07785391565594896
Trained batch 102 in epoch 18, gen_loss = 0.831950554569948, disc_loss = 0.07721707967191356
Trained batch 103 in epoch 18, gen_loss = 0.8312579914927483, disc_loss = 0.07690990652638273
Trained batch 104 in epoch 18, gen_loss = 0.8325921399252755, disc_loss = 0.07644222931315502
Trained batch 105 in epoch 18, gen_loss = 0.8312622409946514, disc_loss = 0.07711242040056947
Trained batch 106 in epoch 18, gen_loss = 0.8297009028006936, disc_loss = 0.07726683995956293
Trained batch 107 in epoch 18, gen_loss = 0.8286176638470756, disc_loss = 0.07792033095568142
Trained batch 108 in epoch 18, gen_loss = 0.829155704297057, disc_loss = 0.07867195292316172
Trained batch 109 in epoch 18, gen_loss = 0.8281355597756126, disc_loss = 0.07886402910913934
Trained batch 110 in epoch 18, gen_loss = 0.8264788829528533, disc_loss = 0.07902903189496682
Trained batch 111 in epoch 18, gen_loss = 0.8277596682310104, disc_loss = 0.07863996689307637
Trained batch 112 in epoch 18, gen_loss = 0.8281727596721818, disc_loss = 0.07822451001214506
Trained batch 113 in epoch 18, gen_loss = 0.8275716168838635, disc_loss = 0.0779117509118167
Trained batch 114 in epoch 18, gen_loss = 0.825383882937224, disc_loss = 0.07799432996012594
Trained batch 115 in epoch 18, gen_loss = 0.8235473828069095, disc_loss = 0.07809818882077675
Trained batch 116 in epoch 18, gen_loss = 0.8257179260253906, disc_loss = 0.07920576605754785
Trained batch 117 in epoch 18, gen_loss = 0.8255901205337653, disc_loss = 0.07939059204437722
Trained batch 118 in epoch 18, gen_loss = 0.8226293423095671, disc_loss = 0.08043815125906918
Trained batch 119 in epoch 18, gen_loss = 0.8233865695695083, disc_loss = 0.08026345492495844
Trained batch 120 in epoch 18, gen_loss = 0.8224413638765161, disc_loss = 0.08044604109677155
Trained batch 121 in epoch 18, gen_loss = 0.822279080748558, disc_loss = 0.08009983573994431
Trained batch 122 in epoch 18, gen_loss = 0.8215182639234434, disc_loss = 0.0800221143138966
Trained batch 123 in epoch 18, gen_loss = 0.8244729876037566, disc_loss = 0.07974623749783684
Trained batch 124 in epoch 18, gen_loss = 0.8219134166240692, disc_loss = 0.08087857656925916
Trained batch 125 in epoch 18, gen_loss = 0.8232632007390733, disc_loss = 0.08057272930200847
Trained batch 126 in epoch 18, gen_loss = 0.8236712182131339, disc_loss = 0.08037935472350186
Trained batch 127 in epoch 18, gen_loss = 0.8251059867907315, disc_loss = 0.08043152046593605
Trained batch 128 in epoch 18, gen_loss = 0.8234216027943663, disc_loss = 0.08100338880145966
Trained batch 129 in epoch 18, gen_loss = 0.8215136021375656, disc_loss = 0.0815749875556391
Trained batch 130 in epoch 18, gen_loss = 0.8205717868022336, disc_loss = 0.08173984510269557
Trained batch 131 in epoch 18, gen_loss = 0.8216125777725017, disc_loss = 0.08163989001574616
Trained batch 132 in epoch 18, gen_loss = 0.8211686855420134, disc_loss = 0.08125374461279104
Trained batch 133 in epoch 18, gen_loss = 0.8197133147449636, disc_loss = 0.08136932552555826
Trained batch 134 in epoch 18, gen_loss = 0.8232184814082252, disc_loss = 0.08105037163391157
Trained batch 135 in epoch 18, gen_loss = 0.8231520282433313, disc_loss = 0.08067867520730942
Trained batch 136 in epoch 18, gen_loss = 0.8226924810531365, disc_loss = 0.0804192154552706
Trained batch 137 in epoch 18, gen_loss = 0.8222078804088675, disc_loss = 0.08051367097979654
Trained batch 138 in epoch 18, gen_loss = 0.8217200441754979, disc_loss = 0.08019057939351677
Trained batch 139 in epoch 18, gen_loss = 0.8232425857867514, disc_loss = 0.07969248074639057
Trained batch 140 in epoch 18, gen_loss = 0.8237163058832182, disc_loss = 0.07970026091190306
Trained batch 141 in epoch 18, gen_loss = 0.8240044463268468, disc_loss = 0.07939795512889683
Trained batch 142 in epoch 18, gen_loss = 0.8247185676664739, disc_loss = 0.07893027718198466
Trained batch 143 in epoch 18, gen_loss = 0.8228462261872159, disc_loss = 0.07925728655471984
Trained batch 144 in epoch 18, gen_loss = 0.8237526496936535, disc_loss = 0.07905149522783428
Trained batch 145 in epoch 18, gen_loss = 0.8235086388375661, disc_loss = 0.08007713929073859
Trained batch 146 in epoch 18, gen_loss = 0.8218894911055662, disc_loss = 0.08030522727489876
Trained batch 147 in epoch 18, gen_loss = 0.8223031261885488, disc_loss = 0.07984065010237533
Trained batch 148 in epoch 18, gen_loss = 0.821673931491455, disc_loss = 0.07985626198601403
Trained batch 149 in epoch 18, gen_loss = 0.8215651454528173, disc_loss = 0.0795173479616642
Trained batch 150 in epoch 18, gen_loss = 0.8208980641222947, disc_loss = 0.07943834270665187
Trained batch 151 in epoch 18, gen_loss = 0.8193687186821511, disc_loss = 0.07968144270738489
Trained batch 152 in epoch 18, gen_loss = 0.8193796703628465, disc_loss = 0.07925427001992277
Trained batch 153 in epoch 18, gen_loss = 0.8210428359059544, disc_loss = 0.0790174290017745
Trained batch 154 in epoch 18, gen_loss = 0.8217817623769084, disc_loss = 0.07858834934811439
Trained batch 155 in epoch 18, gen_loss = 0.8216979604883071, disc_loss = 0.07821576585037968
Trained batch 156 in epoch 18, gen_loss = 0.8216568643500091, disc_loss = 0.07793449633013291
Trained batch 157 in epoch 18, gen_loss = 0.8206985036406336, disc_loss = 0.07765017012487861
Trained batch 158 in epoch 18, gen_loss = 0.8207129459336119, disc_loss = 0.07809972431534117
Trained batch 159 in epoch 18, gen_loss = 0.8206797705963254, disc_loss = 0.07783423658693209
Trained batch 160 in epoch 18, gen_loss = 0.8202764238259808, disc_loss = 0.07766523211037521
Trained batch 161 in epoch 18, gen_loss = 0.8209852736305308, disc_loss = 0.0774724926730549
Trained batch 162 in epoch 18, gen_loss = 0.8214845531191562, disc_loss = 0.07708830262414335
Trained batch 163 in epoch 18, gen_loss = 0.8213199266209835, disc_loss = 0.07684774528166688
Trained batch 164 in epoch 18, gen_loss = 0.820908018133857, disc_loss = 0.0766594295192397
Trained batch 165 in epoch 18, gen_loss = 0.8229800173676157, disc_loss = 0.07706519880006651
Trained batch 166 in epoch 18, gen_loss = 0.822532453758274, disc_loss = 0.07698138695611746
Trained batch 167 in epoch 18, gen_loss = 0.8237458905648618, disc_loss = 0.07660239734797783
Trained batch 168 in epoch 18, gen_loss = 0.8247626855881256, disc_loss = 0.0762887722454392
Trained batch 169 in epoch 18, gen_loss = 0.8242532668744816, disc_loss = 0.07599892372484593
Trained batch 170 in epoch 18, gen_loss = 0.8251234193642935, disc_loss = 0.07619303096172927
Trained batch 171 in epoch 18, gen_loss = 0.8238272519652233, disc_loss = 0.07641705083877368
Trained batch 172 in epoch 18, gen_loss = 0.8225636184215546, disc_loss = 0.07649531341938443
Trained batch 173 in epoch 18, gen_loss = 0.8247501896373157, disc_loss = 0.07672205830164168
Trained batch 174 in epoch 18, gen_loss = 0.8252195598397936, disc_loss = 0.076337681678789
Trained batch 175 in epoch 18, gen_loss = 0.8248169193552299, disc_loss = 0.0764646072215824
Trained batch 176 in epoch 18, gen_loss = 0.8266398362857473, disc_loss = 0.07701806977685899
Trained batch 177 in epoch 18, gen_loss = 0.826186891184764, disc_loss = 0.07701254390138254
Trained batch 178 in epoch 18, gen_loss = 0.8258465919747698, disc_loss = 0.07701056222717523
Trained batch 179 in epoch 18, gen_loss = 0.8276233048902617, disc_loss = 0.07695814293498794
Trained batch 180 in epoch 18, gen_loss = 0.8265110907962968, disc_loss = 0.07702276177539681
Trained batch 181 in epoch 18, gen_loss = 0.8252490734333521, disc_loss = 0.07709137330875619
Trained batch 182 in epoch 18, gen_loss = 0.8282990112005035, disc_loss = 0.07828873743002858
Trained batch 183 in epoch 18, gen_loss = 0.8284850225824377, disc_loss = 0.07803316204808652
Trained batch 184 in epoch 18, gen_loss = 0.8275059621076326, disc_loss = 0.07797044331358896
Trained batch 185 in epoch 18, gen_loss = 0.8270132703486309, disc_loss = 0.0779289737924613
Trained batch 186 in epoch 18, gen_loss = 0.8268514353642489, disc_loss = 0.07782140681968334
Trained batch 187 in epoch 18, gen_loss = 0.8263715668878657, disc_loss = 0.07777804061968593
Trained batch 188 in epoch 18, gen_loss = 0.8264651129800806, disc_loss = 0.07889186252874357
Trained batch 189 in epoch 18, gen_loss = 0.8260713789023851, disc_loss = 0.07859240244877966
Trained batch 190 in epoch 18, gen_loss = 0.8259397618745634, disc_loss = 0.07842113740781215
Trained batch 191 in epoch 18, gen_loss = 0.8269530005442599, disc_loss = 0.07885256363078952
Trained batch 192 in epoch 18, gen_loss = 0.8268380663864353, disc_loss = 0.07859857147800799
Trained batch 193 in epoch 18, gen_loss = 0.826825780813227, disc_loss = 0.07845597352218076
Trained batch 194 in epoch 18, gen_loss = 0.8270415255656609, disc_loss = 0.07833849324438817
Trained batch 195 in epoch 18, gen_loss = 0.8276038545430923, disc_loss = 0.07800160604529083
Trained batch 196 in epoch 18, gen_loss = 0.8279698680197527, disc_loss = 0.07783192921392053
Trained batch 197 in epoch 18, gen_loss = 0.8273908214436637, disc_loss = 0.07769286470261938
Trained batch 198 in epoch 18, gen_loss = 0.8280031772414643, disc_loss = 0.07736457659671055
Trained batch 199 in epoch 18, gen_loss = 0.8284286166727542, disc_loss = 0.0773328810185194
Trained batch 200 in epoch 18, gen_loss = 0.8275266928755822, disc_loss = 0.07731901153699676
Trained batch 201 in epoch 18, gen_loss = 0.8275918805658227, disc_loss = 0.0780098890461544
Trained batch 202 in epoch 18, gen_loss = 0.8273193106569093, disc_loss = 0.07786557900494542
Trained batch 203 in epoch 18, gen_loss = 0.8265719365547685, disc_loss = 0.07795286240677039
Trained batch 204 in epoch 18, gen_loss = 0.8273776160507668, disc_loss = 0.07793976337444491
Trained batch 205 in epoch 18, gen_loss = 0.8276753259225956, disc_loss = 0.07772740884457977
Trained batch 206 in epoch 18, gen_loss = 0.8284372124407027, disc_loss = 0.07741752088717792
Trained batch 207 in epoch 18, gen_loss = 0.8286399965962539, disc_loss = 0.0771445145812602
Trained batch 208 in epoch 18, gen_loss = 0.8293142542599491, disc_loss = 0.07722733176032608
Trained batch 209 in epoch 18, gen_loss = 0.827781235745975, disc_loss = 0.0774084500879759
Trained batch 210 in epoch 18, gen_loss = 0.8280952229601513, disc_loss = 0.0772205988713209
Trained batch 211 in epoch 18, gen_loss = 0.827393946079713, disc_loss = 0.0771504991933844
Trained batch 212 in epoch 18, gen_loss = 0.8275022958645798, disc_loss = 0.07733185843787563
Trained batch 213 in epoch 18, gen_loss = 0.827547240340821, disc_loss = 0.07729065796865203
Trained batch 214 in epoch 18, gen_loss = 0.8275609730288039, disc_loss = 0.07701352726408216
Trained batch 215 in epoch 18, gen_loss = 0.8286162100180432, disc_loss = 0.07703753025270998
Trained batch 216 in epoch 18, gen_loss = 0.8273414696141872, disc_loss = 0.07704094384500783
Trained batch 217 in epoch 18, gen_loss = 0.8268989416163995, disc_loss = 0.07681461963631692
Trained batch 218 in epoch 18, gen_loss = 0.8281072202610643, disc_loss = 0.07653458558924531
Trained batch 219 in epoch 18, gen_loss = 0.8278441349213773, disc_loss = 0.07641558606092903
Trained batch 220 in epoch 18, gen_loss = 0.8279970694181606, disc_loss = 0.07613419942406104
Trained batch 221 in epoch 18, gen_loss = 0.8286186141205264, disc_loss = 0.075958923113675
Trained batch 222 in epoch 18, gen_loss = 0.828111503289954, disc_loss = 0.07607318354444786
Trained batch 223 in epoch 18, gen_loss = 0.8287764701193997, disc_loss = 0.07582090026283238
Trained batch 224 in epoch 18, gen_loss = 0.8291363200876448, disc_loss = 0.07585657722006242
Trained batch 225 in epoch 18, gen_loss = 0.8311887197526155, disc_loss = 0.07572456099406148
Trained batch 226 in epoch 18, gen_loss = 0.8319111927227827, disc_loss = 0.07544593078531489
Trained batch 227 in epoch 18, gen_loss = 0.830669693910239, disc_loss = 0.07652935691651676
Trained batch 228 in epoch 18, gen_loss = 0.8311593164262814, disc_loss = 0.07642519671274715
Trained batch 229 in epoch 18, gen_loss = 0.8313872602970703, disc_loss = 0.07643977894812175
Trained batch 230 in epoch 18, gen_loss = 0.8315287184663666, disc_loss = 0.0762341713806961
Trained batch 231 in epoch 18, gen_loss = 0.8328163861457644, disc_loss = 0.0760863375777764
Trained batch 232 in epoch 18, gen_loss = 0.8337030846929345, disc_loss = 0.07589923236678982
Trained batch 233 in epoch 18, gen_loss = 0.8323487003899028, disc_loss = 0.07608690120391229
Trained batch 234 in epoch 18, gen_loss = 0.8325190553005706, disc_loss = 0.07591223058469118
Trained batch 235 in epoch 18, gen_loss = 0.8316858480289832, disc_loss = 0.07602777882573843
Trained batch 236 in epoch 18, gen_loss = 0.8323133418077155, disc_loss = 0.07620723222928585
Trained batch 237 in epoch 18, gen_loss = 0.8329120156895212, disc_loss = 0.07626795672866352
Trained batch 238 in epoch 18, gen_loss = 0.8323620820893404, disc_loss = 0.07618639232770046
Trained batch 239 in epoch 18, gen_loss = 0.8324091559896867, disc_loss = 0.07605026610738909
Trained batch 240 in epoch 18, gen_loss = 0.8318603148846211, disc_loss = 0.07592435727954776
Trained batch 241 in epoch 18, gen_loss = 0.8315661309425496, disc_loss = 0.07588997298143496
Trained batch 242 in epoch 18, gen_loss = 0.8329282691204009, disc_loss = 0.07661870967811395
Trained batch 243 in epoch 18, gen_loss = 0.8320620647463642, disc_loss = 0.07670079388075554
Trained batch 244 in epoch 18, gen_loss = 0.8315244425316246, disc_loss = 0.07653740940577522
Trained batch 245 in epoch 18, gen_loss = 0.8314483586123319, disc_loss = 0.07639603849454987
Trained batch 246 in epoch 18, gen_loss = 0.8332146868290689, disc_loss = 0.07650501693896798
Trained batch 247 in epoch 18, gen_loss = 0.8331257235859671, disc_loss = 0.07638262557391558
Trained batch 248 in epoch 18, gen_loss = 0.833414938196121, disc_loss = 0.07619411319898195
Trained batch 249 in epoch 18, gen_loss = 0.8332247439622879, disc_loss = 0.07607808547839523
Trained batch 250 in epoch 18, gen_loss = 0.8332695306772255, disc_loss = 0.07596557895723448
Trained batch 251 in epoch 18, gen_loss = 0.8330361536807485, disc_loss = 0.07595529191062919
Trained batch 252 in epoch 18, gen_loss = 0.8326046823748486, disc_loss = 0.0758744449034451
Trained batch 253 in epoch 18, gen_loss = 0.8337971947089894, disc_loss = 0.07581307877984456
Trained batch 254 in epoch 18, gen_loss = 0.8327693133961921, disc_loss = 0.07591909811119824
Trained batch 255 in epoch 18, gen_loss = 0.8327602635836229, disc_loss = 0.07566590288115549
Trained batch 256 in epoch 18, gen_loss = 0.8329536234126481, disc_loss = 0.07605282302424021
Trained batch 257 in epoch 18, gen_loss = 0.8332284343566081, disc_loss = 0.07584236543120225
Trained batch 258 in epoch 18, gen_loss = 0.8321940858621855, disc_loss = 0.07590212754574406
Trained batch 259 in epoch 18, gen_loss = 0.8318492464148082, disc_loss = 0.07584104874314597
Trained batch 260 in epoch 18, gen_loss = 0.8317231653522258, disc_loss = 0.07561703279999824
Trained batch 261 in epoch 18, gen_loss = 0.8321028289221625, disc_loss = 0.07568903932461643
Trained batch 262 in epoch 18, gen_loss = 0.8326031795699333, disc_loss = 0.07543143709703656
Trained batch 263 in epoch 18, gen_loss = 0.8333494939813109, disc_loss = 0.07520382764579897
Trained batch 264 in epoch 18, gen_loss = 0.8330260869467033, disc_loss = 0.07521575074291455
Trained batch 265 in epoch 18, gen_loss = 0.8335793882160258, disc_loss = 0.0750124735995791
Trained batch 266 in epoch 18, gen_loss = 0.8329662469665656, disc_loss = 0.07490587226125632
Trained batch 267 in epoch 18, gen_loss = 0.8346473166524474, disc_loss = 0.07519189877185359
Trained batch 268 in epoch 18, gen_loss = 0.8341939581149572, disc_loss = 0.0752415167631713
Trained batch 269 in epoch 18, gen_loss = 0.8352602008316252, disc_loss = 0.07506754998531606
Trained batch 270 in epoch 18, gen_loss = 0.8362422459019946, disc_loss = 0.07500689794271634
Trained batch 271 in epoch 18, gen_loss = 0.8354322703226524, disc_loss = 0.07533227686551125
Trained batch 272 in epoch 18, gen_loss = 0.8351100706137143, disc_loss = 0.07549817053662551
Trained batch 273 in epoch 18, gen_loss = 0.8346777498504542, disc_loss = 0.07541108807127406
Trained batch 274 in epoch 18, gen_loss = 0.8351014903458682, disc_loss = 0.07532384922558612
Trained batch 275 in epoch 18, gen_loss = 0.8360518332624781, disc_loss = 0.07534117863068114
Trained batch 276 in epoch 18, gen_loss = 0.8349811440125269, disc_loss = 0.0756079327140259
Trained batch 277 in epoch 18, gen_loss = 0.8347236114225799, disc_loss = 0.07549056689516245
Trained batch 278 in epoch 18, gen_loss = 0.8352680162503301, disc_loss = 0.07572766006206526
Trained batch 279 in epoch 18, gen_loss = 0.8347740840698992, disc_loss = 0.07567551214514034
Trained batch 280 in epoch 18, gen_loss = 0.8346417627937005, disc_loss = 0.0754598168709259
Trained batch 281 in epoch 18, gen_loss = 0.8356589458301558, disc_loss = 0.07539469208105976
Trained batch 282 in epoch 18, gen_loss = 0.8360216873484029, disc_loss = 0.07528011711123449
Trained batch 283 in epoch 18, gen_loss = 0.8357558320735542, disc_loss = 0.07515147440856926
Trained batch 284 in epoch 18, gen_loss = 0.8357710828906612, disc_loss = 0.07493926711837974
Trained batch 285 in epoch 18, gen_loss = 0.8354686195408547, disc_loss = 0.07479434938762676
Trained batch 286 in epoch 18, gen_loss = 0.8354620938724757, disc_loss = 0.07460379404849811
Trained batch 287 in epoch 18, gen_loss = 0.8372451655773653, disc_loss = 0.07485825052653025
Trained batch 288 in epoch 18, gen_loss = 0.8378257084264062, disc_loss = 0.07474992219616489
Trained batch 289 in epoch 18, gen_loss = 0.837424075911785, disc_loss = 0.07489907355208335
Trained batch 290 in epoch 18, gen_loss = 0.837116678453393, disc_loss = 0.0748479273650296
Trained batch 291 in epoch 18, gen_loss = 0.8375175884121084, disc_loss = 0.07475931931299808
Trained batch 292 in epoch 18, gen_loss = 0.8372660849891832, disc_loss = 0.07457471470135572
Trained batch 293 in epoch 18, gen_loss = 0.8383370267898858, disc_loss = 0.0745329253635287
Trained batch 294 in epoch 18, gen_loss = 0.8375253999637345, disc_loss = 0.07469039454866769
Trained batch 295 in epoch 18, gen_loss = 0.8369190238818929, disc_loss = 0.07489887898397707
Trained batch 296 in epoch 18, gen_loss = 0.8366039209694974, disc_loss = 0.07471215716478499
Trained batch 297 in epoch 18, gen_loss = 0.8368644251319386, disc_loss = 0.07454216212421756
Trained batch 298 in epoch 18, gen_loss = 0.8375310336666363, disc_loss = 0.07457330655680353
Trained batch 299 in epoch 18, gen_loss = 0.836933644314607, disc_loss = 0.07452943779217701
Trained batch 300 in epoch 18, gen_loss = 0.8362302905895386, disc_loss = 0.07453143977532256
Trained batch 301 in epoch 18, gen_loss = 0.8362873045616592, disc_loss = 0.07448545661724068
Trained batch 302 in epoch 18, gen_loss = 0.8367365271148115, disc_loss = 0.07432931693264655
Trained batch 303 in epoch 18, gen_loss = 0.8363316138520053, disc_loss = 0.07419787827376767
Trained batch 304 in epoch 18, gen_loss = 0.8363597837627911, disc_loss = 0.07399641865039946
Trained batch 305 in epoch 18, gen_loss = 0.8371408327537424, disc_loss = 0.07379695781950954
Trained batch 306 in epoch 18, gen_loss = 0.8365969878260399, disc_loss = 0.0737679949370046
Trained batch 307 in epoch 18, gen_loss = 0.83806046137175, disc_loss = 0.07367116344983798
Trained batch 308 in epoch 18, gen_loss = 0.8374516962994264, disc_loss = 0.0736429442871591
Trained batch 309 in epoch 18, gen_loss = 0.8380614072084427, disc_loss = 0.07344407049578525
Trained batch 310 in epoch 18, gen_loss = 0.8380398367953837, disc_loss = 0.07330208213347043
Trained batch 311 in epoch 18, gen_loss = 0.8376677532035571, disc_loss = 0.07324756568787286
Trained batch 312 in epoch 18, gen_loss = 0.8377488138386235, disc_loss = 0.07330692144402395
Trained batch 313 in epoch 18, gen_loss = 0.8380472336415272, disc_loss = 0.07316182909984213
Trained batch 314 in epoch 18, gen_loss = 0.8374262814483945, disc_loss = 0.07313362296434149
Trained batch 315 in epoch 18, gen_loss = 0.8371124057264268, disc_loss = 0.07305580682026906
Trained batch 316 in epoch 18, gen_loss = 0.8370470580430437, disc_loss = 0.07301928970539702
Trained batch 317 in epoch 18, gen_loss = 0.8369731334207943, disc_loss = 0.07284757149634215
Trained batch 318 in epoch 18, gen_loss = 0.8369371710713007, disc_loss = 0.07277689874464162
Trained batch 319 in epoch 18, gen_loss = 0.8366622188128531, disc_loss = 0.07269484885327984
Trained batch 320 in epoch 18, gen_loss = 0.8364399769038797, disc_loss = 0.07267898892420939
Trained batch 321 in epoch 18, gen_loss = 0.836808322286754, disc_loss = 0.07279700175309496
Trained batch 322 in epoch 18, gen_loss = 0.836703415717872, disc_loss = 0.07269732107699563
Trained batch 323 in epoch 18, gen_loss = 0.8368310482229715, disc_loss = 0.072600323997185
Trained batch 324 in epoch 18, gen_loss = 0.8365030089708475, disc_loss = 0.07261109298524948
Trained batch 325 in epoch 18, gen_loss = 0.8373470455408096, disc_loss = 0.07273942128429475
Trained batch 326 in epoch 18, gen_loss = 0.8376841934266805, disc_loss = 0.07259181763019858
Trained batch 327 in epoch 18, gen_loss = 0.8369527138406183, disc_loss = 0.07287469180584771
Trained batch 328 in epoch 18, gen_loss = 0.8360633680704517, disc_loss = 0.07318306305816562
Trained batch 329 in epoch 18, gen_loss = 0.8364818106094997, disc_loss = 0.0730397044285906
Trained batch 330 in epoch 18, gen_loss = 0.8368888876409329, disc_loss = 0.073116137927505
Trained batch 331 in epoch 18, gen_loss = 0.8369162268487804, disc_loss = 0.07305677473286998
Trained batch 332 in epoch 18, gen_loss = 0.8362132846951127, disc_loss = 0.07309502627499201
Trained batch 333 in epoch 18, gen_loss = 0.8361989415869742, disc_loss = 0.07306366382880572
Trained batch 334 in epoch 18, gen_loss = 0.8365982981760111, disc_loss = 0.07311252787320027
Trained batch 335 in epoch 18, gen_loss = 0.8360745842080741, disc_loss = 0.07312903360607811
Trained batch 336 in epoch 18, gen_loss = 0.8359399217703222, disc_loss = 0.07313007176287185
Trained batch 337 in epoch 18, gen_loss = 0.8362781028952119, disc_loss = 0.0731915329230299
Trained batch 338 in epoch 18, gen_loss = 0.8366820132662062, disc_loss = 0.07301932162327752
Trained batch 339 in epoch 18, gen_loss = 0.8356292082106366, disc_loss = 0.07363834199221696
Trained batch 340 in epoch 18, gen_loss = 0.8363709025893393, disc_loss = 0.07436237711448473
Trained batch 341 in epoch 18, gen_loss = 0.8364253234967851, disc_loss = 0.0743119114715802
Trained batch 342 in epoch 18, gen_loss = 0.8362590888672597, disc_loss = 0.07431116823986737
Trained batch 343 in epoch 18, gen_loss = 0.8361514076417269, disc_loss = 0.0743202407042994
Trained batch 344 in epoch 18, gen_loss = 0.8350503540557364, disc_loss = 0.07486632079749868
Trained batch 345 in epoch 18, gen_loss = 0.8356279375063891, disc_loss = 0.07524496909080214
Trained batch 346 in epoch 18, gen_loss = 0.8357127402460884, disc_loss = 0.0751653284435657
Trained batch 347 in epoch 18, gen_loss = 0.8356298388934683, disc_loss = 0.07510291825680213
Trained batch 348 in epoch 18, gen_loss = 0.8352457671759805, disc_loss = 0.07505878039707768
Trained batch 349 in epoch 18, gen_loss = 0.8354802248307637, disc_loss = 0.0749041001605136
Trained batch 350 in epoch 18, gen_loss = 0.8359822368519938, disc_loss = 0.0750104452873397
Trained batch 351 in epoch 18, gen_loss = 0.8362027277154002, disc_loss = 0.07489501852118834
Trained batch 352 in epoch 18, gen_loss = 0.8357669938218493, disc_loss = 0.07488912293323377
Trained batch 353 in epoch 18, gen_loss = 0.8360786103764496, disc_loss = 0.07478629759812759
Trained batch 354 in epoch 18, gen_loss = 0.8356465570523706, disc_loss = 0.07469806089787416
Trained batch 355 in epoch 18, gen_loss = 0.835401486228691, disc_loss = 0.07457942827447747
Trained batch 356 in epoch 18, gen_loss = 0.8358112108640644, disc_loss = 0.07449371702656024
Trained batch 357 in epoch 18, gen_loss = 0.8351684613101309, disc_loss = 0.07453628928093604
Trained batch 358 in epoch 18, gen_loss = 0.8351823577143688, disc_loss = 0.07437377421491491
Trained batch 359 in epoch 18, gen_loss = 0.8358087530566587, disc_loss = 0.07424786222788195
Trained batch 360 in epoch 18, gen_loss = 0.8360273427745312, disc_loss = 0.07419075831832814
Trained batch 361 in epoch 18, gen_loss = 0.8359211893206802, disc_loss = 0.07424144533807567
Trained batch 362 in epoch 18, gen_loss = 0.8356276756311579, disc_loss = 0.0742556191519026
Trained batch 363 in epoch 18, gen_loss = 0.8363696820624582, disc_loss = 0.07417015765619638
Trained batch 364 in epoch 18, gen_loss = 0.835804671049118, disc_loss = 0.07438161048068576
Trained batch 365 in epoch 18, gen_loss = 0.8356283925107268, disc_loss = 0.07431107553363335
Trained batch 366 in epoch 18, gen_loss = 0.8369276876832874, disc_loss = 0.0747716842366418
Trained batch 367 in epoch 18, gen_loss = 0.8369193947671548, disc_loss = 0.074632876709549
Trained batch 368 in epoch 18, gen_loss = 0.8365864991980193, disc_loss = 0.07454025289573805
Trained batch 369 in epoch 18, gen_loss = 0.8358926330869262, disc_loss = 0.07455666738285406
Trained batch 370 in epoch 18, gen_loss = 0.8355770720786483, disc_loss = 0.07492175369430584
Trained batch 371 in epoch 18, gen_loss = 0.8353712998570935, disc_loss = 0.07538948344787763
Trained batch 372 in epoch 18, gen_loss = 0.8345093099904763, disc_loss = 0.07558519807182272
Trained batch 373 in epoch 18, gen_loss = 0.8341095969479352, disc_loss = 0.07558832513317865
Trained batch 374 in epoch 18, gen_loss = 0.8345690599282583, disc_loss = 0.07595153022309144
Trained batch 375 in epoch 18, gen_loss = 0.8341041672578517, disc_loss = 0.0760863324320142
Trained batch 376 in epoch 18, gen_loss = 0.8338951390206972, disc_loss = 0.07599699030326437
Trained batch 377 in epoch 18, gen_loss = 0.8339477915454794, disc_loss = 0.07591143139593658
Trained batch 378 in epoch 18, gen_loss = 0.8340228932042235, disc_loss = 0.07606870670726715
Trained batch 379 in epoch 18, gen_loss = 0.8341252939481484, disc_loss = 0.07596901235121646
Trained batch 380 in epoch 18, gen_loss = 0.8339939063458931, disc_loss = 0.07592279649293172
Trained batch 381 in epoch 18, gen_loss = 0.8342028031642524, disc_loss = 0.07576036733862851
Trained batch 382 in epoch 18, gen_loss = 0.8337748392288118, disc_loss = 0.07591980392011198
Trained batch 383 in epoch 18, gen_loss = 0.8336048839458575, disc_loss = 0.07577341628833285
Trained batch 384 in epoch 18, gen_loss = 0.8333289780400016, disc_loss = 0.07569351942072829
Trained batch 385 in epoch 18, gen_loss = 0.8334797805300649, disc_loss = 0.07570508636601771
Trained batch 386 in epoch 18, gen_loss = 0.833006196320827, disc_loss = 0.07575488333814134
Trained batch 387 in epoch 18, gen_loss = 0.8334377135351762, disc_loss = 0.07571941491014794
Trained batch 388 in epoch 18, gen_loss = 0.8328522351070051, disc_loss = 0.07590810521469861
Trained batch 389 in epoch 18, gen_loss = 0.8331411026227169, disc_loss = 0.07577260072844533
Trained batch 390 in epoch 18, gen_loss = 0.8332731305333354, disc_loss = 0.07568609252657808
Trained batch 391 in epoch 18, gen_loss = 0.8332680989132852, disc_loss = 0.07557685162197342
Trained batch 392 in epoch 18, gen_loss = 0.8337174920180371, disc_loss = 0.07550143118018791
Trained batch 393 in epoch 18, gen_loss = 0.8336805428193911, disc_loss = 0.07537169167582834
Trained batch 394 in epoch 18, gen_loss = 0.8334404443638235, disc_loss = 0.0753222025765837
Trained batch 395 in epoch 18, gen_loss = 0.8333604714334614, disc_loss = 0.0752473424748527
Trained batch 396 in epoch 18, gen_loss = 0.8340484728891243, disc_loss = 0.07510999193466655
Trained batch 397 in epoch 18, gen_loss = 0.8346149204813655, disc_loss = 0.07496800863104475
Trained batch 398 in epoch 18, gen_loss = 0.8341812415977469, disc_loss = 0.07502350791644558
Trained batch 399 in epoch 18, gen_loss = 0.8344230467826128, disc_loss = 0.07499503925209865
Trained batch 400 in epoch 18, gen_loss = 0.8340292923022387, disc_loss = 0.07489622861583557
Trained batch 401 in epoch 18, gen_loss = 0.8342277868025338, disc_loss = 0.07474401939326702
Trained batch 402 in epoch 18, gen_loss = 0.8342660373404955, disc_loss = 0.07472070448433348
Trained batch 403 in epoch 18, gen_loss = 0.834544335335198, disc_loss = 0.07472958000339937
Trained batch 404 in epoch 18, gen_loss = 0.8349288028699381, disc_loss = 0.07459963463982683
Trained batch 405 in epoch 18, gen_loss = 0.8356740863011975, disc_loss = 0.07453476105876304
Trained batch 406 in epoch 18, gen_loss = 0.8350865365685644, disc_loss = 0.07465093497287582
Trained batch 407 in epoch 18, gen_loss = 0.8351155160834977, disc_loss = 0.07452805846582587
Trained batch 408 in epoch 18, gen_loss = 0.8352384670002245, disc_loss = 0.07443898887553396
Trained batch 409 in epoch 18, gen_loss = 0.8350751735088302, disc_loss = 0.07434627357870341
Trained batch 410 in epoch 18, gen_loss = 0.8350494846955413, disc_loss = 0.0744807195788535
Trained batch 411 in epoch 18, gen_loss = 0.836180131918597, disc_loss = 0.07458221165969678
Trained batch 412 in epoch 18, gen_loss = 0.835534110990044, disc_loss = 0.07484469988967403
Trained batch 413 in epoch 18, gen_loss = 0.8352797464040167, disc_loss = 0.0747657579905241
Trained batch 414 in epoch 18, gen_loss = 0.8364681732941823, disc_loss = 0.07474789303918201
Trained batch 415 in epoch 18, gen_loss = 0.8358083999930666, disc_loss = 0.07493570680246474
Trained batch 416 in epoch 18, gen_loss = 0.8360119491315289, disc_loss = 0.07493287802403636
Trained batch 417 in epoch 18, gen_loss = 0.836260880793681, disc_loss = 0.07489795541239269
Trained batch 418 in epoch 18, gen_loss = 0.8357585472963874, disc_loss = 0.0749286245910322
Trained batch 419 in epoch 18, gen_loss = 0.8354915832479795, disc_loss = 0.0750458097927982
Trained batch 420 in epoch 18, gen_loss = 0.835180802823812, disc_loss = 0.07515292623989514
Trained batch 421 in epoch 18, gen_loss = 0.8350924521119674, disc_loss = 0.07509292745565492
Trained batch 422 in epoch 18, gen_loss = 0.8354166215615915, disc_loss = 0.07527435279008768
Trained batch 423 in epoch 18, gen_loss = 0.8356003448507696, disc_loss = 0.0752033508988976
Trained batch 424 in epoch 18, gen_loss = 0.8347565238616046, disc_loss = 0.07524774419472498
Trained batch 425 in epoch 18, gen_loss = 0.8344678187594168, disc_loss = 0.07524104249781706
Trained batch 426 in epoch 18, gen_loss = 0.8341628313064575, disc_loss = 0.07524749943310399
Trained batch 427 in epoch 18, gen_loss = 0.8349775669173659, disc_loss = 0.07577456039089327
Trained batch 428 in epoch 18, gen_loss = 0.8346961208712527, disc_loss = 0.0759105156794503
Trained batch 429 in epoch 18, gen_loss = 0.8350673212561497, disc_loss = 0.07590608554783948
Trained batch 430 in epoch 18, gen_loss = 0.8352057203615901, disc_loss = 0.07578100626661578
Trained batch 431 in epoch 18, gen_loss = 0.8344612638983462, disc_loss = 0.07603661191253061
Trained batch 432 in epoch 18, gen_loss = 0.8354472171076451, disc_loss = 0.07636306126436378
Trained batch 433 in epoch 18, gen_loss = 0.8350630679987543, disc_loss = 0.07639857674712822
Trained batch 434 in epoch 18, gen_loss = 0.834885528717918, disc_loss = 0.07630731513531043
Trained batch 435 in epoch 18, gen_loss = 0.8348345819416396, disc_loss = 0.07628921276266011
Trained batch 436 in epoch 18, gen_loss = 0.834926184036639, disc_loss = 0.07619037429292769
Trained batch 437 in epoch 18, gen_loss = 0.8344722722219006, disc_loss = 0.07646151393498868
Trained batch 438 in epoch 18, gen_loss = 0.8343301905586399, disc_loss = 0.0764142574534533
Trained batch 439 in epoch 18, gen_loss = 0.8341876899654215, disc_loss = 0.07638399854556403
Trained batch 440 in epoch 18, gen_loss = 0.8338808559236073, disc_loss = 0.07636823205703916
Trained batch 441 in epoch 18, gen_loss = 0.8340648701288041, disc_loss = 0.07622778962673914
Trained batch 442 in epoch 18, gen_loss = 0.8337308547835856, disc_loss = 0.07631186095673936
Trained batch 443 in epoch 18, gen_loss = 0.8340733440609666, disc_loss = 0.07618484311309215
Trained batch 444 in epoch 18, gen_loss = 0.8342871821328496, disc_loss = 0.07606154057417024
Trained batch 445 in epoch 18, gen_loss = 0.8343520107023384, disc_loss = 0.07595907914297731
Trained batch 446 in epoch 18, gen_loss = 0.8341222514775509, disc_loss = 0.07590837855000357
Trained batch 447 in epoch 18, gen_loss = 0.8336770913696715, disc_loss = 0.07600652038984533
Trained batch 448 in epoch 18, gen_loss = 0.833968326880831, disc_loss = 0.07588058217264762
Trained batch 449 in epoch 18, gen_loss = 0.833866296476788, disc_loss = 0.07589744970202446
Trained batch 450 in epoch 18, gen_loss = 0.8337689459720367, disc_loss = 0.07576828641598082
Trained batch 451 in epoch 18, gen_loss = 0.8345522444068858, disc_loss = 0.07569048998762021
Trained batch 452 in epoch 18, gen_loss = 0.8344280681599581, disc_loss = 0.07559441094169554
Trained batch 453 in epoch 18, gen_loss = 0.8339030888374681, disc_loss = 0.07564707326862781
Trained batch 454 in epoch 18, gen_loss = 0.8339335110161331, disc_loss = 0.07554072926005165
Trained batch 455 in epoch 18, gen_loss = 0.8345999115130358, disc_loss = 0.07551955586920182
Trained batch 456 in epoch 18, gen_loss = 0.8348127283987383, disc_loss = 0.07539747356227243
Trained batch 457 in epoch 18, gen_loss = 0.8352100886892544, disc_loss = 0.07539167031483099
Trained batch 458 in epoch 18, gen_loss = 0.8345510646668395, disc_loss = 0.07563931208452887
Trained batch 459 in epoch 18, gen_loss = 0.8348377172065817, disc_loss = 0.07553987047108619
Trained batch 460 in epoch 18, gen_loss = 0.8342591543518282, disc_loss = 0.07560571592600124
Trained batch 461 in epoch 18, gen_loss = 0.8351127808486228, disc_loss = 0.07557579717756092
Trained batch 462 in epoch 18, gen_loss = 0.8352217884094617, disc_loss = 0.07549318286628497
Trained batch 463 in epoch 18, gen_loss = 0.8348392156948303, disc_loss = 0.07553805301672425
Trained batch 464 in epoch 18, gen_loss = 0.8346467839774265, disc_loss = 0.07554515786068414
Trained batch 465 in epoch 18, gen_loss = 0.8348881535775672, disc_loss = 0.07540450421213912
Trained batch 466 in epoch 18, gen_loss = 0.8356044437951654, disc_loss = 0.07529734069286054
Trained batch 467 in epoch 18, gen_loss = 0.8356917175727013, disc_loss = 0.07515663631125075
Trained batch 468 in epoch 18, gen_loss = 0.8356781213014111, disc_loss = 0.07501825090767796
Trained batch 469 in epoch 18, gen_loss = 0.835692058091468, disc_loss = 0.07490335409034123
Trained batch 470 in epoch 18, gen_loss = 0.8354426147831473, disc_loss = 0.07507430558980714
Trained batch 471 in epoch 18, gen_loss = 0.8354072646569397, disc_loss = 0.0750380226083384
Trained batch 472 in epoch 18, gen_loss = 0.8351127286037986, disc_loss = 0.07497496016315691
Trained batch 473 in epoch 18, gen_loss = 0.8352105041596457, disc_loss = 0.07488550174439067
Trained batch 474 in epoch 18, gen_loss = 0.8349421043145029, disc_loss = 0.07479054116692982
Trained batch 475 in epoch 18, gen_loss = 0.8355851780717113, disc_loss = 0.07472242749718745
Trained batch 476 in epoch 18, gen_loss = 0.8354580387379389, disc_loss = 0.07467759656573429
Trained batch 477 in epoch 18, gen_loss = 0.8354264970354456, disc_loss = 0.07456923690605051
Trained batch 478 in epoch 18, gen_loss = 0.8353136502875167, disc_loss = 0.07450725299759237
Trained batch 479 in epoch 18, gen_loss = 0.8349718143542607, disc_loss = 0.0745734812982846
Trained batch 480 in epoch 18, gen_loss = 0.8351502176877614, disc_loss = 0.07463439528998801
Trained batch 481 in epoch 18, gen_loss = 0.8349398445044316, disc_loss = 0.07458922266766924
Trained batch 482 in epoch 18, gen_loss = 0.8345112919067004, disc_loss = 0.07463227573196031
Trained batch 483 in epoch 18, gen_loss = 0.8346001222606533, disc_loss = 0.0746319553033595
Trained batch 484 in epoch 18, gen_loss = 0.8351077974457102, disc_loss = 0.07452659302573536
Trained batch 485 in epoch 18, gen_loss = 0.8350589823575667, disc_loss = 0.07448368519352971
Trained batch 486 in epoch 18, gen_loss = 0.834617356255314, disc_loss = 0.074560189330893
Trained batch 487 in epoch 18, gen_loss = 0.8344012253352853, disc_loss = 0.07448625207886284
Trained batch 488 in epoch 18, gen_loss = 0.8344315809706238, disc_loss = 0.07438307226366975
Trained batch 489 in epoch 18, gen_loss = 0.8349058102588265, disc_loss = 0.07436101693393929
Trained batch 490 in epoch 18, gen_loss = 0.835297617552965, disc_loss = 0.07432708485419966
Trained batch 491 in epoch 18, gen_loss = 0.8356142239115103, disc_loss = 0.07421583395898039
Trained batch 492 in epoch 18, gen_loss = 0.8350807903504517, disc_loss = 0.07482657131019217
Trained batch 493 in epoch 18, gen_loss = 0.8357909858709405, disc_loss = 0.07514971091792833
Trained batch 494 in epoch 18, gen_loss = 0.8370218651463287, disc_loss = 0.07537502274481636
Trained batch 495 in epoch 18, gen_loss = 0.8368427564780558, disc_loss = 0.075326434514981
Trained batch 496 in epoch 18, gen_loss = 0.8362979195727189, disc_loss = 0.07554949981758233
Trained batch 497 in epoch 18, gen_loss = 0.8364819644924149, disc_loss = 0.07549201074546301
Trained batch 498 in epoch 18, gen_loss = 0.8367997438969736, disc_loss = 0.07566086526676445
Trained batch 499 in epoch 18, gen_loss = 0.8364894088506699, disc_loss = 0.0756490279417485
Trained batch 500 in epoch 18, gen_loss = 0.8362652938998864, disc_loss = 0.07569525659850199
Trained batch 501 in epoch 18, gen_loss = 0.8360513941462772, disc_loss = 0.07560874546777857
Trained batch 502 in epoch 18, gen_loss = 0.8361218604842426, disc_loss = 0.07565281806591431
Trained batch 503 in epoch 18, gen_loss = 0.8361626252058952, disc_loss = 0.07563739096827155
Trained batch 504 in epoch 18, gen_loss = 0.8366796220883285, disc_loss = 0.0755468858553484
Trained batch 505 in epoch 18, gen_loss = 0.8366481739541759, disc_loss = 0.07554117817497949
Trained batch 506 in epoch 18, gen_loss = 0.836812141731646, disc_loss = 0.0754247341778945
Trained batch 507 in epoch 18, gen_loss = 0.8365583843368245, disc_loss = 0.07540826630543947
Trained batch 508 in epoch 18, gen_loss = 0.8362859009759599, disc_loss = 0.07545488764493487
Trained batch 509 in epoch 18, gen_loss = 0.836809943002813, disc_loss = 0.07545295881253539
Trained batch 510 in epoch 18, gen_loss = 0.8373298269428618, disc_loss = 0.07536062699015418
Trained batch 511 in epoch 18, gen_loss = 0.8371195227373391, disc_loss = 0.07541639355076768
Trained batch 512 in epoch 18, gen_loss = 0.8368565452958641, disc_loss = 0.0754385444174065
Trained batch 513 in epoch 18, gen_loss = 0.8374985407762491, disc_loss = 0.07539895765577599
Trained batch 514 in epoch 18, gen_loss = 0.8370760789195311, disc_loss = 0.07538755903725775
Trained batch 515 in epoch 18, gen_loss = 0.8371795689643815, disc_loss = 0.07528545850591893
Trained batch 516 in epoch 18, gen_loss = 0.8377438362839144, disc_loss = 0.07523455693633287
Trained batch 517 in epoch 18, gen_loss = 0.8374657428402699, disc_loss = 0.07516818161528831
Trained batch 518 in epoch 18, gen_loss = 0.837185342647207, disc_loss = 0.07512191691846803
Trained batch 519 in epoch 18, gen_loss = 0.8370891880530578, disc_loss = 0.07504500100711504
Trained batch 520 in epoch 18, gen_loss = 0.8371258677768159, disc_loss = 0.07494588999431616
Trained batch 521 in epoch 18, gen_loss = 0.8368212044010674, disc_loss = 0.0749316857039386
Trained batch 522 in epoch 18, gen_loss = 0.836673703521889, disc_loss = 0.0751101238239934
Trained batch 523 in epoch 18, gen_loss = 0.8368781270416639, disc_loss = 0.0750204015697374
Trained batch 524 in epoch 18, gen_loss = 0.836831404595148, disc_loss = 0.07494836281630254
Trained batch 525 in epoch 18, gen_loss = 0.8367406841466636, disc_loss = 0.07504297613906373
Trained batch 526 in epoch 18, gen_loss = 0.8368659847375338, disc_loss = 0.07497018576551942
Trained batch 527 in epoch 18, gen_loss = 0.836848376939694, disc_loss = 0.07490211630162473
Trained batch 528 in epoch 18, gen_loss = 0.8363865887735652, disc_loss = 0.07506200691794233
Trained batch 529 in epoch 18, gen_loss = 0.8365180583495014, disc_loss = 0.07503627450996131
Trained batch 530 in epoch 18, gen_loss = 0.8370020287409565, disc_loss = 0.07500110533818069
Trained batch 531 in epoch 18, gen_loss = 0.8371730056920446, disc_loss = 0.07487860240945522
Trained batch 532 in epoch 18, gen_loss = 0.8368239107543487, disc_loss = 0.07484562633695399
Trained batch 533 in epoch 18, gen_loss = 0.836484401413564, disc_loss = 0.07494173790694456
Trained batch 534 in epoch 18, gen_loss = 0.837079242233918, disc_loss = 0.07503732573937312
Trained batch 535 in epoch 18, gen_loss = 0.8371109861268926, disc_loss = 0.07504124336340812
Trained batch 536 in epoch 18, gen_loss = 0.8369942639349115, disc_loss = 0.0749976817515004
Trained batch 537 in epoch 18, gen_loss = 0.8367324358468605, disc_loss = 0.07500328519121921
Trained batch 538 in epoch 18, gen_loss = 0.836399570577441, disc_loss = 0.07503630961282852
Trained batch 539 in epoch 18, gen_loss = 0.8364806957818843, disc_loss = 0.0749416356647594
Trained batch 540 in epoch 18, gen_loss = 0.8363838683875784, disc_loss = 0.0750868885473188
Trained batch 541 in epoch 18, gen_loss = 0.8359640527695308, disc_loss = 0.07516502088100763
Trained batch 542 in epoch 18, gen_loss = 0.8362104876265342, disc_loss = 0.07506115864413494
Trained batch 543 in epoch 18, gen_loss = 0.8364241857300786, disc_loss = 0.0751247312685283
Trained batch 544 in epoch 18, gen_loss = 0.8362447178691899, disc_loss = 0.07513854941951299
Trained batch 545 in epoch 18, gen_loss = 0.8365971775718661, disc_loss = 0.07502200339678607
Trained batch 546 in epoch 18, gen_loss = 0.8361057548679861, disc_loss = 0.07513542546698282
Trained batch 547 in epoch 18, gen_loss = 0.8366922431618627, disc_loss = 0.0755743917305512
Trained batch 548 in epoch 18, gen_loss = 0.8363105629745511, disc_loss = 0.07553629141355202
Trained batch 549 in epoch 18, gen_loss = 0.8357796480438926, disc_loss = 0.0755821345594119
Trained batch 550 in epoch 18, gen_loss = 0.8356938768861082, disc_loss = 0.07566921715666887
Trained batch 551 in epoch 18, gen_loss = 0.8358327016450356, disc_loss = 0.0756509960544687
Trained batch 552 in epoch 18, gen_loss = 0.8356202548709959, disc_loss = 0.07559988232561897
Trained batch 553 in epoch 18, gen_loss = 0.8352457750790386, disc_loss = 0.07571144338650125
Trained batch 554 in epoch 18, gen_loss = 0.8359069226024387, disc_loss = 0.07572479831843494
Trained batch 555 in epoch 18, gen_loss = 0.8356643862647118, disc_loss = 0.07566120185246088
Trained batch 556 in epoch 18, gen_loss = 0.8353787552518519, disc_loss = 0.07573736708316972
Trained batch 557 in epoch 18, gen_loss = 0.835543465870683, disc_loss = 0.07567732335038242
Trained batch 558 in epoch 18, gen_loss = 0.8355570696760802, disc_loss = 0.07572053568620961
Trained batch 559 in epoch 18, gen_loss = 0.8354416881288801, disc_loss = 0.07572330671329318
Trained batch 560 in epoch 18, gen_loss = 0.8355518330864727, disc_loss = 0.07570863209512091
Trained batch 561 in epoch 18, gen_loss = 0.8353073984066363, disc_loss = 0.07575985527965257
Trained batch 562 in epoch 18, gen_loss = 0.8352699747729259, disc_loss = 0.07568772978663815
Trained batch 563 in epoch 18, gen_loss = 0.835494873794258, disc_loss = 0.07565199771189256
Trained batch 564 in epoch 18, gen_loss = 0.8358009127389013, disc_loss = 0.07574840549181784
Trained batch 565 in epoch 18, gen_loss = 0.8356101885701237, disc_loss = 0.07568229156852348
Trained batch 566 in epoch 18, gen_loss = 0.8352081393018181, disc_loss = 0.07574923660908374
Trained batch 567 in epoch 18, gen_loss = 0.8352119027518891, disc_loss = 0.07566102532978157
Trained batch 568 in epoch 18, gen_loss = 0.8349236246781107, disc_loss = 0.07564358409782233
Trained batch 569 in epoch 18, gen_loss = 0.8350643409971605, disc_loss = 0.07577584894831504
Trained batch 570 in epoch 18, gen_loss = 0.8348089568251695, disc_loss = 0.07571914192328259
Trained batch 571 in epoch 18, gen_loss = 0.834726095095381, disc_loss = 0.07568152111277661
Trained batch 572 in epoch 18, gen_loss = 0.8348708488762274, disc_loss = 0.0755862699542032
Trained batch 573 in epoch 18, gen_loss = 0.834995525327709, disc_loss = 0.07555029230218265
Trained batch 574 in epoch 18, gen_loss = 0.835181595760843, disc_loss = 0.07559830944661212
Trained batch 575 in epoch 18, gen_loss = 0.8349836081680324, disc_loss = 0.07555852740996569
Trained batch 576 in epoch 18, gen_loss = 0.8348657432007418, disc_loss = 0.07555190845516928
Trained batch 577 in epoch 18, gen_loss = 0.8349516397941483, disc_loss = 0.07557557458638062
Trained batch 578 in epoch 18, gen_loss = 0.8354052585229561, disc_loss = 0.07580754111821736
Trained batch 579 in epoch 18, gen_loss = 0.835624359393942, disc_loss = 0.07583369509766585
Trained batch 580 in epoch 18, gen_loss = 0.8353221609342119, disc_loss = 0.07591637223798672
Trained batch 581 in epoch 18, gen_loss = 0.834666222948389, disc_loss = 0.07610431511780803
Trained batch 582 in epoch 18, gen_loss = 0.8350033303067779, disc_loss = 0.07621066697663907
Trained batch 583 in epoch 18, gen_loss = 0.8353012709380829, disc_loss = 0.07619847716884814
Trained batch 584 in epoch 18, gen_loss = 0.8351611796607319, disc_loss = 0.07618573554910911
Trained batch 585 in epoch 18, gen_loss = 0.834974507117841, disc_loss = 0.07629015141424211
Trained batch 586 in epoch 18, gen_loss = 0.8348094322409296, disc_loss = 0.07624783751981577
Trained batch 587 in epoch 18, gen_loss = 0.8342603316315177, disc_loss = 0.07633874940901336
Trained batch 588 in epoch 18, gen_loss = 0.8339508892320008, disc_loss = 0.07632320979372907
Trained batch 589 in epoch 18, gen_loss = 0.8339777200908984, disc_loss = 0.07636700135387355
Trained batch 590 in epoch 18, gen_loss = 0.8337573145851871, disc_loss = 0.07631278922229803
Trained batch 591 in epoch 18, gen_loss = 0.8337983370230004, disc_loss = 0.07642670838332206
Trained batch 592 in epoch 18, gen_loss = 0.8337284926620342, disc_loss = 0.07643417511952014
Trained batch 593 in epoch 18, gen_loss = 0.8330635289953212, disc_loss = 0.07662679318194388
Trained batch 594 in epoch 18, gen_loss = 0.8333860834105676, disc_loss = 0.07657377231365242
Trained batch 595 in epoch 18, gen_loss = 0.8331643645995416, disc_loss = 0.07671095765720828
Trained batch 596 in epoch 18, gen_loss = 0.8330255506226365, disc_loss = 0.07670118602170567
Trained batch 597 in epoch 18, gen_loss = 0.832666046344317, disc_loss = 0.07665309455575901
Trained batch 598 in epoch 18, gen_loss = 0.8328431965114677, disc_loss = 0.07654798749168847
Trained batch 599 in epoch 18, gen_loss = 0.8328129201134046, disc_loss = 0.07646697326563298
Trained batch 600 in epoch 18, gen_loss = 0.832758154032036, disc_loss = 0.07650712354669655
Trained batch 601 in epoch 18, gen_loss = 0.8324838368797619, disc_loss = 0.07650253945571739
Trained batch 602 in epoch 18, gen_loss = 0.8325990275364017, disc_loss = 0.07647109726385197
Trained batch 603 in epoch 18, gen_loss = 0.8329282445426018, disc_loss = 0.07637739535236102
Trained batch 604 in epoch 18, gen_loss = 0.8331498503684998, disc_loss = 0.07651276545029534
Trained batch 605 in epoch 18, gen_loss = 0.83323073347803, disc_loss = 0.07646738057617995
Trained batch 606 in epoch 18, gen_loss = 0.8330804433618385, disc_loss = 0.07646995825505826
Trained batch 607 in epoch 18, gen_loss = 0.8325236280399718, disc_loss = 0.07681424105478647
Trained batch 608 in epoch 18, gen_loss = 0.8320013499514418, disc_loss = 0.07686295604703364
Trained batch 609 in epoch 18, gen_loss = 0.8328871765586197, disc_loss = 0.07740424718463519
Trained batch 610 in epoch 18, gen_loss = 0.8326853633219599, disc_loss = 0.07750740992103486
Trained batch 611 in epoch 18, gen_loss = 0.8330160878549994, disc_loss = 0.07747445665482505
Trained batch 612 in epoch 18, gen_loss = 0.832623731205164, disc_loss = 0.07749086111285655
Trained batch 613 in epoch 18, gen_loss = 0.8325183850254997, disc_loss = 0.07753241681933694
Trained batch 614 in epoch 18, gen_loss = 0.8321213059793643, disc_loss = 0.07764222896620025
Trained batch 615 in epoch 18, gen_loss = 0.8325221453878012, disc_loss = 0.07763572121583312
Trained batch 616 in epoch 18, gen_loss = 0.8325356771049469, disc_loss = 0.07756158861375416
Trained batch 617 in epoch 18, gen_loss = 0.8324931253796642, disc_loss = 0.07756836191241699
Trained batch 618 in epoch 18, gen_loss = 0.8322378871225193, disc_loss = 0.07760867243858358
Trained batch 619 in epoch 18, gen_loss = 0.8322541266199082, disc_loss = 0.07759417338416942
Trained batch 620 in epoch 18, gen_loss = 0.8321666443501502, disc_loss = 0.07752526775542376
Trained batch 621 in epoch 18, gen_loss = 0.8319175726826935, disc_loss = 0.07753151002073498
Trained batch 622 in epoch 18, gen_loss = 0.8320722814834711, disc_loss = 0.07748604239073745
Trained batch 623 in epoch 18, gen_loss = 0.8321947638327495, disc_loss = 0.07738970107554148
Trained batch 624 in epoch 18, gen_loss = 0.8321499758243561, disc_loss = 0.07734665240347385
Trained batch 625 in epoch 18, gen_loss = 0.8323505131866985, disc_loss = 0.07726468925718397
Trained batch 626 in epoch 18, gen_loss = 0.8319290923444849, disc_loss = 0.07727133927412295
Trained batch 627 in epoch 18, gen_loss = 0.8319230572717964, disc_loss = 0.07723931938848773
Trained batch 628 in epoch 18, gen_loss = 0.8322246527160104, disc_loss = 0.07714170575532796
Trained batch 629 in epoch 18, gen_loss = 0.8319451554900124, disc_loss = 0.07717524796783451
Trained batch 630 in epoch 18, gen_loss = 0.8316799420656757, disc_loss = 0.07719684913223122
Trained batch 631 in epoch 18, gen_loss = 0.8316280109501337, disc_loss = 0.07726726104811871
Trained batch 632 in epoch 18, gen_loss = 0.831400741850972, disc_loss = 0.07724687919950504
Trained batch 633 in epoch 18, gen_loss = 0.8316790318169428, disc_loss = 0.07714776639247824
Trained batch 634 in epoch 18, gen_loss = 0.8318165426648508, disc_loss = 0.07706875435303985
Trained batch 635 in epoch 18, gen_loss = 0.8315347408254942, disc_loss = 0.07708500887109142
Trained batch 636 in epoch 18, gen_loss = 0.8324687783628281, disc_loss = 0.07709562220848991
Trained batch 637 in epoch 18, gen_loss = 0.8323324683785065, disc_loss = 0.07703833524020955
Trained batch 638 in epoch 18, gen_loss = 0.8324612806753746, disc_loss = 0.07704271568810343
Trained batch 639 in epoch 18, gen_loss = 0.8323791925329715, disc_loss = 0.07700513810559642
Trained batch 640 in epoch 18, gen_loss = 0.83231123063754, disc_loss = 0.07695875135243124
Trained batch 641 in epoch 18, gen_loss = 0.8329085167787528, disc_loss = 0.0770083743109835
Trained batch 642 in epoch 18, gen_loss = 0.8323673255984928, disc_loss = 0.07718479473138022
Trained batch 643 in epoch 18, gen_loss = 0.8330878129934672, disc_loss = 0.07723844550862353
Trained batch 644 in epoch 18, gen_loss = 0.8329306014286455, disc_loss = 0.07724114455167175
Trained batch 645 in epoch 18, gen_loss = 0.8327733919070601, disc_loss = 0.07721076873722184
Trained batch 646 in epoch 18, gen_loss = 0.8325408172478448, disc_loss = 0.07721392788752983
Trained batch 647 in epoch 18, gen_loss = 0.8325294341294118, disc_loss = 0.07732701859505917
Trained batch 648 in epoch 18, gen_loss = 0.8323541376825841, disc_loss = 0.07729573804133202
Trained batch 649 in epoch 18, gen_loss = 0.8321425428298803, disc_loss = 0.0772239163890481
Trained batch 650 in epoch 18, gen_loss = 0.8321480241514021, disc_loss = 0.0771831706160545
Trained batch 651 in epoch 18, gen_loss = 0.8326118741573, disc_loss = 0.07714442749639139
Trained batch 652 in epoch 18, gen_loss = 0.8324287644663046, disc_loss = 0.07725664415035915
Trained batch 653 in epoch 18, gen_loss = 0.8319503494085522, disc_loss = 0.07758183447809303
Trained batch 654 in epoch 18, gen_loss = 0.8322133625281676, disc_loss = 0.07767592655736527
Trained batch 655 in epoch 18, gen_loss = 0.8323557048400001, disc_loss = 0.07761757386700682
Trained batch 656 in epoch 18, gen_loss = 0.8321043309646473, disc_loss = 0.07759484275324977
Trained batch 657 in epoch 18, gen_loss = 0.831872211808854, disc_loss = 0.0775718721377134
Trained batch 658 in epoch 18, gen_loss = 0.8320150360442438, disc_loss = 0.07762511841364894
Trained batch 659 in epoch 18, gen_loss = 0.8317243380528507, disc_loss = 0.07760376176429969
Trained batch 660 in epoch 18, gen_loss = 0.8314616710353366, disc_loss = 0.07767771966980824
Trained batch 661 in epoch 18, gen_loss = 0.8317301346726288, disc_loss = 0.07761115945166601
Trained batch 662 in epoch 18, gen_loss = 0.8321798667199292, disc_loss = 0.07764420587271677
Trained batch 663 in epoch 18, gen_loss = 0.8318728393908724, disc_loss = 0.07775630588441279
Trained batch 664 in epoch 18, gen_loss = 0.8319072736385174, disc_loss = 0.07770832363320024
Trained batch 665 in epoch 18, gen_loss = 0.8320587865851663, disc_loss = 0.07765322102250548
Trained batch 666 in epoch 18, gen_loss = 0.8319189199532705, disc_loss = 0.0776348043612946
Trained batch 667 in epoch 18, gen_loss = 0.8318278218011657, disc_loss = 0.07758476234649024
Trained batch 668 in epoch 18, gen_loss = 0.8315002336897658, disc_loss = 0.07757966898337162
Trained batch 669 in epoch 18, gen_loss = 0.8317655854705555, disc_loss = 0.07757910773324878
Trained batch 670 in epoch 18, gen_loss = 0.8316506061664104, disc_loss = 0.07762117988961553
Trained batch 671 in epoch 18, gen_loss = 0.831503383593545, disc_loss = 0.07755939913858172
Trained batch 672 in epoch 18, gen_loss = 0.8314206489039389, disc_loss = 0.07750454526477636
Trained batch 673 in epoch 18, gen_loss = 0.8314446707419189, disc_loss = 0.07744390196070208
Trained batch 674 in epoch 18, gen_loss = 0.8314857221091235, disc_loss = 0.07740666843950748
Trained batch 675 in epoch 18, gen_loss = 0.8313834911884641, disc_loss = 0.0775049084758926
Trained batch 676 in epoch 18, gen_loss = 0.8313184695282574, disc_loss = 0.07742726497154027
Trained batch 677 in epoch 18, gen_loss = 0.83111184496971, disc_loss = 0.07745424264926562
Trained batch 678 in epoch 18, gen_loss = 0.8314428601156103, disc_loss = 0.07750109597678476
Trained batch 679 in epoch 18, gen_loss = 0.831835441510467, disc_loss = 0.07751291905091527
Trained batch 680 in epoch 18, gen_loss = 0.8315632157301237, disc_loss = 0.07769096013918934
Trained batch 681 in epoch 18, gen_loss = 0.8319096538590546, disc_loss = 0.077605939298169
Trained batch 682 in epoch 18, gen_loss = 0.832104398643988, disc_loss = 0.07766792286149231
Trained batch 683 in epoch 18, gen_loss = 0.8316711958998825, disc_loss = 0.07775748463358446
Trained batch 684 in epoch 18, gen_loss = 0.831960063389618, disc_loss = 0.07776086214032486
Trained batch 685 in epoch 18, gen_loss = 0.8321779757390565, disc_loss = 0.07767327314204707
Trained batch 686 in epoch 18, gen_loss = 0.8317125171986903, disc_loss = 0.07791287242401028
Trained batch 687 in epoch 18, gen_loss = 0.832058786522857, disc_loss = 0.07790903217256676
Trained batch 688 in epoch 18, gen_loss = 0.8322397301349308, disc_loss = 0.07796122091288404
Trained batch 689 in epoch 18, gen_loss = 0.8322041662274927, disc_loss = 0.07797820441478837
Trained batch 690 in epoch 18, gen_loss = 0.8318870688226565, disc_loss = 0.0780560456717713
Trained batch 691 in epoch 18, gen_loss = 0.8318649707415889, disc_loss = 0.07798981255544835
Trained batch 692 in epoch 18, gen_loss = 0.8317817829302036, disc_loss = 0.07799220011229553
Trained batch 693 in epoch 18, gen_loss = 0.8319639506446526, disc_loss = 0.07790821901809757
Trained batch 694 in epoch 18, gen_loss = 0.8320934954735872, disc_loss = 0.07788764043784828
Trained batch 695 in epoch 18, gen_loss = 0.8319984843590479, disc_loss = 0.07781838846992402
Trained batch 696 in epoch 18, gen_loss = 0.8316758134358241, disc_loss = 0.07791432587314968
Trained batch 697 in epoch 18, gen_loss = 0.8322563800309654, disc_loss = 0.07802867394922712
Trained batch 698 in epoch 18, gen_loss = 0.8323598883950147, disc_loss = 0.07793737229796524
Trained batch 699 in epoch 18, gen_loss = 0.8320901720438685, disc_loss = 0.07802344792921628
Trained batch 700 in epoch 18, gen_loss = 0.8320551532056294, disc_loss = 0.07804446413677277
Trained batch 701 in epoch 18, gen_loss = 0.8322021049736572, disc_loss = 0.07804588185214674
Trained batch 702 in epoch 18, gen_loss = 0.832172172549439, disc_loss = 0.07798166730166924
Trained batch 703 in epoch 18, gen_loss = 0.831925497347997, disc_loss = 0.07804358306351457
Trained batch 704 in epoch 18, gen_loss = 0.8325865456821225, disc_loss = 0.07819877842058104
Trained batch 705 in epoch 18, gen_loss = 0.8323297096632696, disc_loss = 0.07821912048569228
Trained batch 706 in epoch 18, gen_loss = 0.83265667500388, disc_loss = 0.07814475377860888
Trained batch 707 in epoch 18, gen_loss = 0.8325846423789606, disc_loss = 0.07809932185021246
Trained batch 708 in epoch 18, gen_loss = 0.8329127157272506, disc_loss = 0.07802911555165969
Trained batch 709 in epoch 18, gen_loss = 0.8333530796665541, disc_loss = 0.07797045656807826
Trained batch 710 in epoch 18, gen_loss = 0.8334797150894224, disc_loss = 0.0778821081908108
Trained batch 711 in epoch 18, gen_loss = 0.8336016931309459, disc_loss = 0.07779375800020533
Trained batch 712 in epoch 18, gen_loss = 0.8343163974907087, disc_loss = 0.07773629966130556
Trained batch 713 in epoch 18, gen_loss = 0.8340770660244784, disc_loss = 0.07772399003406157
Trained batch 714 in epoch 18, gen_loss = 0.8338891264025148, disc_loss = 0.07770431596473172
Trained batch 715 in epoch 18, gen_loss = 0.8338076202146834, disc_loss = 0.07765366402246557
Trained batch 716 in epoch 18, gen_loss = 0.8342363584573631, disc_loss = 0.07758947282982795
Trained batch 717 in epoch 18, gen_loss = 0.8342645280789532, disc_loss = 0.07754737690667049
Trained batch 718 in epoch 18, gen_loss = 0.8339186525891984, disc_loss = 0.07754999317192525
Trained batch 719 in epoch 18, gen_loss = 0.833779503694839, disc_loss = 0.07747735007433221
Trained batch 720 in epoch 18, gen_loss = 0.8338970099259349, disc_loss = 0.07748060822151033
Trained batch 721 in epoch 18, gen_loss = 0.8338118233096237, disc_loss = 0.07744591597369627
Trained batch 722 in epoch 18, gen_loss = 0.8338218315261033, disc_loss = 0.07738932858853707
Trained batch 723 in epoch 18, gen_loss = 0.8337254084193904, disc_loss = 0.07733307067093886
Trained batch 724 in epoch 18, gen_loss = 0.8338306273674143, disc_loss = 0.07723794318992516
Trained batch 725 in epoch 18, gen_loss = 0.8346523985307736, disc_loss = 0.07739734972414071
Trained batch 726 in epoch 18, gen_loss = 0.8348117740069, disc_loss = 0.07732980549232996
Trained batch 727 in epoch 18, gen_loss = 0.8344380003656005, disc_loss = 0.07742714230482886
Trained batch 728 in epoch 18, gen_loss = 0.834487658591918, disc_loss = 0.07736563217022618
Trained batch 729 in epoch 18, gen_loss = 0.8342815047665818, disc_loss = 0.07736294204751923
Trained batch 730 in epoch 18, gen_loss = 0.8344997901841489, disc_loss = 0.07728045191182646
Trained batch 731 in epoch 18, gen_loss = 0.8345457980297303, disc_loss = 0.07724553566996029
Trained batch 732 in epoch 18, gen_loss = 0.8345710531507312, disc_loss = 0.07716381057873267
Trained batch 733 in epoch 18, gen_loss = 0.8347574327476018, disc_loss = 0.07721185572546899
Trained batch 734 in epoch 18, gen_loss = 0.8346183176348809, disc_loss = 0.0772072895449035
Trained batch 735 in epoch 18, gen_loss = 0.8343634729719033, disc_loss = 0.07714277617734573
Trained batch 736 in epoch 18, gen_loss = 0.8340392000720491, disc_loss = 0.07726308467369553
Trained batch 737 in epoch 18, gen_loss = 0.8343327416556314, disc_loss = 0.07719913455165499
Trained batch 738 in epoch 18, gen_loss = 0.8345087395227326, disc_loss = 0.07710992972113202
Trained batch 739 in epoch 18, gen_loss = 0.8343277545796858, disc_loss = 0.07714019750773504
Trained batch 740 in epoch 18, gen_loss = 0.8342985133169151, disc_loss = 0.07707024287487733
Trained batch 741 in epoch 18, gen_loss = 0.8337940908265564, disc_loss = 0.07717473691736029
Trained batch 742 in epoch 18, gen_loss = 0.8340952748164514, disc_loss = 0.0771513702435617
Trained batch 743 in epoch 18, gen_loss = 0.8346912292463164, disc_loss = 0.07712850106068916
Trained batch 744 in epoch 18, gen_loss = 0.8343176561313987, disc_loss = 0.07725399391813166
Trained batch 745 in epoch 18, gen_loss = 0.8344899783105697, disc_loss = 0.0771825002111874
Trained batch 746 in epoch 18, gen_loss = 0.8344803671520876, disc_loss = 0.07709410965911435
Trained batch 747 in epoch 18, gen_loss = 0.8345618010125059, disc_loss = 0.07709118727604575
Trained batch 748 in epoch 18, gen_loss = 0.8345720593299025, disc_loss = 0.07702183665008905
Trained batch 749 in epoch 18, gen_loss = 0.8349368631442388, disc_loss = 0.07693776995191971
Trained batch 750 in epoch 18, gen_loss = 0.8348798604605201, disc_loss = 0.07687909029344824
Trained batch 751 in epoch 18, gen_loss = 0.8347733843913103, disc_loss = 0.07684334820542643
Trained batch 752 in epoch 18, gen_loss = 0.8349333989271921, disc_loss = 0.07676268623496195
Trained batch 753 in epoch 18, gen_loss = 0.8349617598306596, disc_loss = 0.07667960525571865
Trained batch 754 in epoch 18, gen_loss = 0.834970248337613, disc_loss = 0.07665406559402776
Trained batch 755 in epoch 18, gen_loss = 0.8349274556551661, disc_loss = 0.0765866678190866
Trained batch 756 in epoch 18, gen_loss = 0.8347254113996675, disc_loss = 0.07654228982302795
Trained batch 757 in epoch 18, gen_loss = 0.8349829422688422, disc_loss = 0.07650819269566746
Trained batch 758 in epoch 18, gen_loss = 0.8349113856615286, disc_loss = 0.07645270699691592
Trained batch 759 in epoch 18, gen_loss = 0.8350966475119717, disc_loss = 0.07649200512708998
Trained batch 760 in epoch 18, gen_loss = 0.8352861736121535, disc_loss = 0.07643858539295455
Trained batch 761 in epoch 18, gen_loss = 0.8351159426249232, disc_loss = 0.07642604282683158
Trained batch 762 in epoch 18, gen_loss = 0.8352334877844719, disc_loss = 0.07647811279779844
Trained batch 763 in epoch 18, gen_loss = 0.8351020537199775, disc_loss = 0.0764379139211887
Trained batch 764 in epoch 18, gen_loss = 0.8351533819257824, disc_loss = 0.07638207435534865
Trained batch 765 in epoch 18, gen_loss = 0.8349751914527958, disc_loss = 0.0763706191316461
Trained batch 766 in epoch 18, gen_loss = 0.8350889464012181, disc_loss = 0.07629506895743611
Trained batch 767 in epoch 18, gen_loss = 0.8349905768797422, disc_loss = 0.07625946729118975
Trained batch 768 in epoch 18, gen_loss = 0.8350921823935019, disc_loss = 0.076236182425331
Trained batch 769 in epoch 18, gen_loss = 0.8352681006317014, disc_loss = 0.07615170048114348
Trained batch 770 in epoch 18, gen_loss = 0.8355311546112313, disc_loss = 0.07606593217705551
Trained batch 771 in epoch 18, gen_loss = 0.8354551174094023, disc_loss = 0.07602131854829625
Trained batch 772 in epoch 18, gen_loss = 0.8356053333772879, disc_loss = 0.07610039659480614
Trained batch 773 in epoch 18, gen_loss = 0.8353690922029259, disc_loss = 0.07609611072695456
Trained batch 774 in epoch 18, gen_loss = 0.8354442223041288, disc_loss = 0.07604010848989409
Trained batch 775 in epoch 18, gen_loss = 0.8353476808166381, disc_loss = 0.07600280504011232
Trained batch 776 in epoch 18, gen_loss = 0.8351310352330963, disc_loss = 0.07596502520930276
Trained batch 777 in epoch 18, gen_loss = 0.8358366146568774, disc_loss = 0.07621215214679894
Trained batch 778 in epoch 18, gen_loss = 0.835630890378903, disc_loss = 0.0762276993956852
Trained batch 779 in epoch 18, gen_loss = 0.8358807333386862, disc_loss = 0.07615070330122342
Trained batch 780 in epoch 18, gen_loss = 0.8356415857960412, disc_loss = 0.07615837737650785
Trained batch 781 in epoch 18, gen_loss = 0.8356770836864896, disc_loss = 0.07625676638653973
Trained batch 782 in epoch 18, gen_loss = 0.8356110442567755, disc_loss = 0.07630480122235087
Trained batch 783 in epoch 18, gen_loss = 0.8355029494862776, disc_loss = 0.07625878002133449
Trained batch 784 in epoch 18, gen_loss = 0.8349893152334128, disc_loss = 0.07637458153685947
Trained batch 785 in epoch 18, gen_loss = 0.834969480680752, disc_loss = 0.0763797870773168
Trained batch 786 in epoch 18, gen_loss = 0.8351127169032261, disc_loss = 0.0763106510289288
Trained batch 787 in epoch 18, gen_loss = 0.8352904420364932, disc_loss = 0.07626615224529039
Trained batch 788 in epoch 18, gen_loss = 0.8354782097995357, disc_loss = 0.0761886503800032
Trained batch 789 in epoch 18, gen_loss = 0.835551008318044, disc_loss = 0.07611814795910746
Testing Epoch 18
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.7443979978561401, disc_loss = 0.05216386914253235
Trained batch 1 in epoch 19, gen_loss = 0.7731074690818787, disc_loss = 0.04909336380660534
Trained batch 2 in epoch 19, gen_loss = 0.8018586834271749, disc_loss = 0.06151701634128889
Trained batch 3 in epoch 19, gen_loss = 0.8724975436925888, disc_loss = 0.05238198861479759
Trained batch 4 in epoch 19, gen_loss = 0.8300413727760315, disc_loss = 0.071486434340477
Trained batch 5 in epoch 19, gen_loss = 0.8191538055737814, disc_loss = 0.06913623213768005
Trained batch 6 in epoch 19, gen_loss = 0.8285507134028843, disc_loss = 0.07200485148600169
Trained batch 7 in epoch 19, gen_loss = 0.7915416955947876, disc_loss = 0.07851436082273722
Trained batch 8 in epoch 19, gen_loss = 0.8112395405769348, disc_loss = 0.0732777284251319
Trained batch 9 in epoch 19, gen_loss = 0.8035400807857513, disc_loss = 0.07070443592965603
Trained batch 10 in epoch 19, gen_loss = 0.8003891002048146, disc_loss = 0.07268615371801636
Trained batch 11 in epoch 19, gen_loss = 0.8264495382706324, disc_loss = 0.07268475648015738
Trained batch 12 in epoch 19, gen_loss = 0.8303144115668076, disc_loss = 0.06920052033204299
Trained batch 13 in epoch 19, gen_loss = 0.8245742619037628, disc_loss = 0.06691885420254298
Trained batch 14 in epoch 19, gen_loss = 0.8383349219957987, disc_loss = 0.0636298584441344
Trained batch 15 in epoch 19, gen_loss = 0.8462566770613194, disc_loss = 0.06287763617001474
Trained batch 16 in epoch 19, gen_loss = 0.8310505186810213, disc_loss = 0.0661561110002153
Trained batch 17 in epoch 19, gen_loss = 0.8327042427327898, disc_loss = 0.06413774078504907
Trained batch 18 in epoch 19, gen_loss = 0.8417627278127169, disc_loss = 0.06269088593360625
Trained batch 19 in epoch 19, gen_loss = 0.8507274836301804, disc_loss = 0.060051291901618245
Trained batch 20 in epoch 19, gen_loss = 0.8483999456678119, disc_loss = 0.05918185386274542
Trained batch 21 in epoch 19, gen_loss = 0.8405719101428986, disc_loss = 0.05915792684324763
Trained batch 22 in epoch 19, gen_loss = 0.851392898870551, disc_loss = 0.05717269489136727
Trained batch 23 in epoch 19, gen_loss = 0.8486411596337954, disc_loss = 0.05780939350370318
Trained batch 24 in epoch 19, gen_loss = 0.8489498090744019, disc_loss = 0.05606866799294949
Trained batch 25 in epoch 19, gen_loss = 0.8391417838059939, disc_loss = 0.05767220050956194
Trained batch 26 in epoch 19, gen_loss = 0.8360567953851488, disc_loss = 0.05728522294925319
Trained batch 27 in epoch 19, gen_loss = 0.848192783338683, disc_loss = 0.06482772336208395
Trained batch 28 in epoch 19, gen_loss = 0.8451482448084601, disc_loss = 0.06344616432385199
Trained batch 29 in epoch 19, gen_loss = 0.8476889352003734, disc_loss = 0.06231160722672939
Trained batch 30 in epoch 19, gen_loss = 0.8494866740319037, disc_loss = 0.060969237358339375
Trained batch 31 in epoch 19, gen_loss = 0.8582003340125084, disc_loss = 0.06154057779349387
Trained batch 32 in epoch 19, gen_loss = 0.8524893052650221, disc_loss = 0.06225399063392119
Trained batch 33 in epoch 19, gen_loss = 0.8513568885186139, disc_loss = 0.06135808019077077
Trained batch 34 in epoch 19, gen_loss = 0.8530676671436854, disc_loss = 0.060082399206502095
Trained batch 35 in epoch 19, gen_loss = 0.8513857705725564, disc_loss = 0.060496385105782084
Trained batch 36 in epoch 19, gen_loss = 0.8507566178167189, disc_loss = 0.06129186157439206
Trained batch 37 in epoch 19, gen_loss = 0.8500468558386752, disc_loss = 0.061933160612457676
Trained batch 38 in epoch 19, gen_loss = 0.8495373466075995, disc_loss = 0.06155227038722772
Trained batch 39 in epoch 19, gen_loss = 0.8481766447424889, disc_loss = 0.06091928137466311
Trained batch 40 in epoch 19, gen_loss = 0.8505337616292442, disc_loss = 0.060444636679277186
Trained batch 41 in epoch 19, gen_loss = 0.8537893806185041, disc_loss = 0.059648040194241775
Trained batch 42 in epoch 19, gen_loss = 0.8510301279467206, disc_loss = 0.05935109116483566
Trained batch 43 in epoch 19, gen_loss = 0.8592989065430381, disc_loss = 0.06149696495214647
Trained batch 44 in epoch 19, gen_loss = 0.8554586238331265, disc_loss = 0.06132007609638903
Trained batch 45 in epoch 19, gen_loss = 0.8542284071445465, disc_loss = 0.06154812520126934
Trained batch 46 in epoch 19, gen_loss = 0.8528699075922053, disc_loss = 0.06262929218405104
Trained batch 47 in epoch 19, gen_loss = 0.8443657445410887, disc_loss = 0.06501229375135154
Trained batch 48 in epoch 19, gen_loss = 0.8560514145967911, disc_loss = 0.07137292581705415
Trained batch 49 in epoch 19, gen_loss = 0.8502861690521241, disc_loss = 0.072910744138062
Trained batch 50 in epoch 19, gen_loss = 0.845622698465983, disc_loss = 0.07316461048435931
Trained batch 51 in epoch 19, gen_loss = 0.8422870865234962, disc_loss = 0.07337077553025804
Trained batch 52 in epoch 19, gen_loss = 0.8466803982572736, disc_loss = 0.07283664210084474
Trained batch 53 in epoch 19, gen_loss = 0.8504592246479459, disc_loss = 0.07250757436095565
Trained batch 54 in epoch 19, gen_loss = 0.8494313781911677, disc_loss = 0.07266090773046016
Trained batch 55 in epoch 19, gen_loss = 0.848654258464064, disc_loss = 0.07178198795632593
Trained batch 56 in epoch 19, gen_loss = 0.8449184110290126, disc_loss = 0.07272983600565217
Trained batch 57 in epoch 19, gen_loss = 0.8467562558322117, disc_loss = 0.07280736156450264
Trained batch 58 in epoch 19, gen_loss = 0.8459944027965351, disc_loss = 0.07308224181376272
Trained batch 59 in epoch 19, gen_loss = 0.8456087380647659, disc_loss = 0.0729908611314992
Trained batch 60 in epoch 19, gen_loss = 0.8427518752754711, disc_loss = 0.0735449777213765
Trained batch 61 in epoch 19, gen_loss = 0.846362280268823, disc_loss = 0.0735239285314756
Trained batch 62 in epoch 19, gen_loss = 0.8494468955766588, disc_loss = 0.07330343307602027
Trained batch 63 in epoch 19, gen_loss = 0.845839923247695, disc_loss = 0.07388863983214833
Trained batch 64 in epoch 19, gen_loss = 0.8441014399895301, disc_loss = 0.07356507305342418
Trained batch 65 in epoch 19, gen_loss = 0.8452549323891149, disc_loss = 0.07390561121318376
Trained batch 66 in epoch 19, gen_loss = 0.8505979562873272, disc_loss = 0.07553087828208262
Trained batch 67 in epoch 19, gen_loss = 0.8495738593971028, disc_loss = 0.07544396891642142
Trained batch 68 in epoch 19, gen_loss = 0.8468067516451296, disc_loss = 0.07557255599269833
Trained batch 69 in epoch 19, gen_loss = 0.8485193823065077, disc_loss = 0.07547486996544259
Trained batch 70 in epoch 19, gen_loss = 0.8461723688622595, disc_loss = 0.07680108406069414
Trained batch 71 in epoch 19, gen_loss = 0.8428391474816535, disc_loss = 0.07741920430109733
Trained batch 72 in epoch 19, gen_loss = 0.8465609803591689, disc_loss = 0.0778044803859028
Trained batch 73 in epoch 19, gen_loss = 0.8451476717317427, disc_loss = 0.0774626501559003
Trained batch 74 in epoch 19, gen_loss = 0.8421373025576273, disc_loss = 0.07807443790137768
Trained batch 75 in epoch 19, gen_loss = 0.8402197415891447, disc_loss = 0.07778281279790558
Trained batch 76 in epoch 19, gen_loss = 0.8401980609088749, disc_loss = 0.07749654030935331
Trained batch 77 in epoch 19, gen_loss = 0.840118292814646, disc_loss = 0.07768725209797804
Trained batch 78 in epoch 19, gen_loss = 0.8373447294476666, disc_loss = 0.07804978466769562
Trained batch 79 in epoch 19, gen_loss = 0.8396513178944588, disc_loss = 0.07788245303090661
Trained batch 80 in epoch 19, gen_loss = 0.8390090119691542, disc_loss = 0.07757562166654769
Trained batch 81 in epoch 19, gen_loss = 0.8354080937257627, disc_loss = 0.07827874152671273
Trained batch 82 in epoch 19, gen_loss = 0.8365281856203653, disc_loss = 0.07841439444167786
Trained batch 83 in epoch 19, gen_loss = 0.8364299358356566, disc_loss = 0.07777775615631115
Trained batch 84 in epoch 19, gen_loss = 0.8349796750966241, disc_loss = 0.07762706617222112
Trained batch 85 in epoch 19, gen_loss = 0.8360068195087965, disc_loss = 0.0773358067367659
Trained batch 86 in epoch 19, gen_loss = 0.8321022411872601, disc_loss = 0.07756977275699034
Trained batch 87 in epoch 19, gen_loss = 0.8338861539959908, disc_loss = 0.07717674957926977
Trained batch 88 in epoch 19, gen_loss = 0.8330106125788742, disc_loss = 0.0770596568420362
Trained batch 89 in epoch 19, gen_loss = 0.8333063277933332, disc_loss = 0.0763815322269996
Trained batch 90 in epoch 19, gen_loss = 0.8331152528196901, disc_loss = 0.07590721044075358
Trained batch 91 in epoch 19, gen_loss = 0.8345591140829999, disc_loss = 0.0753450928579854
Trained batch 92 in epoch 19, gen_loss = 0.8342760583405854, disc_loss = 0.07551048115216276
Trained batch 93 in epoch 19, gen_loss = 0.831989031522832, disc_loss = 0.07643911523863356
Trained batch 94 in epoch 19, gen_loss = 0.8319173806592037, disc_loss = 0.07621980074204897
Trained batch 95 in epoch 19, gen_loss = 0.831704598541061, disc_loss = 0.07580750773195177
Trained batch 96 in epoch 19, gen_loss = 0.8316311031272731, disc_loss = 0.0759335429474865
Trained batch 97 in epoch 19, gen_loss = 0.8311998363660307, disc_loss = 0.0753871035591072
Trained batch 98 in epoch 19, gen_loss = 0.83337405895946, disc_loss = 0.07512402342575969
Trained batch 99 in epoch 19, gen_loss = 0.8337526559829712, disc_loss = 0.07457043264061212
Trained batch 100 in epoch 19, gen_loss = 0.8333672863422054, disc_loss = 0.07434258503046366
Trained batch 101 in epoch 19, gen_loss = 0.8324114662759444, disc_loss = 0.07557495760128778
Trained batch 102 in epoch 19, gen_loss = 0.8325125355164982, disc_loss = 0.0749939561649723
Trained batch 103 in epoch 19, gen_loss = 0.834110157421002, disc_loss = 0.07437684405774164
Trained batch 104 in epoch 19, gen_loss = 0.8347126148995899, disc_loss = 0.0738287071120881
Trained batch 105 in epoch 19, gen_loss = 0.8344674723328285, disc_loss = 0.07344924951112776
Trained batch 106 in epoch 19, gen_loss = 0.8361563153356035, disc_loss = 0.07296975727288801
Trained batch 107 in epoch 19, gen_loss = 0.8376280428082855, disc_loss = 0.07257406462708281
Trained batch 108 in epoch 19, gen_loss = 0.8377069005178749, disc_loss = 0.07223509003433885
Trained batch 109 in epoch 19, gen_loss = 0.8373503934253346, disc_loss = 0.0717492308890955
Trained batch 110 in epoch 19, gen_loss = 0.8349040623183723, disc_loss = 0.07236913297124006
Trained batch 111 in epoch 19, gen_loss = 0.8363337442278862, disc_loss = 0.07209730189060792
Trained batch 112 in epoch 19, gen_loss = 0.8350828390205856, disc_loss = 0.07183490107577722
Trained batch 113 in epoch 19, gen_loss = 0.8351353914068457, disc_loss = 0.07153647982008886
Trained batch 114 in epoch 19, gen_loss = 0.8357814928759699, disc_loss = 0.07180989191098058
Trained batch 115 in epoch 19, gen_loss = 0.8342421188436705, disc_loss = 0.0717515520960221
Trained batch 116 in epoch 19, gen_loss = 0.8332744694163656, disc_loss = 0.0714422567293812
Trained batch 117 in epoch 19, gen_loss = 0.8359468013553296, disc_loss = 0.07246797630500237
Trained batch 118 in epoch 19, gen_loss = 0.8359413472544245, disc_loss = 0.07214646076611361
Trained batch 119 in epoch 19, gen_loss = 0.8352850998441378, disc_loss = 0.07202611457711706
Trained batch 120 in epoch 19, gen_loss = 0.8347902332455659, disc_loss = 0.07169987126599905
Trained batch 121 in epoch 19, gen_loss = 0.8393728317784481, disc_loss = 0.07152099700522471
Trained batch 122 in epoch 19, gen_loss = 0.8419079484978342, disc_loss = 0.07107029654600514
Trained batch 123 in epoch 19, gen_loss = 0.840148709954754, disc_loss = 0.07175752609938142
Trained batch 124 in epoch 19, gen_loss = 0.8414726300239563, disc_loss = 0.07125617590546608
Trained batch 125 in epoch 19, gen_loss = 0.8459479889226338, disc_loss = 0.07121756451115721
Trained batch 126 in epoch 19, gen_loss = 0.8459444796945167, disc_loss = 0.0710518490669765
Trained batch 127 in epoch 19, gen_loss = 0.8444541152566671, disc_loss = 0.07106637585093267
Trained batch 128 in epoch 19, gen_loss = 0.8460208390110223, disc_loss = 0.07147332168249197
Trained batch 129 in epoch 19, gen_loss = 0.8455552871410663, disc_loss = 0.07119973983902197
Trained batch 130 in epoch 19, gen_loss = 0.844379831816404, disc_loss = 0.07131066810311253
Trained batch 131 in epoch 19, gen_loss = 0.8454879355249982, disc_loss = 0.0708861760654007
Trained batch 132 in epoch 19, gen_loss = 0.8463304047297714, disc_loss = 0.07071604382218723
Trained batch 133 in epoch 19, gen_loss = 0.8481271235800502, disc_loss = 0.07064867585397033
Trained batch 134 in epoch 19, gen_loss = 0.8464685930146112, disc_loss = 0.07100193007952638
Trained batch 135 in epoch 19, gen_loss = 0.8481191523811397, disc_loss = 0.07174183399526074
Trained batch 136 in epoch 19, gen_loss = 0.8480847195117143, disc_loss = 0.07143349927870461
Trained batch 137 in epoch 19, gen_loss = 0.8471492226573004, disc_loss = 0.0712381258363957
Trained batch 138 in epoch 19, gen_loss = 0.847135156178646, disc_loss = 0.07088324296281492
Trained batch 139 in epoch 19, gen_loss = 0.8493150132043021, disc_loss = 0.07117125783115626
Trained batch 140 in epoch 19, gen_loss = 0.8467695252269718, disc_loss = 0.07190337468017922
Trained batch 141 in epoch 19, gen_loss = 0.8461326620948146, disc_loss = 0.07182376569425555
Trained batch 142 in epoch 19, gen_loss = 0.8469183911810388, disc_loss = 0.07184654276270966
Trained batch 143 in epoch 19, gen_loss = 0.8469407939248614, disc_loss = 0.07200063056209022
Trained batch 144 in epoch 19, gen_loss = 0.8450384958037015, disc_loss = 0.07274076481317651
Trained batch 145 in epoch 19, gen_loss = 0.8444849281278375, disc_loss = 0.07252560012450773
Trained batch 146 in epoch 19, gen_loss = 0.8456779487278997, disc_loss = 0.0723005852782402
Trained batch 147 in epoch 19, gen_loss = 0.8477242407766549, disc_loss = 0.07318551045515247
Trained batch 148 in epoch 19, gen_loss = 0.8464755279905845, disc_loss = 0.07330372772060785
Trained batch 149 in epoch 19, gen_loss = 0.84532239874204, disc_loss = 0.0733686950057745
Trained batch 150 in epoch 19, gen_loss = 0.8440439989235228, disc_loss = 0.07339643260205028
Trained batch 151 in epoch 19, gen_loss = 0.8452044737182165, disc_loss = 0.07355211584485676
Trained batch 152 in epoch 19, gen_loss = 0.8432683126599181, disc_loss = 0.07447712461835419
Trained batch 153 in epoch 19, gen_loss = 0.8454850501828379, disc_loss = 0.07439153503578205
Trained batch 154 in epoch 19, gen_loss = 0.8461052448518814, disc_loss = 0.07427090658776221
Trained batch 155 in epoch 19, gen_loss = 0.8440332588477012, disc_loss = 0.07480499571046004
Trained batch 156 in epoch 19, gen_loss = 0.845492865629257, disc_loss = 0.07457006127116786
Trained batch 157 in epoch 19, gen_loss = 0.8441936004010937, disc_loss = 0.07461844712401493
Trained batch 158 in epoch 19, gen_loss = 0.8446721933172934, disc_loss = 0.07444843078184428
Trained batch 159 in epoch 19, gen_loss = 0.8453073829412461, disc_loss = 0.07521578334271908
Trained batch 160 in epoch 19, gen_loss = 0.8454473481415221, disc_loss = 0.07487032022211493
Trained batch 161 in epoch 19, gen_loss = 0.8440528567190524, disc_loss = 0.07503843878936252
Trained batch 162 in epoch 19, gen_loss = 0.8452339995126783, disc_loss = 0.07496866694668684
Trained batch 163 in epoch 19, gen_loss = 0.8456061540580377, disc_loss = 0.07515645041925514
Trained batch 164 in epoch 19, gen_loss = 0.8444870681473703, disc_loss = 0.07517700304813457
Trained batch 165 in epoch 19, gen_loss = 0.8443928048553238, disc_loss = 0.07481173087046089
Trained batch 166 in epoch 19, gen_loss = 0.8449245216603765, disc_loss = 0.07449444006392342
Trained batch 167 in epoch 19, gen_loss = 0.8438449246542794, disc_loss = 0.07486162815863888
Trained batch 168 in epoch 19, gen_loss = 0.8432361571746465, disc_loss = 0.07473995468232053
Trained batch 169 in epoch 19, gen_loss = 0.8431172328836778, disc_loss = 0.07480904142207959
Trained batch 170 in epoch 19, gen_loss = 0.8412691804400662, disc_loss = 0.07499551200117284
Trained batch 171 in epoch 19, gen_loss = 0.8421205881723138, disc_loss = 0.07467045022044765
Trained batch 172 in epoch 19, gen_loss = 0.8442239061945436, disc_loss = 0.07477733443324276
Trained batch 173 in epoch 19, gen_loss = 0.843999116242617, disc_loss = 0.07463602993594504
Trained batch 174 in epoch 19, gen_loss = 0.8439672126088824, disc_loss = 0.07452370215739523
Trained batch 175 in epoch 19, gen_loss = 0.8421733389523897, disc_loss = 0.07505069704811004
Trained batch 176 in epoch 19, gen_loss = 0.8427348005569587, disc_loss = 0.07485873001696026
Trained batch 177 in epoch 19, gen_loss = 0.8448129534051659, disc_loss = 0.07484437690608287
Trained batch 178 in epoch 19, gen_loss = 0.845178220858121, disc_loss = 0.07533382410027462
Trained batch 179 in epoch 19, gen_loss = 0.8443819906976487, disc_loss = 0.07537726683335172
Trained batch 180 in epoch 19, gen_loss = 0.8438784259458931, disc_loss = 0.07523973127672685
Trained batch 181 in epoch 19, gen_loss = 0.8421612283685705, disc_loss = 0.07580965296825865
Trained batch 182 in epoch 19, gen_loss = 0.8423494436050374, disc_loss = 0.0755176320977387
Trained batch 183 in epoch 19, gen_loss = 0.842316570489303, disc_loss = 0.07550510580894416
Trained batch 184 in epoch 19, gen_loss = 0.841797179144782, disc_loss = 0.07551634657020505
Trained batch 185 in epoch 19, gen_loss = 0.8413957568906969, disc_loss = 0.07537564173621196
Trained batch 186 in epoch 19, gen_loss = 0.840518081889433, disc_loss = 0.07526930330948715
Trained batch 187 in epoch 19, gen_loss = 0.8406837386019687, disc_loss = 0.07492424254900122
Trained batch 188 in epoch 19, gen_loss = 0.840925137201945, disc_loss = 0.07467245613594377
Trained batch 189 in epoch 19, gen_loss = 0.8432900240546779, disc_loss = 0.07544879583445818
Trained batch 190 in epoch 19, gen_loss = 0.8434466326423965, disc_loss = 0.0752186255958614
Trained batch 191 in epoch 19, gen_loss = 0.8423699643462896, disc_loss = 0.07519159376291402
Trained batch 192 in epoch 19, gen_loss = 0.8427821922796378, disc_loss = 0.07486451303325786
Trained batch 193 in epoch 19, gen_loss = 0.843006607797957, disc_loss = 0.07459397415256071
Trained batch 194 in epoch 19, gen_loss = 0.8441062603241358, disc_loss = 0.07438078153018768
Trained batch 195 in epoch 19, gen_loss = 0.8444981453370075, disc_loss = 0.07407984519092252
Trained batch 196 in epoch 19, gen_loss = 0.8444369801409959, disc_loss = 0.07388325352789031
Trained batch 197 in epoch 19, gen_loss = 0.843718330366443, disc_loss = 0.07379116775994801
Trained batch 198 in epoch 19, gen_loss = 0.8427236068188845, disc_loss = 0.07395254426996163
Trained batch 199 in epoch 19, gen_loss = 0.8426611372828483, disc_loss = 0.07367647571023554
Trained batch 200 in epoch 19, gen_loss = 0.8445474137714253, disc_loss = 0.07364064274791313
Trained batch 201 in epoch 19, gen_loss = 0.8446691726694012, disc_loss = 0.07364230371993219
Trained batch 202 in epoch 19, gen_loss = 0.8436311119295693, disc_loss = 0.07376689200973129
Trained batch 203 in epoch 19, gen_loss = 0.8427481820770338, disc_loss = 0.07369113870092905
Trained batch 204 in epoch 19, gen_loss = 0.8453916497346832, disc_loss = 0.07387793183599303
Trained batch 205 in epoch 19, gen_loss = 0.8449307266369607, disc_loss = 0.07371569513026806
Trained batch 206 in epoch 19, gen_loss = 0.8436604378304043, disc_loss = 0.07405255232366242
Trained batch 207 in epoch 19, gen_loss = 0.8428253448353364, disc_loss = 0.07401673095927645
Trained batch 208 in epoch 19, gen_loss = 0.8424551869123176, disc_loss = 0.0738334612760461
Trained batch 209 in epoch 19, gen_loss = 0.8427871051288787, disc_loss = 0.07375715794928726
Trained batch 210 in epoch 19, gen_loss = 0.8433580881611431, disc_loss = 0.07349498066344956
Trained batch 211 in epoch 19, gen_loss = 0.8438429526000653, disc_loss = 0.07329615027608596
Trained batch 212 in epoch 19, gen_loss = 0.8434716202843358, disc_loss = 0.07310804383208354
Trained batch 213 in epoch 19, gen_loss = 0.8431038901070568, disc_loss = 0.07292048401138354
Trained batch 214 in epoch 19, gen_loss = 0.8432863723400027, disc_loss = 0.07268627739489772
Trained batch 215 in epoch 19, gen_loss = 0.8427876907366293, disc_loss = 0.07259673452332478
Trained batch 216 in epoch 19, gen_loss = 0.8419478417541574, disc_loss = 0.07297519322759408
Trained batch 217 in epoch 19, gen_loss = 0.8438198254742754, disc_loss = 0.0729451797723155
Trained batch 218 in epoch 19, gen_loss = 0.8439234195778903, disc_loss = 0.07273834644812563
Trained batch 219 in epoch 19, gen_loss = 0.8433230335062201, disc_loss = 0.07266059535216879
Trained batch 220 in epoch 19, gen_loss = 0.8428396261655368, disc_loss = 0.07254539069833395
Trained batch 221 in epoch 19, gen_loss = 0.843806790875959, disc_loss = 0.0725826858039442
Trained batch 222 in epoch 19, gen_loss = 0.8436359485168629, disc_loss = 0.07263053011884203
Trained batch 223 in epoch 19, gen_loss = 0.8440585942672831, disc_loss = 0.07235936863331258
Trained batch 224 in epoch 19, gen_loss = 0.8437856536441379, disc_loss = 0.07225211533821291
Trained batch 225 in epoch 19, gen_loss = 0.8436778277422474, disc_loss = 0.0722053952605785
Trained batch 226 in epoch 19, gen_loss = 0.844214392653646, disc_loss = 0.07206056642424036
Trained batch 227 in epoch 19, gen_loss = 0.84457217287599, disc_loss = 0.07191776176669488
Trained batch 228 in epoch 19, gen_loss = 0.844212656978957, disc_loss = 0.07183449012207022
Trained batch 229 in epoch 19, gen_loss = 0.8447386565415755, disc_loss = 0.0715690338457732
Trained batch 230 in epoch 19, gen_loss = 0.843913160103224, disc_loss = 0.0716438072560218
Trained batch 231 in epoch 19, gen_loss = 0.8447907045483589, disc_loss = 0.07241286630019673
Trained batch 232 in epoch 19, gen_loss = 0.8465875174866214, disc_loss = 0.07258687488526873
Trained batch 233 in epoch 19, gen_loss = 0.8455405584257892, disc_loss = 0.07292554454686932
Trained batch 234 in epoch 19, gen_loss = 0.8446644605474269, disc_loss = 0.07303805579926739
Trained batch 235 in epoch 19, gen_loss = 0.8451429032168146, disc_loss = 0.07319663345450693
Trained batch 236 in epoch 19, gen_loss = 0.8444507194973748, disc_loss = 0.07319139472684402
Trained batch 237 in epoch 19, gen_loss = 0.8450000423844121, disc_loss = 0.0730389319712437
Trained batch 238 in epoch 19, gen_loss = 0.8446060466467087, disc_loss = 0.07291678199349712
Trained batch 239 in epoch 19, gen_loss = 0.8434309400618076, disc_loss = 0.07305387709056958
Trained batch 240 in epoch 19, gen_loss = 0.8436446691944391, disc_loss = 0.0728344446496412
Trained batch 241 in epoch 19, gen_loss = 0.8438468238046347, disc_loss = 0.07268552601044952
Trained batch 242 in epoch 19, gen_loss = 0.8435925870765875, disc_loss = 0.07251825266797479
Trained batch 243 in epoch 19, gen_loss = 0.8434990896064727, disc_loss = 0.07233833276941518
Trained batch 244 in epoch 19, gen_loss = 0.8444414413705164, disc_loss = 0.07268252159487837
Trained batch 245 in epoch 19, gen_loss = 0.8443771624952797, disc_loss = 0.07248782547099925
Trained batch 246 in epoch 19, gen_loss = 0.8440516289429143, disc_loss = 0.07241797369154479
Trained batch 247 in epoch 19, gen_loss = 0.8449643980110845, disc_loss = 0.0723332327888197
Trained batch 248 in epoch 19, gen_loss = 0.8448356837632666, disc_loss = 0.07215732715679819
Trained batch 249 in epoch 19, gen_loss = 0.8432992961406708, disc_loss = 0.07269197228178383
Trained batch 250 in epoch 19, gen_loss = 0.8445788372560327, disc_loss = 0.07302212527771276
Trained batch 251 in epoch 19, gen_loss = 0.8450572017639403, disc_loss = 0.07279371377450251
Trained batch 252 in epoch 19, gen_loss = 0.8450847508407864, disc_loss = 0.07264143174418465
Trained batch 253 in epoch 19, gen_loss = 0.8445698794886822, disc_loss = 0.07261657388147524
Trained batch 254 in epoch 19, gen_loss = 0.8438438829253702, disc_loss = 0.07260933415051185
Trained batch 255 in epoch 19, gen_loss = 0.8428091949317604, disc_loss = 0.0727279530146916
Trained batch 256 in epoch 19, gen_loss = 0.8431638481552035, disc_loss = 0.07288422628671859
Trained batch 257 in epoch 19, gen_loss = 0.8447150474832964, disc_loss = 0.07290331596624135
Trained batch 258 in epoch 19, gen_loss = 0.8440456443311625, disc_loss = 0.07294364157402493
Trained batch 259 in epoch 19, gen_loss = 0.8432573563777483, disc_loss = 0.07315317374080993
Trained batch 260 in epoch 19, gen_loss = 0.8434740684041575, disc_loss = 0.07305747716262993
Trained batch 261 in epoch 19, gen_loss = 0.8437426062940642, disc_loss = 0.07284400620291592
Trained batch 262 in epoch 19, gen_loss = 0.8429663797748406, disc_loss = 0.0729772506012606
Trained batch 263 in epoch 19, gen_loss = 0.8442245649568962, disc_loss = 0.07304112085098909
Trained batch 264 in epoch 19, gen_loss = 0.8430221661081854, disc_loss = 0.07345045115798712
Trained batch 265 in epoch 19, gen_loss = 0.8435975727730227, disc_loss = 0.0732617390874241
Trained batch 266 in epoch 19, gen_loss = 0.8437249095698868, disc_loss = 0.07363972087715114
Trained batch 267 in epoch 19, gen_loss = 0.8436742551735977, disc_loss = 0.07351312233454813
Trained batch 268 in epoch 19, gen_loss = 0.8432265750537574, disc_loss = 0.07348636815109771
Trained batch 269 in epoch 19, gen_loss = 0.8433156611742797, disc_loss = 0.0737568728108373
Trained batch 270 in epoch 19, gen_loss = 0.8426543098094279, disc_loss = 0.07367079812565963
Trained batch 271 in epoch 19, gen_loss = 0.8419139286612763, disc_loss = 0.07362625948221915
Trained batch 272 in epoch 19, gen_loss = 0.8425540358592303, disc_loss = 0.07380816818388937
Trained batch 273 in epoch 19, gen_loss = 0.8427010454835683, disc_loss = 0.07368458569879188
Trained batch 274 in epoch 19, gen_loss = 0.8428226126324047, disc_loss = 0.07375862933356654
Trained batch 275 in epoch 19, gen_loss = 0.8431632827589477, disc_loss = 0.07395391505333068
Trained batch 276 in epoch 19, gen_loss = 0.8419997730840414, disc_loss = 0.07425089884172816
Trained batch 277 in epoch 19, gen_loss = 0.8417626267714466, disc_loss = 0.07409268067211663
Trained batch 278 in epoch 19, gen_loss = 0.8411216451703006, disc_loss = 0.07422942026287958
Trained batch 279 in epoch 19, gen_loss = 0.841004470203604, disc_loss = 0.07401070140435227
Trained batch 280 in epoch 19, gen_loss = 0.8409983549678028, disc_loss = 0.0737944851062688
Trained batch 281 in epoch 19, gen_loss = 0.8416259041491975, disc_loss = 0.07361197849431782
Trained batch 282 in epoch 19, gen_loss = 0.8415009299352396, disc_loss = 0.07354028139908407
Trained batch 283 in epoch 19, gen_loss = 0.8403326359013437, disc_loss = 0.07363409964813733
Trained batch 284 in epoch 19, gen_loss = 0.8411799324186224, disc_loss = 0.07351280504412819
Trained batch 285 in epoch 19, gen_loss = 0.8421666982707444, disc_loss = 0.07369787231660806
Trained batch 286 in epoch 19, gen_loss = 0.8408694227813428, disc_loss = 0.07470580801783124
Trained batch 287 in epoch 19, gen_loss = 0.8406418830984168, disc_loss = 0.07458127023548716
Trained batch 288 in epoch 19, gen_loss = 0.8413975436794716, disc_loss = 0.07476978248894009
Trained batch 289 in epoch 19, gen_loss = 0.8420412129369276, disc_loss = 0.07465715789846306
Trained batch 290 in epoch 19, gen_loss = 0.8415016464351379, disc_loss = 0.07463865126787182
Trained batch 291 in epoch 19, gen_loss = 0.8410571478817561, disc_loss = 0.0746495554682939
Trained batch 292 in epoch 19, gen_loss = 0.8405053764073108, disc_loss = 0.07476591035316829
Trained batch 293 in epoch 19, gen_loss = 0.8403775531823944, disc_loss = 0.07466526899714859
Trained batch 294 in epoch 19, gen_loss = 0.8402309415704113, disc_loss = 0.07477863602719065
Trained batch 295 in epoch 19, gen_loss = 0.8399112168196086, disc_loss = 0.07473396024087796
Trained batch 296 in epoch 19, gen_loss = 0.8395041131009959, disc_loss = 0.0747900286858732
Trained batch 297 in epoch 19, gen_loss = 0.8390469663095155, disc_loss = 0.07468348866541114
Trained batch 298 in epoch 19, gen_loss = 0.8404657585565063, disc_loss = 0.07539241653820344
Trained batch 299 in epoch 19, gen_loss = 0.8405942853291829, disc_loss = 0.07531331690649191
Trained batch 300 in epoch 19, gen_loss = 0.8396098217694863, disc_loss = 0.07538241242055481
Trained batch 301 in epoch 19, gen_loss = 0.8392903331099757, disc_loss = 0.07534313537427131
Trained batch 302 in epoch 19, gen_loss = 0.8397979850422824, disc_loss = 0.07562660133287852
Trained batch 303 in epoch 19, gen_loss = 0.8389436853559393, disc_loss = 0.07575754914432764
Trained batch 304 in epoch 19, gen_loss = 0.8392624733877964, disc_loss = 0.07570313159071031
Trained batch 305 in epoch 19, gen_loss = 0.8390087756066541, disc_loss = 0.07566363941512856
Trained batch 306 in epoch 19, gen_loss = 0.8394355740919952, disc_loss = 0.07558140813916048
Trained batch 307 in epoch 19, gen_loss = 0.8389166072978602, disc_loss = 0.0755960906964618
Trained batch 308 in epoch 19, gen_loss = 0.8387426421480272, disc_loss = 0.07553440145545406
Trained batch 309 in epoch 19, gen_loss = 0.8401387985675566, disc_loss = 0.07563931474522237
Trained batch 310 in epoch 19, gen_loss = 0.8394386260455827, disc_loss = 0.07572681472376229
Trained batch 311 in epoch 19, gen_loss = 0.839731249671716, disc_loss = 0.07553765915023784
Trained batch 312 in epoch 19, gen_loss = 0.8398209315138503, disc_loss = 0.07561479491619066
Trained batch 313 in epoch 19, gen_loss = 0.839582144454786, disc_loss = 0.07558897597371203
Trained batch 314 in epoch 19, gen_loss = 0.8389952029500689, disc_loss = 0.07583200845808263
Trained batch 315 in epoch 19, gen_loss = 0.8390232590557654, disc_loss = 0.07578849015002952
Trained batch 316 in epoch 19, gen_loss = 0.8384280748171761, disc_loss = 0.07583062661582551
Trained batch 317 in epoch 19, gen_loss = 0.8383032540855168, disc_loss = 0.07571108536736208
Trained batch 318 in epoch 19, gen_loss = 0.8383012817571156, disc_loss = 0.07557358460203047
Trained batch 319 in epoch 19, gen_loss = 0.8383319186046719, disc_loss = 0.07538656952674501
Trained batch 320 in epoch 19, gen_loss = 0.8377651052311573, disc_loss = 0.07533976244754695
Trained batch 321 in epoch 19, gen_loss = 0.8377985695134038, disc_loss = 0.07518328708359358
Trained batch 322 in epoch 19, gen_loss = 0.8374095852530039, disc_loss = 0.07539252932803366
Trained batch 323 in epoch 19, gen_loss = 0.8380830839828208, disc_loss = 0.07555749994576161
Trained batch 324 in epoch 19, gen_loss = 0.8387575556681707, disc_loss = 0.07577338581474928
Trained batch 325 in epoch 19, gen_loss = 0.8377924938143396, disc_loss = 0.07617420004395072
Trained batch 326 in epoch 19, gen_loss = 0.8372180082746966, disc_loss = 0.07614851595452254
Trained batch 327 in epoch 19, gen_loss = 0.8369857905114569, disc_loss = 0.07606057492766256
Trained batch 328 in epoch 19, gen_loss = 0.8374076815361672, disc_loss = 0.07589554169008617
Trained batch 329 in epoch 19, gen_loss = 0.8373700712666367, disc_loss = 0.07612584348993771
Trained batch 330 in epoch 19, gen_loss = 0.8371673480261489, disc_loss = 0.07609176105085276
Trained batch 331 in epoch 19, gen_loss = 0.8369493042848196, disc_loss = 0.07614733939092741
Trained batch 332 in epoch 19, gen_loss = 0.8365934761436852, disc_loss = 0.0760170748071359
Trained batch 333 in epoch 19, gen_loss = 0.8363264356544632, disc_loss = 0.07585361339486466
Trained batch 334 in epoch 19, gen_loss = 0.8363154078597453, disc_loss = 0.0758630579142873
Trained batch 335 in epoch 19, gen_loss = 0.8370714870591959, disc_loss = 0.07567523048713892
Trained batch 336 in epoch 19, gen_loss = 0.8370051716484727, disc_loss = 0.07554871258698957
Trained batch 337 in epoch 19, gen_loss = 0.8366869206611927, disc_loss = 0.07559593285560696
Trained batch 338 in epoch 19, gen_loss = 0.8372118618987654, disc_loss = 0.07542211140140584
Trained batch 339 in epoch 19, gen_loss = 0.8372399289818371, disc_loss = 0.0754741663195412
Trained batch 340 in epoch 19, gen_loss = 0.8374746534481776, disc_loss = 0.07529253179693589
Trained batch 341 in epoch 19, gen_loss = 0.8369650635105824, disc_loss = 0.07547027605983336
Trained batch 342 in epoch 19, gen_loss = 0.8365786006082251, disc_loss = 0.07539470949136916
Trained batch 343 in epoch 19, gen_loss = 0.8369389302855315, disc_loss = 0.07520419912856766
Trained batch 344 in epoch 19, gen_loss = 0.837677774740302, disc_loss = 0.07504559495364842
Trained batch 345 in epoch 19, gen_loss = 0.8373851223143539, disc_loss = 0.07491671053068227
Trained batch 346 in epoch 19, gen_loss = 0.8381227545161068, disc_loss = 0.07473305955003164
Trained batch 347 in epoch 19, gen_loss = 0.8377938721029238, disc_loss = 0.07460637146275191
Trained batch 348 in epoch 19, gen_loss = 0.8380228156346646, disc_loss = 0.07444224758260486
Trained batch 349 in epoch 19, gen_loss = 0.8379110198361533, disc_loss = 0.07430338635774596
Trained batch 350 in epoch 19, gen_loss = 0.8382461558380018, disc_loss = 0.07414546675523717
Trained batch 351 in epoch 19, gen_loss = 0.8378855740143494, disc_loss = 0.07424372382493774
Trained batch 352 in epoch 19, gen_loss = 0.8373289272062502, disc_loss = 0.07422901099816852
Trained batch 353 in epoch 19, gen_loss = 0.8372338678540483, disc_loss = 0.0741261734921843
Trained batch 354 in epoch 19, gen_loss = 0.8374359753769888, disc_loss = 0.07407284875098669
Trained batch 355 in epoch 19, gen_loss = 0.8376189970903183, disc_loss = 0.07391735719611052
Trained batch 356 in epoch 19, gen_loss = 0.8377409552325722, disc_loss = 0.07388147249223054
Trained batch 357 in epoch 19, gen_loss = 0.8378749078545491, disc_loss = 0.07374565123044495
Trained batch 358 in epoch 19, gen_loss = 0.8376993696337622, disc_loss = 0.07361523612742221
Trained batch 359 in epoch 19, gen_loss = 0.8377500807245573, disc_loss = 0.07350476354929722
Trained batch 360 in epoch 19, gen_loss = 0.8372040595704499, disc_loss = 0.07387285867133217
Trained batch 361 in epoch 19, gen_loss = 0.837334133478818, disc_loss = 0.073708175154125
Trained batch 362 in epoch 19, gen_loss = 0.8366958372520678, disc_loss = 0.07370268122726646
Trained batch 363 in epoch 19, gen_loss = 0.837244090798137, disc_loss = 0.0738138399102244
Trained batch 364 in epoch 19, gen_loss = 0.8368915714629709, disc_loss = 0.07373171114196925
Trained batch 365 in epoch 19, gen_loss = 0.8363540306117365, disc_loss = 0.0736872040961813
Trained batch 366 in epoch 19, gen_loss = 0.8370756365622747, disc_loss = 0.07385167468603122
Trained batch 367 in epoch 19, gen_loss = 0.8366855813757234, disc_loss = 0.07390940255414613
Trained batch 368 in epoch 19, gen_loss = 0.8367012595419638, disc_loss = 0.07375978805922315
Trained batch 369 in epoch 19, gen_loss = 0.837434084512092, disc_loss = 0.07379449847833933
Trained batch 370 in epoch 19, gen_loss = 0.8380771938038644, disc_loss = 0.07367389093120545
Trained batch 371 in epoch 19, gen_loss = 0.8378395894842763, disc_loss = 0.07369488229604579
Trained batch 372 in epoch 19, gen_loss = 0.8374948891493974, disc_loss = 0.07372190937369902
Trained batch 373 in epoch 19, gen_loss = 0.8378973255820453, disc_loss = 0.07373714957256766
Trained batch 374 in epoch 19, gen_loss = 0.8389717658360799, disc_loss = 0.07368560438603163
Trained batch 375 in epoch 19, gen_loss = 0.838147575709414, disc_loss = 0.07377268634786076
Trained batch 376 in epoch 19, gen_loss = 0.8379756628044088, disc_loss = 0.07369381755797949
Trained batch 377 in epoch 19, gen_loss = 0.8388358621054857, disc_loss = 0.07444669563747036
Trained batch 378 in epoch 19, gen_loss = 0.8386486653916754, disc_loss = 0.07434376622341318
Trained batch 379 in epoch 19, gen_loss = 0.8377019198317277, disc_loss = 0.0749659355166123
Trained batch 380 in epoch 19, gen_loss = 0.8387846843464168, disc_loss = 0.07625926780976414
Trained batch 381 in epoch 19, gen_loss = 0.8379716352018386, disc_loss = 0.07649398798181514
Trained batch 382 in epoch 19, gen_loss = 0.8381587095733722, disc_loss = 0.07636867115133036
Trained batch 383 in epoch 19, gen_loss = 0.8378870595867435, disc_loss = 0.07638600796296184
Trained batch 384 in epoch 19, gen_loss = 0.8376814569745745, disc_loss = 0.07638724838903585
Trained batch 385 in epoch 19, gen_loss = 0.8376948078370465, disc_loss = 0.07639929140469184
Trained batch 386 in epoch 19, gen_loss = 0.8380819049300458, disc_loss = 0.07650093963124262
Trained batch 387 in epoch 19, gen_loss = 0.8381850152593298, disc_loss = 0.07639365170640659
Trained batch 388 in epoch 19, gen_loss = 0.8377604087704558, disc_loss = 0.07640369973626648
Trained batch 389 in epoch 19, gen_loss = 0.8381085912386577, disc_loss = 0.07638842425046441
Trained batch 390 in epoch 19, gen_loss = 0.8375139218157209, disc_loss = 0.07657773079841262
Trained batch 391 in epoch 19, gen_loss = 0.8371715229384753, disc_loss = 0.07667966277994291
Trained batch 392 in epoch 19, gen_loss = 0.8375905236518414, disc_loss = 0.07662715204297055
Trained batch 393 in epoch 19, gen_loss = 0.83693550564916, disc_loss = 0.07689644548295037
Trained batch 394 in epoch 19, gen_loss = 0.8366662864443623, disc_loss = 0.07686327236315495
Trained batch 395 in epoch 19, gen_loss = 0.8361850284566783, disc_loss = 0.07680372810790861
Trained batch 396 in epoch 19, gen_loss = 0.8362100421631666, disc_loss = 0.07666238485331124
Trained batch 397 in epoch 19, gen_loss = 0.8361543400503283, disc_loss = 0.07655466971076538
Trained batch 398 in epoch 19, gen_loss = 0.8360044393025544, disc_loss = 0.07646033021021531
Trained batch 399 in epoch 19, gen_loss = 0.8361993116140366, disc_loss = 0.07634861222235485
Trained batch 400 in epoch 19, gen_loss = 0.8360737776221182, disc_loss = 0.07622895063019527
Trained batch 401 in epoch 19, gen_loss = 0.8362269158387066, disc_loss = 0.07609741881591689
Trained batch 402 in epoch 19, gen_loss = 0.8364884735041161, disc_loss = 0.07596809999143737
Trained batch 403 in epoch 19, gen_loss = 0.8371521086976079, disc_loss = 0.07583880894079731
Trained batch 404 in epoch 19, gen_loss = 0.837398499029654, disc_loss = 0.07568336654638434
Trained batch 405 in epoch 19, gen_loss = 0.8376126459666661, disc_loss = 0.07556163452868464
Trained batch 406 in epoch 19, gen_loss = 0.8378846474010176, disc_loss = 0.07548181819946892
Trained batch 407 in epoch 19, gen_loss = 0.8375959964651688, disc_loss = 0.07546208401931924
Trained batch 408 in epoch 19, gen_loss = 0.8374803172638481, disc_loss = 0.07538695033402854
Trained batch 409 in epoch 19, gen_loss = 0.8379133330612648, disc_loss = 0.07535413822795196
Trained batch 410 in epoch 19, gen_loss = 0.8381983114275039, disc_loss = 0.0752859658826768
Trained batch 411 in epoch 19, gen_loss = 0.838010646909186, disc_loss = 0.07530165757775957
Trained batch 412 in epoch 19, gen_loss = 0.8381552613964959, disc_loss = 0.07514840292070088
Trained batch 413 in epoch 19, gen_loss = 0.8381841060332054, disc_loss = 0.07514465261691651
Trained batch 414 in epoch 19, gen_loss = 0.8386348030653344, disc_loss = 0.07506525412156999
Trained batch 415 in epoch 19, gen_loss = 0.8379913852191888, disc_loss = 0.07506349233041804
Trained batch 416 in epoch 19, gen_loss = 0.837395039679621, disc_loss = 0.07503316115266342
Trained batch 417 in epoch 19, gen_loss = 0.8384815403148889, disc_loss = 0.07543937521251409
Trained batch 418 in epoch 19, gen_loss = 0.8387454853422033, disc_loss = 0.07539741639581315
Trained batch 419 in epoch 19, gen_loss = 0.8387153240896407, disc_loss = 0.0752960761011179
Trained batch 420 in epoch 19, gen_loss = 0.838304815128127, disc_loss = 0.07529930249874142
Trained batch 421 in epoch 19, gen_loss = 0.8381801020195134, disc_loss = 0.07527008016871826
Trained batch 422 in epoch 19, gen_loss = 0.8382143388121405, disc_loss = 0.07518049642822351
Trained batch 423 in epoch 19, gen_loss = 0.8389681974109614, disc_loss = 0.07527315804409741
Trained batch 424 in epoch 19, gen_loss = 0.8382725158859702, disc_loss = 0.07532323621432571
Trained batch 425 in epoch 19, gen_loss = 0.8380291152727996, disc_loss = 0.07524098765253671
Trained batch 426 in epoch 19, gen_loss = 0.8378064792943504, disc_loss = 0.07526646690351553
Trained batch 427 in epoch 19, gen_loss = 0.8380176707684437, disc_loss = 0.07534821000533336
Trained batch 428 in epoch 19, gen_loss = 0.8376346908527098, disc_loss = 0.07540837798423909
Trained batch 429 in epoch 19, gen_loss = 0.8377833620060322, disc_loss = 0.07528110448660892
Trained batch 430 in epoch 19, gen_loss = 0.8380263562545422, disc_loss = 0.07522453813491661
Trained batch 431 in epoch 19, gen_loss = 0.8379799709827812, disc_loss = 0.07520604795664204
Trained batch 432 in epoch 19, gen_loss = 0.8376392519776871, disc_loss = 0.07516342545827252
Trained batch 433 in epoch 19, gen_loss = 0.8379084686255125, disc_loss = 0.07503120983362815
Trained batch 434 in epoch 19, gen_loss = 0.8386085988461286, disc_loss = 0.07495478641070512
Trained batch 435 in epoch 19, gen_loss = 0.8393327535019008, disc_loss = 0.07485677743834708
Trained batch 436 in epoch 19, gen_loss = 0.8388382901588893, disc_loss = 0.07486908745821949
Trained batch 437 in epoch 19, gen_loss = 0.8386495433169413, disc_loss = 0.07483160239112772
Trained batch 438 in epoch 19, gen_loss = 0.8383693096306438, disc_loss = 0.07479361855639208
Trained batch 439 in epoch 19, gen_loss = 0.8380823146213184, disc_loss = 0.07482946608427235
Trained batch 440 in epoch 19, gen_loss = 0.8385735863731021, disc_loss = 0.0747285765276846
Trained batch 441 in epoch 19, gen_loss = 0.8385447089758394, disc_loss = 0.07465571590501191
Trained batch 442 in epoch 19, gen_loss = 0.8385055755384888, disc_loss = 0.07454059041119927
Trained batch 443 in epoch 19, gen_loss = 0.83897028433847, disc_loss = 0.07440194607972428
Trained batch 444 in epoch 19, gen_loss = 0.8387315882725662, disc_loss = 0.07440511356160212
Trained batch 445 in epoch 19, gen_loss = 0.8389439779279478, disc_loss = 0.07438352359500568
Trained batch 446 in epoch 19, gen_loss = 0.8391744578444718, disc_loss = 0.07427581088404928
Trained batch 447 in epoch 19, gen_loss = 0.8394547123461962, disc_loss = 0.07445374118313859
Trained batch 448 in epoch 19, gen_loss = 0.839026693511912, disc_loss = 0.07454835147677791
Trained batch 449 in epoch 19, gen_loss = 0.8384379144509634, disc_loss = 0.07458384454664257
Trained batch 450 in epoch 19, gen_loss = 0.8387541732608347, disc_loss = 0.07455630666945964
Trained batch 451 in epoch 19, gen_loss = 0.8388538979059827, disc_loss = 0.07443617397210503
Trained batch 452 in epoch 19, gen_loss = 0.8389140243825007, disc_loss = 0.07432246417892689
Trained batch 453 in epoch 19, gen_loss = 0.8391838399324123, disc_loss = 0.07426029479024432
Trained batch 454 in epoch 19, gen_loss = 0.8392466442925589, disc_loss = 0.07414272454577488
Trained batch 455 in epoch 19, gen_loss = 0.8394996068979564, disc_loss = 0.07400905992018811
Trained batch 456 in epoch 19, gen_loss = 0.8394635212760525, disc_loss = 0.07389043723141338
Trained batch 457 in epoch 19, gen_loss = 0.8391539311304884, disc_loss = 0.07384876183775055
Trained batch 458 in epoch 19, gen_loss = 0.8401172732475796, disc_loss = 0.0738679109818925
Trained batch 459 in epoch 19, gen_loss = 0.8403424520855365, disc_loss = 0.07373609733565346
Trained batch 460 in epoch 19, gen_loss = 0.8401525072317061, disc_loss = 0.07362883204266979
Trained batch 461 in epoch 19, gen_loss = 0.8404624069923963, disc_loss = 0.0734968056894226
Trained batch 462 in epoch 19, gen_loss = 0.8402600876713417, disc_loss = 0.07350765379471604
Trained batch 463 in epoch 19, gen_loss = 0.8396110082494801, disc_loss = 0.07365845900093174
Trained batch 464 in epoch 19, gen_loss = 0.8402491287518573, disc_loss = 0.07357603946039754
Trained batch 465 in epoch 19, gen_loss = 0.8402613201878102, disc_loss = 0.07347599331433426
Trained batch 466 in epoch 19, gen_loss = 0.8400115255880662, disc_loss = 0.0734186837294117
Trained batch 467 in epoch 19, gen_loss = 0.8399096112220715, disc_loss = 0.07334065851238039
Trained batch 468 in epoch 19, gen_loss = 0.8399492255660262, disc_loss = 0.07324506025086207
Trained batch 469 in epoch 19, gen_loss = 0.8404026726458935, disc_loss = 0.0731176009718725
Trained batch 470 in epoch 19, gen_loss = 0.8408549069852079, disc_loss = 0.07311095998497905
Trained batch 471 in epoch 19, gen_loss = 0.840868433400736, disc_loss = 0.07309808041032215
Trained batch 472 in epoch 19, gen_loss = 0.8408980243553823, disc_loss = 0.07302946715869686
Trained batch 473 in epoch 19, gen_loss = 0.841154003948099, disc_loss = 0.07292862504107665
Trained batch 474 in epoch 19, gen_loss = 0.8410363444529082, disc_loss = 0.07287447290593072
Trained batch 475 in epoch 19, gen_loss = 0.8410311182256506, disc_loss = 0.07279922853482246
Trained batch 476 in epoch 19, gen_loss = 0.8411103395795922, disc_loss = 0.07269186510526784
Trained batch 477 in epoch 19, gen_loss = 0.8415443938396965, disc_loss = 0.07258591885097855
Trained batch 478 in epoch 19, gen_loss = 0.8414845246362785, disc_loss = 0.07251263836044856
Trained batch 479 in epoch 19, gen_loss = 0.8417266717801491, disc_loss = 0.07239190732361749
Trained batch 480 in epoch 19, gen_loss = 0.8425710983187146, disc_loss = 0.07231783061026907
Trained batch 481 in epoch 19, gen_loss = 0.8421405458598711, disc_loss = 0.07234006952803536
Trained batch 482 in epoch 19, gen_loss = 0.8424250355171614, disc_loss = 0.07222709105992169
Trained batch 483 in epoch 19, gen_loss = 0.8429955164016771, disc_loss = 0.07213231052987831
Trained batch 484 in epoch 19, gen_loss = 0.842908559263367, disc_loss = 0.07242421246681016
Trained batch 485 in epoch 19, gen_loss = 0.8429753336396237, disc_loss = 0.07231506458464473
Trained batch 486 in epoch 19, gen_loss = 0.8427524123593277, disc_loss = 0.07229456528868274
Trained batch 487 in epoch 19, gen_loss = 0.8428226189046609, disc_loss = 0.07218913446546944
Trained batch 488 in epoch 19, gen_loss = 0.8431670556039167, disc_loss = 0.07217863808121296
Trained batch 489 in epoch 19, gen_loss = 0.8426348115716662, disc_loss = 0.07214027160816655
Trained batch 490 in epoch 19, gen_loss = 0.8429563891620597, disc_loss = 0.0720933744771114
Trained batch 491 in epoch 19, gen_loss = 0.8427731901164947, disc_loss = 0.07213767023938822
Trained batch 492 in epoch 19, gen_loss = 0.843342093618598, disc_loss = 0.07204574173879309
Trained batch 493 in epoch 19, gen_loss = 0.8437329475213642, disc_loss = 0.07199727812864881
Trained batch 494 in epoch 19, gen_loss = 0.8431702796858971, disc_loss = 0.07201200544156812
Trained batch 495 in epoch 19, gen_loss = 0.8434374322814326, disc_loss = 0.07230681596669339
Trained batch 496 in epoch 19, gen_loss = 0.8430457232703625, disc_loss = 0.07235230029873566
Trained batch 497 in epoch 19, gen_loss = 0.8431184899854851, disc_loss = 0.07231011645247538
Trained batch 498 in epoch 19, gen_loss = 0.8432770693947175, disc_loss = 0.07229275391894376
Trained batch 499 in epoch 19, gen_loss = 0.8434419982433319, disc_loss = 0.07254597597941756
Trained batch 500 in epoch 19, gen_loss = 0.8433564537299607, disc_loss = 0.0724797149536436
Trained batch 501 in epoch 19, gen_loss = 0.8429169080171927, disc_loss = 0.07272436395955395
Trained batch 502 in epoch 19, gen_loss = 0.8437669462048509, disc_loss = 0.07266601647211472
Trained batch 503 in epoch 19, gen_loss = 0.8440892166561551, disc_loss = 0.07257578514945058
Trained batch 504 in epoch 19, gen_loss = 0.8439853383763002, disc_loss = 0.0725823043928583
Trained batch 505 in epoch 19, gen_loss = 0.8436759055367572, disc_loss = 0.07252326827466841
Trained batch 506 in epoch 19, gen_loss = 0.8436151749988985, disc_loss = 0.07242418211357599
Trained batch 507 in epoch 19, gen_loss = 0.8440480858791531, disc_loss = 0.07231131713749386
Trained batch 508 in epoch 19, gen_loss = 0.8440888721956954, disc_loss = 0.07221700805138745
Trained batch 509 in epoch 19, gen_loss = 0.8439848806343827, disc_loss = 0.07215271703168458
Trained batch 510 in epoch 19, gen_loss = 0.8437645648790199, disc_loss = 0.07210068426545119
Trained batch 511 in epoch 19, gen_loss = 0.8441479465691373, disc_loss = 0.07209153177973349
Trained batch 512 in epoch 19, gen_loss = 0.8441733013816745, disc_loss = 0.07199542736362295
Trained batch 513 in epoch 19, gen_loss = 0.8440020460099098, disc_loss = 0.07196154517161475
Trained batch 514 in epoch 19, gen_loss = 0.8446012485374524, disc_loss = 0.07187788260793224
Trained batch 515 in epoch 19, gen_loss = 0.8439345514589502, disc_loss = 0.07202890394038933
Trained batch 516 in epoch 19, gen_loss = 0.844433084677912, disc_loss = 0.07197774125972846
Trained batch 517 in epoch 19, gen_loss = 0.844545546300623, disc_loss = 0.07187565050041123
Trained batch 518 in epoch 19, gen_loss = 0.8451109530838469, disc_loss = 0.07177500621288269
Trained batch 519 in epoch 19, gen_loss = 0.8446738136502413, disc_loss = 0.07178294614960368
Trained batch 520 in epoch 19, gen_loss = 0.8450779131186443, disc_loss = 0.0717830022228542
Trained batch 521 in epoch 19, gen_loss = 0.8447502295404559, disc_loss = 0.0717539046659095
Trained batch 522 in epoch 19, gen_loss = 0.8453739005110688, disc_loss = 0.07179375427345928
Trained batch 523 in epoch 19, gen_loss = 0.8450804697420761, disc_loss = 0.07176947262394064
Trained batch 524 in epoch 19, gen_loss = 0.8447898629733495, disc_loss = 0.0717629907102812
Trained batch 525 in epoch 19, gen_loss = 0.8448116541362081, disc_loss = 0.07165699558750419
Trained batch 526 in epoch 19, gen_loss = 0.8451064087634295, disc_loss = 0.0715482427492964
Trained batch 527 in epoch 19, gen_loss = 0.8449394184757363, disc_loss = 0.0715401044775111
Trained batch 528 in epoch 19, gen_loss = 0.8449522443890346, disc_loss = 0.07149903250713824
Trained batch 529 in epoch 19, gen_loss = 0.8451606888816042, disc_loss = 0.07138853566721082
Trained batch 530 in epoch 19, gen_loss = 0.8453027527435576, disc_loss = 0.07139804726554232
Trained batch 531 in epoch 19, gen_loss = 0.8451939419023973, disc_loss = 0.071348726870212
Trained batch 532 in epoch 19, gen_loss = 0.8449585699453587, disc_loss = 0.0713230475283614
Trained batch 533 in epoch 19, gen_loss = 0.8454012069362826, disc_loss = 0.07132358734115735
Trained batch 534 in epoch 19, gen_loss = 0.8453131752593495, disc_loss = 0.0712572416081746
Trained batch 535 in epoch 19, gen_loss = 0.8450296870363292, disc_loss = 0.07122003108631375
Trained batch 536 in epoch 19, gen_loss = 0.845077611436613, disc_loss = 0.07116339301076514
Trained batch 537 in epoch 19, gen_loss = 0.8450849007496604, disc_loss = 0.07108842292939033
Trained batch 538 in epoch 19, gen_loss = 0.8453066675251623, disc_loss = 0.07099873970862278
Trained batch 539 in epoch 19, gen_loss = 0.8457075828755344, disc_loss = 0.07090647013823467
Trained batch 540 in epoch 19, gen_loss = 0.8457977700145319, disc_loss = 0.07081352028472421
Trained batch 541 in epoch 19, gen_loss = 0.8457139377444433, disc_loss = 0.07078015429184281
Trained batch 542 in epoch 19, gen_loss = 0.8458132927149918, disc_loss = 0.07067785713423737
Trained batch 543 in epoch 19, gen_loss = 0.8458994395811769, disc_loss = 0.07057008495972053
Trained batch 544 in epoch 19, gen_loss = 0.8455873958561398, disc_loss = 0.07059655231380955
Trained batch 545 in epoch 19, gen_loss = 0.8456784049014905, disc_loss = 0.07049055381135626
Trained batch 546 in epoch 19, gen_loss = 0.8454844486342924, disc_loss = 0.07043777718813153
Trained batch 547 in epoch 19, gen_loss = 0.8460529360675464, disc_loss = 0.07038478398981103
Trained batch 548 in epoch 19, gen_loss = 0.8466778297676197, disc_loss = 0.07035325760724115
Trained batch 549 in epoch 19, gen_loss = 0.8463310762968931, disc_loss = 0.07036103397607803
Trained batch 550 in epoch 19, gen_loss = 0.8461733608626627, disc_loss = 0.0703240042102748
Trained batch 551 in epoch 19, gen_loss = 0.8461841582388118, disc_loss = 0.07030817735400322
Trained batch 552 in epoch 19, gen_loss = 0.8462409184164423, disc_loss = 0.07056612346260716
Trained batch 553 in epoch 19, gen_loss = 0.8458691297455385, disc_loss = 0.07069236248570229
Trained batch 554 in epoch 19, gen_loss = 0.8461415951316421, disc_loss = 0.0706299607616824
Trained batch 555 in epoch 19, gen_loss = 0.8460872588183382, disc_loss = 0.07057711032467137
Trained batch 556 in epoch 19, gen_loss = 0.845985711369951, disc_loss = 0.07053878383721013
Trained batch 557 in epoch 19, gen_loss = 0.8458941487001261, disc_loss = 0.07046744255115375
Trained batch 558 in epoch 19, gen_loss = 0.8457707121888299, disc_loss = 0.07039383239710907
Trained batch 559 in epoch 19, gen_loss = 0.8461710240159716, disc_loss = 0.07032801392488182
Trained batch 560 in epoch 19, gen_loss = 0.8463057795947886, disc_loss = 0.07027015973832093
Trained batch 561 in epoch 19, gen_loss = 0.8461457997878675, disc_loss = 0.0702232996406186
Trained batch 562 in epoch 19, gen_loss = 0.8463334920774768, disc_loss = 0.07016273883715617
Trained batch 563 in epoch 19, gen_loss = 0.8463753527360605, disc_loss = 0.07005875276943259
Trained batch 564 in epoch 19, gen_loss = 0.8462706938254094, disc_loss = 0.07000854084581401
Trained batch 565 in epoch 19, gen_loss = 0.8465907094546005, disc_loss = 0.06990368757726026
Trained batch 566 in epoch 19, gen_loss = 0.8465493412875624, disc_loss = 0.06987102809353901
Trained batch 567 in epoch 19, gen_loss = 0.8461829285386583, disc_loss = 0.06981665722396173
Trained batch 568 in epoch 19, gen_loss = 0.846732928589484, disc_loss = 0.06993654488155418
Trained batch 569 in epoch 19, gen_loss = 0.8470752078190185, disc_loss = 0.06989331342802758
Trained batch 570 in epoch 19, gen_loss = 0.8468660969032715, disc_loss = 0.07001927067670848
Trained batch 571 in epoch 19, gen_loss = 0.846381075419746, disc_loss = 0.07000133901235316
Trained batch 572 in epoch 19, gen_loss = 0.847356695675309, disc_loss = 0.07015125170662141
Trained batch 573 in epoch 19, gen_loss = 0.8472305874791295, disc_loss = 0.07008454428810483
Trained batch 574 in epoch 19, gen_loss = 0.8470644619153893, disc_loss = 0.07001413964706918
Trained batch 575 in epoch 19, gen_loss = 0.8468831149447296, disc_loss = 0.07001096453879857
Trained batch 576 in epoch 19, gen_loss = 0.8470921986437753, disc_loss = 0.06991211292003015
Trained batch 577 in epoch 19, gen_loss = 0.8471811196177064, disc_loss = 0.06981163820941452
Trained batch 578 in epoch 19, gen_loss = 0.8471247331466082, disc_loss = 0.06975290800456041
Trained batch 579 in epoch 19, gen_loss = 0.8471287693442969, disc_loss = 0.06970361916605254
Trained batch 580 in epoch 19, gen_loss = 0.8471772631761745, disc_loss = 0.06964629829866033
Trained batch 581 in epoch 19, gen_loss = 0.8477231731119844, disc_loss = 0.06955800660889071
Trained batch 582 in epoch 19, gen_loss = 0.8474486208493672, disc_loss = 0.06958580850008524
Trained batch 583 in epoch 19, gen_loss = 0.8476318729250398, disc_loss = 0.069485902247236
Trained batch 584 in epoch 19, gen_loss = 0.8479973919371254, disc_loss = 0.06941799794952584
Trained batch 585 in epoch 19, gen_loss = 0.8482170282980688, disc_loss = 0.06936126963613688
Trained batch 586 in epoch 19, gen_loss = 0.8479897606311908, disc_loss = 0.06937031540226388
Trained batch 587 in epoch 19, gen_loss = 0.8483442244481068, disc_loss = 0.06927559568489693
Trained batch 588 in epoch 19, gen_loss = 0.8484514242319583, disc_loss = 0.06917737171382775
Trained batch 589 in epoch 19, gen_loss = 0.8490660943217196, disc_loss = 0.06912095186821485
Trained batch 590 in epoch 19, gen_loss = 0.8487328961617652, disc_loss = 0.06915818684294744
Trained batch 591 in epoch 19, gen_loss = 0.8491643335972283, disc_loss = 0.06906706345664035
Trained batch 592 in epoch 19, gen_loss = 0.8490910238600501, disc_loss = 0.0690139886824191
Trained batch 593 in epoch 19, gen_loss = 0.8495998565195385, disc_loss = 0.06892693067057315
Trained batch 594 in epoch 19, gen_loss = 0.8497633379046656, disc_loss = 0.06891192080562605
Trained batch 595 in epoch 19, gen_loss = 0.8498015304739843, disc_loss = 0.06889722054205435
Trained batch 596 in epoch 19, gen_loss = 0.8496025193676078, disc_loss = 0.06898673575596144
Trained batch 597 in epoch 19, gen_loss = 0.8497560373118092, disc_loss = 0.06911517847111343
Trained batch 598 in epoch 19, gen_loss = 0.8501753868762161, disc_loss = 0.06914908264006468
Trained batch 599 in epoch 19, gen_loss = 0.8499039200941721, disc_loss = 0.06913791187573225
Trained batch 600 in epoch 19, gen_loss = 0.8501142484574469, disc_loss = 0.06905208350610167
Trained batch 601 in epoch 19, gen_loss = 0.8503945811444342, disc_loss = 0.06899069821882832
Trained batch 602 in epoch 19, gen_loss = 0.8507902057807442, disc_loss = 0.06895214635384567
Trained batch 603 in epoch 19, gen_loss = 0.850499954938099, disc_loss = 0.06896396533783451
Trained batch 604 in epoch 19, gen_loss = 0.8505053950735361, disc_loss = 0.06887594674336762
Trained batch 605 in epoch 19, gen_loss = 0.8502794790385974, disc_loss = 0.06881303178060419
Trained batch 606 in epoch 19, gen_loss = 0.8506016278581132, disc_loss = 0.06876512979735702
Trained batch 607 in epoch 19, gen_loss = 0.8508488809395778, disc_loss = 0.06866897697756558
Trained batch 608 in epoch 19, gen_loss = 0.850933824756071, disc_loss = 0.06861727632741231
Trained batch 609 in epoch 19, gen_loss = 0.8510292502700305, disc_loss = 0.06855692835982706
Trained batch 610 in epoch 19, gen_loss = 0.8510131262328152, disc_loss = 0.06848077334573344
Trained batch 611 in epoch 19, gen_loss = 0.8517895851259917, disc_loss = 0.06860219572786412
Trained batch 612 in epoch 19, gen_loss = 0.8515513093008692, disc_loss = 0.06859404716464473
Trained batch 613 in epoch 19, gen_loss = 0.8514881815506503, disc_loss = 0.06857010728227587
Trained batch 614 in epoch 19, gen_loss = 0.8516189681805246, disc_loss = 0.06857053956122902
Trained batch 615 in epoch 19, gen_loss = 0.8514758116239077, disc_loss = 0.06855360664693373
Trained batch 616 in epoch 19, gen_loss = 0.8513692683107076, disc_loss = 0.06857177464825794
Trained batch 617 in epoch 19, gen_loss = 0.8515815510140268, disc_loss = 0.06848755846264197
Trained batch 618 in epoch 19, gen_loss = 0.8523377267725055, disc_loss = 0.06902709599397776
Trained batch 619 in epoch 19, gen_loss = 0.8518399229934138, disc_loss = 0.06950200374027894
Trained batch 620 in epoch 19, gen_loss = 0.851951241877152, disc_loss = 0.0694143614805215
Trained batch 621 in epoch 19, gen_loss = 0.8521225241602809, disc_loss = 0.06943715375419886
Trained batch 622 in epoch 19, gen_loss = 0.8521931080527329, disc_loss = 0.06942111338947692
Trained batch 623 in epoch 19, gen_loss = 0.8518234727283319, disc_loss = 0.06947986546676987
Trained batch 624 in epoch 19, gen_loss = 0.8515969826698303, disc_loss = 0.06944522895514965
Trained batch 625 in epoch 19, gen_loss = 0.8521669327070157, disc_loss = 0.06964935266826384
Trained batch 626 in epoch 19, gen_loss = 0.8521628527169782, disc_loss = 0.06959117648668552
Trained batch 627 in epoch 19, gen_loss = 0.8521221968208909, disc_loss = 0.06953984286315787
Trained batch 628 in epoch 19, gen_loss = 0.8521200066909123, disc_loss = 0.06945626301741278
Trained batch 629 in epoch 19, gen_loss = 0.8518947817976512, disc_loss = 0.06939703742012618
Trained batch 630 in epoch 19, gen_loss = 0.8525625250985619, disc_loss = 0.0694077305300914
Trained batch 631 in epoch 19, gen_loss = 0.852348162686523, disc_loss = 0.06933690604305814
Trained batch 632 in epoch 19, gen_loss = 0.8523069742543249, disc_loss = 0.06930784418837625
Trained batch 633 in epoch 19, gen_loss = 0.8521395386769568, disc_loss = 0.06930912040726338
Trained batch 634 in epoch 19, gen_loss = 0.8524959568902264, disc_loss = 0.06921583021015633
Trained batch 635 in epoch 19, gen_loss = 0.8523529240357801, disc_loss = 0.06933987092625045
Trained batch 636 in epoch 19, gen_loss = 0.8522388921053481, disc_loss = 0.06926502066326666
Trained batch 637 in epoch 19, gen_loss = 0.8519534374292368, disc_loss = 0.06923869594371057
Trained batch 638 in epoch 19, gen_loss = 0.852048054174265, disc_loss = 0.069188509200567
Trained batch 639 in epoch 19, gen_loss = 0.8521453704684973, disc_loss = 0.06909984872909262
Trained batch 640 in epoch 19, gen_loss = 0.8520231221841762, disc_loss = 0.06908439410132662
Trained batch 641 in epoch 19, gen_loss = 0.8519524709086552, disc_loss = 0.06900987056928261
Trained batch 642 in epoch 19, gen_loss = 0.8519439768642882, disc_loss = 0.0689409926104972
Trained batch 643 in epoch 19, gen_loss = 0.8520318933340333, disc_loss = 0.06888953342987514
Trained batch 644 in epoch 19, gen_loss = 0.8519289287485817, disc_loss = 0.0688313450173352
Trained batch 645 in epoch 19, gen_loss = 0.8522258023543993, disc_loss = 0.06876018230483259
Trained batch 646 in epoch 19, gen_loss = 0.8526638122577755, disc_loss = 0.06874707738481681
Trained batch 647 in epoch 19, gen_loss = 0.852301894698614, disc_loss = 0.06880588383402353
Trained batch 648 in epoch 19, gen_loss = 0.8521465966808043, disc_loss = 0.06879880910707732
Trained batch 649 in epoch 19, gen_loss = 0.8525528027461126, disc_loss = 0.0687567145549334
Trained batch 650 in epoch 19, gen_loss = 0.8524639203618016, disc_loss = 0.0687179097794168
Trained batch 651 in epoch 19, gen_loss = 0.8526584707154818, disc_loss = 0.06864442303205377
Trained batch 652 in epoch 19, gen_loss = 0.8526224621769846, disc_loss = 0.06860152009595043
Trained batch 653 in epoch 19, gen_loss = 0.8526977234112743, disc_loss = 0.06859861876507965
Trained batch 654 in epoch 19, gen_loss = 0.8523711090779487, disc_loss = 0.06860440297777416
Trained batch 655 in epoch 19, gen_loss = 0.8520158826396232, disc_loss = 0.06856962110529222
Trained batch 656 in epoch 19, gen_loss = 0.8527574697948845, disc_loss = 0.06862477883356347
Trained batch 657 in epoch 19, gen_loss = 0.8528092708268789, disc_loss = 0.06860325312224927
Trained batch 658 in epoch 19, gen_loss = 0.8524923492816584, disc_loss = 0.06860388039819025
Trained batch 659 in epoch 19, gen_loss = 0.8523097222501581, disc_loss = 0.06859369206834923
Trained batch 660 in epoch 19, gen_loss = 0.8522340893384729, disc_loss = 0.06854688962315647
Trained batch 661 in epoch 19, gen_loss = 0.8528098686404099, disc_loss = 0.06850550394629064
Trained batch 662 in epoch 19, gen_loss = 0.8526854951097594, disc_loss = 0.06847596682079957
Trained batch 663 in epoch 19, gen_loss = 0.8529486219028393, disc_loss = 0.06838698779844331
Trained batch 664 in epoch 19, gen_loss = 0.8530174853210163, disc_loss = 0.06837014842050192
Trained batch 665 in epoch 19, gen_loss = 0.8530934477174604, disc_loss = 0.06834146180595677
Trained batch 666 in epoch 19, gen_loss = 0.8531440133633821, disc_loss = 0.06825771096903925
Trained batch 667 in epoch 19, gen_loss = 0.8532147020280004, disc_loss = 0.0681812148220547
Trained batch 668 in epoch 19, gen_loss = 0.8533826857047944, disc_loss = 0.06809483115632305
Trained batch 669 in epoch 19, gen_loss = 0.8530939336143323, disc_loss = 0.06810732711968359
Trained batch 670 in epoch 19, gen_loss = 0.8532531663842067, disc_loss = 0.06802112761685061
Trained batch 671 in epoch 19, gen_loss = 0.8534209078976086, disc_loss = 0.06795864933519624
Trained batch 672 in epoch 19, gen_loss = 0.8532612678023362, disc_loss = 0.06795643714919443
Trained batch 673 in epoch 19, gen_loss = 0.8533986799794772, disc_loss = 0.06800976645295406
Trained batch 674 in epoch 19, gen_loss = 0.8533667545848422, disc_loss = 0.06795422627004208
Trained batch 675 in epoch 19, gen_loss = 0.8535537432284045, disc_loss = 0.06788378539936032
Trained batch 676 in epoch 19, gen_loss = 0.853673301912305, disc_loss = 0.06779832012973384
Trained batch 677 in epoch 19, gen_loss = 0.8537502971019013, disc_loss = 0.06771862082688858
Trained batch 678 in epoch 19, gen_loss = 0.8536696339215376, disc_loss = 0.06772761866560038
Trained batch 679 in epoch 19, gen_loss = 0.8537290957044152, disc_loss = 0.06766703328775132
Trained batch 680 in epoch 19, gen_loss = 0.853833138680143, disc_loss = 0.06759173084985842
Trained batch 681 in epoch 19, gen_loss = 0.8542569274426904, disc_loss = 0.06757103769201513
Trained batch 682 in epoch 19, gen_loss = 0.8538754223729995, disc_loss = 0.06768693590037644
Trained batch 683 in epoch 19, gen_loss = 0.854095712216974, disc_loss = 0.06765329367236088
Trained batch 684 in epoch 19, gen_loss = 0.854638293189724, disc_loss = 0.06765819855415038
Trained batch 685 in epoch 19, gen_loss = 0.8545078605674099, disc_loss = 0.06767549853413515
Trained batch 686 in epoch 19, gen_loss = 0.8545237640800087, disc_loss = 0.0676087762406733
Trained batch 687 in epoch 19, gen_loss = 0.854181800644065, disc_loss = 0.06765744620176076
Trained batch 688 in epoch 19, gen_loss = 0.8542283904050708, disc_loss = 0.06789959925503966
Trained batch 689 in epoch 19, gen_loss = 0.8545713634594627, disc_loss = 0.06786428776340209
Trained batch 690 in epoch 19, gen_loss = 0.8543720836232264, disc_loss = 0.06790928592212639
Trained batch 691 in epoch 19, gen_loss = 0.8542870488986803, disc_loss = 0.06786807677627815
Trained batch 692 in epoch 19, gen_loss = 0.8543731519498178, disc_loss = 0.0678243532422043
Trained batch 693 in epoch 19, gen_loss = 0.8546411716285288, disc_loss = 0.06775476270884018
Trained batch 694 in epoch 19, gen_loss = 0.8545097764447439, disc_loss = 0.06770760150586101
Trained batch 695 in epoch 19, gen_loss = 0.8542714005914228, disc_loss = 0.06769052434755468
Trained batch 696 in epoch 19, gen_loss = 0.8546336884136009, disc_loss = 0.06766890401990718
Trained batch 697 in epoch 19, gen_loss = 0.8545821876102327, disc_loss = 0.0676055346965192
Trained batch 698 in epoch 19, gen_loss = 0.8546733376123704, disc_loss = 0.06754659921549079
Trained batch 699 in epoch 19, gen_loss = 0.8544947504145759, disc_loss = 0.06748813754213707
Trained batch 700 in epoch 19, gen_loss = 0.8547010398795363, disc_loss = 0.06744847516828188
Trained batch 701 in epoch 19, gen_loss = 0.8549295097504586, disc_loss = 0.06736631884088373
Trained batch 702 in epoch 19, gen_loss = 0.8546773461495151, disc_loss = 0.06738168371584304
Trained batch 703 in epoch 19, gen_loss = 0.8550454936921597, disc_loss = 0.06735587350240993
Trained batch 704 in epoch 19, gen_loss = 0.8551615481681012, disc_loss = 0.06744807575505676
Trained batch 705 in epoch 19, gen_loss = 0.8550239060147964, disc_loss = 0.06740581605678408
Trained batch 706 in epoch 19, gen_loss = 0.8550518990574666, disc_loss = 0.06738628930237034
Trained batch 707 in epoch 19, gen_loss = 0.8551895254749363, disc_loss = 0.06731934410041082
Trained batch 708 in epoch 19, gen_loss = 0.8554839339679993, disc_loss = 0.06725035120216849
Trained batch 709 in epoch 19, gen_loss = 0.8559030887106774, disc_loss = 0.06718192745892095
Trained batch 710 in epoch 19, gen_loss = 0.8558600440139341, disc_loss = 0.06712071867410811
Trained batch 711 in epoch 19, gen_loss = 0.8558924815125679, disc_loss = 0.06704771915565799
Trained batch 712 in epoch 19, gen_loss = 0.8557896643333649, disc_loss = 0.06698592817528384
Trained batch 713 in epoch 19, gen_loss = 0.8556657329994757, disc_loss = 0.06694104132719901
Trained batch 714 in epoch 19, gen_loss = 0.8557309564176973, disc_loss = 0.06690576926290571
Trained batch 715 in epoch 19, gen_loss = 0.8561898256813347, disc_loss = 0.06687133141673643
Trained batch 716 in epoch 19, gen_loss = 0.8561522205836936, disc_loss = 0.06679383228887574
Trained batch 717 in epoch 19, gen_loss = 0.8558260099469454, disc_loss = 0.06687261381064617
Trained batch 718 in epoch 19, gen_loss = 0.856020685363048, disc_loss = 0.06685536451150711
Trained batch 719 in epoch 19, gen_loss = 0.8563109500540628, disc_loss = 0.06678573757203089
Trained batch 720 in epoch 19, gen_loss = 0.8560764568027279, disc_loss = 0.06675237054509033
Trained batch 721 in epoch 19, gen_loss = 0.8558017056734608, disc_loss = 0.06673148612896822
Trained batch 722 in epoch 19, gen_loss = 0.8560220751689842, disc_loss = 0.06671706367577755
Trained batch 723 in epoch 19, gen_loss = 0.8562832762852558, disc_loss = 0.06665416317091462
Trained batch 724 in epoch 19, gen_loss = 0.8562171819292266, disc_loss = 0.06658442620059539
Trained batch 725 in epoch 19, gen_loss = 0.8561029869334429, disc_loss = 0.06663443898838578
Trained batch 726 in epoch 19, gen_loss = 0.85610335532376, disc_loss = 0.0665764300846988
Trained batch 727 in epoch 19, gen_loss = 0.8566009102614371, disc_loss = 0.06658689206936858
Trained batch 728 in epoch 19, gen_loss = 0.8566339758361482, disc_loss = 0.06654823025680864
Trained batch 729 in epoch 19, gen_loss = 0.856310541499151, disc_loss = 0.06666733433734881
Trained batch 730 in epoch 19, gen_loss = 0.8566981780708407, disc_loss = 0.06669563386288616
Trained batch 731 in epoch 19, gen_loss = 0.8567580486255917, disc_loss = 0.06663974777087976
Trained batch 732 in epoch 19, gen_loss = 0.856430598934871, disc_loss = 0.06668691215642802
Trained batch 733 in epoch 19, gen_loss = 0.8561168365809833, disc_loss = 0.06668379580556372
Trained batch 734 in epoch 19, gen_loss = 0.8567553937840624, disc_loss = 0.06690615448517864
Trained batch 735 in epoch 19, gen_loss = 0.8572490093014811, disc_loss = 0.066863301007644
Trained batch 736 in epoch 19, gen_loss = 0.8569897107547465, disc_loss = 0.066953117945301
Trained batch 737 in epoch 19, gen_loss = 0.8570636035950203, disc_loss = 0.06688185601411917
Trained batch 738 in epoch 19, gen_loss = 0.8568884547250358, disc_loss = 0.06685826923264662
Trained batch 739 in epoch 19, gen_loss = 0.8567358831296096, disc_loss = 0.06685206698681656
Trained batch 740 in epoch 19, gen_loss = 0.856682988876595, disc_loss = 0.06680125812654272
Trained batch 741 in epoch 19, gen_loss = 0.8569156285726799, disc_loss = 0.06675604461865485
Trained batch 742 in epoch 19, gen_loss = 0.8563507353312876, disc_loss = 0.06707580764759156
Trained batch 743 in epoch 19, gen_loss = 0.8569041371185292, disc_loss = 0.067125742985887
Trained batch 744 in epoch 19, gen_loss = 0.8569687496895758, disc_loss = 0.06714705015913952
Trained batch 745 in epoch 19, gen_loss = 0.8565604893675438, disc_loss = 0.06721012417261986
Trained batch 746 in epoch 19, gen_loss = 0.8565270335000841, disc_loss = 0.06716446744694488
Trained batch 747 in epoch 19, gen_loss = 0.8564309041927205, disc_loss = 0.06712944544279041
Trained batch 748 in epoch 19, gen_loss = 0.8566004677671935, disc_loss = 0.0671844069767639
Trained batch 749 in epoch 19, gen_loss = 0.8564295508066813, disc_loss = 0.0671580000432829
Trained batch 750 in epoch 19, gen_loss = 0.8561341118876055, disc_loss = 0.06718554417323692
Trained batch 751 in epoch 19, gen_loss = 0.8558438839589028, disc_loss = 0.06715231482063401
Trained batch 752 in epoch 19, gen_loss = 0.8562018403494026, disc_loss = 0.06710375683780408
Trained batch 753 in epoch 19, gen_loss = 0.8560280481289173, disc_loss = 0.06707785559314197
Trained batch 754 in epoch 19, gen_loss = 0.8562025985970403, disc_loss = 0.06706285814304423
Trained batch 755 in epoch 19, gen_loss = 0.8558332947669206, disc_loss = 0.06713609697134604
Trained batch 756 in epoch 19, gen_loss = 0.8559593837043883, disc_loss = 0.06713509095200342
Trained batch 757 in epoch 19, gen_loss = 0.8561910427811907, disc_loss = 0.0670664191902136
Trained batch 758 in epoch 19, gen_loss = 0.8560313866700736, disc_loss = 0.06707791869107717
Trained batch 759 in epoch 19, gen_loss = 0.8558723450491302, disc_loss = 0.06712527560241717
Trained batch 760 in epoch 19, gen_loss = 0.8554618039832949, disc_loss = 0.0672688092852841
Trained batch 761 in epoch 19, gen_loss = 0.8558553162365761, disc_loss = 0.06722098462200501
Trained batch 762 in epoch 19, gen_loss = 0.8559576609656507, disc_loss = 0.06716790091890847
Trained batch 763 in epoch 19, gen_loss = 0.8561334482038209, disc_loss = 0.06711010870533503
Trained batch 764 in epoch 19, gen_loss = 0.8559363545155992, disc_loss = 0.06709387725206957
Trained batch 765 in epoch 19, gen_loss = 0.8555534246229316, disc_loss = 0.06712057734365447
Trained batch 766 in epoch 19, gen_loss = 0.8558504694132948, disc_loss = 0.06709789157987146
Trained batch 767 in epoch 19, gen_loss = 0.8561527621156225, disc_loss = 0.06703720048850907
Trained batch 768 in epoch 19, gen_loss = 0.8560424105243658, disc_loss = 0.06705939299965905
Trained batch 769 in epoch 19, gen_loss = 0.8563484688857933, disc_loss = 0.06715952478373399
Trained batch 770 in epoch 19, gen_loss = 0.8562912906963382, disc_loss = 0.0670951935106311
Trained batch 771 in epoch 19, gen_loss = 0.8560896795339535, disc_loss = 0.06713752554358017
Trained batch 772 in epoch 19, gen_loss = 0.8564194129324515, disc_loss = 0.06707707940110452
Trained batch 773 in epoch 19, gen_loss = 0.8564152468082517, disc_loss = 0.06702776268264159
Trained batch 774 in epoch 19, gen_loss = 0.8563526324302919, disc_loss = 0.06700361994605872
Trained batch 775 in epoch 19, gen_loss = 0.8565035248079251, disc_loss = 0.06700283204104521
Trained batch 776 in epoch 19, gen_loss = 0.856740390088414, disc_loss = 0.06693677684865135
Trained batch 777 in epoch 19, gen_loss = 0.8562083331662156, disc_loss = 0.06722455437398087
Trained batch 778 in epoch 19, gen_loss = 0.8563111446635255, disc_loss = 0.06727061536526535
Trained batch 779 in epoch 19, gen_loss = 0.8562430546833919, disc_loss = 0.06756348036922133
Trained batch 780 in epoch 19, gen_loss = 0.8560472129249085, disc_loss = 0.06759312744258346
Trained batch 781 in epoch 19, gen_loss = 0.8558002987023815, disc_loss = 0.0676092246792677
Trained batch 782 in epoch 19, gen_loss = 0.855820204791438, disc_loss = 0.06757612700668064
Trained batch 783 in epoch 19, gen_loss = 0.8558554079155533, disc_loss = 0.06755639217456574
Trained batch 784 in epoch 19, gen_loss = 0.8557188460781316, disc_loss = 0.06762227911597035
Trained batch 785 in epoch 19, gen_loss = 0.8558860456822179, disc_loss = 0.06768067550914168
Trained batch 786 in epoch 19, gen_loss = 0.8553475424022505, disc_loss = 0.0679283767117346
Trained batch 787 in epoch 19, gen_loss = 0.8555146844556489, disc_loss = 0.06789751053163734
Trained batch 788 in epoch 19, gen_loss = 0.8558522754446787, disc_loss = 0.06788309014913436
Trained batch 789 in epoch 19, gen_loss = 0.855669231203538, disc_loss = 0.06787706418434465
Testing Epoch 19
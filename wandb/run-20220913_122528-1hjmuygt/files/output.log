/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.9894262552261353, disc_loss = 0.4858567714691162
Trained batch 1 in epoch 0, gen_loss = 1.2237910628318787, disc_loss = 0.9011980295181274
Trained batch 2 in epoch 0, gen_loss = 1.0848412315050762, disc_loss = 0.774388055006663
Trained batch 3 in epoch 0, gen_loss = 1.0271174758672714, disc_loss = 0.6570093035697937
Trained batch 4 in epoch 0, gen_loss = 0.9903642416000367, disc_loss = 0.5769002139568329
Trained batch 5 in epoch 0, gen_loss = 0.9573519825935364, disc_loss = 0.5137633631626765
Trained batch 6 in epoch 0, gen_loss = 0.9415823561804635, disc_loss = 0.46332341006823946
Trained batch 7 in epoch 0, gen_loss = 0.9307001531124115, disc_loss = 0.4223371222615242
Trained batch 8 in epoch 0, gen_loss = 0.9245801899168227, disc_loss = 0.3870180572072665
Trained batch 9 in epoch 0, gen_loss = 0.9207180321216584, disc_loss = 0.3573324792087078
Trained batch 10 in epoch 0, gen_loss = 0.9127374887466431, disc_loss = 0.3323917531154372
Trained batch 11 in epoch 0, gen_loss = 0.9038537492354711, disc_loss = 0.3145859818905592
Trained batch 12 in epoch 0, gen_loss = 0.8956684103378882, disc_loss = 0.30222855794888276
Trained batch 13 in epoch 0, gen_loss = 0.8965558792863574, disc_loss = 0.2932367819760527
Trained batch 14 in epoch 0, gen_loss = 0.9020543535550435, disc_loss = 0.2846110160152117
Trained batch 15 in epoch 0, gen_loss = 0.9082713313400745, disc_loss = 0.2737940540537238
Trained batch 16 in epoch 0, gen_loss = 0.9075152909054476, disc_loss = 0.26334694290862365
Trained batch 17 in epoch 0, gen_loss = 0.9030155274603102, disc_loss = 0.25356316856212086
Trained batch 18 in epoch 0, gen_loss = 0.9009798639699033, disc_loss = 0.24426922633459694
Trained batch 19 in epoch 0, gen_loss = 0.9037577331066131, disc_loss = 0.23640738278627396
Trained batch 20 in epoch 0, gen_loss = 0.9008861013821193, disc_loss = 0.2297245068919091
Trained batch 21 in epoch 0, gen_loss = 0.8929264843463898, disc_loss = 0.2257865657183257
Trained batch 22 in epoch 0, gen_loss = 0.8887291421060977, disc_loss = 0.22104371209507404
Trained batch 23 in epoch 0, gen_loss = 0.8794528891642889, disc_loss = 0.22110527474433184
Trained batch 24 in epoch 0, gen_loss = 0.8960547780990601, disc_loss = 0.2239982232451439
Trained batch 25 in epoch 0, gen_loss = 0.8915390968322754, disc_loss = 0.22232249923623526
Trained batch 26 in epoch 0, gen_loss = 0.8816188132321393, disc_loss = 0.22582960653084297
Trained batch 27 in epoch 0, gen_loss = 0.8795668525355202, disc_loss = 0.223934265385781
Trained batch 28 in epoch 0, gen_loss = 0.8774306835799381, disc_loss = 0.2203920013431845
Trained batch 29 in epoch 0, gen_loss = 0.881348184744517, disc_loss = 0.216752161582311
Trained batch 30 in epoch 0, gen_loss = 0.8810719020905033, disc_loss = 0.21261305241815506
Trained batch 31 in epoch 0, gen_loss = 0.8853946961462498, disc_loss = 0.20896016852930188
Trained batch 32 in epoch 0, gen_loss = 0.8877743681271871, disc_loss = 0.20666452926216702
Trained batch 33 in epoch 0, gen_loss = 0.8874016088597915, disc_loss = 0.20370412223479328
Trained batch 34 in epoch 0, gen_loss = 0.8891511525426592, disc_loss = 0.1998326776283128
Trained batch 35 in epoch 0, gen_loss = 0.8922474864456389, disc_loss = 0.19595995441906983
Trained batch 36 in epoch 0, gen_loss = 0.8982635849230999, disc_loss = 0.19227921257953387
Trained batch 37 in epoch 0, gen_loss = 0.9008737818190926, disc_loss = 0.18845316414770327
Trained batch 38 in epoch 0, gen_loss = 0.9039203616288992, disc_loss = 0.18476836755871773
Trained batch 39 in epoch 0, gen_loss = 0.9076135650277137, disc_loss = 0.1813337636180222
Trained batch 40 in epoch 0, gen_loss = 0.9097713828086853, disc_loss = 0.17786714807152748
Trained batch 41 in epoch 0, gen_loss = 0.9161470660141536, disc_loss = 0.1750172549592597
Trained batch 42 in epoch 0, gen_loss = 0.9188995486082032, disc_loss = 0.17312330414735994
Trained batch 43 in epoch 0, gen_loss = 0.9249908775091171, disc_loss = 0.17346290659836747
Trained batch 44 in epoch 0, gen_loss = 0.9294115662574768, disc_loss = 0.17138607129454614
Trained batch 45 in epoch 0, gen_loss = 0.9329533745413241, disc_loss = 0.16878158186116946
Trained batch 46 in epoch 0, gen_loss = 0.9371488588921567, disc_loss = 0.1662618452881245
Trained batch 47 in epoch 0, gen_loss = 0.9418437145650387, disc_loss = 0.16349815965319672
Trained batch 48 in epoch 0, gen_loss = 0.945131468529604, disc_loss = 0.16076070134889106
Trained batch 49 in epoch 0, gen_loss = 0.9473011887073517, disc_loss = 0.1580709606036544
Trained batch 50 in epoch 0, gen_loss = 0.9495470114782745, disc_loss = 0.15546179515327893
Trained batch 51 in epoch 0, gen_loss = 0.9509454564406321, disc_loss = 0.15297668473795056
Trained batch 52 in epoch 0, gen_loss = 0.9540199187566649, disc_loss = 0.15067551896538375
Trained batch 53 in epoch 0, gen_loss = 0.9554210007190704, disc_loss = 0.14835247994159106
Trained batch 54 in epoch 0, gen_loss = 0.9588821508667685, disc_loss = 0.14615929028527302
Trained batch 55 in epoch 0, gen_loss = 0.9623877097453389, disc_loss = 0.14399212938068168
Trained batch 56 in epoch 0, gen_loss = 0.9645477188260931, disc_loss = 0.14193860330341154
Trained batch 57 in epoch 0, gen_loss = 0.9678543857459364, disc_loss = 0.13985174187812313
Trained batch 58 in epoch 0, gen_loss = 0.9707843459258645, disc_loss = 0.1378668557410523
Trained batch 59 in epoch 0, gen_loss = 0.9739923924207687, disc_loss = 0.13593770830581586
Trained batch 60 in epoch 0, gen_loss = 0.9753811916366952, disc_loss = 0.13403787699024208
Trained batch 61 in epoch 0, gen_loss = 0.9769129705044531, disc_loss = 0.1322441747892768
Trained batch 62 in epoch 0, gen_loss = 0.9779311238773285, disc_loss = 0.13048240163969616
Trained batch 63 in epoch 0, gen_loss = 0.9794706171378493, disc_loss = 0.12881485515390523
Trained batch 64 in epoch 0, gen_loss = 0.9812858719092149, disc_loss = 0.12737699090861357
Trained batch 65 in epoch 0, gen_loss = 0.9829603930314382, disc_loss = 0.12584392153516863
Trained batch 66 in epoch 0, gen_loss = 0.9847299189709905, disc_loss = 0.12449714132765335
Trained batch 67 in epoch 0, gen_loss = 0.9864887340980417, disc_loss = 0.1232345072169076
Trained batch 68 in epoch 0, gen_loss = 0.9893102205317953, disc_loss = 0.12209979663400547
Trained batch 69 in epoch 0, gen_loss = 0.9916891651494163, disc_loss = 0.12120486197194882
Trained batch 70 in epoch 0, gen_loss = 0.9939215812884586, disc_loss = 0.12020854607329402
Trained batch 71 in epoch 0, gen_loss = 0.9958149683144357, disc_loss = 0.11893993336707354
Trained batch 72 in epoch 0, gen_loss = 0.9966476184048064, disc_loss = 0.11781505531031791
Trained batch 73 in epoch 0, gen_loss = 0.9969584611622063, disc_loss = 0.11664497449591353
Trained batch 74 in epoch 0, gen_loss = 0.9980785139401753, disc_loss = 0.11538239638010661
Trained batch 75 in epoch 0, gen_loss = 0.9989304424900758, disc_loss = 0.11420657610716789
Trained batch 76 in epoch 0, gen_loss = 1.0003015368015735, disc_loss = 0.1130415526787182
Trained batch 77 in epoch 0, gen_loss = 1.0012854712131696, disc_loss = 0.1118751322516264
Trained batch 78 in epoch 0, gen_loss = 1.0022542318211327, disc_loss = 0.11078984349305872
Trained batch 79 in epoch 0, gen_loss = 1.0028818838298321, disc_loss = 0.10965417143888771
Trained batch 80 in epoch 0, gen_loss = 1.0043830952526611, disc_loss = 0.10869105850104932
Trained batch 81 in epoch 0, gen_loss = 1.0049196125530615, disc_loss = 0.10763150319547915
Trained batch 82 in epoch 0, gen_loss = 1.0063055502362999, disc_loss = 0.10658222946327135
Trained batch 83 in epoch 0, gen_loss = 1.0074831893046696, disc_loss = 0.10551974064271365
Trained batch 84 in epoch 0, gen_loss = 1.0078391909599305, disc_loss = 0.1045152449651676
Trained batch 85 in epoch 0, gen_loss = 1.0084414003893387, disc_loss = 0.10352072134873895
Trained batch 86 in epoch 0, gen_loss = 1.009138120316911, disc_loss = 0.10253891851967094
Trained batch 87 in epoch 0, gen_loss = 1.0097606392069296, disc_loss = 0.10154574110426685
Trained batch 88 in epoch 0, gen_loss = 1.010813587837005, disc_loss = 0.10059165358124825
Trained batch 89 in epoch 0, gen_loss = 1.01100239555041, disc_loss = 0.09966851286590099
Trained batch 90 in epoch 0, gen_loss = 1.0111443243183933, disc_loss = 0.09874297500393547
Trained batch 91 in epoch 0, gen_loss = 1.0117051815209182, disc_loss = 0.09787154221988242
Trained batch 92 in epoch 0, gen_loss = 1.0118397057697337, disc_loss = 0.09699708469692737
Trained batch 93 in epoch 0, gen_loss = 1.0120589320964002, disc_loss = 0.09613795766725819
Trained batch 94 in epoch 0, gen_loss = 1.0131038044628344, disc_loss = 0.09529659777487579
Trained batch 95 in epoch 0, gen_loss = 1.013200160736839, disc_loss = 0.09447724052006379
Trained batch 96 in epoch 0, gen_loss = 1.0132341329584416, disc_loss = 0.09364686207365744
Trained batch 97 in epoch 0, gen_loss = 1.0138738368238722, disc_loss = 0.09283970211803609
Trained batch 98 in epoch 0, gen_loss = 1.0142506342945676, disc_loss = 0.09205774847192294
Trained batch 99 in epoch 0, gen_loss = 1.01470310151577, disc_loss = 0.09126994892954826
Trained batch 100 in epoch 0, gen_loss = 1.015154483884868, disc_loss = 0.09049598968560153
Trained batch 101 in epoch 0, gen_loss = 1.0151656345993865, disc_loss = 0.08972778406870716
Trained batch 102 in epoch 0, gen_loss = 1.0156927612221356, disc_loss = 0.0889952261706145
Trained batch 103 in epoch 0, gen_loss = 1.0158980196485152, disc_loss = 0.08826411788602574
Trained batch 104 in epoch 0, gen_loss = 1.016634536357153, disc_loss = 0.0875314215375554
Trained batch 105 in epoch 0, gen_loss = 1.016617291940833, disc_loss = 0.08682344869692933
Trained batch 106 in epoch 0, gen_loss = 1.016429794168918, disc_loss = 0.0861528698076433
Trained batch 107 in epoch 0, gen_loss = 1.0168247531961512, disc_loss = 0.08548547571559471
Trained batch 108 in epoch 0, gen_loss = 1.0174920515182915, disc_loss = 0.0848194167376795
Trained batch 109 in epoch 0, gen_loss = 1.0176902467554265, disc_loss = 0.08415436879308387
Trained batch 110 in epoch 0, gen_loss = 1.0176859804101892, disc_loss = 0.08349267913548795
Trained batch 111 in epoch 0, gen_loss = 1.0176980974418777, disc_loss = 0.08285377532177206
Trained batch 112 in epoch 0, gen_loss = 1.0176892607612948, disc_loss = 0.0822131033261529
Trained batch 113 in epoch 0, gen_loss = 1.018225974158237, disc_loss = 0.08160302155700169
Trained batch 114 in epoch 0, gen_loss = 1.018342752042024, disc_loss = 0.08099685183361821
Trained batch 115 in epoch 0, gen_loss = 1.0181788339697082, disc_loss = 0.08038807592900662
Trained batch 116 in epoch 0, gen_loss = 1.0185444405955126, disc_loss = 0.07978919214513312
Trained batch 117 in epoch 0, gen_loss = 1.0188715851913064, disc_loss = 0.07921293943773135
Trained batch 118 in epoch 0, gen_loss = 1.0188421201305229, disc_loss = 0.07863717597416219
Trained batch 119 in epoch 0, gen_loss = 1.018923036257426, disc_loss = 0.07807545428319523
Trained batch 120 in epoch 0, gen_loss = 1.0188998919873198, disc_loss = 0.0775208438954447
Trained batch 121 in epoch 0, gen_loss = 1.0191839952937891, disc_loss = 0.07697122074572034
Trained batch 122 in epoch 0, gen_loss = 1.0192182946011303, disc_loss = 0.0764481556806259
Trained batch 123 in epoch 0, gen_loss = 1.0188805441702566, disc_loss = 0.0759200289274656
Trained batch 124 in epoch 0, gen_loss = 1.019519642829895, disc_loss = 0.07539198922365904
Trained batch 125 in epoch 0, gen_loss = 1.0193687563850766, disc_loss = 0.07487094191656936
Trained batch 126 in epoch 0, gen_loss = 1.0193506366624607, disc_loss = 0.07436698217560926
Trained batch 127 in epoch 0, gen_loss = 1.0197139382362366, disc_loss = 0.07386887160828337
Trained batch 128 in epoch 0, gen_loss = 1.0199771195419074, disc_loss = 0.07338230308260797
Trained batch 129 in epoch 0, gen_loss = 1.0206083050140968, disc_loss = 0.07290708353886237
Trained batch 130 in epoch 0, gen_loss = 1.0207199185859157, disc_loss = 0.07243391193932931
Trained batch 131 in epoch 0, gen_loss = 1.0213163702776937, disc_loss = 0.0719643122671793
Trained batch 132 in epoch 0, gen_loss = 1.0216434718970966, disc_loss = 0.07149148382302514
Trained batch 133 in epoch 0, gen_loss = 1.021529628269708, disc_loss = 0.07103336283436684
Trained batch 134 in epoch 0, gen_loss = 1.0219840473598905, disc_loss = 0.07058819922170154
Trained batch 135 in epoch 0, gen_loss = 1.0219058832701515, disc_loss = 0.07014297055737938
Trained batch 136 in epoch 0, gen_loss = 1.021743036969735, disc_loss = 0.06972547868660985
Trained batch 137 in epoch 0, gen_loss = 1.021665081165839, disc_loss = 0.06930783889053957
Trained batch 138 in epoch 0, gen_loss = 1.0218918242042871, disc_loss = 0.06887843942256283
Trained batch 139 in epoch 0, gen_loss = 1.0222355906452452, disc_loss = 0.0684442506304809
Trained batch 140 in epoch 0, gen_loss = 1.022262136564187, disc_loss = 0.06801569340288216
Trained batch 141 in epoch 0, gen_loss = 1.022067712646135, disc_loss = 0.06759130109009713
Trained batch 142 in epoch 0, gen_loss = 1.0218169026441508, disc_loss = 0.06717973581834377
Trained batch 143 in epoch 0, gen_loss = 1.0216828017599053, disc_loss = 0.06676847528110051
Trained batch 144 in epoch 0, gen_loss = 1.02161690983279, disc_loss = 0.06637441125730502
Trained batch 145 in epoch 0, gen_loss = 1.0214252341283512, disc_loss = 0.06597474942379312
Trained batch 146 in epoch 0, gen_loss = 1.0212119667708468, disc_loss = 0.06559430677633808
Trained batch 147 in epoch 0, gen_loss = 1.0215889541683971, disc_loss = 0.06522495826593021
Trained batch 148 in epoch 0, gen_loss = 1.022133631594229, disc_loss = 0.06484019302844302
Trained batch 149 in epoch 0, gen_loss = 1.0220310119787852, disc_loss = 0.0644604595284909
Trained batch 150 in epoch 0, gen_loss = 1.0219686106340775, disc_loss = 0.06408981818841486
Trained batch 151 in epoch 0, gen_loss = 1.02241589795602, disc_loss = 0.0637464193461806
Trained batch 152 in epoch 0, gen_loss = 1.022418676248563, disc_loss = 0.06338762157456646
Trained batch 153 in epoch 0, gen_loss = 1.023007921971284, disc_loss = 0.06305715696003239
Trained batch 154 in epoch 0, gen_loss = 1.02280074204168, disc_loss = 0.06271575034686154
Trained batch 155 in epoch 0, gen_loss = 1.0225757608811061, disc_loss = 0.06239084404212637
Trained batch 156 in epoch 0, gen_loss = 1.0224408606055435, disc_loss = 0.062064907813124404
Trained batch 157 in epoch 0, gen_loss = 1.022271771596957, disc_loss = 0.06176081021269194
Trained batch 158 in epoch 0, gen_loss = 1.022266688211909, disc_loss = 0.061473733865591525
Trained batch 159 in epoch 0, gen_loss = 1.0224845629185437, disc_loss = 0.06118818615505006
Trained batch 160 in epoch 0, gen_loss = 1.0223401255489135, disc_loss = 0.06088441612939379
Trained batch 161 in epoch 0, gen_loss = 1.0227017825768319, disc_loss = 0.0605714788666156
Trained batch 162 in epoch 0, gen_loss = 1.0222952998488959, disc_loss = 0.06024557200369019
Trained batch 163 in epoch 0, gen_loss = 1.0224323385372394, disc_loss = 0.05993885084384734
Trained batch 164 in epoch 0, gen_loss = 1.0225916223092513, disc_loss = 0.059626097398612535
Trained batch 165 in epoch 0, gen_loss = 1.022677042757172, disc_loss = 0.0593090050780854
Trained batch 166 in epoch 0, gen_loss = 1.022537869250703, disc_loss = 0.0589915912509143
Trained batch 167 in epoch 0, gen_loss = 1.0220132991671562, disc_loss = 0.05867935416643463
Trained batch 168 in epoch 0, gen_loss = 1.0219232566963286, disc_loss = 0.058378072959762176
Trained batch 169 in epoch 0, gen_loss = 1.0218417486723732, disc_loss = 0.0580740594825543
Trained batch 170 in epoch 0, gen_loss = 1.0217589742956106, disc_loss = 0.05777038625926215
Trained batch 171 in epoch 0, gen_loss = 1.0217089164395665, disc_loss = 0.0574782706423511
Trained batch 172 in epoch 0, gen_loss = 1.0221026973917304, disc_loss = 0.05719385351824192
Trained batch 173 in epoch 0, gen_loss = 1.021858765133496, disc_loss = 0.05690016849341149
Trained batch 174 in epoch 0, gen_loss = 1.0216273464475358, disc_loss = 0.05661501917189785
Trained batch 175 in epoch 0, gen_loss = 1.0216350982134992, disc_loss = 0.05633328105481765
Trained batch 176 in epoch 0, gen_loss = 1.0211934009514285, disc_loss = 0.05605674947817194
Trained batch 177 in epoch 0, gen_loss = 1.0206556196293135, disc_loss = 0.05577841322356312
Trained batch 178 in epoch 0, gen_loss = 1.0208590733272402, disc_loss = 0.055504097725530076
Trained batch 179 in epoch 0, gen_loss = 1.0205142196681765, disc_loss = 0.05523362727318373
Trained batch 180 in epoch 0, gen_loss = 1.0203350278554042, disc_loss = 0.05496961591528595
Trained batch 181 in epoch 0, gen_loss = 1.0199866190061464, disc_loss = 0.05470887559292081
Trained batch 182 in epoch 0, gen_loss = 1.0197839160434534, disc_loss = 0.05444690808043128
Trained batch 183 in epoch 0, gen_loss = 1.0201925658013509, disc_loss = 0.05419114053897236
Trained batch 184 in epoch 0, gen_loss = 1.020464907143567, disc_loss = 0.053934464626316285
Trained batch 185 in epoch 0, gen_loss = 1.0203853925710082, disc_loss = 0.0536764880557174
Trained batch 186 in epoch 0, gen_loss = 1.0202169182466314, disc_loss = 0.05341898999799461
Trained batch 187 in epoch 0, gen_loss = 1.0202945882969714, disc_loss = 0.053165045445487696
Trained batch 188 in epoch 0, gen_loss = 1.0203232273222909, disc_loss = 0.052914009358063736
Trained batch 189 in epoch 0, gen_loss = 1.0206960489875392, disc_loss = 0.05267669086736676
Trained batch 190 in epoch 0, gen_loss = 1.020460748547659, disc_loss = 0.05243198664283565
Trained batch 191 in epoch 0, gen_loss = 1.0204303842037916, disc_loss = 0.05219154164175658
Trained batch 192 in epoch 0, gen_loss = 1.0205664338225529, disc_loss = 0.0519507240137288
Trained batch 193 in epoch 0, gen_loss = 1.0210382028953315, disc_loss = 0.051722643875334526
Trained batch 194 in epoch 0, gen_loss = 1.0207806165401752, disc_loss = 0.05149802280685459
Trained batch 195 in epoch 0, gen_loss = 1.0204082441573241, disc_loss = 0.0512824792638231
Trained batch 196 in epoch 0, gen_loss = 1.0200924982274244, disc_loss = 0.05106331321273737
Trained batch 197 in epoch 0, gen_loss = 1.0202990734215938, disc_loss = 0.050843656709831625
Trained batch 198 in epoch 0, gen_loss = 1.0202781944418673, disc_loss = 0.0506263247728535
Trained batch 199 in epoch 0, gen_loss = 1.0201896864175797, disc_loss = 0.05040721222525463
Trained batch 200 in epoch 0, gen_loss = 1.0199817075065118, disc_loss = 0.050184321735721474
Trained batch 201 in epoch 0, gen_loss = 1.0203163411357614, disc_loss = 0.04998387071064277
Trained batch 202 in epoch 0, gen_loss = 1.0204003832023132, disc_loss = 0.04977153786435136
Trained batch 203 in epoch 0, gen_loss = 1.0205646881870194, disc_loss = 0.049563802819808614
Trained batch 204 in epoch 0, gen_loss = 1.0210118421694128, disc_loss = 0.0493573154322803
Trained batch 205 in epoch 0, gen_loss = 1.0208008306697733, disc_loss = 0.04914859449490905
Trained batch 206 in epoch 0, gen_loss = 1.0209014876453197, disc_loss = 0.04895199753865959
Trained batch 207 in epoch 0, gen_loss = 1.021089826638882, disc_loss = 0.048755306540092885
Trained batch 208 in epoch 0, gen_loss = 1.0212652169916618, disc_loss = 0.04855878767000431
Trained batch 209 in epoch 0, gen_loss = 1.0215278131621224, disc_loss = 0.04837244746851779
Trained batch 210 in epoch 0, gen_loss = 1.0215476836073456, disc_loss = 0.048185958783031925
Trained batch 211 in epoch 0, gen_loss = 1.0214028684598095, disc_loss = 0.04799298436451211
Trained batch 212 in epoch 0, gen_loss = 1.0213828019692863, disc_loss = 0.04779670579673748
Trained batch 213 in epoch 0, gen_loss = 1.021735916070849, disc_loss = 0.04760025091095018
Trained batch 214 in epoch 0, gen_loss = 1.0217820139818414, disc_loss = 0.047409267652086744
Trained batch 215 in epoch 0, gen_loss = 1.0215454134676192, disc_loss = 0.04721935619643234
Trained batch 216 in epoch 0, gen_loss = 1.021504609815536, disc_loss = 0.047027079201805565
Trained batch 217 in epoch 0, gen_loss = 1.0212224492239297, disc_loss = 0.04683269167301852
Trained batch 218 in epoch 0, gen_loss = 1.0211361325494774, disc_loss = 0.04664265763303733
Trained batch 219 in epoch 0, gen_loss = 1.021112381328236, disc_loss = 0.04645222240466286
Trained batch 220 in epoch 0, gen_loss = 1.0212396572078515, disc_loss = 0.04626779267100862
Trained batch 221 in epoch 0, gen_loss = 1.021102384940998, disc_loss = 0.046083330443162505
Trained batch 222 in epoch 0, gen_loss = 1.0209391229355815, disc_loss = 0.04590334075883098
Trained batch 223 in epoch 0, gen_loss = 1.021083150591169, disc_loss = 0.04572799396243811
Trained batch 224 in epoch 0, gen_loss = 1.0208275890350342, disc_loss = 0.045549549261728925
Trained batch 225 in epoch 0, gen_loss = 1.0208608312944396, disc_loss = 0.04537823140637669
Trained batch 226 in epoch 0, gen_loss = 1.0205364710433893, disc_loss = 0.04520311009442426
Trained batch 227 in epoch 0, gen_loss = 1.0207151906532155, disc_loss = 0.04503463881024927
Trained batch 228 in epoch 0, gen_loss = 1.0206307011400249, disc_loss = 0.04486222948277101
Trained batch 229 in epoch 0, gen_loss = 1.0204983664595562, disc_loss = 0.04469116184981945
Trained batch 230 in epoch 0, gen_loss = 1.0205867295657403, disc_loss = 0.04451718536564411
Trained batch 231 in epoch 0, gen_loss = 1.0204682553122784, disc_loss = 0.044344836619184834
Trained batch 232 in epoch 0, gen_loss = 1.020458010389058, disc_loss = 0.04417650940200482
Trained batch 233 in epoch 0, gen_loss = 1.0199709700213537, disc_loss = 0.0440163405584251
Trained batch 234 in epoch 0, gen_loss = 1.0197965852757718, disc_loss = 0.043855172213404736
Trained batch 235 in epoch 0, gen_loss = 1.020126564270359, disc_loss = 0.043702352454617496
Trained batch 236 in epoch 0, gen_loss = 1.0201517798729587, disc_loss = 0.043544618015959546
Trained batch 237 in epoch 0, gen_loss = 1.0202874553804637, disc_loss = 0.043390160236711134
Trained batch 238 in epoch 0, gen_loss = 1.0200616901888508, disc_loss = 0.043232602252387224
Trained batch 239 in epoch 0, gen_loss = 1.0199808664619923, disc_loss = 0.04307245215362248
Trained batch 240 in epoch 0, gen_loss = 1.0200239264124162, disc_loss = 0.04291150848578306
Trained batch 241 in epoch 0, gen_loss = 1.019939871366359, disc_loss = 0.04275069787351738
Trained batch 242 in epoch 0, gen_loss = 1.0199589763649206, disc_loss = 0.04259614270073151
Trained batch 243 in epoch 0, gen_loss = 1.0202037604128729, disc_loss = 0.04244212709657359
Trained batch 244 in epoch 0, gen_loss = 1.0203887910259013, disc_loss = 0.042290133258745984
Trained batch 245 in epoch 0, gen_loss = 1.0203439113570423, disc_loss = 0.04213737267092234
Trained batch 246 in epoch 0, gen_loss = 1.0203373330807397, disc_loss = 0.041986453842733674
Trained batch 247 in epoch 0, gen_loss = 1.0203557807591654, disc_loss = 0.04183544417197305
Trained batch 248 in epoch 0, gen_loss = 1.0203369257440529, disc_loss = 0.041684076266669964
Trained batch 249 in epoch 0, gen_loss = 1.0203860883712768, disc_loss = 0.041534273372963074
Trained batch 250 in epoch 0, gen_loss = 1.0205848558965431, disc_loss = 0.041385895531787814
Trained batch 251 in epoch 0, gen_loss = 1.0206050962682753, disc_loss = 0.04123808902555278
Trained batch 252 in epoch 0, gen_loss = 1.0205754974614019, disc_loss = 0.041094546176846554
Trained batch 253 in epoch 0, gen_loss = 1.0206146019650257, disc_loss = 0.04094847561754873
Trained batch 254 in epoch 0, gen_loss = 1.0204862994306227, disc_loss = 0.040810613708534074
Trained batch 255 in epoch 0, gen_loss = 1.0204224467743188, disc_loss = 0.040670733085789834
Trained batch 256 in epoch 0, gen_loss = 1.0201463645998141, disc_loss = 0.04053069941576295
Trained batch 257 in epoch 0, gen_loss = 1.019699237605398, disc_loss = 0.04039061045844483
Trained batch 258 in epoch 0, gen_loss = 1.0192768582966336, disc_loss = 0.04025382382083238
Trained batch 259 in epoch 0, gen_loss = 1.019159814256888, disc_loss = 0.04011795533319505
Trained batch 260 in epoch 0, gen_loss = 1.0190141390566625, disc_loss = 0.03997819242870499
Trained batch 261 in epoch 0, gen_loss = 1.0187889019041572, disc_loss = 0.03984156596289507
Trained batch 262 in epoch 0, gen_loss = 1.0188393248351355, disc_loss = 0.03970919564869184
Trained batch 263 in epoch 0, gen_loss = 1.0188357762315057, disc_loss = 0.03957851349806526
Trained batch 264 in epoch 0, gen_loss = 1.0186063435842405, disc_loss = 0.03944508170111562
Trained batch 265 in epoch 0, gen_loss = 1.0183726587241753, disc_loss = 0.03931246472074461
Trained batch 266 in epoch 0, gen_loss = 1.0183111404658256, disc_loss = 0.039182265378074364
Trained batch 267 in epoch 0, gen_loss = 1.018504605586849, disc_loss = 0.039055388452095996
Trained batch 268 in epoch 0, gen_loss = 1.0183152560850945, disc_loss = 0.038933236131160676
Trained batch 269 in epoch 0, gen_loss = 1.0182565788427989, disc_loss = 0.03881343269755167
Trained batch 270 in epoch 0, gen_loss = 1.018445368842445, disc_loss = 0.03869986320189389
Trained batch 271 in epoch 0, gen_loss = 1.0182403674458755, disc_loss = 0.038577252637718204
Trained batch 272 in epoch 0, gen_loss = 1.0180349869605823, disc_loss = 0.038449674020879544
Trained batch 273 in epoch 0, gen_loss = 1.0180920340719015, disc_loss = 0.038324032140297504
Trained batch 274 in epoch 0, gen_loss = 1.0180186210979114, disc_loss = 0.038197658522562544
Trained batch 275 in epoch 0, gen_loss = 1.0179258140100949, disc_loss = 0.03807053250679071
Trained batch 276 in epoch 0, gen_loss = 1.0179001562001473, disc_loss = 0.0379478171810723
Trained batch 277 in epoch 0, gen_loss = 1.0176529997973134, disc_loss = 0.03782782281527845
Trained batch 278 in epoch 0, gen_loss = 1.0177803477506056, disc_loss = 0.03771600578193916
Trained batch 279 in epoch 0, gen_loss = 1.0177989991647856, disc_loss = 0.03760317209609119
Trained batch 280 in epoch 0, gen_loss = 1.017746699450279, disc_loss = 0.03748562491873405
Trained batch 281 in epoch 0, gen_loss = 1.0176908781765202, disc_loss = 0.037366189687605286
Trained batch 282 in epoch 0, gen_loss = 1.0175496160773423, disc_loss = 0.03724778714908991
Trained batch 283 in epoch 0, gen_loss = 1.0173827865174119, disc_loss = 0.03712806712531052
Trained batch 284 in epoch 0, gen_loss = 1.0175605822027776, disc_loss = 0.03701258689867692
Trained batch 285 in epoch 0, gen_loss = 1.017461263008051, disc_loss = 0.036898813118435236
Trained batch 286 in epoch 0, gen_loss = 1.017406479614537, disc_loss = 0.03678743708602928
Trained batch 287 in epoch 0, gen_loss = 1.017446422121591, disc_loss = 0.036674203764252726
Trained batch 288 in epoch 0, gen_loss = 1.0172819808692668, disc_loss = 0.03655983976678195
Trained batch 289 in epoch 0, gen_loss = 1.0170456127873782, disc_loss = 0.03644441301565104
Trained batch 290 in epoch 0, gen_loss = 1.0169192362077457, disc_loss = 0.03632900689622944
Trained batch 291 in epoch 0, gen_loss = 1.0168688523851028, disc_loss = 0.03621496638356491
Trained batch 292 in epoch 0, gen_loss = 1.0168684364992604, disc_loss = 0.036102703136770185
Trained batch 293 in epoch 0, gen_loss = 1.0166223142422786, disc_loss = 0.03599026087326232
Trained batch 294 in epoch 0, gen_loss = 1.0166450165085874, disc_loss = 0.035879278015661036
Trained batch 295 in epoch 0, gen_loss = 1.0166456405375455, disc_loss = 0.03577074027821623
Trained batch 296 in epoch 0, gen_loss = 1.0165613953914707, disc_loss = 0.035661443490974026
Trained batch 297 in epoch 0, gen_loss = 1.0167212982305744, disc_loss = 0.03555781830527238
Trained batch 298 in epoch 0, gen_loss = 1.0167553580325583, disc_loss = 0.03545275858812109
Trained batch 299 in epoch 0, gen_loss = 1.0167352942625683, disc_loss = 0.03534718731883913
Trained batch 300 in epoch 0, gen_loss = 1.016726540568659, disc_loss = 0.03524200880568957
Trained batch 301 in epoch 0, gen_loss = 1.0165205270249322, disc_loss = 0.03513717032592768
Trained batch 302 in epoch 0, gen_loss = 1.0162235022378046, disc_loss = 0.03503261965149307
Trained batch 303 in epoch 0, gen_loss = 1.0162601804262714, disc_loss = 0.034931414128023835
Trained batch 304 in epoch 0, gen_loss = 1.0160494775068565, disc_loss = 0.034827948681491076
Trained batch 305 in epoch 0, gen_loss = 1.0160001050802618, disc_loss = 0.034728787400382356
Trained batch 306 in epoch 0, gen_loss = 1.015835150833627, disc_loss = 0.034630594475510305
Trained batch 307 in epoch 0, gen_loss = 1.015905180147716, disc_loss = 0.03453257245952022
Trained batch 308 in epoch 0, gen_loss = 1.0157680004159995, disc_loss = 0.03443609858549601
Trained batch 309 in epoch 0, gen_loss = 1.0156334104076508, disc_loss = 0.03433594055278527
Trained batch 310 in epoch 0, gen_loss = 1.015804996827791, disc_loss = 0.03423772659527072
Trained batch 311 in epoch 0, gen_loss = 1.0158096494582982, disc_loss = 0.03414091273757199
Trained batch 312 in epoch 0, gen_loss = 1.0159319639205933, disc_loss = 0.034048718692639625
Trained batch 313 in epoch 0, gen_loss = 1.0158662298682388, disc_loss = 0.03395429098234174
Trained batch 314 in epoch 0, gen_loss = 1.0157182515613616, disc_loss = 0.033856358287471626
Trained batch 315 in epoch 0, gen_loss = 1.0155787284992919, disc_loss = 0.033757721647160434
Trained batch 316 in epoch 0, gen_loss = 1.0155341134462448, disc_loss = 0.03366346481588173
Trained batch 317 in epoch 0, gen_loss = 1.0156833621315986, disc_loss = 0.03357432171140077
Trained batch 318 in epoch 0, gen_loss = 1.01555202915377, disc_loss = 0.03348619771718418
Trained batch 319 in epoch 0, gen_loss = 1.0155078509822488, disc_loss = 0.033400168892694634
Trained batch 320 in epoch 0, gen_loss = 1.015266999091686, disc_loss = 0.03331469035072026
Trained batch 321 in epoch 0, gen_loss = 1.0151130436740308, disc_loss = 0.03322613123885315
Trained batch 322 in epoch 0, gen_loss = 1.0150714649504553, disc_loss = 0.033135886108012574
Trained batch 323 in epoch 0, gen_loss = 1.0147198922472236, disc_loss = 0.03304254246033429
Trained batch 324 in epoch 0, gen_loss = 1.0146780111239506, disc_loss = 0.03295254090442681
Trained batch 325 in epoch 0, gen_loss = 1.0149173877356243, disc_loss = 0.03286678269234103
Trained batch 326 in epoch 0, gen_loss = 1.0147200212201577, disc_loss = 0.03277384658167509
Trained batch 327 in epoch 0, gen_loss = 1.0144277756533973, disc_loss = 0.03268195025796048
Trained batch 328 in epoch 0, gen_loss = 1.0145468027033704, disc_loss = 0.032593178183497086
Trained batch 329 in epoch 0, gen_loss = 1.0144429353150455, disc_loss = 0.032503001522413935
Trained batch 330 in epoch 0, gen_loss = 1.0144952094446857, disc_loss = 0.03241611697663218
Trained batch 331 in epoch 0, gen_loss = 1.0142929631184383, disc_loss = 0.03233369826395289
Trained batch 332 in epoch 0, gen_loss = 1.0143311358428933, disc_loss = 0.03225129419328035
Trained batch 333 in epoch 0, gen_loss = 1.0142688610239656, disc_loss = 0.0321670479927502
Trained batch 334 in epoch 0, gen_loss = 1.0139509558677673, disc_loss = 0.03208229552203817
Trained batch 335 in epoch 0, gen_loss = 1.0138447201322942, disc_loss = 0.03199840564047918
Trained batch 336 in epoch 0, gen_loss = 1.0138019353416623, disc_loss = 0.03191408618748497
Trained batch 337 in epoch 0, gen_loss = 1.0136192171178626, disc_loss = 0.031832223701615925
Trained batch 338 in epoch 0, gen_loss = 1.0135587413402434, disc_loss = 0.031749149993237843
Trained batch 339 in epoch 0, gen_loss = 1.013663543497815, disc_loss = 0.03166616013931001
Trained batch 340 in epoch 0, gen_loss = 1.013546888954129, disc_loss = 0.031581667783093854
Trained batch 341 in epoch 0, gen_loss = 1.0134191896483216, disc_loss = 0.03149733007939979
Trained batch 342 in epoch 0, gen_loss = 1.0133043776100648, disc_loss = 0.03141614332260244
Trained batch 343 in epoch 0, gen_loss = 1.0133025464276935, disc_loss = 0.03133528314593118
Trained batch 344 in epoch 0, gen_loss = 1.013057503665703, disc_loss = 0.031254891463406924
Trained batch 345 in epoch 0, gen_loss = 1.0128530406882996, disc_loss = 0.03117375515301771
Trained batch 346 in epoch 0, gen_loss = 1.0126335253289522, disc_loss = 0.03109151043295753
Trained batch 347 in epoch 0, gen_loss = 1.0126433307412026, disc_loss = 0.031010800198485924
Trained batch 348 in epoch 0, gen_loss = 1.0125215560795584, disc_loss = 0.03093096117200837
Trained batch 349 in epoch 0, gen_loss = 1.012283617087773, disc_loss = 0.030851811050171297
Trained batch 350 in epoch 0, gen_loss = 1.0121937373764494, disc_loss = 0.030773303827716626
Trained batch 351 in epoch 0, gen_loss = 1.0125096438621932, disc_loss = 0.030700443285406272
Trained batch 352 in epoch 0, gen_loss = 1.012465198891021, disc_loss = 0.030621512054937967
Trained batch 353 in epoch 0, gen_loss = 1.0124478601129716, disc_loss = 0.030543974689523672
Trained batch 354 in epoch 0, gen_loss = 1.0122552576199384, disc_loss = 0.030466783855398985
Trained batch 355 in epoch 0, gen_loss = 1.0121727476963835, disc_loss = 0.03039003533554483
Trained batch 356 in epoch 0, gen_loss = 1.0123503670639016, disc_loss = 0.030315257203882607
Trained batch 357 in epoch 0, gen_loss = 1.01211360463217, disc_loss = 0.030238041870800685
Trained batch 358 in epoch 0, gen_loss = 1.011940982182378, disc_loss = 0.030162705616340622
Trained batch 359 in epoch 0, gen_loss = 1.011735954052872, disc_loss = 0.03008478851665536
Trained batch 360 in epoch 0, gen_loss = 1.0115510078348282, disc_loss = 0.030006744067501947
Trained batch 361 in epoch 0, gen_loss = 1.011596798732136, disc_loss = 0.029931522104426067
Trained batch 362 in epoch 0, gen_loss = 1.0114889217145515, disc_loss = 0.029859203743920263
Trained batch 363 in epoch 0, gen_loss = 1.011220884519619, disc_loss = 0.02978492223857237
Trained batch 364 in epoch 0, gen_loss = 1.0109694781368725, disc_loss = 0.029710839586715176
Trained batch 365 in epoch 0, gen_loss = 1.010979238429356, disc_loss = 0.029637234191323726
Trained batch 366 in epoch 0, gen_loss = 1.0110991027114826, disc_loss = 0.029564499397627623
Trained batch 367 in epoch 0, gen_loss = 1.0110204035173291, disc_loss = 0.029491113981550923
Trained batch 368 in epoch 0, gen_loss = 1.0110754685673287, disc_loss = 0.02941837500803536
Trained batch 369 in epoch 0, gen_loss = 1.0107029262426737, disc_loss = 0.02936146034343118
Trained batch 370 in epoch 0, gen_loss = 1.010483996244775, disc_loss = 0.02931634265982177
Trained batch 371 in epoch 0, gen_loss = 1.0104472970449796, disc_loss = 0.029265543266314694
Trained batch 372 in epoch 0, gen_loss = 1.010463788106678, disc_loss = 0.029203684071088885
Trained batch 373 in epoch 0, gen_loss = 1.0102438268495753, disc_loss = 0.02913497793139581
Trained batch 374 in epoch 0, gen_loss = 1.0104570552508036, disc_loss = 0.029070553582161665
Trained batch 375 in epoch 0, gen_loss = 1.0103008493464043, disc_loss = 0.029002723645696296
Trained batch 376 in epoch 0, gen_loss = 1.010177756810378, disc_loss = 0.028931126005908064
Trained batch 377 in epoch 0, gen_loss = 1.010265173735442, disc_loss = 0.028861976213871487
Trained batch 378 in epoch 0, gen_loss = 1.0103328341229925, disc_loss = 0.028794121014391685
Trained batch 379 in epoch 0, gen_loss = 1.010221183613727, disc_loss = 0.02872673849893832
Trained batch 380 in epoch 0, gen_loss = 1.0099857488642214, disc_loss = 0.028658602680654077
Trained batch 381 in epoch 0, gen_loss = 1.00989536137481, disc_loss = 0.02858985916111638
Trained batch 382 in epoch 0, gen_loss = 1.0099299565619029, disc_loss = 0.028521442957290546
Trained batch 383 in epoch 0, gen_loss = 1.01007731553788, disc_loss = 0.028455202097878402
Trained batch 384 in epoch 0, gen_loss = 1.0100254159469109, disc_loss = 0.028390342101769207
Trained batch 385 in epoch 0, gen_loss = 1.0099073974270896, disc_loss = 0.028324941830067785
Trained batch 386 in epoch 0, gen_loss = 1.009963514114843, disc_loss = 0.028258962298620693
Trained batch 387 in epoch 0, gen_loss = 1.0098663782028807, disc_loss = 0.028194230025245317
Trained batch 388 in epoch 0, gen_loss = 1.0097818849632243, disc_loss = 0.028130410617973972
Trained batch 389 in epoch 0, gen_loss = 1.0095420958139958, disc_loss = 0.02806924684988096
Trained batch 390 in epoch 0, gen_loss = 1.009288634790484, disc_loss = 0.028005425800995715
Trained batch 391 in epoch 0, gen_loss = 1.0095559483279988, disc_loss = 0.02794326745491589
Trained batch 392 in epoch 0, gen_loss = 1.0095682053165582, disc_loss = 0.027879010640681927
Trained batch 393 in epoch 0, gen_loss = 1.0094393706563765, disc_loss = 0.02781614872359855
Trained batch 394 in epoch 0, gen_loss = 1.009315659275538, disc_loss = 0.027752427132564445
Trained batch 395 in epoch 0, gen_loss = 1.0092085353051774, disc_loss = 0.027691509767501343
Trained batch 396 in epoch 0, gen_loss = 1.0092136457524912, disc_loss = 0.027629317604333764
Trained batch 397 in epoch 0, gen_loss = 1.0091147305977404, disc_loss = 0.027566012867314544
Trained batch 398 in epoch 0, gen_loss = 1.0091202226199005, disc_loss = 0.027503271046839188
Trained batch 399 in epoch 0, gen_loss = 1.0089772577583789, disc_loss = 0.027441359473741614
Trained batch 400 in epoch 0, gen_loss = 1.008953233014913, disc_loss = 0.027379660178533292
Trained batch 401 in epoch 0, gen_loss = 1.008706586870981, disc_loss = 0.02731822701217375
Trained batch 402 in epoch 0, gen_loss = 1.0086431059588865, disc_loss = 0.027258139798098772
Trained batch 403 in epoch 0, gen_loss = 1.0085053075068067, disc_loss = 0.02719754361579803
Trained batch 404 in epoch 0, gen_loss = 1.0083615017525944, disc_loss = 0.027137088691700756
Trained batch 405 in epoch 0, gen_loss = 1.0084554582393814, disc_loss = 0.02707736347767575
Trained batch 406 in epoch 0, gen_loss = 1.0083061184285607, disc_loss = 0.027016051337283097
Trained batch 407 in epoch 0, gen_loss = 1.0084208775969112, disc_loss = 0.02695525092684536
Trained batch 408 in epoch 0, gen_loss = 1.0083504466380933, disc_loss = 0.02689359559105996
Trained batch 409 in epoch 0, gen_loss = 1.0081461275496133, disc_loss = 0.02683271605169355
Trained batch 410 in epoch 0, gen_loss = 1.0080495373756055, disc_loss = 0.026772405207270436
Trained batch 411 in epoch 0, gen_loss = 1.0079176859948242, disc_loss = 0.026712119555862585
Trained batch 412 in epoch 0, gen_loss = 1.007674718018594, disc_loss = 0.026651316730262706
Trained batch 413 in epoch 0, gen_loss = 1.0076770514681719, disc_loss = 0.02659308195596669
Trained batch 414 in epoch 0, gen_loss = 1.0074985084763493, disc_loss = 0.026535545535531477
Trained batch 415 in epoch 0, gen_loss = 1.007340260136586, disc_loss = 0.026476755263362205
Trained batch 416 in epoch 0, gen_loss = 1.0072927862334309, disc_loss = 0.02641860035396621
Trained batch 417 in epoch 0, gen_loss = 1.0071492438966578, disc_loss = 0.02635903986623181
Trained batch 418 in epoch 0, gen_loss = 1.006931217018346, disc_loss = 0.026299227696458913
Trained batch 419 in epoch 0, gen_loss = 1.0070612427734194, disc_loss = 0.026244268764276057
Trained batch 420 in epoch 0, gen_loss = 1.0067679426166054, disc_loss = 0.02619298772428477
Trained batch 421 in epoch 0, gen_loss = 1.006667343502361, disc_loss = 0.02614255419157675
Trained batch 422 in epoch 0, gen_loss = 1.006457948515601, disc_loss = 0.026090417098557802
Trained batch 423 in epoch 0, gen_loss = 1.0065421706662987, disc_loss = 0.026036870325388352
Trained batch 424 in epoch 0, gen_loss = 1.0064030711791094, disc_loss = 0.025983347526258405
Trained batch 425 in epoch 0, gen_loss = 1.0064272390844677, disc_loss = 0.02593789619072275
Trained batch 426 in epoch 0, gen_loss = 1.0064060986739969, disc_loss = 0.02589559568958117
Trained batch 427 in epoch 0, gen_loss = 1.0065220357658706, disc_loss = 0.025851966402489067
Trained batch 428 in epoch 0, gen_loss = 1.006455290845502, disc_loss = 0.025807128919045373
Trained batch 429 in epoch 0, gen_loss = 1.0064827780390895, disc_loss = 0.025761938488739002
Trained batch 430 in epoch 0, gen_loss = 1.0064488144595773, disc_loss = 0.025710502610241524
Trained batch 431 in epoch 0, gen_loss = 1.0064379270705912, disc_loss = 0.025657620061085455
Trained batch 432 in epoch 0, gen_loss = 1.0063652496690287, disc_loss = 0.02560407778798811
Trained batch 433 in epoch 0, gen_loss = 1.0062376535433228, disc_loss = 0.025548744034440546
Trained batch 434 in epoch 0, gen_loss = 1.0061686521288993, disc_loss = 0.025494719967620726
Trained batch 435 in epoch 0, gen_loss = 1.0058970897022737, disc_loss = 0.02544022553014022
Trained batch 436 in epoch 0, gen_loss = 1.0056029200826684, disc_loss = 0.025386664747618547
Trained batch 437 in epoch 0, gen_loss = 1.0054210832674209, disc_loss = 0.025334328494606685
Trained batch 438 in epoch 0, gen_loss = 1.0053668190515124, disc_loss = 0.02528266549128445
Trained batch 439 in epoch 0, gen_loss = 1.0049848468466238, disc_loss = 0.025232589657852342
Trained batch 440 in epoch 0, gen_loss = 1.004778886733412, disc_loss = 0.025188122667180048
Trained batch 441 in epoch 0, gen_loss = 1.0049895750721116, disc_loss = 0.02513964947579614
Trained batch 442 in epoch 0, gen_loss = 1.0048631794296592, disc_loss = 0.02509958811160009
Trained batch 443 in epoch 0, gen_loss = 1.0048867065358806, disc_loss = 0.02506888232761281
Trained batch 444 in epoch 0, gen_loss = 1.0047673865650477, disc_loss = 0.025029992421283228
Trained batch 445 in epoch 0, gen_loss = 1.0046753554600771, disc_loss = 0.024986534064370437
Trained batch 446 in epoch 0, gen_loss = 1.004423106810124, disc_loss = 0.02493866555881322
Trained batch 447 in epoch 0, gen_loss = 1.0044525364147765, disc_loss = 0.024889911062668295
Trained batch 448 in epoch 0, gen_loss = 1.004200217984036, disc_loss = 0.024839069515120295
Trained batch 449 in epoch 0, gen_loss = 1.0039269884427389, disc_loss = 0.02478819433108179
Trained batch 450 in epoch 0, gen_loss = 1.0038063138921616, disc_loss = 0.024736679553781157
Trained batch 451 in epoch 0, gen_loss = 1.0036254529140691, disc_loss = 0.024686078987067844
Trained batch 452 in epoch 0, gen_loss = 1.0036044135262108, disc_loss = 0.024636755938483423
Trained batch 453 in epoch 0, gen_loss = 1.0036282391012503, disc_loss = 0.024588652765932226
Trained batch 454 in epoch 0, gen_loss = 1.0034342049242375, disc_loss = 0.024538941087283113
Trained batch 455 in epoch 0, gen_loss = 1.0034476671563952, disc_loss = 0.024489206192236834
Trained batch 456 in epoch 0, gen_loss = 1.0033527520083756, disc_loss = 0.024438903546541588
Trained batch 457 in epoch 0, gen_loss = 1.0034295261947348, disc_loss = 0.024391098401161503
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.9547933340072632, disc_loss = 0.00310933543369174
Trained batch 1 in epoch 1, gen_loss = 0.9652199149131775, disc_loss = 0.004244111245498061
Trained batch 2 in epoch 1, gen_loss = 0.9811329444249471, disc_loss = 0.004446551203727722
Trained batch 3 in epoch 1, gen_loss = 0.9711175858974457, disc_loss = 0.004042932880111039
Trained batch 4 in epoch 1, gen_loss = 0.9566504478454589, disc_loss = 0.0035975776147097347
Trained batch 5 in epoch 1, gen_loss = 0.9551158944765726, disc_loss = 0.0032724791672080755
Trained batch 6 in epoch 1, gen_loss = 0.9507066948073251, disc_loss = 0.003027454949915409
Trained batch 7 in epoch 1, gen_loss = 0.9626139178872108, disc_loss = 0.0029299413436092436
Trained batch 8 in epoch 1, gen_loss = 0.9576887091000875, disc_loss = 0.002795005424155129
Trained batch 9 in epoch 1, gen_loss = 0.9500637590885163, disc_loss = 0.0026888826745562256
Trained batch 10 in epoch 1, gen_loss = 0.9556197957559065, disc_loss = 0.0026362495475702667
Trained batch 11 in epoch 1, gen_loss = 0.9581711838642756, disc_loss = 0.002644103553999836
Trained batch 12 in epoch 1, gen_loss = 0.9557808408370385, disc_loss = 0.0026441912542885314
Trained batch 13 in epoch 1, gen_loss = 0.9533347104276929, disc_loss = 0.002585986163467169
Trained batch 14 in epoch 1, gen_loss = 0.9516801357269287, disc_loss = 0.002514061238616705
Trained batch 15 in epoch 1, gen_loss = 0.951500840485096, disc_loss = 0.002451830863719806
Trained batch 16 in epoch 1, gen_loss = 0.949426573865554, disc_loss = 0.002383538124644581
Trained batch 17 in epoch 1, gen_loss = 0.953584737247891, disc_loss = 0.002344324848511153
Trained batch 18 in epoch 1, gen_loss = 0.9614695373334383, disc_loss = 0.0024197708913370184
Trained batch 19 in epoch 1, gen_loss = 0.9605838298797608, disc_loss = 0.002432122966274619
Trained batch 20 in epoch 1, gen_loss = 0.9643158344995408, disc_loss = 0.0024539166396217687
Trained batch 21 in epoch 1, gen_loss = 0.9650476358153603, disc_loss = 0.0024560553614388814
Trained batch 22 in epoch 1, gen_loss = 0.9661483324092367, disc_loss = 0.0024782909262601447
Trained batch 23 in epoch 1, gen_loss = 0.9690955057740211, disc_loss = 0.0024857774454479418
Trained batch 24 in epoch 1, gen_loss = 0.9671654748916626, disc_loss = 0.0024933262541890146
Trained batch 25 in epoch 1, gen_loss = 0.9655260443687439, disc_loss = 0.0024753120781567236
Trained batch 26 in epoch 1, gen_loss = 0.9628949319874799, disc_loss = 0.002442937801350598
Trained batch 27 in epoch 1, gen_loss = 0.9695265569857189, disc_loss = 0.002469122118782252
Trained batch 28 in epoch 1, gen_loss = 0.9699249719751293, disc_loss = 0.0024826028946273284
Trained batch 29 in epoch 1, gen_loss = 0.9705352524916331, disc_loss = 0.0024906311572218936
Trained batch 30 in epoch 1, gen_loss = 0.9739343562433797, disc_loss = 0.0024806967290538933
Trained batch 31 in epoch 1, gen_loss = 0.9718198534101248, disc_loss = 0.00249027757672593
Trained batch 32 in epoch 1, gen_loss = 0.9700348521723892, disc_loss = 0.0025170554096500077
Trained batch 33 in epoch 1, gen_loss = 0.9727137088775635, disc_loss = 0.0025420033249675352
Trained batch 34 in epoch 1, gen_loss = 0.9703821080071585, disc_loss = 0.002561916583882911
Trained batch 35 in epoch 1, gen_loss = 0.9697597523530325, disc_loss = 0.0025894767669443455
Trained batch 36 in epoch 1, gen_loss = 0.9717914445980175, disc_loss = 0.0026148868586263947
Trained batch 37 in epoch 1, gen_loss = 0.9721497297286987, disc_loss = 0.002620185149441424
Trained batch 38 in epoch 1, gen_loss = 0.9722080994875003, disc_loss = 0.002616623535943337
Trained batch 39 in epoch 1, gen_loss = 0.9726598143577576, disc_loss = 0.002606864005792886
Trained batch 40 in epoch 1, gen_loss = 0.9718721828809599, disc_loss = 0.002585776843039728
Trained batch 41 in epoch 1, gen_loss = 0.972406458287012, disc_loss = 0.0025693521380335802
Trained batch 42 in epoch 1, gen_loss = 0.9712424832721089, disc_loss = 0.0025603117226341435
Trained batch 43 in epoch 1, gen_loss = 0.970433381470767, disc_loss = 0.0025569727877154946
Trained batch 44 in epoch 1, gen_loss = 0.9702199339866638, disc_loss = 0.002548063111801942
Trained batch 45 in epoch 1, gen_loss = 0.97128357446712, disc_loss = 0.002528948145007472
Trained batch 46 in epoch 1, gen_loss = 0.9690856236092588, disc_loss = 0.0025138917324588972
Trained batch 47 in epoch 1, gen_loss = 0.9705419080952803, disc_loss = 0.0025243783044667603
Trained batch 48 in epoch 1, gen_loss = 0.9708288238973034, disc_loss = 0.0025207725690905842
Trained batch 49 in epoch 1, gen_loss = 0.971187311410904, disc_loss = 0.0025094634550623597
Trained batch 50 in epoch 1, gen_loss = 0.9711893925479814, disc_loss = 0.0024932421305600334
Trained batch 51 in epoch 1, gen_loss = 0.9707479992738137, disc_loss = 0.0024708683911460238
Trained batch 52 in epoch 1, gen_loss = 0.971185602107138, disc_loss = 0.002451077556097001
Trained batch 53 in epoch 1, gen_loss = 0.974503176079856, disc_loss = 0.0024876339852602947
Trained batch 54 in epoch 1, gen_loss = 0.9745983394709501, disc_loss = 0.002486442651768977
Trained batch 55 in epoch 1, gen_loss = 0.9744694999286106, disc_loss = 0.002488379499741963
Trained batch 56 in epoch 1, gen_loss = 0.9753799605787846, disc_loss = 0.00249363542452716
Trained batch 57 in epoch 1, gen_loss = 0.9777033966163109, disc_loss = 0.0025106945059037416
Trained batch 58 in epoch 1, gen_loss = 0.9780637308702631, disc_loss = 0.002531140529692678
Trained batch 59 in epoch 1, gen_loss = 0.977694563070933, disc_loss = 0.0025436689689134558
Trained batch 60 in epoch 1, gen_loss = 0.9778355399116141, disc_loss = 0.0025301441344142447
Trained batch 61 in epoch 1, gen_loss = 0.9773422556538736, disc_loss = 0.0025150637525404172
Trained batch 62 in epoch 1, gen_loss = 0.9766296848418221, disc_loss = 0.002499189523477403
Trained batch 63 in epoch 1, gen_loss = 0.9773613065481186, disc_loss = 0.0024803087890177267
Trained batch 64 in epoch 1, gen_loss = 0.9776363730430603, disc_loss = 0.002460603229701519
Trained batch 65 in epoch 1, gen_loss = 0.9772408505280813, disc_loss = 0.0024409610742815967
Trained batch 66 in epoch 1, gen_loss = 0.978118191014475, disc_loss = 0.002425117313917448
Trained batch 67 in epoch 1, gen_loss = 0.9777466225273469, disc_loss = 0.0024166787608170554
Trained batch 68 in epoch 1, gen_loss = 0.9786663668743079, disc_loss = 0.0024117761058732867
Trained batch 69 in epoch 1, gen_loss = 0.9779897851603372, disc_loss = 0.002401607753043728
Trained batch 70 in epoch 1, gen_loss = 0.9770128659799066, disc_loss = 0.0023947905217835182
Trained batch 71 in epoch 1, gen_loss = 0.9769215914938185, disc_loss = 0.002386284188509712
Trained batch 72 in epoch 1, gen_loss = 0.9762981754459746, disc_loss = 0.002368622606186426
Trained batch 73 in epoch 1, gen_loss = 0.9755717177648802, disc_loss = 0.0023532069895441667
Trained batch 74 in epoch 1, gen_loss = 0.9749057722091675, disc_loss = 0.0023384363468115527
Trained batch 75 in epoch 1, gen_loss = 0.9751481217773337, disc_loss = 0.002327251295546854
Trained batch 76 in epoch 1, gen_loss = 0.9748849899737866, disc_loss = 0.0023123025153340263
Trained batch 77 in epoch 1, gen_loss = 0.9750550236457434, disc_loss = 0.0023002260027286145
Trained batch 78 in epoch 1, gen_loss = 0.9754380168794077, disc_loss = 0.00228545758460613
Trained batch 79 in epoch 1, gen_loss = 0.9754343971610069, disc_loss = 0.0022735258360626178
Trained batch 80 in epoch 1, gen_loss = 0.9749958213464713, disc_loss = 0.0022606506805728983
Trained batch 81 in epoch 1, gen_loss = 0.9742798012931172, disc_loss = 0.002250586352424651
Trained batch 82 in epoch 1, gen_loss = 0.9744798842682896, disc_loss = 0.002245545987578401
Trained batch 83 in epoch 1, gen_loss = 0.975492869814237, disc_loss = 0.0022402399613167204
Trained batch 84 in epoch 1, gen_loss = 0.9755007589564604, disc_loss = 0.00223455872551045
Trained batch 85 in epoch 1, gen_loss = 0.975837248702382, disc_loss = 0.002236731943327847
Trained batch 86 in epoch 1, gen_loss = 0.9764027389986761, disc_loss = 0.002239487808326195
Trained batch 87 in epoch 1, gen_loss = 0.9760520993308588, disc_loss = 0.0022408087706108663
Trained batch 88 in epoch 1, gen_loss = 0.977177131711767, disc_loss = 0.002251370244900162
Trained batch 89 in epoch 1, gen_loss = 0.9768921633561453, disc_loss = 0.002252132060109741
Trained batch 90 in epoch 1, gen_loss = 0.9787015672568437, disc_loss = 0.0022687778506264252
Trained batch 91 in epoch 1, gen_loss = 0.9780240454103636, disc_loss = 0.002276624770551596
Trained batch 92 in epoch 1, gen_loss = 0.9775780811104723, disc_loss = 0.0022773699965127694
Trained batch 93 in epoch 1, gen_loss = 0.9781822270535409, disc_loss = 0.0022751793186081217
Trained batch 94 in epoch 1, gen_loss = 0.9780306791004382, disc_loss = 0.002270412209786867
Trained batch 95 in epoch 1, gen_loss = 0.9777517952024937, disc_loss = 0.0022633220857339134
Trained batch 96 in epoch 1, gen_loss = 0.9777281726758504, disc_loss = 0.002251239668712327
Trained batch 97 in epoch 1, gen_loss = 0.9782577534111179, disc_loss = 0.002242282006832562
Trained batch 98 in epoch 1, gen_loss = 0.9783480113202875, disc_loss = 0.0022340494259777996
Trained batch 99 in epoch 1, gen_loss = 0.9786620682477951, disc_loss = 0.002228052538121119
Trained batch 100 in epoch 1, gen_loss = 0.9784297459196336, disc_loss = 0.0022194412050510546
Trained batch 101 in epoch 1, gen_loss = 0.9780983358037239, disc_loss = 0.0022099761500059827
Trained batch 102 in epoch 1, gen_loss = 0.9778113046896111, disc_loss = 0.002199364926675063
Trained batch 103 in epoch 1, gen_loss = 0.9772581005325685, disc_loss = 0.0021889757582147676
Trained batch 104 in epoch 1, gen_loss = 0.976837780929747, disc_loss = 0.002178873684966848
Trained batch 105 in epoch 1, gen_loss = 0.9763341096212279, disc_loss = 0.0021689142054386154
Trained batch 106 in epoch 1, gen_loss = 0.9765406301088422, disc_loss = 0.002161568519224143
Trained batch 107 in epoch 1, gen_loss = 0.97611965239048, disc_loss = 0.0021537156932970028
Trained batch 108 in epoch 1, gen_loss = 0.9756450456216794, disc_loss = 0.0021458030411324234
Trained batch 109 in epoch 1, gen_loss = 0.9755234739997171, disc_loss = 0.0021348666024013337
Trained batch 110 in epoch 1, gen_loss = 0.9750296081508603, disc_loss = 0.002128672332456755
Trained batch 111 in epoch 1, gen_loss = 0.9742613998906953, disc_loss = 0.002125864911379592
Trained batch 112 in epoch 1, gen_loss = 0.9739189053003767, disc_loss = 0.002127555685748338
Trained batch 113 in epoch 1, gen_loss = 0.9741051217965913, disc_loss = 0.0021322114569780402
Trained batch 114 in epoch 1, gen_loss = 0.9738384360852449, disc_loss = 0.00213125681190792
Trained batch 115 in epoch 1, gen_loss = 0.9741551526661577, disc_loss = 0.002130553919665419
Trained batch 116 in epoch 1, gen_loss = 0.9734872019189036, disc_loss = 0.002126473829480541
Trained batch 117 in epoch 1, gen_loss = 0.9736423224715863, disc_loss = 0.002120665162584697
Trained batch 118 in epoch 1, gen_loss = 0.9732811651309999, disc_loss = 0.0021216207650537064
Trained batch 119 in epoch 1, gen_loss = 0.9730135281880696, disc_loss = 0.0021231836488974903
Trained batch 120 in epoch 1, gen_loss = 0.9733532292783753, disc_loss = 0.0021163194631765143
Trained batch 121 in epoch 1, gen_loss = 0.973156961261249, disc_loss = 0.002113727003919938
Trained batch 122 in epoch 1, gen_loss = 0.9725983055626474, disc_loss = 0.0021195067248943192
Trained batch 123 in epoch 1, gen_loss = 0.9727749834137578, disc_loss = 0.00211686413545507
Trained batch 124 in epoch 1, gen_loss = 0.9724237880706788, disc_loss = 0.0021067434013821184
Trained batch 125 in epoch 1, gen_loss = 0.9722199208206601, disc_loss = 0.0021001507444048505
Trained batch 126 in epoch 1, gen_loss = 0.9720920831199706, disc_loss = 0.0020931454665966214
Trained batch 127 in epoch 1, gen_loss = 0.9716758690774441, disc_loss = 0.0020846890024586173
Trained batch 128 in epoch 1, gen_loss = 0.9716646116833354, disc_loss = 0.0020844891235095183
Trained batch 129 in epoch 1, gen_loss = 0.9710805443617013, disc_loss = 0.00210033494558257
Trained batch 130 in epoch 1, gen_loss = 0.9710708346985678, disc_loss = 0.002123555863891081
Trained batch 131 in epoch 1, gen_loss = 0.9707721101515221, disc_loss = 0.0021392679830596812
Trained batch 132 in epoch 1, gen_loss = 0.9706177801117861, disc_loss = 0.002146483586726472
Trained batch 133 in epoch 1, gen_loss = 0.9704507073359703, disc_loss = 0.002149339439086755
Trained batch 134 in epoch 1, gen_loss = 0.9708429566136113, disc_loss = 0.002150210024599262
Trained batch 135 in epoch 1, gen_loss = 0.9713339069310356, disc_loss = 0.0021488745529923644
Trained batch 136 in epoch 1, gen_loss = 0.9714894851628881, disc_loss = 0.0021450841807026115
Trained batch 137 in epoch 1, gen_loss = 0.9709528239740841, disc_loss = 0.002138859349846219
Trained batch 138 in epoch 1, gen_loss = 0.9707803305962103, disc_loss = 0.0021323640659123176
Trained batch 139 in epoch 1, gen_loss = 0.9709029495716095, disc_loss = 0.002126497574499808
Trained batch 140 in epoch 1, gen_loss = 0.971464457241356, disc_loss = 0.0021299499170425356
Trained batch 141 in epoch 1, gen_loss = 0.9711921882461494, disc_loss = 0.0021351606664608536
Trained batch 142 in epoch 1, gen_loss = 0.9707713064613875, disc_loss = 0.002139355645798329
Trained batch 143 in epoch 1, gen_loss = 0.971161069555415, disc_loss = 0.002137675132366389
Trained batch 144 in epoch 1, gen_loss = 0.9716930442842944, disc_loss = 0.002135667206061169
Trained batch 145 in epoch 1, gen_loss = 0.9721946655070945, disc_loss = 0.002134199719477368
Trained batch 146 in epoch 1, gen_loss = 0.9723279553205788, disc_loss = 0.002134177652837037
Trained batch 147 in epoch 1, gen_loss = 0.9723258457473807, disc_loss = 0.002131510544426714
Trained batch 148 in epoch 1, gen_loss = 0.9727540340199566, disc_loss = 0.002131624231286872
Trained batch 149 in epoch 1, gen_loss = 0.9727630627155304, disc_loss = 0.0021302513603586705
Trained batch 150 in epoch 1, gen_loss = 0.9729792215176766, disc_loss = 0.0021276309926661087
Trained batch 151 in epoch 1, gen_loss = 0.9730750043925486, disc_loss = 0.002122126530019542
Trained batch 152 in epoch 1, gen_loss = 0.972607022796581, disc_loss = 0.0021176682241121005
Trained batch 153 in epoch 1, gen_loss = 0.9720223538287274, disc_loss = 0.0021127082740845667
Trained batch 154 in epoch 1, gen_loss = 0.9719544456851098, disc_loss = 0.00210564304781597
Trained batch 155 in epoch 1, gen_loss = 0.9723497590957544, disc_loss = 0.0021012652719853064
Trained batch 156 in epoch 1, gen_loss = 0.9719836400572661, disc_loss = 0.0020951043720250345
Trained batch 157 in epoch 1, gen_loss = 0.972245831278306, disc_loss = 0.0020899162874586552
Trained batch 158 in epoch 1, gen_loss = 0.9721167353714038, disc_loss = 0.00208485341570838
Trained batch 159 in epoch 1, gen_loss = 0.9718087017536163, disc_loss = 0.00207943882815016
Trained batch 160 in epoch 1, gen_loss = 0.9715269322721114, disc_loss = 0.0020770055964236256
Trained batch 161 in epoch 1, gen_loss = 0.9715596076882915, disc_loss = 0.0020759680928564687
Trained batch 162 in epoch 1, gen_loss = 0.971415800550964, disc_loss = 0.0020737750423597914
Trained batch 163 in epoch 1, gen_loss = 0.9711978878916764, disc_loss = 0.002069190533891343
Trained batch 164 in epoch 1, gen_loss = 0.9710423090241173, disc_loss = 0.002064094246915457
Trained batch 165 in epoch 1, gen_loss = 0.9708652830267527, disc_loss = 0.002059081442028576
Trained batch 166 in epoch 1, gen_loss = 0.9708056110821798, disc_loss = 0.0020536165841308586
Trained batch 167 in epoch 1, gen_loss = 0.9702128789254597, disc_loss = 0.0020496949918673464
Trained batch 168 in epoch 1, gen_loss = 0.970357946390231, disc_loss = 0.002050445374781982
Trained batch 169 in epoch 1, gen_loss = 0.970498700352276, disc_loss = 0.0020508168480934245
Trained batch 170 in epoch 1, gen_loss = 0.9701833766803407, disc_loss = 0.002048559536904162
Trained batch 171 in epoch 1, gen_loss = 0.9702297255050304, disc_loss = 0.0020454627550396593
Trained batch 172 in epoch 1, gen_loss = 0.9703669678958166, disc_loss = 0.00204272795841367
Trained batch 173 in epoch 1, gen_loss = 0.9705677327068373, disc_loss = 0.0020381488530206143
Trained batch 174 in epoch 1, gen_loss = 0.9704408546856471, disc_loss = 0.0020315931128737116
Trained batch 175 in epoch 1, gen_loss = 0.969869867305864, disc_loss = 0.002027955763796027
Trained batch 176 in epoch 1, gen_loss = 0.9699032121458969, disc_loss = 0.0020278337478011554
Trained batch 177 in epoch 1, gen_loss = 0.9702178785640202, disc_loss = 0.0020318283621624657
Trained batch 178 in epoch 1, gen_loss = 0.9698665618230511, disc_loss = 0.0020325591117169644
Trained batch 179 in epoch 1, gen_loss = 0.9702163891659843, disc_loss = 0.002032446205784153
Trained batch 180 in epoch 1, gen_loss = 0.9704714397699135, disc_loss = 0.002031736184253733
Trained batch 181 in epoch 1, gen_loss = 0.9703739138094933, disc_loss = 0.0020299264447952896
Trained batch 182 in epoch 1, gen_loss = 0.9703417508328547, disc_loss = 0.002027665679355768
Trained batch 183 in epoch 1, gen_loss = 0.9703000528009041, disc_loss = 0.002023073049634189
Trained batch 184 in epoch 1, gen_loss = 0.9698893817695411, disc_loss = 0.002020106538563866
Trained batch 185 in epoch 1, gen_loss = 0.9701592800437763, disc_loss = 0.002021149169811378
Trained batch 186 in epoch 1, gen_loss = 0.9696718610544256, disc_loss = 0.0020244030146809784
Trained batch 187 in epoch 1, gen_loss = 0.9696196206706635, disc_loss = 0.002029043811489828
Trained batch 188 in epoch 1, gen_loss = 0.9694021120273247, disc_loss = 0.0020287206292364294
Trained batch 189 in epoch 1, gen_loss = 0.9690353983326963, disc_loss = 0.002025099197635427
Trained batch 190 in epoch 1, gen_loss = 0.9689503268421632, disc_loss = 0.0020204017786626064
Trained batch 191 in epoch 1, gen_loss = 0.9687275504693389, disc_loss = 0.0020143434576311847
Trained batch 192 in epoch 1, gen_loss = 0.9690366708552899, disc_loss = 0.0020086444718908
Trained batch 193 in epoch 1, gen_loss = 0.9692936782369909, disc_loss = 0.0020040047436606944
Trained batch 194 in epoch 1, gen_loss = 0.9690262235127962, disc_loss = 0.0019981419342235684
Trained batch 195 in epoch 1, gen_loss = 0.9686318815362697, disc_loss = 0.0019926258181079235
Trained batch 196 in epoch 1, gen_loss = 0.9683367746130465, disc_loss = 0.0019883419420135204
Trained batch 197 in epoch 1, gen_loss = 0.9680667748354902, disc_loss = 0.001982837708165982
Trained batch 198 in epoch 1, gen_loss = 0.967649468824492, disc_loss = 0.0019778030519092913
Trained batch 199 in epoch 1, gen_loss = 0.9674162554740906, disc_loss = 0.001974459096963983
Trained batch 200 in epoch 1, gen_loss = 0.9670707491499868, disc_loss = 0.0019706214754378875
Trained batch 201 in epoch 1, gen_loss = 0.9677783876362414, disc_loss = 0.0019759026221760393
Trained batch 202 in epoch 1, gen_loss = 0.9682737389221567, disc_loss = 0.001979358092562887
Trained batch 203 in epoch 1, gen_loss = 0.9686227832354751, disc_loss = 0.0019806944317179824
Trained batch 204 in epoch 1, gen_loss = 0.9687303441326792, disc_loss = 0.0019845955877383125
Trained batch 205 in epoch 1, gen_loss = 0.9686025696472057, disc_loss = 0.001988979584019794
Trained batch 206 in epoch 1, gen_loss = 0.9687458475430807, disc_loss = 0.0019898879854121036
Trained batch 207 in epoch 1, gen_loss = 0.9687536820196189, disc_loss = 0.0019874626061489554
Trained batch 208 in epoch 1, gen_loss = 0.9687591386183597, disc_loss = 0.001986095958342553
Trained batch 209 in epoch 1, gen_loss = 0.9684627266157241, disc_loss = 0.001987574328502108
Trained batch 210 in epoch 1, gen_loss = 0.9682764809278516, disc_loss = 0.0019907511042991555
Trained batch 211 in epoch 1, gen_loss = 0.9685324649765806, disc_loss = 0.001989632706819014
Trained batch 212 in epoch 1, gen_loss = 0.9684084818956438, disc_loss = 0.0019852559001867095
Trained batch 213 in epoch 1, gen_loss = 0.9688758613350236, disc_loss = 0.0019844424397854363
Trained batch 214 in epoch 1, gen_loss = 0.9688129915747532, disc_loss = 0.0019902517296222235
Trained batch 215 in epoch 1, gen_loss = 0.9685999789723644, disc_loss = 0.0019965521396780213
Trained batch 216 in epoch 1, gen_loss = 0.9684991718437265, disc_loss = 0.0019997388646457222
Trained batch 217 in epoch 1, gen_loss = 0.9686708146825843, disc_loss = 0.002002429796239669
Trained batch 218 in epoch 1, gen_loss = 0.9689381049103933, disc_loss = 0.0020036254565605734
Trained batch 219 in epoch 1, gen_loss = 0.9687296019359068, disc_loss = 0.0019995480397483334
Trained batch 220 in epoch 1, gen_loss = 0.9684758178249204, disc_loss = 0.0019959870726396897
Trained batch 221 in epoch 1, gen_loss = 0.9685513699376905, disc_loss = 0.001993814619889416
Trained batch 222 in epoch 1, gen_loss = 0.968413559043354, disc_loss = 0.001989932103560728
Trained batch 223 in epoch 1, gen_loss = 0.9688822023038354, disc_loss = 0.001987112458664342
Trained batch 224 in epoch 1, gen_loss = 0.9693781622250874, disc_loss = 0.0019866906316019593
Trained batch 225 in epoch 1, gen_loss = 0.9692126829012305, disc_loss = 0.0019835051269150973
Trained batch 226 in epoch 1, gen_loss = 0.9691153045267785, disc_loss = 0.0019802800171992165
Trained batch 227 in epoch 1, gen_loss = 0.9690699906725633, disc_loss = 0.0019759433157639904
Trained batch 228 in epoch 1, gen_loss = 0.9693778019284577, disc_loss = 0.0019743038154833473
Trained batch 229 in epoch 1, gen_loss = 0.9694028584853462, disc_loss = 0.001978266497557659
Trained batch 230 in epoch 1, gen_loss = 0.9693355699638267, disc_loss = 0.0019841599653604002
Trained batch 231 in epoch 1, gen_loss = 0.9696384447401968, disc_loss = 0.0019828857693937607
Trained batch 232 in epoch 1, gen_loss = 0.969656035368023, disc_loss = 0.0019785009687786417
Trained batch 233 in epoch 1, gen_loss = 0.9697909266011328, disc_loss = 0.0019821950916547137
Trained batch 234 in epoch 1, gen_loss = 0.9697188608189846, disc_loss = 0.0019980973026596325
Trained batch 235 in epoch 1, gen_loss = 0.9695796208866572, disc_loss = 0.00201686029100467
Trained batch 236 in epoch 1, gen_loss = 0.9692436579913529, disc_loss = 0.0020342613096380377
Trained batch 237 in epoch 1, gen_loss = 0.969155572793063, disc_loss = 0.0020472640951825385
Trained batch 238 in epoch 1, gen_loss = 0.9690463223716704, disc_loss = 0.002051455217898749
Trained batch 239 in epoch 1, gen_loss = 0.9690265874067943, disc_loss = 0.002049877836786133
Trained batch 240 in epoch 1, gen_loss = 0.9688763635781791, disc_loss = 0.002045228771326283
Trained batch 241 in epoch 1, gen_loss = 0.9687274209231385, disc_loss = 0.002040584535339909
Trained batch 242 in epoch 1, gen_loss = 0.9685231680242122, disc_loss = 0.002036470293456405
Trained batch 243 in epoch 1, gen_loss = 0.9681627471916011, disc_loss = 0.0020318235946746666
Trained batch 244 in epoch 1, gen_loss = 0.9682699950373903, disc_loss = 0.002028900869808407
Trained batch 245 in epoch 1, gen_loss = 0.9681699716947912, disc_loss = 0.0020263083816252315
Trained batch 246 in epoch 1, gen_loss = 0.967994261125804, disc_loss = 0.0020224781900640533
Trained batch 247 in epoch 1, gen_loss = 0.9681657454179179, disc_loss = 0.0020189737352343546
Trained batch 248 in epoch 1, gen_loss = 0.967890969002582, disc_loss = 0.002014661554469686
Trained batch 249 in epoch 1, gen_loss = 0.9680632436275483, disc_loss = 0.0020106427122373134
Trained batch 250 in epoch 1, gen_loss = 0.9681969228018803, disc_loss = 0.0020067880936133937
Trained batch 251 in epoch 1, gen_loss = 0.9680685360753347, disc_loss = 0.0020029062776186963
Trained batch 252 in epoch 1, gen_loss = 0.9676873903029521, disc_loss = 0.0020004925306558816
Trained batch 253 in epoch 1, gen_loss = 0.968036306889977, disc_loss = 0.001999210502803839
Trained batch 254 in epoch 1, gen_loss = 0.9679652043417388, disc_loss = 0.001996924830189742
Trained batch 255 in epoch 1, gen_loss = 0.9679835957940668, disc_loss = 0.0019938024408929778
Trained batch 256 in epoch 1, gen_loss = 0.9679459233692184, disc_loss = 0.0019909819501546366
Trained batch 257 in epoch 1, gen_loss = 0.9677329694115838, disc_loss = 0.001989421401084437
Trained batch 258 in epoch 1, gen_loss = 0.9677247814690284, disc_loss = 0.0019885144575362357
Trained batch 259 in epoch 1, gen_loss = 0.9676823856738898, disc_loss = 0.00198743619727723
Trained batch 260 in epoch 1, gen_loss = 0.9675515298642418, disc_loss = 0.0019843538478641304
Trained batch 261 in epoch 1, gen_loss = 0.967732681800391, disc_loss = 0.0019819472162390683
Trained batch 262 in epoch 1, gen_loss = 0.9674440450088153, disc_loss = 0.001980068159206441
Trained batch 263 in epoch 1, gen_loss = 0.967366422893423, disc_loss = 0.0019789491116446725
Trained batch 264 in epoch 1, gen_loss = 0.9672157163889903, disc_loss = 0.001978811087693035
Trained batch 265 in epoch 1, gen_loss = 0.9672506689129019, disc_loss = 0.001977786319146521
Trained batch 266 in epoch 1, gen_loss = 0.9673585576957531, disc_loss = 0.0019755790976734226
Trained batch 267 in epoch 1, gen_loss = 0.9672504687932, disc_loss = 0.0019723826612314597
Trained batch 268 in epoch 1, gen_loss = 0.9672066423086428, disc_loss = 0.0019678158595115916
Trained batch 269 in epoch 1, gen_loss = 0.967143342671571, disc_loss = 0.001963614561827853
Trained batch 270 in epoch 1, gen_loss = 0.9669956628686828, disc_loss = 0.0019601849043085428
Trained batch 271 in epoch 1, gen_loss = 0.9669322581852183, disc_loss = 0.0019561111486623038
Trained batch 272 in epoch 1, gen_loss = 0.9667474062014849, disc_loss = 0.0019516718790068158
Trained batch 273 in epoch 1, gen_loss = 0.9665552160165606, disc_loss = 0.0019472206147798901
Trained batch 274 in epoch 1, gen_loss = 0.9662583043358542, disc_loss = 0.0019425799816169523
Trained batch 275 in epoch 1, gen_loss = 0.966625719398692, disc_loss = 0.0019405172847589288
Trained batch 276 in epoch 1, gen_loss = 0.9662375368366173, disc_loss = 0.0019449857080402358
Trained batch 277 in epoch 1, gen_loss = 0.9664206916479756, disc_loss = 0.0019472109668104232
Trained batch 278 in epoch 1, gen_loss = 0.9660170210732354, disc_loss = 0.0019464033111716258
Trained batch 279 in epoch 1, gen_loss = 0.9662492977721351, disc_loss = 0.0019524766198758569
Trained batch 280 in epoch 1, gen_loss = 0.9662907149019615, disc_loss = 0.001965362268741975
Trained batch 281 in epoch 1, gen_loss = 0.9662211941066363, disc_loss = 0.001976227445580752
Trained batch 282 in epoch 1, gen_loss = 0.966018619259339, disc_loss = 0.0019832850473376763
Trained batch 283 in epoch 1, gen_loss = 0.965840823213819, disc_loss = 0.001986312204447221
Trained batch 284 in epoch 1, gen_loss = 0.9659402077658135, disc_loss = 0.001987155792385078
Trained batch 285 in epoch 1, gen_loss = 0.9659942315591799, disc_loss = 0.0019865284964500868
Trained batch 286 in epoch 1, gen_loss = 0.9659007224887091, disc_loss = 0.0019847127862066966
Trained batch 287 in epoch 1, gen_loss = 0.9660460131449832, disc_loss = 0.001982042403041204
Trained batch 288 in epoch 1, gen_loss = 0.9658526932904464, disc_loss = 0.0019795317915799965
Trained batch 289 in epoch 1, gen_loss = 0.9657020918254194, disc_loss = 0.001976752974462278
Trained batch 290 in epoch 1, gen_loss = 0.9657100863063458, disc_loss = 0.00197288997413725
Trained batch 291 in epoch 1, gen_loss = 0.9660095011126505, disc_loss = 0.0019695273120504844
Trained batch 292 in epoch 1, gen_loss = 0.9659005210261296, disc_loss = 0.001967869137188121
Trained batch 293 in epoch 1, gen_loss = 0.9657153213510707, disc_loss = 0.0019716267350452896
Trained batch 294 in epoch 1, gen_loss = 0.9658428076970376, disc_loss = 0.0019738452217020726
Trained batch 295 in epoch 1, gen_loss = 0.9660023110541137, disc_loss = 0.001973627698749329
Trained batch 296 in epoch 1, gen_loss = 0.9660099200929455, disc_loss = 0.0019741654282385604
Trained batch 297 in epoch 1, gen_loss = 0.9660462063030909, disc_loss = 0.001976207363959902
Trained batch 298 in epoch 1, gen_loss = 0.9658981633425556, disc_loss = 0.0019809038679654335
Trained batch 299 in epoch 1, gen_loss = 0.9659674060344696, disc_loss = 0.0019878760674813143
Trained batch 300 in epoch 1, gen_loss = 0.9660362686429705, disc_loss = 0.0019920565334127045
Trained batch 301 in epoch 1, gen_loss = 0.9660128797126921, disc_loss = 0.0019911828894932935
Trained batch 302 in epoch 1, gen_loss = 0.966200594854827, disc_loss = 0.0019886529076192836
Trained batch 303 in epoch 1, gen_loss = 0.9660175062323871, disc_loss = 0.0019876125159881716
Trained batch 304 in epoch 1, gen_loss = 0.9663776839365724, disc_loss = 0.001994083572148544
Trained batch 305 in epoch 1, gen_loss = 0.9660365669166341, disc_loss = 0.001999664905608869
Trained batch 306 in epoch 1, gen_loss = 0.9660260397758856, disc_loss = 0.0020022063731467686
Trained batch 307 in epoch 1, gen_loss = 0.9660023710170349, disc_loss = 0.002003500696162802
Trained batch 308 in epoch 1, gen_loss = 0.966172399644327, disc_loss = 0.0020070308631038878
Trained batch 309 in epoch 1, gen_loss = 0.9662635134112451, disc_loss = 0.0020090713443595073
Trained batch 310 in epoch 1, gen_loss = 0.966265820613628, disc_loss = 0.0020097392151533504
Trained batch 311 in epoch 1, gen_loss = 0.9662492238940337, disc_loss = 0.0020113150456335205
Trained batch 312 in epoch 1, gen_loss = 0.966276230713049, disc_loss = 0.0020132866567566087
Trained batch 313 in epoch 1, gen_loss = 0.966346433777718, disc_loss = 0.002014251266440056
Trained batch 314 in epoch 1, gen_loss = 0.9662391017353724, disc_loss = 0.002011783897048897
Trained batch 315 in epoch 1, gen_loss = 0.9661152074231377, disc_loss = 0.0020082163347426474
Trained batch 316 in epoch 1, gen_loss = 0.9662634391889964, disc_loss = 0.0020053418961350662
Trained batch 317 in epoch 1, gen_loss = 0.9663943965105141, disc_loss = 0.002002605814018152
Trained batch 318 in epoch 1, gen_loss = 0.9665294894977797, disc_loss = 0.0019990720320492983
Trained batch 319 in epoch 1, gen_loss = 0.9666546219959855, disc_loss = 0.001996097782830475
Trained batch 320 in epoch 1, gen_loss = 0.9665930696365618, disc_loss = 0.001992401058388137
Trained batch 321 in epoch 1, gen_loss = 0.9664564710226118, disc_loss = 0.0019884013859352663
Trained batch 322 in epoch 1, gen_loss = 0.9665773509087577, disc_loss = 0.001984523479169344
Trained batch 323 in epoch 1, gen_loss = 0.9665227479036943, disc_loss = 0.0019808412658159887
Trained batch 324 in epoch 1, gen_loss = 0.9664508256545433, disc_loss = 0.0019777547668379087
Trained batch 325 in epoch 1, gen_loss = 0.9666407885361303, disc_loss = 0.0019752690975662845
Trained batch 326 in epoch 1, gen_loss = 0.9666383720319206, disc_loss = 0.001972493703479933
Trained batch 327 in epoch 1, gen_loss = 0.9665502546037116, disc_loss = 0.0019692108769781844
Trained batch 328 in epoch 1, gen_loss = 0.9665579819389389, disc_loss = 0.0019658427254868652
Trained batch 329 in epoch 1, gen_loss = 0.9664970907298002, disc_loss = 0.0019626143120342133
Trained batch 330 in epoch 1, gen_loss = 0.9666615007867265, disc_loss = 0.001960045909171423
Trained batch 331 in epoch 1, gen_loss = 0.9668009740760527, disc_loss = 0.0019573412883987494
Trained batch 332 in epoch 1, gen_loss = 0.9666462859233936, disc_loss = 0.00195405823521193
Trained batch 333 in epoch 1, gen_loss = 0.9666156749168556, disc_loss = 0.0019519170561476337
Trained batch 334 in epoch 1, gen_loss = 0.9666541478527126, disc_loss = 0.0019505478431289989
Trained batch 335 in epoch 1, gen_loss = 0.9668164751714184, disc_loss = 0.0019496800093856152
Trained batch 336 in epoch 1, gen_loss = 0.9667316744164827, disc_loss = 0.0019483012047068434
Trained batch 337 in epoch 1, gen_loss = 0.9666661706549176, disc_loss = 0.0019458047852757767
Trained batch 338 in epoch 1, gen_loss = 0.9664035646964667, disc_loss = 0.00194252711984502
Trained batch 339 in epoch 1, gen_loss = 0.9662451659931856, disc_loss = 0.0019391634140286922
Trained batch 340 in epoch 1, gen_loss = 0.9662661674784775, disc_loss = 0.0019361449146432983
Trained batch 341 in epoch 1, gen_loss = 0.9663511695917587, disc_loss = 0.0019333914774320258
Trained batch 342 in epoch 1, gen_loss = 0.9664146799387807, disc_loss = 0.0019304189330738026
Trained batch 343 in epoch 1, gen_loss = 0.9663001988516298, disc_loss = 0.0019274784453743852
Trained batch 344 in epoch 1, gen_loss = 0.9662588183430658, disc_loss = 0.001925042474075504
Trained batch 345 in epoch 1, gen_loss = 0.9661212911495584, disc_loss = 0.001922560752116445
Trained batch 346 in epoch 1, gen_loss = 0.9661905705413488, disc_loss = 0.0019209799460760755
Trained batch 347 in epoch 1, gen_loss = 0.9660403939156696, disc_loss = 0.0019205187925073351
Trained batch 348 in epoch 1, gen_loss = 0.9658229516707041, disc_loss = 0.0019196007069851402
Trained batch 349 in epoch 1, gen_loss = 0.9658398842811584, disc_loss = 0.0019186088888506804
Trained batch 350 in epoch 1, gen_loss = 0.9656347024474728, disc_loss = 0.0019162519350037657
Trained batch 351 in epoch 1, gen_loss = 0.9656421929936517, disc_loss = 0.0019137137599252376
Trained batch 352 in epoch 1, gen_loss = 0.9655190228402784, disc_loss = 0.0019115976314522094
Trained batch 353 in epoch 1, gen_loss = 0.965336980287638, disc_loss = 0.0019094598664386503
Trained batch 354 in epoch 1, gen_loss = 0.9651175383111121, disc_loss = 0.001907307017122356
Trained batch 355 in epoch 1, gen_loss = 0.9649840981772776, disc_loss = 0.001904501655241056
Trained batch 356 in epoch 1, gen_loss = 0.9649323889521324, disc_loss = 0.0019015464711613452
Trained batch 357 in epoch 1, gen_loss = 0.9649382588250677, disc_loss = 0.0018988739406135891
Trained batch 358 in epoch 1, gen_loss = 0.9649202187745352, disc_loss = 0.001895633734656306
Trained batch 359 in epoch 1, gen_loss = 0.9650677722361353, disc_loss = 0.0018931631228446754
Trained batch 360 in epoch 1, gen_loss = 0.9648548645325975, disc_loss = 0.0018900144823318621
Trained batch 361 in epoch 1, gen_loss = 0.9647905265099436, disc_loss = 0.0018873419432556102
Trained batch 362 in epoch 1, gen_loss = 0.9649090738992717, disc_loss = 0.001885355984504763
Trained batch 363 in epoch 1, gen_loss = 0.9649237137246918, disc_loss = 0.001883643189353029
Trained batch 364 in epoch 1, gen_loss = 0.9648214132818457, disc_loss = 0.001881630728914313
Trained batch 365 in epoch 1, gen_loss = 0.9648391361770734, disc_loss = 0.0018797227330353172
Trained batch 366 in epoch 1, gen_loss = 0.964891172722185, disc_loss = 0.0018784288127909159
Trained batch 367 in epoch 1, gen_loss = 0.9648638766096986, disc_loss = 0.001876343789816652
Trained batch 368 in epoch 1, gen_loss = 0.9649067315951918, disc_loss = 0.001873673714361681
Trained batch 369 in epoch 1, gen_loss = 0.9649540200426772, disc_loss = 0.0018708629533648491
Trained batch 370 in epoch 1, gen_loss = 0.965013971868551, disc_loss = 0.0018680814781974289
Trained batch 371 in epoch 1, gen_loss = 0.9648819504886545, disc_loss = 0.0018661384702652632
Trained batch 372 in epoch 1, gen_loss = 0.9648634482964115, disc_loss = 0.0018639840616659828
Trained batch 373 in epoch 1, gen_loss = 0.9648994935706338, disc_loss = 0.001861332138324216
Trained batch 374 in epoch 1, gen_loss = 0.9647331349054973, disc_loss = 0.0018586554233916105
Trained batch 375 in epoch 1, gen_loss = 0.9647289955235542, disc_loss = 0.001856876960602599
Trained batch 376 in epoch 1, gen_loss = 0.9649980808126515, disc_loss = 0.0018571036380211716
Trained batch 377 in epoch 1, gen_loss = 0.9650127856188981, disc_loss = 0.0018572899343251255
Trained batch 378 in epoch 1, gen_loss = 0.9650902229122876, disc_loss = 0.0018577488911175968
Trained batch 379 in epoch 1, gen_loss = 0.965007231266875, disc_loss = 0.0018565214455041937
Trained batch 380 in epoch 1, gen_loss = 0.9648676218948965, disc_loss = 0.001854025584791012
Trained batch 381 in epoch 1, gen_loss = 0.9648760020420813, disc_loss = 0.0018521524660706189
Trained batch 382 in epoch 1, gen_loss = 0.9647192741809875, disc_loss = 0.0018509446955456183
Trained batch 383 in epoch 1, gen_loss = 0.9646886923971275, disc_loss = 0.0018498128530760976
Trained batch 384 in epoch 1, gen_loss = 0.9644706938173864, disc_loss = 0.0018477025930164986
Trained batch 385 in epoch 1, gen_loss = 0.9644917306813552, disc_loss = 0.001845232228093438
Trained batch 386 in epoch 1, gen_loss = 0.9644527778761023, disc_loss = 0.0018429038558848375
Trained batch 387 in epoch 1, gen_loss = 0.9645712748938, disc_loss = 0.0018404891682049433
Trained batch 388 in epoch 1, gen_loss = 0.9644484820280099, disc_loss = 0.0018376377882534077
Trained batch 389 in epoch 1, gen_loss = 0.9645165331852742, disc_loss = 0.0018359863203771126
Trained batch 390 in epoch 1, gen_loss = 0.9646466825624256, disc_loss = 0.0018348809159861024
Trained batch 391 in epoch 1, gen_loss = 0.9645646625027364, disc_loss = 0.0018336001261819287
Trained batch 392 in epoch 1, gen_loss = 0.9645560312513783, disc_loss = 0.0018317633870996194
Trained batch 393 in epoch 1, gen_loss = 0.964688307742782, disc_loss = 0.0018298174368352321
Trained batch 394 in epoch 1, gen_loss = 0.9645918628837489, disc_loss = 0.0018282788329687016
Trained batch 395 in epoch 1, gen_loss = 0.964494215418594, disc_loss = 0.001827647886444777
Trained batch 396 in epoch 1, gen_loss = 0.9643799832245565, disc_loss = 0.0018266765839157519
Trained batch 397 in epoch 1, gen_loss = 0.9646890840338702, disc_loss = 0.001828499603870292
Trained batch 398 in epoch 1, gen_loss = 0.9647312427224372, disc_loss = 0.001832056414647574
Trained batch 399 in epoch 1, gen_loss = 0.964782951772213, disc_loss = 0.0018364881844900082
Trained batch 400 in epoch 1, gen_loss = 0.9647057936375872, disc_loss = 0.0018389927119683205
Trained batch 401 in epoch 1, gen_loss = 0.9645959441341571, disc_loss = 0.0018389857930434747
Trained batch 402 in epoch 1, gen_loss = 0.9648408546637068, disc_loss = 0.001838815934804705
Trained batch 403 in epoch 1, gen_loss = 0.9649091224269112, disc_loss = 0.0018379429413183214
Trained batch 404 in epoch 1, gen_loss = 0.9646168673479999, disc_loss = 0.0018373175956780251
Trained batch 405 in epoch 1, gen_loss = 0.9646127958015855, disc_loss = 0.0018368278381476646
Trained batch 406 in epoch 1, gen_loss = 0.9646062232938387, disc_loss = 0.0018357163564306604
Trained batch 407 in epoch 1, gen_loss = 0.9644288654420891, disc_loss = 0.0018332950664140906
Trained batch 408 in epoch 1, gen_loss = 0.9644039934888154, disc_loss = 0.0018332474702777918
Trained batch 409 in epoch 1, gen_loss = 0.9642426987973655, disc_loss = 0.0018355292696846514
Trained batch 410 in epoch 1, gen_loss = 0.9641338105329342, disc_loss = 0.0018395211679607159
Trained batch 411 in epoch 1, gen_loss = 0.964324112656047, disc_loss = 0.0018441401960585916
Trained batch 412 in epoch 1, gen_loss = 0.9641494320899464, disc_loss = 0.0018450375739372275
Trained batch 413 in epoch 1, gen_loss = 0.9640883440556733, disc_loss = 0.0018435791207945362
Trained batch 414 in epoch 1, gen_loss = 0.9639644092824086, disc_loss = 0.0018417893044919854
Trained batch 415 in epoch 1, gen_loss = 0.9639771265479234, disc_loss = 0.0018426056994940154
Trained batch 416 in epoch 1, gen_loss = 0.9638492635114015, disc_loss = 0.0018451630128927224
Trained batch 417 in epoch 1, gen_loss = 0.963740845901544, disc_loss = 0.0018475281401051644
Trained batch 418 in epoch 1, gen_loss = 0.9636926790410408, disc_loss = 0.0018487666685774319
Trained batch 419 in epoch 1, gen_loss = 0.963673452536265, disc_loss = 0.0018489982633452331
Trained batch 420 in epoch 1, gen_loss = 0.9636675309115521, disc_loss = 0.0018477508828105879
Trained batch 421 in epoch 1, gen_loss = 0.96374551549342, disc_loss = 0.0018463084116684034
Trained batch 422 in epoch 1, gen_loss = 0.9639598900544728, disc_loss = 0.0018462538655878134
Trained batch 423 in epoch 1, gen_loss = 0.9638895673571892, disc_loss = 0.0018478315167089502
Trained batch 424 in epoch 1, gen_loss = 0.9637399669254527, disc_loss = 0.0018508295213584514
Trained batch 425 in epoch 1, gen_loss = 0.9639233520053362, disc_loss = 0.001853755366181771
Trained batch 426 in epoch 1, gen_loss = 0.9637276474430075, disc_loss = 0.0018536056120895216
Trained batch 427 in epoch 1, gen_loss = 0.9640414398685794, disc_loss = 0.0018543324987599888
Trained batch 428 in epoch 1, gen_loss = 0.9639248426977571, disc_loss = 0.0018611273818946767
Trained batch 429 in epoch 1, gen_loss = 0.9638119816780091, disc_loss = 0.0018792096132867384
Trained batch 430 in epoch 1, gen_loss = 0.9639628102220681, disc_loss = 0.0018980834336536493
Trained batch 431 in epoch 1, gen_loss = 0.963790730331783, disc_loss = 0.0019081270457482551
Trained batch 432 in epoch 1, gen_loss = 0.9639078845328052, disc_loss = 0.0019082134873466459
Trained batch 433 in epoch 1, gen_loss = 0.9637944026751453, disc_loss = 0.0019073708767225871
Trained batch 434 in epoch 1, gen_loss = 0.9637447161236029, disc_loss = 0.0019107163535837812
Trained batch 435 in epoch 1, gen_loss = 0.9637474795000269, disc_loss = 0.0019138551903504092
Trained batch 436 in epoch 1, gen_loss = 0.9638689112608712, disc_loss = 0.0019169500757230432
Trained batch 437 in epoch 1, gen_loss = 0.9639359360144019, disc_loss = 0.0019202092561454056
Trained batch 438 in epoch 1, gen_loss = 0.963953432433969, disc_loss = 0.001921015601193613
Trained batch 439 in epoch 1, gen_loss = 0.9638497941873291, disc_loss = 0.001921582450053062
Trained batch 440 in epoch 1, gen_loss = 0.9638412692108933, disc_loss = 0.0019244719972483426
Trained batch 441 in epoch 1, gen_loss = 0.9637874894821805, disc_loss = 0.001926670011082386
Trained batch 442 in epoch 1, gen_loss = 0.9636021756964397, disc_loss = 0.0019256759321413784
Trained batch 443 in epoch 1, gen_loss = 0.9635194471559009, disc_loss = 0.0019230097170440934
Trained batch 444 in epoch 1, gen_loss = 0.9633000755577945, disc_loss = 0.0019222032676419515
Trained batch 445 in epoch 1, gen_loss = 0.9631480808482576, disc_loss = 0.001920200482370006
Trained batch 446 in epoch 1, gen_loss = 0.9632600165853564, disc_loss = 0.0019188759014035432
Trained batch 447 in epoch 1, gen_loss = 0.9632471058783787, disc_loss = 0.0019192532298412906
Trained batch 448 in epoch 1, gen_loss = 0.9633470820159318, disc_loss = 0.0019200252869969155
Trained batch 449 in epoch 1, gen_loss = 0.9634206179777781, disc_loss = 0.0019195708901517921
Trained batch 450 in epoch 1, gen_loss = 0.9632839478568862, disc_loss = 0.0019172274710470088
Trained batch 451 in epoch 1, gen_loss = 0.9631832744431706, disc_loss = 0.0019146773395740501
Trained batch 452 in epoch 1, gen_loss = 0.9630762074167365, disc_loss = 0.0019115527276367065
Trained batch 453 in epoch 1, gen_loss = 0.9631901061744942, disc_loss = 0.0019092099581607147
Trained batch 454 in epoch 1, gen_loss = 0.9632888509677007, disc_loss = 0.0019068859799017946
Trained batch 455 in epoch 1, gen_loss = 0.96330397732948, disc_loss = 0.0019044912533309687
Trained batch 456 in epoch 1, gen_loss = 0.96336592039342, disc_loss = 0.001902104603127664
Trained batch 457 in epoch 1, gen_loss = 0.963447242975235, disc_loss = 0.0019002186372626053
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.9981094002723694, disc_loss = 0.0012570236576721072
Trained batch 1 in epoch 2, gen_loss = 0.9579973518848419, disc_loss = 0.001423159206751734
Trained batch 2 in epoch 2, gen_loss = 0.9410470724105835, disc_loss = 0.0013794881524518132
Trained batch 3 in epoch 2, gen_loss = 0.9444311857223511, disc_loss = 0.001279512362089008
Trained batch 4 in epoch 2, gen_loss = 0.9539253950119019, disc_loss = 0.001172930863685906
Trained batch 5 in epoch 2, gen_loss = 0.9509711364905039, disc_loss = 0.001111187137818585
Trained batch 6 in epoch 2, gen_loss = 0.9507600665092468, disc_loss = 0.0010705757054633328
Trained batch 7 in epoch 2, gen_loss = 0.9499118104577065, disc_loss = 0.001029645645758137
Trained batch 8 in epoch 2, gen_loss = 0.959150042798784, disc_loss = 0.000997815992579692
Trained batch 9 in epoch 2, gen_loss = 0.966479343175888, disc_loss = 0.0009823907515965403
Trained batch 10 in epoch 2, gen_loss = 0.9668529683893378, disc_loss = 0.000971757917961275
Trained batch 11 in epoch 2, gen_loss = 0.9633949995040894, disc_loss = 0.0009436222026124597
Trained batch 12 in epoch 2, gen_loss = 0.9551118979087243, disc_loss = 0.0009226481242177004
Trained batch 13 in epoch 2, gen_loss = 0.9612011739185878, disc_loss = 0.0009347287663591228
Trained batch 14 in epoch 2, gen_loss = 0.965662670135498, disc_loss = 0.0009516622056253254
Trained batch 15 in epoch 2, gen_loss = 0.9652379266917706, disc_loss = 0.0009580028818163555
Trained batch 16 in epoch 2, gen_loss = 0.9648922296131358, disc_loss = 0.0009342910865705241
Trained batch 17 in epoch 2, gen_loss = 0.9679696924156613, disc_loss = 0.0009239726868044171
Trained batch 18 in epoch 2, gen_loss = 0.9680202477856686, disc_loss = 0.0009133446054827226
Trained batch 19 in epoch 2, gen_loss = 0.9667496830224991, disc_loss = 0.000900117916171439
Trained batch 20 in epoch 2, gen_loss = 0.964558944815681, disc_loss = 0.0008901207502709613
Trained batch 21 in epoch 2, gen_loss = 0.9670312106609344, disc_loss = 0.0009010589750356634
Trained batch 22 in epoch 2, gen_loss = 0.9622694798137831, disc_loss = 0.0009092361964892758
Trained batch 23 in epoch 2, gen_loss = 0.9605738595128059, disc_loss = 0.0009061414918202596
Trained batch 24 in epoch 2, gen_loss = 0.9624785304069519, disc_loss = 0.0009044479741714895
Trained batch 25 in epoch 2, gen_loss = 0.9610048876358912, disc_loss = 0.0008973066735332116
Trained batch 26 in epoch 2, gen_loss = 0.9580252943215547, disc_loss = 0.0008862447101381366
Trained batch 27 in epoch 2, gen_loss = 0.9568480189357486, disc_loss = 0.0008855788224276953
Trained batch 28 in epoch 2, gen_loss = 0.958553081956403, disc_loss = 0.0008924511112754458
Trained batch 29 in epoch 2, gen_loss = 0.957955809434255, disc_loss = 0.0008975442906375974
Trained batch 30 in epoch 2, gen_loss = 0.9566435371675799, disc_loss = 0.000899735291773874
Trained batch 31 in epoch 2, gen_loss = 0.9587877932935953, disc_loss = 0.0009047494295373326
Trained batch 32 in epoch 2, gen_loss = 0.9578693220109651, disc_loss = 0.0008983158869809951
Trained batch 33 in epoch 2, gen_loss = 0.9590196732212516, disc_loss = 0.0009010382705395494
Trained batch 34 in epoch 2, gen_loss = 0.9591714331081935, disc_loss = 0.0009159242784205292
Trained batch 35 in epoch 2, gen_loss = 0.9596319844325384, disc_loss = 0.0009320008992088131
Trained batch 36 in epoch 2, gen_loss = 0.9612979615056837, disc_loss = 0.000952432131885576
Trained batch 37 in epoch 2, gen_loss = 0.9616836089836923, disc_loss = 0.0009592435074553482
Trained batch 38 in epoch 2, gen_loss = 0.9630465110143026, disc_loss = 0.000957436887965275
Trained batch 39 in epoch 2, gen_loss = 0.9629758715629577, disc_loss = 0.0009565508546074853
Trained batch 40 in epoch 2, gen_loss = 0.9642121326632616, disc_loss = 0.0009668128587668989
Trained batch 41 in epoch 2, gen_loss = 0.9637880978130159, disc_loss = 0.0009739519861925926
Trained batch 42 in epoch 2, gen_loss = 0.963721678700558, disc_loss = 0.0009701088244138762
Trained batch 43 in epoch 2, gen_loss = 0.9645168076861989, disc_loss = 0.0009600669396935369
Trained batch 44 in epoch 2, gen_loss = 0.9658287233776517, disc_loss = 0.000952696201339778
Trained batch 45 in epoch 2, gen_loss = 0.9665942010672196, disc_loss = 0.0009498914486080732
Trained batch 46 in epoch 2, gen_loss = 0.9659972913721775, disc_loss = 0.0009497632210618479
Trained batch 47 in epoch 2, gen_loss = 0.9655044960478941, disc_loss = 0.0009601642050256487
Trained batch 48 in epoch 2, gen_loss = 0.9635392269309686, disc_loss = 0.0009670565106753944
Trained batch 49 in epoch 2, gen_loss = 0.9634083652496338, disc_loss = 0.000962263410910964
Trained batch 50 in epoch 2, gen_loss = 0.9623324847688862, disc_loss = 0.0009616495603147675
Trained batch 51 in epoch 2, gen_loss = 0.9639126910613134, disc_loss = 0.000971992146402884
Trained batch 52 in epoch 2, gen_loss = 0.9624354479447851, disc_loss = 0.000988558461924769
Trained batch 53 in epoch 2, gen_loss = 0.9627548974973185, disc_loss = 0.0010029740450489852
Trained batch 54 in epoch 2, gen_loss = 0.9621810761365024, disc_loss = 0.0010104617569595576
Trained batch 55 in epoch 2, gen_loss = 0.962095347898347, disc_loss = 0.0010086503877703632
Trained batch 56 in epoch 2, gen_loss = 0.9625135817025837, disc_loss = 0.001006062069025479
Trained batch 57 in epoch 2, gen_loss = 0.9626929739425922, disc_loss = 0.0010045754496441704
Trained batch 58 in epoch 2, gen_loss = 0.9615759081759695, disc_loss = 0.0010043119851862853
Trained batch 59 in epoch 2, gen_loss = 0.9601519405841827, disc_loss = 0.0010047333965000386
Trained batch 60 in epoch 2, gen_loss = 0.9606380618986536, disc_loss = 0.0010044452835439293
Trained batch 61 in epoch 2, gen_loss = 0.9600796036181911, disc_loss = 0.0010103551293497966
Trained batch 62 in epoch 2, gen_loss = 0.9592477849551609, disc_loss = 0.0010206952777927713
Trained batch 63 in epoch 2, gen_loss = 0.9594763871282339, disc_loss = 0.001016755537420977
Trained batch 64 in epoch 2, gen_loss = 0.9590616427935087, disc_loss = 0.0010132475111346978
Trained batch 65 in epoch 2, gen_loss = 0.9591274694962935, disc_loss = 0.001016448230736635
Trained batch 66 in epoch 2, gen_loss = 0.9576198405294276, disc_loss = 0.0010278489815988647
Trained batch 67 in epoch 2, gen_loss = 0.9566548370263156, disc_loss = 0.001037389356711441
Trained batch 68 in epoch 2, gen_loss = 0.9561863187430562, disc_loss = 0.0010367936397349272
Trained batch 69 in epoch 2, gen_loss = 0.9565957282270704, disc_loss = 0.0010325795363834394
Trained batch 70 in epoch 2, gen_loss = 0.9575952534944239, disc_loss = 0.0010308255474279883
Trained batch 71 in epoch 2, gen_loss = 0.957352925505903, disc_loss = 0.0010330646441111134
Trained batch 72 in epoch 2, gen_loss = 0.9580301903698543, disc_loss = 0.0010374701128991908
Trained batch 73 in epoch 2, gen_loss = 0.9590751407919703, disc_loss = 0.0010423804538928576
Trained batch 74 in epoch 2, gen_loss = 0.958931987285614, disc_loss = 0.0010388937235499421
Trained batch 75 in epoch 2, gen_loss = 0.9591552756334606, disc_loss = 0.0010366590025736705
Trained batch 76 in epoch 2, gen_loss = 0.9586373908179147, disc_loss = 0.0010369007911097694
Trained batch 77 in epoch 2, gen_loss = 0.9589031590865209, disc_loss = 0.0010367804863609564
Trained batch 78 in epoch 2, gen_loss = 0.9581564944001693, disc_loss = 0.001035886342177474
Trained batch 79 in epoch 2, gen_loss = 0.95783596560359, disc_loss = 0.0010355786042055115
Trained batch 80 in epoch 2, gen_loss = 0.9586576848854254, disc_loss = 0.0010338615723828107
Trained batch 81 in epoch 2, gen_loss = 0.9592500045532133, disc_loss = 0.0010335597879730348
Trained batch 82 in epoch 2, gen_loss = 0.9593971759439951, disc_loss = 0.00103147619288886
Trained batch 83 in epoch 2, gen_loss = 0.9587597300608953, disc_loss = 0.00102857477932481
Trained batch 84 in epoch 2, gen_loss = 0.9580791241982404, disc_loss = 0.0010257338495541584
Trained batch 85 in epoch 2, gen_loss = 0.9581778888092485, disc_loss = 0.0010223157052762894
Trained batch 86 in epoch 2, gen_loss = 0.956971862535367, disc_loss = 0.0010200318011947661
Trained batch 87 in epoch 2, gen_loss = 0.9561217447573488, disc_loss = 0.0010224870738139461
Trained batch 88 in epoch 2, gen_loss = 0.9569793089052264, disc_loss = 0.0010235535426933863
Trained batch 89 in epoch 2, gen_loss = 0.9569625602828131, disc_loss = 0.0010232586187258776
Trained batch 90 in epoch 2, gen_loss = 0.9573306172758669, disc_loss = 0.0010247589274473324
Trained batch 91 in epoch 2, gen_loss = 0.9573472012644229, disc_loss = 0.0010258174639286312
Trained batch 92 in epoch 2, gen_loss = 0.9578937881736345, disc_loss = 0.0010261592806957822
Trained batch 93 in epoch 2, gen_loss = 0.958721472861919, disc_loss = 0.0010266084715654638
Trained batch 94 in epoch 2, gen_loss = 0.9587326225481535, disc_loss = 0.0010237903891768502
Trained batch 95 in epoch 2, gen_loss = 0.958850501726071, disc_loss = 0.0010194473719214632
Trained batch 96 in epoch 2, gen_loss = 0.9582284240378547, disc_loss = 0.001015396485076353
Trained batch 97 in epoch 2, gen_loss = 0.9586098346174979, disc_loss = 0.0010176403436106534
Trained batch 98 in epoch 2, gen_loss = 0.9579373712491508, disc_loss = 0.0010282268002158915
Trained batch 99 in epoch 2, gen_loss = 0.9581140571832657, disc_loss = 0.0010389878402929753
Trained batch 100 in epoch 2, gen_loss = 0.9597213840720678, disc_loss = 0.001056085676093134
Trained batch 101 in epoch 2, gen_loss = 0.9595724198163724, disc_loss = 0.0010572993413399102
Trained batch 102 in epoch 2, gen_loss = 0.9601653125679609, disc_loss = 0.0010544888209551573
Trained batch 103 in epoch 2, gen_loss = 0.9600194870279386, disc_loss = 0.0010562583920545876
Trained batch 104 in epoch 2, gen_loss = 0.9600956615947541, disc_loss = 0.001058341940820572
Trained batch 105 in epoch 2, gen_loss = 0.9606029655573503, disc_loss = 0.001060601667597679
Trained batch 106 in epoch 2, gen_loss = 0.9609945583566327, disc_loss = 0.001062127919301878
Trained batch 107 in epoch 2, gen_loss = 0.9609369861858862, disc_loss = 0.0010601243982953882
Trained batch 108 in epoch 2, gen_loss = 0.9619454730541335, disc_loss = 0.0010634510918870704
Trained batch 109 in epoch 2, gen_loss = 0.9618381505662744, disc_loss = 0.0010732347145676613
Trained batch 110 in epoch 2, gen_loss = 0.9616717459919216, disc_loss = 0.0010862203549828616
Trained batch 111 in epoch 2, gen_loss = 0.9633415399917534, disc_loss = 0.001096841409370037
Trained batch 112 in epoch 2, gen_loss = 0.9645728068014162, disc_loss = 0.0011033638549424643
Trained batch 113 in epoch 2, gen_loss = 0.9655453400653705, disc_loss = 0.0011065357820163563
Trained batch 114 in epoch 2, gen_loss = 0.9657859548278477, disc_loss = 0.001108834624249974
Trained batch 115 in epoch 2, gen_loss = 0.9662936612449843, disc_loss = 0.0011164316865374688
Trained batch 116 in epoch 2, gen_loss = 0.966212920144073, disc_loss = 0.0011324872945347785
Trained batch 117 in epoch 2, gen_loss = 0.9659228057174359, disc_loss = 0.0011511335289500402
Trained batch 118 in epoch 2, gen_loss = 0.9657016757155666, disc_loss = 0.0011609681801745245
Trained batch 119 in epoch 2, gen_loss = 0.965938342610995, disc_loss = 0.0011662640637950972
Trained batch 120 in epoch 2, gen_loss = 0.9659663901841344, disc_loss = 0.0011688820038314078
Trained batch 121 in epoch 2, gen_loss = 0.9661238310767002, disc_loss = 0.001168709756905732
Trained batch 122 in epoch 2, gen_loss = 0.9665080396140494, disc_loss = 0.001165944890297071
Trained batch 123 in epoch 2, gen_loss = 0.9661847372208873, disc_loss = 0.0011643478276035298
Trained batch 124 in epoch 2, gen_loss = 0.9665646800994873, disc_loss = 0.0011666524061001837
Trained batch 125 in epoch 2, gen_loss = 0.9664153352616325, disc_loss = 0.0011670664225387135
Trained batch 126 in epoch 2, gen_loss = 0.9666905994490376, disc_loss = 0.001165479949151173
Trained batch 127 in epoch 2, gen_loss = 0.9670447129756212, disc_loss = 0.0011625408551481087
Trained batch 128 in epoch 2, gen_loss = 0.9670786432517592, disc_loss = 0.0011584174723631537
Trained batch 129 in epoch 2, gen_loss = 0.9667385133413168, disc_loss = 0.001154098572442308
Trained batch 130 in epoch 2, gen_loss = 0.9662457649944393, disc_loss = 0.0011497194183819736
Trained batch 131 in epoch 2, gen_loss = 0.9661245255759268, disc_loss = 0.001146216268711159
Trained batch 132 in epoch 2, gen_loss = 0.965824073866794, disc_loss = 0.001141404361495594
Trained batch 133 in epoch 2, gen_loss = 0.9653434682248244, disc_loss = 0.0011369748272995618
Trained batch 134 in epoch 2, gen_loss = 0.9657437086105347, disc_loss = 0.0011357561310028864
Trained batch 135 in epoch 2, gen_loss = 0.9657491261468214, disc_loss = 0.0011362841541995294
Trained batch 136 in epoch 2, gen_loss = 0.9655187538940541, disc_loss = 0.001137098582566845
Trained batch 137 in epoch 2, gen_loss = 0.9660365745641183, disc_loss = 0.001136536856327017
Trained batch 138 in epoch 2, gen_loss = 0.9660775944483366, disc_loss = 0.001132093142155263
Trained batch 139 in epoch 2, gen_loss = 0.9657749354839325, disc_loss = 0.001126459009537939
Trained batch 140 in epoch 2, gen_loss = 0.966311183381588, disc_loss = 0.0011229712628769352
Trained batch 141 in epoch 2, gen_loss = 0.9663593458457732, disc_loss = 0.0011220463712676757
Trained batch 142 in epoch 2, gen_loss = 0.966414320718992, disc_loss = 0.001122947938787471
Trained batch 143 in epoch 2, gen_loss = 0.9664616580638621, disc_loss = 0.0011254499535829786
Trained batch 144 in epoch 2, gen_loss = 0.96743288410121, disc_loss = 0.0011315975227826757
Trained batch 145 in epoch 2, gen_loss = 0.9673217873867244, disc_loss = 0.0011415676636803156
Trained batch 146 in epoch 2, gen_loss = 0.966762692344432, disc_loss = 0.0011534950694744
Trained batch 147 in epoch 2, gen_loss = 0.9666297101491207, disc_loss = 0.0011611061716983975
Trained batch 148 in epoch 2, gen_loss = 0.9668612604173238, disc_loss = 0.0011664353994318229
Trained batch 149 in epoch 2, gen_loss = 0.9671195876598359, disc_loss = 0.0011677053394184137
Trained batch 150 in epoch 2, gen_loss = 0.9669765115573706, disc_loss = 0.0011651363096196845
Trained batch 151 in epoch 2, gen_loss = 0.9675856828689575, disc_loss = 0.0011631751689205167
Trained batch 152 in epoch 2, gen_loss = 0.9678851778990303, disc_loss = 0.0011620286464450722
Trained batch 153 in epoch 2, gen_loss = 0.9679148336509605, disc_loss = 0.0011599288114524967
Trained batch 154 in epoch 2, gen_loss = 0.9677873972923525, disc_loss = 0.00115769280950659
Trained batch 155 in epoch 2, gen_loss = 0.9675552107584782, disc_loss = 0.001156935228209477
Trained batch 156 in epoch 2, gen_loss = 0.9670055277028661, disc_loss = 0.0011560480307956718
Trained batch 157 in epoch 2, gen_loss = 0.9675560314444047, disc_loss = 0.0011544501796862865
Trained batch 158 in epoch 2, gen_loss = 0.9673150894027086, disc_loss = 0.0011531839228847282
Trained batch 159 in epoch 2, gen_loss = 0.9677192140370607, disc_loss = 0.0011545959356226375
Trained batch 160 in epoch 2, gen_loss = 0.9679259443134995, disc_loss = 0.001157596476501872
Trained batch 161 in epoch 2, gen_loss = 0.9674647306954419, disc_loss = 0.0011624499936631226
Trained batch 162 in epoch 2, gen_loss = 0.9673213289559253, disc_loss = 0.0011702219109648005
Trained batch 163 in epoch 2, gen_loss = 0.9671365756814073, disc_loss = 0.0011760046691051684
Trained batch 164 in epoch 2, gen_loss = 0.9672817880457097, disc_loss = 0.0011763093525642586
Trained batch 165 in epoch 2, gen_loss = 0.9678464675524149, disc_loss = 0.001174397756245986
Trained batch 166 in epoch 2, gen_loss = 0.9680897454301755, disc_loss = 0.0011729009156352366
Trained batch 167 in epoch 2, gen_loss = 0.9676566351027716, disc_loss = 0.0011714642052885168
Trained batch 168 in epoch 2, gen_loss = 0.9672771113864064, disc_loss = 0.0011709872545390637
Trained batch 169 in epoch 2, gen_loss = 0.9672096809920143, disc_loss = 0.0011698405636707322
Trained batch 170 in epoch 2, gen_loss = 0.967205900546403, disc_loss = 0.0011688238154478612
Trained batch 171 in epoch 2, gen_loss = 0.9667257593814716, disc_loss = 0.001168550411273108
Trained batch 172 in epoch 2, gen_loss = 0.9665010151146465, disc_loss = 0.00117011872040124
Trained batch 173 in epoch 2, gen_loss = 0.966224727616913, disc_loss = 0.001172160608165405
Trained batch 174 in epoch 2, gen_loss = 0.9655710850443159, disc_loss = 0.001173706616308274
Trained batch 175 in epoch 2, gen_loss = 0.9657762277532708, disc_loss = 0.0011761947827670322
Trained batch 176 in epoch 2, gen_loss = 0.9660073798255059, disc_loss = 0.0011802615506093066
Trained batch 177 in epoch 2, gen_loss = 0.9661139293333117, disc_loss = 0.0011825469955919687
Trained batch 178 in epoch 2, gen_loss = 0.966321716428469, disc_loss = 0.0011827100509603367
Trained batch 179 in epoch 2, gen_loss = 0.9664596097336875, disc_loss = 0.001182877575209002
Trained batch 180 in epoch 2, gen_loss = 0.9666212401996002, disc_loss = 0.0011812796710426944
Trained batch 181 in epoch 2, gen_loss = 0.9663827183482411, disc_loss = 0.001181472554530406
Trained batch 182 in epoch 2, gen_loss = 0.9670794446611665, disc_loss = 0.0011861662243943295
Trained batch 183 in epoch 2, gen_loss = 0.9670889490972394, disc_loss = 0.0011895095678641076
Trained batch 184 in epoch 2, gen_loss = 0.967147231424177, disc_loss = 0.0011897502251510584
Trained batch 185 in epoch 2, gen_loss = 0.9673066168062149, disc_loss = 0.0011881604896775717
Trained batch 186 in epoch 2, gen_loss = 0.9668572188061189, disc_loss = 0.0011867464501049648
Trained batch 187 in epoch 2, gen_loss = 0.9669745523244777, disc_loss = 0.001184664215698115
Trained batch 188 in epoch 2, gen_loss = 0.9672948673919395, disc_loss = 0.001183276724226763
Trained batch 189 in epoch 2, gen_loss = 0.9672654807567597, disc_loss = 0.0011815600205935832
Trained batch 190 in epoch 2, gen_loss = 0.9669851819882218, disc_loss = 0.00117892192122624
Trained batch 191 in epoch 2, gen_loss = 0.9673964157700539, disc_loss = 0.001178109366416417
Trained batch 192 in epoch 2, gen_loss = 0.9674127985158733, disc_loss = 0.0011796499046055513
Trained batch 193 in epoch 2, gen_loss = 0.9675076628468701, disc_loss = 0.0011804944356440172
Trained batch 194 in epoch 2, gen_loss = 0.9673555673697056, disc_loss = 0.0011800327133805228
Trained batch 195 in epoch 2, gen_loss = 0.9671922715342774, disc_loss = 0.0011773243926914542
Trained batch 196 in epoch 2, gen_loss = 0.9668319403822652, disc_loss = 0.0011733560673691577
Trained batch 197 in epoch 2, gen_loss = 0.9668604776714788, disc_loss = 0.0011698711883086203
Trained batch 198 in epoch 2, gen_loss = 0.9671990670750489, disc_loss = 0.0011667727020945886
Trained batch 199 in epoch 2, gen_loss = 0.9671089512109756, disc_loss = 0.0011648199531191495
Trained batch 200 in epoch 2, gen_loss = 0.9667819044483241, disc_loss = 0.0011634114776119422
Trained batch 201 in epoch 2, gen_loss = 0.9671545040489423, disc_loss = 0.001162532183755475
Trained batch 202 in epoch 2, gen_loss = 0.9675071544835133, disc_loss = 0.0011649329054428568
Trained batch 203 in epoch 2, gen_loss = 0.9671274698248097, disc_loss = 0.0011680553684081864
Trained batch 204 in epoch 2, gen_loss = 0.9672457633948908, disc_loss = 0.0011705835603983937
Trained batch 205 in epoch 2, gen_loss = 0.9670050233891867, disc_loss = 0.001171357222031395
Trained batch 206 in epoch 2, gen_loss = 0.9666792684131198, disc_loss = 0.0011697291971042591
Trained batch 207 in epoch 2, gen_loss = 0.9667914595741492, disc_loss = 0.0011672476857011833
Trained batch 208 in epoch 2, gen_loss = 0.9667842995607111, disc_loss = 0.0011645955125228658
Trained batch 209 in epoch 2, gen_loss = 0.9669194227173215, disc_loss = 0.0011631958049422662
Trained batch 210 in epoch 2, gen_loss = 0.9666773295515522, disc_loss = 0.0011632006663125079
Trained batch 211 in epoch 2, gen_loss = 0.9664825527173169, disc_loss = 0.001163120820974483
Trained batch 212 in epoch 2, gen_loss = 0.966677252675446, disc_loss = 0.001162662895690396
Trained batch 213 in epoch 2, gen_loss = 0.9669965121233575, disc_loss = 0.0011614723799904705
Trained batch 214 in epoch 2, gen_loss = 0.966833251576091, disc_loss = 0.0011602588340390992
Trained batch 215 in epoch 2, gen_loss = 0.9667759835720062, disc_loss = 0.0011601883938796905
Trained batch 216 in epoch 2, gen_loss = 0.9670055720113939, disc_loss = 0.0011593475960643559
Trained batch 217 in epoch 2, gen_loss = 0.9669843553949934, disc_loss = 0.00115712514692392
Trained batch 218 in epoch 2, gen_loss = 0.9669835542979306, disc_loss = 0.001155265236032072
Trained batch 219 in epoch 2, gen_loss = 0.9669836038892919, disc_loss = 0.0011531893252553843
Trained batch 220 in epoch 2, gen_loss = 0.9666245884485374, disc_loss = 0.0011511040761660177
Trained batch 221 in epoch 2, gen_loss = 0.967177625174995, disc_loss = 0.0011568197419160038
Trained batch 222 in epoch 2, gen_loss = 0.9673188315378711, disc_loss = 0.0011627858674577583
Trained batch 223 in epoch 2, gen_loss = 0.9672328710023846, disc_loss = 0.001164920465790991
Trained batch 224 in epoch 2, gen_loss = 0.9670948444472419, disc_loss = 0.0011653375582924735
Trained batch 225 in epoch 2, gen_loss = 0.9669425120923372, disc_loss = 0.0011646972083954339
Trained batch 226 in epoch 2, gen_loss = 0.9669862667894573, disc_loss = 0.001162524468810113
Trained batch 227 in epoch 2, gen_loss = 0.9669145625411418, disc_loss = 0.0011596959754426376
Trained batch 228 in epoch 2, gen_loss = 0.9669127269082715, disc_loss = 0.0011573927879880495
Trained batch 229 in epoch 2, gen_loss = 0.9667845412440922, disc_loss = 0.001155327454730666
Trained batch 230 in epoch 2, gen_loss = 0.9667958637852689, disc_loss = 0.0011527053829135366
Trained batch 231 in epoch 2, gen_loss = 0.9664376447426861, disc_loss = 0.0011500490349888046
Trained batch 232 in epoch 2, gen_loss = 0.9660734866821715, disc_loss = 0.0011479314248019614
Trained batch 233 in epoch 2, gen_loss = 0.9664079778724246, disc_loss = 0.0011453489845361896
Trained batch 234 in epoch 2, gen_loss = 0.9663352322071157, disc_loss = 0.0011433546999816168
Trained batch 235 in epoch 2, gen_loss = 0.9661590424129518, disc_loss = 0.001142786757924823
Trained batch 236 in epoch 2, gen_loss = 0.9661204734432043, disc_loss = 0.0011422734628755693
Trained batch 237 in epoch 2, gen_loss = 0.9664094087456455, disc_loss = 0.0011439030321594719
Trained batch 238 in epoch 2, gen_loss = 0.966140570002121, disc_loss = 0.0011473259250253487
Trained batch 239 in epoch 2, gen_loss = 0.9661474898457527, disc_loss = 0.0011523843712590556
Trained batch 240 in epoch 2, gen_loss = 0.9659359234991904, disc_loss = 0.0011554320966699295
Trained batch 241 in epoch 2, gen_loss = 0.9663567520862768, disc_loss = 0.0011599349469660343
Trained batch 242 in epoch 2, gen_loss = 0.96635693115462, disc_loss = 0.0011652232019121495
Trained batch 243 in epoch 2, gen_loss = 0.9660141915082932, disc_loss = 0.0011699503810349164
Trained batch 244 in epoch 2, gen_loss = 0.9656422233094974, disc_loss = 0.0011743898716118492
Trained batch 245 in epoch 2, gen_loss = 0.9654650162390577, disc_loss = 0.0011769629118356445
Trained batch 246 in epoch 2, gen_loss = 0.9651884909583489, disc_loss = 0.001178332856976001
Trained batch 247 in epoch 2, gen_loss = 0.9654198233639041, disc_loss = 0.0011785177469597152
Trained batch 248 in epoch 2, gen_loss = 0.9652991627593596, disc_loss = 0.0011767669225319188
Trained batch 249 in epoch 2, gen_loss = 0.9651739492416381, disc_loss = 0.0011742716714506969
Trained batch 250 in epoch 2, gen_loss = 0.965275736444025, disc_loss = 0.00117229125812646
Trained batch 251 in epoch 2, gen_loss = 0.9654303566804008, disc_loss = 0.0011707306540402998
Trained batch 252 in epoch 2, gen_loss = 0.9656213672735946, disc_loss = 0.0011686551164451014
Trained batch 253 in epoch 2, gen_loss = 0.9655935447516404, disc_loss = 0.0011668671047412166
Trained batch 254 in epoch 2, gen_loss = 0.9653491293682771, disc_loss = 0.001166633353682746
Trained batch 255 in epoch 2, gen_loss = 0.9653278291225433, disc_loss = 0.0011654433754983984
Trained batch 256 in epoch 2, gen_loss = 0.9652459157580068, disc_loss = 0.0011622620127499032
Trained batch 257 in epoch 2, gen_loss = 0.965195031591164, disc_loss = 0.0011611324336782258
Trained batch 258 in epoch 2, gen_loss = 0.9648660683723951, disc_loss = 0.001163529632968152
Trained batch 259 in epoch 2, gen_loss = 0.9648847082486519, disc_loss = 0.0011675846618555414
Trained batch 260 in epoch 2, gen_loss = 0.9649871898336886, disc_loss = 0.0011711375504844532
Trained batch 261 in epoch 2, gen_loss = 0.9651113018279768, disc_loss = 0.00117171170331719
Trained batch 262 in epoch 2, gen_loss = 0.9652961295367194, disc_loss = 0.0011721739567375385
Trained batch 263 in epoch 2, gen_loss = 0.9652613706209443, disc_loss = 0.0011722547103338663
Trained batch 264 in epoch 2, gen_loss = 0.9652028639361544, disc_loss = 0.0011714390605327867
Trained batch 265 in epoch 2, gen_loss = 0.9650495948648095, disc_loss = 0.0011699866743966642
Trained batch 266 in epoch 2, gen_loss = 0.9648002618261045, disc_loss = 0.0011686541649996048
Trained batch 267 in epoch 2, gen_loss = 0.9645618818589111, disc_loss = 0.0011668367713816644
Trained batch 268 in epoch 2, gen_loss = 0.9645677738473318, disc_loss = 0.0011653431751168087
Trained batch 269 in epoch 2, gen_loss = 0.9642692018438268, disc_loss = 0.0011646607577050518
Trained batch 270 in epoch 2, gen_loss = 0.9643444009812555, disc_loss = 0.0011636591403671227
Trained batch 271 in epoch 2, gen_loss = 0.9645457563593107, disc_loss = 0.0011627179813812666
Trained batch 272 in epoch 2, gen_loss = 0.9641879168185559, disc_loss = 0.0011620999139267951
Trained batch 273 in epoch 2, gen_loss = 0.9643235263163156, disc_loss = 0.0011610372819857888
Trained batch 274 in epoch 2, gen_loss = 0.964237422726371, disc_loss = 0.0011585755851543085
Trained batch 275 in epoch 2, gen_loss = 0.9641087463368541, disc_loss = 0.001156408096363336
Trained batch 276 in epoch 2, gen_loss = 0.9643576155931081, disc_loss = 0.0011546545847325792
Trained batch 277 in epoch 2, gen_loss = 0.964393665464662, disc_loss = 0.0011532581836343643
Trained batch 278 in epoch 2, gen_loss = 0.9641978943647023, disc_loss = 0.0011538410854298874
Trained batch 279 in epoch 2, gen_loss = 0.9643076522009714, disc_loss = 0.0011540410302196896
Trained batch 280 in epoch 2, gen_loss = 0.9643016909365127, disc_loss = 0.0011531316741117776
Trained batch 281 in epoch 2, gen_loss = 0.9641768057295617, disc_loss = 0.0011526069425109192
Trained batch 282 in epoch 2, gen_loss = 0.9640639247405656, disc_loss = 0.0011529282034480081
Trained batch 283 in epoch 2, gen_loss = 0.9641066325802199, disc_loss = 0.0011527761773937578
Trained batch 284 in epoch 2, gen_loss = 0.9640499368048551, disc_loss = 0.0011513568164797075
Trained batch 285 in epoch 2, gen_loss = 0.9641393337633226, disc_loss = 0.0011493380143228996
Trained batch 286 in epoch 2, gen_loss = 0.96401169553451, disc_loss = 0.0011485937807566198
Trained batch 287 in epoch 2, gen_loss = 0.9636925767279334, disc_loss = 0.0011485582177152133
Trained batch 288 in epoch 2, gen_loss = 0.9635070347868447, disc_loss = 0.0011487585487598264
Trained batch 289 in epoch 2, gen_loss = 0.9639423226488048, disc_loss = 0.0011510105414219715
Trained batch 290 in epoch 2, gen_loss = 0.9640630540978867, disc_loss = 0.0011658159487071059
Trained batch 291 in epoch 2, gen_loss = 0.9639517456701358, disc_loss = 0.001183401832711079
Trained batch 292 in epoch 2, gen_loss = 0.9637576899024, disc_loss = 0.0011939621373928397
Trained batch 293 in epoch 2, gen_loss = 0.9634729500125054, disc_loss = 0.0011975454577548923
Trained batch 294 in epoch 2, gen_loss = 0.9637332097958711, disc_loss = 0.001209555254949225
Trained batch 295 in epoch 2, gen_loss = 0.9637769140504502, disc_loss = 0.001218209691688645
Trained batch 296 in epoch 2, gen_loss = 0.9636713131911024, disc_loss = 0.0012203977017597569
Trained batch 297 in epoch 2, gen_loss = 0.9634080687225265, disc_loss = 0.001222782863238389
Trained batch 298 in epoch 2, gen_loss = 0.9633894783996021, disc_loss = 0.0012267260655704699
Trained batch 299 in epoch 2, gen_loss = 0.9632807596524556, disc_loss = 0.0012299719324801116
Trained batch 300 in epoch 2, gen_loss = 0.9631479424099589, disc_loss = 0.0012315278714275192
Trained batch 301 in epoch 2, gen_loss = 0.9626655558876643, disc_loss = 0.001232558612354001
Trained batch 302 in epoch 2, gen_loss = 0.9625941615293522, disc_loss = 0.00123201590569278
Trained batch 303 in epoch 2, gen_loss = 0.9625042294593233, disc_loss = 0.0012309123439512117
Trained batch 304 in epoch 2, gen_loss = 0.9623915197419338, disc_loss = 0.0012300239003751976
Trained batch 305 in epoch 2, gen_loss = 0.9624009247309242, disc_loss = 0.0012294335632807168
Trained batch 306 in epoch 2, gen_loss = 0.962380624943525, disc_loss = 0.0012281916949121398
Trained batch 307 in epoch 2, gen_loss = 0.9622981848267765, disc_loss = 0.0012260929279954644
Trained batch 308 in epoch 2, gen_loss = 0.9619000280173465, disc_loss = 0.0012241297455739628
Trained batch 309 in epoch 2, gen_loss = 0.9619925639321727, disc_loss = 0.0012226076443649589
Trained batch 310 in epoch 2, gen_loss = 0.9617557943442243, disc_loss = 0.0012219913488769024
Trained batch 311 in epoch 2, gen_loss = 0.9617519764563977, disc_loss = 0.0012229732039999457
Trained batch 312 in epoch 2, gen_loss = 0.9616834207083851, disc_loss = 0.0012237523714401803
Trained batch 313 in epoch 2, gen_loss = 0.9619487038083897, disc_loss = 0.0012239298006893392
Trained batch 314 in epoch 2, gen_loss = 0.9617877627175951, disc_loss = 0.0012230320887211415
Trained batch 315 in epoch 2, gen_loss = 0.9617479892471169, disc_loss = 0.0012210563681371322
Trained batch 316 in epoch 2, gen_loss = 0.9621321775183693, disc_loss = 0.0012254783948325207
Trained batch 317 in epoch 2, gen_loss = 0.9621259727567997, disc_loss = 0.0012296454705672819
Trained batch 318 in epoch 2, gen_loss = 0.9622740069153167, disc_loss = 0.001235252558647839
Trained batch 319 in epoch 2, gen_loss = 0.9620491307228803, disc_loss = 0.0012412815609422977
Trained batch 320 in epoch 2, gen_loss = 0.9621959505051467, disc_loss = 0.0012443023712034817
Trained batch 321 in epoch 2, gen_loss = 0.9621564882882634, disc_loss = 0.0012438740011489725
Trained batch 322 in epoch 2, gen_loss = 0.9619031921259759, disc_loss = 0.001241930028432317
Trained batch 323 in epoch 2, gen_loss = 0.9618609847477925, disc_loss = 0.001240237478747458
Trained batch 324 in epoch 2, gen_loss = 0.9616321270282452, disc_loss = 0.0012400068965955423
Trained batch 325 in epoch 2, gen_loss = 0.9614408912102869, disc_loss = 0.001240524769749241
Trained batch 326 in epoch 2, gen_loss = 0.9612599921153591, disc_loss = 0.0012408976040108397
Trained batch 327 in epoch 2, gen_loss = 0.9614185414663176, disc_loss = 0.0012407118075515892
Trained batch 328 in epoch 2, gen_loss = 0.9615228259454744, disc_loss = 0.0012400098545561717
Trained batch 329 in epoch 2, gen_loss = 0.9614631959886262, disc_loss = 0.0012390025538589918
Trained batch 330 in epoch 2, gen_loss = 0.9614072600520269, disc_loss = 0.001237974293583447
Trained batch 331 in epoch 2, gen_loss = 0.9614465985312519, disc_loss = 0.0012369770097338695
Trained batch 332 in epoch 2, gen_loss = 0.9613164367976489, disc_loss = 0.0012363990735229072
Trained batch 333 in epoch 2, gen_loss = 0.9612785008496153, disc_loss = 0.0012360395386837378
Trained batch 334 in epoch 2, gen_loss = 0.9611653098419531, disc_loss = 0.001235826114025801
Trained batch 335 in epoch 2, gen_loss = 0.9610678402795678, disc_loss = 0.0012352310129374797
Trained batch 336 in epoch 2, gen_loss = 0.961457331916345, disc_loss = 0.0012371521215134187
Trained batch 337 in epoch 2, gen_loss = 0.961050772455317, disc_loss = 0.0012406715317271077
Trained batch 338 in epoch 2, gen_loss = 0.9610586324624256, disc_loss = 0.0012484088829913585
Trained batch 339 in epoch 2, gen_loss = 0.9612832121989306, disc_loss = 0.001258007506155135
Trained batch 340 in epoch 2, gen_loss = 0.9613213659731175, disc_loss = 0.0012668548704908827
Trained batch 341 in epoch 2, gen_loss = 0.9613583612511729, disc_loss = 0.001273726233640653
Trained batch 342 in epoch 2, gen_loss = 0.961274617788743, disc_loss = 0.0012779825783820699
Trained batch 343 in epoch 2, gen_loss = 0.9613032942247945, disc_loss = 0.0012788660238838084
Trained batch 344 in epoch 2, gen_loss = 0.9612544241158859, disc_loss = 0.0012785137350927445
Trained batch 345 in epoch 2, gen_loss = 0.9610138647473616, disc_loss = 0.0012771583088563292
Trained batch 346 in epoch 2, gen_loss = 0.9611491966316267, disc_loss = 0.001276134302798036
Trained batch 347 in epoch 2, gen_loss = 0.9608828454524622, disc_loss = 0.0012771347532618855
Trained batch 348 in epoch 2, gen_loss = 0.9608110416584507, disc_loss = 0.0012784161540562217
Trained batch 349 in epoch 2, gen_loss = 0.9607391944953374, disc_loss = 0.0012790624636025833
Trained batch 350 in epoch 2, gen_loss = 0.9606107155821602, disc_loss = 0.0012794204812133392
Trained batch 351 in epoch 2, gen_loss = 0.9604963563721288, disc_loss = 0.0012784034117265203
Trained batch 352 in epoch 2, gen_loss = 0.9606384405333327, disc_loss = 0.0012770001788059034
Trained batch 353 in epoch 2, gen_loss = 0.9604948250587377, disc_loss = 0.0012755926177537037
Trained batch 354 in epoch 2, gen_loss = 0.9605907339445302, disc_loss = 0.0012743555193006153
Trained batch 355 in epoch 2, gen_loss = 0.9604447691628103, disc_loss = 0.0012726745008375872
Trained batch 356 in epoch 2, gen_loss = 0.9605556309056216, disc_loss = 0.0012709381342839439
Trained batch 357 in epoch 2, gen_loss = 0.9603601539268174, disc_loss = 0.0012692321456419875
Trained batch 358 in epoch 2, gen_loss = 0.960330919136908, disc_loss = 0.0012677482393840043
Trained batch 359 in epoch 2, gen_loss = 0.960517032775614, disc_loss = 0.0012665078520917128
Trained batch 360 in epoch 2, gen_loss = 0.9605407191445623, disc_loss = 0.0012645218448798558
Trained batch 361 in epoch 2, gen_loss = 0.9604902389299804, disc_loss = 0.001262103591306593
Trained batch 362 in epoch 2, gen_loss = 0.960513430029236, disc_loss = 0.0012600871149197827
Trained batch 363 in epoch 2, gen_loss = 0.9604494740347286, disc_loss = 0.0012588340540097996
Trained batch 364 in epoch 2, gen_loss = 0.9603570195093547, disc_loss = 0.0012586100750175393
Trained batch 365 in epoch 2, gen_loss = 0.9603229108078232, disc_loss = 0.0012574193930308096
Trained batch 366 in epoch 2, gen_loss = 0.9603699617879592, disc_loss = 0.001255620875010744
Trained batch 367 in epoch 2, gen_loss = 0.9605085082028223, disc_loss = 0.0012537046009326689
Trained batch 368 in epoch 2, gen_loss = 0.9605486483431767, disc_loss = 0.0012522528258305003
Trained batch 369 in epoch 2, gen_loss = 0.9606704882673315, disc_loss = 0.001250710297058135
Trained batch 370 in epoch 2, gen_loss = 0.960453183985142, disc_loss = 0.0012486955138253464
Trained batch 371 in epoch 2, gen_loss = 0.9603485514720281, disc_loss = 0.0012471116662259535
Trained batch 372 in epoch 2, gen_loss = 0.9604119578571166, disc_loss = 0.0012447627816984715
Trained batch 373 in epoch 2, gen_loss = 0.9602554384718605, disc_loss = 0.0012433830362135784
Trained batch 374 in epoch 2, gen_loss = 0.9602551800409953, disc_loss = 0.0012441650497882317
Trained batch 375 in epoch 2, gen_loss = 0.9603033931331432, disc_loss = 0.0012446489553382134
Trained batch 376 in epoch 2, gen_loss = 0.9603942099869726, disc_loss = 0.0012439452246818395
Trained batch 377 in epoch 2, gen_loss = 0.9606288732990386, disc_loss = 0.0012427523809025636
Trained batch 378 in epoch 2, gen_loss = 0.9605818065301095, disc_loss = 0.001240993605967793
Trained batch 379 in epoch 2, gen_loss = 0.9607423255318089, disc_loss = 0.0012394537358072979
Trained batch 380 in epoch 2, gen_loss = 0.9607800267187003, disc_loss = 0.00123817729251887
Trained batch 381 in epoch 2, gen_loss = 0.960780924683466, disc_loss = 0.0012364952492982355
Trained batch 382 in epoch 2, gen_loss = 0.9606738839074774, disc_loss = 0.0012345808741603746
Trained batch 383 in epoch 2, gen_loss = 0.9608250687209269, disc_loss = 0.0012330700291537748
Trained batch 384 in epoch 2, gen_loss = 0.9606524385415114, disc_loss = 0.001232009544566443
Trained batch 385 in epoch 2, gen_loss = 0.9607362135704317, disc_loss = 0.001232002781196787
Trained batch 386 in epoch 2, gen_loss = 0.9606758839708274, disc_loss = 0.0012326295124649646
Trained batch 387 in epoch 2, gen_loss = 0.9606890779795106, disc_loss = 0.001233841916267189
Trained batch 388 in epoch 2, gen_loss = 0.9605944119872655, disc_loss = 0.0012344818365201114
Trained batch 389 in epoch 2, gen_loss = 0.9604763458936643, disc_loss = 0.0012334587317383966
Trained batch 390 in epoch 2, gen_loss = 0.9603482243959861, disc_loss = 0.0012314803963092388
Trained batch 391 in epoch 2, gen_loss = 0.9603864369647843, disc_loss = 0.0012295820708125259
Trained batch 392 in epoch 2, gen_loss = 0.9604353979040345, disc_loss = 0.0012276366516845846
Trained batch 393 in epoch 2, gen_loss = 0.960615350661544, disc_loss = 0.001225849240811466
Trained batch 394 in epoch 2, gen_loss = 0.960495535633232, disc_loss = 0.0012241311439112584
Trained batch 395 in epoch 2, gen_loss = 0.9607425082211543, disc_loss = 0.001222811520835761
Trained batch 396 in epoch 2, gen_loss = 0.9605614018980743, disc_loss = 0.0012210779301399923
Trained batch 397 in epoch 2, gen_loss = 0.960527420642987, disc_loss = 0.001219859876173862
Trained batch 398 in epoch 2, gen_loss = 0.9604548982211522, disc_loss = 0.0012182603242403285
Trained batch 399 in epoch 2, gen_loss = 0.9603493370115757, disc_loss = 0.0012162607769278112
Trained batch 400 in epoch 2, gen_loss = 0.9603351552290215, disc_loss = 0.001214416636220247
Trained batch 401 in epoch 2, gen_loss = 0.960285742484515, disc_loss = 0.0012123939337669895
Trained batch 402 in epoch 2, gen_loss = 0.9602937136335349, disc_loss = 0.0012102744813024
Trained batch 403 in epoch 2, gen_loss = 0.9603915530266148, disc_loss = 0.0012085821175841743
Trained batch 404 in epoch 2, gen_loss = 0.9603506341392611, disc_loss = 0.0012083339036361854
Trained batch 405 in epoch 2, gen_loss = 0.9602798753477669, disc_loss = 0.001208808748774102
Trained batch 406 in epoch 2, gen_loss = 0.9603653772750124, disc_loss = 0.0012091175940217272
Trained batch 407 in epoch 2, gen_loss = 0.9604723107288865, disc_loss = 0.001208784074383313
Trained batch 408 in epoch 2, gen_loss = 0.9606895043097965, disc_loss = 0.0012086493083820074
Trained batch 409 in epoch 2, gen_loss = 0.9606256502430613, disc_loss = 0.0012091149081953053
Trained batch 410 in epoch 2, gen_loss = 0.9607535197496995, disc_loss = 0.0012105037571540568
Trained batch 411 in epoch 2, gen_loss = 0.9608239742737372, disc_loss = 0.0012120243715172073
Trained batch 412 in epoch 2, gen_loss = 0.9609084790324472, disc_loss = 0.0012139886700532447
Trained batch 413 in epoch 2, gen_loss = 0.960676395950686, disc_loss = 0.0012151111749108827
Trained batch 414 in epoch 2, gen_loss = 0.9605080107608474, disc_loss = 0.0012150636492633676
Trained batch 415 in epoch 2, gen_loss = 0.9604172245241128, disc_loss = 0.001214463950908304
Trained batch 416 in epoch 2, gen_loss = 0.960578807538076, disc_loss = 0.0012138666113563846
Trained batch 417 in epoch 2, gen_loss = 0.9606316267873682, disc_loss = 0.0012132485552287648
Trained batch 418 in epoch 2, gen_loss = 0.9607333961989828, disc_loss = 0.0012125018879889037
Trained batch 419 in epoch 2, gen_loss = 0.9608105084725789, disc_loss = 0.001211337960142243
Trained batch 420 in epoch 2, gen_loss = 0.9607924687324397, disc_loss = 0.0012100365647776251
Trained batch 421 in epoch 2, gen_loss = 0.9608662994269511, disc_loss = 0.0012086325115965618
Trained batch 422 in epoch 2, gen_loss = 0.9607555322331458, disc_loss = 0.0012070642031253651
Trained batch 423 in epoch 2, gen_loss = 0.9607868381547477, disc_loss = 0.001205649234866284
Trained batch 424 in epoch 2, gen_loss = 0.9607458749939414, disc_loss = 0.0012042537264471108
Trained batch 425 in epoch 2, gen_loss = 0.9609184358881113, disc_loss = 0.0012039645915761362
Trained batch 426 in epoch 2, gen_loss = 0.9608673827430404, disc_loss = 0.001204972146531519
Trained batch 427 in epoch 2, gen_loss = 0.9607988884237325, disc_loss = 0.0012062640084665286
Trained batch 428 in epoch 2, gen_loss = 0.9608284661542008, disc_loss = 0.0012088016717312618
Trained batch 429 in epoch 2, gen_loss = 0.960759241220563, disc_loss = 0.0012116696667954932
Trained batch 430 in epoch 2, gen_loss = 0.9607693053730126, disc_loss = 0.0012122454709727793
Trained batch 431 in epoch 2, gen_loss = 0.9607338759082334, disc_loss = 0.001210598814968425
Trained batch 432 in epoch 2, gen_loss = 0.9605726036684067, disc_loss = 0.0012086154580493748
Trained batch 433 in epoch 2, gen_loss = 0.9604873561090038, disc_loss = 0.0012066244940495566
Trained batch 434 in epoch 2, gen_loss = 0.9602997024854024, disc_loss = 0.0012049515410486994
Trained batch 435 in epoch 2, gen_loss = 0.9602207311796486, disc_loss = 0.0012044195852609814
Trained batch 436 in epoch 2, gen_loss = 0.9600985586234034, disc_loss = 0.0012056641528399947
Trained batch 437 in epoch 2, gen_loss = 0.9599958117966239, disc_loss = 0.0012069633289040428
Trained batch 438 in epoch 2, gen_loss = 0.9600158564593635, disc_loss = 0.0012063573980131154
Trained batch 439 in epoch 2, gen_loss = 0.9599694150415334, disc_loss = 0.00120510668202769
Trained batch 440 in epoch 2, gen_loss = 0.9597764515282076, disc_loss = 0.001204028930472814
Trained batch 441 in epoch 2, gen_loss = 0.9596208285422346, disc_loss = 0.0012025574674699203
Trained batch 442 in epoch 2, gen_loss = 0.9597902012732443, disc_loss = 0.0012020852440930315
Trained batch 443 in epoch 2, gen_loss = 0.9598352068716342, disc_loss = 0.0012035583610528963
Trained batch 444 in epoch 2, gen_loss = 0.9597557250033604, disc_loss = 0.0012067788557850578
Trained batch 445 in epoch 2, gen_loss = 0.9596769194966475, disc_loss = 0.0012107908797780295
Trained batch 446 in epoch 2, gen_loss = 0.9598621716702012, disc_loss = 0.0012139122676879369
Trained batch 447 in epoch 2, gen_loss = 0.9599192807716983, disc_loss = 0.0012149141706946206
Trained batch 448 in epoch 2, gen_loss = 0.9598355914542829, disc_loss = 0.0012146834562011975
Trained batch 449 in epoch 2, gen_loss = 0.9598965011702644, disc_loss = 0.001213572929199371
Trained batch 450 in epoch 2, gen_loss = 0.9596113273151169, disc_loss = 0.00121224736134024
Trained batch 451 in epoch 2, gen_loss = 0.959672513920649, disc_loss = 0.001211266575764403
Trained batch 452 in epoch 2, gen_loss = 0.9596791388446395, disc_loss = 0.0012104231679182969
Trained batch 453 in epoch 2, gen_loss = 0.9596920732884681, disc_loss = 0.0012093101164514799
Trained batch 454 in epoch 2, gen_loss = 0.9597235825035598, disc_loss = 0.0012082113329177865
Trained batch 455 in epoch 2, gen_loss = 0.9596368114937815, disc_loss = 0.0012069292507683777
Trained batch 456 in epoch 2, gen_loss = 0.9598646204372464, disc_loss = 0.001208252509769574
Trained batch 457 in epoch 2, gen_loss = 0.9597829745586262, disc_loss = 0.0012105827739077933
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.9061633944511414, disc_loss = 0.002487066201865673
Trained batch 1 in epoch 3, gen_loss = 0.9176789820194244, disc_loss = 0.0021582947811111808
Trained batch 2 in epoch 3, gen_loss = 0.9278600017229716, disc_loss = 0.0018909520391995709
Trained batch 3 in epoch 3, gen_loss = 0.9289489239454269, disc_loss = 0.0016536625480512157
Trained batch 4 in epoch 3, gen_loss = 0.9428307771682739, disc_loss = 0.0014415979268960655
Trained batch 5 in epoch 3, gen_loss = 0.949582556883494, disc_loss = 0.0012768521992256865
Trained batch 6 in epoch 3, gen_loss = 0.946779557636806, disc_loss = 0.001149568519654817
Trained batch 7 in epoch 3, gen_loss = 0.9554789662361145, disc_loss = 0.0010681393287086394
Trained batch 8 in epoch 3, gen_loss = 0.9547069999906752, disc_loss = 0.0010160988474833882
Trained batch 9 in epoch 3, gen_loss = 0.9569555282592773, disc_loss = 0.0009947209706297143
Trained batch 10 in epoch 3, gen_loss = 0.9606798995624889, disc_loss = 0.0009634822358334945
Trained batch 11 in epoch 3, gen_loss = 0.9556505084037781, disc_loss = 0.0009206223354946511
Trained batch 12 in epoch 3, gen_loss = 0.9528647156862112, disc_loss = 0.0008882920486100304
Trained batch 13 in epoch 3, gen_loss = 0.9652587132794517, disc_loss = 0.0008863710785850085
Trained batch 14 in epoch 3, gen_loss = 0.9648874719937642, disc_loss = 0.0008663065944953511
Trained batch 15 in epoch 3, gen_loss = 0.9667170532047749, disc_loss = 0.0008562460770917824
Trained batch 16 in epoch 3, gen_loss = 0.967873752117157, disc_loss = 0.0008505381085663376
Trained batch 17 in epoch 3, gen_loss = 0.96501953403155, disc_loss = 0.0008362504061854755
Trained batch 18 in epoch 3, gen_loss = 0.9667270654126218, disc_loss = 0.0008242134185581419
Trained batch 19 in epoch 3, gen_loss = 0.9673488169908524, disc_loss = 0.0008139183672028593
Trained batch 20 in epoch 3, gen_loss = 0.9672817332404, disc_loss = 0.0007978114604373418
Trained batch 21 in epoch 3, gen_loss = 0.9643105701966719, disc_loss = 0.0007789830190383575
Trained batch 22 in epoch 3, gen_loss = 0.9656576825224835, disc_loss = 0.0007636839620080655
Trained batch 23 in epoch 3, gen_loss = 0.9658856391906738, disc_loss = 0.0007561108917191935
Trained batch 24 in epoch 3, gen_loss = 0.9675941181182861, disc_loss = 0.0007517995778471232
Trained batch 25 in epoch 3, gen_loss = 0.9650734617159917, disc_loss = 0.0007469635523963147
Trained batch 26 in epoch 3, gen_loss = 0.965858397660432, disc_loss = 0.0007432624050933453
Trained batch 27 in epoch 3, gen_loss = 0.9661592777286258, disc_loss = 0.0007312389955456768
Trained batch 28 in epoch 3, gen_loss = 0.9694089293479919, disc_loss = 0.0007286268077662278
Trained batch 29 in epoch 3, gen_loss = 0.969236280520757, disc_loss = 0.0007290745309243599
Trained batch 30 in epoch 3, gen_loss = 0.96754434416371, disc_loss = 0.0007296231229819598
Trained batch 31 in epoch 3, gen_loss = 0.9660624340176582, disc_loss = 0.0007229344919323921
Trained batch 32 in epoch 3, gen_loss = 0.965640739961104, disc_loss = 0.0007156630304190471
Trained batch 33 in epoch 3, gen_loss = 0.964760810136795, disc_loss = 0.0007094281626290039
Trained batch 34 in epoch 3, gen_loss = 0.9629293152264187, disc_loss = 0.0007035482358852667
Trained batch 35 in epoch 3, gen_loss = 0.9615299320883222, disc_loss = 0.0006980141835002643
Trained batch 36 in epoch 3, gen_loss = 0.9612285075960932, disc_loss = 0.0006955273565836251
Trained batch 37 in epoch 3, gen_loss = 0.961201482697537, disc_loss = 0.0006945339769835731
Trained batch 38 in epoch 3, gen_loss = 0.9594407631800725, disc_loss = 0.0006893097426002034
Trained batch 39 in epoch 3, gen_loss = 0.958518448472023, disc_loss = 0.0006826779033872298
Trained batch 40 in epoch 3, gen_loss = 0.9580646346255046, disc_loss = 0.0006748054768583487
Trained batch 41 in epoch 3, gen_loss = 0.9601728717486063, disc_loss = 0.0006732472233817957
Trained batch 42 in epoch 3, gen_loss = 0.9601368003113325, disc_loss = 0.0006774712812837733
Trained batch 43 in epoch 3, gen_loss = 0.9576256586746736, disc_loss = 0.0006836139516301707
Trained batch 44 in epoch 3, gen_loss = 0.9583528108066983, disc_loss = 0.0006838679190776828
Trained batch 45 in epoch 3, gen_loss = 0.9589557699535204, disc_loss = 0.0006841624050613735
Trained batch 46 in epoch 3, gen_loss = 0.9579412683527521, disc_loss = 0.0006884190537520941
Trained batch 47 in epoch 3, gen_loss = 0.9592475791772207, disc_loss = 0.0006924397002876503
Trained batch 48 in epoch 3, gen_loss = 0.9580805581443164, disc_loss = 0.0006977960791638387
Trained batch 49 in epoch 3, gen_loss = 0.9582290947437286, disc_loss = 0.0007029250735649839
Trained batch 50 in epoch 3, gen_loss = 0.9572855608136046, disc_loss = 0.0007007114021974962
Trained batch 51 in epoch 3, gen_loss = 0.9561797025112005, disc_loss = 0.0006957741598643435
Trained batch 52 in epoch 3, gen_loss = 0.9559509675457792, disc_loss = 0.0006911001823851311
Trained batch 53 in epoch 3, gen_loss = 0.9577047438533218, disc_loss = 0.000692841864764449
Trained batch 54 in epoch 3, gen_loss = 0.9582915945486589, disc_loss = 0.0007024802653838627
Trained batch 55 in epoch 3, gen_loss = 0.9591317421623639, disc_loss = 0.0007173130626532449
Trained batch 56 in epoch 3, gen_loss = 0.9599503707467464, disc_loss = 0.0007349659260893404
Trained batch 57 in epoch 3, gen_loss = 0.9589539468288422, disc_loss = 0.0007534971734677473
Trained batch 58 in epoch 3, gen_loss = 0.9591998498318559, disc_loss = 0.0007675144336999284
Trained batch 59 in epoch 3, gen_loss = 0.959488891561826, disc_loss = 0.0007762045565565738
Trained batch 60 in epoch 3, gen_loss = 0.9596622381053987, disc_loss = 0.0007851929446781573
Trained batch 61 in epoch 3, gen_loss = 0.9592113148781561, disc_loss = 0.000797494086005064
Trained batch 62 in epoch 3, gen_loss = 0.9580633734899854, disc_loss = 0.0008033558228311853
Trained batch 63 in epoch 3, gen_loss = 0.956495089456439, disc_loss = 0.0008030075564420258
Trained batch 64 in epoch 3, gen_loss = 0.9547871011954088, disc_loss = 0.0008016613522508683
Trained batch 65 in epoch 3, gen_loss = 0.9547566175460815, disc_loss = 0.0007992274358085441
Trained batch 66 in epoch 3, gen_loss = 0.9533475922114814, disc_loss = 0.0007941413830632149
Trained batch 67 in epoch 3, gen_loss = 0.953744616578607, disc_loss = 0.0007957581110531464
Trained batch 68 in epoch 3, gen_loss = 0.9550717136134272, disc_loss = 0.0008011565187716506
Trained batch 69 in epoch 3, gen_loss = 0.9552839594227928, disc_loss = 0.0007994945435452141
Trained batch 70 in epoch 3, gen_loss = 0.9554397581328808, disc_loss = 0.0008021793926698746
Trained batch 71 in epoch 3, gen_loss = 0.9555019819074206, disc_loss = 0.0008069373183793181
Trained batch 72 in epoch 3, gen_loss = 0.9569788926268277, disc_loss = 0.0008275348522496244
Trained batch 73 in epoch 3, gen_loss = 0.9580135393787075, disc_loss = 0.0008735367155168205
Trained batch 74 in epoch 3, gen_loss = 0.9589434655507406, disc_loss = 0.000923589903395623
Trained batch 75 in epoch 3, gen_loss = 0.9580849699283901, disc_loss = 0.000978914378241538
Trained batch 76 in epoch 3, gen_loss = 0.958460245039556, disc_loss = 0.0010319646612692672
Trained batch 77 in epoch 3, gen_loss = 0.95869885576077, disc_loss = 0.0010670214027273827
Trained batch 78 in epoch 3, gen_loss = 0.9592758288866357, disc_loss = 0.001077839330316203
Trained batch 79 in epoch 3, gen_loss = 0.9590381234884262, disc_loss = 0.001075170412514126
Trained batch 80 in epoch 3, gen_loss = 0.9589389945253913, disc_loss = 0.0010674494213746561
Trained batch 81 in epoch 3, gen_loss = 0.9590965647522997, disc_loss = 0.0010597242224143772
Trained batch 82 in epoch 3, gen_loss = 0.9586347923221359, disc_loss = 0.0010554554250865546
Trained batch 83 in epoch 3, gen_loss = 0.9593146691719691, disc_loss = 0.0010627450032015553
Trained batch 84 in epoch 3, gen_loss = 0.9595181906924528, disc_loss = 0.0010829354793874218
Trained batch 85 in epoch 3, gen_loss = 0.9591645674650059, disc_loss = 0.001099258519811989
Trained batch 86 in epoch 3, gen_loss = 0.9595087636476276, disc_loss = 0.0010994955697953273
Trained batch 87 in epoch 3, gen_loss = 0.9597007727081125, disc_loss = 0.0010932435589810748
Trained batch 88 in epoch 3, gen_loss = 0.9588466353630751, disc_loss = 0.0010880745660900818
Trained batch 89 in epoch 3, gen_loss = 0.9582757373650869, disc_loss = 0.00108000651461124
Trained batch 90 in epoch 3, gen_loss = 0.9579766549906887, disc_loss = 0.0010716041443219592
Trained batch 91 in epoch 3, gen_loss = 0.9580551819956821, disc_loss = 0.001063118819413079
Trained batch 92 in epoch 3, gen_loss = 0.9576868011105445, disc_loss = 0.0010559673183873014
Trained batch 93 in epoch 3, gen_loss = 0.957559771994327, disc_loss = 0.0010533859625711363
Trained batch 94 in epoch 3, gen_loss = 0.9573089411384181, disc_loss = 0.0010559666727203876
Trained batch 95 in epoch 3, gen_loss = 0.9572986910740534, disc_loss = 0.0010592346622312714
Trained batch 96 in epoch 3, gen_loss = 0.9567939571498596, disc_loss = 0.0010584465251424226
Trained batch 97 in epoch 3, gen_loss = 0.9567608626521363, disc_loss = 0.0010548710228509403
Trained batch 98 in epoch 3, gen_loss = 0.9569458708618627, disc_loss = 0.0010481190240372801
Trained batch 99 in epoch 3, gen_loss = 0.9565534114837646, disc_loss = 0.0010414868764928543
Trained batch 100 in epoch 3, gen_loss = 0.9565807775695725, disc_loss = 0.0010362326206136863
Trained batch 101 in epoch 3, gen_loss = 0.9561060439137852, disc_loss = 0.0010303916645295662
Trained batch 102 in epoch 3, gen_loss = 0.9553368305697024, disc_loss = 0.0010246888257436527
Trained batch 103 in epoch 3, gen_loss = 0.9547373658189406, disc_loss = 0.001020137183681632
Trained batch 104 in epoch 3, gen_loss = 0.9549981043452308, disc_loss = 0.0010170379054865667
Trained batch 105 in epoch 3, gen_loss = 0.9546901881694794, disc_loss = 0.001013705091779384
Trained batch 106 in epoch 3, gen_loss = 0.9544659151095096, disc_loss = 0.0010087007534838168
Trained batch 107 in epoch 3, gen_loss = 0.9547934471457092, disc_loss = 0.0010050793881183145
Trained batch 108 in epoch 3, gen_loss = 0.9547132904376459, disc_loss = 0.001005322590188354
Trained batch 109 in epoch 3, gen_loss = 0.9546958067200401, disc_loss = 0.0010071804440072315
Trained batch 110 in epoch 3, gen_loss = 0.9549162377108324, disc_loss = 0.0010057837777846569
Trained batch 111 in epoch 3, gen_loss = 0.9546538474304336, disc_loss = 0.0010011506731513822
Trained batch 112 in epoch 3, gen_loss = 0.9548472988921984, disc_loss = 0.0009950883251272835
Trained batch 113 in epoch 3, gen_loss = 0.9553364797642356, disc_loss = 0.0009894129825784546
Trained batch 114 in epoch 3, gen_loss = 0.9553625262301901, disc_loss = 0.0009836903335425356
Trained batch 115 in epoch 3, gen_loss = 0.95579250413796, disc_loss = 0.0009792835177183312
Trained batch 116 in epoch 3, gen_loss = 0.9556191558511848, disc_loss = 0.0009756795149077622
Trained batch 117 in epoch 3, gen_loss = 0.956400379285974, disc_loss = 0.000975230308910595
Trained batch 118 in epoch 3, gen_loss = 0.956855479408713, disc_loss = 0.0009747165861293016
Trained batch 119 in epoch 3, gen_loss = 0.9567535052696864, disc_loss = 0.0009719199760487147
Trained batch 120 in epoch 3, gen_loss = 0.957180187721883, disc_loss = 0.0009681711202845255
Trained batch 121 in epoch 3, gen_loss = 0.9567852098433698, disc_loss = 0.0009681062234210645
Trained batch 122 in epoch 3, gen_loss = 0.9573877768787912, disc_loss = 0.0009735836446326892
Trained batch 123 in epoch 3, gen_loss = 0.9572791803267694, disc_loss = 0.0009815109273580264
Trained batch 124 in epoch 3, gen_loss = 0.9573092684745789, disc_loss = 0.0009871525361668319
Trained batch 125 in epoch 3, gen_loss = 0.957006184354661, disc_loss = 0.0009863676615558298
Trained batch 126 in epoch 3, gen_loss = 0.9573287715123394, disc_loss = 0.0009816782991310185
Trained batch 127 in epoch 3, gen_loss = 0.9579166672192514, disc_loss = 0.0009778517276117782
Trained batch 128 in epoch 3, gen_loss = 0.9568764063739037, disc_loss = 0.0009743958626343154
Trained batch 129 in epoch 3, gen_loss = 0.9571889978188735, disc_loss = 0.0009722755333104242
Trained batch 130 in epoch 3, gen_loss = 0.9564759126146332, disc_loss = 0.0009734853415639773
Trained batch 131 in epoch 3, gen_loss = 0.9570454778996381, disc_loss = 0.0009747905518672654
Trained batch 132 in epoch 3, gen_loss = 0.9571888854629115, disc_loss = 0.0009798183649886905
Trained batch 133 in epoch 3, gen_loss = 0.957043256777436, disc_loss = 0.0009870219733757175
Trained batch 134 in epoch 3, gen_loss = 0.9570439391665988, disc_loss = 0.0009925094801777354
Trained batch 135 in epoch 3, gen_loss = 0.9571473843911115, disc_loss = 0.0009961961004592013
Trained batch 136 in epoch 3, gen_loss = 0.9577041838290917, disc_loss = 0.0010014485988857728
Trained batch 137 in epoch 3, gen_loss = 0.9573164279910101, disc_loss = 0.0010103404501274201
Trained batch 138 in epoch 3, gen_loss = 0.9573302474810923, disc_loss = 0.0010192844714791843
Trained batch 139 in epoch 3, gen_loss = 0.9570164569786617, disc_loss = 0.0010219222057328027
Trained batch 140 in epoch 3, gen_loss = 0.957217589760503, disc_loss = 0.0010210402936968583
Trained batch 141 in epoch 3, gen_loss = 0.9573288215717799, disc_loss = 0.0010186321596847847
Trained batch 142 in epoch 3, gen_loss = 0.9573372269010211, disc_loss = 0.001014823533417136
Trained batch 143 in epoch 3, gen_loss = 0.957970024810897, disc_loss = 0.0010142816970781293
Trained batch 144 in epoch 3, gen_loss = 0.9578879783893454, disc_loss = 0.00101783564374461
Trained batch 145 in epoch 3, gen_loss = 0.9575802638922652, disc_loss = 0.0010226365856185224
Trained batch 146 in epoch 3, gen_loss = 0.9566607779386093, disc_loss = 0.0010314509809115381
Trained batch 147 in epoch 3, gen_loss = 0.9566730699829153, disc_loss = 0.001039321232088401
Trained batch 148 in epoch 3, gen_loss = 0.9566260944276848, disc_loss = 0.001044936296678517
Trained batch 149 in epoch 3, gen_loss = 0.9565286993980407, disc_loss = 0.0010463161601607378
Trained batch 150 in epoch 3, gen_loss = 0.9560840248272119, disc_loss = 0.001046297884205455
Trained batch 151 in epoch 3, gen_loss = 0.9553429484367371, disc_loss = 0.0010465032098995596
Trained batch 152 in epoch 3, gen_loss = 0.9558107307533813, disc_loss = 0.0010523580802601512
Trained batch 153 in epoch 3, gen_loss = 0.95607179519418, disc_loss = 0.0010622182984567283
Trained batch 154 in epoch 3, gen_loss = 0.9558991639844833, disc_loss = 0.001065562221394371
Trained batch 155 in epoch 3, gen_loss = 0.9558765330375769, disc_loss = 0.0010646976310780677
Trained batch 156 in epoch 3, gen_loss = 0.9554534930332451, disc_loss = 0.0010622140666348325
Trained batch 157 in epoch 3, gen_loss = 0.955760623080821, disc_loss = 0.0010624537087867885
Trained batch 158 in epoch 3, gen_loss = 0.9555443607786167, disc_loss = 0.0010662700974678257
Trained batch 159 in epoch 3, gen_loss = 0.9550298921763897, disc_loss = 0.001069857365473581
Trained batch 160 in epoch 3, gen_loss = 0.9555928122182811, disc_loss = 0.0010736446344273409
Trained batch 161 in epoch 3, gen_loss = 0.9550929143105025, disc_loss = 0.0010786217177088406
Trained batch 162 in epoch 3, gen_loss = 0.9546354233852925, disc_loss = 0.001084560931744511
Trained batch 163 in epoch 3, gen_loss = 0.9545835932580437, disc_loss = 0.0010851970999771387
Trained batch 164 in epoch 3, gen_loss = 0.9546373186689434, disc_loss = 0.0010844220895898727
Trained batch 165 in epoch 3, gen_loss = 0.9541581675230738, disc_loss = 0.0010810322340378672
Trained batch 166 in epoch 3, gen_loss = 0.9542599802245637, disc_loss = 0.001081763762697678
Trained batch 167 in epoch 3, gen_loss = 0.954781636595726, disc_loss = 0.0010855899712450558
Trained batch 168 in epoch 3, gen_loss = 0.9540759998665759, disc_loss = 0.0010870714844466247
Trained batch 169 in epoch 3, gen_loss = 0.9542797000969158, disc_loss = 0.0010897892371491147
Trained batch 170 in epoch 3, gen_loss = 0.9541277502015321, disc_loss = 0.0010953840252613833
Trained batch 171 in epoch 3, gen_loss = 0.9534805243791535, disc_loss = 0.0010980055283357085
Trained batch 172 in epoch 3, gen_loss = 0.9536233747625626, disc_loss = 0.0010988846748617796
Trained batch 173 in epoch 3, gen_loss = 0.9536038924907816, disc_loss = 0.001102122105691507
Trained batch 174 in epoch 3, gen_loss = 0.9532516149112157, disc_loss = 0.0011039649118070624
Trained batch 175 in epoch 3, gen_loss = 0.953068305822936, disc_loss = 0.001105417537308478
Trained batch 176 in epoch 3, gen_loss = 0.9531175201222047, disc_loss = 0.0011057736554990739
Trained batch 177 in epoch 3, gen_loss = 0.9531334283646573, disc_loss = 0.0011055495511816313
Trained batch 178 in epoch 3, gen_loss = 0.9528213852610667, disc_loss = 0.0011033576732051335
Trained batch 179 in epoch 3, gen_loss = 0.9528113087018331, disc_loss = 0.0010997477707052085
Trained batch 180 in epoch 3, gen_loss = 0.9530904846296785, disc_loss = 0.0010962905556809938
Trained batch 181 in epoch 3, gen_loss = 0.9529923226807143, disc_loss = 0.0010928110159411618
Trained batch 182 in epoch 3, gen_loss = 0.9533168057926366, disc_loss = 0.001089219540030609
Trained batch 183 in epoch 3, gen_loss = 0.953062820693721, disc_loss = 0.0010861513790429024
Trained batch 184 in epoch 3, gen_loss = 0.9531431204563863, disc_loss = 0.0010906070525871238
Trained batch 185 in epoch 3, gen_loss = 0.9531300478084113, disc_loss = 0.0011024583043137525
Trained batch 186 in epoch 3, gen_loss = 0.9530076308046432, disc_loss = 0.0011111323484829703
Trained batch 187 in epoch 3, gen_loss = 0.9526422813217691, disc_loss = 0.0011142069890914346
Trained batch 188 in epoch 3, gen_loss = 0.9526814326407418, disc_loss = 0.0011142310198265862
Trained batch 189 in epoch 3, gen_loss = 0.9528778148324866, disc_loss = 0.0011112434187548626
Trained batch 190 in epoch 3, gen_loss = 0.9533958450661904, disc_loss = 0.0011077402624318678
Trained batch 191 in epoch 3, gen_loss = 0.9536219701791803, disc_loss = 0.0011041926744231507
Trained batch 192 in epoch 3, gen_loss = 0.9530933270800299, disc_loss = 0.0011021676112914582
Trained batch 193 in epoch 3, gen_loss = 0.952889423702181, disc_loss = 0.0011009437101953134
Trained batch 194 in epoch 3, gen_loss = 0.9531911846918938, disc_loss = 0.0011018647980959846
Trained batch 195 in epoch 3, gen_loss = 0.9531633303481706, disc_loss = 0.001105978152012614
Trained batch 196 in epoch 3, gen_loss = 0.9531092707275739, disc_loss = 0.0011111297072939632
Trained batch 197 in epoch 3, gen_loss = 0.9528995725241575, disc_loss = 0.0011157638252526992
Trained batch 198 in epoch 3, gen_loss = 0.952555507571254, disc_loss = 0.0011191784988342313
Trained batch 199 in epoch 3, gen_loss = 0.9522290992736816, disc_loss = 0.001121293476462597
Trained batch 200 in epoch 3, gen_loss = 0.9521667242643252, disc_loss = 0.0011209788107005092
Trained batch 201 in epoch 3, gen_loss = 0.9526043401496245, disc_loss = 0.0011192949018775402
Trained batch 202 in epoch 3, gen_loss = 0.952563625838369, disc_loss = 0.0011167967400405776
Trained batch 203 in epoch 3, gen_loss = 0.9533840552264569, disc_loss = 0.001117905441930691
Trained batch 204 in epoch 3, gen_loss = 0.9533865175596098, disc_loss = 0.0011198140259139331
Trained batch 205 in epoch 3, gen_loss = 0.9534625419713918, disc_loss = 0.0011231204837015875
Trained batch 206 in epoch 3, gen_loss = 0.9535702170381224, disc_loss = 0.001124054915468537
Trained batch 207 in epoch 3, gen_loss = 0.9537977321216693, disc_loss = 0.0011224227207724024
Trained batch 208 in epoch 3, gen_loss = 0.9537004959640321, disc_loss = 0.001119694316734083
Trained batch 209 in epoch 3, gen_loss = 0.9535111682755607, disc_loss = 0.0011170248247383695
Trained batch 210 in epoch 3, gen_loss = 0.9535033392115226, disc_loss = 0.0011148360524474428
Trained batch 211 in epoch 3, gen_loss = 0.9530064255561469, disc_loss = 0.0011124062185221843
Trained batch 212 in epoch 3, gen_loss = 0.9527722258523037, disc_loss = 0.00111122178435741
Trained batch 213 in epoch 3, gen_loss = 0.9526829003730667, disc_loss = 0.0011117340322033388
Trained batch 214 in epoch 3, gen_loss = 0.9521855764610823, disc_loss = 0.0011105514436061386
Trained batch 215 in epoch 3, gen_loss = 0.9517611091335615, disc_loss = 0.0011077884007169847
Trained batch 216 in epoch 3, gen_loss = 0.9519438537584471, disc_loss = 0.0011061598705868173
Trained batch 217 in epoch 3, gen_loss = 0.9522419787875009, disc_loss = 0.0011044932400365573
Trained batch 218 in epoch 3, gen_loss = 0.9522342074951625, disc_loss = 0.001101871284355354
Trained batch 219 in epoch 3, gen_loss = 0.9523010495034131, disc_loss = 0.0010989462964723564
Trained batch 220 in epoch 3, gen_loss = 0.9519748560983131, disc_loss = 0.0010955488706709253
Trained batch 221 in epoch 3, gen_loss = 0.951816212218087, disc_loss = 0.0010920786532166472
Trained batch 222 in epoch 3, gen_loss = 0.9520546205909798, disc_loss = 0.0010889986291895265
Trained batch 223 in epoch 3, gen_loss = 0.9519535396248102, disc_loss = 0.0010853540556386829
Trained batch 224 in epoch 3, gen_loss = 0.9517408635881212, disc_loss = 0.0010829935337985969
Trained batch 225 in epoch 3, gen_loss = 0.9516190071549036, disc_loss = 0.001080377533361192
Trained batch 226 in epoch 3, gen_loss = 0.9515138494285718, disc_loss = 0.0010780733729259312
Trained batch 227 in epoch 3, gen_loss = 0.9518377976982217, disc_loss = 0.0010759067899606745
Trained batch 228 in epoch 3, gen_loss = 0.9517909879247174, disc_loss = 0.0010727558144689518
Trained batch 229 in epoch 3, gen_loss = 0.9521649529104648, disc_loss = 0.001070170092988638
Trained batch 230 in epoch 3, gen_loss = 0.9518130504207694, disc_loss = 0.0010718272247269057
Trained batch 231 in epoch 3, gen_loss = 0.9519963367231961, disc_loss = 0.0010853466154567913
Trained batch 232 in epoch 3, gen_loss = 0.9520898182504679, disc_loss = 0.0011128332739937731
Trained batch 233 in epoch 3, gen_loss = 0.9521482194590772, disc_loss = 0.0011391703037666476
Trained batch 234 in epoch 3, gen_loss = 0.9520899640752915, disc_loss = 0.001154809760826422
Trained batch 235 in epoch 3, gen_loss = 0.9517188092409554, disc_loss = 0.0011580192886728998
Trained batch 236 in epoch 3, gen_loss = 0.9518178701400757, disc_loss = 0.0011572677624669273
Trained batch 237 in epoch 3, gen_loss = 0.9519959868503218, disc_loss = 0.0011571257140638087
Trained batch 238 in epoch 3, gen_loss = 0.9519616103571329, disc_loss = 0.001155885501114932
Trained batch 239 in epoch 3, gen_loss = 0.9520592441161474, disc_loss = 0.0011546887397950437
Trained batch 240 in epoch 3, gen_loss = 0.9520688746974676, disc_loss = 0.001153621149826138
Trained batch 241 in epoch 3, gen_loss = 0.9519733429447679, disc_loss = 0.0011511072851977241
Trained batch 242 in epoch 3, gen_loss = 0.9519181982479958, disc_loss = 0.0011476266826407164
Trained batch 243 in epoch 3, gen_loss = 0.9521066067648716, disc_loss = 0.0011442077088982753
Trained batch 244 in epoch 3, gen_loss = 0.9519605334924192, disc_loss = 0.0011413766156729995
Trained batch 245 in epoch 3, gen_loss = 0.9518211954008273, disc_loss = 0.0011398074476472366
Trained batch 246 in epoch 3, gen_loss = 0.9521189556430708, disc_loss = 0.00113884908918231
Trained batch 247 in epoch 3, gen_loss = 0.9521624181539782, disc_loss = 0.0011367463474368465
Trained batch 248 in epoch 3, gen_loss = 0.9522243726205635, disc_loss = 0.001134501591307975
Trained batch 249 in epoch 3, gen_loss = 0.9521563272476197, disc_loss = 0.00113290120405145
Trained batch 250 in epoch 3, gen_loss = 0.9524368821862209, disc_loss = 0.001131953622643053
Trained batch 251 in epoch 3, gen_loss = 0.952603217628267, disc_loss = 0.0011308941482436946
Trained batch 252 in epoch 3, gen_loss = 0.952863272942102, disc_loss = 0.0011302269737534373
Trained batch 253 in epoch 3, gen_loss = 0.9527055670426586, disc_loss = 0.0011297872763926413
Trained batch 254 in epoch 3, gen_loss = 0.9525753554175882, disc_loss = 0.001127689717766628
Trained batch 255 in epoch 3, gen_loss = 0.9526107427664101, disc_loss = 0.00112550283802193
Trained batch 256 in epoch 3, gen_loss = 0.9529294823858061, disc_loss = 0.001123479636773786
Trained batch 257 in epoch 3, gen_loss = 0.9528477843417678, disc_loss = 0.0011219262667072488
Trained batch 258 in epoch 3, gen_loss = 0.9528970557290155, disc_loss = 0.0011222020131409973
Trained batch 259 in epoch 3, gen_loss = 0.9529616094552553, disc_loss = 0.0011222780713489135
Trained batch 260 in epoch 3, gen_loss = 0.95259290134313, disc_loss = 0.0011216960490549204
Trained batch 261 in epoch 3, gen_loss = 0.9527207738115587, disc_loss = 0.0011206059796621895
Trained batch 262 in epoch 3, gen_loss = 0.9530528758868518, disc_loss = 0.0011203389835257097
Trained batch 263 in epoch 3, gen_loss = 0.9528111512913848, disc_loss = 0.0011194819056651215
Trained batch 264 in epoch 3, gen_loss = 0.9527690864958853, disc_loss = 0.0011174267067855118
Trained batch 265 in epoch 3, gen_loss = 0.9529736342286705, disc_loss = 0.001114405055278282
Trained batch 266 in epoch 3, gen_loss = 0.9534937911265798, disc_loss = 0.0011117763052980523
Trained batch 267 in epoch 3, gen_loss = 0.953604474441329, disc_loss = 0.0011092756248041015
Trained batch 268 in epoch 3, gen_loss = 0.953428191101684, disc_loss = 0.0011070312217629228
Trained batch 269 in epoch 3, gen_loss = 0.9531338159684781, disc_loss = 0.0011051508945119739
Trained batch 270 in epoch 3, gen_loss = 0.95302318185018, disc_loss = 0.0011026494705884604
Trained batch 271 in epoch 3, gen_loss = 0.9533157591872355, disc_loss = 0.0011003532350407435
Trained batch 272 in epoch 3, gen_loss = 0.9531907751446679, disc_loss = 0.0010990433117942782
Trained batch 273 in epoch 3, gen_loss = 0.9529520858378306, disc_loss = 0.001099164223907699
Trained batch 274 in epoch 3, gen_loss = 0.9527053425528786, disc_loss = 0.0010999128109225158
Trained batch 275 in epoch 3, gen_loss = 0.9524404581474222, disc_loss = 0.001100064982998394
Trained batch 276 in epoch 3, gen_loss = 0.952373266435272, disc_loss = 0.0010992011660752004
Trained batch 277 in epoch 3, gen_loss = 0.9525020883666525, disc_loss = 0.0010973693378539353
Trained batch 278 in epoch 3, gen_loss = 0.9524387845429041, disc_loss = 0.001095457883667715
Trained batch 279 in epoch 3, gen_loss = 0.9525601625442505, disc_loss = 0.0010934912018586017
Trained batch 280 in epoch 3, gen_loss = 0.9522964500447609, disc_loss = 0.0010912700713027162
Trained batch 281 in epoch 3, gen_loss = 0.9524964766299471, disc_loss = 0.00108979616311283
Trained batch 282 in epoch 3, gen_loss = 0.9527224841471695, disc_loss = 0.0010887162652740406
Trained batch 283 in epoch 3, gen_loss = 0.9525712306650591, disc_loss = 0.0010863891944148196
Trained batch 284 in epoch 3, gen_loss = 0.9524715072230289, disc_loss = 0.0010836695592540005
Trained batch 285 in epoch 3, gen_loss = 0.9522435623449046, disc_loss = 0.001081067760404968
Trained batch 286 in epoch 3, gen_loss = 0.9522612630697909, disc_loss = 0.0010785998718550215
Trained batch 287 in epoch 3, gen_loss = 0.952120292517874, disc_loss = 0.0010765892119606077
Trained batch 288 in epoch 3, gen_loss = 0.9522158794337078, disc_loss = 0.0010747174340844875
Trained batch 289 in epoch 3, gen_loss = 0.9525840257776195, disc_loss = 0.0010731653645554365
Trained batch 290 in epoch 3, gen_loss = 0.9528609051327526, disc_loss = 0.0010708559292874258
Trained batch 291 in epoch 3, gen_loss = 0.9530099528293087, disc_loss = 0.001068369699231419
Trained batch 292 in epoch 3, gen_loss = 0.9531075567922495, disc_loss = 0.001066339967566552
Trained batch 293 in epoch 3, gen_loss = 0.9533313115437826, disc_loss = 0.0010649033694022786
Trained batch 294 in epoch 3, gen_loss = 0.953403942867861, disc_loss = 0.0010640229993318286
Trained batch 295 in epoch 3, gen_loss = 0.9535399977419827, disc_loss = 0.0010627977141199597
Trained batch 296 in epoch 3, gen_loss = 0.9537065005061602, disc_loss = 0.00106096764317375
Trained batch 297 in epoch 3, gen_loss = 0.9535343540994913, disc_loss = 0.0010586620127585335
Trained batch 298 in epoch 3, gen_loss = 0.9535751699603919, disc_loss = 0.0010565697121275059
Trained batch 299 in epoch 3, gen_loss = 0.953548476099968, disc_loss = 0.0010544298108046254
Trained batch 300 in epoch 3, gen_loss = 0.9537100782030049, disc_loss = 0.001052271228197009
Trained batch 301 in epoch 3, gen_loss = 0.9535796916642726, disc_loss = 0.0010502273062651126
Trained batch 302 in epoch 3, gen_loss = 0.9534919767489921, disc_loss = 0.0010477859423520417
Trained batch 303 in epoch 3, gen_loss = 0.9535221098677108, disc_loss = 0.0010452310982241454
Trained batch 304 in epoch 3, gen_loss = 0.9532628417015075, disc_loss = 0.0010426969696828699
Trained batch 305 in epoch 3, gen_loss = 0.9532874563550637, disc_loss = 0.0010410404058015035
Trained batch 306 in epoch 3, gen_loss = 0.953271325131581, disc_loss = 0.0010400245251309989
Trained batch 307 in epoch 3, gen_loss = 0.9533563676205549, disc_loss = 0.0010389478339710842
Trained batch 308 in epoch 3, gen_loss = 0.9529483860364624, disc_loss = 0.0010377393602574406
Trained batch 309 in epoch 3, gen_loss = 0.952822099385723, disc_loss = 0.0010371801422743667
Trained batch 310 in epoch 3, gen_loss = 0.9527777477475992, disc_loss = 0.001036985622534762
Trained batch 311 in epoch 3, gen_loss = 0.9526147815661553, disc_loss = 0.0010363919866041471
Trained batch 312 in epoch 3, gen_loss = 0.9525789071957524, disc_loss = 0.001034388073646395
Trained batch 313 in epoch 3, gen_loss = 0.9527464182513534, disc_loss = 0.0010326387921265167
Trained batch 314 in epoch 3, gen_loss = 0.9527167036419824, disc_loss = 0.0010308491674968826
Trained batch 315 in epoch 3, gen_loss = 0.9527367504337166, disc_loss = 0.0010294232927697499
Trained batch 316 in epoch 3, gen_loss = 0.9527398479473703, disc_loss = 0.0010277734740162768
Trained batch 317 in epoch 3, gen_loss = 0.9528590997435012, disc_loss = 0.00102589551222865
Trained batch 318 in epoch 3, gen_loss = 0.9530242474101553, disc_loss = 0.001023534739110473
Trained batch 319 in epoch 3, gen_loss = 0.9530222110450268, disc_loss = 0.0010215949923804146
Trained batch 320 in epoch 3, gen_loss = 0.9527984044262182, disc_loss = 0.0010198948403850859
Trained batch 321 in epoch 3, gen_loss = 0.9527603726579535, disc_loss = 0.0010179631793994445
Trained batch 322 in epoch 3, gen_loss = 0.9528470048594401, disc_loss = 0.0010163947710466077
Trained batch 323 in epoch 3, gen_loss = 0.9528494973977407, disc_loss = 0.0010142303583029668
Trained batch 324 in epoch 3, gen_loss = 0.9528934931755066, disc_loss = 0.0010117547064482306
Trained batch 325 in epoch 3, gen_loss = 0.9527830699104473, disc_loss = 0.001009608753096238
Trained batch 326 in epoch 3, gen_loss = 0.9526417093174903, disc_loss = 0.0010081866259625415
Trained batch 327 in epoch 3, gen_loss = 0.9524846447677147, disc_loss = 0.0010066570629111615
Trained batch 328 in epoch 3, gen_loss = 0.9526171296563192, disc_loss = 0.0010052020554494475
Trained batch 329 in epoch 3, gen_loss = 0.9528406179312504, disc_loss = 0.0010035208646899485
Trained batch 330 in epoch 3, gen_loss = 0.9530953039215411, disc_loss = 0.001002187559450062
Trained batch 331 in epoch 3, gen_loss = 0.9532227623893554, disc_loss = 0.0010014929728377722
Trained batch 332 in epoch 3, gen_loss = 0.9533230143266397, disc_loss = 0.0010023719088213558
Trained batch 333 in epoch 3, gen_loss = 0.9532306720753629, disc_loss = 0.001003523952708284
Trained batch 334 in epoch 3, gen_loss = 0.953601163002982, disc_loss = 0.0010055547453282374
Trained batch 335 in epoch 3, gen_loss = 0.9533291240887982, disc_loss = 0.0010063387160785385
Trained batch 336 in epoch 3, gen_loss = 0.9531795085360812, disc_loss = 0.0010050996106521445
Trained batch 337 in epoch 3, gen_loss = 0.9533919404596972, disc_loss = 0.0010033355040417863
Trained batch 338 in epoch 3, gen_loss = 0.953520391367178, disc_loss = 0.0010021243711101073
Trained batch 339 in epoch 3, gen_loss = 0.9536069263430202, disc_loss = 0.001001733187791508
Trained batch 340 in epoch 3, gen_loss = 0.9535565404248727, disc_loss = 0.0010041731728590434
Trained batch 341 in epoch 3, gen_loss = 0.9532553496067984, disc_loss = 0.0010070581944272663
Trained batch 342 in epoch 3, gen_loss = 0.9532799812864632, disc_loss = 0.0010067233357594807
Trained batch 343 in epoch 3, gen_loss = 0.9533919205152711, disc_loss = 0.001006153027045129
Trained batch 344 in epoch 3, gen_loss = 0.9532423124797103, disc_loss = 0.0010055434631953096
Trained batch 345 in epoch 3, gen_loss = 0.9533055662419755, disc_loss = 0.0010039506865681467
Trained batch 346 in epoch 3, gen_loss = 0.9533767902885459, disc_loss = 0.001002556282720966
Trained batch 347 in epoch 3, gen_loss = 0.9533506159124703, disc_loss = 0.0010019734720284675
Trained batch 348 in epoch 3, gen_loss = 0.9532390286382768, disc_loss = 0.001001955357074663
Trained batch 349 in epoch 3, gen_loss = 0.9527997285979135, disc_loss = 0.0010014330821910074
Trained batch 350 in epoch 3, gen_loss = 0.9524976974538928, disc_loss = 0.0010037412445732205
Trained batch 351 in epoch 3, gen_loss = 0.9523520759222183, disc_loss = 0.0010081713166569402
Trained batch 352 in epoch 3, gen_loss = 0.9524995009216979, disc_loss = 0.0010147295287406604
Trained batch 353 in epoch 3, gen_loss = 0.9524192330190691, disc_loss = 0.001023266621994244
Trained batch 354 in epoch 3, gen_loss = 0.9524259558865722, disc_loss = 0.0010287479979550125
Trained batch 355 in epoch 3, gen_loss = 0.9527620162521855, disc_loss = 0.0010298736281614499
Trained batch 356 in epoch 3, gen_loss = 0.9529499732145742, disc_loss = 0.0010300411608628406
Trained batch 357 in epoch 3, gen_loss = 0.9529177947750305, disc_loss = 0.0010302554124669698
Trained batch 358 in epoch 3, gen_loss = 0.9530405339092265, disc_loss = 0.001030007078283801
Trained batch 359 in epoch 3, gen_loss = 0.9532944614688555, disc_loss = 0.0010301346095123638
Trained batch 360 in epoch 3, gen_loss = 0.9531030607025379, disc_loss = 0.0010298615752995387
Trained batch 361 in epoch 3, gen_loss = 0.9531796918718854, disc_loss = 0.001029631960365242
Trained batch 362 in epoch 3, gen_loss = 0.9531130209442013, disc_loss = 0.0010300960915147765
Trained batch 363 in epoch 3, gen_loss = 0.9531650205889901, disc_loss = 0.0010312662157997653
Trained batch 364 in epoch 3, gen_loss = 0.9531017254476678, disc_loss = 0.0010331569028992767
Trained batch 365 in epoch 3, gen_loss = 0.9533041800306143, disc_loss = 0.0010349580762358229
Trained batch 366 in epoch 3, gen_loss = 0.9530243016068877, disc_loss = 0.0010376944294204424
Trained batch 367 in epoch 3, gen_loss = 0.953059049728124, disc_loss = 0.001043857146768183
Trained batch 368 in epoch 3, gen_loss = 0.9530592463850006, disc_loss = 0.0010515780492274338
Trained batch 369 in epoch 3, gen_loss = 0.9529380281229277, disc_loss = 0.0010564799206583082
Trained batch 370 in epoch 3, gen_loss = 0.9527475610576228, disc_loss = 0.0010595795129880188
Trained batch 371 in epoch 3, gen_loss = 0.9528689543085713, disc_loss = 0.0010626878832236573
Trained batch 372 in epoch 3, gen_loss = 0.9530141077156681, disc_loss = 0.0010657900308905515
Trained batch 373 in epoch 3, gen_loss = 0.9530141372731663, disc_loss = 0.0010682272688699837
Trained batch 374 in epoch 3, gen_loss = 0.9531169436772664, disc_loss = 0.0010706429680188497
Trained batch 375 in epoch 3, gen_loss = 0.953085960859948, disc_loss = 0.0010722253627659
Trained batch 376 in epoch 3, gen_loss = 0.9531872933359931, disc_loss = 0.0010717045755090997
Trained batch 377 in epoch 3, gen_loss = 0.9534197329844116, disc_loss = 0.0010707236787306745
Trained batch 378 in epoch 3, gen_loss = 0.9533205815544229, disc_loss = 0.0010702798063473623
Trained batch 379 in epoch 3, gen_loss = 0.9537118497647737, disc_loss = 0.0010708477438464272
Trained batch 380 in epoch 3, gen_loss = 0.9536138982597612, disc_loss = 0.0010715161532400728
Trained batch 381 in epoch 3, gen_loss = 0.9535635400817032, disc_loss = 0.0010714642729437107
Trained batch 382 in epoch 3, gen_loss = 0.9537132972214303, disc_loss = 0.0010702616376157938
Trained batch 383 in epoch 3, gen_loss = 0.9536881046369672, disc_loss = 0.0010684502895704402
Trained batch 384 in epoch 3, gen_loss = 0.9537002198107831, disc_loss = 0.0010667703444797352
Trained batch 385 in epoch 3, gen_loss = 0.953534827176771, disc_loss = 0.0010648818423162054
Trained batch 386 in epoch 3, gen_loss = 0.9534127781557482, disc_loss = 0.0010632270765406602
Trained batch 387 in epoch 3, gen_loss = 0.9533217460224309, disc_loss = 0.0010616179631714536
Trained batch 388 in epoch 3, gen_loss = 0.953087898636845, disc_loss = 0.0010599748561114484
Trained batch 389 in epoch 3, gen_loss = 0.9528591070419703, disc_loss = 0.0010586606722939999
Trained batch 390 in epoch 3, gen_loss = 0.9527887823941458, disc_loss = 0.0010568401351234045
Trained batch 391 in epoch 3, gen_loss = 0.9527667792780059, disc_loss = 0.0010547888727605638
Trained batch 392 in epoch 3, gen_loss = 0.9528853391266354, disc_loss = 0.001053527292973805
Trained batch 393 in epoch 3, gen_loss = 0.9526962406441645, disc_loss = 0.0010529973132442447
Trained batch 394 in epoch 3, gen_loss = 0.9525531482092942, disc_loss = 0.0010523885704394242
Trained batch 395 in epoch 3, gen_loss = 0.9523742098097849, disc_loss = 0.001051193484557308
Trained batch 396 in epoch 3, gen_loss = 0.9524402535832499, disc_loss = 0.0010503420103499688
Trained batch 397 in epoch 3, gen_loss = 0.952629758634759, disc_loss = 0.0010509200164686712
Trained batch 398 in epoch 3, gen_loss = 0.9526154497512301, disc_loss = 0.001052183468979585
Trained batch 399 in epoch 3, gen_loss = 0.9525889229774475, disc_loss = 0.0010530029786605154
Trained batch 400 in epoch 3, gen_loss = 0.9525610108922544, disc_loss = 0.0010529635978503817
Trained batch 401 in epoch 3, gen_loss = 0.9525112451902077, disc_loss = 0.0010522802406545515
Trained batch 402 in epoch 3, gen_loss = 0.9525215615409776, disc_loss = 0.0010508654292334316
Trained batch 403 in epoch 3, gen_loss = 0.9526068649374613, disc_loss = 0.00104907546476242
Trained batch 404 in epoch 3, gen_loss = 0.9525641620895009, disc_loss = 0.0010470023392383468
Trained batch 405 in epoch 3, gen_loss = 0.9526723425082972, disc_loss = 0.0010449367997854755
Trained batch 406 in epoch 3, gen_loss = 0.9526786998976068, disc_loss = 0.0010430492037828297
Trained batch 407 in epoch 3, gen_loss = 0.9527156764970106, disc_loss = 0.0010414160969958175
Trained batch 408 in epoch 3, gen_loss = 0.952735325817957, disc_loss = 0.001039863984407356
Trained batch 409 in epoch 3, gen_loss = 0.9526706116955455, disc_loss = 0.0010383849341007768
Trained batch 410 in epoch 3, gen_loss = 0.9528490113515924, disc_loss = 0.0010370695220681537
Trained batch 411 in epoch 3, gen_loss = 0.9526501753665868, disc_loss = 0.0010361039162092409
Trained batch 412 in epoch 3, gen_loss = 0.9526225910059765, disc_loss = 0.001036043815214985
Trained batch 413 in epoch 3, gen_loss = 0.9526053171802834, disc_loss = 0.001035328461028802
Trained batch 414 in epoch 3, gen_loss = 0.9525013439626578, disc_loss = 0.0010340103232273719
Trained batch 415 in epoch 3, gen_loss = 0.9523385890687888, disc_loss = 0.0010331293511066737
Trained batch 416 in epoch 3, gen_loss = 0.9522356588205845, disc_loss = 0.0010330838708087525
Trained batch 417 in epoch 3, gen_loss = 0.9522347083787599, disc_loss = 0.0010328650313432876
Trained batch 418 in epoch 3, gen_loss = 0.9521559934911978, disc_loss = 0.001031948622415589
Trained batch 419 in epoch 3, gen_loss = 0.952236902429944, disc_loss = 0.0010308336723634662
Trained batch 420 in epoch 3, gen_loss = 0.9521582746732263, disc_loss = 0.0010294785390988505
Trained batch 421 in epoch 3, gen_loss = 0.9521097925037004, disc_loss = 0.0010280494377628339
Trained batch 422 in epoch 3, gen_loss = 0.9520720752136645, disc_loss = 0.0010266984736130751
Trained batch 423 in epoch 3, gen_loss = 0.951902097547954, disc_loss = 0.0010254198811862636
Trained batch 424 in epoch 3, gen_loss = 0.9518655312762541, disc_loss = 0.0010241120566805715
Trained batch 425 in epoch 3, gen_loss = 0.951666963632118, disc_loss = 0.0010233642542302967
Trained batch 426 in epoch 3, gen_loss = 0.9518826039948564, disc_loss = 0.001023236132759614
Trained batch 427 in epoch 3, gen_loss = 0.9518777473229114, disc_loss = 0.0010231214504885905
Trained batch 428 in epoch 3, gen_loss = 0.9518858534750683, disc_loss = 0.0010237122399733556
Trained batch 429 in epoch 3, gen_loss = 0.9517979314160901, disc_loss = 0.001023656543585212
Trained batch 430 in epoch 3, gen_loss = 0.9517237896709044, disc_loss = 0.0010229471365012567
Trained batch 431 in epoch 3, gen_loss = 0.951555682277238, disc_loss = 0.0010215202293221847
Trained batch 432 in epoch 3, gen_loss = 0.9514531659749584, disc_loss = 0.0010198523717535569
Trained batch 433 in epoch 3, gen_loss = 0.9515416266456727, disc_loss = 0.0010180828257566877
Trained batch 434 in epoch 3, gen_loss = 0.9516208460961265, disc_loss = 0.0010165354675859555
Trained batch 435 in epoch 3, gen_loss = 0.9515856590566285, disc_loss = 0.0010152302647421752
Trained batch 436 in epoch 3, gen_loss = 0.9514409234103677, disc_loss = 0.0010145033448103397
Trained batch 437 in epoch 3, gen_loss = 0.9512793160464665, disc_loss = 0.0010138215142574383
Trained batch 438 in epoch 3, gen_loss = 0.9511109367861563, disc_loss = 0.0010124434526598161
Trained batch 439 in epoch 3, gen_loss = 0.9510918335481123, disc_loss = 0.0010107463444001042
Trained batch 440 in epoch 3, gen_loss = 0.9512868862844108, disc_loss = 0.0010093549772507834
Trained batch 441 in epoch 3, gen_loss = 0.9514110360749707, disc_loss = 0.0010086710653552254
Trained batch 442 in epoch 3, gen_loss = 0.951227154877062, disc_loss = 0.001007470216614701
Trained batch 443 in epoch 3, gen_loss = 0.9513002689088788, disc_loss = 0.0010071742722789782
Trained batch 444 in epoch 3, gen_loss = 0.9510795593261718, disc_loss = 0.0010075528763255543
Trained batch 445 in epoch 3, gen_loss = 0.951221189156776, disc_loss = 0.0010076292517444646
Trained batch 446 in epoch 3, gen_loss = 0.951204946510477, disc_loss = 0.0010072559086237128
Trained batch 447 in epoch 3, gen_loss = 0.9510726094512003, disc_loss = 0.0010063106810775935
Trained batch 448 in epoch 3, gen_loss = 0.9511838151776711, disc_loss = 0.001005315542960527
Trained batch 449 in epoch 3, gen_loss = 0.9510601128472222, disc_loss = 0.0010041979000541485
Trained batch 450 in epoch 3, gen_loss = 0.9510324989877096, disc_loss = 0.001004104478880474
Trained batch 451 in epoch 3, gen_loss = 0.9510769313943069, disc_loss = 0.0010041426938074533
Trained batch 452 in epoch 3, gen_loss = 0.9511732552488382, disc_loss = 0.0010043754964238383
Trained batch 453 in epoch 3, gen_loss = 0.9512300765724434, disc_loss = 0.0010041143020280607
Trained batch 454 in epoch 3, gen_loss = 0.9514260240963527, disc_loss = 0.0010029953296787546
Trained batch 455 in epoch 3, gen_loss = 0.9515690491126295, disc_loss = 0.0010019394063866664
Trained batch 456 in epoch 3, gen_loss = 0.9516873011442973, disc_loss = 0.0010009832766581595
Trained batch 457 in epoch 3, gen_loss = 0.9517239838448154, disc_loss = 0.0010000072320766632
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.9760420322418213, disc_loss = 0.00034332580980844796
Trained batch 1 in epoch 4, gen_loss = 0.9560066163539886, disc_loss = 0.0003238959761802107
Trained batch 2 in epoch 4, gen_loss = 0.9412445624669393, disc_loss = 0.00033130771286475164
Trained batch 3 in epoch 4, gen_loss = 0.9416150897741318, disc_loss = 0.00040545030060457066
Trained batch 4 in epoch 4, gen_loss = 0.9621170878410339, disc_loss = 0.0005076862464193255
Trained batch 5 in epoch 4, gen_loss = 0.9622714022795359, disc_loss = 0.0005952159651011849
Trained batch 6 in epoch 4, gen_loss = 0.9545913679259164, disc_loss = 0.0007426505949946918
Trained batch 7 in epoch 4, gen_loss = 0.9487664699554443, disc_loss = 0.0008617783641966525
Trained batch 8 in epoch 4, gen_loss = 0.9473897549841139, disc_loss = 0.0009319184432064907
Trained batch 9 in epoch 4, gen_loss = 0.9502793192863465, disc_loss = 0.0009826450172113256
Trained batch 10 in epoch 4, gen_loss = 0.9487759904427961, disc_loss = 0.0010193944723472339
Trained batch 11 in epoch 4, gen_loss = 0.9519244531790415, disc_loss = 0.001060305262702362
Trained batch 12 in epoch 4, gen_loss = 0.9601353406906128, disc_loss = 0.0010624521595533364
Trained batch 13 in epoch 4, gen_loss = 0.9489055914538247, disc_loss = 0.0011111425639163436
Trained batch 14 in epoch 4, gen_loss = 0.9505207101504008, disc_loss = 0.0013584691972937436
Trained batch 15 in epoch 4, gen_loss = 0.9501871913671494, disc_loss = 0.0014770811485504964
Trained batch 16 in epoch 4, gen_loss = 0.950552901800941, disc_loss = 0.0014603911806582747
Trained batch 17 in epoch 4, gen_loss = 0.9437717033757104, disc_loss = 0.0015162692887113532
Trained batch 18 in epoch 4, gen_loss = 0.9429739870523152, disc_loss = 0.0016606453282292932
Trained batch 19 in epoch 4, gen_loss = 0.941324982047081, disc_loss = 0.001678707754763309
Trained batch 20 in epoch 4, gen_loss = 0.9389021765618097, disc_loss = 0.0016457534497714647
Trained batch 21 in epoch 4, gen_loss = 0.9410460726781325, disc_loss = 0.0016283720152304422
Trained batch 22 in epoch 4, gen_loss = 0.9446363112200862, disc_loss = 0.0015942272413825697
Trained batch 23 in epoch 4, gen_loss = 0.9440889681379, disc_loss = 0.0016206273079054274
Trained batch 24 in epoch 4, gen_loss = 0.9427830100059509, disc_loss = 0.0016635342675726862
Trained batch 25 in epoch 4, gen_loss = 0.9397725623387557, disc_loss = 0.0016598660451843618
Trained batch 26 in epoch 4, gen_loss = 0.9408094949192471, disc_loss = 0.001665868575434649
Trained batch 27 in epoch 4, gen_loss = 0.9389380025012153, disc_loss = 0.0016939333904052287
Trained batch 28 in epoch 4, gen_loss = 0.937232753326153, disc_loss = 0.0017280809386585165
Trained batch 29 in epoch 4, gen_loss = 0.9400460163752238, disc_loss = 0.0017572472832398489
Trained batch 30 in epoch 4, gen_loss = 0.9387511860939765, disc_loss = 0.0017610697569550885
Trained batch 31 in epoch 4, gen_loss = 0.9405638743191957, disc_loss = 0.0017497976032245788
Trained batch 32 in epoch 4, gen_loss = 0.9414105686274442, disc_loss = 0.0017464528641677603
Trained batch 33 in epoch 4, gen_loss = 0.9409418754717883, disc_loss = 0.001755677957108299
Trained batch 34 in epoch 4, gen_loss = 0.9413075430052621, disc_loss = 0.0017462607431558094
Trained batch 35 in epoch 4, gen_loss = 0.9413307574060228, disc_loss = 0.0017231908754587898
Trained batch 36 in epoch 4, gen_loss = 0.9400748014450073, disc_loss = 0.0017041114176233375
Trained batch 37 in epoch 4, gen_loss = 0.9399497007068834, disc_loss = 0.0016993538677189989
Trained batch 38 in epoch 4, gen_loss = 0.9408366252214481, disc_loss = 0.001702105506317308
Trained batch 39 in epoch 4, gen_loss = 0.9408090934157372, disc_loss = 0.0016916418266191614
Trained batch 40 in epoch 4, gen_loss = 0.9418046096476113, disc_loss = 0.0016673525686023711
Trained batch 41 in epoch 4, gen_loss = 0.9403346010616848, disc_loss = 0.0016408609967800743
Trained batch 42 in epoch 4, gen_loss = 0.9400954066320907, disc_loss = 0.0016363794437533807
Trained batch 43 in epoch 4, gen_loss = 0.9382450323213231, disc_loss = 0.0016576770543575879
Trained batch 44 in epoch 4, gen_loss = 0.9360700408617656, disc_loss = 0.0016917911429320358
Trained batch 45 in epoch 4, gen_loss = 0.937376249095668, disc_loss = 0.0017069483336577516
Trained batch 46 in epoch 4, gen_loss = 0.9379041816325898, disc_loss = 0.001694264343043076
Trained batch 47 in epoch 4, gen_loss = 0.9389898379643759, disc_loss = 0.0016747290289155596
Trained batch 48 in epoch 4, gen_loss = 0.9399994003529452, disc_loss = 0.0016679359007180116
Trained batch 49 in epoch 4, gen_loss = 0.9400273108482361, disc_loss = 0.001668565883883275
Trained batch 50 in epoch 4, gen_loss = 0.9402173255004135, disc_loss = 0.0016638347702146526
Trained batch 51 in epoch 4, gen_loss = 0.9416850220698577, disc_loss = 0.0016681169402615454
Trained batch 52 in epoch 4, gen_loss = 0.9410823010048777, disc_loss = 0.0016901066844167082
Trained batch 53 in epoch 4, gen_loss = 0.9408680068122016, disc_loss = 0.0017122595459955778
Trained batch 54 in epoch 4, gen_loss = 0.9398670088161122, disc_loss = 0.0017171730102166873
Trained batch 55 in epoch 4, gen_loss = 0.9401482215949467, disc_loss = 0.0017036157946027483
Trained batch 56 in epoch 4, gen_loss = 0.941369889075296, disc_loss = 0.0016845318559238589
Trained batch 57 in epoch 4, gen_loss = 0.9414434751559948, disc_loss = 0.001660347409879564
Trained batch 58 in epoch 4, gen_loss = 0.9417591569787365, disc_loss = 0.0016369746417848993
Trained batch 59 in epoch 4, gen_loss = 0.94191548426946, disc_loss = 0.0016163201100425795
Trained batch 60 in epoch 4, gen_loss = 0.9423750052686597, disc_loss = 0.001598559605285953
Trained batch 61 in epoch 4, gen_loss = 0.9420886328143458, disc_loss = 0.0015859944058672314
Trained batch 62 in epoch 4, gen_loss = 0.9422614858264015, disc_loss = 0.001575304413332589
Trained batch 63 in epoch 4, gen_loss = 0.9429775848984718, disc_loss = 0.0015616979590049596
Trained batch 64 in epoch 4, gen_loss = 0.9434293912007259, disc_loss = 0.0015451300253446858
Trained batch 65 in epoch 4, gen_loss = 0.9437618418173357, disc_loss = 0.0015268666020622759
Trained batch 66 in epoch 4, gen_loss = 0.9446031744800397, disc_loss = 0.0015099124141113916
Trained batch 67 in epoch 4, gen_loss = 0.9439840877757353, disc_loss = 0.0014948184475275304
Trained batch 68 in epoch 4, gen_loss = 0.9437924001527869, disc_loss = 0.0014812726977929149
Trained batch 69 in epoch 4, gen_loss = 0.9437810719013214, disc_loss = 0.001467658026376739
Trained batch 70 in epoch 4, gen_loss = 0.9450479300928788, disc_loss = 0.0014579604883206037
Trained batch 71 in epoch 4, gen_loss = 0.9457780859536595, disc_loss = 0.0014501540523876126
Trained batch 72 in epoch 4, gen_loss = 0.94558000482925, disc_loss = 0.0014407695326890337
Trained batch 73 in epoch 4, gen_loss = 0.9454435520880932, disc_loss = 0.0014303968267553057
Trained batch 74 in epoch 4, gen_loss = 0.9446994058291117, disc_loss = 0.0014257150197712085
Trained batch 75 in epoch 4, gen_loss = 0.9453742213939366, disc_loss = 0.0014262033747447851
Trained batch 76 in epoch 4, gen_loss = 0.9460182847914758, disc_loss = 0.0014234767968210017
Trained batch 77 in epoch 4, gen_loss = 0.9467239066576346, disc_loss = 0.001415964380915587
Trained batch 78 in epoch 4, gen_loss = 0.9468335433851315, disc_loss = 0.001404676780169476
Trained batch 79 in epoch 4, gen_loss = 0.9461525164544582, disc_loss = 0.0013924730315920896
Trained batch 80 in epoch 4, gen_loss = 0.9460935416045012, disc_loss = 0.0013825154057014043
Trained batch 81 in epoch 4, gen_loss = 0.947136236400139, disc_loss = 0.0013757817406014243
Trained batch 82 in epoch 4, gen_loss = 0.9477420319993812, disc_loss = 0.0013763208372843821
Trained batch 83 in epoch 4, gen_loss = 0.9477169605947676, disc_loss = 0.0013778197913086928
Trained batch 84 in epoch 4, gen_loss = 0.9474606352693894, disc_loss = 0.001372606195646393
Trained batch 85 in epoch 4, gen_loss = 0.9464865666489268, disc_loss = 0.0013621160090456954
Trained batch 86 in epoch 4, gen_loss = 0.946316981452635, disc_loss = 0.0013532998420340918
Trained batch 87 in epoch 4, gen_loss = 0.9464614682576873, disc_loss = 0.0013435067085083574
Trained batch 88 in epoch 4, gen_loss = 0.9467700391672971, disc_loss = 0.0013340231955961815
Trained batch 89 in epoch 4, gen_loss = 0.9460182978047265, disc_loss = 0.0013261444866657258
Trained batch 90 in epoch 4, gen_loss = 0.9458973296396025, disc_loss = 0.001320089546165296
Trained batch 91 in epoch 4, gen_loss = 0.9455827921628952, disc_loss = 0.001315340013800027
Trained batch 92 in epoch 4, gen_loss = 0.9463248028550096, disc_loss = 0.001311312124173167
Trained batch 93 in epoch 4, gen_loss = 0.9465151391130813, disc_loss = 0.001306006639076278
Trained batch 94 in epoch 4, gen_loss = 0.9459552902924387, disc_loss = 0.001298245427345759
Trained batch 95 in epoch 4, gen_loss = 0.9460683961709341, disc_loss = 0.0012893373119974665
Trained batch 96 in epoch 4, gen_loss = 0.945962642885975, disc_loss = 0.0012808749440231734
Trained batch 97 in epoch 4, gen_loss = 0.9463975721476029, disc_loss = 0.0012735822428093881
Trained batch 98 in epoch 4, gen_loss = 0.9474670959241462, disc_loss = 0.0012706578227061063
Trained batch 99 in epoch 4, gen_loss = 0.9478801715373993, disc_loss = 0.0012659907911438495
Trained batch 100 in epoch 4, gen_loss = 0.9481894562740137, disc_loss = 0.0012582110530364853
Trained batch 101 in epoch 4, gen_loss = 0.9485859456015568, disc_loss = 0.0012488386322123308
Trained batch 102 in epoch 4, gen_loss = 0.9482545852661133, disc_loss = 0.0012388546974850293
Trained batch 103 in epoch 4, gen_loss = 0.9483596476224753, disc_loss = 0.0012311494434610582
Trained batch 104 in epoch 4, gen_loss = 0.9485742063749404, disc_loss = 0.0012251209628413476
Trained batch 105 in epoch 4, gen_loss = 0.9487661404429741, disc_loss = 0.001218655683157333
Trained batch 106 in epoch 4, gen_loss = 0.9489914657913636, disc_loss = 0.0012114876212125697
Trained batch 107 in epoch 4, gen_loss = 0.9499570252718749, disc_loss = 0.0012041482178675425
Trained batch 108 in epoch 4, gen_loss = 0.9504671501457145, disc_loss = 0.0011965598531362147
Trained batch 109 in epoch 4, gen_loss = 0.9507247773083773, disc_loss = 0.0011880300888812846
Trained batch 110 in epoch 4, gen_loss = 0.9501377773714496, disc_loss = 0.0011799126718747052
Trained batch 111 in epoch 4, gen_loss = 0.9497925591255937, disc_loss = 0.001174068238469772
Trained batch 112 in epoch 4, gen_loss = 0.949358040252618, disc_loss = 0.001168063516209347
Trained batch 113 in epoch 4, gen_loss = 0.9495185634546113, disc_loss = 0.0011623936782901485
Trained batch 114 in epoch 4, gen_loss = 0.9494048792382945, disc_loss = 0.0011576637139786845
Trained batch 115 in epoch 4, gen_loss = 0.9496701585835424, disc_loss = 0.001152911394079826
Trained batch 116 in epoch 4, gen_loss = 0.9493650136849819, disc_loss = 0.0011469664427244829
Trained batch 117 in epoch 4, gen_loss = 0.9498655684923721, disc_loss = 0.0011419900697932216
Trained batch 118 in epoch 4, gen_loss = 0.949650899201882, disc_loss = 0.001140242367161109
Trained batch 119 in epoch 4, gen_loss = 0.9497538968920708, disc_loss = 0.0011421439431918165
Trained batch 120 in epoch 4, gen_loss = 0.9500797450049849, disc_loss = 0.0011429941004588585
Trained batch 121 in epoch 4, gen_loss = 0.9505941599118904, disc_loss = 0.0011391211883164942
Trained batch 122 in epoch 4, gen_loss = 0.9509248379769364, disc_loss = 0.0011334056699576567
Trained batch 123 in epoch 4, gen_loss = 0.9511065785923312, disc_loss = 0.0011274169413692079
Trained batch 124 in epoch 4, gen_loss = 0.9505872268676758, disc_loss = 0.0011204946904908866
Trained batch 125 in epoch 4, gen_loss = 0.950927691327201, disc_loss = 0.0011152906423260915
Trained batch 126 in epoch 4, gen_loss = 0.9503380337099391, disc_loss = 0.0011118611242479138
Trained batch 127 in epoch 4, gen_loss = 0.9500196850858629, disc_loss = 0.001108025974872362
Trained batch 128 in epoch 4, gen_loss = 0.9500495315522186, disc_loss = 0.0011025995165903784
Trained batch 129 in epoch 4, gen_loss = 0.9493796229362488, disc_loss = 0.0010970537237321527
Trained batch 130 in epoch 4, gen_loss = 0.9499185076196686, disc_loss = 0.0010946806047452998
Trained batch 131 in epoch 4, gen_loss = 0.9503944832267184, disc_loss = 0.001093522718292661
Trained batch 132 in epoch 4, gen_loss = 0.9504923556084023, disc_loss = 0.0010906725949467741
Trained batch 133 in epoch 4, gen_loss = 0.9507218701625938, disc_loss = 0.001086248979302568
Trained batch 134 in epoch 4, gen_loss = 0.9510845396253798, disc_loss = 0.0010808165036400572
Trained batch 135 in epoch 4, gen_loss = 0.950793090988608, disc_loss = 0.001075494345594266
Trained batch 136 in epoch 4, gen_loss = 0.9507419654052623, disc_loss = 0.0010711454334294927
Trained batch 137 in epoch 4, gen_loss = 0.9507209131683129, disc_loss = 0.0010666187900705668
Trained batch 138 in epoch 4, gen_loss = 0.9512432633544043, disc_loss = 0.0010624027024978009
Trained batch 139 in epoch 4, gen_loss = 0.9511706743921552, disc_loss = 0.0010596037586635377
Trained batch 140 in epoch 4, gen_loss = 0.9512247007789342, disc_loss = 0.001057914414662696
Trained batch 141 in epoch 4, gen_loss = 0.9509748178468623, disc_loss = 0.0010558555501555813
Trained batch 142 in epoch 4, gen_loss = 0.9510708180340853, disc_loss = 0.0010532822353696986
Trained batch 143 in epoch 4, gen_loss = 0.9511238800154792, disc_loss = 0.001050179592817181
Trained batch 144 in epoch 4, gen_loss = 0.951909852850026, disc_loss = 0.0010483427059531597
Trained batch 145 in epoch 4, gen_loss = 0.9514678239005886, disc_loss = 0.0010476131691862128
Trained batch 146 in epoch 4, gen_loss = 0.9514153056404218, disc_loss = 0.0010464864275750837
Trained batch 147 in epoch 4, gen_loss = 0.951595160204011, disc_loss = 0.0010432331731174821
Trained batch 148 in epoch 4, gen_loss = 0.9520939744558911, disc_loss = 0.0010399049671051162
Trained batch 149 in epoch 4, gen_loss = 0.9517129011948904, disc_loss = 0.0010379364712086196
Trained batch 150 in epoch 4, gen_loss = 0.9521763060266608, disc_loss = 0.0010370347744843842
Trained batch 151 in epoch 4, gen_loss = 0.9518855759187749, disc_loss = 0.0010355626679819053
Trained batch 152 in epoch 4, gen_loss = 0.9511496825935015, disc_loss = 0.0010332050571580315
Trained batch 153 in epoch 4, gen_loss = 0.9514652955067622, disc_loss = 0.0010311043715065151
Trained batch 154 in epoch 4, gen_loss = 0.9513465712147374, disc_loss = 0.0010294246725783113
Trained batch 155 in epoch 4, gen_loss = 0.9513045335427309, disc_loss = 0.0010278295393128735
Trained batch 156 in epoch 4, gen_loss = 0.9518573314520964, disc_loss = 0.0010266442552200002
Trained batch 157 in epoch 4, gen_loss = 0.9517900438248357, disc_loss = 0.0010257738057002307
Trained batch 158 in epoch 4, gen_loss = 0.9519293908053225, disc_loss = 0.001023915533888675
Trained batch 159 in epoch 4, gen_loss = 0.9518298827111721, disc_loss = 0.0010207582827206352
Trained batch 160 in epoch 4, gen_loss = 0.9514132749219859, disc_loss = 0.0010169450947812395
Trained batch 161 in epoch 4, gen_loss = 0.9514564743012558, disc_loss = 0.0010144779753991989
Trained batch 162 in epoch 4, gen_loss = 0.95140245026606, disc_loss = 0.0010138218718912292
Trained batch 163 in epoch 4, gen_loss = 0.9514032373341118, disc_loss = 0.0010148121506151765
Trained batch 164 in epoch 4, gen_loss = 0.9515110330148177, disc_loss = 0.0010169819233741498
Trained batch 165 in epoch 4, gen_loss = 0.9511499918368925, disc_loss = 0.0010185167421334345
Trained batch 166 in epoch 4, gen_loss = 0.9513567832415689, disc_loss = 0.0010179404798800315
Trained batch 167 in epoch 4, gen_loss = 0.9516378999465988, disc_loss = 0.0010172826327366888
Trained batch 168 in epoch 4, gen_loss = 0.9521442873943486, disc_loss = 0.0010196961460431167
Trained batch 169 in epoch 4, gen_loss = 0.9523787978817435, disc_loss = 0.0010267296275260913
Trained batch 170 in epoch 4, gen_loss = 0.9524855223315501, disc_loss = 0.0010378957655939834
Trained batch 171 in epoch 4, gen_loss = 0.9523404205954352, disc_loss = 0.0010492747062735995
Trained batch 172 in epoch 4, gen_loss = 0.9522056193710062, disc_loss = 0.0010548592561915129
Trained batch 173 in epoch 4, gen_loss = 0.9523735272473303, disc_loss = 0.0010554628515610706
Trained batch 174 in epoch 4, gen_loss = 0.9521465083530971, disc_loss = 0.0010549179973479892
Trained batch 175 in epoch 4, gen_loss = 0.9523706331171773, disc_loss = 0.001054232749249257
Trained batch 176 in epoch 4, gen_loss = 0.952017687471573, disc_loss = 0.0010506604577146343
Trained batch 177 in epoch 4, gen_loss = 0.9520845764808441, disc_loss = 0.001046845677970605
Trained batch 178 in epoch 4, gen_loss = 0.9521766997582419, disc_loss = 0.0010439527979349541
Trained batch 179 in epoch 4, gen_loss = 0.9524786230590608, disc_loss = 0.001041913896592127
Trained batch 180 in epoch 4, gen_loss = 0.9526473003856385, disc_loss = 0.001040569763213849
Trained batch 181 in epoch 4, gen_loss = 0.9527881856148059, disc_loss = 0.0010383317926975356
Trained batch 182 in epoch 4, gen_loss = 0.95240734216294, disc_loss = 0.0010360703772427566
Trained batch 183 in epoch 4, gen_loss = 0.952405208154865, disc_loss = 0.0010346405960381558
Trained batch 184 in epoch 4, gen_loss = 0.9524914087475957, disc_loss = 0.0010333237518254366
Trained batch 185 in epoch 4, gen_loss = 0.9520894971586042, disc_loss = 0.0010308574813778601
Trained batch 186 in epoch 4, gen_loss = 0.9521906802998507, disc_loss = 0.0010280110919972593
Trained batch 187 in epoch 4, gen_loss = 0.9521416324250241, disc_loss = 0.001026634685137864
Trained batch 188 in epoch 4, gen_loss = 0.9526119522316746, disc_loss = 0.0010246539457021133
Trained batch 189 in epoch 4, gen_loss = 0.9524636958774767, disc_loss = 0.0010220017434269385
Trained batch 190 in epoch 4, gen_loss = 0.9520972255636885, disc_loss = 0.0010188167988802964
Trained batch 191 in epoch 4, gen_loss = 0.9522813499594728, disc_loss = 0.001016058752459988
Trained batch 192 in epoch 4, gen_loss = 0.9524055747170522, disc_loss = 0.001013501824894341
Trained batch 193 in epoch 4, gen_loss = 0.9523052914240926, disc_loss = 0.0010106225941178975
Trained batch 194 in epoch 4, gen_loss = 0.9530386505982815, disc_loss = 0.001010250258528126
Trained batch 195 in epoch 4, gen_loss = 0.9527252568882338, disc_loss = 0.0010077626575366594
Trained batch 196 in epoch 4, gen_loss = 0.9529122434896866, disc_loss = 0.0010041846971436483
Trained batch 197 in epoch 4, gen_loss = 0.9527423688859651, disc_loss = 0.0010024660046158284
Trained batch 198 in epoch 4, gen_loss = 0.9523075007314059, disc_loss = 0.0010015146302857236
Trained batch 199 in epoch 4, gen_loss = 0.9525829598307609, disc_loss = 0.00099895611856482
Trained batch 200 in epoch 4, gen_loss = 0.9522623876434061, disc_loss = 0.0009976780177870144
Trained batch 201 in epoch 4, gen_loss = 0.9519905244359875, disc_loss = 0.0009974327722465214
Trained batch 202 in epoch 4, gen_loss = 0.9520834986799456, disc_loss = 0.0009939601603870193
Trained batch 203 in epoch 4, gen_loss = 0.9520072191953659, disc_loss = 0.0009910602030668444
Trained batch 204 in epoch 4, gen_loss = 0.9519374004224451, disc_loss = 0.0009911578974868285
Trained batch 205 in epoch 4, gen_loss = 0.9523833017904781, disc_loss = 0.0009959400617359296
Trained batch 206 in epoch 4, gen_loss = 0.9523555144019749, disc_loss = 0.001004348127430098
Trained batch 207 in epoch 4, gen_loss = 0.9522630151074666, disc_loss = 0.0010127381971799948
Trained batch 208 in epoch 4, gen_loss = 0.952164270661094, disc_loss = 0.0010169573001781898
Trained batch 209 in epoch 4, gen_loss = 0.9521328857966832, disc_loss = 0.0010170415357043524
Trained batch 210 in epoch 4, gen_loss = 0.9518497628623276, disc_loss = 0.0010148437957994427
Trained batch 211 in epoch 4, gen_loss = 0.9518589293057064, disc_loss = 0.0010135777987636415
Trained batch 212 in epoch 4, gen_loss = 0.9517929352505107, disc_loss = 0.0010138924584501016
Trained batch 213 in epoch 4, gen_loss = 0.9518611904616668, disc_loss = 0.0010153066027456911
Trained batch 214 in epoch 4, gen_loss = 0.9515467058780581, disc_loss = 0.0010201829832133858
Trained batch 215 in epoch 4, gen_loss = 0.9515806273729713, disc_loss = 0.001027997066827353
Trained batch 216 in epoch 4, gen_loss = 0.9518462422256646, disc_loss = 0.001034982269629836
Trained batch 217 in epoch 4, gen_loss = 0.9516332450262998, disc_loss = 0.0010393107354794756
Trained batch 218 in epoch 4, gen_loss = 0.951800980252218, disc_loss = 0.0010412240291405555
Trained batch 219 in epoch 4, gen_loss = 0.9516972354867241, disc_loss = 0.0010398489798800173
Trained batch 220 in epoch 4, gen_loss = 0.952090560311106, disc_loss = 0.0010369161817632886
Trained batch 221 in epoch 4, gen_loss = 0.9519990494659355, disc_loss = 0.0010357819167741884
Trained batch 222 in epoch 4, gen_loss = 0.951975794918334, disc_loss = 0.001037366343442885
Trained batch 223 in epoch 4, gen_loss = 0.9517822792487485, disc_loss = 0.0010411133176343615
Trained batch 224 in epoch 4, gen_loss = 0.952115486462911, disc_loss = 0.0010502507938589486
Trained batch 225 in epoch 4, gen_loss = 0.9526125160993728, disc_loss = 0.0010641805064736708
Trained batch 226 in epoch 4, gen_loss = 0.952831355485622, disc_loss = 0.0010771839579440127
Trained batch 227 in epoch 4, gen_loss = 0.9529960845646105, disc_loss = 0.0010864166142071777
Trained batch 228 in epoch 4, gen_loss = 0.9529632579811795, disc_loss = 0.0010897445786789092
Trained batch 229 in epoch 4, gen_loss = 0.9527178624401922, disc_loss = 0.0010901921238932436
Trained batch 230 in epoch 4, gen_loss = 0.9527567379918449, disc_loss = 0.0010898919250449221
Trained batch 231 in epoch 4, gen_loss = 0.9525976980040813, disc_loss = 0.0010883039167624545
Trained batch 232 in epoch 4, gen_loss = 0.9524637291871427, disc_loss = 0.0010859747072521902
Trained batch 233 in epoch 4, gen_loss = 0.9526591433419122, disc_loss = 0.0010829625276124312
Trained batch 234 in epoch 4, gen_loss = 0.9527688906547871, disc_loss = 0.0010800281025598103
Trained batch 235 in epoch 4, gen_loss = 0.9527130917472354, disc_loss = 0.0010774154561350785
Trained batch 236 in epoch 4, gen_loss = 0.952739846102799, disc_loss = 0.001075341332829577
Trained batch 237 in epoch 4, gen_loss = 0.9524777764532747, disc_loss = 0.0010748047674145206
Trained batch 238 in epoch 4, gen_loss = 0.9523349501597831, disc_loss = 0.0010752461730818182
Trained batch 239 in epoch 4, gen_loss = 0.9522151206930478, disc_loss = 0.0010738792804962335
Trained batch 240 in epoch 4, gen_loss = 0.9518926549254612, disc_loss = 0.001071272072038339
Trained batch 241 in epoch 4, gen_loss = 0.9517604932804739, disc_loss = 0.0010687221204361702
Trained batch 242 in epoch 4, gen_loss = 0.9519555880209055, disc_loss = 0.0010659512885273224
Trained batch 243 in epoch 4, gen_loss = 0.9521299903510047, disc_loss = 0.0010637914785517945
Trained batch 244 in epoch 4, gen_loss = 0.9523455444647342, disc_loss = 0.0010616863397073608
Trained batch 245 in epoch 4, gen_loss = 0.9525015237854748, disc_loss = 0.0010589022870597664
Trained batch 246 in epoch 4, gen_loss = 0.9527471219962426, disc_loss = 0.001056090194419939
Trained batch 247 in epoch 4, gen_loss = 0.9526513579391664, disc_loss = 0.0010535362360373725
Trained batch 248 in epoch 4, gen_loss = 0.9528029958407084, disc_loss = 0.0010511239512073602
Trained batch 249 in epoch 4, gen_loss = 0.9529071753025055, disc_loss = 0.0010488774153636768
Trained batch 250 in epoch 4, gen_loss = 0.9526700090127163, disc_loss = 0.0010469736898015532
Trained batch 251 in epoch 4, gen_loss = 0.9527490143738095, disc_loss = 0.0010448046676982711
Trained batch 252 in epoch 4, gen_loss = 0.9524072992943021, disc_loss = 0.0010422807564846655
Trained batch 253 in epoch 4, gen_loss = 0.9522883007376213, disc_loss = 0.0010393988967856657
Trained batch 254 in epoch 4, gen_loss = 0.9518840951078078, disc_loss = 0.0010362280160074542
Trained batch 255 in epoch 4, gen_loss = 0.9517464591190219, disc_loss = 0.0010335666526657405
Trained batch 256 in epoch 4, gen_loss = 0.9515227299719933, disc_loss = 0.0010317695758677839
Trained batch 257 in epoch 4, gen_loss = 0.951528305924216, disc_loss = 0.001030330203891851
Trained batch 258 in epoch 4, gen_loss = 0.9514398149081639, disc_loss = 0.0010290346004434728
Trained batch 259 in epoch 4, gen_loss = 0.9512301461054729, disc_loss = 0.0010279037021973636
Trained batch 260 in epoch 4, gen_loss = 0.951228715679198, disc_loss = 0.0010270322806275917
Trained batch 261 in epoch 4, gen_loss = 0.9511311356802933, disc_loss = 0.0010249744604749584
Trained batch 262 in epoch 4, gen_loss = 0.9512562096798828, disc_loss = 0.0010218003675887828
Trained batch 263 in epoch 4, gen_loss = 0.9511088848565564, disc_loss = 0.001019101727775485
Trained batch 264 in epoch 4, gen_loss = 0.9511435121860145, disc_loss = 0.0010167547242983929
Trained batch 265 in epoch 4, gen_loss = 0.95085440811358, disc_loss = 0.0010140300917117926
Trained batch 266 in epoch 4, gen_loss = 0.9506510047430403, disc_loss = 0.0010108996258655298
Trained batch 267 in epoch 4, gen_loss = 0.9507448651007752, disc_loss = 0.0010080872707476374
Trained batch 268 in epoch 4, gen_loss = 0.950748929303818, disc_loss = 0.0010063995527242896
Trained batch 269 in epoch 4, gen_loss = 0.9508356151757417, disc_loss = 0.001005980635064016
Trained batch 270 in epoch 4, gen_loss = 0.9510868207115089, disc_loss = 0.001005335701545752
Trained batch 271 in epoch 4, gen_loss = 0.950822664096075, disc_loss = 0.0010028033930211677
Trained batch 272 in epoch 4, gen_loss = 0.950569191695133, disc_loss = 0.0010002060042717238
Trained batch 273 in epoch 4, gen_loss = 0.9505945019913415, disc_loss = 0.0009975726218587366
Trained batch 274 in epoch 4, gen_loss = 0.95071979414333, disc_loss = 0.0009949833845232868
Trained batch 275 in epoch 4, gen_loss = 0.9505991307289704, disc_loss = 0.0009928293767333726
Trained batch 276 in epoch 4, gen_loss = 0.9504664316504441, disc_loss = 0.0009914730640951147
Trained batch 277 in epoch 4, gen_loss = 0.9502562593213089, disc_loss = 0.0009898070001320598
Trained batch 278 in epoch 4, gen_loss = 0.9501586921753422, disc_loss = 0.0009887709008929517
Trained batch 279 in epoch 4, gen_loss = 0.9502506754228047, disc_loss = 0.000988803894090649
Trained batch 280 in epoch 4, gen_loss = 0.9504159525620132, disc_loss = 0.0009887521713951377
Trained batch 281 in epoch 4, gen_loss = 0.9501140529805041, disc_loss = 0.0009886651495054648
Trained batch 282 in epoch 4, gen_loss = 0.950009667620642, disc_loss = 0.000987985713912138
Trained batch 283 in epoch 4, gen_loss = 0.9499373660540916, disc_loss = 0.0009863977975840845
Trained batch 284 in epoch 4, gen_loss = 0.9499611258506775, disc_loss = 0.0009842737615128913
Trained batch 285 in epoch 4, gen_loss = 0.9503076991418025, disc_loss = 0.0009822199810349214
Trained batch 286 in epoch 4, gen_loss = 0.9502610225710719, disc_loss = 0.0009803892216602185
Trained batch 287 in epoch 4, gen_loss = 0.9500853282709917, disc_loss = 0.0009781362396602668
Trained batch 288 in epoch 4, gen_loss = 0.9500117075072028, disc_loss = 0.0009761417409381749
Trained batch 289 in epoch 4, gen_loss = 0.9499731540679932, disc_loss = 0.000974433669160072
Trained batch 290 in epoch 4, gen_loss = 0.9501728585495572, disc_loss = 0.0009727354556593334
Trained batch 291 in epoch 4, gen_loss = 0.9502897111520375, disc_loss = 0.0009712351954837923
Trained batch 292 in epoch 4, gen_loss = 0.9503230419988925, disc_loss = 0.0009701157605284253
Trained batch 293 in epoch 4, gen_loss = 0.9503888293188445, disc_loss = 0.0009690441868206974
Trained batch 294 in epoch 4, gen_loss = 0.95022166947187, disc_loss = 0.0009683141490282744
Trained batch 295 in epoch 4, gen_loss = 0.9503763489223815, disc_loss = 0.0009678807811134313
Trained batch 296 in epoch 4, gen_loss = 0.9501711848608974, disc_loss = 0.0009670156758864213
Trained batch 297 in epoch 4, gen_loss = 0.950129879001003, disc_loss = 0.0009658344106294759
Trained batch 298 in epoch 4, gen_loss = 0.9501073585704817, disc_loss = 0.0009641795955776676
Trained batch 299 in epoch 4, gen_loss = 0.9501369259754817, disc_loss = 0.000962221388714776
Trained batch 300 in epoch 4, gen_loss = 0.9502414589704469, disc_loss = 0.0009597768368736293
Trained batch 301 in epoch 4, gen_loss = 0.9505001861133323, disc_loss = 0.0009574862204751135
Trained batch 302 in epoch 4, gen_loss = 0.950406802959568, disc_loss = 0.000955913117518126
Trained batch 303 in epoch 4, gen_loss = 0.9505794234573841, disc_loss = 0.0009546767076627523
Trained batch 304 in epoch 4, gen_loss = 0.9506624790488697, disc_loss = 0.0009526752018499509
Trained batch 305 in epoch 4, gen_loss = 0.9508014021356122, disc_loss = 0.000950361418159636
Trained batch 306 in epoch 4, gen_loss = 0.950966176846905, disc_loss = 0.0009480979729099472
Trained batch 307 in epoch 4, gen_loss = 0.950927523630006, disc_loss = 0.0009458114084252458
Trained batch 308 in epoch 4, gen_loss = 0.9506146749632258, disc_loss = 0.00094324911580629
Trained batch 309 in epoch 4, gen_loss = 0.9506053907255972, disc_loss = 0.0009407805696678077
Trained batch 310 in epoch 4, gen_loss = 0.950402344154775, disc_loss = 0.000939304904560813
Trained batch 311 in epoch 4, gen_loss = 0.9502763568590848, disc_loss = 0.0009396978254162838
Trained batch 312 in epoch 4, gen_loss = 0.9500445752098157, disc_loss = 0.0009409467863200155
Trained batch 313 in epoch 4, gen_loss = 0.9499923994966374, disc_loss = 0.0009413549030877377
Trained batch 314 in epoch 4, gen_loss = 0.9500476649829319, disc_loss = 0.0009399371333457234
Trained batch 315 in epoch 4, gen_loss = 0.9503154235927365, disc_loss = 0.0009398917018994394
Trained batch 316 in epoch 4, gen_loss = 0.9501954345296986, disc_loss = 0.0009399495578381271
Trained batch 317 in epoch 4, gen_loss = 0.950141116695584, disc_loss = 0.0009390914269229514
Trained batch 318 in epoch 4, gen_loss = 0.950117199772204, disc_loss = 0.0009377780389573519
Trained batch 319 in epoch 4, gen_loss = 0.950277541205287, disc_loss = 0.0009363303347527108
Trained batch 320 in epoch 4, gen_loss = 0.9501738537137754, disc_loss = 0.0009358129874807477
Trained batch 321 in epoch 4, gen_loss = 0.9500513476614626, disc_loss = 0.0009348812981787779
Trained batch 322 in epoch 4, gen_loss = 0.9504924263378415, disc_loss = 0.0009333546839808705
Trained batch 323 in epoch 4, gen_loss = 0.9504249117992543, disc_loss = 0.0009324286620090946
Trained batch 324 in epoch 4, gen_loss = 0.9502286386489868, disc_loss = 0.0009327074157324834
Trained batch 325 in epoch 4, gen_loss = 0.9500922807520884, disc_loss = 0.000932892564769143
Trained batch 326 in epoch 4, gen_loss = 0.9502106254253913, disc_loss = 0.0009326797285058823
Trained batch 327 in epoch 4, gen_loss = 0.9504119152339493, disc_loss = 0.0009317225168804104
Trained batch 328 in epoch 4, gen_loss = 0.9506657828313602, disc_loss = 0.0009307408443330801
Trained batch 329 in epoch 4, gen_loss = 0.9506871882713203, disc_loss = 0.000929549354336676
Trained batch 330 in epoch 4, gen_loss = 0.9505171811832762, disc_loss = 0.0009280765057911427
Trained batch 331 in epoch 4, gen_loss = 0.9503725551697145, disc_loss = 0.0009262135192044977
Trained batch 332 in epoch 4, gen_loss = 0.9502774960285908, disc_loss = 0.0009240897303057678
Trained batch 333 in epoch 4, gen_loss = 0.9502641433727241, disc_loss = 0.0009220273748582541
Trained batch 334 in epoch 4, gen_loss = 0.9501834189713891, disc_loss = 0.0009198465952719215
Trained batch 335 in epoch 4, gen_loss = 0.9504008232837632, disc_loss = 0.0009179406207251651
Trained batch 336 in epoch 4, gen_loss = 0.9502559790625417, disc_loss = 0.0009166620151334628
Trained batch 337 in epoch 4, gen_loss = 0.9503403186092715, disc_loss = 0.0009160555483940052
Trained batch 338 in epoch 4, gen_loss = 0.9505756485075374, disc_loss = 0.0009155285749536359
Trained batch 339 in epoch 4, gen_loss = 0.950475201010704, disc_loss = 0.0009136551276349243
Trained batch 340 in epoch 4, gen_loss = 0.9502905434177767, disc_loss = 0.0009122588206594673
Trained batch 341 in epoch 4, gen_loss = 0.9504158280746281, disc_loss = 0.0009123331232150276
Trained batch 342 in epoch 4, gen_loss = 0.9501946022837224, disc_loss = 0.000913045213047996
Trained batch 343 in epoch 4, gen_loss = 0.9500891685832379, disc_loss = 0.0009132061411016133
Trained batch 344 in epoch 4, gen_loss = 0.9502208227696626, disc_loss = 0.0009127930995326597
Trained batch 345 in epoch 4, gen_loss = 0.9500602180558133, disc_loss = 0.0009117236912198031
Trained batch 346 in epoch 4, gen_loss = 0.9499304523042025, disc_loss = 0.0009103027130953527
Trained batch 347 in epoch 4, gen_loss = 0.949945297563213, disc_loss = 0.00090945615383312
Trained batch 348 in epoch 4, gen_loss = 0.9499058784933008, disc_loss = 0.000909392676835901
Trained batch 349 in epoch 4, gen_loss = 0.9500336488655635, disc_loss = 0.0009088875849764528
Trained batch 350 in epoch 4, gen_loss = 0.9500478915339522, disc_loss = 0.000907665548665035
Trained batch 351 in epoch 4, gen_loss = 0.9498631877993996, disc_loss = 0.0009064284310046456
Trained batch 352 in epoch 4, gen_loss = 0.9498378114389631, disc_loss = 0.0009051094009909019
Trained batch 353 in epoch 4, gen_loss = 0.9498849782229817, disc_loss = 0.0009037191243112182
Trained batch 354 in epoch 4, gen_loss = 0.9498048585905156, disc_loss = 0.0009020990227237607
Trained batch 355 in epoch 4, gen_loss = 0.9495933062574836, disc_loss = 0.0009003210346982291
Trained batch 356 in epoch 4, gen_loss = 0.9496267905422285, disc_loss = 0.000898718864413067
Trained batch 357 in epoch 4, gen_loss = 0.9498152781132213, disc_loss = 0.0008971511746311883
Trained batch 358 in epoch 4, gen_loss = 0.9497884370822428, disc_loss = 0.0008955551937227669
Trained batch 359 in epoch 4, gen_loss = 0.9501394829816289, disc_loss = 0.000895274537065739
Trained batch 360 in epoch 4, gen_loss = 0.9500554956887898, disc_loss = 0.0008954837854752972
Trained batch 361 in epoch 4, gen_loss = 0.9498049303971602, disc_loss = 0.0008959654863031056
Trained batch 362 in epoch 4, gen_loss = 0.9499637985360853, disc_loss = 0.0008963895604058012
Trained batch 363 in epoch 4, gen_loss = 0.9499251144927937, disc_loss = 0.0008972927438322926
Trained batch 364 in epoch 4, gen_loss = 0.9499547396620659, disc_loss = 0.0008973422957813903
Trained batch 365 in epoch 4, gen_loss = 0.9499763843140315, disc_loss = 0.000896402698772313
Trained batch 366 in epoch 4, gen_loss = 0.9500591111767844, disc_loss = 0.0008955264398358681
Trained batch 367 in epoch 4, gen_loss = 0.9499622946200164, disc_loss = 0.0008945463434982863
Trained batch 368 in epoch 4, gen_loss = 0.9499787192357588, disc_loss = 0.0008933766389159653
Trained batch 369 in epoch 4, gen_loss = 0.9499984765374982, disc_loss = 0.0008918781085978136
Trained batch 370 in epoch 4, gen_loss = 0.9499029183002173, disc_loss = 0.0008903456076940728
Trained batch 371 in epoch 4, gen_loss = 0.949793460548565, disc_loss = 0.0008888283577185595
Trained batch 372 in epoch 4, gen_loss = 0.94969559450891, disc_loss = 0.0008873320950086581
Trained batch 373 in epoch 4, gen_loss = 0.9498301945268152, disc_loss = 0.0008861516516115317
Trained batch 374 in epoch 4, gen_loss = 0.9495924334526062, disc_loss = 0.0008853194389181832
Trained batch 375 in epoch 4, gen_loss = 0.9494834638973499, disc_loss = 0.0008842788074423183
Trained batch 376 in epoch 4, gen_loss = 0.9493212687241936, disc_loss = 0.0008834125841560153
Trained batch 377 in epoch 4, gen_loss = 0.9494123651237084, disc_loss = 0.0008828447162784715
Trained batch 378 in epoch 4, gen_loss = 0.9492470172275654, disc_loss = 0.0008828997202549317
Trained batch 379 in epoch 4, gen_loss = 0.9493817955255508, disc_loss = 0.0008833352891470942
Trained batch 380 in epoch 4, gen_loss = 0.949350624416131, disc_loss = 0.000882978163955347
Trained batch 381 in epoch 4, gen_loss = 0.9492570484807978, disc_loss = 0.0008820083043513654
Trained batch 382 in epoch 4, gen_loss = 0.9492604590894037, disc_loss = 0.00088100180798271
Trained batch 383 in epoch 4, gen_loss = 0.9491889906736711, disc_loss = 0.0008799816193156099
Trained batch 384 in epoch 4, gen_loss = 0.9491447660830113, disc_loss = 0.0008789027126372925
Trained batch 385 in epoch 4, gen_loss = 0.949140980608105, disc_loss = 0.0008778815576776505
Trained batch 386 in epoch 4, gen_loss = 0.9492680404229373, disc_loss = 0.0008773358929956462
Trained batch 387 in epoch 4, gen_loss = 0.9492762730908149, disc_loss = 0.000877011892371979
Trained batch 388 in epoch 4, gen_loss = 0.9492228095513077, disc_loss = 0.0008763645759605321
Trained batch 389 in epoch 4, gen_loss = 0.948963912939414, disc_loss = 0.0008756505967959619
Trained batch 390 in epoch 4, gen_loss = 0.9490940430585075, disc_loss = 0.0008754801625758648
Trained batch 391 in epoch 4, gen_loss = 0.9489575740025968, disc_loss = 0.0008751285994901769
Trained batch 392 in epoch 4, gen_loss = 0.948940412233804, disc_loss = 0.0008751282625584022
Trained batch 393 in epoch 4, gen_loss = 0.9489677310897614, disc_loss = 0.00087588289813174
Trained batch 394 in epoch 4, gen_loss = 0.9489575849303716, disc_loss = 0.0008757928270652089
Trained batch 395 in epoch 4, gen_loss = 0.9490164832936393, disc_loss = 0.0008755145347389073
Trained batch 396 in epoch 4, gen_loss = 0.9486286068142812, disc_loss = 0.0008752906179056745
Trained batch 397 in epoch 4, gen_loss = 0.9488056477290302, disc_loss = 0.0008756890548562781
Trained batch 398 in epoch 4, gen_loss = 0.9487965072605544, disc_loss = 0.0008778901666987519
Trained batch 399 in epoch 4, gen_loss = 0.9489424632489681, disc_loss = 0.0008803032921423437
Trained batch 400 in epoch 4, gen_loss = 0.9490376404693299, disc_loss = 0.0008818308650510167
Trained batch 401 in epoch 4, gen_loss = 0.9490240403075716, disc_loss = 0.0008821666828705351
Trained batch 402 in epoch 4, gen_loss = 0.9490408044003376, disc_loss = 0.0008816687984850775
Trained batch 403 in epoch 4, gen_loss = 0.9490788760456709, disc_loss = 0.0008810128229825832
Trained batch 404 in epoch 4, gen_loss = 0.9492802742086811, disc_loss = 0.0008809271868588517
Trained batch 405 in epoch 4, gen_loss = 0.9493334748474835, disc_loss = 0.0008823284405493521
Trained batch 406 in epoch 4, gen_loss = 0.9493295053885082, disc_loss = 0.0008863227458925876
Trained batch 407 in epoch 4, gen_loss = 0.9490008625914069, disc_loss = 0.0008887774892369349
Trained batch 408 in epoch 4, gen_loss = 0.9489939693716744, disc_loss = 0.0008880635728452737
Trained batch 409 in epoch 4, gen_loss = 0.9490035664744494, disc_loss = 0.0008876345454709514
Trained batch 410 in epoch 4, gen_loss = 0.9490699244531692, disc_loss = 0.0008872885688535479
Trained batch 411 in epoch 4, gen_loss = 0.9491169905488931, disc_loss = 0.0008871140678608745
Trained batch 412 in epoch 4, gen_loss = 0.9490215141894454, disc_loss = 0.0008861331555109525
Trained batch 413 in epoch 4, gen_loss = 0.9490760060900075, disc_loss = 0.0008848580936839408
Trained batch 414 in epoch 4, gen_loss = 0.9491953230765928, disc_loss = 0.0008837016820430711
Trained batch 415 in epoch 4, gen_loss = 0.9492751080542803, disc_loss = 0.0008825961264077565
Trained batch 416 in epoch 4, gen_loss = 0.9493140801251363, disc_loss = 0.0008819040050758026
Trained batch 417 in epoch 4, gen_loss = 0.9491796567679592, disc_loss = 0.0008811500136106628
Trained batch 418 in epoch 4, gen_loss = 0.9491091815839234, disc_loss = 0.000879916885291473
Trained batch 419 in epoch 4, gen_loss = 0.9490190909022377, disc_loss = 0.0008786308220892568
Trained batch 420 in epoch 4, gen_loss = 0.9488957590841625, disc_loss = 0.0008775431821382695
Trained batch 421 in epoch 4, gen_loss = 0.9487760047212032, disc_loss = 0.0008762552093530198
Trained batch 422 in epoch 4, gen_loss = 0.9488962012261646, disc_loss = 0.0008761651354239721
Trained batch 423 in epoch 4, gen_loss = 0.9488798190119132, disc_loss = 0.0008787374782462754
Trained batch 424 in epoch 4, gen_loss = 0.9486353185597588, disc_loss = 0.000880437774296083
Trained batch 425 in epoch 4, gen_loss = 0.9485818770289981, disc_loss = 0.0008805205499914042
Trained batch 426 in epoch 4, gen_loss = 0.9484940779851248, disc_loss = 0.0008824811961400417
Trained batch 427 in epoch 4, gen_loss = 0.94837313709415, disc_loss = 0.00088672359357316
Trained batch 428 in epoch 4, gen_loss = 0.9485002185081268, disc_loss = 0.0008890571423164744
Trained batch 429 in epoch 4, gen_loss = 0.9484352504098138, disc_loss = 0.0008898903430997243
Trained batch 430 in epoch 4, gen_loss = 0.948498359274145, disc_loss = 0.0008910127899640838
Trained batch 431 in epoch 4, gen_loss = 0.9485996237231625, disc_loss = 0.0008921549779862053
Trained batch 432 in epoch 4, gen_loss = 0.9485383423316286, disc_loss = 0.0008938910635742068
Trained batch 433 in epoch 4, gen_loss = 0.94851750574903, disc_loss = 0.0008953809506803845
Trained batch 434 in epoch 4, gen_loss = 0.9484949449013019, disc_loss = 0.0008972210003378876
Trained batch 435 in epoch 4, gen_loss = 0.9486985657740077, disc_loss = 0.0009001907857146686
Trained batch 436 in epoch 4, gen_loss = 0.9487334758520672, disc_loss = 0.0009050775993720882
Trained batch 437 in epoch 4, gen_loss = 0.9487081291196553, disc_loss = 0.0009109138036821863
Trained batch 438 in epoch 4, gen_loss = 0.9489834839499349, disc_loss = 0.0009152489013048123
Trained batch 439 in epoch 4, gen_loss = 0.9492896029895003, disc_loss = 0.000918739322580884
Trained batch 440 in epoch 4, gen_loss = 0.9494390999919433, disc_loss = 0.0009202620121064361
Trained batch 441 in epoch 4, gen_loss = 0.9496608278060931, disc_loss = 0.0009200465023265815
Trained batch 442 in epoch 4, gen_loss = 0.949570145886854, disc_loss = 0.0009199772390792395
Trained batch 443 in epoch 4, gen_loss = 0.9495670637031933, disc_loss = 0.0009204599771544816
Trained batch 444 in epoch 4, gen_loss = 0.9495115667246701, disc_loss = 0.000921245693723577
Trained batch 445 in epoch 4, gen_loss = 0.949537169238377, disc_loss = 0.0009219787134334754
Trained batch 446 in epoch 4, gen_loss = 0.9494494493109001, disc_loss = 0.0009221577024221695
Trained batch 447 in epoch 4, gen_loss = 0.9494908135384321, disc_loss = 0.0009220178610251294
Trained batch 448 in epoch 4, gen_loss = 0.9492759445727801, disc_loss = 0.0009218894831555167
Trained batch 449 in epoch 4, gen_loss = 0.9493796975082821, disc_loss = 0.0009228912265583252
Trained batch 450 in epoch 4, gen_loss = 0.9494651427818772, disc_loss = 0.0009243104549691684
Trained batch 451 in epoch 4, gen_loss = 0.9495226909629012, disc_loss = 0.0009249319718142073
Trained batch 452 in epoch 4, gen_loss = 0.9496859380477838, disc_loss = 0.0009244345689411367
Trained batch 453 in epoch 4, gen_loss = 0.9499561463683712, disc_loss = 0.0009231939485541745
Trained batch 454 in epoch 4, gen_loss = 0.9499756509131128, disc_loss = 0.0009218176731527629
Trained batch 455 in epoch 4, gen_loss = 0.9501359734618873, disc_loss = 0.0009206865903060565
Trained batch 456 in epoch 4, gen_loss = 0.9500093567032261, disc_loss = 0.00091952684562637
Trained batch 457 in epoch 4, gen_loss = 0.9499523463988409, disc_loss = 0.0009188687044508983
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 1.0390048027038574, disc_loss = 0.0007543704705312848
Trained batch 1 in epoch 5, gen_loss = 0.9949884712696075, disc_loss = 0.0007214365468826145
Trained batch 2 in epoch 5, gen_loss = 0.9558127522468567, disc_loss = 0.0007065226673148572
Trained batch 3 in epoch 5, gen_loss = 0.9532016664743423, disc_loss = 0.0008111588103929535
Trained batch 4 in epoch 5, gen_loss = 0.9634014725685119, disc_loss = 0.0009394739870913326
Trained batch 5 in epoch 5, gen_loss = 0.9551947712898254, disc_loss = 0.0009381801840694001
Trained batch 6 in epoch 5, gen_loss = 0.9570998123713902, disc_loss = 0.0008850679317090128
Trained batch 7 in epoch 5, gen_loss = 0.9572998285293579, disc_loss = 0.0008143174854922108
Trained batch 8 in epoch 5, gen_loss = 0.9554041226704916, disc_loss = 0.000747104495530948
Trained batch 9 in epoch 5, gen_loss = 0.9572682321071625, disc_loss = 0.0006898452440509573
Trained batch 10 in epoch 5, gen_loss = 0.9586305997588418, disc_loss = 0.0006454051974949173
Trained batch 11 in epoch 5, gen_loss = 0.9585630943377813, disc_loss = 0.0006133260152031047
Trained batch 12 in epoch 5, gen_loss = 0.9582072450564458, disc_loss = 0.0005953845885904649
Trained batch 13 in epoch 5, gen_loss = 0.9552481174468994, disc_loss = 0.0005765202991564625
Trained batch 14 in epoch 5, gen_loss = 0.9535402456919352, disc_loss = 0.0005689089089476814
Trained batch 15 in epoch 5, gen_loss = 0.9535848647356033, disc_loss = 0.0005801500246889191
Trained batch 16 in epoch 5, gen_loss = 0.9581566207549151, disc_loss = 0.0006072838698267279
Trained batch 17 in epoch 5, gen_loss = 0.9652706980705261, disc_loss = 0.0006983373847712452
Trained batch 18 in epoch 5, gen_loss = 0.9638618889607882, disc_loss = 0.0008140084054933763
Trained batch 19 in epoch 5, gen_loss = 0.9642363607883453, disc_loss = 0.0008536496039596386
Trained batch 20 in epoch 5, gen_loss = 0.9651927465484256, disc_loss = 0.0008465291480422907
Trained batch 21 in epoch 5, gen_loss = 0.9661485390229658, disc_loss = 0.0008493245656030591
Trained batch 22 in epoch 5, gen_loss = 0.9641410475191863, disc_loss = 0.0008749899608791684
Trained batch 23 in epoch 5, gen_loss = 0.9631273820996284, disc_loss = 0.0008932665332395118
Trained batch 24 in epoch 5, gen_loss = 0.9614273691177369, disc_loss = 0.00090264932368882
Trained batch 25 in epoch 5, gen_loss = 0.9594136659915631, disc_loss = 0.0008986765180732339
Trained batch 26 in epoch 5, gen_loss = 0.9631862110561795, disc_loss = 0.0009116129141249177
Trained batch 27 in epoch 5, gen_loss = 0.962325822029795, disc_loss = 0.0010072644352996057
Trained batch 28 in epoch 5, gen_loss = 0.9624536427958258, disc_loss = 0.0010909131168114856
Trained batch 29 in epoch 5, gen_loss = 0.9636223872502645, disc_loss = 0.0011129233530179287
Trained batch 30 in epoch 5, gen_loss = 0.9649752186190698, disc_loss = 0.0011169861846288005
Trained batch 31 in epoch 5, gen_loss = 0.9638749472796917, disc_loss = 0.001116091601033986
Trained batch 32 in epoch 5, gen_loss = 0.9648948510487875, disc_loss = 0.0011003192868718709
Trained batch 33 in epoch 5, gen_loss = 0.9641900974161485, disc_loss = 0.0010904285633895436
Trained batch 34 in epoch 5, gen_loss = 0.9633788108825684, disc_loss = 0.001107578322989866
Trained batch 35 in epoch 5, gen_loss = 0.9644130104117923, disc_loss = 0.001123042532223432
Trained batch 36 in epoch 5, gen_loss = 0.9629445817019489, disc_loss = 0.001110302351220083
Trained batch 37 in epoch 5, gen_loss = 0.9631272319116091, disc_loss = 0.001091168501788113
Trained batch 38 in epoch 5, gen_loss = 0.9623910906987313, disc_loss = 0.0010985602984407868
Trained batch 39 in epoch 5, gen_loss = 0.9612261906266213, disc_loss = 0.0011218620093131904
Trained batch 40 in epoch 5, gen_loss = 0.9603878884780698, disc_loss = 0.0011180970518247838
Trained batch 41 in epoch 5, gen_loss = 0.961444384994961, disc_loss = 0.0011061481151652213
Trained batch 42 in epoch 5, gen_loss = 0.9609093333399573, disc_loss = 0.0011023889264622487
Trained batch 43 in epoch 5, gen_loss = 0.9589277668432756, disc_loss = 0.0010892284434786152
Trained batch 44 in epoch 5, gen_loss = 0.9622053278817071, disc_loss = 0.0010907153385536124
Trained batch 45 in epoch 5, gen_loss = 0.9605025454707767, disc_loss = 0.0011718509226541398
Trained batch 46 in epoch 5, gen_loss = 0.9617207012277968, disc_loss = 0.0013186366271296952
Trained batch 47 in epoch 5, gen_loss = 0.9599933934708437, disc_loss = 0.0014693059098741894
Trained batch 48 in epoch 5, gen_loss = 0.9618577385435298, disc_loss = 0.0015980565762479923
Trained batch 49 in epoch 5, gen_loss = 0.9598883783817291, disc_loss = 0.001665887059061788
Trained batch 50 in epoch 5, gen_loss = 0.9597209610191046, disc_loss = 0.0016770384670463483
Trained batch 51 in epoch 5, gen_loss = 0.9616125214558381, disc_loss = 0.001666530361734868
Trained batch 52 in epoch 5, gen_loss = 0.9616711150925115, disc_loss = 0.0016593823362062773
Trained batch 53 in epoch 5, gen_loss = 0.9629247596970311, disc_loss = 0.0016602236315116493
Trained batch 54 in epoch 5, gen_loss = 0.9627366152676669, disc_loss = 0.0016536697740031575
Trained batch 55 in epoch 5, gen_loss = 0.9613313164029803, disc_loss = 0.001639316580362252
Trained batch 56 in epoch 5, gen_loss = 0.9589672506901256, disc_loss = 0.001619730743665346
Trained batch 57 in epoch 5, gen_loss = 0.959225687487372, disc_loss = 0.001620014527800557
Trained batch 58 in epoch 5, gen_loss = 0.9580566903292123, disc_loss = 0.0016632447166218406
Trained batch 59 in epoch 5, gen_loss = 0.9569705367088318, disc_loss = 0.0017207778762288702
Trained batch 60 in epoch 5, gen_loss = 0.9565650869588382, disc_loss = 0.0017651276988336114
Trained batch 61 in epoch 5, gen_loss = 0.9564266589380079, disc_loss = 0.0017864647356139857
Trained batch 62 in epoch 5, gen_loss = 0.9564727629934039, disc_loss = 0.0017860537817117772
Trained batch 63 in epoch 5, gen_loss = 0.9570312229916453, disc_loss = 0.001775214438112016
Trained batch 64 in epoch 5, gen_loss = 0.9572111762486971, disc_loss = 0.0017594837946279978
Trained batch 65 in epoch 5, gen_loss = 0.9568274048241702, disc_loss = 0.0017418659465902513
Trained batch 66 in epoch 5, gen_loss = 0.9571403131556155, disc_loss = 0.0017242642417515336
Trained batch 67 in epoch 5, gen_loss = 0.9574627078631345, disc_loss = 0.0017103503508705592
Trained batch 68 in epoch 5, gen_loss = 0.9569408668987993, disc_loss = 0.0016950488329250904
Trained batch 69 in epoch 5, gen_loss = 0.9556246536118643, disc_loss = 0.0016762872787824434
Trained batch 70 in epoch 5, gen_loss = 0.9546772602578284, disc_loss = 0.0016577887503777854
Trained batch 71 in epoch 5, gen_loss = 0.9549576731191741, disc_loss = 0.0016386930639984915
Trained batch 72 in epoch 5, gen_loss = 0.9537476987054904, disc_loss = 0.0016211697310273064
Trained batch 73 in epoch 5, gen_loss = 0.9532801992184406, disc_loss = 0.0016074945553948448
Trained batch 74 in epoch 5, gen_loss = 0.9545903825759887, disc_loss = 0.001596555799090614
Trained batch 75 in epoch 5, gen_loss = 0.9545593316617765, disc_loss = 0.0015839269540983399
Trained batch 76 in epoch 5, gen_loss = 0.9553271570763031, disc_loss = 0.0015704484623191611
Trained batch 77 in epoch 5, gen_loss = 0.9557223251232734, disc_loss = 0.0015583071717395424
Trained batch 78 in epoch 5, gen_loss = 0.9550058985058265, disc_loss = 0.0015478636391602363
Trained batch 79 in epoch 5, gen_loss = 0.9545965127646923, disc_loss = 0.001534768690180499
Trained batch 80 in epoch 5, gen_loss = 0.9558380378617181, disc_loss = 0.001526540439909347
Trained batch 81 in epoch 5, gen_loss = 0.9549574532159945, disc_loss = 0.0015192676318536808
Trained batch 82 in epoch 5, gen_loss = 0.9541034540498113, disc_loss = 0.0015162800197455898
Trained batch 83 in epoch 5, gen_loss = 0.9532380799452463, disc_loss = 0.0015105825067231698
Trained batch 84 in epoch 5, gen_loss = 0.9535780696307912, disc_loss = 0.0015035718699971982
Trained batch 85 in epoch 5, gen_loss = 0.9526894771775534, disc_loss = 0.0015003726144895218
Trained batch 86 in epoch 5, gen_loss = 0.951910367642326, disc_loss = 0.0014977232658775288
Trained batch 87 in epoch 5, gen_loss = 0.9516549151052128, disc_loss = 0.001490233694229656
Trained batch 88 in epoch 5, gen_loss = 0.9508997054582231, disc_loss = 0.001479084559669195
Trained batch 89 in epoch 5, gen_loss = 0.950534940428204, disc_loss = 0.0014675938162124818
Trained batch 90 in epoch 5, gen_loss = 0.9506584202850258, disc_loss = 0.0014557799063418266
Trained batch 91 in epoch 5, gen_loss = 0.9511806880650313, disc_loss = 0.0014445774083825477
Trained batch 92 in epoch 5, gen_loss = 0.9510264249258144, disc_loss = 0.0014383471301776828
Trained batch 93 in epoch 5, gen_loss = 0.9513308513671794, disc_loss = 0.0014317729442251568
Trained batch 94 in epoch 5, gen_loss = 0.9507198528239601, disc_loss = 0.0014246970408988233
Trained batch 95 in epoch 5, gen_loss = 0.9521579363693794, disc_loss = 0.0014219273671187693
Trained batch 96 in epoch 5, gen_loss = 0.9513302187329715, disc_loss = 0.001421888139862183
Trained batch 97 in epoch 5, gen_loss = 0.9509718983757253, disc_loss = 0.0014163093333731272
Trained batch 98 in epoch 5, gen_loss = 0.9506010244591068, disc_loss = 0.0014069880578770405
Trained batch 99 in epoch 5, gen_loss = 0.9501422828435898, disc_loss = 0.0013980830676155165
Trained batch 100 in epoch 5, gen_loss = 0.9493823287510635, disc_loss = 0.0013904529762002501
Trained batch 101 in epoch 5, gen_loss = 0.9492321855881635, disc_loss = 0.0013836677740875851
Trained batch 102 in epoch 5, gen_loss = 0.9504820744968155, disc_loss = 0.0013749464205918308
Trained batch 103 in epoch 5, gen_loss = 0.9510157028069863, disc_loss = 0.00136444152023894
Trained batch 104 in epoch 5, gen_loss = 0.9510998952956426, disc_loss = 0.0013535898067944107
Trained batch 105 in epoch 5, gen_loss = 0.9514291308960825, disc_loss = 0.0013448027690723186
Trained batch 106 in epoch 5, gen_loss = 0.9513808483275298, disc_loss = 0.001339178310955274
Trained batch 107 in epoch 5, gen_loss = 0.9519143286678526, disc_loss = 0.0013320678753424781
Trained batch 108 in epoch 5, gen_loss = 0.9523864585325259, disc_loss = 0.0013221429568531693
Trained batch 109 in epoch 5, gen_loss = 0.9518051174553958, disc_loss = 0.0013122320123577745
Trained batch 110 in epoch 5, gen_loss = 0.951646726947647, disc_loss = 0.0013022869734905307
Trained batch 111 in epoch 5, gen_loss = 0.9508452090833869, disc_loss = 0.0012931452281139042
Trained batch 112 in epoch 5, gen_loss = 0.9495698113357072, disc_loss = 0.0012848927979141193
Trained batch 113 in epoch 5, gen_loss = 0.9494677850028925, disc_loss = 0.0012777712362820463
Trained batch 114 in epoch 5, gen_loss = 0.9493461277173914, disc_loss = 0.0012729193338284106
Trained batch 115 in epoch 5, gen_loss = 0.9492548750392322, disc_loss = 0.0012670864416577388
Trained batch 116 in epoch 5, gen_loss = 0.9492435694759728, disc_loss = 0.0012597379307750151
Trained batch 117 in epoch 5, gen_loss = 0.9484167796070293, disc_loss = 0.001254563889850002
Trained batch 118 in epoch 5, gen_loss = 0.9474650866845075, disc_loss = 0.0012542881266489829
Trained batch 119 in epoch 5, gen_loss = 0.947110936542352, disc_loss = 0.0012506841692811576
Trained batch 120 in epoch 5, gen_loss = 0.9468908935538993, disc_loss = 0.001243958330385133
Trained batch 121 in epoch 5, gen_loss = 0.9470971964421819, disc_loss = 0.0012365694370809713
Trained batch 122 in epoch 5, gen_loss = 0.9474482337633768, disc_loss = 0.0012296632572779494
Trained batch 123 in epoch 5, gen_loss = 0.9477529775711798, disc_loss = 0.001221941346175886
Trained batch 124 in epoch 5, gen_loss = 0.9467319211959839, disc_loss = 0.001215609077946283
Trained batch 125 in epoch 5, gen_loss = 0.9463555718225146, disc_loss = 0.0012130408030648213
Trained batch 126 in epoch 5, gen_loss = 0.9466486174290575, disc_loss = 0.00120938587422743
Trained batch 127 in epoch 5, gen_loss = 0.9464697199873626, disc_loss = 0.0012032314176622094
Trained batch 128 in epoch 5, gen_loss = 0.9457099885903588, disc_loss = 0.0011958473317131991
Trained batch 129 in epoch 5, gen_loss = 0.94609143779828, disc_loss = 0.0011897031393555853
Trained batch 130 in epoch 5, gen_loss = 0.9465336385574049, disc_loss = 0.0011857516361793276
Trained batch 131 in epoch 5, gen_loss = 0.94644892531814, disc_loss = 0.0011798523109146945
Trained batch 132 in epoch 5, gen_loss = 0.9460751593561101, disc_loss = 0.0011732474546503149
Trained batch 133 in epoch 5, gen_loss = 0.9459207026816127, disc_loss = 0.001166788822820987
Trained batch 134 in epoch 5, gen_loss = 0.9463520584283052, disc_loss = 0.0011602508209223204
Trained batch 135 in epoch 5, gen_loss = 0.9470841468257063, disc_loss = 0.0011544327951603062
Trained batch 136 in epoch 5, gen_loss = 0.9471870121294564, disc_loss = 0.001147600602172485
Trained batch 137 in epoch 5, gen_loss = 0.9474844578383625, disc_loss = 0.0011407597143577573
Trained batch 138 in epoch 5, gen_loss = 0.9474591149700632, disc_loss = 0.0011338915618508384
Trained batch 139 in epoch 5, gen_loss = 0.9476505300828388, disc_loss = 0.0011278512519701117
Trained batch 140 in epoch 5, gen_loss = 0.9477243258598003, disc_loss = 0.0011231704895361492
Trained batch 141 in epoch 5, gen_loss = 0.9474578739052087, disc_loss = 0.0011191719089073955
Trained batch 142 in epoch 5, gen_loss = 0.9467524519333472, disc_loss = 0.0011161545405923095
Trained batch 143 in epoch 5, gen_loss = 0.9465215466916561, disc_loss = 0.0011140532848609535
Trained batch 144 in epoch 5, gen_loss = 0.9465207408214438, disc_loss = 0.0011112645479192122
Trained batch 145 in epoch 5, gen_loss = 0.9463567092810592, disc_loss = 0.0011063982624551025
Trained batch 146 in epoch 5, gen_loss = 0.946739931901296, disc_loss = 0.001101400175165119
Trained batch 147 in epoch 5, gen_loss = 0.9465571279461319, disc_loss = 0.0011004622000335665
Trained batch 148 in epoch 5, gen_loss = 0.9466961698244082, disc_loss = 0.0011025119595145245
Trained batch 149 in epoch 5, gen_loss = 0.9469598499933879, disc_loss = 0.0011038787734772388
Trained batch 150 in epoch 5, gen_loss = 0.9467661728132639, disc_loss = 0.0011031167091730834
Trained batch 151 in epoch 5, gen_loss = 0.9468621090054512, disc_loss = 0.0011022441630254769
Trained batch 152 in epoch 5, gen_loss = 0.9466023059452281, disc_loss = 0.0010993684373044232
Trained batch 153 in epoch 5, gen_loss = 0.9464558335867795, disc_loss = 0.0010952077378509808
Trained batch 154 in epoch 5, gen_loss = 0.9463472070232515, disc_loss = 0.0010904554335866123
Trained batch 155 in epoch 5, gen_loss = 0.9470069740827267, disc_loss = 0.0010871724891610658
Trained batch 156 in epoch 5, gen_loss = 0.947314703920085, disc_loss = 0.0010851291165862138
Trained batch 157 in epoch 5, gen_loss = 0.9479397622090352, disc_loss = 0.0010839298577858371
Trained batch 158 in epoch 5, gen_loss = 0.947604165886933, disc_loss = 0.00108366468082967
Trained batch 159 in epoch 5, gen_loss = 0.9477920368313789, disc_loss = 0.00108430147429317
Trained batch 160 in epoch 5, gen_loss = 0.9478867098411418, disc_loss = 0.001085080402167167
Trained batch 161 in epoch 5, gen_loss = 0.9475067835531117, disc_loss = 0.0010829954557221406
Trained batch 162 in epoch 5, gen_loss = 0.9475936995693511, disc_loss = 0.001079547060603573
Trained batch 163 in epoch 5, gen_loss = 0.9473859864037212, disc_loss = 0.0010760458466304444
Trained batch 164 in epoch 5, gen_loss = 0.9478290731256659, disc_loss = 0.0010738292361510862
Trained batch 165 in epoch 5, gen_loss = 0.9478643270860235, disc_loss = 0.001073055602406735
Trained batch 166 in epoch 5, gen_loss = 0.9483055911378232, disc_loss = 0.0010727431740497468
Trained batch 167 in epoch 5, gen_loss = 0.948740446851367, disc_loss = 0.0010714550511953089
Trained batch 168 in epoch 5, gen_loss = 0.9489406163875873, disc_loss = 0.0010684646217265447
Trained batch 169 in epoch 5, gen_loss = 0.9489681990707621, disc_loss = 0.0010642149511327528
Trained batch 170 in epoch 5, gen_loss = 0.9491300990706996, disc_loss = 0.0010598372221769143
Trained batch 171 in epoch 5, gen_loss = 0.9493723535953567, disc_loss = 0.0010560871339484314
Trained batch 172 in epoch 5, gen_loss = 0.9490329406164975, disc_loss = 0.001051971721839741
Trained batch 173 in epoch 5, gen_loss = 0.948433036091684, disc_loss = 0.001047379667429125
Trained batch 174 in epoch 5, gen_loss = 0.9484595870971679, disc_loss = 0.0010426722277354981
Trained batch 175 in epoch 5, gen_loss = 0.9481796317479827, disc_loss = 0.0010385360981837782
Trained batch 176 in epoch 5, gen_loss = 0.9479100980327628, disc_loss = 0.0010345363320248718
Trained batch 177 in epoch 5, gen_loss = 0.9478207685974207, disc_loss = 0.0010315870381878648
Trained batch 178 in epoch 5, gen_loss = 0.9477538975923421, disc_loss = 0.0010285407255010877
Trained batch 179 in epoch 5, gen_loss = 0.9478824251227909, disc_loss = 0.0010246306306928292
Trained batch 180 in epoch 5, gen_loss = 0.9480721433518341, disc_loss = 0.0010204780661920343
Trained batch 181 in epoch 5, gen_loss = 0.9483276504081685, disc_loss = 0.001016282280593609
Trained batch 182 in epoch 5, gen_loss = 0.9481987331082912, disc_loss = 0.001011826561240968
Trained batch 183 in epoch 5, gen_loss = 0.9486437469072964, disc_loss = 0.001007432309842957
Trained batch 184 in epoch 5, gen_loss = 0.9485046531703021, disc_loss = 0.0010028462581701475
Trained batch 185 in epoch 5, gen_loss = 0.9486954260256982, disc_loss = 0.0009988899405617567
Trained batch 186 in epoch 5, gen_loss = 0.9487323047005557, disc_loss = 0.0009970108115918595
Trained batch 187 in epoch 5, gen_loss = 0.9488585518395647, disc_loss = 0.000997241101744139
Trained batch 188 in epoch 5, gen_loss = 0.9489721753609874, disc_loss = 0.0009960415112482946
Trained batch 189 in epoch 5, gen_loss = 0.9489385284875569, disc_loss = 0.00099234483204782
Trained batch 190 in epoch 5, gen_loss = 0.9483465059265417, disc_loss = 0.00098817596999509
Trained batch 191 in epoch 5, gen_loss = 0.9481545534605781, disc_loss = 0.0009869172815039444
Trained batch 192 in epoch 5, gen_loss = 0.9485006588728316, disc_loss = 0.0009872881367493788
Trained batch 193 in epoch 5, gen_loss = 0.9482832412744305, disc_loss = 0.0009839909016778788
Trained batch 194 in epoch 5, gen_loss = 0.9481177849647326, disc_loss = 0.0009796963824042812
Trained batch 195 in epoch 5, gen_loss = 0.9474464730948818, disc_loss = 0.0009771769869911047
Trained batch 196 in epoch 5, gen_loss = 0.9474412490268649, disc_loss = 0.0009784389625251445
Trained batch 197 in epoch 5, gen_loss = 0.9473346372445425, disc_loss = 0.0009815863050247609
Trained batch 198 in epoch 5, gen_loss = 0.9471670544926246, disc_loss = 0.0009831896668356193
Trained batch 199 in epoch 5, gen_loss = 0.9474248763918877, disc_loss = 0.0009813155254232697
Trained batch 200 in epoch 5, gen_loss = 0.9476453190419212, disc_loss = 0.0009775444309502858
Trained batch 201 in epoch 5, gen_loss = 0.947472356333591, disc_loss = 0.0009739122723487418
Trained batch 202 in epoch 5, gen_loss = 0.9475438859075161, disc_loss = 0.0009708344042324117
Trained batch 203 in epoch 5, gen_loss = 0.9469386981982811, disc_loss = 0.0009686576043296715
Trained batch 204 in epoch 5, gen_loss = 0.947525664073665, disc_loss = 0.0009712078986212429
Trained batch 205 in epoch 5, gen_loss = 0.9476473606327205, disc_loss = 0.0009758500695947413
Trained batch 206 in epoch 5, gen_loss = 0.9475306776410716, disc_loss = 0.0009782311131453349
Trained batch 207 in epoch 5, gen_loss = 0.9478242251162345, disc_loss = 0.0009788774066412141
Trained batch 208 in epoch 5, gen_loss = 0.9481977945879886, disc_loss = 0.0009795034766023416
Trained batch 209 in epoch 5, gen_loss = 0.947971042564937, disc_loss = 0.0009784384608446132
Trained batch 210 in epoch 5, gen_loss = 0.9484764258443462, disc_loss = 0.0009765279351323136
Trained batch 211 in epoch 5, gen_loss = 0.9483757153996881, disc_loss = 0.0009746993985246727
Trained batch 212 in epoch 5, gen_loss = 0.9485199322722887, disc_loss = 0.000972179222650861
Trained batch 213 in epoch 5, gen_loss = 0.9485008034193627, disc_loss = 0.0009691648583186825
Trained batch 214 in epoch 5, gen_loss = 0.9487191130948621, disc_loss = 0.0009667081491707629
Trained batch 215 in epoch 5, gen_loss = 0.9483838983707957, disc_loss = 0.0009665974526056003
Trained batch 216 in epoch 5, gen_loss = 0.9482646960816625, disc_loss = 0.0009684656240520269
Trained batch 217 in epoch 5, gen_loss = 0.9486653602451359, disc_loss = 0.0009672196928802621
Trained batch 218 in epoch 5, gen_loss = 0.949089493925713, disc_loss = 0.0009640641608828313
Trained batch 219 in epoch 5, gen_loss = 0.9495214446024461, disc_loss = 0.0009612133370617151
Trained batch 220 in epoch 5, gen_loss = 0.9498419044244343, disc_loss = 0.0009587648099739256
Trained batch 221 in epoch 5, gen_loss = 0.949982649034208, disc_loss = 0.0009564560932958884
Trained batch 222 in epoch 5, gen_loss = 0.9503914203344439, disc_loss = 0.0009540085703752634
Trained batch 223 in epoch 5, gen_loss = 0.9503875457282577, disc_loss = 0.0009516366174336456
Trained batch 224 in epoch 5, gen_loss = 0.9501735962761773, disc_loss = 0.0009485921583190146
Trained batch 225 in epoch 5, gen_loss = 0.9497531088052598, disc_loss = 0.0009463920338600627
Trained batch 226 in epoch 5, gen_loss = 0.949707126827492, disc_loss = 0.0009456493386369001
Trained batch 227 in epoch 5, gen_loss = 0.9493054878293422, disc_loss = 0.0009457787434752262
Trained batch 228 in epoch 5, gen_loss = 0.9491937233370985, disc_loss = 0.0009455847279138163
Trained batch 229 in epoch 5, gen_loss = 0.9487499009007992, disc_loss = 0.0009452410299158857
Trained batch 230 in epoch 5, gen_loss = 0.9488410833594086, disc_loss = 0.0009460211281707002
Trained batch 231 in epoch 5, gen_loss = 0.9486649568224775, disc_loss = 0.0009490752542252926
Trained batch 232 in epoch 5, gen_loss = 0.9489582605627985, disc_loss = 0.0009513618758042211
Trained batch 233 in epoch 5, gen_loss = 0.948800789240079, disc_loss = 0.0009497375774513691
Trained batch 234 in epoch 5, gen_loss = 0.9489291000873484, disc_loss = 0.0009481078869554194
Trained batch 235 in epoch 5, gen_loss = 0.9489377201613733, disc_loss = 0.0009489681533985708
Trained batch 236 in epoch 5, gen_loss = 0.9488103885187882, disc_loss = 0.0009497018683974863
Trained batch 237 in epoch 5, gen_loss = 0.949090223602888, disc_loss = 0.0009489428045809222
Trained batch 238 in epoch 5, gen_loss = 0.9492437293339973, disc_loss = 0.0009476468314087432
Trained batch 239 in epoch 5, gen_loss = 0.9493813184400399, disc_loss = 0.0009476768310075083
Trained batch 240 in epoch 5, gen_loss = 0.9495818441834193, disc_loss = 0.0009472876171537006
Trained batch 241 in epoch 5, gen_loss = 0.9496046169237657, disc_loss = 0.0009456510276270045
Trained batch 242 in epoch 5, gen_loss = 0.9496622549162971, disc_loss = 0.0009426870162947556
Trained batch 243 in epoch 5, gen_loss = 0.9496723266898609, disc_loss = 0.000942026948189882
Trained batch 244 in epoch 5, gen_loss = 0.9499756813049316, disc_loss = 0.0009422678419635916
Trained batch 245 in epoch 5, gen_loss = 0.9501969392706708, disc_loss = 0.0009423662573326288
Trained batch 246 in epoch 5, gen_loss = 0.9504078588022394, disc_loss = 0.0009401508209650001
Trained batch 247 in epoch 5, gen_loss = 0.950607945361445, disc_loss = 0.0009369942424288433
Trained batch 248 in epoch 5, gen_loss = 0.9508452611754697, disc_loss = 0.0009339658427636614
Trained batch 249 in epoch 5, gen_loss = 0.9511326727867127, disc_loss = 0.0009312667371123098
Trained batch 250 in epoch 5, gen_loss = 0.9512059220754768, disc_loss = 0.0009289966226324432
Trained batch 251 in epoch 5, gen_loss = 0.951574897718808, disc_loss = 0.0009284395925374517
Trained batch 252 in epoch 5, gen_loss = 0.9517004602982593, disc_loss = 0.0009298297252092813
Trained batch 253 in epoch 5, gen_loss = 0.951762063766089, disc_loss = 0.0009313264561383472
Trained batch 254 in epoch 5, gen_loss = 0.9517787379377028, disc_loss = 0.0009314462030648856
Trained batch 255 in epoch 5, gen_loss = 0.9519456380512565, disc_loss = 0.0009302892355549375
Trained batch 256 in epoch 5, gen_loss = 0.9521536704167318, disc_loss = 0.0009280415269403976
Trained batch 257 in epoch 5, gen_loss = 0.9522391042506048, disc_loss = 0.0009252015848589029
Trained batch 258 in epoch 5, gen_loss = 0.9523059960497853, disc_loss = 0.0009226755332448933
Trained batch 259 in epoch 5, gen_loss = 0.9520037919282913, disc_loss = 0.0009201373205891847
Trained batch 260 in epoch 5, gen_loss = 0.9522436544356219, disc_loss = 0.0009178801689371002
Trained batch 261 in epoch 5, gen_loss = 0.9523934455773303, disc_loss = 0.0009156085387159331
Trained batch 262 in epoch 5, gen_loss = 0.9524206537257582, disc_loss = 0.0009138150665286695
Trained batch 263 in epoch 5, gen_loss = 0.9523330197641344, disc_loss = 0.000912571813221968
Trained batch 264 in epoch 5, gen_loss = 0.9522542011063054, disc_loss = 0.0009114920496083972
Trained batch 265 in epoch 5, gen_loss = 0.9522779857305655, disc_loss = 0.0009102127458431926
Trained batch 266 in epoch 5, gen_loss = 0.952362184220932, disc_loss = 0.0009085054055125757
Trained batch 267 in epoch 5, gen_loss = 0.9519816883909169, disc_loss = 0.0009066473848274179
Trained batch 268 in epoch 5, gen_loss = 0.9521829051599183, disc_loss = 0.0009048508334022923
Trained batch 269 in epoch 5, gen_loss = 0.9523970539923068, disc_loss = 0.000902978865229266
Trained batch 270 in epoch 5, gen_loss = 0.952305967737388, disc_loss = 0.0009007892208719434
Trained batch 271 in epoch 5, gen_loss = 0.952329259365797, disc_loss = 0.0008988621172701481
Trained batch 272 in epoch 5, gen_loss = 0.9523329850518223, disc_loss = 0.0008972136680852969
Trained batch 273 in epoch 5, gen_loss = 0.9523393770639044, disc_loss = 0.0008958481683121335
Trained batch 274 in epoch 5, gen_loss = 0.952387773773887, disc_loss = 0.0008946860218103129
Trained batch 275 in epoch 5, gen_loss = 0.9525609945041545, disc_loss = 0.0008932303870202252
Trained batch 276 in epoch 5, gen_loss = 0.9531304083145913, disc_loss = 0.0008912544848505804
Trained batch 277 in epoch 5, gen_loss = 0.9532534072725035, disc_loss = 0.0008892741889408923
Trained batch 278 in epoch 5, gen_loss = 0.9537982017763199, disc_loss = 0.0008885821970250612
Trained batch 279 in epoch 5, gen_loss = 0.953815564087459, disc_loss = 0.0008880506467643759
Trained batch 280 in epoch 5, gen_loss = 0.9539403756318143, disc_loss = 0.0008876496672508509
Trained batch 281 in epoch 5, gen_loss = 0.95386141432938, disc_loss = 0.0008874019808222619
Trained batch 282 in epoch 5, gen_loss = 0.9538473375273256, disc_loss = 0.0008868342636226324
Trained batch 283 in epoch 5, gen_loss = 0.9536070605398903, disc_loss = 0.0008860322639930659
Trained batch 284 in epoch 5, gen_loss = 0.9535610012840806, disc_loss = 0.000885262123866644
Trained batch 285 in epoch 5, gen_loss = 0.953432020815936, disc_loss = 0.0008838872647200307
Trained batch 286 in epoch 5, gen_loss = 0.9532972950137866, disc_loss = 0.0008816638250469363
Trained batch 287 in epoch 5, gen_loss = 0.9534456636756659, disc_loss = 0.0008792686046237779
Trained batch 288 in epoch 5, gen_loss = 0.9535495927589575, disc_loss = 0.0008771306314770693
Trained batch 289 in epoch 5, gen_loss = 0.9538159952081483, disc_loss = 0.0008754570849524843
Trained batch 290 in epoch 5, gen_loss = 0.9536864218842942, disc_loss = 0.0008750288141471305
Trained batch 291 in epoch 5, gen_loss = 0.9535366913227186, disc_loss = 0.00087562523683978
Trained batch 292 in epoch 5, gen_loss = 0.9534047089339116, disc_loss = 0.0008771418116143634
Trained batch 293 in epoch 5, gen_loss = 0.9537063030158581, disc_loss = 0.0008790516569243497
Trained batch 294 in epoch 5, gen_loss = 0.9537504224453942, disc_loss = 0.0008811830137994425
Trained batch 295 in epoch 5, gen_loss = 0.9538667560429186, disc_loss = 0.0008827593042165186
Trained batch 296 in epoch 5, gen_loss = 0.9537831217752964, disc_loss = 0.0008833049402101066
Trained batch 297 in epoch 5, gen_loss = 0.9537835129155409, disc_loss = 0.0008824961320024402
Trained batch 298 in epoch 5, gen_loss = 0.9539345359323814, disc_loss = 0.0008807364230906205
Trained batch 299 in epoch 5, gen_loss = 0.9541694128513336, disc_loss = 0.0008797651080628081
Trained batch 300 in epoch 5, gen_loss = 0.9542914886411242, disc_loss = 0.0008807878268235193
Trained batch 301 in epoch 5, gen_loss = 0.9543089994926326, disc_loss = 0.0008828238429812351
Trained batch 302 in epoch 5, gen_loss = 0.954159668176481, disc_loss = 0.0008827371187273738
Trained batch 303 in epoch 5, gen_loss = 0.9541865797027161, disc_loss = 0.000881683952732266
Trained batch 304 in epoch 5, gen_loss = 0.9543599814665122, disc_loss = 0.0008800503522535542
Trained batch 305 in epoch 5, gen_loss = 0.9541077430731331, disc_loss = 0.0008778598323522221
Trained batch 306 in epoch 5, gen_loss = 0.9539980115641988, disc_loss = 0.0008757446032906321
Trained batch 307 in epoch 5, gen_loss = 0.9540571371069202, disc_loss = 0.0008739825162746303
Trained batch 308 in epoch 5, gen_loss = 0.9541025707636837, disc_loss = 0.000872275432361543
Trained batch 309 in epoch 5, gen_loss = 0.9541048224895231, disc_loss = 0.0008708014386713564
Trained batch 310 in epoch 5, gen_loss = 0.9540002692934018, disc_loss = 0.0008698981387242735
Trained batch 311 in epoch 5, gen_loss = 0.9541183945078117, disc_loss = 0.0008689081819633989
Trained batch 312 in epoch 5, gen_loss = 0.9542751995900187, disc_loss = 0.000867117097480044
Trained batch 313 in epoch 5, gen_loss = 0.9543680165224014, disc_loss = 0.0008648995065929629
Trained batch 314 in epoch 5, gen_loss = 0.9541825538589841, disc_loss = 0.000863621082057112
Trained batch 315 in epoch 5, gen_loss = 0.9544449318436128, disc_loss = 0.0008649992881986737
Trained batch 316 in epoch 5, gen_loss = 0.9543640938843087, disc_loss = 0.0008675099864832716
Trained batch 317 in epoch 5, gen_loss = 0.954215924882289, disc_loss = 0.0008688928361186969
Trained batch 318 in epoch 5, gen_loss = 0.9542170834018145, disc_loss = 0.0008684762018742945
Trained batch 319 in epoch 5, gen_loss = 0.9541312485933304, disc_loss = 0.0008670155150866776
Trained batch 320 in epoch 5, gen_loss = 0.9541498101388926, disc_loss = 0.0008651864890994161
Trained batch 321 in epoch 5, gen_loss = 0.9542729539900833, disc_loss = 0.0008632878395829997
Trained batch 322 in epoch 5, gen_loss = 0.9544606090699187, disc_loss = 0.0008617008316486312
Trained batch 323 in epoch 5, gen_loss = 0.9545283317565918, disc_loss = 0.0008603175671772605
Trained batch 324 in epoch 5, gen_loss = 0.9544834309357864, disc_loss = 0.0008590377894982409
Trained batch 325 in epoch 5, gen_loss = 0.9543330603581996, disc_loss = 0.0008576486853916952
Trained batch 326 in epoch 5, gen_loss = 0.9545090880233578, disc_loss = 0.0008564358621633495
Trained batch 327 in epoch 5, gen_loss = 0.954543019758492, disc_loss = 0.000854989800001665
Trained batch 328 in epoch 5, gen_loss = 0.9547764615447325, disc_loss = 0.0008533717896350543
Trained batch 329 in epoch 5, gen_loss = 0.9547507482947726, disc_loss = 0.0008513585966835363
Trained batch 330 in epoch 5, gen_loss = 0.9547122758320812, disc_loss = 0.0008493355849759197
Trained batch 331 in epoch 5, gen_loss = 0.9547001931322626, disc_loss = 0.0008474150406062065
Trained batch 332 in epoch 5, gen_loss = 0.9549784799953839, disc_loss = 0.0008458583693505285
Trained batch 333 in epoch 5, gen_loss = 0.9549104043109689, disc_loss = 0.00084457557382129
Trained batch 334 in epoch 5, gen_loss = 0.9548700145821073, disc_loss = 0.000843529123117897
Trained batch 335 in epoch 5, gen_loss = 0.954885099970159, disc_loss = 0.0008426857185397585
Trained batch 336 in epoch 5, gen_loss = 0.9547696101205639, disc_loss = 0.0008417634051279317
Trained batch 337 in epoch 5, gen_loss = 0.9546366141745325, disc_loss = 0.0008405136969491574
Trained batch 338 in epoch 5, gen_loss = 0.9545218519053277, disc_loss = 0.0008390472965262787
Trained batch 339 in epoch 5, gen_loss = 0.9548272297662848, disc_loss = 0.0008381181579726912
Trained batch 340 in epoch 5, gen_loss = 0.9547196046348192, disc_loss = 0.0008382556812845913
Trained batch 341 in epoch 5, gen_loss = 0.9546627297736051, disc_loss = 0.0008393946920360891
Trained batch 342 in epoch 5, gen_loss = 0.9544548732893807, disc_loss = 0.0008409731930091912
Trained batch 343 in epoch 5, gen_loss = 0.9547026692781337, disc_loss = 0.0008436578028459037
Trained batch 344 in epoch 5, gen_loss = 0.9547378944314044, disc_loss = 0.0008469370789353506
Trained batch 345 in epoch 5, gen_loss = 0.9547046908753456, disc_loss = 0.0008490566560269112
Trained batch 346 in epoch 5, gen_loss = 0.9547904379429666, disc_loss = 0.0008491910032871628
Trained batch 347 in epoch 5, gen_loss = 0.9548085820058296, disc_loss = 0.0008478654100594442
Trained batch 348 in epoch 5, gen_loss = 0.9548716476790201, disc_loss = 0.00084612827441511
Trained batch 349 in epoch 5, gen_loss = 0.9547051402500698, disc_loss = 0.0008447565698796617
Trained batch 350 in epoch 5, gen_loss = 0.9553061424836814, disc_loss = 0.0008438308748145961
Trained batch 351 in epoch 5, gen_loss = 0.9552062805742025, disc_loss = 0.0008421448875940934
Trained batch 352 in epoch 5, gen_loss = 0.9551303702440883, disc_loss = 0.000840170187915203
Trained batch 353 in epoch 5, gen_loss = 0.9550659466261244, disc_loss = 0.0008385077093880476
Trained batch 354 in epoch 5, gen_loss = 0.9551190255393445, disc_loss = 0.0008379751317937609
Trained batch 355 in epoch 5, gen_loss = 0.9550827274496636, disc_loss = 0.0008382162506289236
Trained batch 356 in epoch 5, gen_loss = 0.9552321873125242, disc_loss = 0.0008384407689033144
Trained batch 357 in epoch 5, gen_loss = 0.955389677312787, disc_loss = 0.0008380650128068808
Trained batch 358 in epoch 5, gen_loss = 0.9555952115643324, disc_loss = 0.0008369723835429514
Trained batch 359 in epoch 5, gen_loss = 0.9557459558049838, disc_loss = 0.0008356641742769473
Trained batch 360 in epoch 5, gen_loss = 0.9557456519465037, disc_loss = 0.0008343820074132006
Trained batch 361 in epoch 5, gen_loss = 0.9557347954636779, disc_loss = 0.0008333468382331692
Trained batch 362 in epoch 5, gen_loss = 0.9555877698354485, disc_loss = 0.0008324200164631892
Trained batch 363 in epoch 5, gen_loss = 0.9552660717086477, disc_loss = 0.0008311852403234557
Trained batch 364 in epoch 5, gen_loss = 0.955383176836249, disc_loss = 0.0008298845545465306
Trained batch 365 in epoch 5, gen_loss = 0.9553915144967251, disc_loss = 0.0008287355065208356
Trained batch 366 in epoch 5, gen_loss = 0.955479178181786, disc_loss = 0.0008274635940165911
Trained batch 367 in epoch 5, gen_loss = 0.955487715161365, disc_loss = 0.0008259899368567858
Trained batch 368 in epoch 5, gen_loss = 0.9556189268262083, disc_loss = 0.0008246384780799722
Trained batch 369 in epoch 5, gen_loss = 0.955533524783882, disc_loss = 0.0008231213299802983
Trained batch 370 in epoch 5, gen_loss = 0.9554972224479737, disc_loss = 0.0008215257289852053
Trained batch 371 in epoch 5, gen_loss = 0.955417231205971, disc_loss = 0.0008201306399930599
Trained batch 372 in epoch 5, gen_loss = 0.9554468254301567, disc_loss = 0.0008187637551707633
Trained batch 373 in epoch 5, gen_loss = 0.9552301681615452, disc_loss = 0.0008170769624533456
Trained batch 374 in epoch 5, gen_loss = 0.955264181137085, disc_loss = 0.0008153909473912791
Trained batch 375 in epoch 5, gen_loss = 0.9551075666825822, disc_loss = 0.0008137612377972703
Trained batch 376 in epoch 5, gen_loss = 0.9551004220383237, disc_loss = 0.0008120829718041083
Trained batch 377 in epoch 5, gen_loss = 0.9553779150758471, disc_loss = 0.00081044589470371
Trained batch 378 in epoch 5, gen_loss = 0.9552228552999471, disc_loss = 0.0008089689002725563
Trained batch 379 in epoch 5, gen_loss = 0.9552990259308564, disc_loss = 0.0008076103779067604
Trained batch 380 in epoch 5, gen_loss = 0.9554697965073773, disc_loss = 0.0008069141637677513
Trained batch 381 in epoch 5, gen_loss = 0.955324523736045, disc_loss = 0.0008070002622272775
Trained batch 382 in epoch 5, gen_loss = 0.9553234093183014, disc_loss = 0.0008060613823929976
Trained batch 383 in epoch 5, gen_loss = 0.9552531473649045, disc_loss = 0.000804852448368365
Trained batch 384 in epoch 5, gen_loss = 0.9553335850889032, disc_loss = 0.0008033746331491714
Trained batch 385 in epoch 5, gen_loss = 0.9552981231187909, disc_loss = 0.0008017478894591307
Trained batch 386 in epoch 5, gen_loss = 0.9555919929684287, disc_loss = 0.0008004545105921431
Trained batch 387 in epoch 5, gen_loss = 0.9556271125053623, disc_loss = 0.0007988981520874094
Trained batch 388 in epoch 5, gen_loss = 0.9555134667528932, disc_loss = 0.0007977030010086516
Trained batch 389 in epoch 5, gen_loss = 0.9553366885735438, disc_loss = 0.0007970243044278154
Trained batch 390 in epoch 5, gen_loss = 0.955433150843891, disc_loss = 0.0007969806258625629
Trained batch 391 in epoch 5, gen_loss = 0.9553882359546058, disc_loss = 0.0007964920928408938
Trained batch 392 in epoch 5, gen_loss = 0.9553940212756926, disc_loss = 0.0007954369005187279
Trained batch 393 in epoch 5, gen_loss = 0.9553998209498256, disc_loss = 0.0007942775224863202
Trained batch 394 in epoch 5, gen_loss = 0.955282313612443, disc_loss = 0.0007932696434377422
Trained batch 395 in epoch 5, gen_loss = 0.9553111912024141, disc_loss = 0.0007925442321243052
Trained batch 396 in epoch 5, gen_loss = 0.9552122234397331, disc_loss = 0.0007924623374304657
Trained batch 397 in epoch 5, gen_loss = 0.9550946754726333, disc_loss = 0.0007927487328272411
Trained batch 398 in epoch 5, gen_loss = 0.9549653462897566, disc_loss = 0.0007924491209972926
Trained batch 399 in epoch 5, gen_loss = 0.9547723047435284, disc_loss = 0.000791859580676828
Trained batch 400 in epoch 5, gen_loss = 0.9547507614268924, disc_loss = 0.0007916095787720253
Trained batch 401 in epoch 5, gen_loss = 0.9547547417790142, disc_loss = 0.0007916718434478129
Trained batch 402 in epoch 5, gen_loss = 0.954856689307589, disc_loss = 0.0007915067655527179
Trained batch 403 in epoch 5, gen_loss = 0.9549231409731478, disc_loss = 0.0007909094099094285
Trained batch 404 in epoch 5, gen_loss = 0.9550752997398376, disc_loss = 0.0007899256373890733
Trained batch 405 in epoch 5, gen_loss = 0.9552126545917812, disc_loss = 0.0007886258690498122
Trained batch 406 in epoch 5, gen_loss = 0.9552028275824882, disc_loss = 0.0007872769809817136
Trained batch 407 in epoch 5, gen_loss = 0.9550554466013815, disc_loss = 0.0007860742986368303
Trained batch 408 in epoch 5, gen_loss = 0.9548301983870621, disc_loss = 0.0007847563167143053
Trained batch 409 in epoch 5, gen_loss = 0.9549154405186816, disc_loss = 0.0007834722799399482
Trained batch 410 in epoch 5, gen_loss = 0.9551144149471663, disc_loss = 0.0007824165570742842
Trained batch 411 in epoch 5, gen_loss = 0.9551101623518953, disc_loss = 0.0007823124741335757
Trained batch 412 in epoch 5, gen_loss = 0.9551169048210033, disc_loss = 0.0007831702222295001
Trained batch 413 in epoch 5, gen_loss = 0.9552564916115452, disc_loss = 0.0007843003951135128
Trained batch 414 in epoch 5, gen_loss = 0.9553142462868288, disc_loss = 0.0007851606832763898
Trained batch 415 in epoch 5, gen_loss = 0.9553507767044581, disc_loss = 0.0007858035799192573
Trained batch 416 in epoch 5, gen_loss = 0.955228839703887, disc_loss = 0.000786187498568115
Trained batch 417 in epoch 5, gen_loss = 0.9550734845359931, disc_loss = 0.0007861751515285166
Trained batch 418 in epoch 5, gen_loss = 0.955116575117043, disc_loss = 0.0007862691692288338
Trained batch 419 in epoch 5, gen_loss = 0.9552318304777145, disc_loss = 0.0007862983212232524
Trained batch 420 in epoch 5, gen_loss = 0.9551300546618935, disc_loss = 0.0007857370215278416
Trained batch 421 in epoch 5, gen_loss = 0.9551753494976821, disc_loss = 0.0007849124890806758
Trained batch 422 in epoch 5, gen_loss = 0.9552128701063476, disc_loss = 0.0007839150155107899
Trained batch 423 in epoch 5, gen_loss = 0.9549844152522537, disc_loss = 0.0007826981625427988
Trained batch 424 in epoch 5, gen_loss = 0.9550230023440193, disc_loss = 0.0007816582122776547
Trained batch 425 in epoch 5, gen_loss = 0.9551249504649023, disc_loss = 0.0007806941917772238
Trained batch 426 in epoch 5, gen_loss = 0.955243255550465, disc_loss = 0.0007798346729070686
Trained batch 427 in epoch 5, gen_loss = 0.9552803124501327, disc_loss = 0.000779130579350205
Trained batch 428 in epoch 5, gen_loss = 0.9554742312097882, disc_loss = 0.0007789545616317901
Trained batch 429 in epoch 5, gen_loss = 0.9553937245246976, disc_loss = 0.0007796520197041181
Trained batch 430 in epoch 5, gen_loss = 0.955477209351179, disc_loss = 0.0007814911119934288
Trained batch 431 in epoch 5, gen_loss = 0.9554737653169367, disc_loss = 0.0007841193076577232
Trained batch 432 in epoch 5, gen_loss = 0.9553428292274475, disc_loss = 0.0007857170513377786
Trained batch 433 in epoch 5, gen_loss = 0.9552614458145634, disc_loss = 0.0007855909118283441
Trained batch 434 in epoch 5, gen_loss = 0.9552664744442907, disc_loss = 0.0007846491087840913
Trained batch 435 in epoch 5, gen_loss = 0.9552220246934016, disc_loss = 0.0007835164477067696
Trained batch 436 in epoch 5, gen_loss = 0.9551106801840479, disc_loss = 0.0007822858097414791
Trained batch 437 in epoch 5, gen_loss = 0.9549160965773613, disc_loss = 0.0007809877070570662
Trained batch 438 in epoch 5, gen_loss = 0.9550045113628709, disc_loss = 0.0007798275948769428
Trained batch 439 in epoch 5, gen_loss = 0.9550357234748927, disc_loss = 0.0007797723282816481
Trained batch 440 in epoch 5, gen_loss = 0.9549615984600958, disc_loss = 0.0007803797244850352
Trained batch 441 in epoch 5, gen_loss = 0.9547868547666126, disc_loss = 0.0007808726731049344
Trained batch 442 in epoch 5, gen_loss = 0.9550883652932488, disc_loss = 0.0007817623612542404
Trained batch 443 in epoch 5, gen_loss = 0.9547606415308274, disc_loss = 0.0007845907953729316
Trained batch 444 in epoch 5, gen_loss = 0.9545726727903558, disc_loss = 0.0007912705549080804
Trained batch 445 in epoch 5, gen_loss = 0.9545117936059498, disc_loss = 0.0008029856630590548
Trained batch 446 in epoch 5, gen_loss = 0.9546864839474893, disc_loss = 0.0008165219547883327
Trained batch 447 in epoch 5, gen_loss = 0.9549816113763622, disc_loss = 0.0008295507007330473
Trained batch 448 in epoch 5, gen_loss = 0.95487095664498, disc_loss = 0.0008424339062256328
Trained batch 449 in epoch 5, gen_loss = 0.9548976332611507, disc_loss = 0.0008504721295968112
Trained batch 450 in epoch 5, gen_loss = 0.9550109169964252, disc_loss = 0.0008541563854391734
Trained batch 451 in epoch 5, gen_loss = 0.9551523439915834, disc_loss = 0.0008545491136909272
Trained batch 452 in epoch 5, gen_loss = 0.9552419802737289, disc_loss = 0.000854852393595399
Trained batch 453 in epoch 5, gen_loss = 0.9553714771365279, disc_loss = 0.0008550856837085838
Trained batch 454 in epoch 5, gen_loss = 0.9552972903618446, disc_loss = 0.0008551210330052117
Trained batch 455 in epoch 5, gen_loss = 0.9552190089434908, disc_loss = 0.0008547014229790014
Trained batch 456 in epoch 5, gen_loss = 0.9552795126610303, disc_loss = 0.0008538962088762711
Trained batch 457 in epoch 5, gen_loss = 0.9551304373158117, disc_loss = 0.0008526039083577758
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.8957480788230896, disc_loss = 0.00041700759902596474
Trained batch 1 in epoch 6, gen_loss = 0.9277268350124359, disc_loss = 0.0004741740121971816
Trained batch 2 in epoch 6, gen_loss = 0.9520907203356425, disc_loss = 0.0006382925785146654
Trained batch 3 in epoch 6, gen_loss = 0.9817334562540054, disc_loss = 0.0008434750634478405
Trained batch 4 in epoch 6, gen_loss = 0.9742401599884033, disc_loss = 0.0011306014959700406
Trained batch 5 in epoch 6, gen_loss = 0.9730182985464731, disc_loss = 0.0013705807214137167
Trained batch 6 in epoch 6, gen_loss = 0.9673167637416294, disc_loss = 0.001471502481893237
Trained batch 7 in epoch 6, gen_loss = 0.9627985134720802, disc_loss = 0.0015466719414689578
Trained batch 8 in epoch 6, gen_loss = 0.9625907805230882, disc_loss = 0.001555456036132657
Trained batch 9 in epoch 6, gen_loss = 0.9732926666736603, disc_loss = 0.0015520272369030862
Trained batch 10 in epoch 6, gen_loss = 0.9672895669937134, disc_loss = 0.00158470853718675
Trained batch 11 in epoch 6, gen_loss = 0.9716078142325083, disc_loss = 0.0016303465381497517
Trained batch 12 in epoch 6, gen_loss = 0.9660274890752939, disc_loss = 0.0016216028419036705
Trained batch 13 in epoch 6, gen_loss = 0.9701761177607945, disc_loss = 0.0016099018851361638
Trained batch 14 in epoch 6, gen_loss = 0.968617069721222, disc_loss = 0.0016295899831069013
Trained batch 15 in epoch 6, gen_loss = 0.9629125408828259, disc_loss = 0.0016130883341247682
Trained batch 16 in epoch 6, gen_loss = 0.9608742559657377, disc_loss = 0.0015572104568812339
Trained batch 17 in epoch 6, gen_loss = 0.9557482732666863, disc_loss = 0.0014893698033928457
Trained batch 18 in epoch 6, gen_loss = 0.9519269811479669, disc_loss = 0.0014237327436843004
Trained batch 19 in epoch 6, gen_loss = 0.9529868513345718, disc_loss = 0.0013605487423774321
Trained batch 20 in epoch 6, gen_loss = 0.955057022117433, disc_loss = 0.0013064736884275806
Trained batch 21 in epoch 6, gen_loss = 0.9545906755057249, disc_loss = 0.0012587793469058604
Trained batch 22 in epoch 6, gen_loss = 0.9551652073860168, disc_loss = 0.0012222060044144239
Trained batch 23 in epoch 6, gen_loss = 0.9547410607337952, disc_loss = 0.0011935668887114541
Trained batch 24 in epoch 6, gen_loss = 0.9567839050292969, disc_loss = 0.0011717244103783742
Trained batch 25 in epoch 6, gen_loss = 0.9565676061006693, disc_loss = 0.0011536703952095616
Trained batch 26 in epoch 6, gen_loss = 0.9530488142260799, disc_loss = 0.0011317073006432987
Trained batch 27 in epoch 6, gen_loss = 0.952544948884419, disc_loss = 0.001140632760715172
Trained batch 28 in epoch 6, gen_loss = 0.9502458038001225, disc_loss = 0.0011911080003081788
Trained batch 29 in epoch 6, gen_loss = 0.9469068010648092, disc_loss = 0.001228213289383954
Trained batch 30 in epoch 6, gen_loss = 0.9483878362563348, disc_loss = 0.0012293756181832342
Trained batch 31 in epoch 6, gen_loss = 0.9471995253115892, disc_loss = 0.001201404821131291
Trained batch 32 in epoch 6, gen_loss = 0.9478397531942888, disc_loss = 0.0012095870585074988
Trained batch 33 in epoch 6, gen_loss = 0.951140037354301, disc_loss = 0.001227568522153888
Trained batch 34 in epoch 6, gen_loss = 0.9564394933836801, disc_loss = 0.0012341175382191848
Trained batch 35 in epoch 6, gen_loss = 0.955064434144232, disc_loss = 0.0012504049991548527
Trained batch 36 in epoch 6, gen_loss = 0.9559315104742308, disc_loss = 0.0012755358542120587
Trained batch 37 in epoch 6, gen_loss = 0.956307506874988, disc_loss = 0.0012861666331637504
Trained batch 38 in epoch 6, gen_loss = 0.9537120216932052, disc_loss = 0.0012811897818793138
Trained batch 39 in epoch 6, gen_loss = 0.9544011071324349, disc_loss = 0.0012806982111214893
Trained batch 40 in epoch 6, gen_loss = 0.9534666102106978, disc_loss = 0.0012768359685163355
Trained batch 41 in epoch 6, gen_loss = 0.954013025476819, disc_loss = 0.001265452748200568
Trained batch 42 in epoch 6, gen_loss = 0.9549718499183655, disc_loss = 0.0012480121063268852
Trained batch 43 in epoch 6, gen_loss = 0.9548601386221972, disc_loss = 0.001226201009558281
Trained batch 44 in epoch 6, gen_loss = 0.9543435666296217, disc_loss = 0.0012103966867370117
Trained batch 45 in epoch 6, gen_loss = 0.9564985283043074, disc_loss = 0.0011957505247783442
Trained batch 46 in epoch 6, gen_loss = 0.9584350142073124, disc_loss = 0.001179313302929315
Trained batch 47 in epoch 6, gen_loss = 0.958535066495339, disc_loss = 0.0011643246067857642
Trained batch 48 in epoch 6, gen_loss = 0.9580922321397431, disc_loss = 0.0011486189884765605
Trained batch 49 in epoch 6, gen_loss = 0.9574044275283814, disc_loss = 0.0011369612489943392
Trained batch 50 in epoch 6, gen_loss = 0.9560194623236563, disc_loss = 0.001128353297484436
Trained batch 51 in epoch 6, gen_loss = 0.954803160749949, disc_loss = 0.0011261632588195005
Trained batch 52 in epoch 6, gen_loss = 0.954695667860643, disc_loss = 0.001126479083191129
Trained batch 53 in epoch 6, gen_loss = 0.9544108223032068, disc_loss = 0.001123975783735255
Trained batch 54 in epoch 6, gen_loss = 0.9523933724923568, disc_loss = 0.0011117165730948645
Trained batch 55 in epoch 6, gen_loss = 0.9526723804218429, disc_loss = 0.001098653108523909
Trained batch 56 in epoch 6, gen_loss = 0.9521595521977073, disc_loss = 0.0010946918988146966
Trained batch 57 in epoch 6, gen_loss = 0.9519676411974018, disc_loss = 0.001088367223364285
Trained batch 58 in epoch 6, gen_loss = 0.9523043450662645, disc_loss = 0.0010796220308678793
Trained batch 59 in epoch 6, gen_loss = 0.9522665699323019, disc_loss = 0.0010680277417122852
Trained batch 60 in epoch 6, gen_loss = 0.9516951773987442, disc_loss = 0.0010549902315270614
Trained batch 61 in epoch 6, gen_loss = 0.9515222128360502, disc_loss = 0.0010418407804419047
Trained batch 62 in epoch 6, gen_loss = 0.9503357571268839, disc_loss = 0.00102862228462953
Trained batch 63 in epoch 6, gen_loss = 0.9505847571417689, disc_loss = 0.001016847555320055
Trained batch 64 in epoch 6, gen_loss = 0.9509221856410687, disc_loss = 0.001005703977156932
Trained batch 65 in epoch 6, gen_loss = 0.948905885219574, disc_loss = 0.0009931873785469427
Trained batch 66 in epoch 6, gen_loss = 0.9490784335492263, disc_loss = 0.000995928621216705
Trained batch 67 in epoch 6, gen_loss = 0.9490975641152438, disc_loss = 0.0010128920871733606
Trained batch 68 in epoch 6, gen_loss = 0.9489939255990844, disc_loss = 0.0010221884735654094
Trained batch 69 in epoch 6, gen_loss = 0.948500199828829, disc_loss = 0.0010198433956247754
Trained batch 70 in epoch 6, gen_loss = 0.9483432912490737, disc_loss = 0.0010119608993245236
Trained batch 71 in epoch 6, gen_loss = 0.9487482673592038, disc_loss = 0.0010038170009162666
Trained batch 72 in epoch 6, gen_loss = 0.9489169218768813, disc_loss = 0.0009973136353711534
Trained batch 73 in epoch 6, gen_loss = 0.9484444800260905, disc_loss = 0.0009938869505374994
Trained batch 74 in epoch 6, gen_loss = 0.9487860337893168, disc_loss = 0.0009926493145758287
Trained batch 75 in epoch 6, gen_loss = 0.9493612505887684, disc_loss = 0.000990406497294316
Trained batch 76 in epoch 6, gen_loss = 0.9505511181695121, disc_loss = 0.0009865518763295508
Trained batch 77 in epoch 6, gen_loss = 0.9501094504808768, disc_loss = 0.0009793543974340607
Trained batch 78 in epoch 6, gen_loss = 0.9499331863620614, disc_loss = 0.0009719040788212037
Trained batch 79 in epoch 6, gen_loss = 0.9495942436158658, disc_loss = 0.0009636573950047023
Trained batch 80 in epoch 6, gen_loss = 0.9491579149976189, disc_loss = 0.0009545779628549806
Trained batch 81 in epoch 6, gen_loss = 0.9493950111110036, disc_loss = 0.0009452636932553837
Trained batch 82 in epoch 6, gen_loss = 0.9502709859825043, disc_loss = 0.0009365735702842182
Trained batch 83 in epoch 6, gen_loss = 0.9493331951754433, disc_loss = 0.0009281314333271613
Trained batch 84 in epoch 6, gen_loss = 0.9500189767164342, disc_loss = 0.0009265498506412019
Trained batch 85 in epoch 6, gen_loss = 0.9501601824926775, disc_loss = 0.0009336326202596971
Trained batch 86 in epoch 6, gen_loss = 0.9502795139948527, disc_loss = 0.0009397543759698091
Trained batch 87 in epoch 6, gen_loss = 0.9498950764536858, disc_loss = 0.0009400167772665471
Trained batch 88 in epoch 6, gen_loss = 0.9508197970604628, disc_loss = 0.0009359710889389696
Trained batch 89 in epoch 6, gen_loss = 0.9516562163829804, disc_loss = 0.000928900697585454
Trained batch 90 in epoch 6, gen_loss = 0.9516237895567339, disc_loss = 0.0009204828731106737
Trained batch 91 in epoch 6, gen_loss = 0.9516378602255946, disc_loss = 0.000912204422607117
Trained batch 92 in epoch 6, gen_loss = 0.9520763158798218, disc_loss = 0.0009040469267738542
Trained batch 93 in epoch 6, gen_loss = 0.9509519034243644, disc_loss = 0.0008967990257549397
Trained batch 94 in epoch 6, gen_loss = 0.950934450249923, disc_loss = 0.0008924806214820005
Trained batch 95 in epoch 6, gen_loss = 0.9513896803061167, disc_loss = 0.0008893707060148396
Trained batch 96 in epoch 6, gen_loss = 0.9512769069868264, disc_loss = 0.0008848418890301752
Trained batch 97 in epoch 6, gen_loss = 0.9514287843996164, disc_loss = 0.0008793819950518141
Trained batch 98 in epoch 6, gen_loss = 0.9521065035251656, disc_loss = 0.0008740991373391201
Trained batch 99 in epoch 6, gen_loss = 0.9525601422786713, disc_loss = 0.000868335941049736
Trained batch 100 in epoch 6, gen_loss = 0.9517925446576411, disc_loss = 0.0008619035534228724
Trained batch 101 in epoch 6, gen_loss = 0.952254920613532, disc_loss = 0.000855295039204351
Trained batch 102 in epoch 6, gen_loss = 0.9523219558799151, disc_loss = 0.0008493716556135818
Trained batch 103 in epoch 6, gen_loss = 0.9525878744629713, disc_loss = 0.0008434754070969155
Trained batch 104 in epoch 6, gen_loss = 0.9529222749528431, disc_loss = 0.0008373364207467862
Trained batch 105 in epoch 6, gen_loss = 0.95299531378836, disc_loss = 0.0008308814123562836
Trained batch 106 in epoch 6, gen_loss = 0.9526497972345798, disc_loss = 0.000824383048723652
Trained batch 107 in epoch 6, gen_loss = 0.9528798129823473, disc_loss = 0.0008185088888610524
Trained batch 108 in epoch 6, gen_loss = 0.9521527891859002, disc_loss = 0.0008131705981213599
Trained batch 109 in epoch 6, gen_loss = 0.9515391420234334, disc_loss = 0.0008097660076931458
Trained batch 110 in epoch 6, gen_loss = 0.9518677887615857, disc_loss = 0.0008065537649190037
Trained batch 111 in epoch 6, gen_loss = 0.9523582458496094, disc_loss = 0.0008028433307377522
Trained batch 112 in epoch 6, gen_loss = 0.9523455980604729, disc_loss = 0.000798293268586204
Trained batch 113 in epoch 6, gen_loss = 0.9524162761997759, disc_loss = 0.0007938927081883314
Trained batch 114 in epoch 6, gen_loss = 0.9527312708937603, disc_loss = 0.0007896390581584495
Trained batch 115 in epoch 6, gen_loss = 0.9531974561255554, disc_loss = 0.0007851322624101786
Trained batch 116 in epoch 6, gen_loss = 0.9532523955035413, disc_loss = 0.0007820594441404359
Trained batch 117 in epoch 6, gen_loss = 0.9534965384814699, disc_loss = 0.000780779797577899
Trained batch 118 in epoch 6, gen_loss = 0.9534828913311998, disc_loss = 0.000778441086260821
Trained batch 119 in epoch 6, gen_loss = 0.9532670274376869, disc_loss = 0.0007737410116533284
Trained batch 120 in epoch 6, gen_loss = 0.9525974432298959, disc_loss = 0.0007684851557878423
Trained batch 121 in epoch 6, gen_loss = 0.9522925405228724, disc_loss = 0.0007636852366334499
Trained batch 122 in epoch 6, gen_loss = 0.9530571810598296, disc_loss = 0.0007597468085908823
Trained batch 123 in epoch 6, gen_loss = 0.9531296631020885, disc_loss = 0.000756840318283667
Trained batch 124 in epoch 6, gen_loss = 0.9526693534851074, disc_loss = 0.0007539467099122703
Trained batch 125 in epoch 6, gen_loss = 0.9523803733644032, disc_loss = 0.000751117101846455
Trained batch 126 in epoch 6, gen_loss = 0.9528886314452164, disc_loss = 0.000749219792178194
Trained batch 127 in epoch 6, gen_loss = 0.9528759345412254, disc_loss = 0.0007466597121492669
Trained batch 128 in epoch 6, gen_loss = 0.9523762288943741, disc_loss = 0.0007446749783806907
Trained batch 129 in epoch 6, gen_loss = 0.9518111274792598, disc_loss = 0.0007435534212093513
Trained batch 130 in epoch 6, gen_loss = 0.9520107434906122, disc_loss = 0.000743334464647075
Trained batch 131 in epoch 6, gen_loss = 0.9520066556605425, disc_loss = 0.0007438331575196406
Trained batch 132 in epoch 6, gen_loss = 0.9515930463496903, disc_loss = 0.0007434684307930669
Trained batch 133 in epoch 6, gen_loss = 0.9517413239870498, disc_loss = 0.0007415352829683349
Trained batch 134 in epoch 6, gen_loss = 0.9520834768259967, disc_loss = 0.0007402669039071986
Trained batch 135 in epoch 6, gen_loss = 0.9521195476546007, disc_loss = 0.0007398483571973082
Trained batch 136 in epoch 6, gen_loss = 0.9522037875913355, disc_loss = 0.0007391036016506272
Trained batch 137 in epoch 6, gen_loss = 0.9523373950218809, disc_loss = 0.0007392147048106552
Trained batch 138 in epoch 6, gen_loss = 0.9522940177711652, disc_loss = 0.0007408367362704209
Trained batch 139 in epoch 6, gen_loss = 0.9521674045494625, disc_loss = 0.0007433113625406154
Trained batch 140 in epoch 6, gen_loss = 0.9519881196055852, disc_loss = 0.0007459360987265059
Trained batch 141 in epoch 6, gen_loss = 0.9511944215062639, disc_loss = 0.0007469792211670953
Trained batch 142 in epoch 6, gen_loss = 0.9509461013587205, disc_loss = 0.0007479685835761729
Trained batch 143 in epoch 6, gen_loss = 0.9508367805845208, disc_loss = 0.0007524219076407866
Trained batch 144 in epoch 6, gen_loss = 0.9502173464873741, disc_loss = 0.0007535064954246426
Trained batch 145 in epoch 6, gen_loss = 0.950144988216766, disc_loss = 0.0007511008463477818
Trained batch 146 in epoch 6, gen_loss = 0.9503429260383658, disc_loss = 0.000747479146170639
Trained batch 147 in epoch 6, gen_loss = 0.9499053721492355, disc_loss = 0.0007439915011550387
Trained batch 148 in epoch 6, gen_loss = 0.949931136713732, disc_loss = 0.0007416001563437045
Trained batch 149 in epoch 6, gen_loss = 0.9506570466359456, disc_loss = 0.0007396756051457487
Trained batch 150 in epoch 6, gen_loss = 0.9505340966167829, disc_loss = 0.0007388516798937718
Trained batch 151 in epoch 6, gen_loss = 0.9508505832207831, disc_loss = 0.0007391852162216214
Trained batch 152 in epoch 6, gen_loss = 0.9513149012147991, disc_loss = 0.0007389911057258609
Trained batch 153 in epoch 6, gen_loss = 0.9512136435353911, disc_loss = 0.0007375032111266084
Trained batch 154 in epoch 6, gen_loss = 0.9511201304774131, disc_loss = 0.0007356504046906446
Trained batch 155 in epoch 6, gen_loss = 0.9511552735781058, disc_loss = 0.0007331424379886952
Trained batch 156 in epoch 6, gen_loss = 0.9512397813948856, disc_loss = 0.0007298554798586674
Trained batch 157 in epoch 6, gen_loss = 0.9511547982692719, disc_loss = 0.0007265131264634701
Trained batch 158 in epoch 6, gen_loss = 0.9506112528297136, disc_loss = 0.0007236106845633707
Trained batch 159 in epoch 6, gen_loss = 0.9501673981547356, disc_loss = 0.0007213616719127458
Trained batch 160 in epoch 6, gen_loss = 0.9502842689152831, disc_loss = 0.000720376908502206
Trained batch 161 in epoch 6, gen_loss = 0.950036018350978, disc_loss = 0.0007229901094422215
Trained batch 162 in epoch 6, gen_loss = 0.9498713298077963, disc_loss = 0.0007286810433453498
Trained batch 163 in epoch 6, gen_loss = 0.9500439061624247, disc_loss = 0.0007310883940102407
Trained batch 164 in epoch 6, gen_loss = 0.9497395876682166, disc_loss = 0.0007299679307669232
Trained batch 165 in epoch 6, gen_loss = 0.949391406702708, disc_loss = 0.0007276727726959331
Trained batch 166 in epoch 6, gen_loss = 0.9499230070742305, disc_loss = 0.0007249633036588715
Trained batch 167 in epoch 6, gen_loss = 0.950054787454151, disc_loss = 0.0007226518933055645
Trained batch 168 in epoch 6, gen_loss = 0.9499934255724123, disc_loss = 0.000720588717945113
Trained batch 169 in epoch 6, gen_loss = 0.9507119487313663, disc_loss = 0.0007196475627578741
Trained batch 170 in epoch 6, gen_loss = 0.9505820364979972, disc_loss = 0.0007218104753641913
Trained batch 171 in epoch 6, gen_loss = 0.9509239619554475, disc_loss = 0.0007265570713444017
Trained batch 172 in epoch 6, gen_loss = 0.9510617462885862, disc_loss = 0.0007291784094655994
Trained batch 173 in epoch 6, gen_loss = 0.9510543921898151, disc_loss = 0.0007291417665098494
Trained batch 174 in epoch 6, gen_loss = 0.9509760386603219, disc_loss = 0.000728130037147951
Trained batch 175 in epoch 6, gen_loss = 0.9509213803844019, disc_loss = 0.0007264135293470728
Trained batch 176 in epoch 6, gen_loss = 0.9515465410415735, disc_loss = 0.0007243728212384759
Trained batch 177 in epoch 6, gen_loss = 0.951778564895137, disc_loss = 0.0007219977826148198
Trained batch 178 in epoch 6, gen_loss = 0.9516688052502424, disc_loss = 0.0007194228654541335
Trained batch 179 in epoch 6, gen_loss = 0.9515176130665673, disc_loss = 0.0007164560131463481
Trained batch 180 in epoch 6, gen_loss = 0.951837645709844, disc_loss = 0.0007140704321138592
Trained batch 181 in epoch 6, gen_loss = 0.9523711905374632, disc_loss = 0.0007126217292702327
Trained batch 182 in epoch 6, gen_loss = 0.9523361781255795, disc_loss = 0.0007104081119368707
Trained batch 183 in epoch 6, gen_loss = 0.9526121781572051, disc_loss = 0.0007082903320343062
Trained batch 184 in epoch 6, gen_loss = 0.952971750014537, disc_loss = 0.0007068564807775909
Trained batch 185 in epoch 6, gen_loss = 0.9532185084717248, disc_loss = 0.0007066121832649124
Trained batch 186 in epoch 6, gen_loss = 0.9531258315963541, disc_loss = 0.0007062825906734146
Trained batch 187 in epoch 6, gen_loss = 0.953260525426966, disc_loss = 0.0007051288908343773
Trained batch 188 in epoch 6, gen_loss = 0.9535152871141989, disc_loss = 0.0007037122635492345
Trained batch 189 in epoch 6, gen_loss = 0.9536704248503635, disc_loss = 0.0007022871961357611
Trained batch 190 in epoch 6, gen_loss = 0.9539112423727025, disc_loss = 0.0007008655114539446
Trained batch 191 in epoch 6, gen_loss = 0.9538404969498515, disc_loss = 0.0006992192128715639
Trained batch 192 in epoch 6, gen_loss = 0.9540717722220742, disc_loss = 0.0006980079203123864
Trained batch 193 in epoch 6, gen_loss = 0.9534956053974702, disc_loss = 0.0007000822304914821
Trained batch 194 in epoch 6, gen_loss = 0.9532007238803766, disc_loss = 0.000708910732347972
Trained batch 195 in epoch 6, gen_loss = 0.9526819164047435, disc_loss = 0.0007205409313669684
Trained batch 196 in epoch 6, gen_loss = 0.9528320225967368, disc_loss = 0.0007324166725795045
Trained batch 197 in epoch 6, gen_loss = 0.9527215147861327, disc_loss = 0.0007367637686783006
Trained batch 198 in epoch 6, gen_loss = 0.9526425177727512, disc_loss = 0.0007357756611183239
Trained batch 199 in epoch 6, gen_loss = 0.9521110305190086, disc_loss = 0.0007354864718945464
Trained batch 200 in epoch 6, gen_loss = 0.9520874797408261, disc_loss = 0.0007395113852953501
Trained batch 201 in epoch 6, gen_loss = 0.9520210806686099, disc_loss = 0.0007441676440642971
Trained batch 202 in epoch 6, gen_loss = 0.9518002301014116, disc_loss = 0.0007483221448153908
Trained batch 203 in epoch 6, gen_loss = 0.9515098196034338, disc_loss = 0.0007514382912132514
Trained batch 204 in epoch 6, gen_loss = 0.9516451989732138, disc_loss = 0.00075433194465515
Trained batch 205 in epoch 6, gen_loss = 0.9516050763500546, disc_loss = 0.0007592662362900599
Trained batch 206 in epoch 6, gen_loss = 0.9517251258886955, disc_loss = 0.0007631917590818679
Trained batch 207 in epoch 6, gen_loss = 0.9516073353588581, disc_loss = 0.0007646314353013833
Trained batch 208 in epoch 6, gen_loss = 0.9515270801822534, disc_loss = 0.0007644041836719612
Trained batch 209 in epoch 6, gen_loss = 0.9516339651175908, disc_loss = 0.0007629673281501579
Trained batch 210 in epoch 6, gen_loss = 0.9516125363761215, disc_loss = 0.0007608916523719595
Trained batch 211 in epoch 6, gen_loss = 0.9516360084965544, disc_loss = 0.0007587593846557935
Trained batch 212 in epoch 6, gen_loss = 0.9518916092008493, disc_loss = 0.0007567439498702292
Trained batch 213 in epoch 6, gen_loss = 0.9518049420597398, disc_loss = 0.0007547770607667087
Trained batch 214 in epoch 6, gen_loss = 0.9515926333360893, disc_loss = 0.0007525563512815076
Trained batch 215 in epoch 6, gen_loss = 0.9513955668166831, disc_loss = 0.0007501925218228415
Trained batch 216 in epoch 6, gen_loss = 0.9510850521825975, disc_loss = 0.0007475732298876901
Trained batch 217 in epoch 6, gen_loss = 0.9512387995326191, disc_loss = 0.0007452000660256807
Trained batch 218 in epoch 6, gen_loss = 0.9511631727218628, disc_loss = 0.0007437070224728631
Trained batch 219 in epoch 6, gen_loss = 0.9515695837411013, disc_loss = 0.0007431998407727489
Trained batch 220 in epoch 6, gen_loss = 0.9513882493001843, disc_loss = 0.0007448250439562687
Trained batch 221 in epoch 6, gen_loss = 0.9513838414673332, disc_loss = 0.0007474694319351509
Trained batch 222 in epoch 6, gen_loss = 0.9516605630583828, disc_loss = 0.0007486205949106633
Trained batch 223 in epoch 6, gen_loss = 0.9516275530414922, disc_loss = 0.0007478329138003963
Trained batch 224 in epoch 6, gen_loss = 0.9514113505681355, disc_loss = 0.000745772964696193
Trained batch 225 in epoch 6, gen_loss = 0.9508594385290567, disc_loss = 0.000743265299150201
Trained batch 226 in epoch 6, gen_loss = 0.9506404355233986, disc_loss = 0.0007407055112034788
Trained batch 227 in epoch 6, gen_loss = 0.9505227215980229, disc_loss = 0.0007385460113781798
Trained batch 228 in epoch 6, gen_loss = 0.95052558860404, disc_loss = 0.0007367341884149556
Trained batch 229 in epoch 6, gen_loss = 0.9508839853431867, disc_loss = 0.0007347145918807339
Trained batch 230 in epoch 6, gen_loss = 0.9508923815958428, disc_loss = 0.0007332402612314483
Trained batch 231 in epoch 6, gen_loss = 0.9507385017029171, disc_loss = 0.0007327710066827672
Trained batch 232 in epoch 6, gen_loss = 0.9506775112622797, disc_loss = 0.0007317813125572891
Trained batch 233 in epoch 6, gen_loss = 0.9506936121700157, disc_loss = 0.0007303193063300071
Trained batch 234 in epoch 6, gen_loss = 0.9503665454844211, disc_loss = 0.000728506791811595
Trained batch 235 in epoch 6, gen_loss = 0.9503141462297763, disc_loss = 0.0007268681979671089
Trained batch 236 in epoch 6, gen_loss = 0.950055356015636, disc_loss = 0.0007251844862240214
Trained batch 237 in epoch 6, gen_loss = 0.9499398757930563, disc_loss = 0.0007236144327394226
Trained batch 238 in epoch 6, gen_loss = 0.9501588007895019, disc_loss = 0.0007219726373694806
Trained batch 239 in epoch 6, gen_loss = 0.9500383630394935, disc_loss = 0.0007216438182998294
Trained batch 240 in epoch 6, gen_loss = 0.9504131632721771, disc_loss = 0.0007228750145715889
Trained batch 241 in epoch 6, gen_loss = 0.9507657087538853, disc_loss = 0.0007253915486637934
Trained batch 242 in epoch 6, gen_loss = 0.9512846872149181, disc_loss = 0.0007294596744406156
Trained batch 243 in epoch 6, gen_loss = 0.9510498554980169, disc_loss = 0.0007386470557530181
Trained batch 244 in epoch 6, gen_loss = 0.9511584148115041, disc_loss = 0.000752189264357166
Trained batch 245 in epoch 6, gen_loss = 0.9510008540095353, disc_loss = 0.000762523931112307
Trained batch 246 in epoch 6, gen_loss = 0.9507538847595092, disc_loss = 0.0007673085208601405
Trained batch 247 in epoch 6, gen_loss = 0.9506095929011222, disc_loss = 0.0007688898324211609
Trained batch 248 in epoch 6, gen_loss = 0.9505517923209562, disc_loss = 0.0007687219650948413
Trained batch 249 in epoch 6, gen_loss = 0.9507024383544922, disc_loss = 0.0007679752090480179
Trained batch 250 in epoch 6, gen_loss = 0.9506257057664879, disc_loss = 0.0007681151589033643
Trained batch 251 in epoch 6, gen_loss = 0.950758750240008, disc_loss = 0.0007684100747278463
Trained batch 252 in epoch 6, gen_loss = 0.9509033631430313, disc_loss = 0.0007674309582423728
Trained batch 253 in epoch 6, gen_loss = 0.9510310120939269, disc_loss = 0.000765363956773177
Trained batch 254 in epoch 6, gen_loss = 0.9511146559434779, disc_loss = 0.0007632514467010932
Trained batch 255 in epoch 6, gen_loss = 0.950930789578706, disc_loss = 0.0007607451858575587
Trained batch 256 in epoch 6, gen_loss = 0.950901699205317, disc_loss = 0.0007581853277264217
Trained batch 257 in epoch 6, gen_loss = 0.9509580278581427, disc_loss = 0.0007556391616910064
Trained batch 258 in epoch 6, gen_loss = 0.9508953800993076, disc_loss = 0.0007534631321255682
Trained batch 259 in epoch 6, gen_loss = 0.9509722844912456, disc_loss = 0.0007520371264735542
Trained batch 260 in epoch 6, gen_loss = 0.951103724739104, disc_loss = 0.0007503802408439721
Trained batch 261 in epoch 6, gen_loss = 0.9510045474722185, disc_loss = 0.0007484017313737512
Trained batch 262 in epoch 6, gen_loss = 0.9511898402478758, disc_loss = 0.0007467758087381568
Trained batch 263 in epoch 6, gen_loss = 0.9509103438167861, disc_loss = 0.000745561649912843
Trained batch 264 in epoch 6, gen_loss = 0.9506891493527394, disc_loss = 0.0007449275238784294
Trained batch 265 in epoch 6, gen_loss = 0.9508775338194424, disc_loss = 0.0007441906228977084
Trained batch 266 in epoch 6, gen_loss = 0.9506046926037649, disc_loss = 0.0007429431522692804
Trained batch 267 in epoch 6, gen_loss = 0.9508423246999285, disc_loss = 0.0007415905751693219
Trained batch 268 in epoch 6, gen_loss = 0.9508669433983729, disc_loss = 0.0007399013043360934
Trained batch 269 in epoch 6, gen_loss = 0.9509288145436181, disc_loss = 0.0007383207564459924
Trained batch 270 in epoch 6, gen_loss = 0.9511200438126427, disc_loss = 0.0007363853295949268
Trained batch 271 in epoch 6, gen_loss = 0.9510716114412335, disc_loss = 0.000734281683462006
Trained batch 272 in epoch 6, gen_loss = 0.9508947009568686, disc_loss = 0.0007321831837990287
Trained batch 273 in epoch 6, gen_loss = 0.9510235275230269, disc_loss = 0.0007300124069292142
Trained batch 274 in epoch 6, gen_loss = 0.9507103341275995, disc_loss = 0.0007280162920572118
Trained batch 275 in epoch 6, gen_loss = 0.9508790982806165, disc_loss = 0.000727331743252327
Trained batch 276 in epoch 6, gen_loss = 0.9508658341982735, disc_loss = 0.0007272817716176877
Trained batch 277 in epoch 6, gen_loss = 0.9503084451174565, disc_loss = 0.0007269054951668439
Trained batch 278 in epoch 6, gen_loss = 0.9501511886128388, disc_loss = 0.0007271515653795382
Trained batch 279 in epoch 6, gen_loss = 0.9502955477152552, disc_loss = 0.0007285269012364941
Trained batch 280 in epoch 6, gen_loss = 0.9504135187410375, disc_loss = 0.0007307530254996846
Trained batch 281 in epoch 6, gen_loss = 0.9505719447389562, disc_loss = 0.0007329068837036355
Trained batch 282 in epoch 6, gen_loss = 0.9506950730148558, disc_loss = 0.0007335662244242787
Trained batch 283 in epoch 6, gen_loss = 0.9505935365885076, disc_loss = 0.0007324975693233977
Trained batch 284 in epoch 6, gen_loss = 0.9506039330833836, disc_loss = 0.0007312342983807372
Trained batch 285 in epoch 6, gen_loss = 0.950849720231303, disc_loss = 0.0007298109176317539
Trained batch 286 in epoch 6, gen_loss = 0.9508739070194524, disc_loss = 0.0007281170276272311
Trained batch 287 in epoch 6, gen_loss = 0.9509640812045999, disc_loss = 0.0007264043498101577
Trained batch 288 in epoch 6, gen_loss = 0.9509644735230707, disc_loss = 0.0007245673537550407
Trained batch 289 in epoch 6, gen_loss = 0.9510264450106127, disc_loss = 0.0007227888474078319
Trained batch 290 in epoch 6, gen_loss = 0.9507617630909398, disc_loss = 0.0007215098635070714
Trained batch 291 in epoch 6, gen_loss = 0.9506477556408268, disc_loss = 0.0007209888313709972
Trained batch 292 in epoch 6, gen_loss = 0.9507300082734014, disc_loss = 0.0007202516385358472
Trained batch 293 in epoch 6, gen_loss = 0.9507904693382938, disc_loss = 0.0007188270890047428
Trained batch 294 in epoch 6, gen_loss = 0.9507154654648344, disc_loss = 0.0007173437159261824
Trained batch 295 in epoch 6, gen_loss = 0.9507005744286485, disc_loss = 0.0007164775274882355
Trained batch 296 in epoch 6, gen_loss = 0.950550585082083, disc_loss = 0.0007161579909097475
Trained batch 297 in epoch 6, gen_loss = 0.9503845212443564, disc_loss = 0.0007157552328447877
Trained batch 298 in epoch 6, gen_loss = 0.9503192445107527, disc_loss = 0.0007149181919307511
Trained batch 299 in epoch 6, gen_loss = 0.9505364801486333, disc_loss = 0.000713720549417
Trained batch 300 in epoch 6, gen_loss = 0.950300361428942, disc_loss = 0.0007129159787284176
Trained batch 301 in epoch 6, gen_loss = 0.9500905301002477, disc_loss = 0.0007134859045358014
Trained batch 302 in epoch 6, gen_loss = 0.9500656688567435, disc_loss = 0.0007145333230576521
Trained batch 303 in epoch 6, gen_loss = 0.94993308755128, disc_loss = 0.0007161760931682549
Trained batch 304 in epoch 6, gen_loss = 0.950152660393324, disc_loss = 0.000716459067403835
Trained batch 305 in epoch 6, gen_loss = 0.9502108995041816, disc_loss = 0.0007158412217964142
Trained batch 306 in epoch 6, gen_loss = 0.9504090479608468, disc_loss = 0.0007157352257317845
Trained batch 307 in epoch 6, gen_loss = 0.9506107748715908, disc_loss = 0.0007160424205273097
Trained batch 308 in epoch 6, gen_loss = 0.9505575260683943, disc_loss = 0.0007163172358265343
Trained batch 309 in epoch 6, gen_loss = 0.9504612057439743, disc_loss = 0.0007170724578064702
Trained batch 310 in epoch 6, gen_loss = 0.9504317470685462, disc_loss = 0.0007174842056945203
Trained batch 311 in epoch 6, gen_loss = 0.9504293402036031, disc_loss = 0.0007174288888657033
Trained batch 312 in epoch 6, gen_loss = 0.9502119629527814, disc_loss = 0.0007164424180732698
Trained batch 313 in epoch 6, gen_loss = 0.9498470569871793, disc_loss = 0.0007148833227669005
Trained batch 314 in epoch 6, gen_loss = 0.9497398732200502, disc_loss = 0.0007132606128358194
Trained batch 315 in epoch 6, gen_loss = 0.9499375608902944, disc_loss = 0.0007116548084796486
Trained batch 316 in epoch 6, gen_loss = 0.9499569916950792, disc_loss = 0.0007104089795360238
Trained batch 317 in epoch 6, gen_loss = 0.9500706870600862, disc_loss = 0.000711010721670105
Trained batch 318 in epoch 6, gen_loss = 0.94984170616981, disc_loss = 0.0007145694944141564
Trained batch 319 in epoch 6, gen_loss = 0.9499208718538285, disc_loss = 0.0007189842540128666
Trained batch 320 in epoch 6, gen_loss = 0.9500716438174619, disc_loss = 0.0007222785933893043
Trained batch 321 in epoch 6, gen_loss = 0.950338383639081, disc_loss = 0.0007250176246958764
Trained batch 322 in epoch 6, gen_loss = 0.950177182723125, disc_loss = 0.0007279758101165938
Trained batch 323 in epoch 6, gen_loss = 0.9503840925516905, disc_loss = 0.0007309045477647745
Trained batch 324 in epoch 6, gen_loss = 0.9504863606966459, disc_loss = 0.0007329301896746844
Trained batch 325 in epoch 6, gen_loss = 0.9502522150066002, disc_loss = 0.0007338212906164074
Trained batch 326 in epoch 6, gen_loss = 0.9502101314541761, disc_loss = 0.0007334057043336078
Trained batch 327 in epoch 6, gen_loss = 0.9503169005236974, disc_loss = 0.0007321630761752447
Trained batch 328 in epoch 6, gen_loss = 0.9502158367887457, disc_loss = 0.0007307356314181271
Trained batch 329 in epoch 6, gen_loss = 0.9505156480904782, disc_loss = 0.0007296148044450533
Trained batch 330 in epoch 6, gen_loss = 0.9506149796200662, disc_loss = 0.0007288514524921592
Trained batch 331 in epoch 6, gen_loss = 0.9506580571094191, disc_loss = 0.0007279529783049674
Trained batch 332 in epoch 6, gen_loss = 0.9506649552164851, disc_loss = 0.0007265809318042002
Trained batch 333 in epoch 6, gen_loss = 0.9507830271463908, disc_loss = 0.0007254925190635279
Trained batch 334 in epoch 6, gen_loss = 0.9505071515467629, disc_loss = 0.0007246673222476575
Trained batch 335 in epoch 6, gen_loss = 0.9505240856891587, disc_loss = 0.000724404438642523
Trained batch 336 in epoch 6, gen_loss = 0.9503899851609409, disc_loss = 0.0007245283657766102
Trained batch 337 in epoch 6, gen_loss = 0.9503605968853426, disc_loss = 0.0007244815687900726
Trained batch 338 in epoch 6, gen_loss = 0.9504175680225226, disc_loss = 0.0007238700834766049
Trained batch 339 in epoch 6, gen_loss = 0.9505851642173879, disc_loss = 0.0007227719493290779
Trained batch 340 in epoch 6, gen_loss = 0.9505855493531549, disc_loss = 0.000721534295788525
Trained batch 341 in epoch 6, gen_loss = 0.9506454835509697, disc_loss = 0.0007204946658935886
Trained batch 342 in epoch 6, gen_loss = 0.9506516548704476, disc_loss = 0.000719685372267748
Trained batch 343 in epoch 6, gen_loss = 0.950659028146156, disc_loss = 0.0007188018713392477
Trained batch 344 in epoch 6, gen_loss = 0.9506153953248176, disc_loss = 0.0007176060330559689
Trained batch 345 in epoch 6, gen_loss = 0.950415477931844, disc_loss = 0.0007159262163572302
Trained batch 346 in epoch 6, gen_loss = 0.9505214028124851, disc_loss = 0.000714604470469373
Trained batch 347 in epoch 6, gen_loss = 0.9504062471718624, disc_loss = 0.0007140198994075663
Trained batch 348 in epoch 6, gen_loss = 0.9504290197503601, disc_loss = 0.0007135266776323081
Trained batch 349 in epoch 6, gen_loss = 0.9503668139662061, disc_loss = 0.0007122415867758848
Trained batch 350 in epoch 6, gen_loss = 0.9501764331108484, disc_loss = 0.0007106154276967842
Trained batch 351 in epoch 6, gen_loss = 0.9502849814228036, disc_loss = 0.0007091862121135571
Trained batch 352 in epoch 6, gen_loss = 0.9503251810587162, disc_loss = 0.0007076924478576819
Trained batch 353 in epoch 6, gen_loss = 0.9504733738926171, disc_loss = 0.0007060926451683532
Trained batch 354 in epoch 6, gen_loss = 0.9505713241201051, disc_loss = 0.0007045953170335721
Trained batch 355 in epoch 6, gen_loss = 0.9507491183414888, disc_loss = 0.0007033197307464434
Trained batch 356 in epoch 6, gen_loss = 0.9506954969812174, disc_loss = 0.0007022059296871827
Trained batch 357 in epoch 6, gen_loss = 0.9504548502700955, disc_loss = 0.0007014192812762278
Trained batch 358 in epoch 6, gen_loss = 0.9504627980561642, disc_loss = 0.0007007314895841029
Trained batch 359 in epoch 6, gen_loss = 0.9502866706914372, disc_loss = 0.0006996141803837317
Trained batch 360 in epoch 6, gen_loss = 0.9504136869121457, disc_loss = 0.0006985169603968867
Trained batch 361 in epoch 6, gen_loss = 0.9505332118898465, disc_loss = 0.0006981749177094516
Trained batch 362 in epoch 6, gen_loss = 0.9504969067481596, disc_loss = 0.0006981063597075854
Trained batch 363 in epoch 6, gen_loss = 0.9504325011601815, disc_loss = 0.0006982194629597291
Trained batch 364 in epoch 6, gen_loss = 0.9502534041666004, disc_loss = 0.000697589441252815
Trained batch 365 in epoch 6, gen_loss = 0.9502492418380383, disc_loss = 0.0006962135955435288
Trained batch 366 in epoch 6, gen_loss = 0.9505794313038403, disc_loss = 0.0006948122622456962
Trained batch 367 in epoch 6, gen_loss = 0.9504918909591177, disc_loss = 0.0006933643574721709
Trained batch 368 in epoch 6, gen_loss = 0.9505198951659164, disc_loss = 0.0006920311591569978
Trained batch 369 in epoch 6, gen_loss = 0.9505806131942852, disc_loss = 0.0006907360934820719
Trained batch 370 in epoch 6, gen_loss = 0.9506416614807519, disc_loss = 0.0006896454316362766
Trained batch 371 in epoch 6, gen_loss = 0.950723637976954, disc_loss = 0.0006885560271785512
Trained batch 372 in epoch 6, gen_loss = 0.9505649125927574, disc_loss = 0.0006871964240700428
Trained batch 373 in epoch 6, gen_loss = 0.9506968610426959, disc_loss = 0.0006857410932271331
Trained batch 374 in epoch 6, gen_loss = 0.9508853747049968, disc_loss = 0.0006843295744814289
Trained batch 375 in epoch 6, gen_loss = 0.950773150045821, disc_loss = 0.0006828469252642652
Trained batch 376 in epoch 6, gen_loss = 0.950865728785568, disc_loss = 0.0006814188092049342
Trained batch 377 in epoch 6, gen_loss = 0.9509232473121119, disc_loss = 0.0006800143589398383
Trained batch 378 in epoch 6, gen_loss = 0.9507768487552855, disc_loss = 0.0006787320073516757
Trained batch 379 in epoch 6, gen_loss = 0.950720573099036, disc_loss = 0.0006777397225002794
Trained batch 380 in epoch 6, gen_loss = 0.9506680865300297, disc_loss = 0.0006767252934758986
Trained batch 381 in epoch 6, gen_loss = 0.9508222653603678, disc_loss = 0.0006754016144655545
Trained batch 382 in epoch 6, gen_loss = 0.9509245964939227, disc_loss = 0.0006740156192171106
Trained batch 383 in epoch 6, gen_loss = 0.9508145290116469, disc_loss = 0.0006725569965813823
Trained batch 384 in epoch 6, gen_loss = 0.9504495634661092, disc_loss = 0.0006712649964391822
Trained batch 385 in epoch 6, gen_loss = 0.9502905568619466, disc_loss = 0.000670646903866002
Trained batch 386 in epoch 6, gen_loss = 0.9504543957168126, disc_loss = 0.00067038269371645
Trained batch 387 in epoch 6, gen_loss = 0.9503318841002651, disc_loss = 0.0006696319319088775
Trained batch 388 in epoch 6, gen_loss = 0.9501674729938066, disc_loss = 0.0006686485285920409
Trained batch 389 in epoch 6, gen_loss = 0.9500827064880958, disc_loss = 0.0006679100334086121
Trained batch 390 in epoch 6, gen_loss = 0.9499629013373724, disc_loss = 0.0006668221344590745
Trained batch 391 in epoch 6, gen_loss = 0.949998144896663, disc_loss = 0.0006657304138385296
Trained batch 392 in epoch 6, gen_loss = 0.9500047975520748, disc_loss = 0.0006651985585294384
Trained batch 393 in epoch 6, gen_loss = 0.9498183896698927, disc_loss = 0.0006647288173553534
Trained batch 394 in epoch 6, gen_loss = 0.9500293804120414, disc_loss = 0.0006638650126280734
Trained batch 395 in epoch 6, gen_loss = 0.9503514902158217, disc_loss = 0.0006631713716188008
Trained batch 396 in epoch 6, gen_loss = 0.9501175557636193, disc_loss = 0.0006628676265362599
Trained batch 397 in epoch 6, gen_loss = 0.9501091476960398, disc_loss = 0.0006635058736683095
Trained batch 398 in epoch 6, gen_loss = 0.9502172053308415, disc_loss = 0.0006642245230854916
Trained batch 399 in epoch 6, gen_loss = 0.9500462789833546, disc_loss = 0.0006643667511161766
Trained batch 400 in epoch 6, gen_loss = 0.950247223686399, disc_loss = 0.0006642418634770624
Trained batch 401 in epoch 6, gen_loss = 0.9501993020079029, disc_loss = 0.0006639569700884967
Trained batch 402 in epoch 6, gen_loss = 0.9501508685850328, disc_loss = 0.0006636498406313928
Trained batch 403 in epoch 6, gen_loss = 0.9502428744984145, disc_loss = 0.0006631635973967109
Trained batch 404 in epoch 6, gen_loss = 0.9501555966742244, disc_loss = 0.0006625065598335048
Trained batch 405 in epoch 6, gen_loss = 0.950204522738903, disc_loss = 0.0006618992848223731
Trained batch 406 in epoch 6, gen_loss = 0.950198557218697, disc_loss = 0.0006616722284464385
Trained batch 407 in epoch 6, gen_loss = 0.9502623627583185, disc_loss = 0.0006617449971064856
Trained batch 408 in epoch 6, gen_loss = 0.9503664142636623, disc_loss = 0.0006614958073372877
Trained batch 409 in epoch 6, gen_loss = 0.9503443774653644, disc_loss = 0.0006607553547904146
Trained batch 410 in epoch 6, gen_loss = 0.9502086053509492, disc_loss = 0.0006597391793525885
Trained batch 411 in epoch 6, gen_loss = 0.9503534198964684, disc_loss = 0.0006590730636957038
Trained batch 412 in epoch 6, gen_loss = 0.9505234099473561, disc_loss = 0.0006599489577761772
Trained batch 413 in epoch 6, gen_loss = 0.9505936571077448, disc_loss = 0.0006623463644724843
Trained batch 414 in epoch 6, gen_loss = 0.9505679251199746, disc_loss = 0.0006642199958764376
Trained batch 415 in epoch 6, gen_loss = 0.9506099989207891, disc_loss = 0.0006647293833409024
Trained batch 416 in epoch 6, gen_loss = 0.9505223421741733, disc_loss = 0.0006643967159713308
Trained batch 417 in epoch 6, gen_loss = 0.9504897627248718, disc_loss = 0.0006639596923425989
Trained batch 418 in epoch 6, gen_loss = 0.9504629746257263, disc_loss = 0.0006634459122604199
Trained batch 419 in epoch 6, gen_loss = 0.9504826909019833, disc_loss = 0.0006627778995953989
Trained batch 420 in epoch 6, gen_loss = 0.950434581400946, disc_loss = 0.0006618635298826925
Trained batch 421 in epoch 6, gen_loss = 0.9505618658110994, disc_loss = 0.0006610988274462725
Trained batch 422 in epoch 6, gen_loss = 0.9506987671480112, disc_loss = 0.0006606911976318631
Trained batch 423 in epoch 6, gen_loss = 0.9506621362184579, disc_loss = 0.0006598608125163734
Trained batch 424 in epoch 6, gen_loss = 0.9506341481208801, disc_loss = 0.0006589044412762364
Trained batch 425 in epoch 6, gen_loss = 0.9506214091755415, disc_loss = 0.00065816988025687
Trained batch 426 in epoch 6, gen_loss = 0.9504821474993257, disc_loss = 0.0006576992260004269
Trained batch 427 in epoch 6, gen_loss = 0.9505053921559147, disc_loss = 0.0006570562862553939
Trained batch 428 in epoch 6, gen_loss = 0.9504410841248252, disc_loss = 0.0006561468477200256
Trained batch 429 in epoch 6, gen_loss = 0.9506341896777929, disc_loss = 0.0006569088067112188
Trained batch 430 in epoch 6, gen_loss = 0.9505819452887622, disc_loss = 0.0006616676868838442
Trained batch 431 in epoch 6, gen_loss = 0.9505767662216116, disc_loss = 0.0006686495723476617
Trained batch 432 in epoch 6, gen_loss = 0.9507602819394294, disc_loss = 0.0006732455863161378
Trained batch 433 in epoch 6, gen_loss = 0.9506661484043719, disc_loss = 0.0006743301780978089
Trained batch 434 in epoch 6, gen_loss = 0.9506607949048623, disc_loss = 0.0006741996948211186
Trained batch 435 in epoch 6, gen_loss = 0.9506513496877951, disc_loss = 0.0006748687138422093
Trained batch 436 in epoch 6, gen_loss = 0.9505564526780519, disc_loss = 0.0006752341961194025
Trained batch 437 in epoch 6, gen_loss = 0.9504861160772576, disc_loss = 0.0006745425258262389
Trained batch 438 in epoch 6, gen_loss = 0.9505429969833218, disc_loss = 0.0006735660333970269
Trained batch 439 in epoch 6, gen_loss = 0.9504182357679714, disc_loss = 0.0006724322444907475
Trained batch 440 in epoch 6, gen_loss = 0.9504775256256398, disc_loss = 0.0006713788490346474
Trained batch 441 in epoch 6, gen_loss = 0.9502422924225147, disc_loss = 0.0006703552307665866
Trained batch 442 in epoch 6, gen_loss = 0.9502039637845472, disc_loss = 0.0006694741928873743
Trained batch 443 in epoch 6, gen_loss = 0.9502054365637066, disc_loss = 0.0006688671173915363
Trained batch 444 in epoch 6, gen_loss = 0.950117339043135, disc_loss = 0.0006682077827902636
Trained batch 445 in epoch 6, gen_loss = 0.9500239706627457, disc_loss = 0.0006675050503403604
Trained batch 446 in epoch 6, gen_loss = 0.9499581765541828, disc_loss = 0.0006666630998415815
Trained batch 447 in epoch 6, gen_loss = 0.9500169816559979, disc_loss = 0.0006657736492538138
Trained batch 448 in epoch 6, gen_loss = 0.9501601296968609, disc_loss = 0.0006650336728006589
Trained batch 449 in epoch 6, gen_loss = 0.9500992140505049, disc_loss = 0.0006642578074307595
Trained batch 450 in epoch 6, gen_loss = 0.9501199169856746, disc_loss = 0.0006635930415817502
Trained batch 451 in epoch 6, gen_loss = 0.9499100214612167, disc_loss = 0.0006630854990265839
Trained batch 452 in epoch 6, gen_loss = 0.949899415833008, disc_loss = 0.0006637832490178895
Trained batch 453 in epoch 6, gen_loss = 0.9498819005121744, disc_loss = 0.0006654968059640726
Trained batch 454 in epoch 6, gen_loss = 0.950058537525135, disc_loss = 0.0006688343150257184
Trained batch 455 in epoch 6, gen_loss = 0.9503987251143706, disc_loss = 0.0006725173769378319
Trained batch 456 in epoch 6, gen_loss = 0.950206570604437, disc_loss = 0.0006728430366292861
Trained batch 457 in epoch 6, gen_loss = 0.9500836815896513, disc_loss = 0.0006730862580583935
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 1.040916919708252, disc_loss = 0.0009972219122573733
Trained batch 1 in epoch 7, gen_loss = 1.045819103717804, disc_loss = 0.0010583701659925282
Trained batch 2 in epoch 7, gen_loss = 1.0246882438659668, disc_loss = 0.0010852247166136901
Trained batch 3 in epoch 7, gen_loss = 0.9957629293203354, disc_loss = 0.001241011981619522
Trained batch 4 in epoch 7, gen_loss = 0.9621067404747009, disc_loss = 0.0013373794266954065
Trained batch 5 in epoch 7, gen_loss = 0.9720669885476431, disc_loss = 0.001248573661238576
Trained batch 6 in epoch 7, gen_loss = 0.9741371018545968, disc_loss = 0.0012713192513079516
Trained batch 7 in epoch 7, gen_loss = 0.9659451171755791, disc_loss = 0.0012576329972944222
Trained batch 8 in epoch 7, gen_loss = 0.9623074664009942, disc_loss = 0.0011830304930400518
Trained batch 9 in epoch 7, gen_loss = 0.9618975400924683, disc_loss = 0.0011117943824501709
Trained batch 10 in epoch 7, gen_loss = 0.9571740952405062, disc_loss = 0.0010443045360840517
Trained batch 11 in epoch 7, gen_loss = 0.9533635228872299, disc_loss = 0.0009846400183353883
Trained batch 12 in epoch 7, gen_loss = 0.9503470246608441, disc_loss = 0.0009368114137592224
Trained batch 13 in epoch 7, gen_loss = 0.945388355425426, disc_loss = 0.0008906947166126754
Trained batch 14 in epoch 7, gen_loss = 0.9491067926088969, disc_loss = 0.0009275803187241157
Trained batch 15 in epoch 7, gen_loss = 0.9524068422615528, disc_loss = 0.0011109942715847865
Trained batch 16 in epoch 7, gen_loss = 0.9511157098938438, disc_loss = 0.0011698483516845632
Trained batch 17 in epoch 7, gen_loss = 0.9538163509633806, disc_loss = 0.0011267806241650963
Trained batch 18 in epoch 7, gen_loss = 0.950748644377056, disc_loss = 0.0011934462879588338
Trained batch 19 in epoch 7, gen_loss = 0.9487510830163955, disc_loss = 0.001304642841569148
Trained batch 20 in epoch 7, gen_loss = 0.9475135093643552, disc_loss = 0.0013407942855597607
Trained batch 21 in epoch 7, gen_loss = 0.9449575787240808, disc_loss = 0.0013146822986362333
Trained batch 22 in epoch 7, gen_loss = 0.9459603739821393, disc_loss = 0.0012950010258582947
Trained batch 23 in epoch 7, gen_loss = 0.9449602390329043, disc_loss = 0.0012920039031693402
Trained batch 24 in epoch 7, gen_loss = 0.9475534701347351, disc_loss = 0.0012909575435332953
Trained batch 25 in epoch 7, gen_loss = 0.9475211569896111, disc_loss = 0.001288312574615702
Trained batch 26 in epoch 7, gen_loss = 0.9494525260395474, disc_loss = 0.0012943595755603855
Trained batch 27 in epoch 7, gen_loss = 0.9505459730114255, disc_loss = 0.0013260281016950362
Trained batch 28 in epoch 7, gen_loss = 0.9502582776135412, disc_loss = 0.001351215677929978
Trained batch 29 in epoch 7, gen_loss = 0.9526890933513641, disc_loss = 0.0013436876994092017
Trained batch 30 in epoch 7, gen_loss = 0.9549813751251467, disc_loss = 0.001335240947458172
Trained batch 31 in epoch 7, gen_loss = 0.9545525852590799, disc_loss = 0.0013353743688639952
Trained batch 32 in epoch 7, gen_loss = 0.9536024151426373, disc_loss = 0.0013401177164985602
Trained batch 33 in epoch 7, gen_loss = 0.9520534312023836, disc_loss = 0.0013427486975321219
Trained batch 34 in epoch 7, gen_loss = 0.951429922240121, disc_loss = 0.0013478740068551686
Trained batch 35 in epoch 7, gen_loss = 0.9537769820955064, disc_loss = 0.0013406317076361221
Trained batch 36 in epoch 7, gen_loss = 0.9528128005362846, disc_loss = 0.0013265776309511952
Trained batch 37 in epoch 7, gen_loss = 0.9541020801192835, disc_loss = 0.0013233712065572802
Trained batch 38 in epoch 7, gen_loss = 0.9538814318485749, disc_loss = 0.0013272585914446376
Trained batch 39 in epoch 7, gen_loss = 0.9530377611517906, disc_loss = 0.0013211761543061584
Trained batch 40 in epoch 7, gen_loss = 0.953724156065685, disc_loss = 0.0012978151328464198
Trained batch 41 in epoch 7, gen_loss = 0.9521085577351707, disc_loss = 0.001293599193256038
Trained batch 42 in epoch 7, gen_loss = 0.9529404238212941, disc_loss = 0.00136287672631984
Trained batch 43 in epoch 7, gen_loss = 0.954637355425141, disc_loss = 0.001455764495899943
Trained batch 44 in epoch 7, gen_loss = 0.9556264572673374, disc_loss = 0.0014804590318817645
Trained batch 45 in epoch 7, gen_loss = 0.9567638389442278, disc_loss = 0.0014786715853362061
Trained batch 46 in epoch 7, gen_loss = 0.9573033680307105, disc_loss = 0.0014928751854235902
Trained batch 47 in epoch 7, gen_loss = 0.9571801920731863, disc_loss = 0.0015130820035362074
Trained batch 48 in epoch 7, gen_loss = 0.957595883583536, disc_loss = 0.0015063485188875347
Trained batch 49 in epoch 7, gen_loss = 0.9576843881607056, disc_loss = 0.0014966392942005768
Trained batch 50 in epoch 7, gen_loss = 0.9571025839038924, disc_loss = 0.0014885298744547089
Trained batch 51 in epoch 7, gen_loss = 0.9571344210551336, disc_loss = 0.0014692999298299232
Trained batch 52 in epoch 7, gen_loss = 0.9578326850567224, disc_loss = 0.0014447497422499407
Trained batch 53 in epoch 7, gen_loss = 0.9567150870958964, disc_loss = 0.0014236191927921027
Trained batch 54 in epoch 7, gen_loss = 0.9565889152613554, disc_loss = 0.0014150928981094197
Trained batch 55 in epoch 7, gen_loss = 0.9570917295558112, disc_loss = 0.0014039266232949948
Trained batch 56 in epoch 7, gen_loss = 0.9577829314951312, disc_loss = 0.00138705606539652
Trained batch 57 in epoch 7, gen_loss = 0.9552747401697882, disc_loss = 0.0013809692463837564
Trained batch 58 in epoch 7, gen_loss = 0.9561824697559163, disc_loss = 0.0014148244212018484
Trained batch 59 in epoch 7, gen_loss = 0.9567278116941452, disc_loss = 0.001466095984991019
Trained batch 60 in epoch 7, gen_loss = 0.9565644205593672, disc_loss = 0.001479250147984531
Trained batch 61 in epoch 7, gen_loss = 0.956427970240193, disc_loss = 0.0014714925144348413
Trained batch 62 in epoch 7, gen_loss = 0.9568324864856781, disc_loss = 0.0014586616621633608
Trained batch 63 in epoch 7, gen_loss = 0.9577825497835875, disc_loss = 0.0014441516914303065
Trained batch 64 in epoch 7, gen_loss = 0.9572560521272513, disc_loss = 0.0014269660379236135
Trained batch 65 in epoch 7, gen_loss = 0.9573189462676193, disc_loss = 0.0014112820111525555
Trained batch 66 in epoch 7, gen_loss = 0.956457412064965, disc_loss = 0.0013972916570839597
Trained batch 67 in epoch 7, gen_loss = 0.955293166286805, disc_loss = 0.0013825020822182791
Trained batch 68 in epoch 7, gen_loss = 0.9565232128336809, disc_loss = 0.0013702761291600493
Trained batch 69 in epoch 7, gen_loss = 0.9567601834024702, disc_loss = 0.001360311737101126
Trained batch 70 in epoch 7, gen_loss = 0.9590397015423842, disc_loss = 0.001357549695301355
Trained batch 71 in epoch 7, gen_loss = 0.9581045574612088, disc_loss = 0.0013677495448468511
Trained batch 72 in epoch 7, gen_loss = 0.958264853039833, disc_loss = 0.001391171821000769
Trained batch 73 in epoch 7, gen_loss = 0.957808769232518, disc_loss = 0.0014132441330631893
Trained batch 74 in epoch 7, gen_loss = 0.9583273045221965, disc_loss = 0.0014225375019789983
Trained batch 75 in epoch 7, gen_loss = 0.9586907758524543, disc_loss = 0.001416813216469324
Trained batch 76 in epoch 7, gen_loss = 0.9583729110754929, disc_loss = 0.0014090518623608612
Trained batch 77 in epoch 7, gen_loss = 0.9585907100102841, disc_loss = 0.0014116439504925017
Trained batch 78 in epoch 7, gen_loss = 0.9577396119697185, disc_loss = 0.001419121723347992
Trained batch 79 in epoch 7, gen_loss = 0.9567577913403511, disc_loss = 0.0014242501460103086
Trained batch 80 in epoch 7, gen_loss = 0.9568681753711936, disc_loss = 0.0014252880049932656
Trained batch 81 in epoch 7, gen_loss = 0.9562534253771712, disc_loss = 0.0014174490121460135
Trained batch 82 in epoch 7, gen_loss = 0.9558800681527838, disc_loss = 0.0014056117482152376
Trained batch 83 in epoch 7, gen_loss = 0.955798694065639, disc_loss = 0.0013934169026989757
Trained batch 84 in epoch 7, gen_loss = 0.956162153973299, disc_loss = 0.0013806980003958896
Trained batch 85 in epoch 7, gen_loss = 0.9558618983557058, disc_loss = 0.0013675474768861868
Trained batch 86 in epoch 7, gen_loss = 0.9558938954068327, disc_loss = 0.001354252294825936
Trained batch 87 in epoch 7, gen_loss = 0.9558376812122085, disc_loss = 0.0013408573550722476
Trained batch 88 in epoch 7, gen_loss = 0.9556055142638389, disc_loss = 0.0013276630079928325
Trained batch 89 in epoch 7, gen_loss = 0.9561372578144074, disc_loss = 0.001315193882651834
Trained batch 90 in epoch 7, gen_loss = 0.9561445025297312, disc_loss = 0.0013021160312736365
Trained batch 91 in epoch 7, gen_loss = 0.956128333573756, disc_loss = 0.0012893677479081341
Trained batch 92 in epoch 7, gen_loss = 0.955827711730875, disc_loss = 0.0012773274865266818
Trained batch 93 in epoch 7, gen_loss = 0.9561505165505917, disc_loss = 0.0012660570513268814
Trained batch 94 in epoch 7, gen_loss = 0.9566732707776522, disc_loss = 0.0012568977051782176
Trained batch 95 in epoch 7, gen_loss = 0.956514868264397, disc_loss = 0.0012466493062675
Trained batch 96 in epoch 7, gen_loss = 0.9559669894041475, disc_loss = 0.0012361242810321838
Trained batch 97 in epoch 7, gen_loss = 0.9560903146558878, disc_loss = 0.0012256669789928068
Trained batch 98 in epoch 7, gen_loss = 0.9558466835455461, disc_loss = 0.0012154476058603538
Trained batch 99 in epoch 7, gen_loss = 0.9566771441698074, disc_loss = 0.0012061748455744236
Trained batch 100 in epoch 7, gen_loss = 0.9563457540946432, disc_loss = 0.0011976022027792538
Trained batch 101 in epoch 7, gen_loss = 0.9565361177220064, disc_loss = 0.0011915841012024413
Trained batch 102 in epoch 7, gen_loss = 0.9568925146917695, disc_loss = 0.001185616561397006
Trained batch 103 in epoch 7, gen_loss = 0.9566752520891336, disc_loss = 0.001176365818957073
Trained batch 104 in epoch 7, gen_loss = 0.9568619614555722, disc_loss = 0.001168358223817666
Trained batch 105 in epoch 7, gen_loss = 0.9573909044265747, disc_loss = 0.0011627296476464561
Trained batch 106 in epoch 7, gen_loss = 0.9568670687274398, disc_loss = 0.0011564453961229752
Trained batch 107 in epoch 7, gen_loss = 0.9569742464356952, disc_loss = 0.0011501016807516054
Trained batch 108 in epoch 7, gen_loss = 0.9568623829325404, disc_loss = 0.001144760748485761
Trained batch 109 in epoch 7, gen_loss = 0.9564217177304355, disc_loss = 0.0011390465500880965
Trained batch 110 in epoch 7, gen_loss = 0.9564090784605559, disc_loss = 0.0011322642114120409
Trained batch 111 in epoch 7, gen_loss = 0.9565725422331265, disc_loss = 0.001125635248042402
Trained batch 112 in epoch 7, gen_loss = 0.9560865206001079, disc_loss = 0.0011194838779881612
Trained batch 113 in epoch 7, gen_loss = 0.9556577592565302, disc_loss = 0.0011126479781651461
Trained batch 114 in epoch 7, gen_loss = 0.9554405139840167, disc_loss = 0.0011056658818194157
Trained batch 115 in epoch 7, gen_loss = 0.9553174818384236, disc_loss = 0.0010991222050757516
Trained batch 116 in epoch 7, gen_loss = 0.9552349509337009, disc_loss = 0.0010927019042060431
Trained batch 117 in epoch 7, gen_loss = 0.9549277722835541, disc_loss = 0.0010864956816707707
Trained batch 118 in epoch 7, gen_loss = 0.9542322459341097, disc_loss = 0.0010803295740859677
Trained batch 119 in epoch 7, gen_loss = 0.9544044663508733, disc_loss = 0.001075260545743125
Trained batch 120 in epoch 7, gen_loss = 0.9539143797779871, disc_loss = 0.001071910833634921
Trained batch 121 in epoch 7, gen_loss = 0.9534704670554301, disc_loss = 0.001067017492638771
Trained batch 122 in epoch 7, gen_loss = 0.9531414881954349, disc_loss = 0.0010607357391741172
Trained batch 123 in epoch 7, gen_loss = 0.9534043684121101, disc_loss = 0.0010546388919230535
Trained batch 124 in epoch 7, gen_loss = 0.9540662684440613, disc_loss = 0.0010495830808067695
Trained batch 125 in epoch 7, gen_loss = 0.9537693626350827, disc_loss = 0.0010430702934085968
Trained batch 126 in epoch 7, gen_loss = 0.9544232543997877, disc_loss = 0.0010376824746660038
Trained batch 127 in epoch 7, gen_loss = 0.9541073078289628, disc_loss = 0.0010355766028169455
Trained batch 128 in epoch 7, gen_loss = 0.9546675451042116, disc_loss = 0.0010346247015481224
Trained batch 129 in epoch 7, gen_loss = 0.9547261201418363, disc_loss = 0.0010323445637298462
Trained batch 130 in epoch 7, gen_loss = 0.9547245629871165, disc_loss = 0.0010293426442240855
Trained batch 131 in epoch 7, gen_loss = 0.9547318974227617, disc_loss = 0.001026529043773542
Trained batch 132 in epoch 7, gen_loss = 0.9543717723143729, disc_loss = 0.0010231818788933491
Trained batch 133 in epoch 7, gen_loss = 0.9544114203595403, disc_loss = 0.0010192175806281087
Trained batch 134 in epoch 7, gen_loss = 0.9541742708947923, disc_loss = 0.0010144984274154047
Trained batch 135 in epoch 7, gen_loss = 0.9533068708637181, disc_loss = 0.0010096847810714012
Trained batch 136 in epoch 7, gen_loss = 0.9528321819583865, disc_loss = 0.001006269383917216
Trained batch 137 in epoch 7, gen_loss = 0.9530166543048361, disc_loss = 0.0010020040320249382
Trained batch 138 in epoch 7, gen_loss = 0.9523130766779399, disc_loss = 0.0009967077378160152
Trained batch 139 in epoch 7, gen_loss = 0.9532014216695514, disc_loss = 0.0009938674390598732
Trained batch 140 in epoch 7, gen_loss = 0.9535134612245763, disc_loss = 0.0009916619612779203
Trained batch 141 in epoch 7, gen_loss = 0.9536960590893114, disc_loss = 0.0009884682312217528
Trained batch 142 in epoch 7, gen_loss = 0.953496230232132, disc_loss = 0.0009841574984846859
Trained batch 143 in epoch 7, gen_loss = 0.9533848191301028, disc_loss = 0.0009798756661136092
Trained batch 144 in epoch 7, gen_loss = 0.9526609737297584, disc_loss = 0.0009761451869994273
Trained batch 145 in epoch 7, gen_loss = 0.9525395243951719, disc_loss = 0.0009745796271264936
Trained batch 146 in epoch 7, gen_loss = 0.9521134122699296, disc_loss = 0.0009750289940291091
Trained batch 147 in epoch 7, gen_loss = 0.9521777138516709, disc_loss = 0.0009734437765940596
Trained batch 148 in epoch 7, gen_loss = 0.9526350938233753, disc_loss = 0.0009700370514562241
Trained batch 149 in epoch 7, gen_loss = 0.9527839926878611, disc_loss = 0.0009665680271185314
Trained batch 150 in epoch 7, gen_loss = 0.9530105709240136, disc_loss = 0.0009625384185867175
Trained batch 151 in epoch 7, gen_loss = 0.9531113873971137, disc_loss = 0.0009583594004844168
Trained batch 152 in epoch 7, gen_loss = 0.952998114567177, disc_loss = 0.0009539695996851995
Trained batch 153 in epoch 7, gen_loss = 0.9531652246202741, disc_loss = 0.0009495622337442012
Trained batch 154 in epoch 7, gen_loss = 0.9529988131215495, disc_loss = 0.0009449792552679296
Trained batch 155 in epoch 7, gen_loss = 0.9525165657202402, disc_loss = 0.000940392765094144
Trained batch 156 in epoch 7, gen_loss = 0.9528396395361347, disc_loss = 0.0009359789794981243
Trained batch 157 in epoch 7, gen_loss = 0.9529452874690671, disc_loss = 0.0009310886404208863
Trained batch 158 in epoch 7, gen_loss = 0.9531254041119941, disc_loss = 0.0009261975843721486
Trained batch 159 in epoch 7, gen_loss = 0.9531413599848747, disc_loss = 0.0009214229734425316
Trained batch 160 in epoch 7, gen_loss = 0.9524680835119685, disc_loss = 0.0009166918115065612
Trained batch 161 in epoch 7, gen_loss = 0.9525878135068917, disc_loss = 0.0009120301006471072
Trained batch 162 in epoch 7, gen_loss = 0.9523082371869701, disc_loss = 0.0009077532108704577
Trained batch 163 in epoch 7, gen_loss = 0.9521689952873602, disc_loss = 0.000903461888544659
Trained batch 164 in epoch 7, gen_loss = 0.9518752585757863, disc_loss = 0.0008989805763121694
Trained batch 165 in epoch 7, gen_loss = 0.9519795829273132, disc_loss = 0.0008950178453233093
Trained batch 166 in epoch 7, gen_loss = 0.9517622936271621, disc_loss = 0.0008914251393543746
Trained batch 167 in epoch 7, gen_loss = 0.9516124125747454, disc_loss = 0.0008873797507389792
Trained batch 168 in epoch 7, gen_loss = 0.9518883245936512, disc_loss = 0.0008831353584812822
Trained batch 169 in epoch 7, gen_loss = 0.9512127564233892, disc_loss = 0.0008791551287525662
Trained batch 170 in epoch 7, gen_loss = 0.9511063395187869, disc_loss = 0.0008764501051924175
Trained batch 171 in epoch 7, gen_loss = 0.9510209941586782, disc_loss = 0.0008744217221372014
Trained batch 172 in epoch 7, gen_loss = 0.9512751963786307, disc_loss = 0.0008721959665639735
Trained batch 173 in epoch 7, gen_loss = 0.9510024272162338, disc_loss = 0.0008698949823992316
Trained batch 174 in epoch 7, gen_loss = 0.9510202288627625, disc_loss = 0.0008679414674406871
Trained batch 175 in epoch 7, gen_loss = 0.9509292282164097, disc_loss = 0.0008668603299652618
Trained batch 176 in epoch 7, gen_loss = 0.9513282799451365, disc_loss = 0.0008657607895297151
Trained batch 177 in epoch 7, gen_loss = 0.9511761682087116, disc_loss = 0.0008635799655739186
Trained batch 178 in epoch 7, gen_loss = 0.9511175675099123, disc_loss = 0.0008603516318503632
Trained batch 179 in epoch 7, gen_loss = 0.9508113592863083, disc_loss = 0.0008570463614079118
Trained batch 180 in epoch 7, gen_loss = 0.9508488906022593, disc_loss = 0.0008540006454304653
Trained batch 181 in epoch 7, gen_loss = 0.9508846333393683, disc_loss = 0.0008511085130861489
Trained batch 182 in epoch 7, gen_loss = 0.9510807193042151, disc_loss = 0.000848248056495496
Trained batch 183 in epoch 7, gen_loss = 0.9510119975261067, disc_loss = 0.0008452056911704384
Trained batch 184 in epoch 7, gen_loss = 0.9512768529556893, disc_loss = 0.0008424195046442234
Trained batch 185 in epoch 7, gen_loss = 0.9515780790518689, disc_loss = 0.0008403384482697083
Trained batch 186 in epoch 7, gen_loss = 0.9515454306959469, disc_loss = 0.0008378640964426808
Trained batch 187 in epoch 7, gen_loss = 0.9516928294237624, disc_loss = 0.0008352485610304668
Trained batch 188 in epoch 7, gen_loss = 0.9516465723829926, disc_loss = 0.0008329066409262528
Trained batch 189 in epoch 7, gen_loss = 0.951898097364526, disc_loss = 0.0008306926570520246
Trained batch 190 in epoch 7, gen_loss = 0.9520607250523193, disc_loss = 0.0008281392825636964
Trained batch 191 in epoch 7, gen_loss = 0.9518885084738334, disc_loss = 0.0008253008090074824
Trained batch 192 in epoch 7, gen_loss = 0.9516623088115238, disc_loss = 0.0008223894907377535
Trained batch 193 in epoch 7, gen_loss = 0.952015811020566, disc_loss = 0.0008194943452367952
Trained batch 194 in epoch 7, gen_loss = 0.9526029641811664, disc_loss = 0.0008167533365896162
Trained batch 195 in epoch 7, gen_loss = 0.9524571104925506, disc_loss = 0.0008143944356487161
Trained batch 196 in epoch 7, gen_loss = 0.9520538839591941, disc_loss = 0.0008125790318168066
Trained batch 197 in epoch 7, gen_loss = 0.9521093431747321, disc_loss = 0.0008105469721039014
Trained batch 198 in epoch 7, gen_loss = 0.9525201527317565, disc_loss = 0.0008083443557662215
Trained batch 199 in epoch 7, gen_loss = 0.9520193222165108, disc_loss = 0.0008063999686419265
Trained batch 200 in epoch 7, gen_loss = 0.9516973148530988, disc_loss = 0.0008049786273437548
Trained batch 201 in epoch 7, gen_loss = 0.9514129014298467, disc_loss = 0.0008033850606465205
Trained batch 202 in epoch 7, gen_loss = 0.951175688229171, disc_loss = 0.0008012989989402727
Trained batch 203 in epoch 7, gen_loss = 0.9513913048248664, disc_loss = 0.0007987940209882343
Trained batch 204 in epoch 7, gen_loss = 0.9510679015299169, disc_loss = 0.0007967526570854072
Trained batch 205 in epoch 7, gen_loss = 0.950906082553771, disc_loss = 0.0007961949032479309
Trained batch 206 in epoch 7, gen_loss = 0.9507700040720511, disc_loss = 0.0007967860354273692
Trained batch 207 in epoch 7, gen_loss = 0.9505101940952815, disc_loss = 0.0007977150901821845
Trained batch 208 in epoch 7, gen_loss = 0.950362257695084, disc_loss = 0.0007977182459577464
Trained batch 209 in epoch 7, gen_loss = 0.9508659303188324, disc_loss = 0.0007972404089828377
Trained batch 210 in epoch 7, gen_loss = 0.9508040281833631, disc_loss = 0.0007966291002837623
Trained batch 211 in epoch 7, gen_loss = 0.9508081688633505, disc_loss = 0.0007959883987496141
Trained batch 212 in epoch 7, gen_loss = 0.9508457556017128, disc_loss = 0.000795283054830747
Trained batch 213 in epoch 7, gen_loss = 0.9510747854397675, disc_loss = 0.0007940293007522656
Trained batch 214 in epoch 7, gen_loss = 0.9510181038878684, disc_loss = 0.0007929275143312203
Trained batch 215 in epoch 7, gen_loss = 0.9509705547933225, disc_loss = 0.0007915511588955134
Trained batch 216 in epoch 7, gen_loss = 0.9506672343350775, disc_loss = 0.0007902309951004422
Trained batch 217 in epoch 7, gen_loss = 0.9506656068180679, disc_loss = 0.000789465491968066
Trained batch 218 in epoch 7, gen_loss = 0.9505651225782421, disc_loss = 0.0007889458368618475
Trained batch 219 in epoch 7, gen_loss = 0.9507682437246496, disc_loss = 0.0007888073980707718
Trained batch 220 in epoch 7, gen_loss = 0.9508349798383756, disc_loss = 0.0007887251772712369
Trained batch 221 in epoch 7, gen_loss = 0.9508053155632706, disc_loss = 0.0007888110783103191
Trained batch 222 in epoch 7, gen_loss = 0.9507200907698661, disc_loss = 0.0007890903575877312
Trained batch 223 in epoch 7, gen_loss = 0.9512027781456709, disc_loss = 0.0007882305249040655
Trained batch 224 in epoch 7, gen_loss = 0.9513776938120524, disc_loss = 0.0007866679954006233
Trained batch 225 in epoch 7, gen_loss = 0.9510597138278252, disc_loss = 0.0007853410449481685
Trained batch 226 in epoch 7, gen_loss = 0.9510149635407368, disc_loss = 0.0007841621117490971
Trained batch 227 in epoch 7, gen_loss = 0.9507715968709243, disc_loss = 0.0007833092008934871
Trained batch 228 in epoch 7, gen_loss = 0.9503595350090593, disc_loss = 0.0007824017880428541
Trained batch 229 in epoch 7, gen_loss = 0.950072181224823, disc_loss = 0.0007818566825691327
Trained batch 230 in epoch 7, gen_loss = 0.9503786398734881, disc_loss = 0.0007824491696493716
Trained batch 231 in epoch 7, gen_loss = 0.9500845470305147, disc_loss = 0.0007839692390352238
Trained batch 232 in epoch 7, gen_loss = 0.9499192716226046, disc_loss = 0.0007850715090233889
Trained batch 233 in epoch 7, gen_loss = 0.9496504307812096, disc_loss = 0.0007848455275246738
Trained batch 234 in epoch 7, gen_loss = 0.9492638904997643, disc_loss = 0.0007843105083435496
Trained batch 235 in epoch 7, gen_loss = 0.9493640507176772, disc_loss = 0.0007848479308141592
Trained batch 236 in epoch 7, gen_loss = 0.9493922000192891, disc_loss = 0.0007850139071886872
Trained batch 237 in epoch 7, gen_loss = 0.949278354143896, disc_loss = 0.0007840766852839944
Trained batch 238 in epoch 7, gen_loss = 0.9493518982971064, disc_loss = 0.0007828296570494093
Trained batch 239 in epoch 7, gen_loss = 0.9493272192776203, disc_loss = 0.0007815090853910079
Trained batch 240 in epoch 7, gen_loss = 0.9494940967480672, disc_loss = 0.0007799804788271228
Trained batch 241 in epoch 7, gen_loss = 0.9493437168026758, disc_loss = 0.0007778650857695794
Trained batch 242 in epoch 7, gen_loss = 0.949351673999441, disc_loss = 0.0007758919789083111
Trained batch 243 in epoch 7, gen_loss = 0.949434755034134, disc_loss = 0.0007744856112799798
Trained batch 244 in epoch 7, gen_loss = 0.9493296178019777, disc_loss = 0.0007727122560917989
Trained batch 245 in epoch 7, gen_loss = 0.949443972692257, disc_loss = 0.0007706329817916797
Trained batch 246 in epoch 7, gen_loss = 0.949450365927538, disc_loss = 0.0007694415782407673
Trained batch 247 in epoch 7, gen_loss = 0.9490403268606432, disc_loss = 0.0007680362398992481
Trained batch 248 in epoch 7, gen_loss = 0.9489799259178131, disc_loss = 0.000766083187468997
Trained batch 249 in epoch 7, gen_loss = 0.9488804278373718, disc_loss = 0.0007641726664151065
Trained batch 250 in epoch 7, gen_loss = 0.9488367521430392, disc_loss = 0.0007625336881585056
Trained batch 251 in epoch 7, gen_loss = 0.9486160888558343, disc_loss = 0.0007604358545486032
Trained batch 252 in epoch 7, gen_loss = 0.9486555664435677, disc_loss = 0.0007583008412586473
Trained batch 253 in epoch 7, gen_loss = 0.9488944929885114, disc_loss = 0.0007569625395978984
Trained batch 254 in epoch 7, gen_loss = 0.9488161108073067, disc_loss = 0.0007550101077832354
Trained batch 255 in epoch 7, gen_loss = 0.9487381821963936, disc_loss = 0.0007527173149810551
Trained batch 256 in epoch 7, gen_loss = 0.9486151448947446, disc_loss = 0.0007504935032988858
Trained batch 257 in epoch 7, gen_loss = 0.9484017519063728, disc_loss = 0.0007483367213677947
Trained batch 258 in epoch 7, gen_loss = 0.9482774628635539, disc_loss = 0.0007461277972754005
Trained batch 259 in epoch 7, gen_loss = 0.9482341754894991, disc_loss = 0.0007440352664651492
Trained batch 260 in epoch 7, gen_loss = 0.9482185208020996, disc_loss = 0.0007422467317009324
Trained batch 261 in epoch 7, gen_loss = 0.9482208601846039, disc_loss = 0.0007406324556964727
Trained batch 262 in epoch 7, gen_loss = 0.9482721829142408, disc_loss = 0.0007390159939392735
Trained batch 263 in epoch 7, gen_loss = 0.9480408484285529, disc_loss = 0.0007367659114661916
Trained batch 264 in epoch 7, gen_loss = 0.9477670651561809, disc_loss = 0.0007344596297699817
Trained batch 265 in epoch 7, gen_loss = 0.9475889154394767, disc_loss = 0.0007321911845820136
Trained batch 266 in epoch 7, gen_loss = 0.9475700301623969, disc_loss = 0.000730222905986011
Trained batch 267 in epoch 7, gen_loss = 0.9477588578836241, disc_loss = 0.0007284398229989057
Trained batch 268 in epoch 7, gen_loss = 0.9476844196425938, disc_loss = 0.00072669609677874
Trained batch 269 in epoch 7, gen_loss = 0.947661899195777, disc_loss = 0.0007251923399356504
Trained batch 270 in epoch 7, gen_loss = 0.9475702372864163, disc_loss = 0.0007236842656717722
Trained batch 271 in epoch 7, gen_loss = 0.9477434254744473, disc_loss = 0.0007224642258199096
Trained batch 272 in epoch 7, gen_loss = 0.9478705409682278, disc_loss = 0.0007214624199746757
Trained batch 273 in epoch 7, gen_loss = 0.9479222234583249, disc_loss = 0.0007200153475715677
Trained batch 274 in epoch 7, gen_loss = 0.9477797991579229, disc_loss = 0.000718458435096016
Trained batch 275 in epoch 7, gen_loss = 0.9478901575009028, disc_loss = 0.0007175115715126858
Trained batch 276 in epoch 7, gen_loss = 0.9480586191807413, disc_loss = 0.0007168504049949388
Trained batch 277 in epoch 7, gen_loss = 0.9481592120455323, disc_loss = 0.0007158306877676518
Trained batch 278 in epoch 7, gen_loss = 0.9481810286480893, disc_loss = 0.000714363557400055
Trained batch 279 in epoch 7, gen_loss = 0.9482047702584948, disc_loss = 0.0007126193011312613
Trained batch 280 in epoch 7, gen_loss = 0.9481948346854104, disc_loss = 0.000710987495473881
Trained batch 281 in epoch 7, gen_loss = 0.948182854669314, disc_loss = 0.0007093612894998757
Trained batch 282 in epoch 7, gen_loss = 0.9480113591406455, disc_loss = 0.0007079288887119993
Trained batch 283 in epoch 7, gen_loss = 0.9478490537321064, disc_loss = 0.0007070045179152914
Trained batch 284 in epoch 7, gen_loss = 0.947696702522144, disc_loss = 0.0007061635131800645
Trained batch 285 in epoch 7, gen_loss = 0.9479148554635215, disc_loss = 0.0007059382837692314
Trained batch 286 in epoch 7, gen_loss = 0.947842192982132, disc_loss = 0.0007072285404639766
Trained batch 287 in epoch 7, gen_loss = 0.9482807372179296, disc_loss = 0.0007113292803195589
Trained batch 288 in epoch 7, gen_loss = 0.9480037505651427, disc_loss = 0.0007189642974323751
Trained batch 289 in epoch 7, gen_loss = 0.948270774504234, disc_loss = 0.0007275507414055153
Trained batch 290 in epoch 7, gen_loss = 0.9482004021860889, disc_loss = 0.0007331235639517327
Trained batch 291 in epoch 7, gen_loss = 0.9480931379207193, disc_loss = 0.0007362253120733578
Trained batch 292 in epoch 7, gen_loss = 0.9479698703557558, disc_loss = 0.0007371400832993204
Trained batch 293 in epoch 7, gen_loss = 0.9478663137169923, disc_loss = 0.0007366579282176713
Trained batch 294 in epoch 7, gen_loss = 0.9478201506501537, disc_loss = 0.0007358194019061403
Trained batch 295 in epoch 7, gen_loss = 0.9478940770432756, disc_loss = 0.000734514874607526
Trained batch 296 in epoch 7, gen_loss = 0.9479679493390349, disc_loss = 0.0007331479073859601
Trained batch 297 in epoch 7, gen_loss = 0.948278635340249, disc_loss = 0.0007328709840208867
Trained batch 298 in epoch 7, gen_loss = 0.9483261469215852, disc_loss = 0.0007357905312428831
Trained batch 299 in epoch 7, gen_loss = 0.9484377207358679, disc_loss = 0.0007418687628038849
Trained batch 300 in epoch 7, gen_loss = 0.9488392016816377, disc_loss = 0.0007462990077667285
Trained batch 301 in epoch 7, gen_loss = 0.9483861508748389, disc_loss = 0.000746928512956022
Trained batch 302 in epoch 7, gen_loss = 0.9483334256870912, disc_loss = 0.0007485525108944539
Trained batch 303 in epoch 7, gen_loss = 0.9482496157288551, disc_loss = 0.0007523531425441002
Trained batch 304 in epoch 7, gen_loss = 0.9483651903809094, disc_loss = 0.0007561707710770921
Trained batch 305 in epoch 7, gen_loss = 0.9483934968125587, disc_loss = 0.0007607300525753351
Trained batch 306 in epoch 7, gen_loss = 0.9483263158642896, disc_loss = 0.0007646286062644461
Trained batch 307 in epoch 7, gen_loss = 0.9483185257617529, disc_loss = 0.0007673539631386203
Trained batch 308 in epoch 7, gen_loss = 0.948398286277808, disc_loss = 0.0007692488529387874
Trained batch 309 in epoch 7, gen_loss = 0.9484656589646493, disc_loss = 0.0007695637754119572
Trained batch 310 in epoch 7, gen_loss = 0.9485330246269128, disc_loss = 0.0007684608373770017
Trained batch 311 in epoch 7, gen_loss = 0.948399737286262, disc_loss = 0.0007668296048695294
Trained batch 312 in epoch 7, gen_loss = 0.9483993561884847, disc_loss = 0.0007653366757583575
Trained batch 313 in epoch 7, gen_loss = 0.9483669774167857, disc_loss = 0.0007639807705681438
Trained batch 314 in epoch 7, gen_loss = 0.9485049419932895, disc_loss = 0.0007627299076707531
Trained batch 315 in epoch 7, gen_loss = 0.9483493989026999, disc_loss = 0.000761863736776912
Trained batch 316 in epoch 7, gen_loss = 0.9481090549790897, disc_loss = 0.0007612101467618607
Trained batch 317 in epoch 7, gen_loss = 0.9482266121315506, disc_loss = 0.0007603455701170771
Trained batch 318 in epoch 7, gen_loss = 0.9482255607936824, disc_loss = 0.0007591235858671438
Trained batch 319 in epoch 7, gen_loss = 0.9483494620770216, disc_loss = 0.0007575014496069343
Trained batch 320 in epoch 7, gen_loss = 0.9482936131248593, disc_loss = 0.0007556165641788799
Trained batch 321 in epoch 7, gen_loss = 0.9483373298408082, disc_loss = 0.0007541253271596564
Trained batch 322 in epoch 7, gen_loss = 0.9484194583568042, disc_loss = 0.000752668910578395
Trained batch 323 in epoch 7, gen_loss = 0.948631841827322, disc_loss = 0.0007510666484315017
Trained batch 324 in epoch 7, gen_loss = 0.9487196399615361, disc_loss = 0.0007493044522841676
Trained batch 325 in epoch 7, gen_loss = 0.9485841185037344, disc_loss = 0.0007473915449145073
Trained batch 326 in epoch 7, gen_loss = 0.948854445682024, disc_loss = 0.0007460127615431091
Trained batch 327 in epoch 7, gen_loss = 0.9489979678537788, disc_loss = 0.0007451034211177413
Trained batch 328 in epoch 7, gen_loss = 0.9490299449503241, disc_loss = 0.0007437274798907984
Trained batch 329 in epoch 7, gen_loss = 0.9489117958328941, disc_loss = 0.0007420645131567267
Trained batch 330 in epoch 7, gen_loss = 0.948713147748273, disc_loss = 0.0007410879243197612
Trained batch 331 in epoch 7, gen_loss = 0.9486977274877479, disc_loss = 0.0007404893459099995
Trained batch 332 in epoch 7, gen_loss = 0.9486931240236437, disc_loss = 0.0007391336964626514
Trained batch 333 in epoch 7, gen_loss = 0.9485904328123538, disc_loss = 0.0007374549514968171
Trained batch 334 in epoch 7, gen_loss = 0.9487327171795403, disc_loss = 0.0007361586384628135
Trained batch 335 in epoch 7, gen_loss = 0.9487134901185831, disc_loss = 0.0007360980796095516
Trained batch 336 in epoch 7, gen_loss = 0.9491664374617511, disc_loss = 0.0007384540098622574
Trained batch 337 in epoch 7, gen_loss = 0.949297099952867, disc_loss = 0.0007412825117284465
Trained batch 338 in epoch 7, gen_loss = 0.9492031024620596, disc_loss = 0.0007428343319897279
Trained batch 339 in epoch 7, gen_loss = 0.9490661487859838, disc_loss = 0.000743618976626107
Trained batch 340 in epoch 7, gen_loss = 0.9490398456973415, disc_loss = 0.0007452613211856865
Trained batch 341 in epoch 7, gen_loss = 0.949170659682904, disc_loss = 0.0007470966032869591
Trained batch 342 in epoch 7, gen_loss = 0.9492804272529335, disc_loss = 0.0007478834619289454
Trained batch 343 in epoch 7, gen_loss = 0.9495106157521869, disc_loss = 0.0007474054040950398
Trained batch 344 in epoch 7, gen_loss = 0.949502954794013, disc_loss = 0.0007462791675883953
Trained batch 345 in epoch 7, gen_loss = 0.9495019549234754, disc_loss = 0.0007449943568749956
Trained batch 346 in epoch 7, gen_loss = 0.9494574279537805, disc_loss = 0.0007437133156125479
Trained batch 347 in epoch 7, gen_loss = 0.9493427100195282, disc_loss = 0.0007426337902327122
Trained batch 348 in epoch 7, gen_loss = 0.9492725087783398, disc_loss = 0.0007416806062002984
Trained batch 349 in epoch 7, gen_loss = 0.9491648972034454, disc_loss = 0.0007409235155708822
Trained batch 350 in epoch 7, gen_loss = 0.9493352237590018, disc_loss = 0.000740211879807336
Trained batch 351 in epoch 7, gen_loss = 0.949396412819624, disc_loss = 0.0007396818161644412
Trained batch 352 in epoch 7, gen_loss = 0.9492925545649218, disc_loss = 0.0007392414356614846
Trained batch 353 in epoch 7, gen_loss = 0.9493947768278714, disc_loss = 0.0007383849906391795
Trained batch 354 in epoch 7, gen_loss = 0.9493810682229593, disc_loss = 0.0007372707467113005
Trained batch 355 in epoch 7, gen_loss = 0.9496195914035432, disc_loss = 0.0007365497599749596
Trained batch 356 in epoch 7, gen_loss = 0.9497234949878618, disc_loss = 0.0007361746542331833
Trained batch 357 in epoch 7, gen_loss = 0.949432014087059, disc_loss = 0.0007361060071979811
Trained batch 358 in epoch 7, gen_loss = 0.9494502838275559, disc_loss = 0.0007361600065732266
Trained batch 359 in epoch 7, gen_loss = 0.9495506839619743, disc_loss = 0.0007360002603996286
Trained batch 360 in epoch 7, gen_loss = 0.9494635510642773, disc_loss = 0.0007347731820889426
Trained batch 361 in epoch 7, gen_loss = 0.9494236361914576, disc_loss = 0.0007334511793181249
Trained batch 362 in epoch 7, gen_loss = 0.9495027415023363, disc_loss = 0.0007328083534236258
Trained batch 363 in epoch 7, gen_loss = 0.9496214889235549, disc_loss = 0.0007319983253562516
Trained batch 364 in epoch 7, gen_loss = 0.9497728078332666, disc_loss = 0.0007307825375616245
Trained batch 365 in epoch 7, gen_loss = 0.9497986978194752, disc_loss = 0.0007292123056904927
Trained batch 366 in epoch 7, gen_loss = 0.9498981839954366, disc_loss = 0.0007278115631094487
Trained batch 367 in epoch 7, gen_loss = 0.9499468698125818, disc_loss = 0.0007270546363898851
Trained batch 368 in epoch 7, gen_loss = 0.949993739444712, disc_loss = 0.0007261457209974441
Trained batch 369 in epoch 7, gen_loss = 0.9497511396536956, disc_loss = 0.0007250363319070783
Trained batch 370 in epoch 7, gen_loss = 0.9497196336962143, disc_loss = 0.0007242269169886262
Trained batch 371 in epoch 7, gen_loss = 0.9496015887106618, disc_loss = 0.0007240723965076794
Trained batch 372 in epoch 7, gen_loss = 0.9494385008198326, disc_loss = 0.0007247245952380252
Trained batch 373 in epoch 7, gen_loss = 0.9493967712244248, disc_loss = 0.0007249113075565273
Trained batch 374 in epoch 7, gen_loss = 0.949545770963033, disc_loss = 0.0007240250334531689
Trained batch 375 in epoch 7, gen_loss = 0.9493944573592632, disc_loss = 0.0007231164483450715
Trained batch 376 in epoch 7, gen_loss = 0.9491958006307364, disc_loss = 0.0007217952809670189
Trained batch 377 in epoch 7, gen_loss = 0.9493636550411345, disc_loss = 0.0007208482232286654
Trained batch 378 in epoch 7, gen_loss = 0.9493313735267418, disc_loss = 0.0007203271895346642
Trained batch 379 in epoch 7, gen_loss = 0.9491712403924841, disc_loss = 0.00071931309882386
Trained batch 380 in epoch 7, gen_loss = 0.9490257151170666, disc_loss = 0.0007185352744435002
Trained batch 381 in epoch 7, gen_loss = 0.9489803165977538, disc_loss = 0.0007173878335255607
Trained batch 382 in epoch 7, gen_loss = 0.9487056799096787, disc_loss = 0.0007162406798114747
Trained batch 383 in epoch 7, gen_loss = 0.9488797835074365, disc_loss = 0.0007152766664830779
Trained batch 384 in epoch 7, gen_loss = 0.9487645598201009, disc_loss = 0.0007148706127795717
Trained batch 385 in epoch 7, gen_loss = 0.9484533287700594, disc_loss = 0.0007161973500060318
Trained batch 386 in epoch 7, gen_loss = 0.948486658029778, disc_loss = 0.0007193879638657151
Trained batch 387 in epoch 7, gen_loss = 0.9484585909192095, disc_loss = 0.0007224989519469541
Trained batch 388 in epoch 7, gen_loss = 0.9481891595918905, disc_loss = 0.0007230138771938026
Trained batch 389 in epoch 7, gen_loss = 0.9481623670993707, disc_loss = 0.0007228510136766813
Trained batch 390 in epoch 7, gen_loss = 0.9481395827534863, disc_loss = 0.0007226134618328017
Trained batch 391 in epoch 7, gen_loss = 0.9483226537704468, disc_loss = 0.0007219469857123581
Trained batch 392 in epoch 7, gen_loss = 0.9484594174620457, disc_loss = 0.0007207591230515983
Trained batch 393 in epoch 7, gen_loss = 0.9483327909472025, disc_loss = 0.000719609146582868
Trained batch 394 in epoch 7, gen_loss = 0.9484591935254351, disc_loss = 0.000718766769882044
Trained batch 395 in epoch 7, gen_loss = 0.9482726958966015, disc_loss = 0.0007180273969057416
Trained batch 396 in epoch 7, gen_loss = 0.9482489168193539, disc_loss = 0.0007188534646711995
Trained batch 397 in epoch 7, gen_loss = 0.9482705822242564, disc_loss = 0.0007195456452412067
Trained batch 398 in epoch 7, gen_loss = 0.9481546602452309, disc_loss = 0.0007188420456161321
Trained batch 399 in epoch 7, gen_loss = 0.9481710013747215, disc_loss = 0.0007177825284088613
Trained batch 400 in epoch 7, gen_loss = 0.948251235514805, disc_loss = 0.0007167775078314912
Trained batch 401 in epoch 7, gen_loss = 0.9482699923254364, disc_loss = 0.0007155900676656556
Trained batch 402 in epoch 7, gen_loss = 0.9482828709978619, disc_loss = 0.0007142561410796983
Trained batch 403 in epoch 7, gen_loss = 0.9481723518064706, disc_loss = 0.0007128481283691126
Trained batch 404 in epoch 7, gen_loss = 0.9480886618296306, disc_loss = 0.0007115714980668767
Trained batch 405 in epoch 7, gen_loss = 0.9480398599737383, disc_loss = 0.0007103473105636457
Trained batch 406 in epoch 7, gen_loss = 0.947984020891588, disc_loss = 0.0007093880826542132
Trained batch 407 in epoch 7, gen_loss = 0.9479267398516337, disc_loss = 0.0007086998395571558
Trained batch 408 in epoch 7, gen_loss = 0.9479390656744064, disc_loss = 0.0007079267831807296
Trained batch 409 in epoch 7, gen_loss = 0.9478026055708164, disc_loss = 0.0007066106664374606
Trained batch 410 in epoch 7, gen_loss = 0.9477021177899808, disc_loss = 0.0007052466604284208
Trained batch 411 in epoch 7, gen_loss = 0.9474665392371058, disc_loss = 0.0007039815381997789
Trained batch 412 in epoch 7, gen_loss = 0.9474488059487239, disc_loss = 0.0007030924662500033
Trained batch 413 in epoch 7, gen_loss = 0.9473400912135119, disc_loss = 0.0007028121862966559
Trained batch 414 in epoch 7, gen_loss = 0.9473445877971419, disc_loss = 0.0007028298112367426
Trained batch 415 in epoch 7, gen_loss = 0.9471869887067721, disc_loss = 0.0007027442375496881
Trained batch 416 in epoch 7, gen_loss = 0.947456680613456, disc_loss = 0.0007034981585184796
Trained batch 417 in epoch 7, gen_loss = 0.9474531801408558, disc_loss = 0.0007053325149764275
Trained batch 418 in epoch 7, gen_loss = 0.9475813542174838, disc_loss = 0.0007061955917305435
Trained batch 419 in epoch 7, gen_loss = 0.9474872965188254, disc_loss = 0.0007054738051097264
Trained batch 420 in epoch 7, gen_loss = 0.9475704750085953, disc_loss = 0.0007043339355905139
Trained batch 421 in epoch 7, gen_loss = 0.9475298895372599, disc_loss = 0.0007032057274821528
Trained batch 422 in epoch 7, gen_loss = 0.9475323373262482, disc_loss = 0.0007023781301463617
Trained batch 423 in epoch 7, gen_loss = 0.9475836326491158, disc_loss = 0.0007018462923917708
Trained batch 424 in epoch 7, gen_loss = 0.947676142243778, disc_loss = 0.0007010103572461316
Trained batch 425 in epoch 7, gen_loss = 0.9477438842746574, disc_loss = 0.0006998702279781756
Trained batch 426 in epoch 7, gen_loss = 0.9478462189086986, disc_loss = 0.0006989693173438537
Trained batch 427 in epoch 7, gen_loss = 0.9478300081513752, disc_loss = 0.0006984761431535802
Trained batch 428 in epoch 7, gen_loss = 0.9480123915872374, disc_loss = 0.000698552808915927
Trained batch 429 in epoch 7, gen_loss = 0.9479157335536424, disc_loss = 0.0006992503153945341
Trained batch 430 in epoch 7, gen_loss = 0.9479632629319299, disc_loss = 0.0007000767192754705
Trained batch 431 in epoch 7, gen_loss = 0.9480203910282364, disc_loss = 0.0007005045088724863
Trained batch 432 in epoch 7, gen_loss = 0.9479804451966671, disc_loss = 0.0007006132246751131
Trained batch 433 in epoch 7, gen_loss = 0.9477017357052746, disc_loss = 0.0007003253213294099
Trained batch 434 in epoch 7, gen_loss = 0.9476489885100003, disc_loss = 0.0006998869976505166
Trained batch 435 in epoch 7, gen_loss = 0.947547064871963, disc_loss = 0.0006990061090018071
Trained batch 436 in epoch 7, gen_loss = 0.9477868807124873, disc_loss = 0.0006978034272721225
Trained batch 437 in epoch 7, gen_loss = 0.947782559890181, disc_loss = 0.0006965028587064268
Trained batch 438 in epoch 7, gen_loss = 0.9478446412195106, disc_loss = 0.0006951953231472128
Trained batch 439 in epoch 7, gen_loss = 0.9477778632532466, disc_loss = 0.0006939939802329966
Trained batch 440 in epoch 7, gen_loss = 0.9479463619439781, disc_loss = 0.0006931650586879776
Trained batch 441 in epoch 7, gen_loss = 0.9481430277565486, disc_loss = 0.000692213969735789
Trained batch 442 in epoch 7, gen_loss = 0.9481968521802743, disc_loss = 0.0006908845267393658
Trained batch 443 in epoch 7, gen_loss = 0.9482789083912566, disc_loss = 0.0006899275430695779
Trained batch 444 in epoch 7, gen_loss = 0.9483348658915316, disc_loss = 0.0006891109599676925
Trained batch 445 in epoch 7, gen_loss = 0.9481960703439242, disc_loss = 0.0006880401960608545
Trained batch 446 in epoch 7, gen_loss = 0.948219297982969, disc_loss = 0.0006868745114001127
Trained batch 447 in epoch 7, gen_loss = 0.9482314533420971, disc_loss = 0.000685761384180036
Trained batch 448 in epoch 7, gen_loss = 0.9481457830271901, disc_loss = 0.0006846760424983922
Trained batch 449 in epoch 7, gen_loss = 0.948109650876787, disc_loss = 0.0006834911685372289
Trained batch 450 in epoch 7, gen_loss = 0.948104599891375, disc_loss = 0.0006822189993253174
Trained batch 451 in epoch 7, gen_loss = 0.9480705659473891, disc_loss = 0.0006809052753199635
Trained batch 452 in epoch 7, gen_loss = 0.9479437392805322, disc_loss = 0.0006796918025377276
Trained batch 453 in epoch 7, gen_loss = 0.9481085974739512, disc_loss = 0.0006789113610470308
Trained batch 454 in epoch 7, gen_loss = 0.9481381253881769, disc_loss = 0.0006780308194920308
Trained batch 455 in epoch 7, gen_loss = 0.9480750686243961, disc_loss = 0.0006768211096482047
Trained batch 456 in epoch 7, gen_loss = 0.9481854376177298, disc_loss = 0.0006758058966356288
Trained batch 457 in epoch 7, gen_loss = 0.9483096136276379, disc_loss = 0.0006749031737345875
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.8979040384292603, disc_loss = 0.00027595547726377845
Trained batch 1 in epoch 8, gen_loss = 0.930223286151886, disc_loss = 0.0003875355760101229
Trained batch 2 in epoch 8, gen_loss = 0.9573042790095011, disc_loss = 0.000399837347989281
Trained batch 3 in epoch 8, gen_loss = 0.940260574221611, disc_loss = 0.00035955813655164093
Trained batch 4 in epoch 8, gen_loss = 0.9197527766227722, disc_loss = 0.00032371586130466314
Trained batch 5 in epoch 8, gen_loss = 0.9228101670742035, disc_loss = 0.0002985089037489767
Trained batch 6 in epoch 8, gen_loss = 0.92179822070258, disc_loss = 0.00029344260526288835
Trained batch 7 in epoch 8, gen_loss = 0.9344518408179283, disc_loss = 0.0002845590224751504
Trained batch 8 in epoch 8, gen_loss = 0.9381056427955627, disc_loss = 0.00027804354289805307
Trained batch 9 in epoch 8, gen_loss = 0.926830381155014, disc_loss = 0.00027110260125482453
Trained batch 10 in epoch 8, gen_loss = 0.930483801798387, disc_loss = 0.000268783043297431
Trained batch 11 in epoch 8, gen_loss = 0.9187761495510737, disc_loss = 0.0003214717908122111
Trained batch 12 in epoch 8, gen_loss = 0.9223321217757005, disc_loss = 0.0004246894330628073
Trained batch 13 in epoch 8, gen_loss = 0.9240417906216213, disc_loss = 0.0005247228452520046
Trained batch 14 in epoch 8, gen_loss = 0.9297649780909221, disc_loss = 0.0005614182203620052
Trained batch 15 in epoch 8, gen_loss = 0.9312979429960251, disc_loss = 0.0005911898833801388
Trained batch 16 in epoch 8, gen_loss = 0.9294519354315365, disc_loss = 0.0006164935244562323
Trained batch 17 in epoch 8, gen_loss = 0.9285472962591383, disc_loss = 0.0006203124576131813
Trained batch 18 in epoch 8, gen_loss = 0.9254140665656642, disc_loss = 0.0006135058134340829
Trained batch 19 in epoch 8, gen_loss = 0.9251352697610855, disc_loss = 0.0006081276944314596
Trained batch 20 in epoch 8, gen_loss = 0.925702745006198, disc_loss = 0.000602315200099145
Trained batch 21 in epoch 8, gen_loss = 0.9285872741179033, disc_loss = 0.0005926907622117803
Trained batch 22 in epoch 8, gen_loss = 0.930252088152844, disc_loss = 0.0005826444267649608
Trained batch 23 in epoch 8, gen_loss = 0.9312104235092798, disc_loss = 0.0005697244214388775
Trained batch 24 in epoch 8, gen_loss = 0.930752317905426, disc_loss = 0.0005607879330636933
Trained batch 25 in epoch 8, gen_loss = 0.9310898734973028, disc_loss = 0.0005504949653046564
Trained batch 26 in epoch 8, gen_loss = 0.9297875938592134, disc_loss = 0.0005376686830358165
Trained batch 27 in epoch 8, gen_loss = 0.9319906724350793, disc_loss = 0.0005278469132982926
Trained batch 28 in epoch 8, gen_loss = 0.9308924613327816, disc_loss = 0.0005269960318651885
Trained batch 29 in epoch 8, gen_loss = 0.9327069858709971, disc_loss = 0.0005366450520038294
Trained batch 30 in epoch 8, gen_loss = 0.9302180370976848, disc_loss = 0.0005567160265092107
Trained batch 31 in epoch 8, gen_loss = 0.9324550088495016, disc_loss = 0.0005802714072160597
Trained batch 32 in epoch 8, gen_loss = 0.9306744409329963, disc_loss = 0.000601097602294899
Trained batch 33 in epoch 8, gen_loss = 0.9318608624093673, disc_loss = 0.0006210251419414656
Trained batch 34 in epoch 8, gen_loss = 0.9325657180377416, disc_loss = 0.0006363298972636196
Trained batch 35 in epoch 8, gen_loss = 0.9316129436095556, disc_loss = 0.0006484924908565719
Trained batch 36 in epoch 8, gen_loss = 0.9333432348998817, disc_loss = 0.0006617729082495931
Trained batch 37 in epoch 8, gen_loss = 0.9344226263071361, disc_loss = 0.0006729609353657763
Trained batch 38 in epoch 8, gen_loss = 0.9348755448292463, disc_loss = 0.000681562495092527
Trained batch 39 in epoch 8, gen_loss = 0.9355635464191436, disc_loss = 0.0006889039050292922
Trained batch 40 in epoch 8, gen_loss = 0.934573670712913, disc_loss = 0.000699204515890082
Trained batch 41 in epoch 8, gen_loss = 0.9368751077424913, disc_loss = 0.000714390802992663
Trained batch 42 in epoch 8, gen_loss = 0.9365401642267094, disc_loss = 0.0007282483515324244
Trained batch 43 in epoch 8, gen_loss = 0.9378097477284345, disc_loss = 0.0007340879988491492
Trained batch 44 in epoch 8, gen_loss = 0.93795155816608, disc_loss = 0.0007310984006229167
Trained batch 45 in epoch 8, gen_loss = 0.9400968720083651, disc_loss = 0.0007260725956850523
Trained batch 46 in epoch 8, gen_loss = 0.9433174602528835, disc_loss = 0.0007199407230066928
Trained batch 47 in epoch 8, gen_loss = 0.9437180496752262, disc_loss = 0.0007085931535281512
Trained batch 48 in epoch 8, gen_loss = 0.9442534872463771, disc_loss = 0.0006965260322524083
Trained batch 49 in epoch 8, gen_loss = 0.9432830035686492, disc_loss = 0.000686012588266749
Trained batch 50 in epoch 8, gen_loss = 0.9421076096740424, disc_loss = 0.0006756595610960515
Trained batch 51 in epoch 8, gen_loss = 0.9441671440234551, disc_loss = 0.0006654823493870656
Trained batch 52 in epoch 8, gen_loss = 0.9449074650710484, disc_loss = 0.0006575902618076828
Trained batch 53 in epoch 8, gen_loss = 0.9447433838137874, disc_loss = 0.0006539513811326793
Trained batch 54 in epoch 8, gen_loss = 0.9465332508087159, disc_loss = 0.0006546633675249971
Trained batch 55 in epoch 8, gen_loss = 0.9471672368901116, disc_loss = 0.0006538789319685227
Trained batch 56 in epoch 8, gen_loss = 0.9483072611323574, disc_loss = 0.0006469328948521268
Trained batch 57 in epoch 8, gen_loss = 0.9475948060381001, disc_loss = 0.000641808313456091
Trained batch 58 in epoch 8, gen_loss = 0.9476990366386155, disc_loss = 0.0006460492477961421
Trained batch 59 in epoch 8, gen_loss = 0.9480773458878199, disc_loss = 0.0006532516682151861
Trained batch 60 in epoch 8, gen_loss = 0.9474122612202753, disc_loss = 0.0006535723941404465
Trained batch 61 in epoch 8, gen_loss = 0.949342974731999, disc_loss = 0.0006489628175322357
Trained batch 62 in epoch 8, gen_loss = 0.9491305777004787, disc_loss = 0.0006445961321116469
Trained batch 63 in epoch 8, gen_loss = 0.9471388021484017, disc_loss = 0.0006473152345733979
Trained batch 64 in epoch 8, gen_loss = 0.9475667687562795, disc_loss = 0.0006503269732302914
Trained batch 65 in epoch 8, gen_loss = 0.9467301558364521, disc_loss = 0.0006438453990884943
Trained batch 66 in epoch 8, gen_loss = 0.9469067151866742, disc_loss = 0.0006433369501914356
Trained batch 67 in epoch 8, gen_loss = 0.947498148855041, disc_loss = 0.0006447499816953068
Trained batch 68 in epoch 8, gen_loss = 0.9472688721573871, disc_loss = 0.000641957495025818
Trained batch 69 in epoch 8, gen_loss = 0.9473395764827728, disc_loss = 0.000635071966722275
Trained batch 70 in epoch 8, gen_loss = 0.9477577763544002, disc_loss = 0.0006283507251974301
Trained batch 71 in epoch 8, gen_loss = 0.9479184597730637, disc_loss = 0.0006214891808566689
Trained batch 72 in epoch 8, gen_loss = 0.9470617264917452, disc_loss = 0.0006156943484101036
Trained batch 73 in epoch 8, gen_loss = 0.9471235782713503, disc_loss = 0.0006244787525517766
Trained batch 74 in epoch 8, gen_loss = 0.9473907883961995, disc_loss = 0.0006676499751241256
Trained batch 75 in epoch 8, gen_loss = 0.9490076585819847, disc_loss = 0.0007376157526251566
Trained batch 76 in epoch 8, gen_loss = 0.9491688152412315, disc_loss = 0.0008086935188409618
Trained batch 77 in epoch 8, gen_loss = 0.9482915661273859, disc_loss = 0.0008652954834710377
Trained batch 78 in epoch 8, gen_loss = 0.9487209440786627, disc_loss = 0.0009056146428301411
Trained batch 79 in epoch 8, gen_loss = 0.9481180876493454, disc_loss = 0.0009244424309144961
Trained batch 80 in epoch 8, gen_loss = 0.9478730368025509, disc_loss = 0.0009267616296261779
Trained batch 81 in epoch 8, gen_loss = 0.9474240199821752, disc_loss = 0.0009213550241306288
Trained batch 82 in epoch 8, gen_loss = 0.946907426937517, disc_loss = 0.0009149799189328339
Trained batch 83 in epoch 8, gen_loss = 0.9471451242764791, disc_loss = 0.0009089402571719672
Trained batch 84 in epoch 8, gen_loss = 0.9462784844286302, disc_loss = 0.0009036417037029476
Trained batch 85 in epoch 8, gen_loss = 0.9457632698291956, disc_loss = 0.0008973172107077918
Trained batch 86 in epoch 8, gen_loss = 0.946430592016242, disc_loss = 0.0008946278185353497
Trained batch 87 in epoch 8, gen_loss = 0.9468552456660704, disc_loss = 0.0008975475565503901
Trained batch 88 in epoch 8, gen_loss = 0.9457393871264511, disc_loss = 0.0009022018374493241
Trained batch 89 in epoch 8, gen_loss = 0.945539903640747, disc_loss = 0.0009084875679238596
Trained batch 90 in epoch 8, gen_loss = 0.9453878376510118, disc_loss = 0.0009126375889236741
Trained batch 91 in epoch 8, gen_loss = 0.9458213701196339, disc_loss = 0.0009169205273476267
Trained batch 92 in epoch 8, gen_loss = 0.9449738283311168, disc_loss = 0.0009245260663065178
Trained batch 93 in epoch 8, gen_loss = 0.9447231394179324, disc_loss = 0.0009371310362884616
Trained batch 94 in epoch 8, gen_loss = 0.9443522804661801, disc_loss = 0.0009489083720836788
Trained batch 95 in epoch 8, gen_loss = 0.9442372440050045, disc_loss = 0.000959691767093318
Trained batch 96 in epoch 8, gen_loss = 0.9441085138271764, disc_loss = 0.0009684298933392448
Trained batch 97 in epoch 8, gen_loss = 0.9440919373716626, disc_loss = 0.0009724245194645066
Trained batch 98 in epoch 8, gen_loss = 0.9438462823328345, disc_loss = 0.0009734436744386612
Trained batch 99 in epoch 8, gen_loss = 0.9442153680324554, disc_loss = 0.0009735466816346161
Trained batch 100 in epoch 8, gen_loss = 0.9443286574713075, disc_loss = 0.0009716801609876243
Trained batch 101 in epoch 8, gen_loss = 0.9452825141888038, disc_loss = 0.0009677746591692352
Trained batch 102 in epoch 8, gen_loss = 0.9454010725021362, disc_loss = 0.0009628641568870256
Trained batch 103 in epoch 8, gen_loss = 0.9460061341524124, disc_loss = 0.0009576762509263622
Trained batch 104 in epoch 8, gen_loss = 0.9462793520518712, disc_loss = 0.0009522156182876123
Trained batch 105 in epoch 8, gen_loss = 0.9461247105643434, disc_loss = 0.0009467744184460245
Trained batch 106 in epoch 8, gen_loss = 0.9465324054254549, disc_loss = 0.0009410619236872679
Trained batch 107 in epoch 8, gen_loss = 0.9461966101770047, disc_loss = 0.0009359895972280625
Trained batch 108 in epoch 8, gen_loss = 0.9463806425759552, disc_loss = 0.0009315426986335581
Trained batch 109 in epoch 8, gen_loss = 0.9460963769392534, disc_loss = 0.0009267855163092132
Trained batch 110 in epoch 8, gen_loss = 0.9459344041240108, disc_loss = 0.0009238393754417261
Trained batch 111 in epoch 8, gen_loss = 0.9456501741494451, disc_loss = 0.0009210978982342308
Trained batch 112 in epoch 8, gen_loss = 0.9458797315580655, disc_loss = 0.0009173930427409807
Trained batch 113 in epoch 8, gen_loss = 0.9461437035025212, disc_loss = 0.0009138773140812031
Trained batch 114 in epoch 8, gen_loss = 0.9454999306927556, disc_loss = 0.0009104181736525472
Trained batch 115 in epoch 8, gen_loss = 0.9450010693278806, disc_loss = 0.0009073286614850452
Trained batch 116 in epoch 8, gen_loss = 0.944807842755929, disc_loss = 0.0009051361258050157
Trained batch 117 in epoch 8, gen_loss = 0.9450414872775643, disc_loss = 0.0009044400932784271
Trained batch 118 in epoch 8, gen_loss = 0.9451909380800584, disc_loss = 0.0009036603026158575
Trained batch 119 in epoch 8, gen_loss = 0.9442549313108126, disc_loss = 0.0009003828466423632
Trained batch 120 in epoch 8, gen_loss = 0.9447348378906565, disc_loss = 0.0008957018129997079
Trained batch 121 in epoch 8, gen_loss = 0.9438181201942631, disc_loss = 0.000893098479194078
Trained batch 122 in epoch 8, gen_loss = 0.944340761599502, disc_loss = 0.0009007893660772076
Trained batch 123 in epoch 8, gen_loss = 0.944750145558388, disc_loss = 0.0009172631652026828
Trained batch 124 in epoch 8, gen_loss = 0.9439702634811401, disc_loss = 0.0009293149500153959
Trained batch 125 in epoch 8, gen_loss = 0.9439696461435348, disc_loss = 0.0009339897554286475
Trained batch 126 in epoch 8, gen_loss = 0.944574714645626, disc_loss = 0.0009340213595222184
Trained batch 127 in epoch 8, gen_loss = 0.944643790833652, disc_loss = 0.0009327193984063342
Trained batch 128 in epoch 8, gen_loss = 0.9448882637097854, disc_loss = 0.0009299247618584151
Trained batch 129 in epoch 8, gen_loss = 0.9455042481422424, disc_loss = 0.0009250383638293268
Trained batch 130 in epoch 8, gen_loss = 0.945440212733873, disc_loss = 0.0009197226715743371
Trained batch 131 in epoch 8, gen_loss = 0.9460715141260263, disc_loss = 0.0009165800253289159
Trained batch 132 in epoch 8, gen_loss = 0.9464314544111266, disc_loss = 0.0009132094398540046
Trained batch 133 in epoch 8, gen_loss = 0.9466371611872716, disc_loss = 0.0009081362113104647
Trained batch 134 in epoch 8, gen_loss = 0.9463486340310838, disc_loss = 0.0009031677119545983
Trained batch 135 in epoch 8, gen_loss = 0.9467810423058622, disc_loss = 0.0008985603140257916
Trained batch 136 in epoch 8, gen_loss = 0.9464253513482366, disc_loss = 0.0008940503916178021
Trained batch 137 in epoch 8, gen_loss = 0.9469585457573766, disc_loss = 0.0008923460279576196
Trained batch 138 in epoch 8, gen_loss = 0.9471905012782529, disc_loss = 0.0008916422943944755
Trained batch 139 in epoch 8, gen_loss = 0.9472304493188858, disc_loss = 0.0008902065205412717
Trained batch 140 in epoch 8, gen_loss = 0.9470188317569435, disc_loss = 0.0008881669746445994
Trained batch 141 in epoch 8, gen_loss = 0.9470177145910935, disc_loss = 0.0008874617980811155
Trained batch 142 in epoch 8, gen_loss = 0.9465243424568976, disc_loss = 0.000889300167950528
Trained batch 143 in epoch 8, gen_loss = 0.9468665114707417, disc_loss = 0.0008906635188799959
Trained batch 144 in epoch 8, gen_loss = 0.9466707233724923, disc_loss = 0.0008882924949485359
Trained batch 145 in epoch 8, gen_loss = 0.9468258917331696, disc_loss = 0.0008841089648952108
Trained batch 146 in epoch 8, gen_loss = 0.9468461481892333, disc_loss = 0.0008802109960819829
Trained batch 147 in epoch 8, gen_loss = 0.9467840754502529, disc_loss = 0.0008781903046395668
Trained batch 148 in epoch 8, gen_loss = 0.947144831186973, disc_loss = 0.000877677686742957
Trained batch 149 in epoch 8, gen_loss = 0.9469784259796142, disc_loss = 0.0008754000474194375
Trained batch 150 in epoch 8, gen_loss = 0.9468875223437682, disc_loss = 0.0008708594396011904
Trained batch 151 in epoch 8, gen_loss = 0.9465160009108091, disc_loss = 0.0008659402427790491
Trained batch 152 in epoch 8, gen_loss = 0.9458450764612435, disc_loss = 0.0008612810670218607
Trained batch 153 in epoch 8, gen_loss = 0.9456363777061562, disc_loss = 0.0008567925433926103
Trained batch 154 in epoch 8, gen_loss = 0.9456659478525962, disc_loss = 0.0008524960248670992
Trained batch 155 in epoch 8, gen_loss = 0.9456257220262136, disc_loss = 0.0008485258780964591
Trained batch 156 in epoch 8, gen_loss = 0.945883162462028, disc_loss = 0.0008451593275127079
Trained batch 157 in epoch 8, gen_loss = 0.9454926576795457, disc_loss = 0.0008411998860538006
Trained batch 158 in epoch 8, gen_loss = 0.9456234015758682, disc_loss = 0.0008371027356559856
Trained batch 159 in epoch 8, gen_loss = 0.9457052439451218, disc_loss = 0.0008328657183483302
Trained batch 160 in epoch 8, gen_loss = 0.945718634943044, disc_loss = 0.0008294069312508536
Trained batch 161 in epoch 8, gen_loss = 0.9463319101451356, disc_loss = 0.0008268523744823423
Trained batch 162 in epoch 8, gen_loss = 0.9463613691505479, disc_loss = 0.0008239387562234195
Trained batch 163 in epoch 8, gen_loss = 0.9465758956787063, disc_loss = 0.0008205737379662091
Trained batch 164 in epoch 8, gen_loss = 0.946903138810938, disc_loss = 0.0008169636308483667
Trained batch 165 in epoch 8, gen_loss = 0.9466931981494627, disc_loss = 0.0008138825991387333
Trained batch 166 in epoch 8, gen_loss = 0.9465177562422381, disc_loss = 0.0008109805322653742
Trained batch 167 in epoch 8, gen_loss = 0.9462408082825797, disc_loss = 0.0008072903036095557
Trained batch 168 in epoch 8, gen_loss = 0.9465974816203823, disc_loss = 0.0008035511280941783
Trained batch 169 in epoch 8, gen_loss = 0.9464756681638605, disc_loss = 0.0008004107567317346
Trained batch 170 in epoch 8, gen_loss = 0.946356879688843, disc_loss = 0.0007980299364007486
Trained batch 171 in epoch 8, gen_loss = 0.946234503111174, disc_loss = 0.0007969263083501827
Trained batch 172 in epoch 8, gen_loss = 0.9458557505139037, disc_loss = 0.0007956359401544437
Trained batch 173 in epoch 8, gen_loss = 0.9452709699499195, disc_loss = 0.0007932928424922686
Trained batch 174 in epoch 8, gen_loss = 0.9451953598431179, disc_loss = 0.0007905930663192911
Trained batch 175 in epoch 8, gen_loss = 0.9453394402834502, disc_loss = 0.0007882915646901397
Trained batch 176 in epoch 8, gen_loss = 0.9451044824837291, disc_loss = 0.0007869116001694048
Trained batch 177 in epoch 8, gen_loss = 0.9455560084139363, disc_loss = 0.0007863515295386523
Trained batch 178 in epoch 8, gen_loss = 0.9457600090090789, disc_loss = 0.0007843497859941036
Trained batch 179 in epoch 8, gen_loss = 0.9453498866822985, disc_loss = 0.0007814260964450013
Trained batch 180 in epoch 8, gen_loss = 0.9451018239253134, disc_loss = 0.0007780963646309728
Trained batch 181 in epoch 8, gen_loss = 0.9451082695971479, disc_loss = 0.000774712775127737
Trained batch 182 in epoch 8, gen_loss = 0.9449330613912781, disc_loss = 0.0007713917310284756
Trained batch 183 in epoch 8, gen_loss = 0.9444939811592516, disc_loss = 0.0007679131746123818
Trained batch 184 in epoch 8, gen_loss = 0.9443687574283497, disc_loss = 0.0007654295105493401
Trained batch 185 in epoch 8, gen_loss = 0.9444834602776394, disc_loss = 0.0007643208655770317
Trained batch 186 in epoch 8, gen_loss = 0.9442477691619792, disc_loss = 0.000762764925468977
Trained batch 187 in epoch 8, gen_loss = 0.9437565055299313, disc_loss = 0.0007605052151701146
Trained batch 188 in epoch 8, gen_loss = 0.9434700270809194, disc_loss = 0.0007580094475689635
Trained batch 189 in epoch 8, gen_loss = 0.9435515394336299, disc_loss = 0.0007550364479692162
Trained batch 190 in epoch 8, gen_loss = 0.9437360804118411, disc_loss = 0.0007517936250014494
Trained batch 191 in epoch 8, gen_loss = 0.9435060704126954, disc_loss = 0.0007487331095035188
Trained batch 192 in epoch 8, gen_loss = 0.9432174427521661, disc_loss = 0.0007465403800567255
Trained batch 193 in epoch 8, gen_loss = 0.9437257896379098, disc_loss = 0.0007445948305251749
Trained batch 194 in epoch 8, gen_loss = 0.9439520988708887, disc_loss = 0.0007424807496882307
Trained batch 195 in epoch 8, gen_loss = 0.943903067282268, disc_loss = 0.000740488770338279
Trained batch 196 in epoch 8, gen_loss = 0.9436069490945884, disc_loss = 0.0007382762399123896
Trained batch 197 in epoch 8, gen_loss = 0.943863003542929, disc_loss = 0.0007355378373617758
Trained batch 198 in epoch 8, gen_loss = 0.944180702444297, disc_loss = 0.0007328508106170306
Trained batch 199 in epoch 8, gen_loss = 0.9443487709760666, disc_loss = 0.0007307060640596319
Trained batch 200 in epoch 8, gen_loss = 0.9445336084460738, disc_loss = 0.0007298258360561021
Trained batch 201 in epoch 8, gen_loss = 0.9447052381416359, disc_loss = 0.000729636558461796
Trained batch 202 in epoch 8, gen_loss = 0.9450257749393068, disc_loss = 0.0007294205900825321
Trained batch 203 in epoch 8, gen_loss = 0.9453271402447831, disc_loss = 0.0007284062553035077
Trained batch 204 in epoch 8, gen_loss = 0.9455553214724471, disc_loss = 0.0007268830516273383
Trained batch 205 in epoch 8, gen_loss = 0.9458043832802078, disc_loss = 0.0007247115781777131
Trained batch 206 in epoch 8, gen_loss = 0.9455671843123321, disc_loss = 0.0007225694785801162
Trained batch 207 in epoch 8, gen_loss = 0.9451656630979135, disc_loss = 0.0007201916633465982
Trained batch 208 in epoch 8, gen_loss = 0.9447725885792783, disc_loss = 0.0007174645044922196
Trained batch 209 in epoch 8, gen_loss = 0.9451828633035932, disc_loss = 0.0007149528138272996
Trained batch 210 in epoch 8, gen_loss = 0.9448085752143679, disc_loss = 0.0007130750308753437
Trained batch 211 in epoch 8, gen_loss = 0.9450127516152724, disc_loss = 0.0007121783556561601
Trained batch 212 in epoch 8, gen_loss = 0.9450489428121719, disc_loss = 0.0007107828234370466
Trained batch 213 in epoch 8, gen_loss = 0.9448925432200744, disc_loss = 0.0007084712570274214
Trained batch 214 in epoch 8, gen_loss = 0.9452237597731656, disc_loss = 0.0007061509058139352
Trained batch 215 in epoch 8, gen_loss = 0.9449773930289127, disc_loss = 0.000704222968192038
Trained batch 216 in epoch 8, gen_loss = 0.9450214002538936, disc_loss = 0.0007027087732881291
Trained batch 217 in epoch 8, gen_loss = 0.9446692578836319, disc_loss = 0.0007025476494631004
Trained batch 218 in epoch 8, gen_loss = 0.9449345992036062, disc_loss = 0.0007043383146697851
Trained batch 219 in epoch 8, gen_loss = 0.9450083464384079, disc_loss = 0.0007068292956153693
Trained batch 220 in epoch 8, gen_loss = 0.944580426313219, disc_loss = 0.0007092955776930648
Trained batch 221 in epoch 8, gen_loss = 0.9444353910716804, disc_loss = 0.0007144395939256945
Trained batch 222 in epoch 8, gen_loss = 0.9443170850586998, disc_loss = 0.0007203704088398009
Trained batch 223 in epoch 8, gen_loss = 0.9440958185919693, disc_loss = 0.0007240774293677532
Trained batch 224 in epoch 8, gen_loss = 0.943843788570828, disc_loss = 0.0007253464160021394
Trained batch 225 in epoch 8, gen_loss = 0.9439485703421905, disc_loss = 0.0007254997590521713
Trained batch 226 in epoch 8, gen_loss = 0.9440008609305395, disc_loss = 0.0007246763057984198
Trained batch 227 in epoch 8, gen_loss = 0.9441651244435394, disc_loss = 0.0007236074461456666
Trained batch 228 in epoch 8, gen_loss = 0.9440379158378168, disc_loss = 0.000721819754730601
Trained batch 229 in epoch 8, gen_loss = 0.9439353046209916, disc_loss = 0.0007194055122849733
Trained batch 230 in epoch 8, gen_loss = 0.9434966883618078, disc_loss = 0.0007173067433265687
Trained batch 231 in epoch 8, gen_loss = 0.9434338391854845, disc_loss = 0.0007158816100353102
Trained batch 232 in epoch 8, gen_loss = 0.9435837025806116, disc_loss = 0.0007140178658325993
Trained batch 233 in epoch 8, gen_loss = 0.9437345763047537, disc_loss = 0.00071158940017295
Trained batch 234 in epoch 8, gen_loss = 0.9437526611571616, disc_loss = 0.0007095919440852161
Trained batch 235 in epoch 8, gen_loss = 0.9438629142813764, disc_loss = 0.000707890660246988
Trained batch 236 in epoch 8, gen_loss = 0.9442588339878034, disc_loss = 0.000706856218763462
Trained batch 237 in epoch 8, gen_loss = 0.9448556321508744, disc_loss = 0.0007061744095956194
Trained batch 238 in epoch 8, gen_loss = 0.9449207904947353, disc_loss = 0.0007053396532922851
Trained batch 239 in epoch 8, gen_loss = 0.9450828475256761, disc_loss = 0.0007040267730796283
Trained batch 240 in epoch 8, gen_loss = 0.9452859979447488, disc_loss = 0.0007029156224378017
Trained batch 241 in epoch 8, gen_loss = 0.9451521231123239, disc_loss = 0.0007027032851142431
Trained batch 242 in epoch 8, gen_loss = 0.9450898634062873, disc_loss = 0.0007028512869517936
Trained batch 243 in epoch 8, gen_loss = 0.9449754203440713, disc_loss = 0.0007023426020526533
Trained batch 244 in epoch 8, gen_loss = 0.9447901859575388, disc_loss = 0.0007011666728245398
Trained batch 245 in epoch 8, gen_loss = 0.9444103827321433, disc_loss = 0.0006997007993168228
Trained batch 246 in epoch 8, gen_loss = 0.9443767886412772, disc_loss = 0.0006988232764806636
Trained batch 247 in epoch 8, gen_loss = 0.9442355245832474, disc_loss = 0.0006982362600894938
Trained batch 248 in epoch 8, gen_loss = 0.9445263125810278, disc_loss = 0.0006979617023589015
Trained batch 249 in epoch 8, gen_loss = 0.9444381036758422, disc_loss = 0.0006975112652289681
Trained batch 250 in epoch 8, gen_loss = 0.944549185583791, disc_loss = 0.000696356821491242
Trained batch 251 in epoch 8, gen_loss = 0.9446398332005456, disc_loss = 0.0006946763241435364
Trained batch 252 in epoch 8, gen_loss = 0.9446875848788989, disc_loss = 0.0006931645365127292
Trained batch 253 in epoch 8, gen_loss = 0.9449804305560946, disc_loss = 0.0006922516563570853
Trained batch 254 in epoch 8, gen_loss = 0.945134325354707, disc_loss = 0.0006918865989313881
Trained batch 255 in epoch 8, gen_loss = 0.945050333859399, disc_loss = 0.0006917643289057196
Trained batch 256 in epoch 8, gen_loss = 0.9451459407342547, disc_loss = 0.0006917985281313621
Trained batch 257 in epoch 8, gen_loss = 0.9449570708034575, disc_loss = 0.0006918784264450741
Trained batch 258 in epoch 8, gen_loss = 0.9446674164197619, disc_loss = 0.0006919604873677543
Trained batch 259 in epoch 8, gen_loss = 0.9444415227724956, disc_loss = 0.0006918839463861122
Trained batch 260 in epoch 8, gen_loss = 0.9444488211609852, disc_loss = 0.0006920245333447146
Trained batch 261 in epoch 8, gen_loss = 0.9444513978393934, disc_loss = 0.0006920972111735329
Trained batch 262 in epoch 8, gen_loss = 0.9444986157997479, disc_loss = 0.0006913597208731932
Trained batch 263 in epoch 8, gen_loss = 0.9450240358710289, disc_loss = 0.0006898670105301514
Trained batch 264 in epoch 8, gen_loss = 0.9450977599845742, disc_loss = 0.0006883337728586927
Trained batch 265 in epoch 8, gen_loss = 0.9452441085998277, disc_loss = 0.0006877583318851237
Trained batch 266 in epoch 8, gen_loss = 0.9449031536052289, disc_loss = 0.0006878860102428389
Trained batch 267 in epoch 8, gen_loss = 0.9449142159810707, disc_loss = 0.00068805083529737
Trained batch 268 in epoch 8, gen_loss = 0.9447665190164928, disc_loss = 0.000687954002343461
Trained batch 269 in epoch 8, gen_loss = 0.9447138636200516, disc_loss = 0.0006874385356139909
Trained batch 270 in epoch 8, gen_loss = 0.9446847803918198, disc_loss = 0.0006866038839115394
Trained batch 271 in epoch 8, gen_loss = 0.9446385960806819, disc_loss = 0.0006851486955116236
Trained batch 272 in epoch 8, gen_loss = 0.9444679526182321, disc_loss = 0.0006838143135710098
Trained batch 273 in epoch 8, gen_loss = 0.9448045668375753, disc_loss = 0.0006822617802608343
Trained batch 274 in epoch 8, gen_loss = 0.944540500424125, disc_loss = 0.0006804946779844944
Trained batch 275 in epoch 8, gen_loss = 0.9442891415910445, disc_loss = 0.0006788208665439279
Trained batch 276 in epoch 8, gen_loss = 0.9445300194760953, disc_loss = 0.0006773264557316509
Trained batch 277 in epoch 8, gen_loss = 0.9445941431059254, disc_loss = 0.0006762267938997637
Trained batch 278 in epoch 8, gen_loss = 0.9444808750596952, disc_loss = 0.0006751454728204877
Trained batch 279 in epoch 8, gen_loss = 0.944884238924299, disc_loss = 0.0006741846476091139
Trained batch 280 in epoch 8, gen_loss = 0.944816816956123, disc_loss = 0.0006738412969710895
Trained batch 281 in epoch 8, gen_loss = 0.9446232610560478, disc_loss = 0.0006741493171888423
Trained batch 282 in epoch 8, gen_loss = 0.9447304515872322, disc_loss = 0.0006738840373004244
Trained batch 283 in epoch 8, gen_loss = 0.9446251081748748, disc_loss = 0.0006732239565626771
Trained batch 284 in epoch 8, gen_loss = 0.944639653908579, disc_loss = 0.0006727343742743854
Trained batch 285 in epoch 8, gen_loss = 0.9445175584796426, disc_loss = 0.0006727689714944381
Trained batch 286 in epoch 8, gen_loss = 0.9443682218262542, disc_loss = 0.0006740439531291131
Trained batch 287 in epoch 8, gen_loss = 0.9442290185640255, disc_loss = 0.0006767779166491689
Trained batch 288 in epoch 8, gen_loss = 0.9444885338466472, disc_loss = 0.0006817710938562146
Trained batch 289 in epoch 8, gen_loss = 0.944688559195091, disc_loss = 0.0006896409257274956
Trained batch 290 in epoch 8, gen_loss = 0.9448404103210292, disc_loss = 0.0006989332037390597
Trained batch 291 in epoch 8, gen_loss = 0.9448831148751794, disc_loss = 0.0007054116882898922
Trained batch 292 in epoch 8, gen_loss = 0.944780319217122, disc_loss = 0.0007080210704768058
Trained batch 293 in epoch 8, gen_loss = 0.9448122998484138, disc_loss = 0.0007092847213027112
Trained batch 294 in epoch 8, gen_loss = 0.9448451753390037, disc_loss = 0.0007096566572603848
Trained batch 295 in epoch 8, gen_loss = 0.944680411469292, disc_loss = 0.0007089925506128615
Trained batch 296 in epoch 8, gen_loss = 0.944709614872531, disc_loss = 0.0007073608042259923
Trained batch 297 in epoch 8, gen_loss = 0.9449273051831546, disc_loss = 0.0007056037927805853
Trained batch 298 in epoch 8, gen_loss = 0.9447335162290362, disc_loss = 0.000703811986334108
Trained batch 299 in epoch 8, gen_loss = 0.9447939636309942, disc_loss = 0.0007024877481065535
Trained batch 300 in epoch 8, gen_loss = 0.9449000513038762, disc_loss = 0.0007028096816034529
Trained batch 301 in epoch 8, gen_loss = 0.944991387081462, disc_loss = 0.0007046527369082782
Trained batch 302 in epoch 8, gen_loss = 0.9449653359923033, disc_loss = 0.000707437001464953
Trained batch 303 in epoch 8, gen_loss = 0.9450919418350646, disc_loss = 0.0007090461684990595
Trained batch 304 in epoch 8, gen_loss = 0.945205210662279, disc_loss = 0.0007084946718246324
Trained batch 305 in epoch 8, gen_loss = 0.9450712977281583, disc_loss = 0.0007072941852741862
Trained batch 306 in epoch 8, gen_loss = 0.9449112986120417, disc_loss = 0.0007062855178808054
Trained batch 307 in epoch 8, gen_loss = 0.9449701914926628, disc_loss = 0.0007052319203242629
Trained batch 308 in epoch 8, gen_loss = 0.945094283923362, disc_loss = 0.000703847383834274
Trained batch 309 in epoch 8, gen_loss = 0.94507706876724, disc_loss = 0.0007020317043849988
Trained batch 310 in epoch 8, gen_loss = 0.9450909384193911, disc_loss = 0.0007001860141645596
Trained batch 311 in epoch 8, gen_loss = 0.9449946473424251, disc_loss = 0.0006986058137371378
Trained batch 312 in epoch 8, gen_loss = 0.9448120045585754, disc_loss = 0.0006969260658005836
Trained batch 313 in epoch 8, gen_loss = 0.9451536623535642, disc_loss = 0.0006955537573263127
Trained batch 314 in epoch 8, gen_loss = 0.9454693101701283, disc_loss = 0.0006941171239651296
Trained batch 315 in epoch 8, gen_loss = 0.9452409648065325, disc_loss = 0.0006924447638245706
Trained batch 316 in epoch 8, gen_loss = 0.9455913995342676, disc_loss = 0.0006914731094996336
Trained batch 317 in epoch 8, gen_loss = 0.9457905534303414, disc_loss = 0.000691671840051766
Trained batch 318 in epoch 8, gen_loss = 0.9460746459079012, disc_loss = 0.0006927179427088317
Trained batch 319 in epoch 8, gen_loss = 0.9461388932541013, disc_loss = 0.0006935917321698071
Trained batch 320 in epoch 8, gen_loss = 0.9459537115423851, disc_loss = 0.0006934324213875911
Trained batch 321 in epoch 8, gen_loss = 0.9458394159811624, disc_loss = 0.0006927387893828274
Trained batch 322 in epoch 8, gen_loss = 0.9458383246102938, disc_loss = 0.0006921047121974793
Trained batch 323 in epoch 8, gen_loss = 0.9457509935270121, disc_loss = 0.0006908712188485452
Trained batch 324 in epoch 8, gen_loss = 0.9456205523931063, disc_loss = 0.0006892009871080518
Trained batch 325 in epoch 8, gen_loss = 0.945466001889457, disc_loss = 0.0006873936057494285
Trained batch 326 in epoch 8, gen_loss = 0.9454563258255658, disc_loss = 0.0006855211182143567
Trained batch 327 in epoch 8, gen_loss = 0.9454427136153709, disc_loss = 0.0006836269614457084
Trained batch 328 in epoch 8, gen_loss = 0.945579117917, disc_loss = 0.0006818261611146928
Trained batch 329 in epoch 8, gen_loss = 0.9454010204835371, disc_loss = 0.0006800494978961069
Trained batch 330 in epoch 8, gen_loss = 0.9453548841245946, disc_loss = 0.0006783904472453551
Trained batch 331 in epoch 8, gen_loss = 0.9455674603042832, disc_loss = 0.000677022859674187
Trained batch 332 in epoch 8, gen_loss = 0.9456543725532096, disc_loss = 0.0006757864701957022
Trained batch 333 in epoch 8, gen_loss = 0.9457252498515352, disc_loss = 0.0006745946499256592
Trained batch 334 in epoch 8, gen_loss = 0.9458412293177932, disc_loss = 0.0006732102280001351
Trained batch 335 in epoch 8, gen_loss = 0.9457846473725069, disc_loss = 0.0006718886601923995
Trained batch 336 in epoch 8, gen_loss = 0.945725869177357, disc_loss = 0.0006706357216737123
Trained batch 337 in epoch 8, gen_loss = 0.9457717211641503, disc_loss = 0.000669095186703837
Trained batch 338 in epoch 8, gen_loss = 0.9456580356862341, disc_loss = 0.0006675468548055076
Trained batch 339 in epoch 8, gen_loss = 0.9454724490642548, disc_loss = 0.0006662473711056758
Trained batch 340 in epoch 8, gen_loss = 0.9456623037539619, disc_loss = 0.0006651342423338118
Trained batch 341 in epoch 8, gen_loss = 0.9458410715499119, disc_loss = 0.0006641769766263263
Trained batch 342 in epoch 8, gen_loss = 0.946126089846775, disc_loss = 0.0006636950221876939
Trained batch 343 in epoch 8, gen_loss = 0.9460238117811292, disc_loss = 0.0006632977180722031
Trained batch 344 in epoch 8, gen_loss = 0.9460775765819825, disc_loss = 0.0006627185249311404
Trained batch 345 in epoch 8, gen_loss = 0.945811595703136, disc_loss = 0.000661782759301145
Trained batch 346 in epoch 8, gen_loss = 0.9458354910787313, disc_loss = 0.0006604797543526053
Trained batch 347 in epoch 8, gen_loss = 0.9458732601554914, disc_loss = 0.0006590030370716704
Trained batch 348 in epoch 8, gen_loss = 0.9459491155209035, disc_loss = 0.0006574590314627641
Trained batch 349 in epoch 8, gen_loss = 0.9459889027050563, disc_loss = 0.0006560061928757932
Trained batch 350 in epoch 8, gen_loss = 0.946056907503014, disc_loss = 0.0006546019908779386
Trained batch 351 in epoch 8, gen_loss = 0.9462753617289391, disc_loss = 0.000653297754049411
Trained batch 352 in epoch 8, gen_loss = 0.9463178647138579, disc_loss = 0.0006519770406167783
Trained batch 353 in epoch 8, gen_loss = 0.9461767415879137, disc_loss = 0.0006506822200758069
Trained batch 354 in epoch 8, gen_loss = 0.9463416353077956, disc_loss = 0.0006495844026983217
Trained batch 355 in epoch 8, gen_loss = 0.946190128500542, disc_loss = 0.0006487321733698848
Trained batch 356 in epoch 8, gen_loss = 0.946198640417318, disc_loss = 0.0006483393642897796
Trained batch 357 in epoch 8, gen_loss = 0.946320329631507, disc_loss = 0.0006478453933545219
Trained batch 358 in epoch 8, gen_loss = 0.9463070245838431, disc_loss = 0.0006470442697878286
Trained batch 359 in epoch 8, gen_loss = 0.9463412856062253, disc_loss = 0.0006462282057529794
Trained batch 360 in epoch 8, gen_loss = 0.946332544666248, disc_loss = 0.0006453505971533804
Trained batch 361 in epoch 8, gen_loss = 0.9463734641588853, disc_loss = 0.0006444788826264516
Trained batch 362 in epoch 8, gen_loss = 0.9461341584024351, disc_loss = 0.0006431648521544604
Trained batch 363 in epoch 8, gen_loss = 0.9463814533018804, disc_loss = 0.0006417133476194007
Trained batch 364 in epoch 8, gen_loss = 0.946625991390176, disc_loss = 0.0006408493395150027
Trained batch 365 in epoch 8, gen_loss = 0.9466849063914982, disc_loss = 0.0006412717910259873
Trained batch 366 in epoch 8, gen_loss = 0.9465947341204339, disc_loss = 0.0006430344424746253
Trained batch 367 in epoch 8, gen_loss = 0.9467038533285909, disc_loss = 0.0006454867085148694
Trained batch 368 in epoch 8, gen_loss = 0.9467247669612812, disc_loss = 0.0006481494321268579
Trained batch 369 in epoch 8, gen_loss = 0.946546649610674, disc_loss = 0.0006497089282453777
Trained batch 370 in epoch 8, gen_loss = 0.9467343104817475, disc_loss = 0.0006502670376704983
Trained batch 371 in epoch 8, gen_loss = 0.946596064074065, disc_loss = 0.0006499394193494765
Trained batch 372 in epoch 8, gen_loss = 0.9468815171686638, disc_loss = 0.0006501000028625742
Trained batch 373 in epoch 8, gen_loss = 0.9464827248438157, disc_loss = 0.0006505178543373277
Trained batch 374 in epoch 8, gen_loss = 0.9464898567199707, disc_loss = 0.0006509999044743988
Trained batch 375 in epoch 8, gen_loss = 0.9463901218581707, disc_loss = 0.0006524650802833654
Trained batch 376 in epoch 8, gen_loss = 0.946288630089646, disc_loss = 0.0006537463848761021
Trained batch 377 in epoch 8, gen_loss = 0.9461541551130789, disc_loss = 0.0006557982897137418
Trained batch 378 in epoch 8, gen_loss = 0.9461592747227813, disc_loss = 0.0006595027080614496
Trained batch 379 in epoch 8, gen_loss = 0.9461893000100788, disc_loss = 0.0006640996755059429
Trained batch 380 in epoch 8, gen_loss = 0.9464151996952967, disc_loss = 0.0006680698532941433
Trained batch 381 in epoch 8, gen_loss = 0.9465136094243115, disc_loss = 0.0006710254974154016
Trained batch 382 in epoch 8, gen_loss = 0.9466269327517278, disc_loss = 0.0006730303269704286
Trained batch 383 in epoch 8, gen_loss = 0.9465189501643181, disc_loss = 0.0006740599487973972
Trained batch 384 in epoch 8, gen_loss = 0.9463765669178653, disc_loss = 0.0006748068937313646
Trained batch 385 in epoch 8, gen_loss = 0.9463684481660319, disc_loss = 0.0006753309609537637
Trained batch 386 in epoch 8, gen_loss = 0.9463234591545676, disc_loss = 0.0006751267990773936
Trained batch 387 in epoch 8, gen_loss = 0.9462124699169827, disc_loss = 0.0006743192370777251
Trained batch 388 in epoch 8, gen_loss = 0.9464021617771727, disc_loss = 0.0006736179519599426
Trained batch 389 in epoch 8, gen_loss = 0.9463576310720199, disc_loss = 0.0006730793872497414
Trained batch 390 in epoch 8, gen_loss = 0.9464418641136735, disc_loss = 0.0006725508341742287
Trained batch 391 in epoch 8, gen_loss = 0.9464592900203199, disc_loss = 0.0006719318728625824
Trained batch 392 in epoch 8, gen_loss = 0.9464176471603433, disc_loss = 0.0006713583166143767
Trained batch 393 in epoch 8, gen_loss = 0.9463825038241857, disc_loss = 0.0006709211451619884
Trained batch 394 in epoch 8, gen_loss = 0.9465365723718571, disc_loss = 0.0006705596121477517
Trained batch 395 in epoch 8, gen_loss = 0.9466475526792835, disc_loss = 0.0006700905493257457
Trained batch 396 in epoch 8, gen_loss = 0.9465964307412693, disc_loss = 0.0006692633636318374
Trained batch 397 in epoch 8, gen_loss = 0.9463148337213239, disc_loss = 0.0006681435804408402
Trained batch 398 in epoch 8, gen_loss = 0.9462280718605023, disc_loss = 0.0006670365615709647
Trained batch 399 in epoch 8, gen_loss = 0.9464331659674644, disc_loss = 0.0006659496179963753
Trained batch 400 in epoch 8, gen_loss = 0.9464019325903229, disc_loss = 0.0006647901252637027
Trained batch 401 in epoch 8, gen_loss = 0.9464401504886684, disc_loss = 0.0006636427687728646
Trained batch 402 in epoch 8, gen_loss = 0.9466966943764509, disc_loss = 0.000662682400149017
Trained batch 403 in epoch 8, gen_loss = 0.9466285631798281, disc_loss = 0.0006617718293338191
Trained batch 404 in epoch 8, gen_loss = 0.9467429038919049, disc_loss = 0.0006609313181898971
Trained batch 405 in epoch 8, gen_loss = 0.9466517476612711, disc_loss = 0.0006603362077118524
Trained batch 406 in epoch 8, gen_loss = 0.9467025654028909, disc_loss = 0.0006600769149408108
Trained batch 407 in epoch 8, gen_loss = 0.9467579875798786, disc_loss = 0.0006597278220486295
Trained batch 408 in epoch 8, gen_loss = 0.9466541301650349, disc_loss = 0.0006591717622458905
Trained batch 409 in epoch 8, gen_loss = 0.9468129857284266, disc_loss = 0.0006585986958071306
Trained batch 410 in epoch 8, gen_loss = 0.9468991833301647, disc_loss = 0.0006581929883484303
Trained batch 411 in epoch 8, gen_loss = 0.9467703808569213, disc_loss = 0.0006574949239417673
Trained batch 412 in epoch 8, gen_loss = 0.9467891306045846, disc_loss = 0.000656794221841614
Trained batch 413 in epoch 8, gen_loss = 0.9465157031149104, disc_loss = 0.0006570308774861267
Trained batch 414 in epoch 8, gen_loss = 0.9466252806675003, disc_loss = 0.0006581559094722405
Trained batch 415 in epoch 8, gen_loss = 0.9465601086043395, disc_loss = 0.000658380234321717
Trained batch 416 in epoch 8, gen_loss = 0.9464336497892293, disc_loss = 0.0006578852546174354
Trained batch 417 in epoch 8, gen_loss = 0.9465651890022333, disc_loss = 0.0006571338276074404
Trained batch 418 in epoch 8, gen_loss = 0.9467592821200879, disc_loss = 0.0006564852621244892
Trained batch 419 in epoch 8, gen_loss = 0.9468298226594924, disc_loss = 0.0006560219385781758
Trained batch 420 in epoch 8, gen_loss = 0.9471657359685014, disc_loss = 0.0006563563650824304
Trained batch 421 in epoch 8, gen_loss = 0.9470938842443494, disc_loss = 0.0006572346833071912
Trained batch 422 in epoch 8, gen_loss = 0.9471231689126215, disc_loss = 0.0006582406845380526
Trained batch 423 in epoch 8, gen_loss = 0.9471896806696676, disc_loss = 0.0006585437928529331
Trained batch 424 in epoch 8, gen_loss = 0.9471045186940361, disc_loss = 0.0006585254526169807
Trained batch 425 in epoch 8, gen_loss = 0.9469157047394855, disc_loss = 0.0006585646890716774
Trained batch 426 in epoch 8, gen_loss = 0.9470543846034334, disc_loss = 0.0006590390786171708
Trained batch 427 in epoch 8, gen_loss = 0.9471343885236811, disc_loss = 0.000658930782290588
Trained batch 428 in epoch 8, gen_loss = 0.9470291529502068, disc_loss = 0.0006579072541148306
Trained batch 429 in epoch 8, gen_loss = 0.9467849576196005, disc_loss = 0.0006568485908013996
Trained batch 430 in epoch 8, gen_loss = 0.946838256654496, disc_loss = 0.0006557304684493827
Trained batch 431 in epoch 8, gen_loss = 0.9468590851735186, disc_loss = 0.0006546530997318903
Trained batch 432 in epoch 8, gen_loss = 0.9470381648656128, disc_loss = 0.0006537481467582352
Trained batch 433 in epoch 8, gen_loss = 0.9468465441932327, disc_loss = 0.0006527973396867494
Trained batch 434 in epoch 8, gen_loss = 0.9468202959532025, disc_loss = 0.000652262633689813
Trained batch 435 in epoch 8, gen_loss = 0.9469836940732571, disc_loss = 0.0006517633778082341
Trained batch 436 in epoch 8, gen_loss = 0.9471046083033494, disc_loss = 0.0006508968932306643
Trained batch 437 in epoch 8, gen_loss = 0.9473324892999919, disc_loss = 0.0006498672658268981
Trained batch 438 in epoch 8, gen_loss = 0.9472940421593217, disc_loss = 0.000648823554122026
Trained batch 439 in epoch 8, gen_loss = 0.9472583773461255, disc_loss = 0.0006480472793885961
Trained batch 440 in epoch 8, gen_loss = 0.9475314873957039, disc_loss = 0.000647318406228389
Trained batch 441 in epoch 8, gen_loss = 0.9472600336258228, disc_loss = 0.0006461225262246773
Trained batch 442 in epoch 8, gen_loss = 0.9474759792097535, disc_loss = 0.0006453411421858396
Trained batch 443 in epoch 8, gen_loss = 0.9474928297169574, disc_loss = 0.0006459950240536568
Trained batch 444 in epoch 8, gen_loss = 0.9474203054824571, disc_loss = 0.0006469311787788704
Trained batch 445 in epoch 8, gen_loss = 0.9472869807027381, disc_loss = 0.0006471725757340295
Trained batch 446 in epoch 8, gen_loss = 0.94720229806516, disc_loss = 0.0006470559500845387
Trained batch 447 in epoch 8, gen_loss = 0.9472693887406162, disc_loss = 0.0006464760378678745
Trained batch 448 in epoch 8, gen_loss = 0.9473512041276707, disc_loss = 0.0006456992524506976
Trained batch 449 in epoch 8, gen_loss = 0.9472889241907332, disc_loss = 0.0006453144255404671
Trained batch 450 in epoch 8, gen_loss = 0.947490642842591, disc_loss = 0.0006450644641094521
Trained batch 451 in epoch 8, gen_loss = 0.9473885452061628, disc_loss = 0.000645006099196596
Trained batch 452 in epoch 8, gen_loss = 0.9475268503161719, disc_loss = 0.0006465083905588219
Trained batch 453 in epoch 8, gen_loss = 0.9474443257642737, disc_loss = 0.0006495062982364012
Trained batch 454 in epoch 8, gen_loss = 0.9475225225909726, disc_loss = 0.0006527825225410717
Trained batch 455 in epoch 8, gen_loss = 0.9473983143505297, disc_loss = 0.0006559560381247776
Trained batch 456 in epoch 8, gen_loss = 0.9473733129856101, disc_loss = 0.0006587646585222766
Trained batch 457 in epoch 8, gen_loss = 0.9473622480334153, disc_loss = 0.0006610781209051252
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.9508358836174011, disc_loss = 0.0013895716983824968
Trained batch 1 in epoch 9, gen_loss = 0.9465518891811371, disc_loss = 0.0011884160921908915
Trained batch 2 in epoch 9, gen_loss = 0.9495265285174052, disc_loss = 0.0010180225557026763
Trained batch 3 in epoch 9, gen_loss = 0.9263340383768082, disc_loss = 0.0008589197095716372
Trained batch 4 in epoch 9, gen_loss = 0.9334878087043762, disc_loss = 0.0007650407846085727
Trained batch 5 in epoch 9, gen_loss = 0.9406351347764333, disc_loss = 0.0007408086288099488
Trained batch 6 in epoch 9, gen_loss = 0.9349876897675651, disc_loss = 0.000723240156990609
Trained batch 7 in epoch 9, gen_loss = 0.9406867697834969, disc_loss = 0.0006808229518355802
Trained batch 8 in epoch 9, gen_loss = 0.9436159796184964, disc_loss = 0.0006374700816296455
Trained batch 9 in epoch 9, gen_loss = 0.9404695510864258, disc_loss = 0.000597099527658429
Trained batch 10 in epoch 9, gen_loss = 0.9424998489293185, disc_loss = 0.0005648471401813863
Trained batch 11 in epoch 9, gen_loss = 0.9442296971877416, disc_loss = 0.0005460595578673141
Trained batch 12 in epoch 9, gen_loss = 0.940569689640632, disc_loss = 0.000527032526756207
Trained batch 13 in epoch 9, gen_loss = 0.9391500949859619, disc_loss = 0.0005039109912883889
Trained batch 14 in epoch 9, gen_loss = 0.9384082873662313, disc_loss = 0.00048819279472809283
Trained batch 15 in epoch 9, gen_loss = 0.9471245259046555, disc_loss = 0.0004917575397485052
Trained batch 16 in epoch 9, gen_loss = 0.94483641315909, disc_loss = 0.0005016465344370398
Trained batch 17 in epoch 9, gen_loss = 0.9424946473704444, disc_loss = 0.0005109799070244966
Trained batch 18 in epoch 9, gen_loss = 0.9439383149147034, disc_loss = 0.0005138857990172447
Trained batch 19 in epoch 9, gen_loss = 0.9464754551649094, disc_loss = 0.0005107382843561936
Trained batch 20 in epoch 9, gen_loss = 0.9397225294794355, disc_loss = 0.0005214896969153502
Trained batch 21 in epoch 9, gen_loss = 0.9478136436505751, disc_loss = 0.0005797582357031802
Trained batch 22 in epoch 9, gen_loss = 0.9490187427271968, disc_loss = 0.0006498406779112132
Trained batch 23 in epoch 9, gen_loss = 0.947527565062046, disc_loss = 0.0006976567243934065
Trained batch 24 in epoch 9, gen_loss = 0.9523488545417785, disc_loss = 0.0007433391601080075
Trained batch 25 in epoch 9, gen_loss = 0.9506392776966095, disc_loss = 0.0007884386941441335
Trained batch 26 in epoch 9, gen_loss = 0.9485406500321848, disc_loss = 0.0008230971833216716
Trained batch 27 in epoch 9, gen_loss = 0.9455775001219341, disc_loss = 0.0008390634658488645
Trained batch 28 in epoch 9, gen_loss = 0.9428818246413921, disc_loss = 0.0008567197108841983
Trained batch 29 in epoch 9, gen_loss = 0.9435194194316864, disc_loss = 0.0008726085347007029
Trained batch 30 in epoch 9, gen_loss = 0.9436795923017687, disc_loss = 0.0008796243106893774
Trained batch 31 in epoch 9, gen_loss = 0.945136621594429, disc_loss = 0.0008779958411651023
Trained batch 32 in epoch 9, gen_loss = 0.9445957324721597, disc_loss = 0.0008706080177834144
Trained batch 33 in epoch 9, gen_loss = 0.9450875818729401, disc_loss = 0.0008673053239095572
Trained batch 34 in epoch 9, gen_loss = 0.9435521040643965, disc_loss = 0.0008680141402042604
Trained batch 35 in epoch 9, gen_loss = 0.9454446683327357, disc_loss = 0.0008640990551308884
Trained batch 36 in epoch 9, gen_loss = 0.94542516405518, disc_loss = 0.0008522106670441006
Trained batch 37 in epoch 9, gen_loss = 0.9456253490949932, disc_loss = 0.0008390859580494611
Trained batch 38 in epoch 9, gen_loss = 0.9452100885220063, disc_loss = 0.0008274633224713258
Trained batch 39 in epoch 9, gen_loss = 0.9462803319096565, disc_loss = 0.0008203318018786376
Trained batch 40 in epoch 9, gen_loss = 0.9454510284633171, disc_loss = 0.0008195301857862122
Trained batch 41 in epoch 9, gen_loss = 0.9487595288526445, disc_loss = 0.0008369133917897541
Trained batch 42 in epoch 9, gen_loss = 0.9470206623853639, disc_loss = 0.0008812051893856246
Trained batch 43 in epoch 9, gen_loss = 0.9480888938361948, disc_loss = 0.0009308456908250016
Trained batch 44 in epoch 9, gen_loss = 0.9478398111131456, disc_loss = 0.0009692419899187775
Trained batch 45 in epoch 9, gen_loss = 0.947886189688807, disc_loss = 0.0009759196175803917
Trained batch 46 in epoch 9, gen_loss = 0.948512095086118, disc_loss = 0.0009689405941320187
Trained batch 47 in epoch 9, gen_loss = 0.9483072894314925, disc_loss = 0.0009655317392874471
Trained batch 48 in epoch 9, gen_loss = 0.9472496837985759, disc_loss = 0.000959499444211453
Trained batch 49 in epoch 9, gen_loss = 0.9461517727375031, disc_loss = 0.0009497489218483679
Trained batch 50 in epoch 9, gen_loss = 0.9464445090761372, disc_loss = 0.0009395877585869611
Trained batch 51 in epoch 9, gen_loss = 0.9464761855510565, disc_loss = 0.0009280804759048176
Trained batch 52 in epoch 9, gen_loss = 0.9463981300030114, disc_loss = 0.0009143981549401223
Trained batch 53 in epoch 9, gen_loss = 0.9465421151231836, disc_loss = 0.0009014956721566032
Trained batch 54 in epoch 9, gen_loss = 0.9465894980864091, disc_loss = 0.000889180558574894
Trained batch 55 in epoch 9, gen_loss = 0.9462436544043678, disc_loss = 0.0008756208558874537
Trained batch 56 in epoch 9, gen_loss = 0.9454923376702425, disc_loss = 0.0008630346011047726
Trained batch 57 in epoch 9, gen_loss = 0.9447650693613907, disc_loss = 0.0008516522931790076
Trained batch 58 in epoch 9, gen_loss = 0.9457596247479066, disc_loss = 0.0008457879581729392
Trained batch 59 in epoch 9, gen_loss = 0.9438984125852585, disc_loss = 0.0008621981001245634
Trained batch 60 in epoch 9, gen_loss = 0.9433810232115574, disc_loss = 0.0009010535510749267
Trained batch 61 in epoch 9, gen_loss = 0.9425919046325069, disc_loss = 0.0009408689823636275
Trained batch 62 in epoch 9, gen_loss = 0.9426702393425835, disc_loss = 0.0009735781749773268
Trained batch 63 in epoch 9, gen_loss = 0.9428808409720659, disc_loss = 0.0009845342212884134
Trained batch 64 in epoch 9, gen_loss = 0.9422170052161584, disc_loss = 0.0009790887610646537
Trained batch 65 in epoch 9, gen_loss = 0.9418337715394569, disc_loss = 0.000968214776852013
Trained batch 66 in epoch 9, gen_loss = 0.9415267679228712, disc_loss = 0.0009556828340803927
Trained batch 67 in epoch 9, gen_loss = 0.9407215880997041, disc_loss = 0.0009436495079973931
Trained batch 68 in epoch 9, gen_loss = 0.9407271915587826, disc_loss = 0.0009319411231748139
Trained batch 69 in epoch 9, gen_loss = 0.9411178691046579, disc_loss = 0.0009204768022755161
Trained batch 70 in epoch 9, gen_loss = 0.9400109631914488, disc_loss = 0.0009097896608963452
Trained batch 71 in epoch 9, gen_loss = 0.9410813442534871, disc_loss = 0.0009005951449378497
Trained batch 72 in epoch 9, gen_loss = 0.9405295375275285, disc_loss = 0.0008948961311109262
Trained batch 73 in epoch 9, gen_loss = 0.9404097207494684, disc_loss = 0.0008937343294304368
Trained batch 74 in epoch 9, gen_loss = 0.9394746621449789, disc_loss = 0.0008947043089816967
Trained batch 75 in epoch 9, gen_loss = 0.9404810023935217, disc_loss = 0.0008950599700543343
Trained batch 76 in epoch 9, gen_loss = 0.9411796896488636, disc_loss = 0.0008922146864586159
Trained batch 77 in epoch 9, gen_loss = 0.9422997350876148, disc_loss = 0.0008862155880659628
Trained batch 78 in epoch 9, gen_loss = 0.9418824232077296, disc_loss = 0.0008790045560343497
Trained batch 79 in epoch 9, gen_loss = 0.942284943163395, disc_loss = 0.0008712401966477045
Trained batch 80 in epoch 9, gen_loss = 0.942443409083802, disc_loss = 0.0008626367421073402
Trained batch 81 in epoch 9, gen_loss = 0.9425049642237221, disc_loss = 0.0008537987944181645
Trained batch 82 in epoch 9, gen_loss = 0.9433386914701347, disc_loss = 0.0008449504865159517
Trained batch 83 in epoch 9, gen_loss = 0.9434315462907156, disc_loss = 0.0008370864019352233
Trained batch 84 in epoch 9, gen_loss = 0.9447549525429221, disc_loss = 0.0008335671757402665
Trained batch 85 in epoch 9, gen_loss = 0.9458334875661273, disc_loss = 0.0008363859554709391
Trained batch 86 in epoch 9, gen_loss = 0.9458505278346182, disc_loss = 0.0008393007828372306
Trained batch 87 in epoch 9, gen_loss = 0.9461731172420762, disc_loss = 0.0008366003881250931
Trained batch 88 in epoch 9, gen_loss = 0.9459414294596469, disc_loss = 0.0008314043751739887
Trained batch 89 in epoch 9, gen_loss = 0.9453652885225085, disc_loss = 0.0008263773152268389
Trained batch 90 in epoch 9, gen_loss = 0.9448358527906648, disc_loss = 0.0008219274731255699
Trained batch 91 in epoch 9, gen_loss = 0.9451807672562806, disc_loss = 0.0008162488394072684
Trained batch 92 in epoch 9, gen_loss = 0.9453603170251333, disc_loss = 0.0008104038434178238
Trained batch 93 in epoch 9, gen_loss = 0.9456761733014533, disc_loss = 0.000806034946668041
Trained batch 94 in epoch 9, gen_loss = 0.9451947833362379, disc_loss = 0.0008022692327167055
Trained batch 95 in epoch 9, gen_loss = 0.9456641978273789, disc_loss = 0.0007978260985813298
Trained batch 96 in epoch 9, gen_loss = 0.9466713021710976, disc_loss = 0.0007927983974649081
Trained batch 97 in epoch 9, gen_loss = 0.9462396970817021, disc_loss = 0.0007881078585787505
Trained batch 98 in epoch 9, gen_loss = 0.9457142678174105, disc_loss = 0.000783564741876108
Trained batch 99 in epoch 9, gen_loss = 0.9456336927413941, disc_loss = 0.0007779451440728735
Trained batch 100 in epoch 9, gen_loss = 0.9460328840973353, disc_loss = 0.0007725208340729079
Trained batch 101 in epoch 9, gen_loss = 0.9461975156092176, disc_loss = 0.0007667589837664683
Trained batch 102 in epoch 9, gen_loss = 0.9465284382255332, disc_loss = 0.0007604832507532035
Trained batch 103 in epoch 9, gen_loss = 0.9461783342636548, disc_loss = 0.0007546637794943168
Trained batch 104 in epoch 9, gen_loss = 0.9459772609529041, disc_loss = 0.0007508949426534984
Trained batch 105 in epoch 9, gen_loss = 0.9458537720284372, disc_loss = 0.0007468302133449195
Trained batch 106 in epoch 9, gen_loss = 0.9464278287976702, disc_loss = 0.000741560569834878
Trained batch 107 in epoch 9, gen_loss = 0.9461167068393143, disc_loss = 0.0007365795940535867
Trained batch 108 in epoch 9, gen_loss = 0.9464131965549714, disc_loss = 0.0007317729565045805
Trained batch 109 in epoch 9, gen_loss = 0.9466951196843928, disc_loss = 0.0007267379355405204
Trained batch 110 in epoch 9, gen_loss = 0.9471185062382672, disc_loss = 0.0007212179052739966
Trained batch 111 in epoch 9, gen_loss = 0.9470559135079384, disc_loss = 0.000715863553523377
Trained batch 112 in epoch 9, gen_loss = 0.9474155734070634, disc_loss = 0.0007118414797710948
Trained batch 113 in epoch 9, gen_loss = 0.9473878061562254, disc_loss = 0.0007084750292338676
Trained batch 114 in epoch 9, gen_loss = 0.9472901779672374, disc_loss = 0.0007038511690157263
Trained batch 115 in epoch 9, gen_loss = 0.9482691524357632, disc_loss = 0.0006993937066250384
Trained batch 116 in epoch 9, gen_loss = 0.9484792402666858, disc_loss = 0.0006963510599094802
Trained batch 117 in epoch 9, gen_loss = 0.948446488986581, disc_loss = 0.0006932526739547029
Trained batch 118 in epoch 9, gen_loss = 0.9484116084435407, disc_loss = 0.0006895776984317056
Trained batch 119 in epoch 9, gen_loss = 0.9496567204594613, disc_loss = 0.0006866872075382465
Trained batch 120 in epoch 9, gen_loss = 0.9493871488847023, disc_loss = 0.0006847167135050812
Trained batch 121 in epoch 9, gen_loss = 0.9493935503920571, disc_loss = 0.0006833457496288217
Trained batch 122 in epoch 9, gen_loss = 0.9486536858527641, disc_loss = 0.0006818155541815379
Trained batch 123 in epoch 9, gen_loss = 0.9482686053360662, disc_loss = 0.0006793620632379316
Trained batch 124 in epoch 9, gen_loss = 0.9481815524101257, disc_loss = 0.000675744351116009
Trained batch 125 in epoch 9, gen_loss = 0.9479068697444977, disc_loss = 0.0006718595025068637
Trained batch 126 in epoch 9, gen_loss = 0.9478875121732396, disc_loss = 0.0006684313880464825
Trained batch 127 in epoch 9, gen_loss = 0.9483440234325826, disc_loss = 0.0006647722627803887
Trained batch 128 in epoch 9, gen_loss = 0.9481936656227408, disc_loss = 0.0006604226150521972
Trained batch 129 in epoch 9, gen_loss = 0.9482980141272912, disc_loss = 0.0006566023821785795
Trained batch 130 in epoch 9, gen_loss = 0.9487215153133596, disc_loss = 0.0006531428001738395
Trained batch 131 in epoch 9, gen_loss = 0.9488665000958876, disc_loss = 0.0006492384186320564
Trained batch 132 in epoch 9, gen_loss = 0.9485987725114464, disc_loss = 0.0006453285108760692
Trained batch 133 in epoch 9, gen_loss = 0.9483247884173891, disc_loss = 0.0006416044045398673
Trained batch 134 in epoch 9, gen_loss = 0.948370694231104, disc_loss = 0.0006386558539816179
Trained batch 135 in epoch 9, gen_loss = 0.9480740208836163, disc_loss = 0.0006367247039687593
Trained batch 136 in epoch 9, gen_loss = 0.947198696380114, disc_loss = 0.0006337165607867701
Trained batch 137 in epoch 9, gen_loss = 0.9469901396744493, disc_loss = 0.0006304058952082414
Trained batch 138 in epoch 9, gen_loss = 0.9479455866402001, disc_loss = 0.0006277509630517867
Trained batch 139 in epoch 9, gen_loss = 0.9483706112418856, disc_loss = 0.0006255425891660187
Trained batch 140 in epoch 9, gen_loss = 0.9484719278964591, disc_loss = 0.0006236927472868214
Trained batch 141 in epoch 9, gen_loss = 0.948023752847188, disc_loss = 0.0006215085622770089
Trained batch 142 in epoch 9, gen_loss = 0.948190782870446, disc_loss = 0.000618658603343647
Trained batch 143 in epoch 9, gen_loss = 0.9487765733566549, disc_loss = 0.0006160714359692873
Trained batch 144 in epoch 9, gen_loss = 0.9481796498956352, disc_loss = 0.0006125340413338312
Trained batch 145 in epoch 9, gen_loss = 0.9488348801658578, disc_loss = 0.0006116589530604758
Trained batch 146 in epoch 9, gen_loss = 0.949186477936855, disc_loss = 0.0006156149140632787
Trained batch 147 in epoch 9, gen_loss = 0.9492850645973876, disc_loss = 0.0006198576753082012
Trained batch 148 in epoch 9, gen_loss = 0.9487469192319269, disc_loss = 0.0006205439523128862
Trained batch 149 in epoch 9, gen_loss = 0.948676948149999, disc_loss = 0.0006193556369301708
Trained batch 150 in epoch 9, gen_loss = 0.948645912653563, disc_loss = 0.000619866901868723
Trained batch 151 in epoch 9, gen_loss = 0.9489167438525903, disc_loss = 0.0006217901770804403
Trained batch 152 in epoch 9, gen_loss = 0.9483801597863241, disc_loss = 0.0006218923806396216
Trained batch 153 in epoch 9, gen_loss = 0.948345886035399, disc_loss = 0.0006207480285163249
Trained batch 154 in epoch 9, gen_loss = 0.9481904191355551, disc_loss = 0.0006195514570384647
Trained batch 155 in epoch 9, gen_loss = 0.9478408858562127, disc_loss = 0.0006178618946134334
Trained batch 156 in epoch 9, gen_loss = 0.9475175609254534, disc_loss = 0.0006155029440593052
Trained batch 157 in epoch 9, gen_loss = 0.947454059048544, disc_loss = 0.0006132340086775071
Trained batch 158 in epoch 9, gen_loss = 0.9471726559992856, disc_loss = 0.0006108701164755859
Trained batch 159 in epoch 9, gen_loss = 0.9473146937787533, disc_loss = 0.0006083988144837349
Trained batch 160 in epoch 9, gen_loss = 0.94733338622573, disc_loss = 0.0006058708891964529
Trained batch 161 in epoch 9, gen_loss = 0.9473919522615126, disc_loss = 0.0006032518241328136
Trained batch 162 in epoch 9, gen_loss = 0.9470500485297361, disc_loss = 0.0006007942818965837
Trained batch 163 in epoch 9, gen_loss = 0.9472088999137646, disc_loss = 0.000599038382083896
Trained batch 164 in epoch 9, gen_loss = 0.9472056890978958, disc_loss = 0.0005975833432978216
Trained batch 165 in epoch 9, gen_loss = 0.9468557888484863, disc_loss = 0.0005956088322588574
Trained batch 166 in epoch 9, gen_loss = 0.9471319567657517, disc_loss = 0.0005940101948140808
Trained batch 167 in epoch 9, gen_loss = 0.9469909210290227, disc_loss = 0.000593087414060955
Trained batch 168 in epoch 9, gen_loss = 0.9470447774469499, disc_loss = 0.0005913485875632201
Trained batch 169 in epoch 9, gen_loss = 0.9469970513792599, disc_loss = 0.0005888021590876365
Trained batch 170 in epoch 9, gen_loss = 0.9466189818772656, disc_loss = 0.0005858600242077019
Trained batch 171 in epoch 9, gen_loss = 0.9464166795098504, disc_loss = 0.000583402906814563
Trained batch 172 in epoch 9, gen_loss = 0.9461887272107119, disc_loss = 0.0005820527365074541
Trained batch 173 in epoch 9, gen_loss = 0.946121299061282, disc_loss = 0.0005800556310354839
Trained batch 174 in epoch 9, gen_loss = 0.9460752940177918, disc_loss = 0.000577383479519215
Trained batch 175 in epoch 9, gen_loss = 0.9462106183848598, disc_loss = 0.0005764211224562711
Trained batch 176 in epoch 9, gen_loss = 0.9456707690395204, disc_loss = 0.0005748517714121174
Trained batch 177 in epoch 9, gen_loss = 0.9457608809631862, disc_loss = 0.00057242903604991
Trained batch 178 in epoch 9, gen_loss = 0.94570890951423, disc_loss = 0.0005728481123620623
Trained batch 179 in epoch 9, gen_loss = 0.9458438224262662, disc_loss = 0.0005736030082819829
Trained batch 180 in epoch 9, gen_loss = 0.9459201057971511, disc_loss = 0.0005732631959305376
Trained batch 181 in epoch 9, gen_loss = 0.9456112424095908, disc_loss = 0.0005722183426029745
Trained batch 182 in epoch 9, gen_loss = 0.9453898795315476, disc_loss = 0.0005709164139917731
Trained batch 183 in epoch 9, gen_loss = 0.9457171646797139, disc_loss = 0.0005696281611523337
Trained batch 184 in epoch 9, gen_loss = 0.9453308949599395, disc_loss = 0.0005682313502483019
Trained batch 185 in epoch 9, gen_loss = 0.9456502038945434, disc_loss = 0.0005675152995497218
Trained batch 186 in epoch 9, gen_loss = 0.945403021924636, disc_loss = 0.0005680230307799918
Trained batch 187 in epoch 9, gen_loss = 0.9455952403393197, disc_loss = 0.0005688384150376573
Trained batch 188 in epoch 9, gen_loss = 0.9454052810946469, disc_loss = 0.000567972545574232
Trained batch 189 in epoch 9, gen_loss = 0.9451460314424415, disc_loss = 0.0005668258157368798
Trained batch 190 in epoch 9, gen_loss = 0.9455023707519651, disc_loss = 0.0005675800043647056
Trained batch 191 in epoch 9, gen_loss = 0.9456833790366849, disc_loss = 0.0005675396669933738
Trained batch 192 in epoch 9, gen_loss = 0.9454812577351387, disc_loss = 0.0005665935540223166
Trained batch 193 in epoch 9, gen_loss = 0.945697150894047, disc_loss = 0.0005669193641617463
Trained batch 194 in epoch 9, gen_loss = 0.9457697177544618, disc_loss = 0.0005661724895710508
Trained batch 195 in epoch 9, gen_loss = 0.9458428697318447, disc_loss = 0.0005647684283387059
Trained batch 196 in epoch 9, gen_loss = 0.9459197363877659, disc_loss = 0.00056378490554209
Trained batch 197 in epoch 9, gen_loss = 0.9459259913425253, disc_loss = 0.0005648383830886833
Trained batch 198 in epoch 9, gen_loss = 0.9458894903336338, disc_loss = 0.0005678630106521995
Trained batch 199 in epoch 9, gen_loss = 0.9457524538040161, disc_loss = 0.0005715475764736766
Trained batch 200 in epoch 9, gen_loss = 0.9460534444495813, disc_loss = 0.0005750391393840841
Trained batch 201 in epoch 9, gen_loss = 0.9460115633388557, disc_loss = 0.0005778361773631296
Trained batch 202 in epoch 9, gen_loss = 0.9459311539316412, disc_loss = 0.0005794741458338662
Trained batch 203 in epoch 9, gen_loss = 0.9454320645799824, disc_loss = 0.000580121248668886
Trained batch 204 in epoch 9, gen_loss = 0.9454740326579024, disc_loss = 0.0005805169616218247
Trained batch 205 in epoch 9, gen_loss = 0.9455658920760294, disc_loss = 0.0005794141342828403
Trained batch 206 in epoch 9, gen_loss = 0.9457405437017985, disc_loss = 0.0005776026270859582
Trained batch 207 in epoch 9, gen_loss = 0.9457670261080449, disc_loss = 0.0005755985501729391
Trained batch 208 in epoch 9, gen_loss = 0.9459508115595038, disc_loss = 0.0005741591625050397
Trained batch 209 in epoch 9, gen_loss = 0.9460408267520722, disc_loss = 0.0005732991930147233
Trained batch 210 in epoch 9, gen_loss = 0.9461925159698414, disc_loss = 0.0005719970681531337
Trained batch 211 in epoch 9, gen_loss = 0.9459008414228007, disc_loss = 0.0005699721010421614
Trained batch 212 in epoch 9, gen_loss = 0.9462020170520729, disc_loss = 0.0005685364305011123
Trained batch 213 in epoch 9, gen_loss = 0.9459808588585007, disc_loss = 0.0005678140954604094
Trained batch 214 in epoch 9, gen_loss = 0.9460890839266223, disc_loss = 0.0005683512011337159
Trained batch 215 in epoch 9, gen_loss = 0.9461202764952624, disc_loss = 0.0005696773707178956
Trained batch 216 in epoch 9, gen_loss = 0.9458124640350518, disc_loss = 0.0005703482028227815
Trained batch 217 in epoch 9, gen_loss = 0.945934887052676, disc_loss = 0.00056994599495788
Trained batch 218 in epoch 9, gen_loss = 0.9460239557370748, disc_loss = 0.0005688485149910767
Trained batch 219 in epoch 9, gen_loss = 0.946008947762576, disc_loss = 0.0005675189874388954
Trained batch 220 in epoch 9, gen_loss = 0.9457748095374302, disc_loss = 0.0005662943077446446
Trained batch 221 in epoch 9, gen_loss = 0.9452600736875791, disc_loss = 0.0005653914376707362
Trained batch 222 in epoch 9, gen_loss = 0.945404689408204, disc_loss = 0.0005643659398155997
Trained batch 223 in epoch 9, gen_loss = 0.9454649865095105, disc_loss = 0.0005630558755780969
Trained batch 224 in epoch 9, gen_loss = 0.9457350781228807, disc_loss = 0.0005617654402481599
Trained batch 225 in epoch 9, gen_loss = 0.9460014060007788, disc_loss = 0.0005604877811186922
Trained batch 226 in epoch 9, gen_loss = 0.9465076343078446, disc_loss = 0.0005594022970263013
Trained batch 227 in epoch 9, gen_loss = 0.9464873106856095, disc_loss = 0.0005583160370741481
Trained batch 228 in epoch 9, gen_loss = 0.945862949154783, disc_loss = 0.0005579005654110252
Trained batch 229 in epoch 9, gen_loss = 0.9455604330353115, disc_loss = 0.0005587036477189268
Trained batch 230 in epoch 9, gen_loss = 0.9456106700422444, disc_loss = 0.0005596167508974365
Trained batch 231 in epoch 9, gen_loss = 0.9454600718514673, disc_loss = 0.0005606757819397648
Trained batch 232 in epoch 9, gen_loss = 0.9455592292061179, disc_loss = 0.0005631811279541705
Trained batch 233 in epoch 9, gen_loss = 0.9455844925509559, disc_loss = 0.0005667742808661861
Trained batch 234 in epoch 9, gen_loss = 0.9455974939021659, disc_loss = 0.0005702676247815265
Trained batch 235 in epoch 9, gen_loss = 0.9455265195693, disc_loss = 0.0005731629204030654
Trained batch 236 in epoch 9, gen_loss = 0.9454189081232256, disc_loss = 0.0005750311407180039
Trained batch 237 in epoch 9, gen_loss = 0.9460037070162156, disc_loss = 0.0005758004900148264
Trained batch 238 in epoch 9, gen_loss = 0.9458704311478587, disc_loss = 0.0005767412456171392
Trained batch 239 in epoch 9, gen_loss = 0.945814727495114, disc_loss = 0.0005782581083622063
Trained batch 240 in epoch 9, gen_loss = 0.9460063304643908, disc_loss = 0.0005794056145140043
Trained batch 241 in epoch 9, gen_loss = 0.9458375284987047, disc_loss = 0.0005790586257401531
Trained batch 242 in epoch 9, gen_loss = 0.9461191129782562, disc_loss = 0.0005779696019786053
Trained batch 243 in epoch 9, gen_loss = 0.945698393172905, disc_loss = 0.0005775767004691812
Trained batch 244 in epoch 9, gen_loss = 0.9458813883820358, disc_loss = 0.0005801132643756894
Trained batch 245 in epoch 9, gen_loss = 0.9460711505839495, disc_loss = 0.00058376883514835
Trained batch 246 in epoch 9, gen_loss = 0.9458707908869755, disc_loss = 0.0005855450114689632
Trained batch 247 in epoch 9, gen_loss = 0.9458175719745697, disc_loss = 0.0005854665497252192
Trained batch 248 in epoch 9, gen_loss = 0.9463141874137174, disc_loss = 0.0005850869528509781
Trained batch 249 in epoch 9, gen_loss = 0.9463124213218689, disc_loss = 0.0005856175773078575
Trained batch 250 in epoch 9, gen_loss = 0.9462196674954844, disc_loss = 0.0005866608106340114
Trained batch 251 in epoch 9, gen_loss = 0.946371022670988, disc_loss = 0.0005868974063011433
Trained batch 252 in epoch 9, gen_loss = 0.9467005117137441, disc_loss = 0.0005866447717858765
Trained batch 253 in epoch 9, gen_loss = 0.946581238836754, disc_loss = 0.0005866055977008283
Trained batch 254 in epoch 9, gen_loss = 0.9465871532758077, disc_loss = 0.0005875095911095758
Trained batch 255 in epoch 9, gen_loss = 0.9462282706517726, disc_loss = 0.000589184068189752
Trained batch 256 in epoch 9, gen_loss = 0.9464284610655521, disc_loss = 0.0005922951931016092
Trained batch 257 in epoch 9, gen_loss = 0.9467735597791598, disc_loss = 0.000595079560185667
Trained batch 258 in epoch 9, gen_loss = 0.9466005669597494, disc_loss = 0.0005957268543216007
Trained batch 259 in epoch 9, gen_loss = 0.9465107165850126, disc_loss = 0.0005958593006093557
Trained batch 260 in epoch 9, gen_loss = 0.9465757644952942, disc_loss = 0.0005955257149943119
Trained batch 261 in epoch 9, gen_loss = 0.9465362775416775, disc_loss = 0.0005952764829249257
Trained batch 262 in epoch 9, gen_loss = 0.9464175986699732, disc_loss = 0.0005950190638370827
Trained batch 263 in epoch 9, gen_loss = 0.9463177284959591, disc_loss = 0.0005948130326005137
Trained batch 264 in epoch 9, gen_loss = 0.9465623425987532, disc_loss = 0.0005950118952105701
Trained batch 265 in epoch 9, gen_loss = 0.9465849717756859, disc_loss = 0.000595395637197329
Trained batch 266 in epoch 9, gen_loss = 0.9469976626085431, disc_loss = 0.0005960376181749607
Trained batch 267 in epoch 9, gen_loss = 0.9471677546180896, disc_loss = 0.0005969631987573482
Trained batch 268 in epoch 9, gen_loss = 0.9469864226628414, disc_loss = 0.0005979566841574946
Trained batch 269 in epoch 9, gen_loss = 0.9467006497912936, disc_loss = 0.0005977940636781837
Trained batch 270 in epoch 9, gen_loss = 0.9467949785869499, disc_loss = 0.0005973390286583865
Trained batch 271 in epoch 9, gen_loss = 0.9469652504605406, disc_loss = 0.0005964512750805999
Trained batch 272 in epoch 9, gen_loss = 0.9470143298526387, disc_loss = 0.0005948514864786832
Trained batch 273 in epoch 9, gen_loss = 0.9470053195518299, disc_loss = 0.0005930459179833063
Trained batch 274 in epoch 9, gen_loss = 0.9471614239432595, disc_loss = 0.0005913208475315266
Trained batch 275 in epoch 9, gen_loss = 0.9470773157866105, disc_loss = 0.0005898138048339034
Trained batch 276 in epoch 9, gen_loss = 0.9470490509852606, disc_loss = 0.0005882232806024172
Trained batch 277 in epoch 9, gen_loss = 0.9470036147738532, disc_loss = 0.0005864433229925184
Trained batch 278 in epoch 9, gen_loss = 0.9469343750707565, disc_loss = 0.0005847417386605464
Trained batch 279 in epoch 9, gen_loss = 0.9469271466135979, disc_loss = 0.0005831544693137402
Trained batch 280 in epoch 9, gen_loss = 0.9471244292327093, disc_loss = 0.0005816621504182549
Trained batch 281 in epoch 9, gen_loss = 0.9469238517554939, disc_loss = 0.0005803243018959645
Trained batch 282 in epoch 9, gen_loss = 0.9468383601613264, disc_loss = 0.0005790786904312897
Trained batch 283 in epoch 9, gen_loss = 0.9468476297989697, disc_loss = 0.0005776901157524906
Trained batch 284 in epoch 9, gen_loss = 0.9468611344956515, disc_loss = 0.0005765505074554025
Trained batch 285 in epoch 9, gen_loss = 0.9465203631174314, disc_loss = 0.0005758123015575811
Trained batch 286 in epoch 9, gen_loss = 0.9466343964433837, disc_loss = 0.0005751270485199414
Trained batch 287 in epoch 9, gen_loss = 0.946128797199991, disc_loss = 0.0005741268432504714
Trained batch 288 in epoch 9, gen_loss = 0.9459220276159399, disc_loss = 0.0005733853585042855
Trained batch 289 in epoch 9, gen_loss = 0.9460619521552118, disc_loss = 0.0005734267057238773
Trained batch 290 in epoch 9, gen_loss = 0.9460468386456728, disc_loss = 0.0005736395125739401
Trained batch 291 in epoch 9, gen_loss = 0.9458169047146627, disc_loss = 0.0005738819790204703
Trained batch 292 in epoch 9, gen_loss = 0.9464655528703241, disc_loss = 0.0005743023942162301
Trained batch 293 in epoch 9, gen_loss = 0.9463447089097938, disc_loss = 0.0005758138321572518
Trained batch 294 in epoch 9, gen_loss = 0.9462115142305019, disc_loss = 0.000577419150055394
Trained batch 295 in epoch 9, gen_loss = 0.9463672041893005, disc_loss = 0.000577884975059164
Trained batch 296 in epoch 9, gen_loss = 0.9463453152364352, disc_loss = 0.0005772716332388091
Trained batch 297 in epoch 9, gen_loss = 0.9464735656776684, disc_loss = 0.0005763527776234574
Trained batch 298 in epoch 9, gen_loss = 0.9465115684330663, disc_loss = 0.0005753527463903965
Trained batch 299 in epoch 9, gen_loss = 0.946488983631134, disc_loss = 0.0005740016337707251
Trained batch 300 in epoch 9, gen_loss = 0.9467865996978607, disc_loss = 0.0005724074419708134
Trained batch 301 in epoch 9, gen_loss = 0.9465723017983089, disc_loss = 0.000571223008399174
Trained batch 302 in epoch 9, gen_loss = 0.9463727700434895, disc_loss = 0.0005702646143521988
Trained batch 303 in epoch 9, gen_loss = 0.9462368519682633, disc_loss = 0.0005689883188623705
Trained batch 304 in epoch 9, gen_loss = 0.9461444811742814, disc_loss = 0.000567513960938458
Trained batch 305 in epoch 9, gen_loss = 0.9459717073082144, disc_loss = 0.0005661694037068324
Trained batch 306 in epoch 9, gen_loss = 0.9458173721155049, disc_loss = 0.0005651109181939858
Trained batch 307 in epoch 9, gen_loss = 0.9458812962878834, disc_loss = 0.0005641215177636152
Trained batch 308 in epoch 9, gen_loss = 0.9457208548934715, disc_loss = 0.000563268771786529
Trained batch 309 in epoch 9, gen_loss = 0.9455709086310479, disc_loss = 0.0005620122582073354
Trained batch 310 in epoch 9, gen_loss = 0.9453723645286928, disc_loss = 0.0005606420359583991
Trained batch 311 in epoch 9, gen_loss = 0.945467125146817, disc_loss = 0.0005592138775402698
Trained batch 312 in epoch 9, gen_loss = 0.9453961140812396, disc_loss = 0.0005583539692080243
Trained batch 313 in epoch 9, gen_loss = 0.9452775058093345, disc_loss = 0.0005589500515907855
Trained batch 314 in epoch 9, gen_loss = 0.9454056874154106, disc_loss = 0.0005594289364082561
Trained batch 315 in epoch 9, gen_loss = 0.9455583169113232, disc_loss = 0.0005589952476229077
Trained batch 316 in epoch 9, gen_loss = 0.9456377875541663, disc_loss = 0.0005581415251829465
Trained batch 317 in epoch 9, gen_loss = 0.9455349958917629, disc_loss = 0.0005567284720000202
Trained batch 318 in epoch 9, gen_loss = 0.9458268843474433, disc_loss = 0.0005560433199657652
Trained batch 319 in epoch 9, gen_loss = 0.9457226473838091, disc_loss = 0.0005572515961375756
Trained batch 320 in epoch 9, gen_loss = 0.9457723314517013, disc_loss = 0.0005592497821728267
Trained batch 321 in epoch 9, gen_loss = 0.945698569835343, disc_loss = 0.0005601179387520924
Trained batch 322 in epoch 9, gen_loss = 0.9456192681294846, disc_loss = 0.0005599265305333318
Trained batch 323 in epoch 9, gen_loss = 0.9457195541005076, disc_loss = 0.0005593726281303032
Trained batch 324 in epoch 9, gen_loss = 0.9455936094430777, disc_loss = 0.0005593654346347858
Trained batch 325 in epoch 9, gen_loss = 0.9454637893869833, disc_loss = 0.0005600005959177052
Trained batch 326 in epoch 9, gen_loss = 0.9455907842434874, disc_loss = 0.0005605359057897976
Trained batch 327 in epoch 9, gen_loss = 0.9456583266941513, disc_loss = 0.0005602321999481874
Trained batch 328 in epoch 9, gen_loss = 0.9458926106296411, disc_loss = 0.0005596469582032304
Trained batch 329 in epoch 9, gen_loss = 0.9456375104008299, disc_loss = 0.0005589224434736411
Trained batch 330 in epoch 9, gen_loss = 0.9457545566774928, disc_loss = 0.0005586852346004614
Trained batch 331 in epoch 9, gen_loss = 0.945557177066803, disc_loss = 0.0005583222964669842
Trained batch 332 in epoch 9, gen_loss = 0.9454104186178328, disc_loss = 0.0005574368646871102
Trained batch 333 in epoch 9, gen_loss = 0.9453743478495203, disc_loss = 0.0005562497714787448
Trained batch 334 in epoch 9, gen_loss = 0.9454123287058588, disc_loss = 0.0005549654147827497
Trained batch 335 in epoch 9, gen_loss = 0.9455126280940714, disc_loss = 0.0005539324107476638
Trained batch 336 in epoch 9, gen_loss = 0.9455327579104936, disc_loss = 0.0005531703203226348
Trained batch 337 in epoch 9, gen_loss = 0.9454896753356301, disc_loss = 0.0005522998089550102
Trained batch 338 in epoch 9, gen_loss = 0.9454009343037563, disc_loss = 0.0005513350217885429
Trained batch 339 in epoch 9, gen_loss = 0.945542982746573, disc_loss = 0.0005504050523621332
Trained batch 340 in epoch 9, gen_loss = 0.9452249975847709, disc_loss = 0.0005491986657650541
Trained batch 341 in epoch 9, gen_loss = 0.9452113591090977, disc_loss = 0.0005486555969290168
Trained batch 342 in epoch 9, gen_loss = 0.9453405449411264, disc_loss = 0.0005494636364614472
Trained batch 343 in epoch 9, gen_loss = 0.9451346766463545, disc_loss = 0.0005501376741703161
Trained batch 344 in epoch 9, gen_loss = 0.9452122304750525, disc_loss = 0.0005500850780188794
Trained batch 345 in epoch 9, gen_loss = 0.9453495730554438, disc_loss = 0.0005498150365835599
Trained batch 346 in epoch 9, gen_loss = 0.9454028544577123, disc_loss = 0.0005503675976472233
Trained batch 347 in epoch 9, gen_loss = 0.9454402267590336, disc_loss = 0.0005515964745511113
Trained batch 348 in epoch 9, gen_loss = 0.9456558116527547, disc_loss = 0.000552617517267594
Trained batch 349 in epoch 9, gen_loss = 0.945639272247042, disc_loss = 0.0005527144701669126
Trained batch 350 in epoch 9, gen_loss = 0.9454587998553219, disc_loss = 0.0005521672429829342
Trained batch 351 in epoch 9, gen_loss = 0.9454536192457784, disc_loss = 0.0005521234557735708
Trained batch 352 in epoch 9, gen_loss = 0.9456853408989082, disc_loss = 0.0005520507138833884
Trained batch 353 in epoch 9, gen_loss = 0.9457095664436534, disc_loss = 0.0005520028928291489
Trained batch 354 in epoch 9, gen_loss = 0.9456294526516552, disc_loss = 0.0005522148945601657
Trained batch 355 in epoch 9, gen_loss = 0.9457663008001413, disc_loss = 0.0005530852897944887
Trained batch 356 in epoch 9, gen_loss = 0.9459743972252063, disc_loss = 0.0005554249930421819
Trained batch 357 in epoch 9, gen_loss = 0.9457829220001924, disc_loss = 0.0005568880730490044
Trained batch 358 in epoch 9, gen_loss = 0.9458376220673904, disc_loss = 0.0005577076187154309
Trained batch 359 in epoch 9, gen_loss = 0.9459612460600005, disc_loss = 0.0005592111772582737
Trained batch 360 in epoch 9, gen_loss = 0.9460035833295363, disc_loss = 0.0005605004955108286
Trained batch 361 in epoch 9, gen_loss = 0.946087599459274, disc_loss = 0.0005603604145635573
Trained batch 362 in epoch 9, gen_loss = 0.9459573368724056, disc_loss = 0.0005598891915393655
Trained batch 363 in epoch 9, gen_loss = 0.9458768516778946, disc_loss = 0.0005606054713368124
Trained batch 364 in epoch 9, gen_loss = 0.9460906272065149, disc_loss = 0.0005606363088527236
Trained batch 365 in epoch 9, gen_loss = 0.9458573831886542, disc_loss = 0.0005596025520553965
Trained batch 366 in epoch 9, gen_loss = 0.9458683404350801, disc_loss = 0.0005588910458526988
Trained batch 367 in epoch 9, gen_loss = 0.945681344717741, disc_loss = 0.0005593947728851598
Trained batch 368 in epoch 9, gen_loss = 0.9457728812688089, disc_loss = 0.0005630422963257273
Trained batch 369 in epoch 9, gen_loss = 0.9460016200671325, disc_loss = 0.0005670696697543954
Trained batch 370 in epoch 9, gen_loss = 0.9458750020461584, disc_loss = 0.0005690599957228741
Trained batch 371 in epoch 9, gen_loss = 0.945960898392944, disc_loss = 0.0005697261146050677
Trained batch 372 in epoch 9, gen_loss = 0.9457746082592267, disc_loss = 0.0005696167639268177
Trained batch 373 in epoch 9, gen_loss = 0.945721738319346, disc_loss = 0.0005692483969798491
Trained batch 374 in epoch 9, gen_loss = 0.9457372206052145, disc_loss = 0.0005686108637601137
Trained batch 375 in epoch 9, gen_loss = 0.9459159264856196, disc_loss = 0.0005679431656546435
Trained batch 376 in epoch 9, gen_loss = 0.9459305606406943, disc_loss = 0.0005677888967808266
Trained batch 377 in epoch 9, gen_loss = 0.9460230034495157, disc_loss = 0.0005684048296186442
Trained batch 378 in epoch 9, gen_loss = 0.9458825732913055, disc_loss = 0.000569392769108465
Trained batch 379 in epoch 9, gen_loss = 0.9459415773027822, disc_loss = 0.0005705892408609782
Trained batch 380 in epoch 9, gen_loss = 0.9458723554773907, disc_loss = 0.0005712392518426392
Trained batch 381 in epoch 9, gen_loss = 0.9458543797125991, disc_loss = 0.0005711626649422191
Trained batch 382 in epoch 9, gen_loss = 0.9459977434758418, disc_loss = 0.000570836695374352
Trained batch 383 in epoch 9, gen_loss = 0.9458986314324042, disc_loss = 0.0005706938995899691
Trained batch 384 in epoch 9, gen_loss = 0.9459659749811345, disc_loss = 0.0005708113814667835
Trained batch 385 in epoch 9, gen_loss = 0.945939575452261, disc_loss = 0.0005709396959029119
Trained batch 386 in epoch 9, gen_loss = 0.9459253937699074, disc_loss = 0.0005715056997844203
Trained batch 387 in epoch 9, gen_loss = 0.9458783299652571, disc_loss = 0.0005719063423403548
Trained batch 388 in epoch 9, gen_loss = 0.9460345659893399, disc_loss = 0.0005716779761574204
Trained batch 389 in epoch 9, gen_loss = 0.9462456101026291, disc_loss = 0.0005708584790297139
Trained batch 390 in epoch 9, gen_loss = 0.9462488657983062, disc_loss = 0.0005698558627157365
Trained batch 391 in epoch 9, gen_loss = 0.9463247129199456, disc_loss = 0.0005691094230147725
Trained batch 392 in epoch 9, gen_loss = 0.9463803751474725, disc_loss = 0.0005685869638710911
Trained batch 393 in epoch 9, gen_loss = 0.9463571880372043, disc_loss = 0.000568083256762593
Trained batch 394 in epoch 9, gen_loss = 0.9462292992616002, disc_loss = 0.0005679816163080167
Trained batch 395 in epoch 9, gen_loss = 0.9462876544155255, disc_loss = 0.0005689484726213097
Trained batch 396 in epoch 9, gen_loss = 0.9460404591836618, disc_loss = 0.0005709004455148677
Trained batch 397 in epoch 9, gen_loss = 0.9458672943426736, disc_loss = 0.0005732464738483845
Trained batch 398 in epoch 9, gen_loss = 0.945949731912828, disc_loss = 0.0005745530343074165
Trained batch 399 in epoch 9, gen_loss = 0.9461063200235367, disc_loss = 0.0005749645207106369
Trained batch 400 in epoch 9, gen_loss = 0.9459777758305804, disc_loss = 0.000574879994295988
Trained batch 401 in epoch 9, gen_loss = 0.9460882250942401, disc_loss = 0.0005746158765135472
Trained batch 402 in epoch 9, gen_loss = 0.9459644516111899, disc_loss = 0.000574352353592877
Trained batch 403 in epoch 9, gen_loss = 0.946033784658602, disc_loss = 0.0005740332644113505
Trained batch 404 in epoch 9, gen_loss = 0.9459408760070801, disc_loss = 0.0005732940272773029
Trained batch 405 in epoch 9, gen_loss = 0.945881802166624, disc_loss = 0.000572175732679009
Trained batch 406 in epoch 9, gen_loss = 0.9459557644565216, disc_loss = 0.000571047277974236
Trained batch 407 in epoch 9, gen_loss = 0.9459359505597282, disc_loss = 0.0005700446522228851
Trained batch 408 in epoch 9, gen_loss = 0.9459622713639275, disc_loss = 0.0005691950868544496
Trained batch 409 in epoch 9, gen_loss = 0.9458855140499952, disc_loss = 0.0005684984816847335
Trained batch 410 in epoch 9, gen_loss = 0.9459547042266586, disc_loss = 0.000568080008675887
Trained batch 411 in epoch 9, gen_loss = 0.9461430209932975, disc_loss = 0.0005678366272247145
Trained batch 412 in epoch 9, gen_loss = 0.9462229570522724, disc_loss = 0.0005674970179428933
Trained batch 413 in epoch 9, gen_loss = 0.946167448580553, disc_loss = 0.0005673656353041145
Trained batch 414 in epoch 9, gen_loss = 0.9462975007941924, disc_loss = 0.0005678626065070921
Trained batch 415 in epoch 9, gen_loss = 0.9461074322462082, disc_loss = 0.0005692892640616684
Trained batch 416 in epoch 9, gen_loss = 0.9459653335223667, disc_loss = 0.000571099812225902
Trained batch 417 in epoch 9, gen_loss = 0.9458954881823234, disc_loss = 0.0005723241605116645
Trained batch 418 in epoch 9, gen_loss = 0.9459773293542976, disc_loss = 0.0005727158337204966
Trained batch 419 in epoch 9, gen_loss = 0.9460901467573075, disc_loss = 0.0005725693047896216
Trained batch 420 in epoch 9, gen_loss = 0.9462958486516232, disc_loss = 0.0005721929336732393
Trained batch 421 in epoch 9, gen_loss = 0.9462650599072895, disc_loss = 0.0005714387650458391
Trained batch 422 in epoch 9, gen_loss = 0.9462020456368196, disc_loss = 0.0005705877273855676
Trained batch 423 in epoch 9, gen_loss = 0.9462344993679028, disc_loss = 0.000569714408399859
Trained batch 424 in epoch 9, gen_loss = 0.9462219949329601, disc_loss = 0.0005689259254380458
Trained batch 425 in epoch 9, gen_loss = 0.9464154244868408, disc_loss = 0.0005682965127502277
Trained batch 426 in epoch 9, gen_loss = 0.9463616303872727, disc_loss = 0.0005675399492379437
Trained batch 427 in epoch 9, gen_loss = 0.9463612406610329, disc_loss = 0.0005671056469084497
Trained batch 428 in epoch 9, gen_loss = 0.94662815596396, disc_loss = 0.0005681396262468672
Trained batch 429 in epoch 9, gen_loss = 0.9467237927192865, disc_loss = 0.0005701139120034451
Trained batch 430 in epoch 9, gen_loss = 0.9469081993169408, disc_loss = 0.0005705543015193542
Trained batch 431 in epoch 9, gen_loss = 0.9467875201393057, disc_loss = 0.0005703382516912825
Trained batch 432 in epoch 9, gen_loss = 0.9466613423741718, disc_loss = 0.0005708042161753476
Trained batch 433 in epoch 9, gen_loss = 0.9466220601912467, disc_loss = 0.0005711507274854278
Trained batch 434 in epoch 9, gen_loss = 0.9466266448470367, disc_loss = 0.0005713198322772005
Trained batch 435 in epoch 9, gen_loss = 0.9465402390705336, disc_loss = 0.0005714956980494734
Trained batch 436 in epoch 9, gen_loss = 0.9466779372512066, disc_loss = 0.0005726243113840236
Trained batch 437 in epoch 9, gen_loss = 0.9464704135781554, disc_loss = 0.0005744414590385511
Trained batch 438 in epoch 9, gen_loss = 0.9463983776900654, disc_loss = 0.0005769037288659494
Trained batch 439 in epoch 9, gen_loss = 0.9464265433224764, disc_loss = 0.0005797615749212458
Trained batch 440 in epoch 9, gen_loss = 0.9464566645438439, disc_loss = 0.0005825095849890154
Trained batch 441 in epoch 9, gen_loss = 0.9464596420931061, disc_loss = 0.0005842632929905374
Trained batch 442 in epoch 9, gen_loss = 0.9466321815486417, disc_loss = 0.000585064829570114
Trained batch 443 in epoch 9, gen_loss = 0.9466495496464206, disc_loss = 0.0005858331338245776
Trained batch 444 in epoch 9, gen_loss = 0.9465784150562929, disc_loss = 0.0005866660218027922
Trained batch 445 in epoch 9, gen_loss = 0.9468810061168244, disc_loss = 0.000587188126183258
Trained batch 446 in epoch 9, gen_loss = 0.946858320726911, disc_loss = 0.000587336846992037
Trained batch 447 in epoch 9, gen_loss = 0.9469707355435405, disc_loss = 0.000587233438198252
Trained batch 448 in epoch 9, gen_loss = 0.9470696570082072, disc_loss = 0.0005870015459880077
Trained batch 449 in epoch 9, gen_loss = 0.9471304313341776, disc_loss = 0.0005867516506987158
Trained batch 450 in epoch 9, gen_loss = 0.947073256361511, disc_loss = 0.0005864146596912404
Trained batch 451 in epoch 9, gen_loss = 0.9470782132275337, disc_loss = 0.0005859217386564242
Trained batch 452 in epoch 9, gen_loss = 0.947070488340281, disc_loss = 0.0005854870403982405
Trained batch 453 in epoch 9, gen_loss = 0.9469980095976774, disc_loss = 0.000585402874971585
Trained batch 454 in epoch 9, gen_loss = 0.946923563506577, disc_loss = 0.0005851665304002741
Trained batch 455 in epoch 9, gen_loss = 0.9468718453457481, disc_loss = 0.0005845119504125538
Trained batch 456 in epoch 9, gen_loss = 0.9470563039216223, disc_loss = 0.0005840725427106505
Trained batch 457 in epoch 9, gen_loss = 0.947242952590426, disc_loss = 0.0005842909940441421
Testing Epoch 9
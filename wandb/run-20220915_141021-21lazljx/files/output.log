/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.6749559044837952, disc_loss = 0.550228476524353
Trained batch 1 in epoch 0, gen_loss = 0.7914029359817505, disc_loss = 0.9618310332298279
Trained batch 2 in epoch 0, gen_loss = 0.7657650907834371, disc_loss = 0.8491586446762085
Trained batch 3 in epoch 0, gen_loss = 0.7264192253351212, disc_loss = 0.7143398076295853
Trained batch 4 in epoch 0, gen_loss = 0.6980612754821778, disc_loss = 0.6412604808807373
Trained batch 5 in epoch 0, gen_loss = 0.684324045976003, disc_loss = 0.5761210819085439
Trained batch 6 in epoch 0, gen_loss = 0.664392249924796, disc_loss = 0.5271021596023014
Trained batch 7 in epoch 0, gen_loss = 0.6413075514137745, disc_loss = 0.4872364401817322
Trained batch 8 in epoch 0, gen_loss = 0.6306487222512563, disc_loss = 0.45287149316734737
Trained batch 9 in epoch 0, gen_loss = 0.6254202395677566, disc_loss = 0.42666787654161453
Trained batch 10 in epoch 0, gen_loss = 0.6220928511836312, disc_loss = 0.4061330692334609
Trained batch 11 in epoch 0, gen_loss = 0.6259606207410494, disc_loss = 0.38699423521757126
Trained batch 12 in epoch 0, gen_loss = 0.6241052402899816, disc_loss = 0.3682500204214683
Trained batch 13 in epoch 0, gen_loss = 0.6158154330083302, disc_loss = 0.3522333343114172
Trained batch 14 in epoch 0, gen_loss = 0.611180204153061, disc_loss = 0.3375521312157313
Trained batch 15 in epoch 0, gen_loss = 0.6117970403283834, disc_loss = 0.3226106339134276
Trained batch 16 in epoch 0, gen_loss = 0.6091639206689947, disc_loss = 0.31053223066470204
Trained batch 17 in epoch 0, gen_loss = 0.6041407369905047, disc_loss = 0.3046281801329719
Trained batch 18 in epoch 0, gen_loss = 0.6073129067295476, disc_loss = 0.2968635872790688
Trained batch 19 in epoch 0, gen_loss = 0.6093957528471947, disc_loss = 0.2904109925031662
Trained batch 20 in epoch 0, gen_loss = 0.6119090190955571, disc_loss = 0.2809640782929602
Trained batch 21 in epoch 0, gen_loss = 0.6104762134226885, disc_loss = 0.27320878309282387
Trained batch 22 in epoch 0, gen_loss = 0.608736241641252, disc_loss = 0.2663324235574059
Trained batch 23 in epoch 0, gen_loss = 0.6105114482343197, disc_loss = 0.26191137234369916
Trained batch 24 in epoch 0, gen_loss = 0.6122815763950348, disc_loss = 0.25625613510608675
Trained batch 25 in epoch 0, gen_loss = 0.6145566484102836, disc_loss = 0.2502767452253745
Trained batch 26 in epoch 0, gen_loss = 0.6171408461199867, disc_loss = 0.24494413010500096
Trained batch 27 in epoch 0, gen_loss = 0.6181518595133509, disc_loss = 0.24007312314850943
Trained batch 28 in epoch 0, gen_loss = 0.6216467300365711, disc_loss = 0.2347738578401763
Trained batch 29 in epoch 0, gen_loss = 0.6237648616234461, disc_loss = 0.22943111956119538
Trained batch 30 in epoch 0, gen_loss = 0.6258419357961224, disc_loss = 0.22443344203695173
Trained batch 31 in epoch 0, gen_loss = 0.6262667058035731, disc_loss = 0.21963023277930915
Trained batch 32 in epoch 0, gen_loss = 0.6299829148884976, disc_loss = 0.21459253775802525
Trained batch 33 in epoch 0, gen_loss = 0.6329538936124128, disc_loss = 0.2102728870642536
Trained batch 34 in epoch 0, gen_loss = 0.634066310099193, disc_loss = 0.20704169688480242
Trained batch 35 in epoch 0, gen_loss = 0.6374485335416264, disc_loss = 0.20314745739516285
Trained batch 36 in epoch 0, gen_loss = 0.639215420226793, disc_loss = 0.19905234520902504
Trained batch 37 in epoch 0, gen_loss = 0.6400907220024812, disc_loss = 0.19638029574171492
Trained batch 38 in epoch 0, gen_loss = 0.6449157037796118, disc_loss = 0.1943714111470259
Trained batch 39 in epoch 0, gen_loss = 0.6470586977899074, disc_loss = 0.192644748929888
Trained batch 40 in epoch 0, gen_loss = 0.6485249334719123, disc_loss = 0.19128504695325363
Trained batch 41 in epoch 0, gen_loss = 0.650413345013346, disc_loss = 0.1913291160017252
Trained batch 42 in epoch 0, gen_loss = 0.6510394596776297, disc_loss = 0.19137468076376027
Trained batch 43 in epoch 0, gen_loss = 0.6524543457410552, disc_loss = 0.18868287559598684
Trained batch 44 in epoch 0, gen_loss = 0.6519392801655663, disc_loss = 0.18626602565248807
Trained batch 45 in epoch 0, gen_loss = 0.6517768288436143, disc_loss = 0.18416789635691955
Trained batch 46 in epoch 0, gen_loss = 0.6542120810518873, disc_loss = 0.182374220975536
Trained batch 47 in epoch 0, gen_loss = 0.6568751552452644, disc_loss = 0.18175477076632282
Trained batch 48 in epoch 0, gen_loss = 0.6579608923318435, disc_loss = 0.18167643621563911
Trained batch 49 in epoch 0, gen_loss = 0.6617841511964798, disc_loss = 0.1799303137511015
Trained batch 50 in epoch 0, gen_loss = 0.6609852261403028, disc_loss = 0.17882811519152977
Trained batch 51 in epoch 0, gen_loss = 0.6643364492517251, disc_loss = 0.1782418216507022
Trained batch 52 in epoch 0, gen_loss = 0.6661570021566355, disc_loss = 0.1761930948299057
Trained batch 53 in epoch 0, gen_loss = 0.6682700310592298, disc_loss = 0.1738332329938809
Trained batch 54 in epoch 0, gen_loss = 0.6693607942624525, disc_loss = 0.1719647740098563
Trained batch 55 in epoch 0, gen_loss = 0.6696829737297126, disc_loss = 0.1717969290246921
Trained batch 56 in epoch 0, gen_loss = 0.6721783735250172, disc_loss = 0.1709554755504717
Trained batch 57 in epoch 0, gen_loss = 0.6721859558902937, disc_loss = 0.16905923393265954
Trained batch 58 in epoch 0, gen_loss = 0.670743498256651, disc_loss = 0.16819956052606388
Trained batch 59 in epoch 0, gen_loss = 0.6723979935050011, disc_loss = 0.16753204328318436
Trained batch 60 in epoch 0, gen_loss = 0.6713829123582996, disc_loss = 0.1676081258986817
Trained batch 61 in epoch 0, gen_loss = 0.6725032718912247, disc_loss = 0.1664257604748972
Trained batch 62 in epoch 0, gen_loss = 0.6726525203576164, disc_loss = 0.1648595557799415
Trained batch 63 in epoch 0, gen_loss = 0.6722362055443227, disc_loss = 0.16398612584453076
Trained batch 64 in epoch 0, gen_loss = 0.6735236273362086, disc_loss = 0.16288364048187548
Trained batch 65 in epoch 0, gen_loss = 0.6730932209527853, disc_loss = 0.16164148903705858
Trained batch 66 in epoch 0, gen_loss = 0.6726861120159946, disc_loss = 0.1604779186978269
Trained batch 67 in epoch 0, gen_loss = 0.6734280502971481, disc_loss = 0.15996270824004621
Trained batch 68 in epoch 0, gen_loss = 0.6722118064113285, disc_loss = 0.16050451475641
Trained batch 69 in epoch 0, gen_loss = 0.6745067651782717, disc_loss = 0.15978532752820424
Trained batch 70 in epoch 0, gen_loss = 0.6747889069604202, disc_loss = 0.1584795589598132
Trained batch 71 in epoch 0, gen_loss = 0.6747793840865294, disc_loss = 0.15751342951423591
Trained batch 72 in epoch 0, gen_loss = 0.6760559290239255, disc_loss = 0.1566949292813262
Trained batch 73 in epoch 0, gen_loss = 0.6753174924367183, disc_loss = 0.15595985143571287
Trained batch 74 in epoch 0, gen_loss = 0.675417396624883, disc_loss = 0.1552236337463061
Trained batch 75 in epoch 0, gen_loss = 0.6748122294482432, disc_loss = 0.15492586997386656
Trained batch 76 in epoch 0, gen_loss = 0.6772260716209164, disc_loss = 0.15689409911245494
Trained batch 77 in epoch 0, gen_loss = 0.6760768764294111, disc_loss = 0.15976763125031423
Trained batch 78 in epoch 0, gen_loss = 0.6750403487984138, disc_loss = 0.15990689632636082
Trained batch 79 in epoch 0, gen_loss = 0.676178264990449, disc_loss = 0.16117185624316335
Trained batch 80 in epoch 0, gen_loss = 0.6751483962123777, disc_loss = 0.160584421897376
Trained batch 81 in epoch 0, gen_loss = 0.6728980065118976, disc_loss = 0.16010496011231004
Trained batch 82 in epoch 0, gen_loss = 0.6736312820968857, disc_loss = 0.15915123831076794
Trained batch 83 in epoch 0, gen_loss = 0.6739874059955279, disc_loss = 0.1579848268024978
Trained batch 84 in epoch 0, gen_loss = 0.6740715766654295, disc_loss = 0.15715910345315934
Trained batch 85 in epoch 0, gen_loss = 0.6739379961130231, disc_loss = 0.15587445664717708
Trained batch 86 in epoch 0, gen_loss = 0.6741539270713411, disc_loss = 0.1547359818185883
Trained batch 87 in epoch 0, gen_loss = 0.6735649735412814, disc_loss = 0.15400909556245262
Trained batch 88 in epoch 0, gen_loss = 0.6742953326594964, disc_loss = 0.15289472240243066
Trained batch 89 in epoch 0, gen_loss = 0.674912949734264, disc_loss = 0.15205820554660426
Trained batch 90 in epoch 0, gen_loss = 0.6747797586760678, disc_loss = 0.15136251569940493
Trained batch 91 in epoch 0, gen_loss = 0.6737322668018548, disc_loss = 0.15102622767343468
Trained batch 92 in epoch 0, gen_loss = 0.6751006601318237, disc_loss = 0.15353736774094642
Trained batch 93 in epoch 0, gen_loss = 0.6740185031865505, disc_loss = 0.15400289201197473
Trained batch 94 in epoch 0, gen_loss = 0.6739448431291079, disc_loss = 0.15381841106634392
Trained batch 95 in epoch 0, gen_loss = 0.673504532314837, disc_loss = 0.15387451784530035
Trained batch 96 in epoch 0, gen_loss = 0.6733816219973809, disc_loss = 0.1543672165843015
Trained batch 97 in epoch 0, gen_loss = 0.6733689232140171, disc_loss = 0.15453587331790097
Trained batch 98 in epoch 0, gen_loss = 0.6732158838498472, disc_loss = 0.15421098429295751
Trained batch 99 in epoch 0, gen_loss = 0.6725213572382926, disc_loss = 0.15362654764205216
Trained batch 100 in epoch 0, gen_loss = 0.6725309517714056, disc_loss = 0.15305046917925966
Trained batch 101 in epoch 0, gen_loss = 0.6717036632346172, disc_loss = 0.15265844985112256
Trained batch 102 in epoch 0, gen_loss = 0.6716332733631134, disc_loss = 0.15299943136503397
Trained batch 103 in epoch 0, gen_loss = 0.6704366605442303, disc_loss = 0.15496880005901822
Trained batch 104 in epoch 0, gen_loss = 0.6701526468708402, disc_loss = 0.1548907537190687
Trained batch 105 in epoch 0, gen_loss = 0.6715834351643076, disc_loss = 0.15489824330609925
Trained batch 106 in epoch 0, gen_loss = 0.6712860194879158, disc_loss = 0.15485220385071274
Trained batch 107 in epoch 0, gen_loss = 0.6711874667693067, disc_loss = 0.155014894247331
Trained batch 108 in epoch 0, gen_loss = 0.6714531738276875, disc_loss = 0.15521507829837844
Trained batch 109 in epoch 0, gen_loss = 0.6704815319993279, disc_loss = 0.15509501157159156
Trained batch 110 in epoch 0, gen_loss = 0.6708149101820078, disc_loss = 0.15525779104581824
Trained batch 111 in epoch 0, gen_loss = 0.6694608540939433, disc_loss = 0.15641181546795582
Trained batch 112 in epoch 0, gen_loss = 0.6702940587976337, disc_loss = 0.1571806052419464
Trained batch 113 in epoch 0, gen_loss = 0.6709519789407128, disc_loss = 0.15640575736107534
Trained batch 114 in epoch 0, gen_loss = 0.670768204720124, disc_loss = 0.15628253360805305
Trained batch 115 in epoch 0, gen_loss = 0.6704002343888941, disc_loss = 0.15676748762228365
Trained batch 116 in epoch 0, gen_loss = 0.671126853961211, disc_loss = 0.1571205454185987
Trained batch 117 in epoch 0, gen_loss = 0.6706059400813055, disc_loss = 0.1570619180230266
Trained batch 118 in epoch 0, gen_loss = 0.6698813736438751, disc_loss = 0.157175478533286
Trained batch 119 in epoch 0, gen_loss = 0.6691986478865146, disc_loss = 0.1574875062641998
Trained batch 120 in epoch 0, gen_loss = 0.6684759177944877, disc_loss = 0.15781905221914458
Trained batch 121 in epoch 0, gen_loss = 0.6677125641068474, disc_loss = 0.15845173862991763
Trained batch 122 in epoch 0, gen_loss = 0.6665571717227378, disc_loss = 0.1594163617649214
Trained batch 123 in epoch 0, gen_loss = 0.6667022548856274, disc_loss = 0.15946192952293542
Trained batch 124 in epoch 0, gen_loss = 0.6664841034412384, disc_loss = 0.15903310266137122
Trained batch 125 in epoch 0, gen_loss = 0.6654047116873756, disc_loss = 0.1593272937018247
Trained batch 126 in epoch 0, gen_loss = 0.665427862893878, disc_loss = 0.15997213550557302
Trained batch 127 in epoch 0, gen_loss = 0.6649346614722162, disc_loss = 0.16095298927393742
Trained batch 128 in epoch 0, gen_loss = 0.6640269721663276, disc_loss = 0.16110336529307587
Trained batch 129 in epoch 0, gen_loss = 0.6633811664122802, disc_loss = 0.16138834268427812
Trained batch 130 in epoch 0, gen_loss = 0.6626466942652491, disc_loss = 0.16148237966512904
Trained batch 131 in epoch 0, gen_loss = 0.6615115812782085, disc_loss = 0.16200225137061242
Trained batch 132 in epoch 0, gen_loss = 0.6607444808447271, disc_loss = 0.16181071351905515
Trained batch 133 in epoch 0, gen_loss = 0.6602021804941234, disc_loss = 0.1616981939426554
Trained batch 134 in epoch 0, gen_loss = 0.660492362137194, disc_loss = 0.16162704452872276
Trained batch 135 in epoch 0, gen_loss = 0.6594159232781214, disc_loss = 0.1617074554293033
Trained batch 136 in epoch 0, gen_loss = 0.6596207916736603, disc_loss = 0.16299671220192075
Trained batch 137 in epoch 0, gen_loss = 0.6590265594962714, disc_loss = 0.16436029498235902
Trained batch 138 in epoch 0, gen_loss = 0.6582332602936587, disc_loss = 0.16489044542042472
Trained batch 139 in epoch 0, gen_loss = 0.658168690758092, disc_loss = 0.16536229659936258
Trained batch 140 in epoch 0, gen_loss = 0.6574405514179392, disc_loss = 0.16557145353855815
Trained batch 141 in epoch 0, gen_loss = 0.6564817833648601, disc_loss = 0.16571533913448663
Trained batch 142 in epoch 0, gen_loss = 0.6564772960606154, disc_loss = 0.1658598056675254
Trained batch 143 in epoch 0, gen_loss = 0.6562282875594165, disc_loss = 0.16597904422734347
Trained batch 144 in epoch 0, gen_loss = 0.6557549569113501, disc_loss = 0.16601207865209416
Trained batch 145 in epoch 0, gen_loss = 0.6555391352062356, disc_loss = 0.16618719107586227
Trained batch 146 in epoch 0, gen_loss = 0.6545962433831222, disc_loss = 0.1665406011450453
Trained batch 147 in epoch 0, gen_loss = 0.6540751422981959, disc_loss = 0.16648710219541918
Trained batch 148 in epoch 0, gen_loss = 0.6538149544456661, disc_loss = 0.16645719493495537
Trained batch 149 in epoch 0, gen_loss = 0.652938101887703, disc_loss = 0.16674628637731076
Trained batch 150 in epoch 0, gen_loss = 0.6526168985477346, disc_loss = 0.16688055118286846
Trained batch 151 in epoch 0, gen_loss = 0.6521007365694171, disc_loss = 0.16688677445544223
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.6443819403648376, disc_loss = 0.1728101372718811
Trained batch 1 in epoch 1, gen_loss = 0.6003999412059784, disc_loss = 0.19522231817245483
Trained batch 2 in epoch 1, gen_loss = 0.6287168661753336, disc_loss = 0.2197277843952179
Trained batch 3 in epoch 1, gen_loss = 0.5927123203873634, disc_loss = 0.2852952480316162
Trained batch 4 in epoch 1, gen_loss = 0.5763741075992584, disc_loss = 0.25752480030059816
Trained batch 5 in epoch 1, gen_loss = 0.5863146136204401, disc_loss = 0.2511345098416011
Trained batch 6 in epoch 1, gen_loss = 0.581596029656274, disc_loss = 0.2447152818952288
Trained batch 7 in epoch 1, gen_loss = 0.5797885619103909, disc_loss = 0.23812569491565228
Trained batch 8 in epoch 1, gen_loss = 0.5794302920500437, disc_loss = 0.23368128140767416
Trained batch 9 in epoch 1, gen_loss = 0.5708580553531647, disc_loss = 0.23088729828596116
Trained batch 10 in epoch 1, gen_loss = 0.5691611550071023, disc_loss = 0.2278186556967822
Trained batch 11 in epoch 1, gen_loss = 0.5679972867170969, disc_loss = 0.22525488461057344
Trained batch 12 in epoch 1, gen_loss = 0.5627165895241958, disc_loss = 0.22252266108989716
Trained batch 13 in epoch 1, gen_loss = 0.5593769890921456, disc_loss = 0.22010894545486995
Trained batch 14 in epoch 1, gen_loss = 0.5594244798024496, disc_loss = 0.21607057650883993
Trained batch 15 in epoch 1, gen_loss = 0.5606095492839813, disc_loss = 0.2110795211046934
Trained batch 16 in epoch 1, gen_loss = 0.5578292783568887, disc_loss = 0.20914299523129182
Trained batch 17 in epoch 1, gen_loss = 0.5608284870783488, disc_loss = 0.2083739232685831
Trained batch 18 in epoch 1, gen_loss = 0.5533459123812223, disc_loss = 0.21110088809540398
Trained batch 19 in epoch 1, gen_loss = 0.5541144341230393, disc_loss = 0.20805829986929894
Trained batch 20 in epoch 1, gen_loss = 0.5595932148751759, disc_loss = 0.20853535689058758
Trained batch 21 in epoch 1, gen_loss = 0.5552683526819403, disc_loss = 0.21107448976148258
Trained batch 22 in epoch 1, gen_loss = 0.5528910496960515, disc_loss = 0.2094094448763391
Trained batch 23 in epoch 1, gen_loss = 0.5557378679513931, disc_loss = 0.20983943156898022
Trained batch 24 in epoch 1, gen_loss = 0.5515008282661438, disc_loss = 0.20945762753486633
Trained batch 25 in epoch 1, gen_loss = 0.5472799081068772, disc_loss = 0.21012941461343032
Trained batch 26 in epoch 1, gen_loss = 0.5497404601838853, disc_loss = 0.20817919517004932
Trained batch 27 in epoch 1, gen_loss = 0.5501272359064647, disc_loss = 0.20653924558843886
Trained batch 28 in epoch 1, gen_loss = 0.5507929900596882, disc_loss = 0.2049102058698391
Trained batch 29 in epoch 1, gen_loss = 0.5520481328169505, disc_loss = 0.20215914671619734
Trained batch 30 in epoch 1, gen_loss = 0.5544715869811273, disc_loss = 0.2003783903294994
Trained batch 31 in epoch 1, gen_loss = 0.55350605212152, disc_loss = 0.19903761451132596
Trained batch 32 in epoch 1, gen_loss = 0.5578006036353834, disc_loss = 0.19895979197639407
Trained batch 33 in epoch 1, gen_loss = 0.5563726547886344, disc_loss = 0.20396933638874223
Trained batch 34 in epoch 1, gen_loss = 0.5602251802171979, disc_loss = 0.2036975513611521
Trained batch 35 in epoch 1, gen_loss = 0.5600898431407081, disc_loss = 0.20264731326864827
Trained batch 36 in epoch 1, gen_loss = 0.5585492817131249, disc_loss = 0.20285334196445104
Trained batch 37 in epoch 1, gen_loss = 0.5594949973256964, disc_loss = 0.20346622110197418
Trained batch 38 in epoch 1, gen_loss = 0.5555322139691083, disc_loss = 0.20534077000159484
Trained batch 39 in epoch 1, gen_loss = 0.5545471280813217, disc_loss = 0.205000870116055
Trained batch 40 in epoch 1, gen_loss = 0.5573331481072961, disc_loss = 0.20664329517905305
Trained batch 41 in epoch 1, gen_loss = 0.5554457697130385, disc_loss = 0.20681815257384664
Trained batch 42 in epoch 1, gen_loss = 0.5551396019236986, disc_loss = 0.20630254353894745
Trained batch 43 in epoch 1, gen_loss = 0.5557637641375716, disc_loss = 0.20640748722309415
Trained batch 44 in epoch 1, gen_loss = 0.5545570539103614, disc_loss = 0.2051069983177715
Trained batch 45 in epoch 1, gen_loss = 0.553539211983266, disc_loss = 0.20405269624746364
Trained batch 46 in epoch 1, gen_loss = 0.553429145128169, disc_loss = 0.20256121028611002
Trained batch 47 in epoch 1, gen_loss = 0.553443280979991, disc_loss = 0.20097943193589649
Trained batch 48 in epoch 1, gen_loss = 0.5528394658954776, disc_loss = 0.19948389928559868
Trained batch 49 in epoch 1, gen_loss = 0.5533858913183213, disc_loss = 0.1981254203617573
Trained batch 50 in epoch 1, gen_loss = 0.5541607614825753, disc_loss = 0.1968335575040649
Trained batch 51 in epoch 1, gen_loss = 0.5539441114434829, disc_loss = 0.19599898173831976
Trained batch 52 in epoch 1, gen_loss = 0.5524772731763012, disc_loss = 0.19667422982319346
Trained batch 53 in epoch 1, gen_loss = 0.5535526739226447, disc_loss = 0.19626445337026208
Trained batch 54 in epoch 1, gen_loss = 0.5535882711410522, disc_loss = 0.19529326138171282
Trained batch 55 in epoch 1, gen_loss = 0.5554885353360858, disc_loss = 0.19501597766897508
Trained batch 56 in epoch 1, gen_loss = 0.5543903917597052, disc_loss = 0.19633908347602477
Trained batch 57 in epoch 1, gen_loss = 0.5554221796578375, disc_loss = 0.19642951044029203
Trained batch 58 in epoch 1, gen_loss = 0.5532329941199998, disc_loss = 0.1959517763580306
Trained batch 59 in epoch 1, gen_loss = 0.5520526692271233, disc_loss = 0.1954098928719759
Trained batch 60 in epoch 1, gen_loss = 0.5531438222674073, disc_loss = 0.19534679819814493
Trained batch 61 in epoch 1, gen_loss = 0.5517541198961197, disc_loss = 0.19714968254969967
Trained batch 62 in epoch 1, gen_loss = 0.5541808274057176, disc_loss = 0.1995067356361283
Trained batch 63 in epoch 1, gen_loss = 0.5546456938609481, disc_loss = 0.19799422041978687
Trained batch 64 in epoch 1, gen_loss = 0.5532339022709774, disc_loss = 0.19754849018958898
Trained batch 65 in epoch 1, gen_loss = 0.5529218279954159, disc_loss = 0.19766810863758577
Trained batch 66 in epoch 1, gen_loss = 0.5548306587916702, disc_loss = 0.19974410144695595
Trained batch 67 in epoch 1, gen_loss = 0.5547921166700476, disc_loss = 0.19918935537776528
Trained batch 68 in epoch 1, gen_loss = 0.5541127902874048, disc_loss = 0.19926464741212735
Trained batch 69 in epoch 1, gen_loss = 0.5543323329516819, disc_loss = 0.19905999505094119
Trained batch 70 in epoch 1, gen_loss = 0.5538054436025485, disc_loss = 0.19852887398340333
Trained batch 71 in epoch 1, gen_loss = 0.5532893985509872, disc_loss = 0.19819865613761875
Trained batch 72 in epoch 1, gen_loss = 0.5527056365796964, disc_loss = 0.197792418505231
Trained batch 73 in epoch 1, gen_loss = 0.5520943185767612, disc_loss = 0.19744374492281191
Trained batch 74 in epoch 1, gen_loss = 0.5512822858492533, disc_loss = 0.19756025244792302
Trained batch 75 in epoch 1, gen_loss = 0.5498814853398424, disc_loss = 0.19906201615537467
Trained batch 76 in epoch 1, gen_loss = 0.5508834978976807, disc_loss = 0.19868625497276132
Trained batch 77 in epoch 1, gen_loss = 0.5510179977386426, disc_loss = 0.19922833383465424
Trained batch 78 in epoch 1, gen_loss = 0.5495499696912645, disc_loss = 0.20054456261517126
Trained batch 79 in epoch 1, gen_loss = 0.548707377910614, disc_loss = 0.20082332836464048
Trained batch 80 in epoch 1, gen_loss = 0.5501718594704146, disc_loss = 0.2016806529811871
Trained batch 81 in epoch 1, gen_loss = 0.5491480220381807, disc_loss = 0.2011785326389278
Trained batch 82 in epoch 1, gen_loss = 0.5478108248796808, disc_loss = 0.2015107727373939
Trained batch 83 in epoch 1, gen_loss = 0.5484116180312066, disc_loss = 0.20126082260339034
Trained batch 84 in epoch 1, gen_loss = 0.5486688778680914, disc_loss = 0.2007031238254379
Trained batch 85 in epoch 1, gen_loss = 0.5473170339368111, disc_loss = 0.20052334137780722
Trained batch 86 in epoch 1, gen_loss = 0.5475777103298012, disc_loss = 0.20092553422711362
Trained batch 87 in epoch 1, gen_loss = 0.5473711494017731, disc_loss = 0.20066813692789187
Trained batch 88 in epoch 1, gen_loss = 0.5472507794921317, disc_loss = 0.20040216983369227
Trained batch 89 in epoch 1, gen_loss = 0.5486985256274541, disc_loss = 0.20131592493918207
Trained batch 90 in epoch 1, gen_loss = 0.5479572864024194, disc_loss = 0.20248650923207567
Trained batch 91 in epoch 1, gen_loss = 0.5473108437398205, disc_loss = 0.20244180127654388
Trained batch 92 in epoch 1, gen_loss = 0.5474040447383799, disc_loss = 0.20266985148191452
Trained batch 93 in epoch 1, gen_loss = 0.546904463400232, disc_loss = 0.2027169864704
Trained batch 94 in epoch 1, gen_loss = 0.5464164486056879, disc_loss = 0.20235857798864967
Trained batch 95 in epoch 1, gen_loss = 0.5458842072015008, disc_loss = 0.20181883087692162
Trained batch 96 in epoch 1, gen_loss = 0.5453808937490601, disc_loss = 0.20158939439918577
Trained batch 97 in epoch 1, gen_loss = 0.5450390300580433, disc_loss = 0.20123103770370387
Trained batch 98 in epoch 1, gen_loss = 0.545596595063354, disc_loss = 0.2017103729374481
Trained batch 99 in epoch 1, gen_loss = 0.5449061128497124, disc_loss = 0.2019421673566103
Trained batch 100 in epoch 1, gen_loss = 0.5444986144504925, disc_loss = 0.20162228494882584
Trained batch 101 in epoch 1, gen_loss = 0.5446593963048038, disc_loss = 0.20220311606923738
Trained batch 102 in epoch 1, gen_loss = 0.5435829336203418, disc_loss = 0.20259909266696394
Trained batch 103 in epoch 1, gen_loss = 0.5431479860383731, disc_loss = 0.20258493986553872
Trained batch 104 in epoch 1, gen_loss = 0.542497208856401, disc_loss = 0.20224194789216632
Trained batch 105 in epoch 1, gen_loss = 0.5424639174960694, disc_loss = 0.2016478476799884
Trained batch 106 in epoch 1, gen_loss = 0.5422037291192563, disc_loss = 0.20152388144040775
Trained batch 107 in epoch 1, gen_loss = 0.5412845147980584, disc_loss = 0.20154714646438757
Trained batch 108 in epoch 1, gen_loss = 0.5418196954858412, disc_loss = 0.20147798702530906
Trained batch 109 in epoch 1, gen_loss = 0.541370794989846, disc_loss = 0.2010638438165188
Trained batch 110 in epoch 1, gen_loss = 0.5405631583553177, disc_loss = 0.20182097904585503
Trained batch 111 in epoch 1, gen_loss = 0.5415867755987814, disc_loss = 0.20317922964958207
Trained batch 112 in epoch 1, gen_loss = 0.540986618109509, disc_loss = 0.20306340512712445
Trained batch 113 in epoch 1, gen_loss = 0.5403657045803572, disc_loss = 0.2028303062053103
Trained batch 114 in epoch 1, gen_loss = 0.54042107877524, disc_loss = 0.20266147042098254
Trained batch 115 in epoch 1, gen_loss = 0.5401982246287937, disc_loss = 0.20224512336326056
Trained batch 116 in epoch 1, gen_loss = 0.5399017840878576, disc_loss = 0.20180968653697234
Trained batch 117 in epoch 1, gen_loss = 0.5397814459214776, disc_loss = 0.20142798637182024
Trained batch 118 in epoch 1, gen_loss = 0.5398830979311166, disc_loss = 0.20113286895661794
Trained batch 119 in epoch 1, gen_loss = 0.5395892195403575, disc_loss = 0.20070326843609412
Trained batch 120 in epoch 1, gen_loss = 0.5387927345500505, disc_loss = 0.2005181782378638
Trained batch 121 in epoch 1, gen_loss = 0.5387632927445115, disc_loss = 0.20045438195105458
Trained batch 122 in epoch 1, gen_loss = 0.5380124977933682, disc_loss = 0.2004236881204737
Trained batch 123 in epoch 1, gen_loss = 0.5385053681750451, disc_loss = 0.2005324003797385
Trained batch 124 in epoch 1, gen_loss = 0.5380619814395905, disc_loss = 0.20015665680170058
Trained batch 125 in epoch 1, gen_loss = 0.537671599123213, disc_loss = 0.1997506326981007
Trained batch 126 in epoch 1, gen_loss = 0.5386486044080239, disc_loss = 0.2002633114851366
Trained batch 127 in epoch 1, gen_loss = 0.5375724674668163, disc_loss = 0.2011967659345828
Trained batch 128 in epoch 1, gen_loss = 0.5374344598877338, disc_loss = 0.20077251920173333
Trained batch 129 in epoch 1, gen_loss = 0.5378457713585634, disc_loss = 0.20106257526920393
Trained batch 130 in epoch 1, gen_loss = 0.5370094089107659, disc_loss = 0.20128039031765843
Trained batch 131 in epoch 1, gen_loss = 0.5364701802080328, disc_loss = 0.2011621773355838
Trained batch 132 in epoch 1, gen_loss = 0.536276300150649, disc_loss = 0.20100865244193183
Trained batch 133 in epoch 1, gen_loss = 0.5356371651834516, disc_loss = 0.20085707245700396
Trained batch 134 in epoch 1, gen_loss = 0.5350249405260439, disc_loss = 0.20066255259293098
Trained batch 135 in epoch 1, gen_loss = 0.5353754592292449, disc_loss = 0.2003699520821957
Trained batch 136 in epoch 1, gen_loss = 0.5353624272520525, disc_loss = 0.20042117891738015
Trained batch 137 in epoch 1, gen_loss = 0.5346131437066672, disc_loss = 0.20163299019138017
Trained batch 138 in epoch 1, gen_loss = 0.5342474691301798, disc_loss = 0.20122590966576295
Trained batch 139 in epoch 1, gen_loss = 0.534734474335398, disc_loss = 0.2016752424516848
Trained batch 140 in epoch 1, gen_loss = 0.5339625306586002, disc_loss = 0.20183165809998277
Trained batch 141 in epoch 1, gen_loss = 0.5334312567408656, disc_loss = 0.20165710576193432
Trained batch 142 in epoch 1, gen_loss = 0.5334699558211373, disc_loss = 0.2013725036611924
Trained batch 143 in epoch 1, gen_loss = 0.5334296863940027, disc_loss = 0.20121966752534112
Trained batch 144 in epoch 1, gen_loss = 0.5331464150856281, disc_loss = 0.20110371631794963
Trained batch 145 in epoch 1, gen_loss = 0.5335587148797022, disc_loss = 0.20101438539281283
Trained batch 146 in epoch 1, gen_loss = 0.5332401946288388, disc_loss = 0.2006092905288651
Trained batch 147 in epoch 1, gen_loss = 0.5330169817080369, disc_loss = 0.20027215985228886
Trained batch 148 in epoch 1, gen_loss = 0.532240407178866, disc_loss = 0.20008595282799446
Trained batch 149 in epoch 1, gen_loss = 0.5319427601496378, disc_loss = 0.1995284588634968
Trained batch 150 in epoch 1, gen_loss = 0.5318315025196959, disc_loss = 0.19909331996906673
Trained batch 151 in epoch 1, gen_loss = 0.5317473756639581, disc_loss = 0.1985340801704871
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.6135292053222656, disc_loss = 0.2890321612358093
Trained batch 1 in epoch 2, gen_loss = 0.5372950285673141, disc_loss = 0.3207557797431946
Trained batch 2 in epoch 2, gen_loss = 0.5314748585224152, disc_loss = 0.2558139810959498
Trained batch 3 in epoch 2, gen_loss = 0.5512365028262138, disc_loss = 0.25356414541602135
Trained batch 4 in epoch 2, gen_loss = 0.5249852776527405, disc_loss = 0.24435281455516816
Trained batch 5 in epoch 2, gen_loss = 0.522601713736852, disc_loss = 0.22570481896400452
Trained batch 6 in epoch 2, gen_loss = 0.53439918586186, disc_loss = 0.21192612179688045
Trained batch 7 in epoch 2, gen_loss = 0.5329763665795326, disc_loss = 0.1958408998325467
Trained batch 8 in epoch 2, gen_loss = 0.5318295227156745, disc_loss = 0.1873476497001118
Trained batch 9 in epoch 2, gen_loss = 0.5401727378368377, disc_loss = 0.18393840715289117
Trained batch 10 in epoch 2, gen_loss = 0.5353663292798129, disc_loss = 0.1769393337043849
Trained batch 11 in epoch 2, gen_loss = 0.5346391598383585, disc_loss = 0.16942763701081276
Trained batch 12 in epoch 2, gen_loss = 0.5394236858074481, disc_loss = 0.1654059858276294
Trained batch 13 in epoch 2, gen_loss = 0.5298223899943488, disc_loss = 0.175579589924642
Trained batch 14 in epoch 2, gen_loss = 0.5476161102453868, disc_loss = 0.18106473634640377
Trained batch 15 in epoch 2, gen_loss = 0.5418881978839636, disc_loss = 0.1775178825482726
Trained batch 16 in epoch 2, gen_loss = 0.5354712237330044, disc_loss = 0.19008954219958363
Trained batch 17 in epoch 2, gen_loss = 0.5358964221345054, disc_loss = 0.1854567900300026
Trained batch 18 in epoch 2, gen_loss = 0.5393789300793096, disc_loss = 0.18285175373679713
Trained batch 19 in epoch 2, gen_loss = 0.5366511717438698, disc_loss = 0.18081829622387885
Trained batch 20 in epoch 2, gen_loss = 0.5371253731704894, disc_loss = 0.17875789744513376
Trained batch 21 in epoch 2, gen_loss = 0.5355962365865707, disc_loss = 0.17524709146131168
Trained batch 22 in epoch 2, gen_loss = 0.5358048508996549, disc_loss = 0.16977740338315134
Trained batch 23 in epoch 2, gen_loss = 0.5319508947432041, disc_loss = 0.16844717133790255
Trained batch 24 in epoch 2, gen_loss = 0.5357812941074371, disc_loss = 0.17019255489110946
Trained batch 25 in epoch 2, gen_loss = 0.5305203761045749, disc_loss = 0.1719755447254731
Trained batch 26 in epoch 2, gen_loss = 0.5320337734840535, disc_loss = 0.17127047065231535
Trained batch 27 in epoch 2, gen_loss = 0.5336993709206581, disc_loss = 0.16959674363689764
Trained batch 28 in epoch 2, gen_loss = 0.5327355563640594, disc_loss = 0.1685041602829407
Trained batch 29 in epoch 2, gen_loss = 0.5355924715598425, disc_loss = 0.1717175933221976
Trained batch 30 in epoch 2, gen_loss = 0.533297352252468, disc_loss = 0.1838300009408305
Trained batch 31 in epoch 2, gen_loss = 0.5311999227851629, disc_loss = 0.18369921506382525
Trained batch 32 in epoch 2, gen_loss = 0.529802250139641, disc_loss = 0.18489076535810123
Trained batch 33 in epoch 2, gen_loss = 0.5282598243040197, disc_loss = 0.18493784240940037
Trained batch 34 in epoch 2, gen_loss = 0.5255689910479955, disc_loss = 0.18526994053806578
Trained batch 35 in epoch 2, gen_loss = 0.5252751128541099, disc_loss = 0.1848158250666327
Trained batch 36 in epoch 2, gen_loss = 0.5230968070996774, disc_loss = 0.18411274556372617
Trained batch 37 in epoch 2, gen_loss = 0.52256919286753, disc_loss = 0.18260127874581436
Trained batch 38 in epoch 2, gen_loss = 0.5231286860429324, disc_loss = 0.18176386161492422
Trained batch 39 in epoch 2, gen_loss = 0.5221121080219746, disc_loss = 0.18013350069522857
Trained batch 40 in epoch 2, gen_loss = 0.5226879170755061, disc_loss = 0.1786185993653972
Trained batch 41 in epoch 2, gen_loss = 0.5251882125933965, disc_loss = 0.17907465604089556
Trained batch 42 in epoch 2, gen_loss = 0.5222008401571319, disc_loss = 0.18735060130440911
Trained batch 43 in epoch 2, gen_loss = 0.5214419222690843, disc_loss = 0.18820771405642683
Trained batch 44 in epoch 2, gen_loss = 0.5204648799366421, disc_loss = 0.18927387562063006
Trained batch 45 in epoch 2, gen_loss = 0.5201568849708723, disc_loss = 0.18993716136268948
Trained batch 46 in epoch 2, gen_loss = 0.5194748741515139, disc_loss = 0.19023153978459378
Trained batch 47 in epoch 2, gen_loss = 0.5182304649303356, disc_loss = 0.18996250784645477
Trained batch 48 in epoch 2, gen_loss = 0.5180054167095496, disc_loss = 0.1897525991104087
Trained batch 49 in epoch 2, gen_loss = 0.5175211316347123, disc_loss = 0.1886955925822258
Trained batch 50 in epoch 2, gen_loss = 0.5173998936718586, disc_loss = 0.1878868940414167
Trained batch 51 in epoch 2, gen_loss = 0.5182411080369582, disc_loss = 0.18938253504725602
Trained batch 52 in epoch 2, gen_loss = 0.5163874210051771, disc_loss = 0.19116520291229464
Trained batch 53 in epoch 2, gen_loss = 0.5180904423749005, disc_loss = 0.1915205810908918
Trained batch 54 in epoch 2, gen_loss = 0.516690655188127, disc_loss = 0.19226891723546116
Trained batch 55 in epoch 2, gen_loss = 0.5164301874382156, disc_loss = 0.19160842709243298
Trained batch 56 in epoch 2, gen_loss = 0.5153411177166721, disc_loss = 0.19082370112862504
Trained batch 57 in epoch 2, gen_loss = 0.515077975289575, disc_loss = 0.19078138419266405
Trained batch 58 in epoch 2, gen_loss = 0.5159358109458018, disc_loss = 0.19069349285909684
Trained batch 59 in epoch 2, gen_loss = 0.5145993361870448, disc_loss = 0.1911521725356579
Trained batch 60 in epoch 2, gen_loss = 0.5135620534420013, disc_loss = 0.19088077081031488
Trained batch 61 in epoch 2, gen_loss = 0.5129021117764134, disc_loss = 0.19048270655255164
Trained batch 62 in epoch 2, gen_loss = 0.5124309862416888, disc_loss = 0.18986635264896212
Trained batch 63 in epoch 2, gen_loss = 0.5122097157873213, disc_loss = 0.1886663418263197
Trained batch 64 in epoch 2, gen_loss = 0.5106968049819652, disc_loss = 0.18851801982292762
Trained batch 65 in epoch 2, gen_loss = 0.5120690388209892, disc_loss = 0.18964028177839337
Trained batch 66 in epoch 2, gen_loss = 0.5109365177688314, disc_loss = 0.1911318573489118
Trained batch 67 in epoch 2, gen_loss = 0.5112858182367157, disc_loss = 0.19113638493068077
Trained batch 68 in epoch 2, gen_loss = 0.5115947477195574, disc_loss = 0.19075551737045895
Trained batch 69 in epoch 2, gen_loss = 0.5112125724554062, disc_loss = 0.1902847598705973
Trained batch 70 in epoch 2, gen_loss = 0.5110230928575489, disc_loss = 0.18962526636224397
Trained batch 71 in epoch 2, gen_loss = 0.5104491607182555, disc_loss = 0.18903903332021502
Trained batch 72 in epoch 2, gen_loss = 0.5098778748348968, disc_loss = 0.18876401896346107
Trained batch 73 in epoch 2, gen_loss = 0.5117437698551126, disc_loss = 0.18974474314096812
Trained batch 74 in epoch 2, gen_loss = 0.5105511077245076, disc_loss = 0.19068864305814107
Trained batch 75 in epoch 2, gen_loss = 0.5098300662479902, disc_loss = 0.19061539145676712
Trained batch 76 in epoch 2, gen_loss = 0.509331671448497, disc_loss = 0.19006910629860765
Trained batch 77 in epoch 2, gen_loss = 0.5083488359665259, disc_loss = 0.1894716821037806
Trained batch 78 in epoch 2, gen_loss = 0.5096558162683174, disc_loss = 0.18866989469226403
Trained batch 79 in epoch 2, gen_loss = 0.5087386846542359, disc_loss = 0.18841766528785228
Trained batch 80 in epoch 2, gen_loss = 0.5096362880718561, disc_loss = 0.18789395818739763
Trained batch 81 in epoch 2, gen_loss = 0.5091768386887341, disc_loss = 0.18731874209351657
Trained batch 82 in epoch 2, gen_loss = 0.5094875872853291, disc_loss = 0.1867997777390193
Trained batch 83 in epoch 2, gen_loss = 0.5082894311774344, disc_loss = 0.1868851931676978
Trained batch 84 in epoch 2, gen_loss = 0.5095365471699659, disc_loss = 0.18782707014504602
Trained batch 85 in epoch 2, gen_loss = 0.5082218574230061, disc_loss = 0.18853546315154365
Trained batch 86 in epoch 2, gen_loss = 0.507395785430382, disc_loss = 0.18850758894421588
Trained batch 87 in epoch 2, gen_loss = 0.5077256438407031, disc_loss = 0.18918105045502837
Trained batch 88 in epoch 2, gen_loss = 0.506616820780079, disc_loss = 0.18902958259823616
Trained batch 89 in epoch 2, gen_loss = 0.5061492333809535, disc_loss = 0.18853684498204126
Trained batch 90 in epoch 2, gen_loss = 0.5069923659602364, disc_loss = 0.18845718378549095
Trained batch 91 in epoch 2, gen_loss = 0.5058486613890399, disc_loss = 0.18857755333833073
Trained batch 92 in epoch 2, gen_loss = 0.5061080369257158, disc_loss = 0.18856002326293658
Trained batch 93 in epoch 2, gen_loss = 0.5056360766608664, disc_loss = 0.188114602673561
Trained batch 94 in epoch 2, gen_loss = 0.5054444231485066, disc_loss = 0.18757413108097878
Trained batch 95 in epoch 2, gen_loss = 0.5062129274010658, disc_loss = 0.18735801490644613
Trained batch 96 in epoch 2, gen_loss = 0.505617884323769, disc_loss = 0.18714142859596566
Trained batch 97 in epoch 2, gen_loss = 0.5057600021970515, disc_loss = 0.18707522308948088
Trained batch 98 in epoch 2, gen_loss = 0.5051973483177147, disc_loss = 0.18732705817680168
Trained batch 99 in epoch 2, gen_loss = 0.5065723094344139, disc_loss = 0.18811297342181205
Trained batch 100 in epoch 2, gen_loss = 0.5065954832157286, disc_loss = 0.18764946351547052
Trained batch 101 in epoch 2, gen_loss = 0.5060838700509539, disc_loss = 0.18693330584495677
Trained batch 102 in epoch 2, gen_loss = 0.5064802071423207, disc_loss = 0.18622465974208222
Trained batch 103 in epoch 2, gen_loss = 0.5062618129528486, disc_loss = 0.18634901188600522
Trained batch 104 in epoch 2, gen_loss = 0.5057706270899092, disc_loss = 0.1866059986608369
Trained batch 105 in epoch 2, gen_loss = 0.5057304709587457, disc_loss = 0.18594610023329844
Trained batch 106 in epoch 2, gen_loss = 0.5064436436813569, disc_loss = 0.1863240204821123
Trained batch 107 in epoch 2, gen_loss = 0.5051166453847179, disc_loss = 0.1872050376539981
Trained batch 108 in epoch 2, gen_loss = 0.5062629667990798, disc_loss = 0.18717943917994107
Trained batch 109 in epoch 2, gen_loss = 0.5059042643417012, disc_loss = 0.1866917414421385
Trained batch 110 in epoch 2, gen_loss = 0.5059970869674338, disc_loss = 0.18603368828425537
Trained batch 111 in epoch 2, gen_loss = 0.5066414150808539, disc_loss = 0.18627514078148774
Trained batch 112 in epoch 2, gen_loss = 0.5058463846160247, disc_loss = 0.18624718553197067
Trained batch 113 in epoch 2, gen_loss = 0.5058499995553702, disc_loss = 0.18575758408558996
Trained batch 114 in epoch 2, gen_loss = 0.5057589543902355, disc_loss = 0.1850703396227049
Trained batch 115 in epoch 2, gen_loss = 0.5055431983080404, disc_loss = 0.18449943512678146
Trained batch 116 in epoch 2, gen_loss = 0.5060992426851876, disc_loss = 0.1841988581368047
Trained batch 117 in epoch 2, gen_loss = 0.5053803382788674, disc_loss = 0.18501910920870507
Trained batch 118 in epoch 2, gen_loss = 0.5067730693757033, disc_loss = 0.1859395281106484
Trained batch 119 in epoch 2, gen_loss = 0.506456530590852, disc_loss = 0.18578984936078388
Trained batch 120 in epoch 2, gen_loss = 0.5063476210290735, disc_loss = 0.18576467542116307
Trained batch 121 in epoch 2, gen_loss = 0.506337434786265, disc_loss = 0.18543940159629602
Trained batch 122 in epoch 2, gen_loss = 0.5060017826111336, disc_loss = 0.18518012871102588
Trained batch 123 in epoch 2, gen_loss = 0.505941228039803, disc_loss = 0.18473494064904028
Trained batch 124 in epoch 2, gen_loss = 0.5068390684127808, disc_loss = 0.1841110178232193
Trained batch 125 in epoch 2, gen_loss = 0.506116780496779, disc_loss = 0.18532369593306194
Trained batch 126 in epoch 2, gen_loss = 0.5064357528536338, disc_loss = 0.18483413063635037
Trained batch 127 in epoch 2, gen_loss = 0.5066928956657648, disc_loss = 0.18425808456959203
Trained batch 128 in epoch 2, gen_loss = 0.5065808605778125, disc_loss = 0.18393234614022944
Trained batch 129 in epoch 2, gen_loss = 0.5075432259302873, disc_loss = 0.1835783835213918
Trained batch 130 in epoch 2, gen_loss = 0.5072896639809353, disc_loss = 0.1832521568614108
Trained batch 131 in epoch 2, gen_loss = 0.5075011280449954, disc_loss = 0.18302412110973487
Trained batch 132 in epoch 2, gen_loss = 0.5071115587887011, disc_loss = 0.18266098374935022
Trained batch 133 in epoch 2, gen_loss = 0.5079645220913104, disc_loss = 0.18226817834065923
Trained batch 134 in epoch 2, gen_loss = 0.5072682585981158, disc_loss = 0.182004022984593
Trained batch 135 in epoch 2, gen_loss = 0.508428937591174, disc_loss = 0.18138424750855742
Trained batch 136 in epoch 2, gen_loss = 0.5089267725056975, disc_loss = 0.1804582303675422
Trained batch 137 in epoch 2, gen_loss = 0.508375690035198, disc_loss = 0.18059179867091385
Trained batch 138 in epoch 2, gen_loss = 0.5097251350073506, disc_loss = 0.18105653464365348
Trained batch 139 in epoch 2, gen_loss = 0.5091066594634738, disc_loss = 0.18072537034749986
Trained batch 140 in epoch 2, gen_loss = 0.5087982211129886, disc_loss = 0.1806042509298798
Trained batch 141 in epoch 2, gen_loss = 0.5097844220802817, disc_loss = 0.1820486345341508
Trained batch 142 in epoch 2, gen_loss = 0.5092270365961782, disc_loss = 0.1831875003717996
Trained batch 143 in epoch 2, gen_loss = 0.508821428856916, disc_loss = 0.1842161797814899
Trained batch 144 in epoch 2, gen_loss = 0.5090097750055379, disc_loss = 0.18553789360769865
Trained batch 145 in epoch 2, gen_loss = 0.5090894337794553, disc_loss = 0.18589940289520238
Trained batch 146 in epoch 2, gen_loss = 0.5085848393488903, disc_loss = 0.1859407022494037
Trained batch 147 in epoch 2, gen_loss = 0.5081528209753938, disc_loss = 0.18596072686282364
Trained batch 148 in epoch 2, gen_loss = 0.5078043885679053, disc_loss = 0.18588091223031883
Trained batch 149 in epoch 2, gen_loss = 0.5078515501817068, disc_loss = 0.1860426163673401
Trained batch 150 in epoch 2, gen_loss = 0.5074464915603991, disc_loss = 0.1859616594796149
Trained batch 151 in epoch 2, gen_loss = 0.5072513606987501, disc_loss = 0.18560984005269252
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.5115766525268555, disc_loss = 0.13993164896965027
Trained batch 1 in epoch 3, gen_loss = 0.48936954140663147, disc_loss = 0.13128457963466644
Trained batch 2 in epoch 3, gen_loss = 0.5043068528175354, disc_loss = 0.12741300960381827
Trained batch 3 in epoch 3, gen_loss = 0.5045101344585419, disc_loss = 0.12121498584747314
Trained batch 4 in epoch 3, gen_loss = 0.519216513633728, disc_loss = 0.11564166098833084
Trained batch 5 in epoch 3, gen_loss = 0.5096682558457056, disc_loss = 0.12330232188105583
Trained batch 6 in epoch 3, gen_loss = 0.5443687651838575, disc_loss = 0.15664017306906836
Trained batch 7 in epoch 3, gen_loss = 0.5285940207540989, disc_loss = 0.15946568828076124
Trained batch 8 in epoch 3, gen_loss = 0.524733328157001, disc_loss = 0.16243355721235275
Trained batch 9 in epoch 3, gen_loss = 0.5178887188434601, disc_loss = 0.1672337420284748
Trained batch 10 in epoch 3, gen_loss = 0.5209327340126038, disc_loss = 0.17309183898297223
Trained batch 11 in epoch 3, gen_loss = 0.5181922564903895, disc_loss = 0.17671220190823078
Trained batch 12 in epoch 3, gen_loss = 0.5112505509303167, disc_loss = 0.17568914878826875
Trained batch 13 in epoch 3, gen_loss = 0.5101999981062753, disc_loss = 0.17252435375537192
Trained batch 14 in epoch 3, gen_loss = 0.513345201810201, disc_loss = 0.1708998089035352
Trained batch 15 in epoch 3, gen_loss = 0.5122028812766075, disc_loss = 0.16722436482086778
Trained batch 16 in epoch 3, gen_loss = 0.5090814706157235, disc_loss = 0.16338137581067927
Trained batch 17 in epoch 3, gen_loss = 0.5103399174080955, disc_loss = 0.16086599520511097
Trained batch 18 in epoch 3, gen_loss = 0.5065067943773771, disc_loss = 0.1587967296179972
Trained batch 19 in epoch 3, gen_loss = 0.5099251598119736, disc_loss = 0.15547744147479534
Trained batch 20 in epoch 3, gen_loss = 0.5084309847581954, disc_loss = 0.15842444449663162
Trained batch 21 in epoch 3, gen_loss = 0.5155542262575843, disc_loss = 0.17328923026269133
Trained batch 22 in epoch 3, gen_loss = 0.5140794282374175, disc_loss = 0.17345983470263687
Trained batch 23 in epoch 3, gen_loss = 0.5082761682569981, disc_loss = 0.17730317420015732
Trained batch 24 in epoch 3, gen_loss = 0.5057304239273072, disc_loss = 0.17708730548620225
Trained batch 25 in epoch 3, gen_loss = 0.5056967368492713, disc_loss = 0.17667350488213393
Trained batch 26 in epoch 3, gen_loss = 0.5039826212105928, disc_loss = 0.17539296299219131
Trained batch 27 in epoch 3, gen_loss = 0.5035836973360607, disc_loss = 0.17326460326356546
Trained batch 28 in epoch 3, gen_loss = 0.5042779774501406, disc_loss = 0.17318642935876188
Trained batch 29 in epoch 3, gen_loss = 0.5015236546595891, disc_loss = 0.1733872763812542
Trained batch 30 in epoch 3, gen_loss = 0.5027555159984096, disc_loss = 0.1732337905033942
Trained batch 31 in epoch 3, gen_loss = 0.5009007910266519, disc_loss = 0.17451120004989207
Trained batch 32 in epoch 3, gen_loss = 0.5044373896988955, disc_loss = 0.1785472146037853
Trained batch 33 in epoch 3, gen_loss = 0.5050396892954322, disc_loss = 0.1773557147997267
Trained batch 34 in epoch 3, gen_loss = 0.5035182552678245, disc_loss = 0.17678469866514207
Trained batch 35 in epoch 3, gen_loss = 0.5035821009013388, disc_loss = 0.17523274777664077
Trained batch 36 in epoch 3, gen_loss = 0.5012714057355314, disc_loss = 0.17381905824751467
Trained batch 37 in epoch 3, gen_loss = 0.5019075603861558, disc_loss = 0.1729542746355659
Trained batch 38 in epoch 3, gen_loss = 0.502821364463904, disc_loss = 0.17102201665059114
Trained batch 39 in epoch 3, gen_loss = 0.5032978594303131, disc_loss = 0.16934413593262435
Trained batch 40 in epoch 3, gen_loss = 0.5051750206365818, disc_loss = 0.16840839222436998
Trained batch 41 in epoch 3, gen_loss = 0.5034141831454777, disc_loss = 0.16875629570512546
Trained batch 42 in epoch 3, gen_loss = 0.5057198065657948, disc_loss = 0.16885306270316588
Trained batch 43 in epoch 3, gen_loss = 0.5047798305749893, disc_loss = 0.16792737709527666
Trained batch 44 in epoch 3, gen_loss = 0.5076260513729519, disc_loss = 0.167422610686885
Trained batch 45 in epoch 3, gen_loss = 0.5068495377250339, disc_loss = 0.167007634335238
Trained batch 46 in epoch 3, gen_loss = 0.5094652835358965, disc_loss = 0.1674927125902886
Trained batch 47 in epoch 3, gen_loss = 0.5078336447477341, disc_loss = 0.16724711827312908
Trained batch 48 in epoch 3, gen_loss = 0.5074948808368371, disc_loss = 0.16620871287827588
Trained batch 49 in epoch 3, gen_loss = 0.5062680977582932, disc_loss = 0.16542825654149054
Trained batch 50 in epoch 3, gen_loss = 0.506584192607917, disc_loss = 0.1648724442895721
Trained batch 51 in epoch 3, gen_loss = 0.5047443509101868, disc_loss = 0.1654869164698399
Trained batch 52 in epoch 3, gen_loss = 0.5069112181663513, disc_loss = 0.16730602015301865
Trained batch 53 in epoch 3, gen_loss = 0.5065522337401355, disc_loss = 0.1670784587385478
Trained batch 54 in epoch 3, gen_loss = 0.5059431769631125, disc_loss = 0.16658103398301385
Trained batch 55 in epoch 3, gen_loss = 0.5058564980115209, disc_loss = 0.16584366360413177
Trained batch 56 in epoch 3, gen_loss = 0.5057690425922996, disc_loss = 0.1644986565960081
Trained batch 57 in epoch 3, gen_loss = 0.5065113665728733, disc_loss = 0.16366920761507134
Trained batch 58 in epoch 3, gen_loss = 0.5084916555275352, disc_loss = 0.16341175378884298
Trained batch 59 in epoch 3, gen_loss = 0.5060495525598526, disc_loss = 0.16581547372043132
Trained batch 60 in epoch 3, gen_loss = 0.5069580068353747, disc_loss = 0.1667644045636302
Trained batch 61 in epoch 3, gen_loss = 0.5063837324419329, disc_loss = 0.16603160228940747
Trained batch 62 in epoch 3, gen_loss = 0.5051634032574911, disc_loss = 0.16541540232442675
Trained batch 63 in epoch 3, gen_loss = 0.5048578684218228, disc_loss = 0.16437612171284854
Trained batch 64 in epoch 3, gen_loss = 0.5056086746545938, disc_loss = 0.16389524363554442
Trained batch 65 in epoch 3, gen_loss = 0.5054016153920781, disc_loss = 0.16256092917738538
Trained batch 66 in epoch 3, gen_loss = 0.5066176639564002, disc_loss = 0.16149371217435865
Trained batch 67 in epoch 3, gen_loss = 0.5057654678821564, disc_loss = 0.16146489846355774
Trained batch 68 in epoch 3, gen_loss = 0.508369070896204, disc_loss = 0.16371595859527588
Trained batch 69 in epoch 3, gen_loss = 0.5095729725701469, disc_loss = 0.16334981684173858
Trained batch 70 in epoch 3, gen_loss = 0.5091633796691895, disc_loss = 0.1638760812265772
Trained batch 71 in epoch 3, gen_loss = 0.5104772175351778, disc_loss = 0.16389510283867517
Trained batch 72 in epoch 3, gen_loss = 0.5101243069727127, disc_loss = 0.1634085388624505
Trained batch 73 in epoch 3, gen_loss = 0.5095982209250733, disc_loss = 0.1636996790766716
Trained batch 74 in epoch 3, gen_loss = 0.5088154617945353, disc_loss = 0.1641436594724655
Trained batch 75 in epoch 3, gen_loss = 0.5098150278392591, disc_loss = 0.16594521446447624
Trained batch 76 in epoch 3, gen_loss = 0.5085693617145737, disc_loss = 0.16595954767295293
Trained batch 77 in epoch 3, gen_loss = 0.5074168825760866, disc_loss = 0.16716785595203057
Trained batch 78 in epoch 3, gen_loss = 0.5092659464365319, disc_loss = 0.16912788624250435
Trained batch 79 in epoch 3, gen_loss = 0.5092688910663128, disc_loss = 0.16912122461944817
Trained batch 80 in epoch 3, gen_loss = 0.5080453827057356, disc_loss = 0.1697478726690198
Trained batch 81 in epoch 3, gen_loss = 0.5073486319402369, disc_loss = 0.16967525151444646
Trained batch 82 in epoch 3, gen_loss = 0.5070675449917116, disc_loss = 0.16952991611268148
Trained batch 83 in epoch 3, gen_loss = 0.5066165324477923, disc_loss = 0.1692417258662837
Trained batch 84 in epoch 3, gen_loss = 0.5057579373612123, disc_loss = 0.1687636135255589
Trained batch 85 in epoch 3, gen_loss = 0.5054089135901872, disc_loss = 0.1682691567165907
Trained batch 86 in epoch 3, gen_loss = 0.5058402151897036, disc_loss = 0.16802180344345927
Trained batch 87 in epoch 3, gen_loss = 0.5049581124701283, disc_loss = 0.167729481885379
Trained batch 88 in epoch 3, gen_loss = 0.5060847344693173, disc_loss = 0.16856748652592135
Trained batch 89 in epoch 3, gen_loss = 0.5052941570679347, disc_loss = 0.1683533302611775
Trained batch 90 in epoch 3, gen_loss = 0.5045443272197639, disc_loss = 0.16803891760307355
Trained batch 91 in epoch 3, gen_loss = 0.5048908082687337, disc_loss = 0.16765652094846187
Trained batch 92 in epoch 3, gen_loss = 0.5052160149620425, disc_loss = 0.1668584895550564
Trained batch 93 in epoch 3, gen_loss = 0.5042214273138249, disc_loss = 0.16662063948968622
Trained batch 94 in epoch 3, gen_loss = 0.5056785570947747, disc_loss = 0.16567265430563374
Trained batch 95 in epoch 3, gen_loss = 0.5057172160595655, disc_loss = 0.1648185340066751
Trained batch 96 in epoch 3, gen_loss = 0.5058165733347234, disc_loss = 0.16383354289015545
Trained batch 97 in epoch 3, gen_loss = 0.5070763625660721, disc_loss = 0.16311739043009524
Trained batch 98 in epoch 3, gen_loss = 0.5072229594895334, disc_loss = 0.1622737278089379
Trained batch 99 in epoch 3, gen_loss = 0.5078831678628921, disc_loss = 0.1612647373229265
Trained batch 100 in epoch 3, gen_loss = 0.5091299243492655, disc_loss = 0.16001329460356495
Trained batch 101 in epoch 3, gen_loss = 0.5101880641544566, disc_loss = 0.1589187024270787
Trained batch 102 in epoch 3, gen_loss = 0.5110373340764092, disc_loss = 0.15767785385974403
Trained batch 103 in epoch 3, gen_loss = 0.5135633166019733, disc_loss = 0.15666879176233822
Trained batch 104 in epoch 3, gen_loss = 0.5147779073034014, disc_loss = 0.15529879416738238
Trained batch 105 in epoch 3, gen_loss = 0.5162297099266412, disc_loss = 0.1540435696688463
Trained batch 106 in epoch 3, gen_loss = 0.516595382556737, disc_loss = 0.15344226527436872
Trained batch 107 in epoch 3, gen_loss = 0.5178078192251699, disc_loss = 0.153495944208569
Trained batch 108 in epoch 3, gen_loss = 0.5167894822741868, disc_loss = 0.1537432425886119
Trained batch 109 in epoch 3, gen_loss = 0.5189945437691429, disc_loss = 0.15422220731323416
Trained batch 110 in epoch 3, gen_loss = 0.5187827439995499, disc_loss = 0.15358202401045207
Trained batch 111 in epoch 3, gen_loss = 0.5186984986066818, disc_loss = 0.15314082535249846
Trained batch 112 in epoch 3, gen_loss = 0.5190689648147178, disc_loss = 0.15335492341391807
Trained batch 113 in epoch 3, gen_loss = 0.5180989974423459, disc_loss = 0.1541197769213141
Trained batch 114 in epoch 3, gen_loss = 0.5184736091157665, disc_loss = 0.15408239934755408
Trained batch 115 in epoch 3, gen_loss = 0.5188955484793104, disc_loss = 0.1545372702952089
Trained batch 116 in epoch 3, gen_loss = 0.5182580621833475, disc_loss = 0.1544376526378159
Trained batch 117 in epoch 3, gen_loss = 0.5186206870159861, disc_loss = 0.15459457949056463
Trained batch 118 in epoch 3, gen_loss = 0.5177644536274821, disc_loss = 0.1553456936062885
Trained batch 119 in epoch 3, gen_loss = 0.5176102034747601, disc_loss = 0.15646660576264063
Trained batch 120 in epoch 3, gen_loss = 0.5171319416239242, disc_loss = 0.15646485750340233
Trained batch 121 in epoch 3, gen_loss = 0.5161903229404669, disc_loss = 0.156555531088446
Trained batch 122 in epoch 3, gen_loss = 0.5160023722706771, disc_loss = 0.1567056037303878
Trained batch 123 in epoch 3, gen_loss = 0.5159990703386645, disc_loss = 0.15655061878984974
Trained batch 124 in epoch 3, gen_loss = 0.5155876154899597, disc_loss = 0.15637132036685944
Trained batch 125 in epoch 3, gen_loss = 0.5156059539507306, disc_loss = 0.15590466943288606
Trained batch 126 in epoch 3, gen_loss = 0.5153963741824383, disc_loss = 0.1555949170875737
Trained batch 127 in epoch 3, gen_loss = 0.514772936468944, disc_loss = 0.15583771705860272
Trained batch 128 in epoch 3, gen_loss = 0.5157595653404561, disc_loss = 0.15729478284601092
Trained batch 129 in epoch 3, gen_loss = 0.5151019772657981, disc_loss = 0.1571052423463418
Trained batch 130 in epoch 3, gen_loss = 0.5144135895121189, disc_loss = 0.15707715930602023
Trained batch 131 in epoch 3, gen_loss = 0.5144388434110265, disc_loss = 0.157138747417114
Trained batch 132 in epoch 3, gen_loss = 0.5140175830600853, disc_loss = 0.1570963046716568
Trained batch 133 in epoch 3, gen_loss = 0.514267287814795, disc_loss = 0.15740237134828497
Trained batch 134 in epoch 3, gen_loss = 0.5137723858709689, disc_loss = 0.15719533645444447
Trained batch 135 in epoch 3, gen_loss = 0.5136405873824569, disc_loss = 0.15657647847033598
Trained batch 136 in epoch 3, gen_loss = 0.5134095732313003, disc_loss = 0.15618731576378328
Trained batch 137 in epoch 3, gen_loss = 0.5127101179914199, disc_loss = 0.156071447537861
Trained batch 138 in epoch 3, gen_loss = 0.513467257614616, disc_loss = 0.15677531433405636
Trained batch 139 in epoch 3, gen_loss = 0.5130833977035114, disc_loss = 0.1571826161550624
Trained batch 140 in epoch 3, gen_loss = 0.5132225284762416, disc_loss = 0.15763170620862474
Trained batch 141 in epoch 3, gen_loss = 0.5126509521628769, disc_loss = 0.1581298907772756
Trained batch 142 in epoch 3, gen_loss = 0.5119616778997275, disc_loss = 0.15865125142402584
Trained batch 143 in epoch 3, gen_loss = 0.5117072419573864, disc_loss = 0.15902889721716443
Trained batch 144 in epoch 3, gen_loss = 0.5112776565140691, disc_loss = 0.15912917970583357
Trained batch 145 in epoch 3, gen_loss = 0.5106853265060137, disc_loss = 0.15896789061084185
Trained batch 146 in epoch 3, gen_loss = 0.5100823182638, disc_loss = 0.15912559937660387
Trained batch 147 in epoch 3, gen_loss = 0.5107464480238992, disc_loss = 0.16003634825952956
Trained batch 148 in epoch 3, gen_loss = 0.5105699696796853, disc_loss = 0.16012324027767116
Trained batch 149 in epoch 3, gen_loss = 0.5098572822411855, disc_loss = 0.16004038547476132
Trained batch 150 in epoch 3, gen_loss = 0.5095390829424195, disc_loss = 0.15994488280143168
Trained batch 151 in epoch 3, gen_loss = 0.5091979525199062, disc_loss = 0.16002636074431634
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.49503612518310547, disc_loss = 0.11481460928916931
Trained batch 1 in epoch 4, gen_loss = 0.478400856256485, disc_loss = 0.10630397498607635
Trained batch 2 in epoch 4, gen_loss = 0.47246930996576947, disc_loss = 0.11483722925186157
Trained batch 3 in epoch 4, gen_loss = 0.4790232554078102, disc_loss = 0.12306278198957443
Trained batch 4 in epoch 4, gen_loss = 0.46585545539855955, disc_loss = 0.13227516114711763
Trained batch 5 in epoch 4, gen_loss = 0.49152839183807373, disc_loss = 0.1510557234287262
Trained batch 6 in epoch 4, gen_loss = 0.47999114223888945, disc_loss = 0.15240200928279332
Trained batch 7 in epoch 4, gen_loss = 0.4777693562209606, disc_loss = 0.15063134022057056
Trained batch 8 in epoch 4, gen_loss = 0.4928050802813636, disc_loss = 0.1594589865869946
Trained batch 9 in epoch 4, gen_loss = 0.489054000377655, disc_loss = 0.15992485135793685
Trained batch 10 in epoch 4, gen_loss = 0.49392831325531006, disc_loss = 0.16402109915559943
Trained batch 11 in epoch 4, gen_loss = 0.489971491197745, disc_loss = 0.16109352310498556
Trained batch 12 in epoch 4, gen_loss = 0.49234627989622265, disc_loss = 0.15667263991557634
Trained batch 13 in epoch 4, gen_loss = 0.4949555035148348, disc_loss = 0.1539159081876278
Trained batch 14 in epoch 4, gen_loss = 0.490483429034551, disc_loss = 0.15505750526984532
Trained batch 15 in epoch 4, gen_loss = 0.49609491042792797, disc_loss = 0.16192493913695216
Trained batch 16 in epoch 4, gen_loss = 0.4954041523091933, disc_loss = 0.16212429413024118
Trained batch 17 in epoch 4, gen_loss = 0.49322489897410077, disc_loss = 0.16164791708191237
Trained batch 18 in epoch 4, gen_loss = 0.4966559096386558, disc_loss = 0.16429082068957782
Trained batch 19 in epoch 4, gen_loss = 0.49404501616954805, disc_loss = 0.16161432452499866
Trained batch 20 in epoch 4, gen_loss = 0.4956627771967933, disc_loss = 0.15766901629311697
Trained batch 21 in epoch 4, gen_loss = 0.4993851726705378, disc_loss = 0.15523209355094217
Trained batch 22 in epoch 4, gen_loss = 0.49883226726366126, disc_loss = 0.15137057654235675
Trained batch 23 in epoch 4, gen_loss = 0.49683091789484024, disc_loss = 0.15000942877183357
Trained batch 24 in epoch 4, gen_loss = 0.5028520703315735, disc_loss = 0.1538967564702034
Trained batch 25 in epoch 4, gen_loss = 0.5006081393131843, disc_loss = 0.15385175238435084
Trained batch 26 in epoch 4, gen_loss = 0.5005583167076111, disc_loss = 0.15227563817192008
Trained batch 27 in epoch 4, gen_loss = 0.5032466650009155, disc_loss = 0.14842259910489833
Trained batch 28 in epoch 4, gen_loss = 0.5021620916909185, disc_loss = 0.14636345387532793
Trained batch 29 in epoch 4, gen_loss = 0.5081633498271306, disc_loss = 0.14435143396258354
Trained batch 30 in epoch 4, gen_loss = 0.5080213421775449, disc_loss = 0.14349747256886575
Trained batch 31 in epoch 4, gen_loss = 0.5085902260616422, disc_loss = 0.1434715900104493
Trained batch 32 in epoch 4, gen_loss = 0.5045827040166566, disc_loss = 0.15194374029383514
Trained batch 33 in epoch 4, gen_loss = 0.5112098621971467, disc_loss = 0.1544816623277524
Trained batch 34 in epoch 4, gen_loss = 0.5101351635796684, disc_loss = 0.15416733303240368
Trained batch 35 in epoch 4, gen_loss = 0.5085289743211534, disc_loss = 0.15424236303402317
Trained batch 36 in epoch 4, gen_loss = 0.5096022744436521, disc_loss = 0.15391132215390335
Trained batch 37 in epoch 4, gen_loss = 0.5068928058210173, disc_loss = 0.1548016916372274
Trained batch 38 in epoch 4, gen_loss = 0.5091282060513129, disc_loss = 0.15526729573806128
Trained batch 39 in epoch 4, gen_loss = 0.5098357297480106, disc_loss = 0.15261823628097773
Trained batch 40 in epoch 4, gen_loss = 0.5098237736922938, disc_loss = 0.15070733773272213
Trained batch 41 in epoch 4, gen_loss = 0.5110481487853187, disc_loss = 0.1493008259151663
Trained batch 42 in epoch 4, gen_loss = 0.5124942944493405, disc_loss = 0.14808138789132583
Trained batch 43 in epoch 4, gen_loss = 0.5125974680889737, disc_loss = 0.14634620330550455
Trained batch 44 in epoch 4, gen_loss = 0.5152279688252344, disc_loss = 0.14606705274846818
Trained batch 45 in epoch 4, gen_loss = 0.515302603011546, disc_loss = 0.14472801724205847
Trained batch 46 in epoch 4, gen_loss = 0.5127331633517083, disc_loss = 0.14415863108761767
Trained batch 47 in epoch 4, gen_loss = 0.5168167681743702, disc_loss = 0.14825076439107457
Trained batch 48 in epoch 4, gen_loss = 0.5142551782179852, disc_loss = 0.15435989550790008
Trained batch 49 in epoch 4, gen_loss = 0.5168449556827546, disc_loss = 0.15718970492482184
Trained batch 50 in epoch 4, gen_loss = 0.5155036694863263, disc_loss = 0.1574433529201676
Trained batch 51 in epoch 4, gen_loss = 0.513502296920006, disc_loss = 0.15770182343056569
Trained batch 52 in epoch 4, gen_loss = 0.5114526214464655, disc_loss = 0.15825211453550267
Trained batch 53 in epoch 4, gen_loss = 0.5099155444789816, disc_loss = 0.16027482916359548
Trained batch 54 in epoch 4, gen_loss = 0.5100664469328794, disc_loss = 0.16350997374816376
Trained batch 55 in epoch 4, gen_loss = 0.5084673634597233, disc_loss = 0.16520501686526196
Trained batch 56 in epoch 4, gen_loss = 0.5073467440772474, disc_loss = 0.1656541943288686
Trained batch 57 in epoch 4, gen_loss = 0.5074881757127827, disc_loss = 0.1660618513565639
Trained batch 58 in epoch 4, gen_loss = 0.5073537669949613, disc_loss = 0.16588118508205577
Trained batch 59 in epoch 4, gen_loss = 0.5076166604955991, disc_loss = 0.1655555977175633
Trained batch 60 in epoch 4, gen_loss = 0.5067405119294026, disc_loss = 0.16614715376349745
Trained batch 61 in epoch 4, gen_loss = 0.5059577548696149, disc_loss = 0.16688881033370573
Trained batch 62 in epoch 4, gen_loss = 0.5059270721579355, disc_loss = 0.16629112535525883
Trained batch 63 in epoch 4, gen_loss = 0.50551474140957, disc_loss = 0.16574473853688687
Trained batch 64 in epoch 4, gen_loss = 0.5051741567941812, disc_loss = 0.16503113278975853
Trained batch 65 in epoch 4, gen_loss = 0.5057446852777944, disc_loss = 0.16427205988403523
Trained batch 66 in epoch 4, gen_loss = 0.5051416652416115, disc_loss = 0.16406762410900486
Trained batch 67 in epoch 4, gen_loss = 0.5047204709228348, disc_loss = 0.16371343361542506
Trained batch 68 in epoch 4, gen_loss = 0.504363075978514, disc_loss = 0.16329233553530514
Trained batch 69 in epoch 4, gen_loss = 0.5059830635786057, disc_loss = 0.16290485890848297
Trained batch 70 in epoch 4, gen_loss = 0.504983018401643, disc_loss = 0.16300259562025607
Trained batch 71 in epoch 4, gen_loss = 0.505527695433961, disc_loss = 0.1633876803227597
Trained batch 72 in epoch 4, gen_loss = 0.5053763573300348, disc_loss = 0.1635285367908543
Trained batch 73 in epoch 4, gen_loss = 0.5048147597022958, disc_loss = 0.1650150459561799
Trained batch 74 in epoch 4, gen_loss = 0.5058550234635671, disc_loss = 0.16667497088511785
Trained batch 75 in epoch 4, gen_loss = 0.5040983491038021, disc_loss = 0.16740692848045574
Trained batch 76 in epoch 4, gen_loss = 0.5028755250689271, disc_loss = 0.16741295110482673
Trained batch 77 in epoch 4, gen_loss = 0.5032338052988052, disc_loss = 0.16795757441566542
Trained batch 78 in epoch 4, gen_loss = 0.5028973595251011, disc_loss = 0.1678539208030399
Trained batch 79 in epoch 4, gen_loss = 0.5019844487309456, disc_loss = 0.16851931801065803
Trained batch 80 in epoch 4, gen_loss = 0.5020608813674362, disc_loss = 0.16858246784519265
Trained batch 81 in epoch 4, gen_loss = 0.5017479629051395, disc_loss = 0.16880619062519656
Trained batch 82 in epoch 4, gen_loss = 0.5015058517456055, disc_loss = 0.16888026381472507
Trained batch 83 in epoch 4, gen_loss = 0.5011050860796656, disc_loss = 0.16852796725219205
Trained batch 84 in epoch 4, gen_loss = 0.5003006829934962, disc_loss = 0.16837532143382467
Trained batch 85 in epoch 4, gen_loss = 0.499902191203694, disc_loss = 0.16793543802097785
Trained batch 86 in epoch 4, gen_loss = 0.5004646336210186, disc_loss = 0.16787601073925523
Trained batch 87 in epoch 4, gen_loss = 0.49977652965621516, disc_loss = 0.16787851068445228
Trained batch 88 in epoch 4, gen_loss = 0.49956102418095877, disc_loss = 0.16741706623455113
Trained batch 89 in epoch 4, gen_loss = 0.49932130972544353, disc_loss = 0.16720065615243382
Trained batch 90 in epoch 4, gen_loss = 0.4988270824427133, disc_loss = 0.166806531558325
Trained batch 91 in epoch 4, gen_loss = 0.49903907626867294, disc_loss = 0.1657021176069975
Trained batch 92 in epoch 4, gen_loss = 0.49890111723253805, disc_loss = 0.16472116481232388
Trained batch 93 in epoch 4, gen_loss = 0.4985249616364215, disc_loss = 0.16413930668792825
Trained batch 94 in epoch 4, gen_loss = 0.4978841354972438, disc_loss = 0.1641643510837304
Trained batch 95 in epoch 4, gen_loss = 0.49960320070385933, disc_loss = 0.16606839241770407
Trained batch 96 in epoch 4, gen_loss = 0.4991525829452829, disc_loss = 0.16576323258815354
Trained batch 97 in epoch 4, gen_loss = 0.4987735471555165, disc_loss = 0.16625675186514854
Trained batch 98 in epoch 4, gen_loss = 0.49971039096514386, disc_loss = 0.16717649221119255
Trained batch 99 in epoch 4, gen_loss = 0.49992344349622725, disc_loss = 0.16685948751866816
Trained batch 100 in epoch 4, gen_loss = 0.4991642720628493, disc_loss = 0.16679753960654287
Trained batch 101 in epoch 4, gen_loss = 0.49803733650375814, disc_loss = 0.1668870550598584
Trained batch 102 in epoch 4, gen_loss = 0.4981103070731302, disc_loss = 0.16675783064469551
Trained batch 103 in epoch 4, gen_loss = 0.49833298474550247, disc_loss = 0.16664493306038472
Trained batch 104 in epoch 4, gen_loss = 0.4976318489937555, disc_loss = 0.1664413116517521
Trained batch 105 in epoch 4, gen_loss = 0.4975601721484706, disc_loss = 0.1661663716834671
Trained batch 106 in epoch 4, gen_loss = 0.49679882671231423, disc_loss = 0.16627983588760145
Trained batch 107 in epoch 4, gen_loss = 0.4966558264913382, disc_loss = 0.16616434045135975
Trained batch 108 in epoch 4, gen_loss = 0.4959686923464504, disc_loss = 0.16600908263834244
Trained batch 109 in epoch 4, gen_loss = 0.49659282781861047, disc_loss = 0.16582307307557625
Trained batch 110 in epoch 4, gen_loss = 0.4965573468723813, disc_loss = 0.16562964176540976
Trained batch 111 in epoch 4, gen_loss = 0.49602734563606127, disc_loss = 0.16565681787739908
Trained batch 112 in epoch 4, gen_loss = 0.4961102024643822, disc_loss = 0.16563152244924445
Trained batch 113 in epoch 4, gen_loss = 0.496745857230404, disc_loss = 0.16470563875740035
Trained batch 114 in epoch 4, gen_loss = 0.4961755073588827, disc_loss = 0.16454916939787242
Trained batch 115 in epoch 4, gen_loss = 0.4974368579428771, disc_loss = 0.1649257552906357
Trained batch 116 in epoch 4, gen_loss = 0.49779341312555164, disc_loss = 0.16421433391734067
Trained batch 117 in epoch 4, gen_loss = 0.4977239239013801, disc_loss = 0.16390599878662723
Trained batch 118 in epoch 4, gen_loss = 0.49990044421508534, disc_loss = 0.16452708051485174
Trained batch 119 in epoch 4, gen_loss = 0.501491250594457, disc_loss = 0.16330652617228528
Trained batch 120 in epoch 4, gen_loss = 0.5015933227933143, disc_loss = 0.16276942127314972
Trained batch 121 in epoch 4, gen_loss = 0.501543723657483, disc_loss = 0.1627432268693066
Trained batch 122 in epoch 4, gen_loss = 0.5038464316507665, disc_loss = 0.16532226302093123
Trained batch 123 in epoch 4, gen_loss = 0.5041838889160464, disc_loss = 0.1658683403154775
Trained batch 124 in epoch 4, gen_loss = 0.5053959531784058, disc_loss = 0.17279650719463827
Trained batch 125 in epoch 4, gen_loss = 0.5064517552890475, disc_loss = 0.1796608352738004
Trained batch 126 in epoch 4, gen_loss = 0.5064273284176203, disc_loss = 0.1801677751758202
Trained batch 127 in epoch 4, gen_loss = 0.5065144011750817, disc_loss = 0.18126161229156423
Trained batch 128 in epoch 4, gen_loss = 0.5062367992345677, disc_loss = 0.18206548062694627
Trained batch 129 in epoch 4, gen_loss = 0.5054400959840187, disc_loss = 0.18291636953273646
Trained batch 130 in epoch 4, gen_loss = 0.5045633705062721, disc_loss = 0.183792932300281
Trained batch 131 in epoch 4, gen_loss = 0.5036692429672588, disc_loss = 0.18431744923476467
Trained batch 132 in epoch 4, gen_loss = 0.503016642161778, disc_loss = 0.1846632775535485
Trained batch 133 in epoch 4, gen_loss = 0.5024634882140515, disc_loss = 0.18507376853932642
Trained batch 134 in epoch 4, gen_loss = 0.5021207626219149, disc_loss = 0.1855780235733147
Trained batch 135 in epoch 4, gen_loss = 0.5017332982491044, disc_loss = 0.18593324103173525
Trained batch 136 in epoch 4, gen_loss = 0.5014780168115658, disc_loss = 0.18647405174798773
Trained batch 137 in epoch 4, gen_loss = 0.5009371223657028, disc_loss = 0.18662663383166428
Trained batch 138 in epoch 4, gen_loss = 0.5004831543929286, disc_loss = 0.18670032078252852
Trained batch 139 in epoch 4, gen_loss = 0.49991060623100825, disc_loss = 0.18674856888662492
Trained batch 140 in epoch 4, gen_loss = 0.4992477056827951, disc_loss = 0.18693517102258847
Trained batch 141 in epoch 4, gen_loss = 0.49852989509072104, disc_loss = 0.18698810509235506
Trained batch 142 in epoch 4, gen_loss = 0.4984070683692719, disc_loss = 0.18713592447444694
Trained batch 143 in epoch 4, gen_loss = 0.49776201467547154, disc_loss = 0.1872803306646852
Trained batch 144 in epoch 4, gen_loss = 0.49739601797071, disc_loss = 0.18730783448394003
Trained batch 145 in epoch 4, gen_loss = 0.4965422122854076, disc_loss = 0.1874677977358846
Trained batch 146 in epoch 4, gen_loss = 0.4960215345126431, disc_loss = 0.1877620672921137
Trained batch 147 in epoch 4, gen_loss = 0.4955601968072556, disc_loss = 0.18782873075405085
Trained batch 148 in epoch 4, gen_loss = 0.49543967743047934, disc_loss = 0.18811241338567045
Trained batch 149 in epoch 4, gen_loss = 0.4955080564816793, disc_loss = 0.1882112130150199
Trained batch 150 in epoch 4, gen_loss = 0.4954951825915583, disc_loss = 0.18821824777451968
Trained batch 151 in epoch 4, gen_loss = 0.49487872362921115, disc_loss = 0.1882516597275083
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.4775847792625427, disc_loss = 0.16950571537017822
Trained batch 1 in epoch 5, gen_loss = 0.4462041109800339, disc_loss = 0.17583868652582169
Trained batch 2 in epoch 5, gen_loss = 0.45423538486162823, disc_loss = 0.1667137642701467
Trained batch 3 in epoch 5, gen_loss = 0.4518062397837639, disc_loss = 0.16633276641368866
Trained batch 4 in epoch 5, gen_loss = 0.44148815870285035, disc_loss = 0.17134130895137786
Trained batch 5 in epoch 5, gen_loss = 0.46276330947875977, disc_loss = 0.17344975968201956
Trained batch 6 in epoch 5, gen_loss = 0.4540680306298392, disc_loss = 0.17120852640696935
Trained batch 7 in epoch 5, gen_loss = 0.45367226377129555, disc_loss = 0.17334403656423092
Trained batch 8 in epoch 5, gen_loss = 0.46483229597409564, disc_loss = 0.1757016595866945
Trained batch 9 in epoch 5, gen_loss = 0.4651389569044113, disc_loss = 0.1773531809449196
Trained batch 10 in epoch 5, gen_loss = 0.46349226615645667, disc_loss = 0.18760719218037344
Trained batch 11 in epoch 5, gen_loss = 0.4680875663956006, disc_loss = 0.19407164429624876
Trained batch 12 in epoch 5, gen_loss = 0.4693891704082489, disc_loss = 0.1951069407738172
Trained batch 13 in epoch 5, gen_loss = 0.4698655328580311, disc_loss = 0.19534348377159663
Trained batch 14 in epoch 5, gen_loss = 0.47112795114517214, disc_loss = 0.19671315749486287
Trained batch 15 in epoch 5, gen_loss = 0.4694663714617491, disc_loss = 0.19875475764274597
Trained batch 16 in epoch 5, gen_loss = 0.46591849537456737, disc_loss = 0.1982665281085407
Trained batch 17 in epoch 5, gen_loss = 0.4662862784332699, disc_loss = 0.19595987846453986
Trained batch 18 in epoch 5, gen_loss = 0.4678611849483691, disc_loss = 0.1925085414397089
Trained batch 19 in epoch 5, gen_loss = 0.4666313543915749, disc_loss = 0.19026387110352516
Trained batch 20 in epoch 5, gen_loss = 0.46663907454127357, disc_loss = 0.18873160155046553
Trained batch 21 in epoch 5, gen_loss = 0.4671339690685272, disc_loss = 0.18578342449936
Trained batch 22 in epoch 5, gen_loss = 0.4701515747153241, disc_loss = 0.18253008762131567
Trained batch 23 in epoch 5, gen_loss = 0.46861281245946884, disc_loss = 0.1846682590742906
Trained batch 24 in epoch 5, gen_loss = 0.46767658948898316, disc_loss = 0.1841019558906555
Trained batch 25 in epoch 5, gen_loss = 0.46821279709155744, disc_loss = 0.1837965129659726
Trained batch 26 in epoch 5, gen_loss = 0.46744868380052074, disc_loss = 0.18141261488199234
Trained batch 27 in epoch 5, gen_loss = 0.4685049152800015, disc_loss = 0.1806214534278427
Trained batch 28 in epoch 5, gen_loss = 0.46638202872769585, disc_loss = 0.18140851757649717
Trained batch 29 in epoch 5, gen_loss = 0.46989059646924336, disc_loss = 0.18691246037681897
Trained batch 30 in epoch 5, gen_loss = 0.46857823767969686, disc_loss = 0.1887583691746958
Trained batch 31 in epoch 5, gen_loss = 0.46909919660538435, disc_loss = 0.18937695561908185
Trained batch 32 in epoch 5, gen_loss = 0.468089273481658, disc_loss = 0.18997806920246643
Trained batch 33 in epoch 5, gen_loss = 0.4680712827864815, disc_loss = 0.18927921683472745
Trained batch 34 in epoch 5, gen_loss = 0.46794584904398234, disc_loss = 0.1876742211835725
Trained batch 35 in epoch 5, gen_loss = 0.4685244833429654, disc_loss = 0.1860556434839964
Trained batch 36 in epoch 5, gen_loss = 0.46845733152853475, disc_loss = 0.18586155993712916
Trained batch 37 in epoch 5, gen_loss = 0.4698489747549358, disc_loss = 0.1852809580925264
Trained batch 38 in epoch 5, gen_loss = 0.47271900757765156, disc_loss = 0.18353162266505071
Trained batch 39 in epoch 5, gen_loss = 0.4729121007025242, disc_loss = 0.18235428165644407
Trained batch 40 in epoch 5, gen_loss = 0.4713922731760072, disc_loss = 0.18329182030951105
Trained batch 41 in epoch 5, gen_loss = 0.47189298414048697, disc_loss = 0.18426155387645676
Trained batch 42 in epoch 5, gen_loss = 0.471699223961941, disc_loss = 0.1840601367659347
Trained batch 43 in epoch 5, gen_loss = 0.47210079770196567, disc_loss = 0.18229438076642426
Trained batch 44 in epoch 5, gen_loss = 0.4725818912188212, disc_loss = 0.18069699472851222
Trained batch 45 in epoch 5, gen_loss = 0.4713055070327676, disc_loss = 0.17961274573336478
Trained batch 46 in epoch 5, gen_loss = 0.47255955034113944, disc_loss = 0.18101343322307506
Trained batch 47 in epoch 5, gen_loss = 0.4724281548211972, disc_loss = 0.18270795854429403
Trained batch 48 in epoch 5, gen_loss = 0.47362554620723335, disc_loss = 0.18288235214291787
Trained batch 49 in epoch 5, gen_loss = 0.473435760140419, disc_loss = 0.18166628122329712
Trained batch 50 in epoch 5, gen_loss = 0.4727601391427657, disc_loss = 0.1810166993561913
Trained batch 51 in epoch 5, gen_loss = 0.472375220977343, disc_loss = 0.18108664768246505
Trained batch 52 in epoch 5, gen_loss = 0.47098509714288533, disc_loss = 0.181216022034861
Trained batch 53 in epoch 5, gen_loss = 0.47053717352725843, disc_loss = 0.181206664553395
Trained batch 54 in epoch 5, gen_loss = 0.47038926644758744, disc_loss = 0.18094912686131218
Trained batch 55 in epoch 5, gen_loss = 0.46918471955827307, disc_loss = 0.18170694448053837
Trained batch 56 in epoch 5, gen_loss = 0.4708457458437535, disc_loss = 0.18250087060426412
Trained batch 57 in epoch 5, gen_loss = 0.4704240329306701, disc_loss = 0.18211427074054193
Trained batch 58 in epoch 5, gen_loss = 0.46985191005771443, disc_loss = 0.18195738959110389
Trained batch 59 in epoch 5, gen_loss = 0.46968177805344263, disc_loss = 0.1823024866481622
Trained batch 60 in epoch 5, gen_loss = 0.46976590840542903, disc_loss = 0.1827361915932327
Trained batch 61 in epoch 5, gen_loss = 0.4719357067538846, disc_loss = 0.18381210272350618
Trained batch 62 in epoch 5, gen_loss = 0.470822637043302, disc_loss = 0.18538852414441487
Trained batch 63 in epoch 5, gen_loss = 0.4718830343335867, disc_loss = 0.18548773508518934
Trained batch 64 in epoch 5, gen_loss = 0.47175622765834513, disc_loss = 0.1862797526212839
Trained batch 65 in epoch 5, gen_loss = 0.4710751523574193, disc_loss = 0.1868211148363171
Trained batch 66 in epoch 5, gen_loss = 0.47159290358201783, disc_loss = 0.1865386495839304
Trained batch 67 in epoch 5, gen_loss = 0.4715108696152182, disc_loss = 0.18707868369186625
Trained batch 68 in epoch 5, gen_loss = 0.4706146432005841, disc_loss = 0.18643541936425195
Trained batch 69 in epoch 5, gen_loss = 0.47014257609844207, disc_loss = 0.18729362104620254
Trained batch 70 in epoch 5, gen_loss = 0.47142878258732, disc_loss = 0.1876468985853061
Trained batch 71 in epoch 5, gen_loss = 0.4712902427547508, disc_loss = 0.1874486445966694
Trained batch 72 in epoch 5, gen_loss = 0.47028111227571145, disc_loss = 0.18804826699707605
Trained batch 73 in epoch 5, gen_loss = 0.4713012676786732, disc_loss = 0.1876446802068401
Trained batch 74 in epoch 5, gen_loss = 0.47213855465253196, disc_loss = 0.18720050573348998
Trained batch 75 in epoch 5, gen_loss = 0.47149711219887985, disc_loss = 0.18677984530988492
Trained batch 76 in epoch 5, gen_loss = 0.47130633793868026, disc_loss = 0.18632279355804643
Trained batch 77 in epoch 5, gen_loss = 0.47151316205660504, disc_loss = 0.18598430393598017
Trained batch 78 in epoch 5, gen_loss = 0.4721382531938674, disc_loss = 0.18566671334489993
Trained batch 79 in epoch 5, gen_loss = 0.4722190789878368, disc_loss = 0.1851291574537754
Trained batch 80 in epoch 5, gen_loss = 0.4732032999580289, disc_loss = 0.18330291580454802
Trained batch 81 in epoch 5, gen_loss = 0.4714853065769847, disc_loss = 0.18598462027929177
Trained batch 82 in epoch 5, gen_loss = 0.4733285731579884, disc_loss = 0.18609136598835507
Trained batch 83 in epoch 5, gen_loss = 0.47347093586410793, disc_loss = 0.18632816935756377
Trained batch 84 in epoch 5, gen_loss = 0.47254881999071907, disc_loss = 0.18676049713702764
Trained batch 85 in epoch 5, gen_loss = 0.4728039835774621, disc_loss = 0.1861191461685785
Trained batch 86 in epoch 5, gen_loss = 0.47283488854594613, disc_loss = 0.18551154456090654
Trained batch 87 in epoch 5, gen_loss = 0.47183939746835013, disc_loss = 0.18514994248239833
Trained batch 88 in epoch 5, gen_loss = 0.47126145543677084, disc_loss = 0.18495656302973126
Trained batch 89 in epoch 5, gen_loss = 0.4722326394584444, disc_loss = 0.18584748610026305
Trained batch 90 in epoch 5, gen_loss = 0.47305601344003784, disc_loss = 0.1850887028152471
Trained batch 91 in epoch 5, gen_loss = 0.47297169721644855, disc_loss = 0.18661777339065852
Trained batch 92 in epoch 5, gen_loss = 0.4740242470977127, disc_loss = 0.18554080906574444
Trained batch 93 in epoch 5, gen_loss = 0.47466007255493325, disc_loss = 0.1844507106678917
Trained batch 94 in epoch 5, gen_loss = 0.4742374533101132, disc_loss = 0.18379578727640603
Trained batch 95 in epoch 5, gen_loss = 0.47413402205954, disc_loss = 0.18352341989520937
Trained batch 96 in epoch 5, gen_loss = 0.47372493455090475, disc_loss = 0.18315157213622762
Trained batch 97 in epoch 5, gen_loss = 0.47418380118146236, disc_loss = 0.18224964910471925
Trained batch 98 in epoch 5, gen_loss = 0.4749367860230533, disc_loss = 0.18205709766709444
Trained batch 99 in epoch 5, gen_loss = 0.4756163516640663, disc_loss = 0.18125474493950605
Trained batch 100 in epoch 5, gen_loss = 0.47537806571120084, disc_loss = 0.18100454027552415
Trained batch 101 in epoch 5, gen_loss = 0.47546521325906116, disc_loss = 0.18108344220501535
Trained batch 102 in epoch 5, gen_loss = 0.47511743081426155, disc_loss = 0.1815611820993493
Trained batch 103 in epoch 5, gen_loss = 0.47484258017860925, disc_loss = 0.182513986606724
Trained batch 104 in epoch 5, gen_loss = 0.47589990269570126, disc_loss = 0.18292925737443425
Trained batch 105 in epoch 5, gen_loss = 0.4760713754397518, disc_loss = 0.18266016367893173
Trained batch 106 in epoch 5, gen_loss = 0.47604827373941366, disc_loss = 0.18287902523841815
Trained batch 107 in epoch 5, gen_loss = 0.47588392071149965, disc_loss = 0.18312855599517072
Trained batch 108 in epoch 5, gen_loss = 0.4755728050656275, disc_loss = 0.18309104972339552
Trained batch 109 in epoch 5, gen_loss = 0.4764915322715586, disc_loss = 0.18295067071237348
Trained batch 110 in epoch 5, gen_loss = 0.4763306046391393, disc_loss = 0.182372520467988
Trained batch 111 in epoch 5, gen_loss = 0.47633496166339945, disc_loss = 0.18188539423447633
Trained batch 112 in epoch 5, gen_loss = 0.47694146554026984, disc_loss = 0.1810276758552125
Trained batch 113 in epoch 5, gen_loss = 0.477160111592527, disc_loss = 0.1805455530094996
Trained batch 114 in epoch 5, gen_loss = 0.47622659957927205, disc_loss = 0.18216044251685556
Trained batch 115 in epoch 5, gen_loss = 0.47569787065530644, disc_loss = 0.18248133730657143
Trained batch 116 in epoch 5, gen_loss = 0.47601563018611354, disc_loss = 0.18299021766099155
Trained batch 117 in epoch 5, gen_loss = 0.4755744310253758, disc_loss = 0.18285965044998517
Trained batch 118 in epoch 5, gen_loss = 0.4753675523425351, disc_loss = 0.18287806485255226
Trained batch 119 in epoch 5, gen_loss = 0.4759275255103906, disc_loss = 0.18266051532700658
Trained batch 120 in epoch 5, gen_loss = 0.47714377508675754, disc_loss = 0.18139570986867443
Trained batch 121 in epoch 5, gen_loss = 0.47694199617768895, disc_loss = 0.18097275921494746
Trained batch 122 in epoch 5, gen_loss = 0.4787320361389377, disc_loss = 0.18029176321153234
Trained batch 123 in epoch 5, gen_loss = 0.47979485147422357, disc_loss = 0.17902879556640983
Trained batch 124 in epoch 5, gen_loss = 0.4804794361591339, disc_loss = 0.17774860514700414
Trained batch 125 in epoch 5, gen_loss = 0.48097122164945755, disc_loss = 0.17648482495652779
Trained batch 126 in epoch 5, gen_loss = 0.4815759257538112, disc_loss = 0.1752772437716563
Trained batch 127 in epoch 5, gen_loss = 0.4823336659464985, disc_loss = 0.17440446358523332
Trained batch 128 in epoch 5, gen_loss = 0.4829510979412138, disc_loss = 0.173350913464561
Trained batch 129 in epoch 5, gen_loss = 0.48479048632658445, disc_loss = 0.1723686897983918
Trained batch 130 in epoch 5, gen_loss = 0.4855208540235767, disc_loss = 0.1711728951061955
Trained batch 131 in epoch 5, gen_loss = 0.4848895219690872, disc_loss = 0.17211386521883082
Trained batch 132 in epoch 5, gen_loss = 0.48646101176290585, disc_loss = 0.1729703909136299
Trained batch 133 in epoch 5, gen_loss = 0.487839057151951, disc_loss = 0.1720031225192013
Trained batch 134 in epoch 5, gen_loss = 0.48776434350896763, disc_loss = 0.17157942073212729
Trained batch 135 in epoch 5, gen_loss = 0.48732077571399074, disc_loss = 0.17094794644371553
Trained batch 136 in epoch 5, gen_loss = 0.48800596116233047, disc_loss = 0.17101159773386307
Trained batch 137 in epoch 5, gen_loss = 0.4887078095605408, disc_loss = 0.17078859440010527
Trained batch 138 in epoch 5, gen_loss = 0.4883424444593114, disc_loss = 0.1710450407519615
Trained batch 139 in epoch 5, gen_loss = 0.4890425335083689, disc_loss = 0.1707510733710868
Trained batch 140 in epoch 5, gen_loss = 0.4893308863149467, disc_loss = 0.17028210333264465
Trained batch 141 in epoch 5, gen_loss = 0.48970851533009974, disc_loss = 0.16951894657817526
Trained batch 142 in epoch 5, gen_loss = 0.48990971871189304, disc_loss = 0.16870667603049244
Trained batch 143 in epoch 5, gen_loss = 0.4901710705210765, disc_loss = 0.16807710182749563
Trained batch 144 in epoch 5, gen_loss = 0.4904657053536382, disc_loss = 0.16751024070484885
Trained batch 145 in epoch 5, gen_loss = 0.4911064483123283, disc_loss = 0.1668322024586266
Trained batch 146 in epoch 5, gen_loss = 0.4915001224092886, disc_loss = 0.166050676889971
Trained batch 147 in epoch 5, gen_loss = 0.49109152664203903, disc_loss = 0.1671987940129396
Trained batch 148 in epoch 5, gen_loss = 0.4920537381764226, disc_loss = 0.16645692213869734
Trained batch 149 in epoch 5, gen_loss = 0.49228091855843864, disc_loss = 0.16635902379949888
Trained batch 150 in epoch 5, gen_loss = 0.4921132101128433, disc_loss = 0.166679142770783
Trained batch 151 in epoch 5, gen_loss = 0.4919110189535116, disc_loss = 0.16646728875409617
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.5331183075904846, disc_loss = 0.20646506547927856
Trained batch 1 in epoch 6, gen_loss = 0.5030320733785629, disc_loss = 0.18235129863023758
Trained batch 2 in epoch 6, gen_loss = 0.47397278745969135, disc_loss = 0.2240367978811264
Trained batch 3 in epoch 6, gen_loss = 0.4805664047598839, disc_loss = 0.2197011262178421
Trained batch 4 in epoch 6, gen_loss = 0.48844593167304995, disc_loss = 0.20208679437637328
Trained batch 5 in epoch 6, gen_loss = 0.4792439689238866, disc_loss = 0.19558042039473852
Trained batch 6 in epoch 6, gen_loss = 0.4737938514777592, disc_loss = 0.1996500619820186
Trained batch 7 in epoch 6, gen_loss = 0.4988590367138386, disc_loss = 0.2082962766289711
Trained batch 8 in epoch 6, gen_loss = 0.4895985457632277, disc_loss = 0.20353822906812033
Trained batch 9 in epoch 6, gen_loss = 0.4890033662319183, disc_loss = 0.1992747589945793
Trained batch 10 in epoch 6, gen_loss = 0.4965205734426325, disc_loss = 0.19578229839151556
Trained batch 11 in epoch 6, gen_loss = 0.48981685439745587, disc_loss = 0.19623742625117302
Trained batch 12 in epoch 6, gen_loss = 0.49505576262107265, disc_loss = 0.2001033562880296
Trained batch 13 in epoch 6, gen_loss = 0.4913813854966845, disc_loss = 0.19423331639596395
Trained batch 14 in epoch 6, gen_loss = 0.4863134980201721, disc_loss = 0.19212473034858704
Trained batch 15 in epoch 6, gen_loss = 0.4873022846877575, disc_loss = 0.19634412601590157
Trained batch 16 in epoch 6, gen_loss = 0.48680027442819934, disc_loss = 0.19649992532589855
Trained batch 17 in epoch 6, gen_loss = 0.48606546388732064, disc_loss = 0.19302035454246733
Trained batch 18 in epoch 6, gen_loss = 0.4882882174692656, disc_loss = 0.19195224187876048
Trained batch 19 in epoch 6, gen_loss = 0.4890700042247772, disc_loss = 0.18892810121178627
Trained batch 20 in epoch 6, gen_loss = 0.48315422449793133, disc_loss = 0.1902225422007697
Trained batch 21 in epoch 6, gen_loss = 0.4827394864775918, disc_loss = 0.18751825189048593
Trained batch 22 in epoch 6, gen_loss = 0.4856407124063243, disc_loss = 0.18786781961503235
Trained batch 23 in epoch 6, gen_loss = 0.48798151810963947, disc_loss = 0.18463481031358242
Trained batch 24 in epoch 6, gen_loss = 0.48428165793418887, disc_loss = 0.18445784449577332
Trained batch 25 in epoch 6, gen_loss = 0.4867507620499684, disc_loss = 0.18300715203468615
Trained batch 26 in epoch 6, gen_loss = 0.4858014362829703, disc_loss = 0.18159412178728315
Trained batch 27 in epoch 6, gen_loss = 0.484120103929724, disc_loss = 0.18099051767161914
Trained batch 28 in epoch 6, gen_loss = 0.4834151401601989, disc_loss = 0.18040571181938567
Trained batch 29 in epoch 6, gen_loss = 0.48663317461808525, disc_loss = 0.17919407685597738
Trained batch 30 in epoch 6, gen_loss = 0.49070257813699786, disc_loss = 0.17507639503286732
Trained batch 31 in epoch 6, gen_loss = 0.4881491418927908, disc_loss = 0.17342400806955993
Trained batch 32 in epoch 6, gen_loss = 0.48792798681692645, disc_loss = 0.17285139520059933
Trained batch 33 in epoch 6, gen_loss = 0.4894358945243499, disc_loss = 0.1704236996524474
Trained batch 34 in epoch 6, gen_loss = 0.4867986151150295, disc_loss = 0.168805017215865
Trained batch 35 in epoch 6, gen_loss = 0.48552631586790085, disc_loss = 0.16839883973201117
Trained batch 36 in epoch 6, gen_loss = 0.48883403877954223, disc_loss = 0.17120303656603839
Trained batch 37 in epoch 6, gen_loss = 0.48804257496407155, disc_loss = 0.1746905665648611
Trained batch 38 in epoch 6, gen_loss = 0.4882973722922496, disc_loss = 0.18158379502785513
Trained batch 39 in epoch 6, gen_loss = 0.4915728226304054, disc_loss = 0.18736762180924416
Trained batch 40 in epoch 6, gen_loss = 0.4915278568500426, disc_loss = 0.18890396196667741
Trained batch 41 in epoch 6, gen_loss = 0.48956904950596036, disc_loss = 0.1899699146548907
Trained batch 42 in epoch 6, gen_loss = 0.49009877720544504, disc_loss = 0.18888850440812666
Trained batch 43 in epoch 6, gen_loss = 0.4895775690674782, disc_loss = 0.18800971386107532
Trained batch 44 in epoch 6, gen_loss = 0.48801747692955866, disc_loss = 0.18791744079854752
Trained batch 45 in epoch 6, gen_loss = 0.48637083691099414, disc_loss = 0.18744264607844147
Trained batch 46 in epoch 6, gen_loss = 0.487363023960844, disc_loss = 0.1867306498771018
Trained batch 47 in epoch 6, gen_loss = 0.4856564700603485, disc_loss = 0.1879659335439404
Trained batch 48 in epoch 6, gen_loss = 0.4836096952156145, disc_loss = 0.1885931434071794
Trained batch 49 in epoch 6, gen_loss = 0.48312748074531553, disc_loss = 0.1882528394460678
Trained batch 50 in epoch 6, gen_loss = 0.48386337827233705, disc_loss = 0.1891747505641451
Trained batch 51 in epoch 6, gen_loss = 0.48276914484225786, disc_loss = 0.19032467156648636
Trained batch 52 in epoch 6, gen_loss = 0.4816450645338814, disc_loss = 0.19106161678737066
Trained batch 53 in epoch 6, gen_loss = 0.48098147136193736, disc_loss = 0.1917139302801203
Trained batch 54 in epoch 6, gen_loss = 0.48070461424914274, disc_loss = 0.19104936068708248
Trained batch 55 in epoch 6, gen_loss = 0.4792350935084479, disc_loss = 0.19080815464258194
Trained batch 56 in epoch 6, gen_loss = 0.47767531871795654, disc_loss = 0.19038541641151696
Trained batch 57 in epoch 6, gen_loss = 0.47797294680414526, disc_loss = 0.1915444983490582
Trained batch 58 in epoch 6, gen_loss = 0.4774914166684878, disc_loss = 0.1921511807684171
Trained batch 59 in epoch 6, gen_loss = 0.4770271693666776, disc_loss = 0.1922956218322118
Trained batch 60 in epoch 6, gen_loss = 0.4779886608241034, disc_loss = 0.19241919209722613
Trained batch 61 in epoch 6, gen_loss = 0.47730197300834043, disc_loss = 0.19219239921339096
Trained batch 62 in epoch 6, gen_loss = 0.4763207709978497, disc_loss = 0.19201460527995276
Trained batch 63 in epoch 6, gen_loss = 0.474976665340364, disc_loss = 0.1923260074108839
Trained batch 64 in epoch 6, gen_loss = 0.47528144579667314, disc_loss = 0.193968233695397
Trained batch 65 in epoch 6, gen_loss = 0.47524725487737945, disc_loss = 0.19267480730107336
Trained batch 66 in epoch 6, gen_loss = 0.4737753854758704, disc_loss = 0.1929125945959518
Trained batch 67 in epoch 6, gen_loss = 0.4743400860358687, disc_loss = 0.1931864684995483
Trained batch 68 in epoch 6, gen_loss = 0.4740489552850309, disc_loss = 0.1931589459595473
Trained batch 69 in epoch 6, gen_loss = 0.4733470516545432, disc_loss = 0.19273244036095483
Trained batch 70 in epoch 6, gen_loss = 0.4734272595862268, disc_loss = 0.19362664495555448
Trained batch 71 in epoch 6, gen_loss = 0.4735766264299552, disc_loss = 0.19323464669287205
Trained batch 72 in epoch 6, gen_loss = 0.47297876542561673, disc_loss = 0.19348241062196966
Trained batch 73 in epoch 6, gen_loss = 0.4745970130772204, disc_loss = 0.19367357685759262
Trained batch 74 in epoch 6, gen_loss = 0.474292505979538, disc_loss = 0.19266164024670918
Trained batch 75 in epoch 6, gen_loss = 0.4736011134166467, disc_loss = 0.19277371152451164
Trained batch 76 in epoch 6, gen_loss = 0.47570183873176575, disc_loss = 0.19536129065922328
Trained batch 77 in epoch 6, gen_loss = 0.4752861811564519, disc_loss = 0.19508709834936339
Trained batch 78 in epoch 6, gen_loss = 0.47562260416489616, disc_loss = 0.19435803648791736
Trained batch 79 in epoch 6, gen_loss = 0.4749822862446308, disc_loss = 0.1941298244521022
Trained batch 80 in epoch 6, gen_loss = 0.47449167091169475, disc_loss = 0.19440783100363648
Trained batch 81 in epoch 6, gen_loss = 0.47437943445473185, disc_loss = 0.1936559589897714
Trained batch 82 in epoch 6, gen_loss = 0.47428555230060254, disc_loss = 0.1935524046421051
Trained batch 83 in epoch 6, gen_loss = 0.47371791161241983, disc_loss = 0.19337227213240804
Trained batch 84 in epoch 6, gen_loss = 0.4752166572739096, disc_loss = 0.1930457998724545
Trained batch 85 in epoch 6, gen_loss = 0.4753787607647652, disc_loss = 0.19342425361622212
Trained batch 86 in epoch 6, gen_loss = 0.47459783362246105, disc_loss = 0.19412216098829246
Trained batch 87 in epoch 6, gen_loss = 0.4746650660579855, disc_loss = 0.19394421712918716
Trained batch 88 in epoch 6, gen_loss = 0.4746919877073738, disc_loss = 0.1934635793225149
Trained batch 89 in epoch 6, gen_loss = 0.474286401602957, disc_loss = 0.19296222627162934
Trained batch 90 in epoch 6, gen_loss = 0.4742474955516857, disc_loss = 0.19255166803742504
Trained batch 91 in epoch 6, gen_loss = 0.47375321971333545, disc_loss = 0.19244683825451395
Trained batch 92 in epoch 6, gen_loss = 0.4736682522681452, disc_loss = 0.19237143698559012
Trained batch 93 in epoch 6, gen_loss = 0.4740001857280731, disc_loss = 0.19179563018235754
Trained batch 94 in epoch 6, gen_loss = 0.47330340837177476, disc_loss = 0.191610491589496
Trained batch 95 in epoch 6, gen_loss = 0.4731072473029296, disc_loss = 0.1915271240286529
Trained batch 96 in epoch 6, gen_loss = 0.47282424999266554, disc_loss = 0.1919064913521108
Trained batch 97 in epoch 6, gen_loss = 0.47374436472143444, disc_loss = 0.19298347237767005
Trained batch 98 in epoch 6, gen_loss = 0.47347396401443864, disc_loss = 0.19271264277925396
Trained batch 99 in epoch 6, gen_loss = 0.4731467691063881, disc_loss = 0.19243901133537292
Trained batch 100 in epoch 6, gen_loss = 0.47369704771750043, disc_loss = 0.1925421810091132
Trained batch 101 in epoch 6, gen_loss = 0.4730611732777427, disc_loss = 0.19214273828501796
Trained batch 102 in epoch 6, gen_loss = 0.47379512549604025, disc_loss = 0.19136971944165462
Trained batch 103 in epoch 6, gen_loss = 0.4744824173931892, disc_loss = 0.19084852948211706
Trained batch 104 in epoch 6, gen_loss = 0.4738278019995916, disc_loss = 0.19116783198856171
Trained batch 105 in epoch 6, gen_loss = 0.4748941226950232, disc_loss = 0.19062094727777085
Trained batch 106 in epoch 6, gen_loss = 0.4744848675816973, disc_loss = 0.19022047296862735
Trained batch 107 in epoch 6, gen_loss = 0.47554557356569505, disc_loss = 0.18992545648857398
Trained batch 108 in epoch 6, gen_loss = 0.4756260473246968, disc_loss = 0.18951894657327495
Trained batch 109 in epoch 6, gen_loss = 0.47613292146812786, disc_loss = 0.18992701470851897
Trained batch 110 in epoch 6, gen_loss = 0.4763672091402449, disc_loss = 0.19010045480083776
Trained batch 111 in epoch 6, gen_loss = 0.47676313056477476, disc_loss = 0.1899374042238508
Trained batch 112 in epoch 6, gen_loss = 0.47655492625405305, disc_loss = 0.18987832317310097
Trained batch 113 in epoch 6, gen_loss = 0.4763006194118868, disc_loss = 0.18966816914708992
Trained batch 114 in epoch 6, gen_loss = 0.476038217285405, disc_loss = 0.18957226548505865
Trained batch 115 in epoch 6, gen_loss = 0.4758370215522832, disc_loss = 0.18985820574493245
Trained batch 116 in epoch 6, gen_loss = 0.47597096083510637, disc_loss = 0.189584450971367
Trained batch 117 in epoch 6, gen_loss = 0.4757734047154249, disc_loss = 0.18908265144643138
Trained batch 118 in epoch 6, gen_loss = 0.4757428877994794, disc_loss = 0.1889719338226719
Trained batch 119 in epoch 6, gen_loss = 0.4756945672134558, disc_loss = 0.1885791049649318
Trained batch 120 in epoch 6, gen_loss = 0.47560992738432134, disc_loss = 0.1884867595739601
Trained batch 121 in epoch 6, gen_loss = 0.4757921927776493, disc_loss = 0.18808327627475144
Trained batch 122 in epoch 6, gen_loss = 0.47573817382013894, disc_loss = 0.18833767604537127
Trained batch 123 in epoch 6, gen_loss = 0.475157275315254, disc_loss = 0.1883302023333888
Trained batch 124 in epoch 6, gen_loss = 0.4759946684837341, disc_loss = 0.18819126677513123
Trained batch 125 in epoch 6, gen_loss = 0.476844355700508, disc_loss = 0.18738850939368445
Trained batch 126 in epoch 6, gen_loss = 0.4769801783749438, disc_loss = 0.18704093570314992
Trained batch 127 in epoch 6, gen_loss = 0.47716510808095336, disc_loss = 0.1866548229008913
Trained batch 128 in epoch 6, gen_loss = 0.47771579581637713, disc_loss = 0.18674184301102809
Trained batch 129 in epoch 6, gen_loss = 0.47773500680923464, disc_loss = 0.186729731124181
Trained batch 130 in epoch 6, gen_loss = 0.4782411219509503, disc_loss = 0.18619893735829202
Trained batch 131 in epoch 6, gen_loss = 0.478492230628476, disc_loss = 0.18543404086746954
Trained batch 132 in epoch 6, gen_loss = 0.4779467546850219, disc_loss = 0.18576714402078687
Trained batch 133 in epoch 6, gen_loss = 0.4784067731295059, disc_loss = 0.18569938221306942
Trained batch 134 in epoch 6, gen_loss = 0.47829251112761323, disc_loss = 0.18555615991353988
Trained batch 135 in epoch 6, gen_loss = 0.4778098319383228, disc_loss = 0.18500878207166405
Trained batch 136 in epoch 6, gen_loss = 0.4783601021244578, disc_loss = 0.184562105005675
Trained batch 137 in epoch 6, gen_loss = 0.47822366719660553, disc_loss = 0.18422099613193152
Trained batch 138 in epoch 6, gen_loss = 0.47794812660423114, disc_loss = 0.1835966924969241
Trained batch 139 in epoch 6, gen_loss = 0.4776122099586895, disc_loss = 0.18328757850187166
Trained batch 140 in epoch 6, gen_loss = 0.47774890868376335, disc_loss = 0.18321609666161504
Trained batch 141 in epoch 6, gen_loss = 0.4778541985531928, disc_loss = 0.18320466158255724
Trained batch 142 in epoch 6, gen_loss = 0.47773196688898795, disc_loss = 0.18237193788473421
Trained batch 143 in epoch 6, gen_loss = 0.47736915863222545, disc_loss = 0.18221170677699977
Trained batch 144 in epoch 6, gen_loss = 0.47816553033631426, disc_loss = 0.1826440247482267
Trained batch 145 in epoch 6, gen_loss = 0.47843098926217587, disc_loss = 0.18173736382326852
Trained batch 146 in epoch 6, gen_loss = 0.47805152823324915, disc_loss = 0.18142244399708957
Trained batch 147 in epoch 6, gen_loss = 0.47827063823068466, disc_loss = 0.181625318965195
Trained batch 148 in epoch 6, gen_loss = 0.4781868465794813, disc_loss = 0.18146782120902266
Trained batch 149 in epoch 6, gen_loss = 0.4784876012802124, disc_loss = 0.18123884923756123
Trained batch 150 in epoch 6, gen_loss = 0.4785991141338222, disc_loss = 0.18103172612802082
Trained batch 151 in epoch 6, gen_loss = 0.4791700110623711, disc_loss = 0.18076586887534513
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.39640820026397705, disc_loss = 0.19671162962913513
Trained batch 1 in epoch 7, gen_loss = 0.43725165724754333, disc_loss = 0.17488813400268555
Trained batch 2 in epoch 7, gen_loss = 0.4518839716911316, disc_loss = 0.16567473113536835
Trained batch 3 in epoch 7, gen_loss = 0.5187558978796005, disc_loss = 0.1804526224732399
Trained batch 4 in epoch 7, gen_loss = 0.5042803406715393, disc_loss = 0.16482881605625152
Trained batch 5 in epoch 7, gen_loss = 0.48733989894390106, disc_loss = 0.15399784470597902
Trained batch 6 in epoch 7, gen_loss = 0.4911745914391109, disc_loss = 0.14901452937296458
Trained batch 7 in epoch 7, gen_loss = 0.4925774596631527, disc_loss = 0.14647963177412748
Trained batch 8 in epoch 7, gen_loss = 0.4902581075827281, disc_loss = 0.14617580423752466
Trained batch 9 in epoch 7, gen_loss = 0.4901765614748001, disc_loss = 0.1413971595466137
Trained batch 10 in epoch 7, gen_loss = 0.4946593019095334, disc_loss = 0.14997512711720032
Trained batch 11 in epoch 7, gen_loss = 0.4878351241350174, disc_loss = 0.1540435558805863
Trained batch 12 in epoch 7, gen_loss = 0.4893735326253451, disc_loss = 0.15510779676529077
Trained batch 13 in epoch 7, gen_loss = 0.5026199775082725, disc_loss = 0.16351875928895815
Trained batch 14 in epoch 7, gen_loss = 0.4942974011103312, disc_loss = 0.16465309808651607
Trained batch 15 in epoch 7, gen_loss = 0.48634667322039604, disc_loss = 0.17214368423447013
Trained batch 16 in epoch 7, gen_loss = 0.48699179992956276, disc_loss = 0.17544930077650966
Trained batch 17 in epoch 7, gen_loss = 0.4845143242014779, disc_loss = 0.17874269228842524
Trained batch 18 in epoch 7, gen_loss = 0.48292127879042374, disc_loss = 0.18154408939574895
Trained batch 19 in epoch 7, gen_loss = 0.47831678837537767, disc_loss = 0.18456688784062864
Trained batch 20 in epoch 7, gen_loss = 0.47682355841000873, disc_loss = 0.18596505657547996
Trained batch 21 in epoch 7, gen_loss = 0.4799109169028022, disc_loss = 0.18502594564448704
Trained batch 22 in epoch 7, gen_loss = 0.4801524424034616, disc_loss = 0.1820843018915342
Trained batch 23 in epoch 7, gen_loss = 0.47772559026877087, disc_loss = 0.1831852694352468
Trained batch 24 in epoch 7, gen_loss = 0.4782263505458832, disc_loss = 0.18281998872756958
Trained batch 25 in epoch 7, gen_loss = 0.47674335539340973, disc_loss = 0.1821337451155369
Trained batch 26 in epoch 7, gen_loss = 0.47430054788236264, disc_loss = 0.1879774492096018
Trained batch 27 in epoch 7, gen_loss = 0.4791246737752642, disc_loss = 0.18825102278164454
Trained batch 28 in epoch 7, gen_loss = 0.4804073325518904, disc_loss = 0.18768620182727946
Trained batch 29 in epoch 7, gen_loss = 0.4793326914310455, disc_loss = 0.18574801286061604
Trained batch 30 in epoch 7, gen_loss = 0.4774340929523591, disc_loss = 0.18472607385727666
Trained batch 31 in epoch 7, gen_loss = 0.479189969599247, disc_loss = 0.18557289196178317
Trained batch 32 in epoch 7, gen_loss = 0.47887356534148706, disc_loss = 0.18345084831570135
Trained batch 33 in epoch 7, gen_loss = 0.47740208839668946, disc_loss = 0.18363561393583522
Trained batch 34 in epoch 7, gen_loss = 0.4785265931061336, disc_loss = 0.18144217537982124
Trained batch 35 in epoch 7, gen_loss = 0.47928642315997017, disc_loss = 0.1792140064968003
Trained batch 36 in epoch 7, gen_loss = 0.4816273797202755, disc_loss = 0.17804344481713064
Trained batch 37 in epoch 7, gen_loss = 0.48026502053988607, disc_loss = 0.17768852491127818
Trained batch 38 in epoch 7, gen_loss = 0.47846226126719743, disc_loss = 0.17606384651019022
Trained batch 39 in epoch 7, gen_loss = 0.47966399416327477, disc_loss = 0.17752520609647035
Trained batch 40 in epoch 7, gen_loss = 0.48035843561335306, disc_loss = 0.1762517001934168
Trained batch 41 in epoch 7, gen_loss = 0.4787076910336812, disc_loss = 0.17917614625323386
Trained batch 42 in epoch 7, gen_loss = 0.4797444731690163, disc_loss = 0.17944228874389515
Trained batch 43 in epoch 7, gen_loss = 0.47935104302384635, disc_loss = 0.17782386155291038
Trained batch 44 in epoch 7, gen_loss = 0.4788728720611996, disc_loss = 0.1769373036093182
Trained batch 45 in epoch 7, gen_loss = 0.4792585036028986, disc_loss = 0.1755877998859986
Trained batch 46 in epoch 7, gen_loss = 0.4798525267458977, disc_loss = 0.17401996714637635
Trained batch 47 in epoch 7, gen_loss = 0.48168893655141193, disc_loss = 0.1742455312050879
Trained batch 48 in epoch 7, gen_loss = 0.4818663511957441, disc_loss = 0.17342133683209515
Trained batch 49 in epoch 7, gen_loss = 0.48057424068450927, disc_loss = 0.17353189423680304
Trained batch 50 in epoch 7, gen_loss = 0.4801298794793148, disc_loss = 0.1724255448755096
Trained batch 51 in epoch 7, gen_loss = 0.4801623528966537, disc_loss = 0.1702655658412438
Trained batch 52 in epoch 7, gen_loss = 0.4803072967619266, disc_loss = 0.16974225232623658
Trained batch 53 in epoch 7, gen_loss = 0.481534946847845, disc_loss = 0.17041343823075294
Trained batch 54 in epoch 7, gen_loss = 0.48124785098162565, disc_loss = 0.17102277129888535
Trained batch 55 in epoch 7, gen_loss = 0.4809560083917209, disc_loss = 0.17273567896336317
Trained batch 56 in epoch 7, gen_loss = 0.48193281575253133, disc_loss = 0.17334433880291486
Trained batch 57 in epoch 7, gen_loss = 0.48125061701084004, disc_loss = 0.17352790732322068
Trained batch 58 in epoch 7, gen_loss = 0.4813048137446581, disc_loss = 0.17269537219051587
Trained batch 59 in epoch 7, gen_loss = 0.4822587177157402, disc_loss = 0.17294313671688238
Trained batch 60 in epoch 7, gen_loss = 0.4821847608832062, disc_loss = 0.1728073616252571
Trained batch 61 in epoch 7, gen_loss = 0.48351698440890156, disc_loss = 0.17244088805971608
Trained batch 62 in epoch 7, gen_loss = 0.4835379809614212, disc_loss = 0.1712831807514978
Trained batch 63 in epoch 7, gen_loss = 0.4847809807397425, disc_loss = 0.17096902872435749
Trained batch 64 in epoch 7, gen_loss = 0.4832948157420525, disc_loss = 0.17315643544380482
Trained batch 65 in epoch 7, gen_loss = 0.4854873296889392, disc_loss = 0.17299550139542783
Trained batch 66 in epoch 7, gen_loss = 0.4871087229963559, disc_loss = 0.17251137188121454
Trained batch 67 in epoch 7, gen_loss = 0.4869230468483532, disc_loss = 0.1715490152949796
Trained batch 68 in epoch 7, gen_loss = 0.48744357496068097, disc_loss = 0.17024242219285687
Trained batch 69 in epoch 7, gen_loss = 0.48822668279920306, disc_loss = 0.16982547332133566
Trained batch 70 in epoch 7, gen_loss = 0.4879131333928713, disc_loss = 0.16846282727701564
Trained batch 71 in epoch 7, gen_loss = 0.48867352058490116, disc_loss = 0.16710553597658873
Trained batch 72 in epoch 7, gen_loss = 0.49010005960725755, disc_loss = 0.16509428880598448
Trained batch 73 in epoch 7, gen_loss = 0.49007519878245687, disc_loss = 0.16406744794064276
Trained batch 74 in epoch 7, gen_loss = 0.49186806241671244, disc_loss = 0.16324103151758512
Trained batch 75 in epoch 7, gen_loss = 0.49368424595970856, disc_loss = 0.16276345593168548
Trained batch 76 in epoch 7, gen_loss = 0.49377116560935974, disc_loss = 0.16137602876920204
Trained batch 77 in epoch 7, gen_loss = 0.4933382880229216, disc_loss = 0.16099818155933648
Trained batch 78 in epoch 7, gen_loss = 0.4932070996942399, disc_loss = 0.16039898586046847
Trained batch 79 in epoch 7, gen_loss = 0.49395221285521984, disc_loss = 0.1588040987960994
Trained batch 80 in epoch 7, gen_loss = 0.4950377834431919, disc_loss = 0.15777934296631518
Trained batch 81 in epoch 7, gen_loss = 0.49527894105853104, disc_loss = 0.15635866335615878
Trained batch 82 in epoch 7, gen_loss = 0.4956378617200507, disc_loss = 0.15549519065632877
Trained batch 83 in epoch 7, gen_loss = 0.4958869002404667, disc_loss = 0.1551189258517254
Trained batch 84 in epoch 7, gen_loss = 0.4960663742878858, disc_loss = 0.1546190107569975
Trained batch 85 in epoch 7, gen_loss = 0.4964970533930978, disc_loss = 0.15428366823944933
Trained batch 86 in epoch 7, gen_loss = 0.49621155481228885, disc_loss = 0.15455573471798295
Trained batch 87 in epoch 7, gen_loss = 0.4951482963832942, disc_loss = 0.1548702476376837
Trained batch 88 in epoch 7, gen_loss = 0.4959549334611786, disc_loss = 0.1565691882304931
Trained batch 89 in epoch 7, gen_loss = 0.4944929341475169, disc_loss = 0.1584270308415095
Trained batch 90 in epoch 7, gen_loss = 0.49492489178102095, disc_loss = 0.15830571147111747
Trained batch 91 in epoch 7, gen_loss = 0.49477444459562714, disc_loss = 0.1584297036347182
Trained batch 92 in epoch 7, gen_loss = 0.4933211354799168, disc_loss = 0.1591058006530167
Trained batch 93 in epoch 7, gen_loss = 0.49356102436146837, disc_loss = 0.1588287317055337
Trained batch 94 in epoch 7, gen_loss = 0.49472279297678096, disc_loss = 0.15798922847760352
Trained batch 95 in epoch 7, gen_loss = 0.4939558394253254, disc_loss = 0.15792924732280275
Trained batch 96 in epoch 7, gen_loss = 0.49417419654806866, disc_loss = 0.15810669013827117
Trained batch 97 in epoch 7, gen_loss = 0.494675271973318, disc_loss = 0.15727609114683405
Trained batch 98 in epoch 7, gen_loss = 0.49500620786589805, disc_loss = 0.1563784811984409
Trained batch 99 in epoch 7, gen_loss = 0.4947228267788887, disc_loss = 0.15657912619411946
Trained batch 100 in epoch 7, gen_loss = 0.4952329110981214, disc_loss = 0.1560714903591883
Trained batch 101 in epoch 7, gen_loss = 0.4965410784763448, disc_loss = 0.15612042483453656
Trained batch 102 in epoch 7, gen_loss = 0.49566062590450916, disc_loss = 0.15557046842227862
Trained batch 103 in epoch 7, gen_loss = 0.4958037364368255, disc_loss = 0.15476367737238222
Trained batch 104 in epoch 7, gen_loss = 0.4974100893452054, disc_loss = 0.15496046514738174
Trained batch 105 in epoch 7, gen_loss = 0.49756973785049513, disc_loss = 0.15405570912473607
Trained batch 106 in epoch 7, gen_loss = 0.49811649684594056, disc_loss = 0.15292612724354335
Trained batch 107 in epoch 7, gen_loss = 0.49740367548333275, disc_loss = 0.1529993962979427
Trained batch 108 in epoch 7, gen_loss = 0.4986500857620064, disc_loss = 0.15338403318043148
Trained batch 109 in epoch 7, gen_loss = 0.4995595224879005, disc_loss = 0.15216103839603337
Trained batch 110 in epoch 7, gen_loss = 0.49894468660827157, disc_loss = 0.15411381886617556
Trained batch 111 in epoch 7, gen_loss = 0.5000829215028456, disc_loss = 0.15414827017645752
Trained batch 112 in epoch 7, gen_loss = 0.5004134048930312, disc_loss = 0.15354440466756314
Trained batch 113 in epoch 7, gen_loss = 0.49945538974644843, disc_loss = 0.15408346141900933
Trained batch 114 in epoch 7, gen_loss = 0.49991150938946266, disc_loss = 0.15334366799696633
Trained batch 115 in epoch 7, gen_loss = 0.5002214852078207, disc_loss = 0.15314635563770246
Trained batch 116 in epoch 7, gen_loss = 0.49955697039253694, disc_loss = 0.1539284292067218
Trained batch 117 in epoch 7, gen_loss = 0.4994113215450513, disc_loss = 0.15410520950868978
Trained batch 118 in epoch 7, gen_loss = 0.499094603692784, disc_loss = 0.1540091610631021
Trained batch 119 in epoch 7, gen_loss = 0.4989001688857873, disc_loss = 0.15342458095401526
Trained batch 120 in epoch 7, gen_loss = 0.49986601540864994, disc_loss = 0.1529376743869348
Trained batch 121 in epoch 7, gen_loss = 0.49952747856007246, disc_loss = 0.15293318955380408
Trained batch 122 in epoch 7, gen_loss = 0.49946004321904686, disc_loss = 0.15328077033040968
Trained batch 123 in epoch 7, gen_loss = 0.4989640441152357, disc_loss = 0.1529277688673427
Trained batch 124 in epoch 7, gen_loss = 0.4989834802150726, disc_loss = 0.15239033740758895
Trained batch 125 in epoch 7, gen_loss = 0.4998588677909639, disc_loss = 0.15205075982071103
Trained batch 126 in epoch 7, gen_loss = 0.49951343625549255, disc_loss = 0.1515679727271786
Trained batch 127 in epoch 7, gen_loss = 0.49970914679579437, disc_loss = 0.15080108828260563
Trained batch 128 in epoch 7, gen_loss = 0.49975041479103327, disc_loss = 0.1505671084909014
Trained batch 129 in epoch 7, gen_loss = 0.49998037471221046, disc_loss = 0.15060785163480503
Trained batch 130 in epoch 7, gen_loss = 0.49944864588839405, disc_loss = 0.15082260377648224
Trained batch 131 in epoch 7, gen_loss = 0.49911224322788644, disc_loss = 0.1507869472614292
Trained batch 132 in epoch 7, gen_loss = 0.49951952718254317, disc_loss = 0.15043451701451963
Trained batch 133 in epoch 7, gen_loss = 0.5000356148872802, disc_loss = 0.15008898716030725
Trained batch 134 in epoch 7, gen_loss = 0.4995217031902737, disc_loss = 0.1499728448137089
Trained batch 135 in epoch 7, gen_loss = 0.49997857388328104, disc_loss = 0.1496444848804351
Trained batch 136 in epoch 7, gen_loss = 0.5008546971056583, disc_loss = 0.14897388374827203
Trained batch 137 in epoch 7, gen_loss = 0.5006001485862593, disc_loss = 0.14865854471597983
Trained batch 138 in epoch 7, gen_loss = 0.5011412820798887, disc_loss = 0.14806646620519728
Trained batch 139 in epoch 7, gen_loss = 0.5019011827451842, disc_loss = 0.14746841466320412
Trained batch 140 in epoch 7, gen_loss = 0.5026175956776802, disc_loss = 0.14680197494144134
Trained batch 141 in epoch 7, gen_loss = 0.5020771769570632, disc_loss = 0.14696752403298735
Trained batch 142 in epoch 7, gen_loss = 0.5038960642747946, disc_loss = 0.14743416675633483
Trained batch 143 in epoch 7, gen_loss = 0.5039486098620627, disc_loss = 0.1468713689957642
Trained batch 144 in epoch 7, gen_loss = 0.5034442036316312, disc_loss = 0.14717212429848212
Trained batch 145 in epoch 7, gen_loss = 0.5044006270496812, disc_loss = 0.1466308644117966
Trained batch 146 in epoch 7, gen_loss = 0.5059318653985757, disc_loss = 0.14663941060908797
Trained batch 147 in epoch 7, gen_loss = 0.5054439149192862, disc_loss = 0.1475679196568357
Trained batch 148 in epoch 7, gen_loss = 0.5065286403534396, disc_loss = 0.14711807935729923
Trained batch 149 in epoch 7, gen_loss = 0.5070325251420339, disc_loss = 0.14691207570334275
Trained batch 150 in epoch 7, gen_loss = 0.5066342375531102, disc_loss = 0.1469565061790659
Trained batch 151 in epoch 7, gen_loss = 0.5068617821916154, disc_loss = 0.14685501444986776
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.6321814060211182, disc_loss = 0.08752860128879547
Trained batch 1 in epoch 8, gen_loss = 0.5576150119304657, disc_loss = 0.12389569729566574
Trained batch 2 in epoch 8, gen_loss = 0.54155033826828, disc_loss = 0.13355867067972818
Trained batch 3 in epoch 8, gen_loss = 0.54527647793293, disc_loss = 0.14359673112630844
Trained batch 4 in epoch 8, gen_loss = 0.5410553693771363, disc_loss = 0.12671369016170503
Trained batch 5 in epoch 8, gen_loss = 0.5614089965820312, disc_loss = 0.11324431374669075
Trained batch 6 in epoch 8, gen_loss = 0.5457605080945152, disc_loss = 0.12211837193795613
Trained batch 7 in epoch 8, gen_loss = 0.553310502320528, disc_loss = 0.11842775996774435
Trained batch 8 in epoch 8, gen_loss = 0.5712795025772519, disc_loss = 0.14241637372308308
Trained batch 9 in epoch 8, gen_loss = 0.55741568505764, disc_loss = 0.13650659695267678
Trained batch 10 in epoch 8, gen_loss = 0.5543765506961129, disc_loss = 0.13307904181155292
Trained batch 11 in epoch 8, gen_loss = 0.5499900604287783, disc_loss = 0.13529977637032667
Trained batch 12 in epoch 8, gen_loss = 0.5439442006441263, disc_loss = 0.13580533002431577
Trained batch 13 in epoch 8, gen_loss = 0.5335624239274434, disc_loss = 0.14044877939990588
Trained batch 14 in epoch 8, gen_loss = 0.5376181662082672, disc_loss = 0.14779563198486964
Trained batch 15 in epoch 8, gen_loss = 0.5292442385107279, disc_loss = 0.15099591435864568
Trained batch 16 in epoch 8, gen_loss = 0.5226859783425051, disc_loss = 0.15738936776624007
Trained batch 17 in epoch 8, gen_loss = 0.5181940065489875, disc_loss = 0.16133610531687737
Trained batch 18 in epoch 8, gen_loss = 0.5154153343878294, disc_loss = 0.15825924943936498
Trained batch 19 in epoch 8, gen_loss = 0.5129272907972335, disc_loss = 0.15697369016706944
Trained batch 20 in epoch 8, gen_loss = 0.5123582681020101, disc_loss = 0.15477413080987476
Trained batch 21 in epoch 8, gen_loss = 0.5075383552096107, disc_loss = 0.1554016647013751
Trained batch 22 in epoch 8, gen_loss = 0.5084158765233081, disc_loss = 0.153038684764634
Trained batch 23 in epoch 8, gen_loss = 0.5095508856077989, disc_loss = 0.15163735331346592
Trained batch 24 in epoch 8, gen_loss = 0.5098735749721527, disc_loss = 0.1500597581267357
Trained batch 25 in epoch 8, gen_loss = 0.5074057842676456, disc_loss = 0.15192288704789603
Trained batch 26 in epoch 8, gen_loss = 0.5050322556937182, disc_loss = 0.153642481399907
Trained batch 27 in epoch 8, gen_loss = 0.5044293829372951, disc_loss = 0.15342865910913264
Trained batch 28 in epoch 8, gen_loss = 0.5014933769045204, disc_loss = 0.15266716505946784
Trained batch 29 in epoch 8, gen_loss = 0.5020218461751937, disc_loss = 0.15502946004271506
Trained batch 30 in epoch 8, gen_loss = 0.4996740058545143, disc_loss = 0.1556262938726333
Trained batch 31 in epoch 8, gen_loss = 0.4984929645434022, disc_loss = 0.15291497576981783
Trained batch 32 in epoch 8, gen_loss = 0.500301210266171, disc_loss = 0.1520574219299085
Trained batch 33 in epoch 8, gen_loss = 0.5031261768411187, disc_loss = 0.14955534676418586
Trained batch 34 in epoch 8, gen_loss = 0.4996289508683341, disc_loss = 0.14982704669237137
Trained batch 35 in epoch 8, gen_loss = 0.502352848649025, disc_loss = 0.1469599080996381
Trained batch 36 in epoch 8, gen_loss = 0.5022138727677835, disc_loss = 0.14645572268479579
Trained batch 37 in epoch 8, gen_loss = 0.4981720745563507, disc_loss = 0.14889501094033844
Trained batch 38 in epoch 8, gen_loss = 0.4985348949065575, disc_loss = 0.14917518446842828
Trained batch 39 in epoch 8, gen_loss = 0.5021256491541862, disc_loss = 0.15180478449910878
Trained batch 40 in epoch 8, gen_loss = 0.49985567607530734, disc_loss = 0.15315853440906943
Trained batch 41 in epoch 8, gen_loss = 0.4978183947858356, disc_loss = 0.15463127781237876
Trained batch 42 in epoch 8, gen_loss = 0.49999214604843495, disc_loss = 0.15702087328184483
Trained batch 43 in epoch 8, gen_loss = 0.4990622123534029, disc_loss = 0.15770457024601373
Trained batch 44 in epoch 8, gen_loss = 0.4990993678569794, disc_loss = 0.15828147613339955
Trained batch 45 in epoch 8, gen_loss = 0.49911300060541736, disc_loss = 0.15980804241869762
Trained batch 46 in epoch 8, gen_loss = 0.4964541031959209, disc_loss = 0.16171855320955844
Trained batch 47 in epoch 8, gen_loss = 0.497512557854255, disc_loss = 0.16124974082534513
Trained batch 48 in epoch 8, gen_loss = 0.4971826331956046, disc_loss = 0.16035423199741208
Trained batch 49 in epoch 8, gen_loss = 0.49718883633613586, disc_loss = 0.16037554413080216
Trained batch 50 in epoch 8, gen_loss = 0.4969790309083228, disc_loss = 0.1594375686026087
Trained batch 51 in epoch 8, gen_loss = 0.49601078835817486, disc_loss = 0.1597917817819577
Trained batch 52 in epoch 8, gen_loss = 0.4956941582121939, disc_loss = 0.15955547327702901
Trained batch 53 in epoch 8, gen_loss = 0.4955269495646159, disc_loss = 0.15938868608187745
Trained batch 54 in epoch 8, gen_loss = 0.49516106627204204, disc_loss = 0.16075383655049585
Trained batch 55 in epoch 8, gen_loss = 0.49592174483197077, disc_loss = 0.16161647239433868
Trained batch 56 in epoch 8, gen_loss = 0.49485487791529875, disc_loss = 0.16154401880084424
Trained batch 57 in epoch 8, gen_loss = 0.495427629043316, disc_loss = 0.16149681331268673
Trained batch 58 in epoch 8, gen_loss = 0.49482268398090945, disc_loss = 0.1609135748723806
Trained batch 59 in epoch 8, gen_loss = 0.4948987950881322, disc_loss = 0.15929958485066892
Trained batch 60 in epoch 8, gen_loss = 0.4934731511796107, disc_loss = 0.15869134676749588
Trained batch 61 in epoch 8, gen_loss = 0.4937792492489661, disc_loss = 0.15794059405884436
Trained batch 62 in epoch 8, gen_loss = 0.49477156429063707, disc_loss = 0.1561073133396724
Trained batch 63 in epoch 8, gen_loss = 0.4933058153837919, disc_loss = 0.15826602489687502
Trained batch 64 in epoch 8, gen_loss = 0.49447500980817355, disc_loss = 0.15994334473059726
Trained batch 65 in epoch 8, gen_loss = 0.4929603401458625, disc_loss = 0.1595596307606408
Trained batch 66 in epoch 8, gen_loss = 0.49155377363091085, disc_loss = 0.16067511933063394
Trained batch 67 in epoch 8, gen_loss = 0.492561895181151, disc_loss = 0.16073310484780984
Trained batch 68 in epoch 8, gen_loss = 0.4925329564274221, disc_loss = 0.1593241134415502
Trained batch 69 in epoch 8, gen_loss = 0.49222485210214345, disc_loss = 0.15906717308929988
Trained batch 70 in epoch 8, gen_loss = 0.4923501203597431, disc_loss = 0.1587060425483005
Trained batch 71 in epoch 8, gen_loss = 0.4934600181877613, disc_loss = 0.1579545439324445
Trained batch 72 in epoch 8, gen_loss = 0.4933707644678142, disc_loss = 0.15667496672640108
Trained batch 73 in epoch 8, gen_loss = 0.49260782510847656, disc_loss = 0.15659721769593857
Trained batch 74 in epoch 8, gen_loss = 0.49378034631411233, disc_loss = 0.15877344856659573
Trained batch 75 in epoch 8, gen_loss = 0.49354458757137, disc_loss = 0.15833934092600094
Trained batch 76 in epoch 8, gen_loss = 0.492700433963305, disc_loss = 0.1586933781380777
Trained batch 77 in epoch 8, gen_loss = 0.4934695764229848, disc_loss = 0.15959206347664198
Trained batch 78 in epoch 8, gen_loss = 0.49270206991630267, disc_loss = 0.15954833572046667
Trained batch 79 in epoch 8, gen_loss = 0.49345064982771875, disc_loss = 0.15906992014497517
Trained batch 80 in epoch 8, gen_loss = 0.49402375059363285, disc_loss = 0.15822139299578136
Trained batch 81 in epoch 8, gen_loss = 0.4936226908026672, disc_loss = 0.15732856685431992
Trained batch 82 in epoch 8, gen_loss = 0.4947955066181091, disc_loss = 0.15745402684053741
Trained batch 83 in epoch 8, gen_loss = 0.4934068425070672, disc_loss = 0.15957751772588208
Trained batch 84 in epoch 8, gen_loss = 0.4946420722147998, disc_loss = 0.16016386019832948
Trained batch 85 in epoch 8, gen_loss = 0.4958532047133113, disc_loss = 0.1595120345090711
Trained batch 86 in epoch 8, gen_loss = 0.4957606343702338, disc_loss = 0.16046737134456635
Trained batch 87 in epoch 8, gen_loss = 0.49536628648638725, disc_loss = 0.1599591884084723
Trained batch 88 in epoch 8, gen_loss = 0.49536367112331176, disc_loss = 0.1595612479729599
Trained batch 89 in epoch 8, gen_loss = 0.4944099376598994, disc_loss = 0.1598120038708051
Trained batch 90 in epoch 8, gen_loss = 0.4944437611234057, disc_loss = 0.15921878061451755
Trained batch 91 in epoch 8, gen_loss = 0.49437058490255603, disc_loss = 0.1593211262446383
Trained batch 92 in epoch 8, gen_loss = 0.493831951772013, disc_loss = 0.15927470243105324
Trained batch 93 in epoch 8, gen_loss = 0.49443801603418713, disc_loss = 0.15869948902028672
Trained batch 94 in epoch 8, gen_loss = 0.4946124183504205, disc_loss = 0.15875968227260992
Trained batch 95 in epoch 8, gen_loss = 0.4946352733920018, disc_loss = 0.15834542410448194
Trained batch 96 in epoch 8, gen_loss = 0.4947471071764366, disc_loss = 0.1579513471458376
Trained batch 97 in epoch 8, gen_loss = 0.49375916287607075, disc_loss = 0.15902502211380978
Trained batch 98 in epoch 8, gen_loss = 0.49393388990199927, disc_loss = 0.15823585660469652
Trained batch 99 in epoch 8, gen_loss = 0.49393955916166304, disc_loss = 0.15840237103402616
Trained batch 100 in epoch 8, gen_loss = 0.4940171409951578, disc_loss = 0.15829112749583651
Trained batch 101 in epoch 8, gen_loss = 0.49264945060599086, disc_loss = 0.15935375388054288
Trained batch 102 in epoch 8, gen_loss = 0.49205795190866713, disc_loss = 0.1594479070271103
Trained batch 103 in epoch 8, gen_loss = 0.4917732815329845, disc_loss = 0.15948545309500053
Trained batch 104 in epoch 8, gen_loss = 0.49167345819019137, disc_loss = 0.1586816451379231
Trained batch 105 in epoch 8, gen_loss = 0.4928834618262525, disc_loss = 0.15853348051039678
Trained batch 106 in epoch 8, gen_loss = 0.49220247134984096, disc_loss = 0.15887472604479747
Trained batch 107 in epoch 8, gen_loss = 0.49211320750139376, disc_loss = 0.15912213466233677
Trained batch 108 in epoch 8, gen_loss = 0.4915375039664977, disc_loss = 0.15917911496731119
Trained batch 109 in epoch 8, gen_loss = 0.49152892204848203, disc_loss = 0.15845640057867225
Trained batch 110 in epoch 8, gen_loss = 0.4920460477068618, disc_loss = 0.15763826171557108
Trained batch 111 in epoch 8, gen_loss = 0.4919896775058338, disc_loss = 0.1579438059457711
Trained batch 112 in epoch 8, gen_loss = 0.49144400906773794, disc_loss = 0.15820802972380038
Trained batch 113 in epoch 8, gen_loss = 0.4918277634863268, disc_loss = 0.15855525015738972
Trained batch 114 in epoch 8, gen_loss = 0.4919562407161879, disc_loss = 0.15895910457424495
Trained batch 115 in epoch 8, gen_loss = 0.49103469504364605, disc_loss = 0.15947449117385107
Trained batch 116 in epoch 8, gen_loss = 0.49147542343180406, disc_loss = 0.15912913015255561
Trained batch 117 in epoch 8, gen_loss = 0.49190769079378094, disc_loss = 0.15888069759486084
Trained batch 118 in epoch 8, gen_loss = 0.4913292872805555, disc_loss = 0.15911836220937617
Trained batch 119 in epoch 8, gen_loss = 0.4904938481748104, disc_loss = 0.15948476952811083
Trained batch 120 in epoch 8, gen_loss = 0.4905955390004087, disc_loss = 0.15916154472049604
Trained batch 121 in epoch 8, gen_loss = 0.49031690178347415, disc_loss = 0.1590768691824108
Trained batch 122 in epoch 8, gen_loss = 0.4903835082441811, disc_loss = 0.15824492248456654
Trained batch 123 in epoch 8, gen_loss = 0.4913603110659507, disc_loss = 0.15744251838975376
Trained batch 124 in epoch 8, gen_loss = 0.49035903429985045, disc_loss = 0.15820750460028649
Trained batch 125 in epoch 8, gen_loss = 0.49103257556756336, disc_loss = 0.15828648218441577
Trained batch 126 in epoch 8, gen_loss = 0.4910219774002165, disc_loss = 0.1573573324800007
Trained batch 127 in epoch 8, gen_loss = 0.4915638284292072, disc_loss = 0.1563963126100134
Trained batch 128 in epoch 8, gen_loss = 0.4927291682986326, disc_loss = 0.15545116639298986
Trained batch 129 in epoch 8, gen_loss = 0.49258497013495517, disc_loss = 0.15555936874678503
Trained batch 130 in epoch 8, gen_loss = 0.49456885184040505, disc_loss = 0.1562718768099337
Trained batch 131 in epoch 8, gen_loss = 0.4944571543372039, disc_loss = 0.15557762701064348
Trained batch 132 in epoch 8, gen_loss = 0.4939997532313928, disc_loss = 0.1562402785328546
Trained batch 133 in epoch 8, gen_loss = 0.4946752595367716, disc_loss = 0.15616402155094183
Trained batch 134 in epoch 8, gen_loss = 0.4946065792330989, disc_loss = 0.15552816680736012
Trained batch 135 in epoch 8, gen_loss = 0.4945063954767059, disc_loss = 0.15499569324995666
Trained batch 136 in epoch 8, gen_loss = 0.49449216427594206, disc_loss = 0.15437204469620747
Trained batch 137 in epoch 8, gen_loss = 0.49466389914353687, disc_loss = 0.1548017799800289
Trained batch 138 in epoch 8, gen_loss = 0.49402250360241895, disc_loss = 0.15505299108813134
Trained batch 139 in epoch 8, gen_loss = 0.4946753174066544, disc_loss = 0.1544381022187216
Trained batch 140 in epoch 8, gen_loss = 0.4945240851412428, disc_loss = 0.15431135256134026
Trained batch 141 in epoch 8, gen_loss = 0.4941212532805725, disc_loss = 0.15436118041020883
Trained batch 142 in epoch 8, gen_loss = 0.49339364479471753, disc_loss = 0.1543101222104543
Trained batch 143 in epoch 8, gen_loss = 0.4928788921485345, disc_loss = 0.15422914609209532
Trained batch 144 in epoch 8, gen_loss = 0.49327125939829597, disc_loss = 0.15424874545685177
Trained batch 145 in epoch 8, gen_loss = 0.49383836555970856, disc_loss = 0.15376323867232017
Trained batch 146 in epoch 8, gen_loss = 0.4943844710483032, disc_loss = 0.15307099937277585
Trained batch 147 in epoch 8, gen_loss = 0.4935131352898237, disc_loss = 0.15345359122934374
Trained batch 148 in epoch 8, gen_loss = 0.4941253944131352, disc_loss = 0.15328931860975772
Trained batch 149 in epoch 8, gen_loss = 0.4945195569594701, disc_loss = 0.15284237948556742
Trained batch 150 in epoch 8, gen_loss = 0.4940060533040407, disc_loss = 0.15257027318442104
Trained batch 151 in epoch 8, gen_loss = 0.4936774745583534, disc_loss = 0.15250318504771904
Testing Epoch 8

Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.7223861217498779, disc_loss = 0.2953964173793793
Trained batch 1 in epoch 9, gen_loss = 0.5856934189796448, disc_loss = 0.20521564781665802
Trained batch 2 in epoch 9, gen_loss = 0.5382126172383627, disc_loss = 0.17772950728734335
Trained batch 3 in epoch 9, gen_loss = 0.5323058068752289, disc_loss = 0.2071370631456375
Trained batch 4 in epoch 9, gen_loss = 0.530626904964447, disc_loss = 0.1800239145755768
Trained batch 5 in epoch 9, gen_loss = 0.5137310524781545, disc_loss = 0.16774058838685355
Trained batch 6 in epoch 9, gen_loss = 0.505113001380648, disc_loss = 0.16459253430366516
Trained batch 7 in epoch 9, gen_loss = 0.5057464800775051, disc_loss = 0.17101506516337395
Trained batch 8 in epoch 9, gen_loss = 0.49869319796562195, disc_loss = 0.1675504744052887
Trained batch 9 in epoch 9, gen_loss = 0.49819726645946505, disc_loss = 0.16983012109994888
Trained batch 10 in epoch 9, gen_loss = 0.4922764274207028, disc_loss = 0.17463462596589868
Trained batch 11 in epoch 9, gen_loss = 0.48916148394346237, disc_loss = 0.16980438803633055
Trained batch 12 in epoch 9, gen_loss = 0.4920531167433812, disc_loss = 0.17173414734693673
Trained batch 13 in epoch 9, gen_loss = 0.49532473725931986, disc_loss = 0.16396093581404006
Trained batch 14 in epoch 9, gen_loss = 0.4917365888754527, disc_loss = 0.16023621161778767
Trained batch 15 in epoch 9, gen_loss = 0.4865094367414713, disc_loss = 0.1618690062314272
Trained batch 16 in epoch 9, gen_loss = 0.4966788449708153, disc_loss = 0.1731582950143253
Trained batch 17 in epoch 9, gen_loss = 0.4923344833983315, disc_loss = 0.17093954318099552
Trained batch 18 in epoch 9, gen_loss = 0.4853727346972415, disc_loss = 0.16974776983261108
Trained batch 19 in epoch 9, gen_loss = 0.48217078745365144, disc_loss = 0.1700039178133011
Trained batch 20 in epoch 9, gen_loss = 0.48029754984946477, disc_loss = 0.16782353392669133
Trained batch 21 in epoch 9, gen_loss = 0.4796369035135616, disc_loss = 0.16752456738190216
Trained batch 22 in epoch 9, gen_loss = 0.48263860655867535, disc_loss = 0.16902083871157272
Trained batch 23 in epoch 9, gen_loss = 0.48294293756286305, disc_loss = 0.1687560211867094
Trained batch 24 in epoch 9, gen_loss = 0.4834248745441437, disc_loss = 0.16734147191047669
Trained batch 25 in epoch 9, gen_loss = 0.4869638876273082, disc_loss = 0.1644982901903299
Trained batch 26 in epoch 9, gen_loss = 0.4905184628786864, disc_loss = 0.1635913959255925
Trained batch 27 in epoch 9, gen_loss = 0.48894145765474867, disc_loss = 0.16208629044038908
Trained batch 28 in epoch 9, gen_loss = 0.48977862658171817, disc_loss = 0.1617298830172111
Trained batch 29 in epoch 9, gen_loss = 0.4906197855869929, disc_loss = 0.15954467058181762
Trained batch 30 in epoch 9, gen_loss = 0.4921448374948194, disc_loss = 0.15638956151181652
Trained batch 31 in epoch 9, gen_loss = 0.4922387292608619, disc_loss = 0.15380699408706278
Trained batch 32 in epoch 9, gen_loss = 0.49489433024868823, disc_loss = 0.15212203460660847
Trained batch 33 in epoch 9, gen_loss = 0.4960949605002123, disc_loss = 0.14988786847714117
Trained batch 34 in epoch 9, gen_loss = 0.496516352891922, disc_loss = 0.15119504534772465
Trained batch 35 in epoch 9, gen_loss = 0.4999021482136514, disc_loss = 0.15164388788657057
Trained batch 36 in epoch 9, gen_loss = 0.5019764022247212, disc_loss = 0.14989411901380564
Trained batch 37 in epoch 9, gen_loss = 0.5006286980290162, disc_loss = 0.15002217682960786
Trained batch 38 in epoch 9, gen_loss = 0.5029540558656057, disc_loss = 0.14848866667120886
Trained batch 39 in epoch 9, gen_loss = 0.506538737565279, disc_loss = 0.14663506103679538
Trained batch 40 in epoch 9, gen_loss = 0.5054382914450111, disc_loss = 0.1459518103156148
Trained batch 41 in epoch 9, gen_loss = 0.5067914781116304, disc_loss = 0.14384610835640205
Trained batch 42 in epoch 9, gen_loss = 0.5076738318731618, disc_loss = 0.14375619581618973
Trained batch 43 in epoch 9, gen_loss = 0.5063370825214819, disc_loss = 0.1432469789446755
Trained batch 44 in epoch 9, gen_loss = 0.5057458963659075, disc_loss = 0.1421760957274172
Trained batch 45 in epoch 9, gen_loss = 0.508823939639589, disc_loss = 0.14088696702990844
Trained batch 46 in epoch 9, gen_loss = 0.5139359318195506, disc_loss = 0.13905768564089815
Trained batch 47 in epoch 9, gen_loss = 0.5115931977828344, disc_loss = 0.14010761111664274
Trained batch 48 in epoch 9, gen_loss = 0.5135877424356888, disc_loss = 0.1376069898964191
Trained batch 49 in epoch 9, gen_loss = 0.5172571969032288, disc_loss = 0.13738680712878704
Trained batch 50 in epoch 9, gen_loss = 0.5175010748938018, disc_loss = 0.1357592272700048
Trained batch 51 in epoch 9, gen_loss = 0.5165201379702642, disc_loss = 0.1350951982805362
Trained batch 52 in epoch 9, gen_loss = 0.5164963209404135, disc_loss = 0.13521413870577542
Trained batch 53 in epoch 9, gen_loss = 0.5166736112700568, disc_loss = 0.13377889142268234
Trained batch 54 in epoch 9, gen_loss = 0.5169812137430364, disc_loss = 0.13345112590627237
Trained batch 55 in epoch 9, gen_loss = 0.5177255613463265, disc_loss = 0.13155123395180063
Trained batch 56 in epoch 9, gen_loss = 0.5167701814258308, disc_loss = 0.13170975306185714
Trained batch 57 in epoch 9, gen_loss = 0.5174089305359741, disc_loss = 0.13084587432315636
Trained batch 58 in epoch 9, gen_loss = 0.5181818993414863, disc_loss = 0.13308652051550857
Trained batch 59 in epoch 9, gen_loss = 0.5154449452956518, disc_loss = 0.1355893425953885
Trained batch 60 in epoch 9, gen_loss = 0.5153770114554733, disc_loss = 0.13503068517588201
Trained batch 61 in epoch 9, gen_loss = 0.5174612845143964, disc_loss = 0.13508597187577717
Trained batch 62 in epoch 9, gen_loss = 0.5151857535044352, disc_loss = 0.13608759668256556
Trained batch 63 in epoch 9, gen_loss = 0.5155724296346307, disc_loss = 0.13512666712631471
Trained batch 64 in epoch 9, gen_loss = 0.518835725234105, disc_loss = 0.13382368274033069
Trained batch 65 in epoch 9, gen_loss = 0.5211592542402672, disc_loss = 0.1320767036046494
Trained batch 66 in epoch 9, gen_loss = 0.5230356107896833, disc_loss = 0.13054022832370515
Trained batch 67 in epoch 9, gen_loss = 0.524807977325776, disc_loss = 0.12890779177713044
Trained batch 68 in epoch 9, gen_loss = 0.5272435882817144, disc_loss = 0.1275787905830404
Trained batch 69 in epoch 9, gen_loss = 0.5296719023159572, disc_loss = 0.12596745762441838
Trained batch 70 in epoch 9, gen_loss = 0.5301306650672161, disc_loss = 0.12462981402034491
Trained batch 71 in epoch 9, gen_loss = 0.5314291036791272, disc_loss = 0.12305033314300494
Trained batch 72 in epoch 9, gen_loss = 0.5323135967123999, disc_loss = 0.12167059776870763
Trained batch 73 in epoch 9, gen_loss = 0.532606714480632, disc_loss = 0.12036746170220745
Trained batch 74 in epoch 9, gen_loss = 0.5328757540384929, disc_loss = 0.11920487194011609
Trained batch 75 in epoch 9, gen_loss = 0.5349767466909007, disc_loss = 0.1196265992046775
Trained batch 76 in epoch 9, gen_loss = 0.5345781933177601, disc_loss = 0.11986737193950972
Trained batch 77 in epoch 9, gen_loss = 0.5338858641110934, disc_loss = 0.12074858646314496
Trained batch 78 in epoch 9, gen_loss = 0.5335811557649057, disc_loss = 0.12219498852338595
Trained batch 79 in epoch 9, gen_loss = 0.5328521858900785, disc_loss = 0.12193574429256841
Trained batch 80 in epoch 9, gen_loss = 0.5327713471135975, disc_loss = 0.1211965585725359
Trained batch 81 in epoch 9, gen_loss = 0.5334704587372338, disc_loss = 0.12247844379985841
Trained batch 82 in epoch 9, gen_loss = 0.5327600222754191, disc_loss = 0.12350501724889121
Trained batch 83 in epoch 9, gen_loss = 0.5335336210472243, disc_loss = 0.1228020356502384
Trained batch 84 in epoch 9, gen_loss = 0.5334752864697401, disc_loss = 0.12214864539530347
Trained batch 85 in epoch 9, gen_loss = 0.5329135548929835, disc_loss = 0.12207776839779906
Trained batch 86 in epoch 9, gen_loss = 0.5339327526503596, disc_loss = 0.12185935576542697
Trained batch 87 in epoch 9, gen_loss = 0.5348073769022118, disc_loss = 0.1207595806971023
Trained batch 88 in epoch 9, gen_loss = 0.53399784745795, disc_loss = 0.12040688958688733
Trained batch 89 in epoch 9, gen_loss = 0.5335913217729993, disc_loss = 0.12044070229555169
Trained batch 90 in epoch 9, gen_loss = 0.5337298463334094, disc_loss = 0.12032435162013376
Trained batch 91 in epoch 9, gen_loss = 0.5332219134206357, disc_loss = 0.12119670745754696
Trained batch 92 in epoch 9, gen_loss = 0.5320170521736145, disc_loss = 0.12228432216591412
Trained batch 93 in epoch 9, gen_loss = 0.5320156222962319, disc_loss = 0.12267594767655148
Trained batch 94 in epoch 9, gen_loss = 0.5324700110837033, disc_loss = 0.12205601608086573
Trained batch 95 in epoch 9, gen_loss = 0.533109396075209, disc_loss = 0.12094177271743926
Trained batch 96 in epoch 9, gen_loss = 0.5324321585832182, disc_loss = 0.1203368270539285
Trained batch 97 in epoch 9, gen_loss = 0.5318829532788725, disc_loss = 0.12033957452988442
Trained batch 98 in epoch 9, gen_loss = 0.534229748778873, disc_loss = 0.11996058876052348
Trained batch 99 in epoch 9, gen_loss = 0.5340789395570755, disc_loss = 0.11971988302655517
Trained batch 100 in epoch 9, gen_loss = 0.5348084244397607, disc_loss = 0.11885173243498152
Trained batch 101 in epoch 9, gen_loss = 0.5359938156371024, disc_loss = 0.11788903395006177
Trained batch 102 in epoch 9, gen_loss = 0.5368524604630702, disc_loss = 0.11689591202523233
Trained batch 103 in epoch 9, gen_loss = 0.5369914913406739, disc_loss = 0.11613969444834556
Trained batch 104 in epoch 9, gen_loss = 0.5372312909080869, disc_loss = 0.11520442305398838
Trained batch 105 in epoch 9, gen_loss = 0.5378255141231248, disc_loss = 0.11433815937664993
Trained batch 106 in epoch 9, gen_loss = 0.5366778797078355, disc_loss = 0.11417094655509029
Trained batch 107 in epoch 9, gen_loss = 0.5365261860467769, disc_loss = 0.113574674896275
Trained batch 108 in epoch 9, gen_loss = 0.5376577032815426, disc_loss = 0.1140246111643287
Trained batch 109 in epoch 9, gen_loss = 0.5361870069395412, disc_loss = 0.11613064238124272
Trained batch 110 in epoch 9, gen_loss = 0.5372940492522609, disc_loss = 0.11716379164004917
Trained batch 111 in epoch 9, gen_loss = 0.538311750495008, disc_loss = 0.11629219152798344
Trained batch 112 in epoch 9, gen_loss = 0.5373596063757364, disc_loss = 0.11710405177477978
Trained batch 113 in epoch 9, gen_loss = 0.5374270316801573, disc_loss = 0.11681878043077233
Trained batch 114 in epoch 9, gen_loss = 0.5376667240391607, disc_loss = 0.11653973362206117
Trained batch 115 in epoch 9, gen_loss = 0.536653611680557, disc_loss = 0.11710594368873742
Trained batch 116 in epoch 9, gen_loss = 0.5362897836245023, disc_loss = 0.11667605635160819
Trained batch 117 in epoch 9, gen_loss = 0.5352299592252505, disc_loss = 0.11726277863796232
Trained batch 118 in epoch 9, gen_loss = 0.5347130987323633, disc_loss = 0.11751954043831896
Trained batch 119 in epoch 9, gen_loss = 0.534789227694273, disc_loss = 0.11809112751701226
Trained batch 120 in epoch 9, gen_loss = 0.5351605787257517, disc_loss = 0.11834384364745587
Trained batch 121 in epoch 9, gen_loss = 0.534807495650698, disc_loss = 0.11819586889879381
Trained batch 122 in epoch 9, gen_loss = 0.5340653112748774, disc_loss = 0.1190518913639149
Trained batch 123 in epoch 9, gen_loss = 0.5337004423622163, disc_loss = 0.11938430103773792
Trained batch 124 in epoch 9, gen_loss = 0.5331419365406036, disc_loss = 0.11931702559441328
Trained batch 125 in epoch 9, gen_loss = 0.5327887904076349, disc_loss = 0.11999369772624165
Trained batch 126 in epoch 9, gen_loss = 0.5327324585651788, disc_loss = 0.12048156283003843
Trained batch 127 in epoch 9, gen_loss = 0.5321554117836058, disc_loss = 0.12113428225711687
Trained batch 128 in epoch 9, gen_loss = 0.5310507742471473, disc_loss = 0.12232110175022552
Trained batch 129 in epoch 9, gen_loss = 0.5325458689377858, disc_loss = 0.123525733837428
Trained batch 130 in epoch 9, gen_loss = 0.5326316513633, disc_loss = 0.12297483058006481
Trained batch 131 in epoch 9, gen_loss = 0.5317641914342389, disc_loss = 0.12306285612144027
Trained batch 132 in epoch 9, gen_loss = 0.532417878396529, disc_loss = 0.12354187070062958
Trained batch 133 in epoch 9, gen_loss = 0.5322952735335079, disc_loss = 0.12294444396619254
Trained batch 134 in epoch 9, gen_loss = 0.5315496056168167, disc_loss = 0.12272036119053761
Trained batch 135 in epoch 9, gen_loss = 0.5311903002507546, disc_loss = 0.12301501105128623
Trained batch 136 in epoch 9, gen_loss = 0.5315739116529479, disc_loss = 0.1237202759791356
Trained batch 137 in epoch 9, gen_loss = 0.5320182848667753, disc_loss = 0.12360262443594959
Trained batch 138 in epoch 9, gen_loss = 0.5309951058823428, disc_loss = 0.12557109573306582
Trained batch 139 in epoch 9, gen_loss = 0.5310369383011545, disc_loss = 0.12493224313615688
Trained batch 140 in epoch 9, gen_loss = 0.5309217024779489, disc_loss = 0.12566696434341212
Trained batch 141 in epoch 9, gen_loss = 0.5307895098353775, disc_loss = 0.12571490628802232
Trained batch 142 in epoch 9, gen_loss = 0.5303018059763875, disc_loss = 0.125596518276611
Trained batch 143 in epoch 9, gen_loss = 0.5295538482152753, disc_loss = 0.12575738545274362
Trained batch 144 in epoch 9, gen_loss = 0.529563182592392, disc_loss = 0.12559641897036083
Trained batch 145 in epoch 9, gen_loss = 0.5294272824101252, disc_loss = 0.12529980957074321
Trained batch 146 in epoch 9, gen_loss = 0.5291502043908957, disc_loss = 0.12487917362401883
Trained batch 147 in epoch 9, gen_loss = 0.5296134878252003, disc_loss = 0.12491494804192838
Trained batch 148 in epoch 9, gen_loss = 0.5285076492984823, disc_loss = 0.12572468761604705
Trained batch 149 in epoch 9, gen_loss = 0.5281697883208593, disc_loss = 0.12526983133827646
Trained batch 150 in epoch 9, gen_loss = 0.5283962861196885, disc_loss = 0.1255301751430757
Trained batch 151 in epoch 9, gen_loss = 0.5278967522868985, disc_loss = 0.1252610779208082
Testing Epoch 9
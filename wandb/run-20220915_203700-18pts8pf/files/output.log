/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 3.1391851902008057, disc_loss = 0.5825279951095581
Trained batch 1 in epoch 0, gen_loss = 3.283486008644104, disc_loss = 0.7378966212272644
Trained batch 2 in epoch 0, gen_loss = 3.213108777999878, disc_loss = 0.7900107701619467
Trained batch 3 in epoch 0, gen_loss = 3.133589804172516, disc_loss = 0.6900593936443329
Trained batch 4 in epoch 0, gen_loss = 3.109995889663696, disc_loss = 0.6308066666126251
Trained batch 5 in epoch 0, gen_loss = 3.055770516395569, disc_loss = 0.5780073801676432
Trained batch 6 in epoch 0, gen_loss = 3.0218349524906705, disc_loss = 0.5351407315049853
Trained batch 7 in epoch 0, gen_loss = 2.9705401360988617, disc_loss = 0.49708836153149605
Trained batch 8 in epoch 0, gen_loss = 2.9482713540395102, disc_loss = 0.4631751345263587
Trained batch 9 in epoch 0, gen_loss = 2.9714030981063844, disc_loss = 0.43378604352474215
Trained batch 10 in epoch 0, gen_loss = 2.9834951704198662, disc_loss = 0.408922252329913
Trained batch 11 in epoch 0, gen_loss = 2.9495114286740622, disc_loss = 0.38654396931330365
Trained batch 12 in epoch 0, gen_loss = 2.9590461620917687, disc_loss = 0.3665399757715372
Trained batch 13 in epoch 0, gen_loss = 2.976897188595363, disc_loss = 0.3480599474694048
Trained batch 14 in epoch 0, gen_loss = 2.9653372287750246, disc_loss = 0.33214139491319655
Trained batch 15 in epoch 0, gen_loss = 2.958291217684746, disc_loss = 0.3179406807757914
Trained batch 16 in epoch 0, gen_loss = 2.9660462351406323, disc_loss = 0.3070126408163239
Trained batch 17 in epoch 0, gen_loss = 2.9834510617785983, disc_loss = 0.2975371020535628
Trained batch 18 in epoch 0, gen_loss = 2.992876077953138, disc_loss = 0.28820648044347763
Trained batch 19 in epoch 0, gen_loss = 3.0247668504714964, disc_loss = 0.2787786528468132
Trained batch 20 in epoch 0, gen_loss = 3.0351236207144603, disc_loss = 0.26934459450699033
Trained batch 21 in epoch 0, gen_loss = 3.0347177440469917, disc_loss = 0.26061663912101224
Trained batch 22 in epoch 0, gen_loss = 3.0385025791499927, disc_loss = 0.2524399290914121
Trained batch 23 in epoch 0, gen_loss = 3.030356148878733, disc_loss = 0.2451821823293964
Trained batch 24 in epoch 0, gen_loss = 3.0283671379089356, disc_loss = 0.23908951252698898
Trained batch 25 in epoch 0, gen_loss = 3.049642957173861, disc_loss = 0.23297879443718836
Trained batch 26 in epoch 0, gen_loss = 3.057517087018048, disc_loss = 0.22658718887854506
Trained batch 27 in epoch 0, gen_loss = 3.0619358675820485, disc_loss = 0.22134427872619458
Trained batch 28 in epoch 0, gen_loss = 3.054951470473717, disc_loss = 0.2168683696152835
Trained batch 29 in epoch 0, gen_loss = 3.0548853079477944, disc_loss = 0.21232888338466485
Trained batch 30 in epoch 0, gen_loss = 3.061278373964371, disc_loss = 0.20815483156231143
Trained batch 31 in epoch 0, gen_loss = 3.07040736079216, disc_loss = 0.203828377998434
Trained batch 32 in epoch 0, gen_loss = 3.0715560479597612, disc_loss = 0.19995491488864928
Trained batch 33 in epoch 0, gen_loss = 3.0737169490141025, disc_loss = 0.19596830569207668
Trained batch 34 in epoch 0, gen_loss = 3.072351237705776, disc_loss = 0.19228821897080967
Trained batch 35 in epoch 0, gen_loss = 3.064451575279236, disc_loss = 0.18879063499884474
Trained batch 36 in epoch 0, gen_loss = 3.0594930391053894, disc_loss = 0.18612293768170718
Trained batch 37 in epoch 0, gen_loss = 3.071970826701114, disc_loss = 0.18475017098611907
Trained batch 38 in epoch 0, gen_loss = 3.0670379002889, disc_loss = 0.1833981450360555
Trained batch 39 in epoch 0, gen_loss = 3.064987897872925, disc_loss = 0.18114744191989302
Trained batch 40 in epoch 0, gen_loss = 3.0675748499428352, disc_loss = 0.17837853211818672
Trained batch 41 in epoch 0, gen_loss = 3.071118780544826, disc_loss = 0.17529257537708395
Trained batch 42 in epoch 0, gen_loss = 3.069210168927215, disc_loss = 0.172261354795029
Trained batch 43 in epoch 0, gen_loss = 3.076161790977825, disc_loss = 0.16953391031446782
Trained batch 44 in epoch 0, gen_loss = 3.079759211010403, disc_loss = 0.16724307462573051
Trained batch 45 in epoch 0, gen_loss = 3.077868041784867, disc_loss = 0.16475300879582114
Trained batch 46 in epoch 0, gen_loss = 3.075755809215789, disc_loss = 0.16202874695684047
Trained batch 47 in epoch 0, gen_loss = 3.0650695264339447, disc_loss = 0.15959564091948172
Trained batch 48 in epoch 0, gen_loss = 3.0614425406164054, disc_loss = 0.15705125839734563
Trained batch 49 in epoch 0, gen_loss = 3.066979236602783, disc_loss = 0.1545656354725361
Trained batch 50 in epoch 0, gen_loss = 3.0668563796024695, disc_loss = 0.15210673863104746
Trained batch 51 in epoch 0, gen_loss = 3.069195880339696, disc_loss = 0.14969198703049466
Trained batch 52 in epoch 0, gen_loss = 3.0656672918571615, disc_loss = 0.14738938880135427
Trained batch 53 in epoch 0, gen_loss = 3.0626893794095076, disc_loss = 0.145206439136355
Trained batch 54 in epoch 0, gen_loss = 3.0589536493474787, disc_loss = 0.14326590563763272
Trained batch 55 in epoch 0, gen_loss = 3.062602771180017, disc_loss = 0.14184352828721916
Trained batch 56 in epoch 0, gen_loss = 3.064553239889312, disc_loss = 0.14079736780963445
Trained batch 57 in epoch 0, gen_loss = 3.066046044744294, disc_loss = 0.13973064200374588
Trained batch 58 in epoch 0, gen_loss = 3.0688680753869524, disc_loss = 0.13798158394835763
Trained batch 59 in epoch 0, gen_loss = 3.066779534022013, disc_loss = 0.13618851006031035
Trained batch 60 in epoch 0, gen_loss = 3.061545352466771, disc_loss = 0.134427455696659
Trained batch 61 in epoch 0, gen_loss = 3.0608257901284004, disc_loss = 0.13268501792223222
Trained batch 62 in epoch 0, gen_loss = 3.0586391403561546, disc_loss = 0.1310903944429897
Trained batch 63 in epoch 0, gen_loss = 3.056751996278763, disc_loss = 0.1296907865907997
Trained batch 64 in epoch 0, gen_loss = 3.0600971442002516, disc_loss = 0.12897902795901664
Trained batch 65 in epoch 0, gen_loss = 3.0571012858188515, disc_loss = 0.12871953416051288
Trained batch 66 in epoch 0, gen_loss = 3.0599709909353683, disc_loss = 0.1278634630699656
Trained batch 67 in epoch 0, gen_loss = 3.056417167186737, disc_loss = 0.12653535319601789
Trained batch 68 in epoch 0, gen_loss = 3.053193918172864, disc_loss = 0.12526644798724548
Trained batch 69 in epoch 0, gen_loss = 3.0508132219314574, disc_loss = 0.12390933997396912
Trained batch 70 in epoch 0, gen_loss = 3.0538249687409738, disc_loss = 0.12253306394206806
Trained batch 71 in epoch 0, gen_loss = 3.055517567528619, disc_loss = 0.12125808675773442
Trained batch 72 in epoch 0, gen_loss = 3.05786094926808, disc_loss = 0.12025733463057917
Trained batch 73 in epoch 0, gen_loss = 3.0562876108530403, disc_loss = 0.11961742991430534
Trained batch 74 in epoch 0, gen_loss = 3.0542265288035075, disc_loss = 0.11904269037147364
Trained batch 75 in epoch 0, gen_loss = 3.0549317190521643, disc_loss = 0.11847025722167209
Trained batch 76 in epoch 0, gen_loss = 3.054662478434575, disc_loss = 0.11794949794647755
Trained batch 77 in epoch 0, gen_loss = 3.0516699246871166, disc_loss = 0.11724264688121203
Trained batch 78 in epoch 0, gen_loss = 3.047142215921909, disc_loss = 0.11628192193994794
Trained batch 79 in epoch 0, gen_loss = 3.0483640313148497, disc_loss = 0.1151588010136038
Trained batch 80 in epoch 0, gen_loss = 3.052481339301592, disc_loss = 0.11393957552902492
Trained batch 81 in epoch 0, gen_loss = 3.0571936688772063, disc_loss = 0.11277854940058982
Trained batch 82 in epoch 0, gen_loss = 3.054691441087838, disc_loss = 0.11169335771217404
Trained batch 83 in epoch 0, gen_loss = 3.0497447479338873, disc_loss = 0.11064556269862112
Trained batch 84 in epoch 0, gen_loss = 3.0488497958463783, disc_loss = 0.10952584688716074
Trained batch 85 in epoch 0, gen_loss = 3.050258057062016, disc_loss = 0.1084077848814601
Trained batch 86 in epoch 0, gen_loss = 3.0514638149875335, disc_loss = 0.10737631502079553
Trained batch 87 in epoch 0, gen_loss = 3.0516253926537256, disc_loss = 0.10633183964951472
Trained batch 88 in epoch 0, gen_loss = 3.048013046886144, disc_loss = 0.10529289377874203
Trained batch 89 in epoch 0, gen_loss = 3.0520674626032513, disc_loss = 0.10426653909186522
Trained batch 90 in epoch 0, gen_loss = 3.0502748829977855, disc_loss = 0.10327009233431174
Trained batch 91 in epoch 0, gen_loss = 3.0508640719496687, disc_loss = 0.10229084670098255
Trained batch 92 in epoch 0, gen_loss = 3.0512973595690984, disc_loss = 0.10134585695441371
Trained batch 93 in epoch 0, gen_loss = 3.051912771894577, disc_loss = 0.10041777154510008
Trained batch 94 in epoch 0, gen_loss = 3.0516883825000964, disc_loss = 0.09952963023005347
Trained batch 95 in epoch 0, gen_loss = 3.052783228456974, disc_loss = 0.09866717330684575
Trained batch 96 in epoch 0, gen_loss = 3.0537225708519062, disc_loss = 0.09782185045445395
Trained batch 97 in epoch 0, gen_loss = 3.0535862129561755, disc_loss = 0.09696574940593267
Trained batch 98 in epoch 0, gen_loss = 3.051811923884382, disc_loss = 0.09611015413144622
Trained batch 99 in epoch 0, gen_loss = 3.0532616066932676, disc_loss = 0.09533544814214111
Trained batch 100 in epoch 0, gen_loss = 3.0539290527305982, disc_loss = 0.09457608356629268
Trained batch 101 in epoch 0, gen_loss = 3.057185446514803, disc_loss = 0.09385086384181883
Trained batch 102 in epoch 0, gen_loss = 3.0575107139291116, disc_loss = 0.09313488610595175
Trained batch 103 in epoch 0, gen_loss = 3.059376033452841, disc_loss = 0.09243043449420768
Trained batch 104 in epoch 0, gen_loss = 3.058634203956241, disc_loss = 0.09180837782720724
Trained batch 105 in epoch 0, gen_loss = 3.060131147222699, disc_loss = 0.09123931127547655
Trained batch 106 in epoch 0, gen_loss = 3.0623645960727583, disc_loss = 0.09073956451753032
Trained batch 107 in epoch 0, gen_loss = 3.0607649904710277, disc_loss = 0.09022826779012878
Trained batch 108 in epoch 0, gen_loss = 3.0603041102033144, disc_loss = 0.08963919822297511
Trained batch 109 in epoch 0, gen_loss = 3.059623863480308, disc_loss = 0.08896983098238706
Trained batch 110 in epoch 0, gen_loss = 3.0581505685239225, disc_loss = 0.08834199515079055
Trained batch 111 in epoch 0, gen_loss = 3.054089590907097, disc_loss = 0.0876864010767479
Trained batch 112 in epoch 0, gen_loss = 3.051645880251859, disc_loss = 0.08702555653202322
Trained batch 113 in epoch 0, gen_loss = 3.0494884482601234, disc_loss = 0.08637735183889929
Trained batch 114 in epoch 0, gen_loss = 3.0489935273709503, disc_loss = 0.08578280076060606
Trained batch 115 in epoch 0, gen_loss = 3.048889828139338, disc_loss = 0.08521810780953744
Trained batch 116 in epoch 0, gen_loss = 3.047997592860817, disc_loss = 0.08461886158802061
Trained batch 117 in epoch 0, gen_loss = 3.0488041982812395, disc_loss = 0.08399885135971136
Trained batch 118 in epoch 0, gen_loss = 3.047822379264511, disc_loss = 0.08337139914266202
Trained batch 119 in epoch 0, gen_loss = 3.046115513642629, disc_loss = 0.08276209033404787
Trained batch 120 in epoch 0, gen_loss = 3.0454536233066527, disc_loss = 0.08217903456750734
Trained batch 121 in epoch 0, gen_loss = 3.046752740125187, disc_loss = 0.08159958127672311
Trained batch 122 in epoch 0, gen_loss = 3.043960371637732, disc_loss = 0.0810655665515763
Trained batch 123 in epoch 0, gen_loss = 3.043701675630385, disc_loss = 0.0805562742490081
Trained batch 124 in epoch 0, gen_loss = 3.0448906650543215, disc_loss = 0.08002335811406373
Trained batch 125 in epoch 0, gen_loss = 3.0450692990469554, disc_loss = 0.07949525967151636
Trained batch 126 in epoch 0, gen_loss = 3.0424228240185833, disc_loss = 0.07897042252094023
Trained batch 127 in epoch 0, gen_loss = 3.0410981848835945, disc_loss = 0.07848841298982734
Trained batch 128 in epoch 0, gen_loss = 3.040007602336795, disc_loss = 0.0779821323014276
Trained batch 129 in epoch 0, gen_loss = 3.0410033299372747, disc_loss = 0.07749491107578461
Trained batch 130 in epoch 0, gen_loss = 3.039559331559043, disc_loss = 0.07699131045689564
Trained batch 131 in epoch 0, gen_loss = 3.0369307489106148, disc_loss = 0.07647193820131096
Trained batch 132 in epoch 0, gen_loss = 3.034910119565806, disc_loss = 0.07596318175862159
Trained batch 133 in epoch 0, gen_loss = 3.0357898544909347, disc_loss = 0.07546117178984542
Trained batch 134 in epoch 0, gen_loss = 3.034939416249593, disc_loss = 0.07499769648744001
Trained batch 135 in epoch 0, gen_loss = 3.034098639207728, disc_loss = 0.0745745153467664
Trained batch 136 in epoch 0, gen_loss = 3.0350794739966847, disc_loss = 0.07413672264257487
Trained batch 137 in epoch 0, gen_loss = 3.035792908806732, disc_loss = 0.07366965420922075
Trained batch 138 in epoch 0, gen_loss = 3.038863242101326, disc_loss = 0.07318881602971244
Trained batch 139 in epoch 0, gen_loss = 3.0373720492635456, disc_loss = 0.07272132146172225
Trained batch 140 in epoch 0, gen_loss = 3.0364103148169552, disc_loss = 0.07226114230005877
Trained batch 141 in epoch 0, gen_loss = 3.033789431545096, disc_loss = 0.07181433126540251
Trained batch 142 in epoch 0, gen_loss = 3.033240303292975, disc_loss = 0.07136090833146672
Trained batch 143 in epoch 0, gen_loss = 3.033498176270061, disc_loss = 0.07093233299545115
Trained batch 144 in epoch 0, gen_loss = 3.032619966309646, disc_loss = 0.07054251643090413
Trained batch 145 in epoch 0, gen_loss = 3.0318728228137917, disc_loss = 0.07018229152292829
Trained batch 146 in epoch 0, gen_loss = 3.033501146601982, disc_loss = 0.06980802246755889
Trained batch 147 in epoch 0, gen_loss = 3.032976155345504, disc_loss = 0.0694160559340506
Trained batch 148 in epoch 0, gen_loss = 3.0337467513628456, disc_loss = 0.06903870377514586
Trained batch 149 in epoch 0, gen_loss = 3.0325291951497397, disc_loss = 0.06866318741813301
Trained batch 150 in epoch 0, gen_loss = 3.0339784132723775, disc_loss = 0.06831065978583516
Trained batch 151 in epoch 0, gen_loss = 3.0332672094043933, disc_loss = 0.0679405292888221
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.8638341426849365, disc_loss = 0.010770958848297596
Trained batch 1 in epoch 1, gen_loss = 2.8650660514831543, disc_loss = 0.010672135278582573
Trained batch 2 in epoch 1, gen_loss = 2.8431941668192544, disc_loss = 0.011073246287802855
Trained batch 3 in epoch 1, gen_loss = 2.913952112197876, disc_loss = 0.010889670113101602
Trained batch 4 in epoch 1, gen_loss = 2.912515926361084, disc_loss = 0.010450507886707783
Trained batch 5 in epoch 1, gen_loss = 2.895318071047465, disc_loss = 0.010118208670367798
Trained batch 6 in epoch 1, gen_loss = 2.9031949724469865, disc_loss = 0.010024764042879854
Trained batch 7 in epoch 1, gen_loss = 2.8726351857185364, disc_loss = 0.010074759018607438
Trained batch 8 in epoch 1, gen_loss = 2.875487062666151, disc_loss = 0.010036136541101668
Trained batch 9 in epoch 1, gen_loss = 2.8723839044570925, disc_loss = 0.01005291324108839
Trained batch 10 in epoch 1, gen_loss = 2.914843125776811, disc_loss = 0.010280054147270594
Trained batch 11 in epoch 1, gen_loss = 2.9391499956448874, disc_loss = 0.010317584499716759
Trained batch 12 in epoch 1, gen_loss = 2.927795043358436, disc_loss = 0.010341539835700622
Trained batch 13 in epoch 1, gen_loss = 2.957766124180385, disc_loss = 0.010114384815096855
Trained batch 14 in epoch 1, gen_loss = 2.958703311284383, disc_loss = 0.009936462715268135
Trained batch 15 in epoch 1, gen_loss = 2.955172672867775, disc_loss = 0.009645375364925712
Trained batch 16 in epoch 1, gen_loss = 2.9619180034188664, disc_loss = 0.009432291721596438
Trained batch 17 in epoch 1, gen_loss = 2.972398532761468, disc_loss = 0.009266624925658107
Trained batch 18 in epoch 1, gen_loss = 2.961312783391852, disc_loss = 0.00933999673610455
Trained batch 19 in epoch 1, gen_loss = 2.967843437194824, disc_loss = 0.009420621744357049
Trained batch 20 in epoch 1, gen_loss = 2.9574271270206998, disc_loss = 0.00950897771066853
Trained batch 21 in epoch 1, gen_loss = 2.961421912366694, disc_loss = 0.009603906867348334
Trained batch 22 in epoch 1, gen_loss = 2.9614272946896762, disc_loss = 0.009693257652385079
Trained batch 23 in epoch 1, gen_loss = 2.961673140525818, disc_loss = 0.00968736136564985
Trained batch 24 in epoch 1, gen_loss = 2.950768346786499, disc_loss = 0.009677880015224218
Trained batch 25 in epoch 1, gen_loss = 2.9710811101473293, disc_loss = 0.009782103158963414
Trained batch 26 in epoch 1, gen_loss = 2.970708696930497, disc_loss = 0.00979299168964779
Trained batch 27 in epoch 1, gen_loss = 2.9642745426722934, disc_loss = 0.009863555581042809
Trained batch 28 in epoch 1, gen_loss = 2.9577854255150102, disc_loss = 0.009766569441377089
Trained batch 29 in epoch 1, gen_loss = 2.9591684579849242, disc_loss = 0.009713583206757904
Trained batch 30 in epoch 1, gen_loss = 2.9599835795740925, disc_loss = 0.00957057835353959
Trained batch 31 in epoch 1, gen_loss = 2.9578912407159805, disc_loss = 0.009435940766707063
Trained batch 32 in epoch 1, gen_loss = 2.959393855297204, disc_loss = 0.009318554477596825
Trained batch 33 in epoch 1, gen_loss = 2.9630024853874657, disc_loss = 0.009205624666612814
Trained batch 34 in epoch 1, gen_loss = 2.972031102861677, disc_loss = 0.009138455068958657
Trained batch 35 in epoch 1, gen_loss = 2.9740005466673107, disc_loss = 0.009079630822978087
Trained batch 36 in epoch 1, gen_loss = 2.9748727953111804, disc_loss = 0.009047977198418733
Trained batch 37 in epoch 1, gen_loss = 2.9691595215546456, disc_loss = 0.009033856594837025
Trained batch 38 in epoch 1, gen_loss = 2.968396999897101, disc_loss = 0.008955453809064168
Trained batch 39 in epoch 1, gen_loss = 2.96485121846199, disc_loss = 0.00886903804494068
Trained batch 40 in epoch 1, gen_loss = 2.9621606047560527, disc_loss = 0.008799742362121256
Trained batch 41 in epoch 1, gen_loss = 2.9707385926019576, disc_loss = 0.008751830052850502
Trained batch 42 in epoch 1, gen_loss = 2.9757529524869697, disc_loss = 0.008710546992979077
Trained batch 43 in epoch 1, gen_loss = 2.977074996991591, disc_loss = 0.008672080140306869
Trained batch 44 in epoch 1, gen_loss = 2.9828685071733263, disc_loss = 0.008639780649294456
Trained batch 45 in epoch 1, gen_loss = 2.9842014986535776, disc_loss = 0.008595843809535321
Trained batch 46 in epoch 1, gen_loss = 2.9890521840846285, disc_loss = 0.008715284066869224
Trained batch 47 in epoch 1, gen_loss = 2.9891147712866464, disc_loss = 0.008790416128855819
Trained batch 48 in epoch 1, gen_loss = 2.9926380186664816, disc_loss = 0.008831202746273912
Trained batch 49 in epoch 1, gen_loss = 2.9987807846069336, disc_loss = 0.00891174872405827
Trained batch 50 in epoch 1, gen_loss = 3.0052843748354445, disc_loss = 0.008928113644394805
Trained batch 51 in epoch 1, gen_loss = 3.0037287198580227, disc_loss = 0.008976358159158666
Trained batch 52 in epoch 1, gen_loss = 2.9999204176776813, disc_loss = 0.009007611039604218
Trained batch 53 in epoch 1, gen_loss = 3.005182893187911, disc_loss = 0.009019879805338051
Trained batch 54 in epoch 1, gen_loss = 3.006660656495528, disc_loss = 0.009005592636425386
Trained batch 55 in epoch 1, gen_loss = 3.01015048793384, disc_loss = 0.008974127504708511
Trained batch 56 in epoch 1, gen_loss = 3.004605540058069, disc_loss = 0.008904437150544765
Trained batch 57 in epoch 1, gen_loss = 3.0027592141052772, disc_loss = 0.008848533202926147
Trained batch 58 in epoch 1, gen_loss = 3.0044089697175105, disc_loss = 0.008814168375743142
Trained batch 59 in epoch 1, gen_loss = 3.0065173506736755, disc_loss = 0.008893567005482812
Trained batch 60 in epoch 1, gen_loss = 3.00289164996538, disc_loss = 0.008974694379712225
Trained batch 61 in epoch 1, gen_loss = 3.0026341022983676, disc_loss = 0.008991567365404579
Trained batch 62 in epoch 1, gen_loss = 3.002871903162154, disc_loss = 0.008964311457165176
Trained batch 63 in epoch 1, gen_loss = 3.008661687374115, disc_loss = 0.008917967141314875
Trained batch 64 in epoch 1, gen_loss = 3.004407057395348, disc_loss = 0.008865309957987988
Trained batch 65 in epoch 1, gen_loss = 3.004145950982065, disc_loss = 0.008803200428233002
Trained batch 66 in epoch 1, gen_loss = 3.010240615303837, disc_loss = 0.008747417021042375
Trained batch 67 in epoch 1, gen_loss = 3.0065851316732517, disc_loss = 0.00870946524938678
Trained batch 68 in epoch 1, gen_loss = 3.007270678229954, disc_loss = 0.008677403840735771
Trained batch 69 in epoch 1, gen_loss = 3.010167213848659, disc_loss = 0.008638029259496501
Trained batch 70 in epoch 1, gen_loss = 3.014116619674253, disc_loss = 0.00865083501975931
Trained batch 71 in epoch 1, gen_loss = 3.016019148959054, disc_loss = 0.008646377705089334
Trained batch 72 in epoch 1, gen_loss = 3.019549784595019, disc_loss = 0.008622612925373937
Trained batch 73 in epoch 1, gen_loss = 3.0204703066800094, disc_loss = 0.0085830031453657
Trained batch 74 in epoch 1, gen_loss = 3.0200852807362875, disc_loss = 0.008593178695688646
Trained batch 75 in epoch 1, gen_loss = 3.0164411601267362, disc_loss = 0.008618311423465218
Trained batch 76 in epoch 1, gen_loss = 3.025307190882695, disc_loss = 0.008663681740933037
Trained batch 77 in epoch 1, gen_loss = 3.02254048983256, disc_loss = 0.008689995789422821
Trained batch 78 in epoch 1, gen_loss = 3.0211956048313575, disc_loss = 0.008691658814072231
Trained batch 79 in epoch 1, gen_loss = 3.026042342185974, disc_loss = 0.008709137391997501
Trained batch 80 in epoch 1, gen_loss = 3.022905820681725, disc_loss = 0.00879332464027368
Trained batch 81 in epoch 1, gen_loss = 3.0199999867416008, disc_loss = 0.008880461946629533
Trained batch 82 in epoch 1, gen_loss = 3.0276878684400077, disc_loss = 0.009243479598852166
Trained batch 83 in epoch 1, gen_loss = 3.020548071180071, disc_loss = 0.009619773493059688
Trained batch 84 in epoch 1, gen_loss = 3.0305377511417166, disc_loss = 0.010158229526132346
Trained batch 85 in epoch 1, gen_loss = 3.032080129135487, disc_loss = 0.010526488941206141
Trained batch 86 in epoch 1, gen_loss = 3.03380658160681, disc_loss = 0.011514666345741215
Trained batch 87 in epoch 1, gen_loss = 3.0424944975159387, disc_loss = 0.014125209889078344
Trained batch 88 in epoch 1, gen_loss = 3.0448430950721996, disc_loss = 0.01784721476789773
Trained batch 89 in epoch 1, gen_loss = 3.0407369666629367, disc_loss = 0.020391235164263184
Trained batch 90 in epoch 1, gen_loss = 3.0377085339892043, disc_loss = 0.021612329382940637
Trained batch 91 in epoch 1, gen_loss = 3.0348243609718653, disc_loss = 0.021663265986084614
Trained batch 92 in epoch 1, gen_loss = 3.032419458512337, disc_loss = 0.021684516056050217
Trained batch 93 in epoch 1, gen_loss = 3.031180866221164, disc_loss = 0.021613842882017825
Trained batch 94 in epoch 1, gen_loss = 3.033624209855732, disc_loss = 0.021492918664099355
Trained batch 95 in epoch 1, gen_loss = 3.036005718012651, disc_loss = 0.021342556981835514
Trained batch 96 in epoch 1, gen_loss = 3.035341982988967, disc_loss = 0.021195533882212087
Trained batch 97 in epoch 1, gen_loss = 3.0319312762240975, disc_loss = 0.021115339584458544
Trained batch 98 in epoch 1, gen_loss = 3.031547522304034, disc_loss = 0.02104048515114971
Trained batch 99 in epoch 1, gen_loss = 3.032693748474121, disc_loss = 0.020894229183904826
Trained batch 100 in epoch 1, gen_loss = 3.034656616720823, disc_loss = 0.02076292753053626
Trained batch 101 in epoch 1, gen_loss = 3.0333697632247327, disc_loss = 0.020628779336773588
Trained batch 102 in epoch 1, gen_loss = 3.031864492638597, disc_loss = 0.020489272001443556
Trained batch 103 in epoch 1, gen_loss = 3.033137688269982, disc_loss = 0.02034925393616924
Trained batch 104 in epoch 1, gen_loss = 3.0336977232070197, disc_loss = 0.020202088959160307
Trained batch 105 in epoch 1, gen_loss = 3.0348969607982994, disc_loss = 0.02005251691202229
Trained batch 106 in epoch 1, gen_loss = 3.035358858999805, disc_loss = 0.019900789297246767
Trained batch 107 in epoch 1, gen_loss = 3.0374399224917092, disc_loss = 0.019755013222392235
Trained batch 108 in epoch 1, gen_loss = 3.035110471445486, disc_loss = 0.01966141458652025
Trained batch 109 in epoch 1, gen_loss = 3.0318661711432715, disc_loss = 0.019550828233530576
Trained batch 110 in epoch 1, gen_loss = 3.0300205033104697, disc_loss = 0.0194742697257515
Trained batch 111 in epoch 1, gen_loss = 3.0315511418240413, disc_loss = 0.019360070362121666
Trained batch 112 in epoch 1, gen_loss = 3.029587190763085, disc_loss = 0.019254748169662415
Trained batch 113 in epoch 1, gen_loss = 3.0271140378818178, disc_loss = 0.01913358244571116
Trained batch 114 in epoch 1, gen_loss = 3.0253953498342763, disc_loss = 0.019033228913727013
Trained batch 115 in epoch 1, gen_loss = 3.024862048954799, disc_loss = 0.018913794919077694
Trained batch 116 in epoch 1, gen_loss = 3.02490377629924, disc_loss = 0.018804875234317068
Trained batch 117 in epoch 1, gen_loss = 3.0230693635293995, disc_loss = 0.01869950865363797
Trained batch 118 in epoch 1, gen_loss = 3.0231278343360963, disc_loss = 0.018590648302479702
Trained batch 119 in epoch 1, gen_loss = 3.023874580860138, disc_loss = 0.018476516039421163
Trained batch 120 in epoch 1, gen_loss = 3.025282631235674, disc_loss = 0.018379234204699925
Trained batch 121 in epoch 1, gen_loss = 3.027972670852161, disc_loss = 0.018275161628748794
Trained batch 122 in epoch 1, gen_loss = 3.026769785377068, disc_loss = 0.01816502999802067
Trained batch 123 in epoch 1, gen_loss = 3.0249947578676286, disc_loss = 0.018114981095066235
Trained batch 124 in epoch 1, gen_loss = 3.025783071517944, disc_loss = 0.018067666109651326
Trained batch 125 in epoch 1, gen_loss = 3.024934694880531, disc_loss = 0.017983581556657715
Trained batch 126 in epoch 1, gen_loss = 3.0244874785265585, disc_loss = 0.01788388574715909
Trained batch 127 in epoch 1, gen_loss = 3.0250999610871077, disc_loss = 0.01777572504215641
Trained batch 128 in epoch 1, gen_loss = 3.0233520537383796, disc_loss = 0.01766996066511948
Trained batch 129 in epoch 1, gen_loss = 3.0213137810046855, disc_loss = 0.01756894362445634
Trained batch 130 in epoch 1, gen_loss = 3.0216891783794373, disc_loss = 0.017461079958371307
Trained batch 131 in epoch 1, gen_loss = 3.022503300146623, disc_loss = 0.017355933055196972
Trained batch 132 in epoch 1, gen_loss = 3.0248082096415354, disc_loss = 0.01725670574513033
Trained batch 133 in epoch 1, gen_loss = 3.0216916924092305, disc_loss = 0.017237791690780824
Trained batch 134 in epoch 1, gen_loss = 3.020596504211426, disc_loss = 0.017195294124798643
Trained batch 135 in epoch 1, gen_loss = 3.0160025936715744, disc_loss = 0.017119562592330006
Trained batch 136 in epoch 1, gen_loss = 3.0170106835608936, disc_loss = 0.017036342130035815
Trained batch 137 in epoch 1, gen_loss = 3.016712432322295, disc_loss = 0.01694522372217498
Trained batch 138 in epoch 1, gen_loss = 3.0169506158760124, disc_loss = 0.016855126297061176
Trained batch 139 in epoch 1, gen_loss = 3.0154510055269514, disc_loss = 0.01676960689947009
Trained batch 140 in epoch 1, gen_loss = 3.0140564340226192, disc_loss = 0.016680062398420157
Trained batch 141 in epoch 1, gen_loss = 3.013880089974739, disc_loss = 0.01658820289410126
Trained batch 142 in epoch 1, gen_loss = 3.014158834110607, disc_loss = 0.016505040619131568
Trained batch 143 in epoch 1, gen_loss = 3.0109336525201797, disc_loss = 0.01642775175989502
Trained batch 144 in epoch 1, gen_loss = 3.0139298932305696, disc_loss = 0.016340243609236745
Trained batch 145 in epoch 1, gen_loss = 3.0150955572520215, disc_loss = 0.0162541501507903
Trained batch 146 in epoch 1, gen_loss = 3.014550971336105, disc_loss = 0.016168540118731
Trained batch 147 in epoch 1, gen_loss = 3.014142506831401, disc_loss = 0.016078291898215743
Trained batch 148 in epoch 1, gen_loss = 3.012824784989325, disc_loss = 0.01599983079046411
Trained batch 149 in epoch 1, gen_loss = 3.013975086212158, disc_loss = 0.01591686442028731
Trained batch 150 in epoch 1, gen_loss = 3.0152145363637155, disc_loss = 0.01583698444802388
Trained batch 151 in epoch 1, gen_loss = 3.017957751688204, disc_loss = 0.01575508605118988
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.8205559253692627, disc_loss = 0.00477178767323494
Trained batch 1 in epoch 2, gen_loss = 3.1036999225616455, disc_loss = 0.003861901117488742
Trained batch 2 in epoch 2, gen_loss = 3.1276469230651855, disc_loss = 0.004422364911685388
Trained batch 3 in epoch 2, gen_loss = 3.072772741317749, disc_loss = 0.004455851507373154
Trained batch 4 in epoch 2, gen_loss = 3.0906444072723387, disc_loss = 0.004259881097823381
Trained batch 5 in epoch 2, gen_loss = 3.1218839089075723, disc_loss = 0.004066211481889089
Trained batch 6 in epoch 2, gen_loss = 3.082918405532837, disc_loss = 0.003958880601982985
Trained batch 7 in epoch 2, gen_loss = 3.0606152713298798, disc_loss = 0.0038048044370952994
Trained batch 8 in epoch 2, gen_loss = 3.0399387412601047, disc_loss = 0.003737118457340532
Trained batch 9 in epoch 2, gen_loss = 3.018047404289246, disc_loss = 0.003658444620668888
Trained batch 10 in epoch 2, gen_loss = 3.018422755328092, disc_loss = 0.0036072258160195565
Trained batch 11 in epoch 2, gen_loss = 3.049956500530243, disc_loss = 0.003698941747037073
Trained batch 12 in epoch 2, gen_loss = 3.0186212062835693, disc_loss = 0.0038859168282495095
Trained batch 13 in epoch 2, gen_loss = 3.0198807375771657, disc_loss = 0.004110754766900625
Trained batch 14 in epoch 2, gen_loss = 3.0184874534606934, disc_loss = 0.0043783788569271564
Trained batch 15 in epoch 2, gen_loss = 3.0227614641189575, disc_loss = 0.004713213042123243
Trained batch 16 in epoch 2, gen_loss = 3.024329802569221, disc_loss = 0.005015235202496543
Trained batch 17 in epoch 2, gen_loss = 3.0424421893225775, disc_loss = 0.005146940238773823
Trained batch 18 in epoch 2, gen_loss = 3.028755551890323, disc_loss = 0.005207963532915241
Trained batch 19 in epoch 2, gen_loss = 3.045848476886749, disc_loss = 0.005169586976990104
Trained batch 20 in epoch 2, gen_loss = 3.0499614420391263, disc_loss = 0.00508099410771614
Trained batch 21 in epoch 2, gen_loss = 3.040409651669589, disc_loss = 0.005021618308753453
Trained batch 22 in epoch 2, gen_loss = 3.029217948084292, disc_loss = 0.004967196864764328
Trained batch 23 in epoch 2, gen_loss = 3.042089194059372, disc_loss = 0.004911371467945476
Trained batch 24 in epoch 2, gen_loss = 3.032543077468872, disc_loss = 0.004885435327887535
Trained batch 25 in epoch 2, gen_loss = 3.032335694019611, disc_loss = 0.004793193513670793
Trained batch 26 in epoch 2, gen_loss = 3.021047583332768, disc_loss = 0.004698000382632017
Trained batch 27 in epoch 2, gen_loss = 3.0228616424969266, disc_loss = 0.004626985888795129
Trained batch 28 in epoch 2, gen_loss = 3.025009327921374, disc_loss = 0.004541249472069843
Trained batch 29 in epoch 2, gen_loss = 3.0165368795394896, disc_loss = 0.004500326987666389
Trained batch 30 in epoch 2, gen_loss = 3.02261544043018, disc_loss = 0.004494048287010481
Trained batch 31 in epoch 2, gen_loss = 3.0306725576519966, disc_loss = 0.004474195840884931
Trained batch 32 in epoch 2, gen_loss = 3.023033770647916, disc_loss = 0.004448203482862675
Trained batch 33 in epoch 2, gen_loss = 3.0188728009953216, disc_loss = 0.004414752495529897
Trained batch 34 in epoch 2, gen_loss = 3.018790170124599, disc_loss = 0.004391678176554186
Trained batch 35 in epoch 2, gen_loss = 3.0283002853393555, disc_loss = 0.00434808050825571
Trained batch 36 in epoch 2, gen_loss = 3.0194374677297233, disc_loss = 0.004568288914506903
Trained batch 37 in epoch 2, gen_loss = 3.0097884504418624, disc_loss = 0.0056742981235545715
Trained batch 38 in epoch 2, gen_loss = 3.025878539452186, disc_loss = 0.0069832306605978655
Trained batch 39 in epoch 2, gen_loss = 3.016852605342865, disc_loss = 0.007066004915395751
Trained batch 40 in epoch 2, gen_loss = 3.022249279952631, disc_loss = 0.007292071408478588
Trained batch 41 in epoch 2, gen_loss = 3.023495736576262, disc_loss = 0.007403043148640011
Trained batch 42 in epoch 2, gen_loss = 3.022334154262099, disc_loss = 0.007404367055007538
Trained batch 43 in epoch 2, gen_loss = 3.0270819501443342, disc_loss = 0.007377545365174724
Trained batch 44 in epoch 2, gen_loss = 3.020298873053657, disc_loss = 0.00750535657732851
Trained batch 45 in epoch 2, gen_loss = 3.0165347534677256, disc_loss = 0.007642133783994485
Trained batch 46 in epoch 2, gen_loss = 3.017849658397918, disc_loss = 0.007683614957483208
Trained batch 47 in epoch 2, gen_loss = 3.02059169113636, disc_loss = 0.007831959999748506
Trained batch 48 in epoch 2, gen_loss = 3.0304230670539702, disc_loss = 0.007887804172743035
Trained batch 49 in epoch 2, gen_loss = 3.0252282190322877, disc_loss = 0.007887841309420765
Trained batch 50 in epoch 2, gen_loss = 3.0239151552611707, disc_loss = 0.007814907509943141
Trained batch 51 in epoch 2, gen_loss = 3.020078773681934, disc_loss = 0.0077258342375548985
Trained batch 52 in epoch 2, gen_loss = 3.028730756831619, disc_loss = 0.007685807849860417
Trained batch 53 in epoch 2, gen_loss = 3.025333320652997, disc_loss = 0.007686109454543503
Trained batch 54 in epoch 2, gen_loss = 3.023243149844083, disc_loss = 0.007672331008044156
Trained batch 55 in epoch 2, gen_loss = 3.0234528865133012, disc_loss = 0.0076170759940786025
Trained batch 56 in epoch 2, gen_loss = 3.0220495023225484, disc_loss = 0.007589007155937061
Trained batch 57 in epoch 2, gen_loss = 3.0193332803660424, disc_loss = 0.007577997511895052
Trained batch 58 in epoch 2, gen_loss = 3.0139199071011302, disc_loss = 0.007578046416263964
Trained batch 59 in epoch 2, gen_loss = 3.0063371539115904, disc_loss = 0.007590066633808116
Trained batch 60 in epoch 2, gen_loss = 3.0084601542988763, disc_loss = 0.007544732270915
Trained batch 61 in epoch 2, gen_loss = 3.003218666199715, disc_loss = 0.007467418916583542
Trained batch 62 in epoch 2, gen_loss = 3.004839639815073, disc_loss = 0.007402919255019654
Trained batch 63 in epoch 2, gen_loss = 3.0060871839523315, disc_loss = 0.007320311735384166
Trained batch 64 in epoch 2, gen_loss = 3.0081264972686768, disc_loss = 0.007250216424178619
Trained batch 65 in epoch 2, gen_loss = 3.009886134754528, disc_loss = 0.007178326320806236
Trained batch 66 in epoch 2, gen_loss = 3.0071866334374273, disc_loss = 0.007150908250973296
Trained batch 67 in epoch 2, gen_loss = 3.007140766171848, disc_loss = 0.00715116916142185
Trained batch 68 in epoch 2, gen_loss = 3.013825990151668, disc_loss = 0.007162763919357372
Trained batch 69 in epoch 2, gen_loss = 3.017277618816921, disc_loss = 0.00711068272191499
Trained batch 70 in epoch 2, gen_loss = 3.0139752609629027, disc_loss = 0.0070738950941029565
Trained batch 71 in epoch 2, gen_loss = 3.0120465424325733, disc_loss = 0.007025503779813234
Trained batch 72 in epoch 2, gen_loss = 3.0146763553358102, disc_loss = 0.006980319695598255
Trained batch 73 in epoch 2, gen_loss = 3.021357220572394, disc_loss = 0.0069423275464843654
Trained batch 74 in epoch 2, gen_loss = 3.0254612223307293, disc_loss = 0.006897843470796943
Trained batch 75 in epoch 2, gen_loss = 3.02707134422503, disc_loss = 0.006850658722932597
Trained batch 76 in epoch 2, gen_loss = 3.0254492511996975, disc_loss = 0.006833807761817203
Trained batch 77 in epoch 2, gen_loss = 3.029462533119397, disc_loss = 0.006820690236054361
Trained batch 78 in epoch 2, gen_loss = 3.031226634979248, disc_loss = 0.006779898742001645
Trained batch 79 in epoch 2, gen_loss = 3.0302838891744615, disc_loss = 0.006726363516645506
Trained batch 80 in epoch 2, gen_loss = 3.0317593651053345, disc_loss = 0.006680685716370742
Trained batch 81 in epoch 2, gen_loss = 3.036216221204618, disc_loss = 0.00663212156377551
Trained batch 82 in epoch 2, gen_loss = 3.0342512360538345, disc_loss = 0.006603496267000236
Trained batch 83 in epoch 2, gen_loss = 3.0334912708827426, disc_loss = 0.006585784095694267
Trained batch 84 in epoch 2, gen_loss = 3.0355265112484204, disc_loss = 0.006547757509328863
Trained batch 85 in epoch 2, gen_loss = 3.034282390461412, disc_loss = 0.00650746802810233
Trained batch 86 in epoch 2, gen_loss = 3.038390825534689, disc_loss = 0.006459877973465228
Trained batch 87 in epoch 2, gen_loss = 3.040564187548377, disc_loss = 0.006418826129943641
Trained batch 88 in epoch 2, gen_loss = 3.0420427134867465, disc_loss = 0.0063792275437520125
Trained batch 89 in epoch 2, gen_loss = 3.0417344358232286, disc_loss = 0.006341729072543482
Trained batch 90 in epoch 2, gen_loss = 3.039768771810846, disc_loss = 0.0063009487572484296
Trained batch 91 in epoch 2, gen_loss = 3.0403050521145696, disc_loss = 0.006252372908183252
Trained batch 92 in epoch 2, gen_loss = 3.0391624819847847, disc_loss = 0.006215042639924314
Trained batch 93 in epoch 2, gen_loss = 3.03580082731044, disc_loss = 0.006180677478736702
Trained batch 94 in epoch 2, gen_loss = 3.032770151841013, disc_loss = 0.006147415041433353
Trained batch 95 in epoch 2, gen_loss = 3.0315858870744705, disc_loss = 0.0061292127187092165
Trained batch 96 in epoch 2, gen_loss = 3.034785329681082, disc_loss = 0.006144835443245535
Trained batch 97 in epoch 2, gen_loss = 3.03956831961262, disc_loss = 0.006121766720233219
Trained batch 98 in epoch 2, gen_loss = 3.040079880242396, disc_loss = 0.00610826269375405
Trained batch 99 in epoch 2, gen_loss = 3.038738718032837, disc_loss = 0.0061229248018935326
Trained batch 100 in epoch 2, gen_loss = 3.034874498254002, disc_loss = 0.006151145052091025
Trained batch 101 in epoch 2, gen_loss = 3.037763107056711, disc_loss = 0.0062639183940037205
Trained batch 102 in epoch 2, gen_loss = 3.0357797655087073, disc_loss = 0.006383201618253896
Trained batch 103 in epoch 2, gen_loss = 3.0347782373428345, disc_loss = 0.0064904603507154835
Trained batch 104 in epoch 2, gen_loss = 3.032257114137922, disc_loss = 0.0065556878534456095
Trained batch 105 in epoch 2, gen_loss = 3.0327251407335387, disc_loss = 0.006552827373182155
Trained batch 106 in epoch 2, gen_loss = 3.032243699670952, disc_loss = 0.006520916150760985
Trained batch 107 in epoch 2, gen_loss = 3.0313487428205983, disc_loss = 0.00648104264487133
Trained batch 108 in epoch 2, gen_loss = 3.0299366526647447, disc_loss = 0.006448179395835197
Trained batch 109 in epoch 2, gen_loss = 3.030496486750516, disc_loss = 0.006411057619631968
Trained batch 110 in epoch 2, gen_loss = 3.0339651644766867, disc_loss = 0.006370202524939904
Trained batch 111 in epoch 2, gen_loss = 3.033862137368747, disc_loss = 0.006329014771576372
Trained batch 112 in epoch 2, gen_loss = 3.0339903493898106, disc_loss = 0.006290367566485914
Trained batch 113 in epoch 2, gen_loss = 3.0355054683852614, disc_loss = 0.006248652046595357
Trained batch 114 in epoch 2, gen_loss = 3.0346891610518747, disc_loss = 0.006216827741540644
Trained batch 115 in epoch 2, gen_loss = 3.0341951127710014, disc_loss = 0.006184699248667036
Trained batch 116 in epoch 2, gen_loss = 3.033825362849439, disc_loss = 0.006150233433940089
Trained batch 117 in epoch 2, gen_loss = 3.0336522975210416, disc_loss = 0.00611464239724012
Trained batch 118 in epoch 2, gen_loss = 3.032961428666315, disc_loss = 0.006078786767447884
Trained batch 119 in epoch 2, gen_loss = 3.031372288862864, disc_loss = 0.0060427582143650705
Trained batch 120 in epoch 2, gen_loss = 3.0293181119871533, disc_loss = 0.00601579752088763
Trained batch 121 in epoch 2, gen_loss = 3.0260522717335183, disc_loss = 0.005989625257989544
Trained batch 122 in epoch 2, gen_loss = 3.0238059613762833, disc_loss = 0.00597000173936651
Trained batch 123 in epoch 2, gen_loss = 3.023305396879873, disc_loss = 0.005950955058177633
Trained batch 124 in epoch 2, gen_loss = 3.022402359008789, disc_loss = 0.0059141881447285416
Trained batch 125 in epoch 2, gen_loss = 3.026441558958992, disc_loss = 0.005881936575788709
Trained batch 126 in epoch 2, gen_loss = 3.026126305888018, disc_loss = 0.005849955032403603
Trained batch 127 in epoch 2, gen_loss = 3.0256391931325197, disc_loss = 0.005818610994538176
Trained batch 128 in epoch 2, gen_loss = 3.0273362037747407, disc_loss = 0.005798686416675301
Trained batch 129 in epoch 2, gen_loss = 3.025654831299415, disc_loss = 0.00578183032428989
Trained batch 130 in epoch 2, gen_loss = 3.02385829605219, disc_loss = 0.005778002119018831
Trained batch 131 in epoch 2, gen_loss = 3.0244741855245647, disc_loss = 0.005759101496854176
Trained batch 132 in epoch 2, gen_loss = 3.0221036018285536, disc_loss = 0.005754403869754502
Trained batch 133 in epoch 2, gen_loss = 3.0193378925323486, disc_loss = 0.005762206614643002
Trained batch 134 in epoch 2, gen_loss = 3.0206659422980415, disc_loss = 0.005791217987253158
Trained batch 135 in epoch 2, gen_loss = 3.018736504456576, disc_loss = 0.00585571608869085
Trained batch 136 in epoch 2, gen_loss = 3.017389619437447, disc_loss = 0.006293156267531271
Trained batch 137 in epoch 2, gen_loss = 3.0090890829113945, disc_loss = 0.00861844720919549
Trained batch 138 in epoch 2, gen_loss = 3.016505556998493, disc_loss = 0.012830175923371165
Trained batch 139 in epoch 2, gen_loss = 3.0158009120396208, disc_loss = 0.013673021413186298
Trained batch 140 in epoch 2, gen_loss = 3.015093967424217, disc_loss = 0.014587828329704861
Trained batch 141 in epoch 2, gen_loss = 3.0103843195337645, disc_loss = 0.015249494340231406
Trained batch 142 in epoch 2, gen_loss = 3.0066853569937755, disc_loss = 0.015730256261955296
Trained batch 143 in epoch 2, gen_loss = 3.003856481777297, disc_loss = 0.01613628086407617
Trained batch 144 in epoch 2, gen_loss = 3.0029936445170438, disc_loss = 0.01677109376398911
Trained batch 145 in epoch 2, gen_loss = 3.001763242564789, disc_loss = 0.01760192086110019
Trained batch 146 in epoch 2, gen_loss = 3.0009390172504244, disc_loss = 0.018603828724562413
Trained batch 147 in epoch 2, gen_loss = 3.0005318925187394, disc_loss = 0.019518040355005477
Trained batch 148 in epoch 2, gen_loss = 2.9983706218284247, disc_loss = 0.020162770394923403
Trained batch 149 in epoch 2, gen_loss = 2.9967452589670818, disc_loss = 0.02043996242961536
Trained batch 150 in epoch 2, gen_loss = 2.998460693864633, disc_loss = 0.02061451360466119
Trained batch 151 in epoch 2, gen_loss = 3.002392003410741, disc_loss = 0.02130033365775537
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.4788830280303955, disc_loss = 0.23618297278881073
Trained batch 1 in epoch 3, gen_loss = 3.2355650663375854, disc_loss = 0.22166449576616287
Trained batch 2 in epoch 3, gen_loss = 3.1290948390960693, disc_loss = 0.16441250095764795
Trained batch 3 in epoch 3, gen_loss = 3.0615475177764893, disc_loss = 0.14910641685128212
Trained batch 4 in epoch 3, gen_loss = 3.090224599838257, disc_loss = 0.14786151945590972
Trained batch 5 in epoch 3, gen_loss = 3.149727781613668, disc_loss = 0.14670350402593613
Trained batch 6 in epoch 3, gen_loss = 3.1371597221919467, disc_loss = 0.12992357781955174
Trained batch 7 in epoch 3, gen_loss = 3.1339375376701355, disc_loss = 0.1166545101441443
Trained batch 8 in epoch 3, gen_loss = 3.110010200076633, disc_loss = 0.10498291937013467
Trained batch 9 in epoch 3, gen_loss = 3.114015507698059, disc_loss = 0.09555914662778378
Trained batch 10 in epoch 3, gen_loss = 3.1140106374567207, disc_loss = 0.0874305684119463
Trained batch 11 in epoch 3, gen_loss = 3.112294356028239, disc_loss = 0.08075565305383255
Trained batch 12 in epoch 3, gen_loss = 3.1163404904879055, disc_loss = 0.07494285369578463
Trained batch 13 in epoch 3, gen_loss = 3.1115024941308156, disc_loss = 0.07011369286504175
Trained batch 14 in epoch 3, gen_loss = 3.0978289604187013, disc_loss = 0.06580711842204133
Trained batch 15 in epoch 3, gen_loss = 3.1106456518173218, disc_loss = 0.06204023424652405
Trained batch 16 in epoch 3, gen_loss = 3.1123265799354103, disc_loss = 0.0586783993331825
Trained batch 17 in epoch 3, gen_loss = 3.107364786995782, disc_loss = 0.055717070716329746
Trained batch 18 in epoch 3, gen_loss = 3.108635300084164, disc_loss = 0.05303213644870802
Trained batch 19 in epoch 3, gen_loss = 3.097089695930481, disc_loss = 0.05107992410194129
Trained batch 20 in epoch 3, gen_loss = 3.0914529845828103, disc_loss = 0.04921979716579829
Trained batch 21 in epoch 3, gen_loss = 3.091444123875011, disc_loss = 0.04750377614982426
Trained batch 22 in epoch 3, gen_loss = 3.088589212168818, disc_loss = 0.045878637723786676
Trained batch 23 in epoch 3, gen_loss = 3.0859397649765015, disc_loss = 0.04415818728739396
Trained batch 24 in epoch 3, gen_loss = 3.0832080078125, disc_loss = 0.04254064909182489
Trained batch 25 in epoch 3, gen_loss = 3.0726471680861254, disc_loss = 0.04104866720556926
Trained batch 26 in epoch 3, gen_loss = 3.0671379301283093, disc_loss = 0.03965166067980506
Trained batch 27 in epoch 3, gen_loss = 3.048525393009186, disc_loss = 0.03901588652349476
Trained batch 28 in epoch 3, gen_loss = 3.040119935726297, disc_loss = 0.038311266581174626
Trained batch 29 in epoch 3, gen_loss = 3.0368460257848104, disc_loss = 0.03721655801249047
Trained batch 30 in epoch 3, gen_loss = 3.0446027632682555, disc_loss = 0.036195354115578435
Trained batch 31 in epoch 3, gen_loss = 3.040979579091072, disc_loss = 0.03518313323002076
Trained batch 32 in epoch 3, gen_loss = 3.0360659758249917, disc_loss = 0.034250610529191115
Trained batch 33 in epoch 3, gen_loss = 3.030063846532036, disc_loss = 0.033351156655151176
Trained batch 34 in epoch 3, gen_loss = 3.038622842516218, disc_loss = 0.03251369615484561
Trained batch 35 in epoch 3, gen_loss = 3.0357042484813266, disc_loss = 0.03176816269600143
Trained batch 36 in epoch 3, gen_loss = 3.038502416095218, disc_loss = 0.031048187444842345
Trained batch 37 in epoch 3, gen_loss = 3.0383236972909224, disc_loss = 0.030352212292583364
Trained batch 38 in epoch 3, gen_loss = 3.03622729350359, disc_loss = 0.029678360869487126
Trained batch 39 in epoch 3, gen_loss = 3.0269673645496367, disc_loss = 0.02907121441094205
Trained batch 40 in epoch 3, gen_loss = 3.0291697688219026, disc_loss = 0.02848965477016641
Trained batch 41 in epoch 3, gen_loss = 3.0220605702627275, disc_loss = 0.02789944160308334
Trained batch 42 in epoch 3, gen_loss = 3.024923884591391, disc_loss = 0.027341588091668347
Trained batch 43 in epoch 3, gen_loss = 3.030580661513589, disc_loss = 0.026810314310502938
Trained batch 44 in epoch 3, gen_loss = 3.0349407725863986, disc_loss = 0.026278130642862784
Trained batch 45 in epoch 3, gen_loss = 3.0321644389111064, disc_loss = 0.02577528509858024
Trained batch 46 in epoch 3, gen_loss = 3.035611314976469, disc_loss = 0.025342585741879142
Trained batch 47 in epoch 3, gen_loss = 3.0419926792383194, disc_loss = 0.02494315201086768
Trained batch 48 in epoch 3, gen_loss = 3.044471482841336, disc_loss = 0.024537905266660512
Trained batch 49 in epoch 3, gen_loss = 3.0422187995910646, disc_loss = 0.024161819978617133
Trained batch 50 in epoch 3, gen_loss = 3.0372817937065575, disc_loss = 0.02376769371239432
Trained batch 51 in epoch 3, gen_loss = 3.0341102068240824, disc_loss = 0.023412461065723058
Trained batch 52 in epoch 3, gen_loss = 3.0311413980879873, disc_loss = 0.02305808768361666
Trained batch 53 in epoch 3, gen_loss = 3.0304045765488237, disc_loss = 0.0227026394913318
Trained batch 54 in epoch 3, gen_loss = 3.0332975777712736, disc_loss = 0.022365921947427772
Trained batch 55 in epoch 3, gen_loss = 3.03569923554148, disc_loss = 0.022026438931269304
Trained batch 56 in epoch 3, gen_loss = 3.027480276007401, disc_loss = 0.02170433232707805
Trained batch 57 in epoch 3, gen_loss = 3.0307398417900346, disc_loss = 0.02144105038364771
Trained batch 58 in epoch 3, gen_loss = 3.029573367813886, disc_loss = 0.02112671029280429
Trained batch 59 in epoch 3, gen_loss = 3.0393694480260214, disc_loss = 0.020822883614649377
Trained batch 60 in epoch 3, gen_loss = 3.041691002298574, disc_loss = 0.02054692096397525
Trained batch 61 in epoch 3, gen_loss = 3.042942443201619, disc_loss = 0.02026815756764864
Trained batch 62 in epoch 3, gen_loss = 3.0424466246650335, disc_loss = 0.019983353159789528
Trained batch 63 in epoch 3, gen_loss = 3.035521984100342, disc_loss = 0.019734841022000182
Trained batch 64 in epoch 3, gen_loss = 3.035414875470675, disc_loss = 0.019512619028011192
Trained batch 65 in epoch 3, gen_loss = 3.039169708887736, disc_loss = 0.01926480945213839
Trained batch 66 in epoch 3, gen_loss = 3.0378371637258956, disc_loss = 0.019016865752081374
Trained batch 67 in epoch 3, gen_loss = 3.0382728892214157, disc_loss = 0.018788107708507383
Trained batch 68 in epoch 3, gen_loss = 3.037281571954921, disc_loss = 0.01856399126742305
Trained batch 69 in epoch 3, gen_loss = 3.042174243927002, disc_loss = 0.018336157953100545
Trained batch 70 in epoch 3, gen_loss = 3.041987462782524, disc_loss = 0.01811477991844147
Trained batch 71 in epoch 3, gen_loss = 3.0372853643364377, disc_loss = 0.01793762741403447
Trained batch 72 in epoch 3, gen_loss = 3.0363137395414586, disc_loss = 0.017772777650301178
Trained batch 73 in epoch 3, gen_loss = 3.0326759493028796, disc_loss = 0.017579652715121973
Trained batch 74 in epoch 3, gen_loss = 3.030773944854736, disc_loss = 0.017415875351677337
Trained batch 75 in epoch 3, gen_loss = 3.0327005198127344, disc_loss = 0.01725856340367739
Trained batch 76 in epoch 3, gen_loss = 3.0312863758632114, disc_loss = 0.017108761832456697
Trained batch 77 in epoch 3, gen_loss = 3.0294304352540236, disc_loss = 0.01695799977423098
Trained batch 78 in epoch 3, gen_loss = 3.0293334043478666, disc_loss = 0.01679549537764131
Trained batch 79 in epoch 3, gen_loss = 3.027008053660393, disc_loss = 0.016616873219027183
Trained batch 80 in epoch 3, gen_loss = 3.0222112749829706, disc_loss = 0.01647004280756745
Trained batch 81 in epoch 3, gen_loss = 3.0214577738831685, disc_loss = 0.016323059232246768
Trained batch 82 in epoch 3, gen_loss = 3.0194642371441947, disc_loss = 0.016174697617338186
Trained batch 83 in epoch 3, gen_loss = 3.0198578238487244, disc_loss = 0.016037111982725383
Trained batch 84 in epoch 3, gen_loss = 3.0194897006539736, disc_loss = 0.015875633940210236
Trained batch 85 in epoch 3, gen_loss = 3.0169449989185777, disc_loss = 0.01572016553498458
Trained batch 86 in epoch 3, gen_loss = 3.019224358701158, disc_loss = 0.015562833966580272
Trained batch 87 in epoch 3, gen_loss = 3.019767690788616, disc_loss = 0.015406107666256668
Trained batch 88 in epoch 3, gen_loss = 3.0239174017745456, disc_loss = 0.015254550618695075
Trained batch 89 in epoch 3, gen_loss = 3.0233902242448596, disc_loss = 0.015121138918523987
Trained batch 90 in epoch 3, gen_loss = 3.0207462913387424, disc_loss = 0.014973261003423442
Trained batch 91 in epoch 3, gen_loss = 3.017594946467358, disc_loss = 0.014833651967700976
Trained batch 92 in epoch 3, gen_loss = 3.0207937635401243, disc_loss = 0.014696574398136188
Trained batch 93 in epoch 3, gen_loss = 3.023487032727992, disc_loss = 0.014567531733228726
Trained batch 94 in epoch 3, gen_loss = 3.021929909053602, disc_loss = 0.0144420675479954
Trained batch 95 in epoch 3, gen_loss = 3.0195484086871147, disc_loss = 0.014314783975957349
Trained batch 96 in epoch 3, gen_loss = 3.021238597397952, disc_loss = 0.014190413824705043
Trained batch 97 in epoch 3, gen_loss = 3.022063581310973, disc_loss = 0.014060107274788755
Trained batch 98 in epoch 3, gen_loss = 3.0236464895383275, disc_loss = 0.013942294915187916
Trained batch 99 in epoch 3, gen_loss = 3.022127802371979, disc_loss = 0.0138394843286369
Trained batch 100 in epoch 3, gen_loss = 3.0212381830309876, disc_loss = 0.013728010536189938
Trained batch 101 in epoch 3, gen_loss = 3.0215825356689154, disc_loss = 0.01361727363808884
Trained batch 102 in epoch 3, gen_loss = 3.018713152524337, disc_loss = 0.013506937291681115
Trained batch 103 in epoch 3, gen_loss = 3.0191296224410715, disc_loss = 0.013394594212653689
Trained batch 104 in epoch 3, gen_loss = 3.0177558149610246, disc_loss = 0.013284376274705642
Trained batch 105 in epoch 3, gen_loss = 3.0160777816232645, disc_loss = 0.01317451522083742
Trained batch 106 in epoch 3, gen_loss = 3.0182440927095504, disc_loss = 0.013064580162221166
Trained batch 107 in epoch 3, gen_loss = 3.0180504277900413, disc_loss = 0.012960660056840559
Trained batch 108 in epoch 3, gen_loss = 3.0150735859477193, disc_loss = 0.012858847537453911
Trained batch 109 in epoch 3, gen_loss = 3.016994461146268, disc_loss = 0.012765974266750907
Trained batch 110 in epoch 3, gen_loss = 3.016002051465146, disc_loss = 0.012680381539630125
Trained batch 111 in epoch 3, gen_loss = 3.0197697473423823, disc_loss = 0.012594539301062468
Trained batch 112 in epoch 3, gen_loss = 3.017339843564329, disc_loss = 0.012511875384602597
Trained batch 113 in epoch 3, gen_loss = 3.0198680350655005, disc_loss = 0.012420113264836306
Trained batch 114 in epoch 3, gen_loss = 3.019704433109449, disc_loss = 0.012329409005241874
Trained batch 115 in epoch 3, gen_loss = 3.0219144903380295, disc_loss = 0.0122435488206222
Trained batch 116 in epoch 3, gen_loss = 3.0209491680829954, disc_loss = 0.012164164452940926
Trained batch 117 in epoch 3, gen_loss = 3.0202611745414085, disc_loss = 0.01208165300106314
Trained batch 118 in epoch 3, gen_loss = 3.0220158400655794, disc_loss = 0.011996251678665583
Trained batch 119 in epoch 3, gen_loss = 3.0229981462160747, disc_loss = 0.011908774736609
Trained batch 120 in epoch 3, gen_loss = 3.0228679140737236, disc_loss = 0.011827704867094078
Trained batch 121 in epoch 3, gen_loss = 3.022027267784369, disc_loss = 0.011753613786718457
Trained batch 122 in epoch 3, gen_loss = 3.024724801381429, disc_loss = 0.011686048363486865
Trained batch 123 in epoch 3, gen_loss = 3.025124213387889, disc_loss = 0.011619035390228214
Trained batch 124 in epoch 3, gen_loss = 3.026190414428711, disc_loss = 0.011546345385722816
Trained batch 125 in epoch 3, gen_loss = 3.025597227944268, disc_loss = 0.011478666429563114
Trained batch 126 in epoch 3, gen_loss = 3.026388787847804, disc_loss = 0.011403337158592725
Trained batch 127 in epoch 3, gen_loss = 3.0262655690312386, disc_loss = 0.01133562651284592
Trained batch 128 in epoch 3, gen_loss = 3.024727697520293, disc_loss = 0.011266412273908481
Trained batch 129 in epoch 3, gen_loss = 3.025583474452679, disc_loss = 0.011191668838728219
Trained batch 130 in epoch 3, gen_loss = 3.0258255186881726, disc_loss = 0.011121009022374246
Trained batch 131 in epoch 3, gen_loss = 3.028137611620354, disc_loss = 0.011051294135430715
Trained batch 132 in epoch 3, gen_loss = 3.0271482144979607, disc_loss = 0.010981938053321625
Trained batch 133 in epoch 3, gen_loss = 3.0253871554759013, disc_loss = 0.010917306082747154
Trained batch 134 in epoch 3, gen_loss = 3.0238310619636817, disc_loss = 0.0108600140368152
Trained batch 135 in epoch 3, gen_loss = 3.0246088960591484, disc_loss = 0.010804816506125088
Trained batch 136 in epoch 3, gen_loss = 3.0253520394763807, disc_loss = 0.01074403537399931
Trained batch 137 in epoch 3, gen_loss = 3.0257612155831377, disc_loss = 0.010701263047572549
Trained batch 138 in epoch 3, gen_loss = 3.0241965424242636, disc_loss = 0.010692935042491974
Trained batch 139 in epoch 3, gen_loss = 3.0236208319664, disc_loss = 0.010836135270905548
Trained batch 140 in epoch 3, gen_loss = 3.0239659995897443, disc_loss = 0.01133568700591221
Trained batch 141 in epoch 3, gen_loss = 3.0226621426327127, disc_loss = 0.011664655552291587
Trained batch 142 in epoch 3, gen_loss = 3.0222340263686815, disc_loss = 0.011686292119565178
Trained batch 143 in epoch 3, gen_loss = 3.022029002507528, disc_loss = 0.011675846828438807
Trained batch 144 in epoch 3, gen_loss = 3.0208898840279415, disc_loss = 0.011628458347845951
Trained batch 145 in epoch 3, gen_loss = 3.018632859399874, disc_loss = 0.01157114373867668
Trained batch 146 in epoch 3, gen_loss = 3.0177697129801015, disc_loss = 0.011522045410491627
Trained batch 147 in epoch 3, gen_loss = 3.014901207911002, disc_loss = 0.011459987554730646
Trained batch 148 in epoch 3, gen_loss = 3.014846654546341, disc_loss = 0.011395391032268488
Trained batch 149 in epoch 3, gen_loss = 3.014469165802002, disc_loss = 0.011336449368391186
Trained batch 150 in epoch 3, gen_loss = 3.0141802260417814, disc_loss = 0.01127741659377757
Trained batch 151 in epoch 3, gen_loss = 3.0127084647354327, disc_loss = 0.011215857188002892
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 3.3198044300079346, disc_loss = 0.001825828803703189
Trained batch 1 in epoch 4, gen_loss = 3.0872799158096313, disc_loss = 0.0017390334978699684
Trained batch 2 in epoch 4, gen_loss = 2.9952046871185303, disc_loss = 0.0019759145410110555
Trained batch 3 in epoch 4, gen_loss = 2.984370529651642, disc_loss = 0.0019332361407577991
Trained batch 4 in epoch 4, gen_loss = 2.98246111869812, disc_loss = 0.001850447175092995
Trained batch 5 in epoch 4, gen_loss = 3.0284913778305054, disc_loss = 0.001749059670449545
Trained batch 6 in epoch 4, gen_loss = 2.9986798763275146, disc_loss = 0.0018446467583999038
Trained batch 7 in epoch 4, gen_loss = 2.97241747379303, disc_loss = 0.001849789623520337
Trained batch 8 in epoch 4, gen_loss = 2.986169179280599, disc_loss = 0.001953089907247987
Trained batch 9 in epoch 4, gen_loss = 3.006101703643799, disc_loss = 0.0018932240549474955
Trained batch 10 in epoch 4, gen_loss = 3.006436001170765, disc_loss = 0.001964560667560859
Trained batch 11 in epoch 4, gen_loss = 2.9907883604367576, disc_loss = 0.0019367003405932337
Trained batch 12 in epoch 4, gen_loss = 2.9867477600391092, disc_loss = 0.0019286762331970609
Trained batch 13 in epoch 4, gen_loss = 2.956961444446019, disc_loss = 0.002030329703952053
Trained batch 14 in epoch 4, gen_loss = 2.9640098253885907, disc_loss = 0.0020697615342214703
Trained batch 15 in epoch 4, gen_loss = 2.963173985481262, disc_loss = 0.0020757797537953593
Trained batch 16 in epoch 4, gen_loss = 2.961683511734009, disc_loss = 0.002135794233147274
Trained batch 17 in epoch 4, gen_loss = 2.9536779854032726, disc_loss = 0.0021372131240140232
Trained batch 18 in epoch 4, gen_loss = 2.963963420767533, disc_loss = 0.0021360614153213405
Trained batch 19 in epoch 4, gen_loss = 2.9642264246940613, disc_loss = 0.0022642998315859585
Trained batch 20 in epoch 4, gen_loss = 2.972424790972755, disc_loss = 0.002371782353813095
Trained batch 21 in epoch 4, gen_loss = 2.9659969698299062, disc_loss = 0.0024075748832811687
Trained batch 22 in epoch 4, gen_loss = 2.968240437300309, disc_loss = 0.00240691132215864
Trained batch 23 in epoch 4, gen_loss = 2.9717652201652527, disc_loss = 0.002464586010319181
Trained batch 24 in epoch 4, gen_loss = 2.9634917736053468, disc_loss = 0.0027256954042240975
Trained batch 25 in epoch 4, gen_loss = 2.9615365175100474, disc_loss = 0.002924555155914277
Trained batch 26 in epoch 4, gen_loss = 2.9581315958941423, disc_loss = 0.0029609389560021184
Trained batch 27 in epoch 4, gen_loss = 2.9625857727868214, disc_loss = 0.0029855679645801763
Trained batch 28 in epoch 4, gen_loss = 2.9692377715275207, disc_loss = 0.0029550404247731484
Trained batch 29 in epoch 4, gen_loss = 2.973431595166524, disc_loss = 0.0029414955177344384
Trained batch 30 in epoch 4, gen_loss = 2.971786445186984, disc_loss = 0.0029163524065346966
Trained batch 31 in epoch 4, gen_loss = 2.966446675360203, disc_loss = 0.002881184278521687
Trained batch 32 in epoch 4, gen_loss = 2.9688746495680376, disc_loss = 0.002834917236627503
Trained batch 33 in epoch 4, gen_loss = 2.97277210039251, disc_loss = 0.00280309612999725
Trained batch 34 in epoch 4, gen_loss = 2.963273048400879, disc_loss = 0.002855560070435916
Trained batch 35 in epoch 4, gen_loss = 2.9698407583766513, disc_loss = 0.002841843330922226
Trained batch 36 in epoch 4, gen_loss = 2.967586208034206, disc_loss = 0.002821085143935036
Trained batch 37 in epoch 4, gen_loss = 2.959477110912925, disc_loss = 0.0028348890390541208
Trained batch 38 in epoch 4, gen_loss = 2.959839869768192, disc_loss = 0.00283537089275435
Trained batch 39 in epoch 4, gen_loss = 2.953423672914505, disc_loss = 0.0028217944083735345
Trained batch 40 in epoch 4, gen_loss = 2.9569151052614537, disc_loss = 0.0027989823734614907
Trained batch 41 in epoch 4, gen_loss = 2.9573699235916138, disc_loss = 0.002809536343972598
Trained batch 42 in epoch 4, gen_loss = 2.958166710166044, disc_loss = 0.0027989095271846584
Trained batch 43 in epoch 4, gen_loss = 2.9591388160532173, disc_loss = 0.002767375530145893
Trained batch 44 in epoch 4, gen_loss = 2.955429119533963, disc_loss = 0.0027321983672057588
Trained batch 45 in epoch 4, gen_loss = 2.9602756396583887, disc_loss = 0.00270186509663725
Trained batch 46 in epoch 4, gen_loss = 2.965077319043748, disc_loss = 0.002675942861118374
Trained batch 47 in epoch 4, gen_loss = 2.967170079549154, disc_loss = 0.0026610185183623494
Trained batch 48 in epoch 4, gen_loss = 2.9680629506403085, disc_loss = 0.0027856171839129255
Trained batch 49 in epoch 4, gen_loss = 2.9663561964035035, disc_loss = 0.0029006215394474567
Trained batch 50 in epoch 4, gen_loss = 2.96998267547757, disc_loss = 0.0030040404069986123
Trained batch 51 in epoch 4, gen_loss = 2.963455626597771, disc_loss = 0.0031420221717920727
Trained batch 52 in epoch 4, gen_loss = 2.9677880530087455, disc_loss = 0.00323460506108361
Trained batch 53 in epoch 4, gen_loss = 2.9639906883239746, disc_loss = 0.0032336547802616325
Trained batch 54 in epoch 4, gen_loss = 2.9723928928375245, disc_loss = 0.0032089499037035486
Trained batch 55 in epoch 4, gen_loss = 2.9719412326812744, disc_loss = 0.0031732909181820495
Trained batch 56 in epoch 4, gen_loss = 2.9647414767951297, disc_loss = 0.0031560263923254973
Trained batch 57 in epoch 4, gen_loss = 2.966136936483712, disc_loss = 0.0031414359551051566
Trained batch 58 in epoch 4, gen_loss = 2.9632178686432917, disc_loss = 0.003148204422066525
Trained batch 59 in epoch 4, gen_loss = 2.962482766310374, disc_loss = 0.003148906286029766
Trained batch 60 in epoch 4, gen_loss = 2.963438338920718, disc_loss = 0.0031316660909501254
Trained batch 61 in epoch 4, gen_loss = 2.9635019225458943, disc_loss = 0.003104044124484062
Trained batch 62 in epoch 4, gen_loss = 2.9637257106720454, disc_loss = 0.0030855550707894423
Trained batch 63 in epoch 4, gen_loss = 2.9657117761671543, disc_loss = 0.0030599325818911893
Trained batch 64 in epoch 4, gen_loss = 2.965877004770132, disc_loss = 0.00303674317860546
Trained batch 65 in epoch 4, gen_loss = 2.9645204255075166, disc_loss = 0.003022013371457543
Trained batch 66 in epoch 4, gen_loss = 2.966632259425832, disc_loss = 0.003003541637323241
Trained batch 67 in epoch 4, gen_loss = 2.967549534404979, disc_loss = 0.002972443331279518
Trained batch 68 in epoch 4, gen_loss = 2.9683222839797754, disc_loss = 0.002938752464167234
Trained batch 69 in epoch 4, gen_loss = 2.9681191648755756, disc_loss = 0.0029118597474215285
Trained batch 70 in epoch 4, gen_loss = 2.9681262164048747, disc_loss = 0.002887548285234772
Trained batch 71 in epoch 4, gen_loss = 2.9699824485513897, disc_loss = 0.0028616489418911645
Trained batch 72 in epoch 4, gen_loss = 2.9687029988798375, disc_loss = 0.002832279223247036
Trained batch 73 in epoch 4, gen_loss = 2.9707531510172664, disc_loss = 0.002804270199015485
Trained batch 74 in epoch 4, gen_loss = 2.9734204387664795, disc_loss = 0.002784554917210092
Trained batch 75 in epoch 4, gen_loss = 2.9719612316081396, disc_loss = 0.0027723238676308506
Trained batch 76 in epoch 4, gen_loss = 2.97168256090833, disc_loss = 0.0027459970601326363
Trained batch 77 in epoch 4, gen_loss = 2.9683405558268228, disc_loss = 0.00272610995437926
Trained batch 78 in epoch 4, gen_loss = 2.96456958070586, disc_loss = 0.0027165664942003787
Trained batch 79 in epoch 4, gen_loss = 2.9667773962020876, disc_loss = 0.002727665428392356
Trained batch 80 in epoch 4, gen_loss = 2.9683313487488547, disc_loss = 0.0027246230165474117
Trained batch 81 in epoch 4, gen_loss = 2.9709963507768586, disc_loss = 0.0027274409864131905
Trained batch 82 in epoch 4, gen_loss = 2.968409454966166, disc_loss = 0.0027126507400198423
Trained batch 83 in epoch 4, gen_loss = 2.9660708535285223, disc_loss = 0.002692252836173533
Trained batch 84 in epoch 4, gen_loss = 2.9683475410237032, disc_loss = 0.002674064153175363
Trained batch 85 in epoch 4, gen_loss = 2.970847348834193, disc_loss = 0.002664808650246583
Trained batch 86 in epoch 4, gen_loss = 2.969694924080509, disc_loss = 0.002661976947893399
Trained batch 87 in epoch 4, gen_loss = 2.972352474927902, disc_loss = 0.002658308976440987
Trained batch 88 in epoch 4, gen_loss = 2.967288362845946, disc_loss = 0.0026523582931618425
Trained batch 89 in epoch 4, gen_loss = 2.9666483455234105, disc_loss = 0.0026436761623093237
Trained batch 90 in epoch 4, gen_loss = 2.9623158082857235, disc_loss = 0.0026339158770157496
Trained batch 91 in epoch 4, gen_loss = 2.9604254727778225, disc_loss = 0.0026307388407471794
Trained batch 92 in epoch 4, gen_loss = 2.960814965668545, disc_loss = 0.0026255906715999125
Trained batch 93 in epoch 4, gen_loss = 2.9594417607530636, disc_loss = 0.002616092808509959
Trained batch 94 in epoch 4, gen_loss = 2.9579787430010342, disc_loss = 0.0026021049989044275
Trained batch 95 in epoch 4, gen_loss = 2.9574602618813515, disc_loss = 0.002587466324257548
Trained batch 96 in epoch 4, gen_loss = 2.9592873411080274, disc_loss = 0.0025682587677027225
Trained batch 97 in epoch 4, gen_loss = 2.959345428311095, disc_loss = 0.002552421330545592
Trained batch 98 in epoch 4, gen_loss = 2.9590952564971618, disc_loss = 0.002541053930245754
Trained batch 99 in epoch 4, gen_loss = 2.9598557901382447, disc_loss = 0.002529853584128432
Trained batch 100 in epoch 4, gen_loss = 2.961158613167187, disc_loss = 0.0025175411633381823
Trained batch 101 in epoch 4, gen_loss = 2.958626354441923, disc_loss = 0.0025234751445560844
Trained batch 102 in epoch 4, gen_loss = 2.958028404458055, disc_loss = 0.0025208230877466933
Trained batch 103 in epoch 4, gen_loss = 2.9569779451076803, disc_loss = 0.0025225714539723974
Trained batch 104 in epoch 4, gen_loss = 2.9536846569606237, disc_loss = 0.0025347319991505216
Trained batch 105 in epoch 4, gen_loss = 2.9516577990549915, disc_loss = 0.00252493162132044
Trained batch 106 in epoch 4, gen_loss = 2.9502423188396705, disc_loss = 0.0025293153507208502
Trained batch 107 in epoch 4, gen_loss = 2.9506222318719932, disc_loss = 0.002541501295463941
Trained batch 108 in epoch 4, gen_loss = 2.951188008719628, disc_loss = 0.002548398565898282
Trained batch 109 in epoch 4, gen_loss = 2.953057143904946, disc_loss = 0.002542404833101583
Trained batch 110 in epoch 4, gen_loss = 2.9495996763040355, disc_loss = 0.0025309057584292517
Trained batch 111 in epoch 4, gen_loss = 2.948687725833484, disc_loss = 0.0025187360780754326
Trained batch 112 in epoch 4, gen_loss = 2.9479780682420307, disc_loss = 0.002506495946379527
Trained batch 113 in epoch 4, gen_loss = 2.9466411670049033, disc_loss = 0.0024915267631672976
Trained batch 114 in epoch 4, gen_loss = 2.9450524392335313, disc_loss = 0.0024789013899862767
Trained batch 115 in epoch 4, gen_loss = 2.9460034103229127, disc_loss = 0.0024772228046866327
Trained batch 116 in epoch 4, gen_loss = 2.9434877664614945, disc_loss = 0.0024673789789358904
Trained batch 117 in epoch 4, gen_loss = 2.942732960490857, disc_loss = 0.002454101567756448
Trained batch 118 in epoch 4, gen_loss = 2.944259220812501, disc_loss = 0.002443980281789075
Trained batch 119 in epoch 4, gen_loss = 2.9433562457561493, disc_loss = 0.0024342282665505382
Trained batch 120 in epoch 4, gen_loss = 2.9416902912549734, disc_loss = 0.002424168815135894
Trained batch 121 in epoch 4, gen_loss = 2.941669938994236, disc_loss = 0.002411128138191998
Trained batch 122 in epoch 4, gen_loss = 2.945140920034269, disc_loss = 0.002398359102795158
Trained batch 123 in epoch 4, gen_loss = 2.944290955220499, disc_loss = 0.0023880722235903266
Trained batch 124 in epoch 4, gen_loss = 2.9478648166656494, disc_loss = 0.0023794241994619368
Trained batch 125 in epoch 4, gen_loss = 2.9483611583709717, disc_loss = 0.0023680014109852474
Trained batch 126 in epoch 4, gen_loss = 2.9505484686123102, disc_loss = 0.0023886420627447272
Trained batch 127 in epoch 4, gen_loss = 2.9496475718915462, disc_loss = 0.0023905141383693262
Trained batch 128 in epoch 4, gen_loss = 2.951327394145404, disc_loss = 0.0023897973754688695
Trained batch 129 in epoch 4, gen_loss = 2.9521725049385656, disc_loss = 0.002390841636000774
Trained batch 130 in epoch 4, gen_loss = 2.9569828291885725, disc_loss = 0.002393446142433339
Trained batch 131 in epoch 4, gen_loss = 2.9574826684865085, disc_loss = 0.002389510858461797
Trained batch 132 in epoch 4, gen_loss = 2.9569930725527884, disc_loss = 0.0023833678810353063
Trained batch 133 in epoch 4, gen_loss = 2.9586135967453915, disc_loss = 0.0023742482998345828
Trained batch 134 in epoch 4, gen_loss = 2.959004854272913, disc_loss = 0.002364843607345527
Trained batch 135 in epoch 4, gen_loss = 2.959091091857237, disc_loss = 0.0023558861879898947
Trained batch 136 in epoch 4, gen_loss = 2.959008312573398, disc_loss = 0.0023472019285133558
Trained batch 137 in epoch 4, gen_loss = 2.9581008078395454, disc_loss = 0.00233699589422769
Trained batch 138 in epoch 4, gen_loss = 2.956962443084168, disc_loss = 0.0023262461357609295
Trained batch 139 in epoch 4, gen_loss = 2.9584011793136598, disc_loss = 0.0023203082798447993
Trained batch 140 in epoch 4, gen_loss = 2.9574190606462194, disc_loss = 0.0023159648503130632
Trained batch 141 in epoch 4, gen_loss = 2.958031266507968, disc_loss = 0.002309066838663544
Trained batch 142 in epoch 4, gen_loss = 2.960861934648527, disc_loss = 0.0023053189897518996
Trained batch 143 in epoch 4, gen_loss = 2.9628792024321027, disc_loss = 0.002299619220138993
Trained batch 144 in epoch 4, gen_loss = 2.9645290226771914, disc_loss = 0.002293694910496987
Trained batch 145 in epoch 4, gen_loss = 2.962908970166559, disc_loss = 0.002293070414652155
Trained batch 146 in epoch 4, gen_loss = 2.9610522279934006, disc_loss = 0.002290480022578418
Trained batch 147 in epoch 4, gen_loss = 2.961259004232046, disc_loss = 0.0022907203576225483
Trained batch 148 in epoch 4, gen_loss = 2.9611131072844437, disc_loss = 0.0022864136110441195
Trained batch 149 in epoch 4, gen_loss = 2.9590519777933757, disc_loss = 0.002279329348821193
Trained batch 150 in epoch 4, gen_loss = 2.957993347913224, disc_loss = 0.002269614984771693
Trained batch 151 in epoch 4, gen_loss = 2.9608016657201865, disc_loss = 0.0022605218335612384
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 3.150418758392334, disc_loss = 0.001419477048330009
Trained batch 1 in epoch 5, gen_loss = 2.994753837585449, disc_loss = 0.0016126471455208957
Trained batch 2 in epoch 5, gen_loss = 3.0887627601623535, disc_loss = 0.0023453368727738657
Trained batch 3 in epoch 5, gen_loss = 3.0546122789382935, disc_loss = 0.0032528181036468595
Trained batch 4 in epoch 5, gen_loss = 3.114888334274292, disc_loss = 0.006608624267391861
Trained batch 5 in epoch 5, gen_loss = 3.022523840268453, disc_loss = 0.007530404933883498
Trained batch 6 in epoch 5, gen_loss = 3.0733494077410017, disc_loss = 0.007397275068797171
Trained batch 7 in epoch 5, gen_loss = 3.0266873240470886, disc_loss = 0.0070522930909646675
Trained batch 8 in epoch 5, gen_loss = 3.0354860623677573, disc_loss = 0.006867334751101832
Trained batch 9 in epoch 5, gen_loss = 3.015657067298889, disc_loss = 0.006947085249703377
Trained batch 10 in epoch 5, gen_loss = 3.0132042277943003, disc_loss = 0.007111241353083064
Trained batch 11 in epoch 5, gen_loss = 3.023212711016337, disc_loss = 0.006683071910326059
Trained batch 12 in epoch 5, gen_loss = 3.0367830900045543, disc_loss = 0.006331135635264218
Trained batch 13 in epoch 5, gen_loss = 3.0472615446363176, disc_loss = 0.005950697456553046
Trained batch 14 in epoch 5, gen_loss = 3.033451271057129, disc_loss = 0.005651619370716314
Trained batch 15 in epoch 5, gen_loss = 3.036143258213997, disc_loss = 0.0053803837290615775
Trained batch 16 in epoch 5, gen_loss = 3.046470656114466, disc_loss = 0.0051988736959174275
Trained batch 17 in epoch 5, gen_loss = 3.0455688105689154, disc_loss = 0.005010076429850112
Trained batch 18 in epoch 5, gen_loss = 3.0376419895573665, disc_loss = 0.004826115156327815
Trained batch 19 in epoch 5, gen_loss = 3.038659727573395, disc_loss = 0.004679029399994761
Trained batch 20 in epoch 5, gen_loss = 3.044021209081014, disc_loss = 0.004561365726182149
Trained batch 21 in epoch 5, gen_loss = 3.0332878069444136, disc_loss = 0.00442212947580794
Trained batch 22 in epoch 5, gen_loss = 3.022256799366163, disc_loss = 0.004307747388299069
Trained batch 23 in epoch 5, gen_loss = 3.0118155777454376, disc_loss = 0.004202073478760819
Trained batch 24 in epoch 5, gen_loss = 3.009613485336304, disc_loss = 0.004091839762404561
Trained batch 25 in epoch 5, gen_loss = 3.008918890586266, disc_loss = 0.004042872881445174
Trained batch 26 in epoch 5, gen_loss = 3.002238900573165, disc_loss = 0.00409567143112697
Trained batch 27 in epoch 5, gen_loss = 3.008700064250401, disc_loss = 0.004036883150027799
Trained batch 28 in epoch 5, gen_loss = 2.995692729949951, disc_loss = 0.004012551889273113
Trained batch 29 in epoch 5, gen_loss = 2.98918461004893, disc_loss = 0.0039587272253508365
Trained batch 30 in epoch 5, gen_loss = 2.9946683760612243, disc_loss = 0.003935795239803772
Trained batch 31 in epoch 5, gen_loss = 3.0034897476434708, disc_loss = 0.004058407816046383
Trained batch 32 in epoch 5, gen_loss = 2.9982912323691626, disc_loss = 0.004037663502844445
Trained batch 33 in epoch 5, gen_loss = 2.9982450990115894, disc_loss = 0.003983698312795776
Trained batch 34 in epoch 5, gen_loss = 2.991919313158308, disc_loss = 0.0039128647185862064
Trained batch 35 in epoch 5, gen_loss = 2.9910641643736096, disc_loss = 0.0038310826607307214
Trained batch 36 in epoch 5, gen_loss = 2.9981804860604777, disc_loss = 0.0037541446382985326
Trained batch 37 in epoch 5, gen_loss = 2.997639674889414, disc_loss = 0.0037035583028275716
Trained batch 38 in epoch 5, gen_loss = 3.0011488596598306, disc_loss = 0.003682230688774815
Trained batch 39 in epoch 5, gen_loss = 3.0013397932052612, disc_loss = 0.0036607589747291057
Trained batch 40 in epoch 5, gen_loss = 3.0027752387814406, disc_loss = 0.0036524163513648802
Trained batch 41 in epoch 5, gen_loss = 2.997052646818615, disc_loss = 0.0036311917938292027
Trained batch 42 in epoch 5, gen_loss = 2.999292390291081, disc_loss = 0.003592590205804553
Trained batch 43 in epoch 5, gen_loss = 2.9993666302074087, disc_loss = 0.003570811018686403
Trained batch 44 in epoch 5, gen_loss = 2.9968889130486382, disc_loss = 0.003570917978261908
Trained batch 45 in epoch 5, gen_loss = 2.999767666277678, disc_loss = 0.003572720396534904
Trained batch 46 in epoch 5, gen_loss = 2.995416022361593, disc_loss = 0.0035815335156277137
Trained batch 47 in epoch 5, gen_loss = 2.9953729659318924, disc_loss = 0.003630994033301249
Trained batch 48 in epoch 5, gen_loss = 3.0064091195865554, disc_loss = 0.003612408081867865
Trained batch 49 in epoch 5, gen_loss = 3.002716073989868, disc_loss = 0.003570705191232264
Trained batch 50 in epoch 5, gen_loss = 3.000400603986254, disc_loss = 0.003533709173401197
Trained batch 51 in epoch 5, gen_loss = 2.996933849958273, disc_loss = 0.003500332939438522
Trained batch 52 in epoch 5, gen_loss = 2.9946138948764442, disc_loss = 0.0034708623062678664
Trained batch 53 in epoch 5, gen_loss = 3.000227129017865, disc_loss = 0.0034300427262981734
Trained batch 54 in epoch 5, gen_loss = 3.011289015683261, disc_loss = 0.003394027426838875
Trained batch 55 in epoch 5, gen_loss = 3.0127529118742262, disc_loss = 0.0033451233321102336
Trained batch 56 in epoch 5, gen_loss = 3.013232335709689, disc_loss = 0.0033018576949344655
Trained batch 57 in epoch 5, gen_loss = 3.0123043389155946, disc_loss = 0.0032666151468031877
Trained batch 58 in epoch 5, gen_loss = 3.0167233418610135, disc_loss = 0.0032264971000663303
Trained batch 59 in epoch 5, gen_loss = 3.015368191401164, disc_loss = 0.003236897421690325
Trained batch 60 in epoch 5, gen_loss = 3.015854690895706, disc_loss = 0.0032845445694859887
Trained batch 61 in epoch 5, gen_loss = 3.021518111228943, disc_loss = 0.0032707486985131136
Trained batch 62 in epoch 5, gen_loss = 3.0228196060846724, disc_loss = 0.0032555554542572254
Trained batch 63 in epoch 5, gen_loss = 3.0229850746691227, disc_loss = 0.0032521589600946754
Trained batch 64 in epoch 5, gen_loss = 3.0205882916083704, disc_loss = 0.003255214191113527
Trained batch 65 in epoch 5, gen_loss = 3.0123193300131597, disc_loss = 0.003292310714834567
Trained batch 66 in epoch 5, gen_loss = 3.0114333451683843, disc_loss = 0.003397827092280139
Trained batch 67 in epoch 5, gen_loss = 3.016926390283248, disc_loss = 0.0036613268859903604
Trained batch 68 in epoch 5, gen_loss = 3.020662166070247, disc_loss = 0.0036895054702957473
Trained batch 69 in epoch 5, gen_loss = 3.0159095661980766, disc_loss = 0.003760094554828746
Trained batch 70 in epoch 5, gen_loss = 3.0169466549242046, disc_loss = 0.003767826345185159
Trained batch 71 in epoch 5, gen_loss = 3.0181532071696386, disc_loss = 0.003774554960222708
Trained batch 72 in epoch 5, gen_loss = 3.018674585917225, disc_loss = 0.003763399233607805
Trained batch 73 in epoch 5, gen_loss = 3.01636203237482, disc_loss = 0.003806834769863132
Trained batch 74 in epoch 5, gen_loss = 3.01765274365743, disc_loss = 0.0038237949398656685
Trained batch 75 in epoch 5, gen_loss = 3.0183432886475012, disc_loss = 0.003790553435560708
Trained batch 76 in epoch 5, gen_loss = 3.020536271008578, disc_loss = 0.0037634179446628534
Trained batch 77 in epoch 5, gen_loss = 3.016972068028572, disc_loss = 0.0038673149388976013
Trained batch 78 in epoch 5, gen_loss = 3.016806774501559, disc_loss = 0.004348657602338191
Trained batch 79 in epoch 5, gen_loss = 3.024547961354256, disc_loss = 0.004652028462442104
Trained batch 80 in epoch 5, gen_loss = 3.024819753788136, disc_loss = 0.005003634450761716
Trained batch 81 in epoch 5, gen_loss = 3.0183093111689496, disc_loss = 0.005100099416733606
Trained batch 82 in epoch 5, gen_loss = 3.0154167284448463, disc_loss = 0.005298958576553647
Trained batch 83 in epoch 5, gen_loss = 3.0180968188104176, disc_loss = 0.005376814178557002
Trained batch 84 in epoch 5, gen_loss = 3.017370411928962, disc_loss = 0.005505220768699313
Trained batch 85 in epoch 5, gen_loss = 3.016101826068967, disc_loss = 0.005521579235413133
Trained batch 86 in epoch 5, gen_loss = 3.0139980535397584, disc_loss = 0.005496721617053209
Trained batch 87 in epoch 5, gen_loss = 3.010672786019065, disc_loss = 0.005451212129132314
Trained batch 88 in epoch 5, gen_loss = 3.01222300797366, disc_loss = 0.005401162268447407
Trained batch 89 in epoch 5, gen_loss = 3.012288045883179, disc_loss = 0.005351883729195429
Trained batch 90 in epoch 5, gen_loss = 3.0073018283634396, disc_loss = 0.00531859073409258
Trained batch 91 in epoch 5, gen_loss = 3.0096104222795237, disc_loss = 0.005297551050519004
Trained batch 92 in epoch 5, gen_loss = 3.007642597280523, disc_loss = 0.005258759776611001
Trained batch 93 in epoch 5, gen_loss = 3.0041717722060834, disc_loss = 0.005210476069205857
Trained batch 94 in epoch 5, gen_loss = 3.004855186060855, disc_loss = 0.005194211397074947
Trained batch 95 in epoch 5, gen_loss = 3.007839545607567, disc_loss = 0.005172745507782868
Trained batch 96 in epoch 5, gen_loss = 3.006969933657302, disc_loss = 0.005138163351617062
Trained batch 97 in epoch 5, gen_loss = 3.0014508184121578, disc_loss = 0.00511066004519864
Trained batch 98 in epoch 5, gen_loss = 3.0006188768329043, disc_loss = 0.005077666091506906
Trained batch 99 in epoch 5, gen_loss = 2.999868607521057, disc_loss = 0.00505025138729252
Trained batch 100 in epoch 5, gen_loss = 3.0010584274140917, disc_loss = 0.005017278928051491
Trained batch 101 in epoch 5, gen_loss = 3.003272383820777, disc_loss = 0.004979914679721582
Trained batch 102 in epoch 5, gen_loss = 3.0058895314781413, disc_loss = 0.004941218698767999
Trained batch 103 in epoch 5, gen_loss = 3.003336794101275, disc_loss = 0.004903332084023322
Trained batch 104 in epoch 5, gen_loss = 3.000905093692598, disc_loss = 0.00486759222112596
Trained batch 105 in epoch 5, gen_loss = 3.000473551030429, disc_loss = 0.0048397864294150526
Trained batch 106 in epoch 5, gen_loss = 2.997527721886323, disc_loss = 0.004806667001630728
Trained batch 107 in epoch 5, gen_loss = 2.9983829149493464, disc_loss = 0.004776269493891892
Trained batch 108 in epoch 5, gen_loss = 2.9990655041615897, disc_loss = 0.004749208063938134
Trained batch 109 in epoch 5, gen_loss = 2.996818750554865, disc_loss = 0.0047179308730516244
Trained batch 110 in epoch 5, gen_loss = 2.9974929448720573, disc_loss = 0.004687269559121682
Trained batch 111 in epoch 5, gen_loss = 2.9952703714370728, disc_loss = 0.004659268726494962
Trained batch 112 in epoch 5, gen_loss = 2.9958831905263716, disc_loss = 0.004631661658537929
Trained batch 113 in epoch 5, gen_loss = 2.9963512378826476, disc_loss = 0.004601202046359775
Trained batch 114 in epoch 5, gen_loss = 2.994821950663691, disc_loss = 0.004581037008851443
Trained batch 115 in epoch 5, gen_loss = 2.995727987125002, disc_loss = 0.004578324924985846
Trained batch 116 in epoch 5, gen_loss = 2.9937136438157825, disc_loss = 0.004602809754025159
Trained batch 117 in epoch 5, gen_loss = 2.9977683334027305, disc_loss = 0.0046204007299759
Trained batch 118 in epoch 5, gen_loss = 2.9971359697710565, disc_loss = 0.004695035719719692
Trained batch 119 in epoch 5, gen_loss = 2.992787782351176, disc_loss = 0.005235399009931522
Trained batch 120 in epoch 5, gen_loss = 2.996229313621836, disc_loss = 0.00824299179044483
Trained batch 121 in epoch 5, gen_loss = 2.9874918695356025, disc_loss = 0.010321823985995267
Trained batch 122 in epoch 5, gen_loss = 2.988625914100709, disc_loss = 0.011048109383261725
Trained batch 123 in epoch 5, gen_loss = 2.9900814140996625, disc_loss = 0.01274021782427876
Trained batch 124 in epoch 5, gen_loss = 2.990468351364136, disc_loss = 0.013582553341053426
Trained batch 125 in epoch 5, gen_loss = 2.987845926057725, disc_loss = 0.013836682270584067
Trained batch 126 in epoch 5, gen_loss = 2.9854041966866323, disc_loss = 0.01417769270116742
Trained batch 127 in epoch 5, gen_loss = 2.983129655942321, disc_loss = 0.01433127060499828
Trained batch 128 in epoch 5, gen_loss = 2.984323786210644, disc_loss = 0.01435778425670727
Trained batch 129 in epoch 5, gen_loss = 2.983827601946317, disc_loss = 0.014512837963859335
Trained batch 130 in epoch 5, gen_loss = 2.9806345837716837, disc_loss = 0.014692111323829313
Trained batch 131 in epoch 5, gen_loss = 2.978575186295943, disc_loss = 0.014841875229842228
Trained batch 132 in epoch 5, gen_loss = 2.975849191048988, disc_loss = 0.014995955490101045
Trained batch 133 in epoch 5, gen_loss = 2.9765985581412244, disc_loss = 0.015111081940712713
Trained batch 134 in epoch 5, gen_loss = 2.975027624766032, disc_loss = 0.01520855356335502
Trained batch 135 in epoch 5, gen_loss = 2.974899293745265, disc_loss = 0.015309522215187932
Trained batch 136 in epoch 5, gen_loss = 2.97337670221816, disc_loss = 0.015308173114168764
Trained batch 137 in epoch 5, gen_loss = 2.9739914510561074, disc_loss = 0.015362309938991793
Trained batch 138 in epoch 5, gen_loss = 2.9743056383064324, disc_loss = 0.015538474101834536
Trained batch 139 in epoch 5, gen_loss = 2.9718028988157, disc_loss = 0.015684057904374122
Trained batch 140 in epoch 5, gen_loss = 2.9755775387405503, disc_loss = 0.01569838103167845
Trained batch 141 in epoch 5, gen_loss = 2.9790840719787166, disc_loss = 0.015669722515847008
Trained batch 142 in epoch 5, gen_loss = 2.9812364344830278, disc_loss = 0.015625499793771213
Trained batch 143 in epoch 5, gen_loss = 2.983280966679255, disc_loss = 0.015596745321494786
Trained batch 144 in epoch 5, gen_loss = 2.9861484659129176, disc_loss = 0.015649583440370343
Trained batch 145 in epoch 5, gen_loss = 2.9856143716263444, disc_loss = 0.016084337599849813
Trained batch 146 in epoch 5, gen_loss = 2.990778245082518, disc_loss = 0.016524031016259728
Trained batch 147 in epoch 5, gen_loss = 2.9928462763090393, disc_loss = 0.016950200103393227
Trained batch 148 in epoch 5, gen_loss = 2.990616654389657, disc_loss = 0.01725233585539355
Trained batch 149 in epoch 5, gen_loss = 2.9916315110524496, disc_loss = 0.017225527632205438
Trained batch 150 in epoch 5, gen_loss = 2.9925482888884893, disc_loss = 0.017483563383652624
Trained batch 151 in epoch 5, gen_loss = 2.99067433256852, disc_loss = 0.017652872477284337
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 3.4087839126586914, disc_loss = 0.032087285071611404
Trained batch 1 in epoch 6, gen_loss = 3.17801034450531, disc_loss = 0.029096534475684166
Trained batch 2 in epoch 6, gen_loss = 3.168510675430298, disc_loss = 0.025116469711065292
Trained batch 3 in epoch 6, gen_loss = 3.176498591899872, disc_loss = 0.021772364852949977
Trained batch 4 in epoch 6, gen_loss = 3.213617467880249, disc_loss = 0.01813455009832978
Trained batch 5 in epoch 6, gen_loss = 3.193317453066508, disc_loss = 0.015973562995592754
Trained batch 6 in epoch 6, gen_loss = 3.198305300303868, disc_loss = 0.014488856707300459
Trained batch 7 in epoch 6, gen_loss = 3.1751535832881927, disc_loss = 0.013304597465321422
Trained batch 8 in epoch 6, gen_loss = 3.1540211306677923, disc_loss = 0.012516247315539254
Trained batch 9 in epoch 6, gen_loss = 3.115260291099548, disc_loss = 0.011642230884172022
Trained batch 10 in epoch 6, gen_loss = 3.1044215939261695, disc_loss = 0.010858221593397584
Trained batch 11 in epoch 6, gen_loss = 3.0880457758903503, disc_loss = 0.010348310286644846
Trained batch 12 in epoch 6, gen_loss = 3.0839341420393724, disc_loss = 0.00998208519572822
Trained batch 13 in epoch 6, gen_loss = 3.0956345115389143, disc_loss = 0.009511789972228664
Trained batch 14 in epoch 6, gen_loss = 3.0977546691894533, disc_loss = 0.009075830054158966
Trained batch 15 in epoch 6, gen_loss = 3.1036054641008377, disc_loss = 0.008691147217177786
Trained batch 16 in epoch 6, gen_loss = 3.1016979077283073, disc_loss = 0.008503800956532359
Trained batch 17 in epoch 6, gen_loss = 3.095144655969408, disc_loss = 0.008593421985602213
Trained batch 18 in epoch 6, gen_loss = 3.110019244645771, disc_loss = 0.00890775950086352
Trained batch 19 in epoch 6, gen_loss = 3.1002395033836363, disc_loss = 0.009468409826513379
Trained batch 20 in epoch 6, gen_loss = 3.1030869711013067, disc_loss = 0.009428492691811351
Trained batch 21 in epoch 6, gen_loss = 3.1029369831085205, disc_loss = 0.009305824832567438
Trained batch 22 in epoch 6, gen_loss = 3.110959239628004, disc_loss = 0.009165742505422753
Trained batch 23 in epoch 6, gen_loss = 3.0987057189146676, disc_loss = 0.008900903000418717
Trained batch 24 in epoch 6, gen_loss = 3.10830322265625, disc_loss = 0.00861830887850374
Trained batch 25 in epoch 6, gen_loss = 3.103001227745643, disc_loss = 0.008386773464735597
Trained batch 26 in epoch 6, gen_loss = 3.118660158581204, disc_loss = 0.008318696770368627
Trained batch 27 in epoch 6, gen_loss = 3.1249998807907104, disc_loss = 0.008432250981318898
Trained batch 28 in epoch 6, gen_loss = 3.111291474309461, disc_loss = 0.008762103196329855
Trained batch 29 in epoch 6, gen_loss = 3.129501136144002, disc_loss = 0.008941499528009444
Trained batch 30 in epoch 6, gen_loss = 3.1342430730019846, disc_loss = 0.008737172702357413
Trained batch 31 in epoch 6, gen_loss = 3.1205514669418335, disc_loss = 0.008662163436383707
Trained batch 32 in epoch 6, gen_loss = 3.1109825192075786, disc_loss = 0.00859845748213543
Trained batch 33 in epoch 6, gen_loss = 3.1103555735419777, disc_loss = 0.008493434579577297
Trained batch 34 in epoch 6, gen_loss = 3.1067705154418945, disc_loss = 0.008340882546534496
Trained batch 35 in epoch 6, gen_loss = 3.1051945553885565, disc_loss = 0.008160253129770152
Trained batch 36 in epoch 6, gen_loss = 3.0964744284346297, disc_loss = 0.008004318623853897
Trained batch 37 in epoch 6, gen_loss = 3.1107064422808195, disc_loss = 0.007916651130041205
Trained batch 38 in epoch 6, gen_loss = 3.129933253312722, disc_loss = 0.008045153217748381
Trained batch 39 in epoch 6, gen_loss = 3.13497554063797, disc_loss = 0.00801410156127531
Trained batch 40 in epoch 6, gen_loss = 3.1308013811344053, disc_loss = 0.008184976810475857
Trained batch 41 in epoch 6, gen_loss = 3.145484288533529, disc_loss = 0.008863362464277694
Trained batch 42 in epoch 6, gen_loss = 3.1323837790378306, disc_loss = 0.00940793885058875
Trained batch 43 in epoch 6, gen_loss = 3.1118669564073738, disc_loss = 0.015320327410749584
Trained batch 44 in epoch 6, gen_loss = 3.126677083969116, disc_loss = 0.018046358830502464
Trained batch 45 in epoch 6, gen_loss = 3.1174383526263028, disc_loss = 0.018582158218360626
Trained batch 46 in epoch 6, gen_loss = 3.1053419163886535, disc_loss = 0.01946524841998248
Trained batch 47 in epoch 6, gen_loss = 3.104586665829023, disc_loss = 0.019542145952679373
Trained batch 48 in epoch 6, gen_loss = 3.1112082637086207, disc_loss = 0.01963019460601238
Trained batch 49 in epoch 6, gen_loss = 3.1059410476684572, disc_loss = 0.01977427168050781
Trained batch 50 in epoch 6, gen_loss = 3.101456801096598, disc_loss = 0.020031333245866586
Trained batch 51 in epoch 6, gen_loss = 3.0976331875874448, disc_loss = 0.020096279879978213
Trained batch 52 in epoch 6, gen_loss = 3.0946548389938644, disc_loss = 0.019858634356356594
Trained batch 53 in epoch 6, gen_loss = 3.1024682875032776, disc_loss = 0.019631378156460683
Trained batch 54 in epoch 6, gen_loss = 3.10040769143538, disc_loss = 0.019417362298223783
Trained batch 55 in epoch 6, gen_loss = 3.101661524602345, disc_loss = 0.019267159890400114
Trained batch 56 in epoch 6, gen_loss = 3.1055753314704226, disc_loss = 0.019207887459758734
Trained batch 57 in epoch 6, gen_loss = 3.105383511247306, disc_loss = 0.01904477729213199
Trained batch 58 in epoch 6, gen_loss = 3.1079996157500704, disc_loss = 0.01880832272384442
Trained batch 59 in epoch 6, gen_loss = 3.1091886440912884, disc_loss = 0.018548329944799966
Trained batch 60 in epoch 6, gen_loss = 3.1093687190384163, disc_loss = 0.018316176431787918
Trained batch 61 in epoch 6, gen_loss = 3.1024963432742703, disc_loss = 0.01813683076198363
Trained batch 62 in epoch 6, gen_loss = 3.1030492896125432, disc_loss = 0.01806621740032579
Trained batch 63 in epoch 6, gen_loss = 3.1031262762844563, disc_loss = 0.017957590798687306
Trained batch 64 in epoch 6, gen_loss = 3.0992471841665417, disc_loss = 0.017815066059119998
Trained batch 65 in epoch 6, gen_loss = 3.1000733014309043, disc_loss = 0.017609968317573832
Trained batch 66 in epoch 6, gen_loss = 3.1003397970057245, disc_loss = 0.01747156007027726
Trained batch 67 in epoch 6, gen_loss = 3.1009393088957844, disc_loss = 0.017291322379605845
Trained batch 68 in epoch 6, gen_loss = 3.0994493615800054, disc_loss = 0.017114836845776416
Trained batch 69 in epoch 6, gen_loss = 3.1034594876425605, disc_loss = 0.016956729683027204
Trained batch 70 in epoch 6, gen_loss = 3.108247629353698, disc_loss = 0.01677375370275859
Trained batch 71 in epoch 6, gen_loss = 3.1095054944356284, disc_loss = 0.016645510760200623
Trained batch 72 in epoch 6, gen_loss = 3.109700702641108, disc_loss = 0.01650299985529472
Trained batch 73 in epoch 6, gen_loss = 3.1101191720447026, disc_loss = 0.016371409523590293
Trained batch 74 in epoch 6, gen_loss = 3.109679854710897, disc_loss = 0.01617722604268541
Trained batch 75 in epoch 6, gen_loss = 3.112329025017588, disc_loss = 0.015985707830527406
Trained batch 76 in epoch 6, gen_loss = 3.111552250849736, disc_loss = 0.01579873811743863
Trained batch 77 in epoch 6, gen_loss = 3.113184439830291, disc_loss = 0.01562632012885446
Trained batch 78 in epoch 6, gen_loss = 3.1151442618309697, disc_loss = 0.0154536128975451
Trained batch 79 in epoch 6, gen_loss = 3.113291844725609, disc_loss = 0.015315388183807954
Trained batch 80 in epoch 6, gen_loss = 3.1106322047151167, disc_loss = 0.015209814338128508
Trained batch 81 in epoch 6, gen_loss = 3.1078597685185874, disc_loss = 0.01506508649156497
Trained batch 82 in epoch 6, gen_loss = 3.1070659505315574, disc_loss = 0.014918656955215048
Trained batch 83 in epoch 6, gen_loss = 3.1082864659173146, disc_loss = 0.014767902487489794
Trained batch 84 in epoch 6, gen_loss = 3.107049616645364, disc_loss = 0.01463982278809828
Trained batch 85 in epoch 6, gen_loss = 3.105400235153908, disc_loss = 0.014530290237649582
Trained batch 86 in epoch 6, gen_loss = 3.107501731521782, disc_loss = 0.014418864103526562
Trained batch 87 in epoch 6, gen_loss = 3.110912496393377, disc_loss = 0.01430694662055678
Trained batch 88 in epoch 6, gen_loss = 3.1106929189703436, disc_loss = 0.014159910698693372
Trained batch 89 in epoch 6, gen_loss = 3.11432245042589, disc_loss = 0.014093750243126932
Trained batch 90 in epoch 6, gen_loss = 3.1125538558750363, disc_loss = 0.014035770386856581
Trained batch 91 in epoch 6, gen_loss = 3.11310243865718, disc_loss = 0.01397320685235014
Trained batch 92 in epoch 6, gen_loss = 3.1131697188141527, disc_loss = 0.013859018774813301
Trained batch 93 in epoch 6, gen_loss = 3.115105933331429, disc_loss = 0.01380926036855523
Trained batch 94 in epoch 6, gen_loss = 3.115970405779387, disc_loss = 0.013685615947715155
Trained batch 95 in epoch 6, gen_loss = 3.116891165574392, disc_loss = 0.013640241492491137
Trained batch 96 in epoch 6, gen_loss = 3.1128793598450337, disc_loss = 0.013570403045321786
Trained batch 97 in epoch 6, gen_loss = 3.1119903885588354, disc_loss = 0.01346681354334578
Trained batch 98 in epoch 6, gen_loss = 3.1152319281992287, disc_loss = 0.013394386534616727
Trained batch 99 in epoch 6, gen_loss = 3.1151758146286013, disc_loss = 0.013295415443135426
Trained batch 100 in epoch 6, gen_loss = 3.1149325724875574, disc_loss = 0.013192064136884516
Trained batch 101 in epoch 6, gen_loss = 3.1124544003430534, disc_loss = 0.013081257449526923
Trained batch 102 in epoch 6, gen_loss = 3.111066447878347, disc_loss = 0.012989769539416053
Trained batch 103 in epoch 6, gen_loss = 3.1071619941638065, disc_loss = 0.012937797451741062
Trained batch 104 in epoch 6, gen_loss = 3.1034811088017054, disc_loss = 0.012954862596511485
Trained batch 105 in epoch 6, gen_loss = 3.104172663868598, disc_loss = 0.013035593944259058
Trained batch 106 in epoch 6, gen_loss = 3.103808543392431, disc_loss = 0.012982506499730189
Trained batch 107 in epoch 6, gen_loss = 3.101611508263482, disc_loss = 0.01289621292488408
Trained batch 108 in epoch 6, gen_loss = 3.1033314980498146, disc_loss = 0.012796353607506859
Trained batch 109 in epoch 6, gen_loss = 3.1041174520145765, disc_loss = 0.012733838117723776
Trained batch 110 in epoch 6, gen_loss = 3.1034483114878335, disc_loss = 0.012698512326145696
Trained batch 111 in epoch 6, gen_loss = 3.1018262739692415, disc_loss = 0.01263709846846593
Trained batch 112 in epoch 6, gen_loss = 3.103665643033728, disc_loss = 0.012547871006232381
Trained batch 113 in epoch 6, gen_loss = 3.1038294131295725, disc_loss = 0.012472746614979482
Trained batch 114 in epoch 6, gen_loss = 3.1058545568714973, disc_loss = 0.012388074846492837
Trained batch 115 in epoch 6, gen_loss = 3.1060878449472886, disc_loss = 0.012290991169344312
Trained batch 116 in epoch 6, gen_loss = 3.104485868388771, disc_loss = 0.012201500977946715
Trained batch 117 in epoch 6, gen_loss = 3.1021942607427047, disc_loss = 0.012168260142246609
Trained batch 118 in epoch 6, gen_loss = 3.099283801407373, disc_loss = 0.012140602273514354
Trained batch 119 in epoch 6, gen_loss = 3.0986027816931405, disc_loss = 0.012101611787026437
Trained batch 120 in epoch 6, gen_loss = 3.096448620488821, disc_loss = 0.01203899106014643
Trained batch 121 in epoch 6, gen_loss = 3.0952936098223827, disc_loss = 0.01197087006036528
Trained batch 122 in epoch 6, gen_loss = 3.0945736179506875, disc_loss = 0.011893946875257766
Trained batch 123 in epoch 6, gen_loss = 3.0937326031346477, disc_loss = 0.011813686253698242
Trained batch 124 in epoch 6, gen_loss = 3.0904295539855955, disc_loss = 0.011769674574956299
Trained batch 125 in epoch 6, gen_loss = 3.090822002244374, disc_loss = 0.0117914176320598
Trained batch 126 in epoch 6, gen_loss = 3.0905957616220308, disc_loss = 0.011759400886564157
Trained batch 127 in epoch 6, gen_loss = 3.0905049312859774, disc_loss = 0.011694896944391076
Trained batch 128 in epoch 6, gen_loss = 3.0896198601685754, disc_loss = 0.011629659579633626
Trained batch 129 in epoch 6, gen_loss = 3.091576258952801, disc_loss = 0.011548646240351864
Trained batch 130 in epoch 6, gen_loss = 3.0903318346911712, disc_loss = 0.01146943150941311
Trained batch 131 in epoch 6, gen_loss = 3.086442121953675, disc_loss = 0.011801563686634781
Trained batch 132 in epoch 6, gen_loss = 3.0796630310833004, disc_loss = 0.012855173085108959
Trained batch 133 in epoch 6, gen_loss = 3.07935683051152, disc_loss = 0.012998557333320157
Trained batch 134 in epoch 6, gen_loss = 3.0805889270923754, disc_loss = 0.01305991880664671
Trained batch 135 in epoch 6, gen_loss = 3.0827108796905067, disc_loss = 0.013066570264259902
Trained batch 136 in epoch 6, gen_loss = 3.0812592367186165, disc_loss = 0.013058360166385443
Trained batch 137 in epoch 6, gen_loss = 3.081487206445224, disc_loss = 0.013041512200446881
Trained batch 138 in epoch 6, gen_loss = 3.082229724033273, disc_loss = 0.012997061935447746
Trained batch 139 in epoch 6, gen_loss = 3.0821142860821316, disc_loss = 0.012928168073163502
Trained batch 140 in epoch 6, gen_loss = 3.081132389974932, disc_loss = 0.012857774361730256
Trained batch 141 in epoch 6, gen_loss = 3.0831524637383474, disc_loss = 0.012789117044467531
Trained batch 142 in epoch 6, gen_loss = 3.0831879002230984, disc_loss = 0.012710477119650353
Trained batch 143 in epoch 6, gen_loss = 3.081456664535734, disc_loss = 0.012671340442870537
Trained batch 144 in epoch 6, gen_loss = 3.077823079865554, disc_loss = 0.012638048742544549
Trained batch 145 in epoch 6, gen_loss = 3.0773391397032017, disc_loss = 0.012582446733961673
Trained batch 146 in epoch 6, gen_loss = 3.0765584180144225, disc_loss = 0.012513132138671924
Trained batch 147 in epoch 6, gen_loss = 3.0786795906118445, disc_loss = 0.012450373023622544
Trained batch 148 in epoch 6, gen_loss = 3.07779042352766, disc_loss = 0.01240895163180344
Trained batch 149 in epoch 6, gen_loss = 3.077660597165426, disc_loss = 0.01236884858769675
Trained batch 150 in epoch 6, gen_loss = 3.0770757845695447, disc_loss = 0.01231332602818182
Trained batch 151 in epoch 6, gen_loss = 3.076362653782493, disc_loss = 0.012259848121749727
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.932553768157959, disc_loss = 0.005740205757319927
Trained batch 1 in epoch 7, gen_loss = 3.140927791595459, disc_loss = 0.01025018421933055
Trained batch 2 in epoch 7, gen_loss = 3.1366043090820312, disc_loss = 0.01853938369701306
Trained batch 3 in epoch 7, gen_loss = 3.0737118124961853, disc_loss = 0.020544182742014527
Trained batch 4 in epoch 7, gen_loss = 3.0491992950439455, disc_loss = 0.021541103534400464
Trained batch 5 in epoch 7, gen_loss = 3.033753752708435, disc_loss = 0.019419911162306864
Trained batch 6 in epoch 7, gen_loss = 3.0596445969172885, disc_loss = 0.017425608688167164
Trained batch 7 in epoch 7, gen_loss = 3.0778440833091736, disc_loss = 0.016043468145653605
Trained batch 8 in epoch 7, gen_loss = 3.0902954737345376, disc_loss = 0.014588615339663293
Trained batch 9 in epoch 7, gen_loss = 3.0616286277770994, disc_loss = 0.013817878346890211
Trained batch 10 in epoch 7, gen_loss = 3.068954597819935, disc_loss = 0.013354229656132784
Trained batch 11 in epoch 7, gen_loss = 3.087800661722819, disc_loss = 0.01288552318389217
Trained batch 12 in epoch 7, gen_loss = 3.0737052330603967, disc_loss = 0.012331861787690567
Trained batch 13 in epoch 7, gen_loss = 3.108313662665231, disc_loss = 0.011787264441539134
Trained batch 14 in epoch 7, gen_loss = 3.0946014881134034, disc_loss = 0.011235567337522904
Trained batch 15 in epoch 7, gen_loss = 3.1206422597169876, disc_loss = 0.01130214156000875
Trained batch 16 in epoch 7, gen_loss = 3.134465119417976, disc_loss = 0.01099594498929732
Trained batch 17 in epoch 7, gen_loss = 3.1261867019865246, disc_loss = 0.010566299936423698
Trained batch 18 in epoch 7, gen_loss = 3.137367712823968, disc_loss = 0.01012435386349496
Trained batch 19 in epoch 7, gen_loss = 3.130015218257904, disc_loss = 0.00992327353451401
Trained batch 20 in epoch 7, gen_loss = 3.11534055074056, disc_loss = 0.009848516412256729
Trained batch 21 in epoch 7, gen_loss = 3.123046777465127, disc_loss = 0.009645522085272452
Trained batch 22 in epoch 7, gen_loss = 3.1306547392969546, disc_loss = 0.009361063079584552
Trained batch 23 in epoch 7, gen_loss = 3.1378224591414132, disc_loss = 0.009084618563065305
Trained batch 24 in epoch 7, gen_loss = 3.1291437435150145, disc_loss = 0.008836868721991777
Trained batch 25 in epoch 7, gen_loss = 3.1373187486941996, disc_loss = 0.00860112566106881
Trained batch 26 in epoch 7, gen_loss = 3.14780773056878, disc_loss = 0.0086882918883391
Trained batch 27 in epoch 7, gen_loss = 3.1426976237978255, disc_loss = 0.00869706184104351
Trained batch 28 in epoch 7, gen_loss = 3.149414999731656, disc_loss = 0.008525772493910688
Trained batch 29 in epoch 7, gen_loss = 3.1543375968933107, disc_loss = 0.008417146086382369
Trained batch 30 in epoch 7, gen_loss = 3.151861636869369, disc_loss = 0.008244602527889994
Trained batch 31 in epoch 7, gen_loss = 3.1395411044359207, disc_loss = 0.008121137994749006
Trained batch 32 in epoch 7, gen_loss = 3.137233611309167, disc_loss = 0.008002849740230224
Trained batch 33 in epoch 7, gen_loss = 3.142076913048239, disc_loss = 0.008100811056518817
Trained batch 34 in epoch 7, gen_loss = 3.1409059115818567, disc_loss = 0.008030772841136371
Trained batch 35 in epoch 7, gen_loss = 3.1424644854333668, disc_loss = 0.008010918888936026
Trained batch 36 in epoch 7, gen_loss = 3.13783116598387, disc_loss = 0.007880993634210649
Trained batch 37 in epoch 7, gen_loss = 3.1368706163607145, disc_loss = 0.007736214142488806
Trained batch 38 in epoch 7, gen_loss = 3.133987579590235, disc_loss = 0.007621846185662808
Trained batch 39 in epoch 7, gen_loss = 3.1275669515132902, disc_loss = 0.007543815602548421
Trained batch 40 in epoch 7, gen_loss = 3.119644310416245, disc_loss = 0.007579594191799804
Trained batch 41 in epoch 7, gen_loss = 3.124868778955369, disc_loss = 0.00767390008661009
Trained batch 42 in epoch 7, gen_loss = 3.121803699537765, disc_loss = 0.007624532236869252
Trained batch 43 in epoch 7, gen_loss = 3.1276867118748752, disc_loss = 0.007544455435973677
Trained batch 44 in epoch 7, gen_loss = 3.1250460889604357, disc_loss = 0.007456491825481256
Trained batch 45 in epoch 7, gen_loss = 3.1204322472862573, disc_loss = 0.007395090140483301
Trained batch 46 in epoch 7, gen_loss = 3.1185292233812048, disc_loss = 0.007320242408821558
Trained batch 47 in epoch 7, gen_loss = 3.1243790139754615, disc_loss = 0.0072724466541937245
Trained batch 48 in epoch 7, gen_loss = 3.123327654235217, disc_loss = 0.00723525134808555
Trained batch 49 in epoch 7, gen_loss = 3.1162929773330688, disc_loss = 0.007211067117750645
Trained batch 50 in epoch 7, gen_loss = 3.113623156267054, disc_loss = 0.007145374040941105
Trained batch 51 in epoch 7, gen_loss = 3.1055100697737474, disc_loss = 0.007153680668964695
Trained batch 52 in epoch 7, gen_loss = 3.1090024327332118, disc_loss = 0.0074924839054287045
Trained batch 53 in epoch 7, gen_loss = 3.1155808899137707, disc_loss = 0.007586096202161301
Trained batch 54 in epoch 7, gen_loss = 3.11495567668568, disc_loss = 0.007743844893676313
Trained batch 55 in epoch 7, gen_loss = 3.106665266411645, disc_loss = 0.007744178088614717
Trained batch 56 in epoch 7, gen_loss = 3.1010790624116598, disc_loss = 0.007699210895225406
Trained batch 57 in epoch 7, gen_loss = 3.102979898452759, disc_loss = 0.007613757151532276
Trained batch 58 in epoch 7, gen_loss = 3.100630978406486, disc_loss = 0.007533822634841426
Trained batch 59 in epoch 7, gen_loss = 3.0976927359898885, disc_loss = 0.007521402114070952
Trained batch 60 in epoch 7, gen_loss = 3.098855495452881, disc_loss = 0.007602200728886929
Trained batch 61 in epoch 7, gen_loss = 3.0999976204287623, disc_loss = 0.007558643690220291
Trained batch 62 in epoch 7, gen_loss = 3.1024543292938715, disc_loss = 0.007529436544116054
Trained batch 63 in epoch 7, gen_loss = 3.0994177907705307, disc_loss = 0.007472236960893497
Trained batch 64 in epoch 7, gen_loss = 3.1050532781160793, disc_loss = 0.008363015921070025
Trained batch 65 in epoch 7, gen_loss = 3.102932734922929, disc_loss = 0.009648141056073435
Trained batch 66 in epoch 7, gen_loss = 3.1010306557612632, disc_loss = 0.010817713896507647
Trained batch 67 in epoch 7, gen_loss = 3.103077257380766, disc_loss = 0.01115491013864384
Trained batch 68 in epoch 7, gen_loss = 3.0986510186955547, disc_loss = 0.011235855600756147
Trained batch 69 in epoch 7, gen_loss = 3.096380468777248, disc_loss = 0.011248810469572034
Trained batch 70 in epoch 7, gen_loss = 3.096253519326868, disc_loss = 0.011229923782004436
Trained batch 71 in epoch 7, gen_loss = 3.0932821002271442, disc_loss = 0.011141182460253023
Trained batch 72 in epoch 7, gen_loss = 3.095474716735213, disc_loss = 0.011059597995744585
Trained batch 73 in epoch 7, gen_loss = 3.095503858617834, disc_loss = 0.010958810893793565
Trained batch 74 in epoch 7, gen_loss = 3.0910356616973877, disc_loss = 0.010862997875859341
Trained batch 75 in epoch 7, gen_loss = 3.085963497036382, disc_loss = 0.010751470316838669
Trained batch 76 in epoch 7, gen_loss = 3.08871324650653, disc_loss = 0.010732986522814283
Trained batch 77 in epoch 7, gen_loss = 3.0874338302856836, disc_loss = 0.010667400255512733
Trained batch 78 in epoch 7, gen_loss = 3.083750908887839, disc_loss = 0.01056567245882146
Trained batch 79 in epoch 7, gen_loss = 3.0792349904775618, disc_loss = 0.010489424655679614
Trained batch 80 in epoch 7, gen_loss = 3.076530153368726, disc_loss = 0.010389369018490852
Trained batch 81 in epoch 7, gen_loss = 3.0736454318209394, disc_loss = 0.010279758512496767
Trained batch 82 in epoch 7, gen_loss = 3.0711720679179733, disc_loss = 0.010192828244496003
Trained batch 83 in epoch 7, gen_loss = 3.0699589933667863, disc_loss = 0.010089869577703732
Trained batch 84 in epoch 7, gen_loss = 3.065729996737312, disc_loss = 0.009989284704822828
Trained batch 85 in epoch 7, gen_loss = 3.0597817565119545, disc_loss = 0.009894976005239715
Trained batch 86 in epoch 7, gen_loss = 3.0546946032293913, disc_loss = 0.00980768603508243
Trained batch 87 in epoch 7, gen_loss = 3.0534327057274906, disc_loss = 0.009713023420772515
Trained batch 88 in epoch 7, gen_loss = 3.0477406228526256, disc_loss = 0.009646529168298657
Trained batch 89 in epoch 7, gen_loss = 3.049877985318502, disc_loss = 0.009576212947205122
Trained batch 90 in epoch 7, gen_loss = 3.05175796183911, disc_loss = 0.009554823437081342
Trained batch 91 in epoch 7, gen_loss = 3.050907622212949, disc_loss = 0.009503032426278956
Trained batch 92 in epoch 7, gen_loss = 3.049045490962203, disc_loss = 0.009474309593168717
Trained batch 93 in epoch 7, gen_loss = 3.0521940145086734, disc_loss = 0.009414301354170559
Trained batch 94 in epoch 7, gen_loss = 3.049444140886006, disc_loss = 0.009343030341704818
Trained batch 95 in epoch 7, gen_loss = 3.048677804569403, disc_loss = 0.00927703487711066
Trained batch 96 in epoch 7, gen_loss = 3.0520199918255364, disc_loss = 0.0092035867117787
Trained batch 97 in epoch 7, gen_loss = 3.0507004990869637, disc_loss = 0.00914200011293917
Trained batch 98 in epoch 7, gen_loss = 3.049798938963148, disc_loss = 0.00908596443383945
Trained batch 99 in epoch 7, gen_loss = 3.0519997382164004, disc_loss = 0.009033784993225708
Trained batch 100 in epoch 7, gen_loss = 3.0509267915593514, disc_loss = 0.008977548833613718
Trained batch 101 in epoch 7, gen_loss = 3.0486760209588444, disc_loss = 0.00893519330409118
Trained batch 102 in epoch 7, gen_loss = 3.04808562473186, disc_loss = 0.008871500159939299
Trained batch 103 in epoch 7, gen_loss = 3.0499715827978573, disc_loss = 0.008815164725932006
Trained batch 104 in epoch 7, gen_loss = 3.047086241131737, disc_loss = 0.008759999158792197
Trained batch 105 in epoch 7, gen_loss = 3.0458135717319994, disc_loss = 0.008702568199160456
Trained batch 106 in epoch 7, gen_loss = 3.0429663056525116, disc_loss = 0.008656802322828672
Trained batch 107 in epoch 7, gen_loss = 3.0460106642157943, disc_loss = 0.008600382967550238
Trained batch 108 in epoch 7, gen_loss = 3.0446427787115815, disc_loss = 0.008546059003843148
Trained batch 109 in epoch 7, gen_loss = 3.0448176882483744, disc_loss = 0.008484629702500322
Trained batch 110 in epoch 7, gen_loss = 3.0446362173235095, disc_loss = 0.008428772019960725
Trained batch 111 in epoch 7, gen_loss = 3.042095850620951, disc_loss = 0.008370248826395255
Trained batch 112 in epoch 7, gen_loss = 3.0419775806697067, disc_loss = 0.008311269397896805
Trained batch 113 in epoch 7, gen_loss = 3.043627147088971, disc_loss = 0.008280685201099371
Trained batch 114 in epoch 7, gen_loss = 3.0424180590588112, disc_loss = 0.008258768686336343
Trained batch 115 in epoch 7, gen_loss = 3.0395149136411734, disc_loss = 0.008220486859750837
Trained batch 116 in epoch 7, gen_loss = 3.039394286962656, disc_loss = 0.00820851491059726
Trained batch 117 in epoch 7, gen_loss = 3.0374783459356274, disc_loss = 0.00817775763314754
Trained batch 118 in epoch 7, gen_loss = 3.037748773558801, disc_loss = 0.008131703967424188
Trained batch 119 in epoch 7, gen_loss = 3.034984936316808, disc_loss = 0.008101852640781242
Trained batch 120 in epoch 7, gen_loss = 3.035973515392335, disc_loss = 0.008081264823698246
Trained batch 121 in epoch 7, gen_loss = 3.0356659517913567, disc_loss = 0.008086528796053752
Trained batch 122 in epoch 7, gen_loss = 3.034480125923467, disc_loss = 0.008134087137840083
Trained batch 123 in epoch 7, gen_loss = 3.0321297876296507, disc_loss = 0.008142461578714691
Trained batch 124 in epoch 7, gen_loss = 3.0324025344848633, disc_loss = 0.008098029733635485
Trained batch 125 in epoch 7, gen_loss = 3.0310892510035683, disc_loss = 0.008081064745229447
Trained batch 126 in epoch 7, gen_loss = 3.0325935337487167, disc_loss = 0.008119568955629888
Trained batch 127 in epoch 7, gen_loss = 3.03188194334507, disc_loss = 0.008079414964413445
Trained batch 128 in epoch 7, gen_loss = 3.0305701928545337, disc_loss = 0.00806603832224514
Trained batch 129 in epoch 7, gen_loss = 3.0315489328824556, disc_loss = 0.008044242127261196
Trained batch 130 in epoch 7, gen_loss = 3.0289944929021004, disc_loss = 0.008003885266797631
Trained batch 131 in epoch 7, gen_loss = 3.0297562407724783, disc_loss = 0.007972365489518834
Trained batch 132 in epoch 7, gen_loss = 3.0273640119939818, disc_loss = 0.007933887260041683
Trained batch 133 in epoch 7, gen_loss = 3.0256459481680573, disc_loss = 0.007893852558536038
Trained batch 134 in epoch 7, gen_loss = 3.024776679498178, disc_loss = 0.007864548603107256
Trained batch 135 in epoch 7, gen_loss = 3.024644432698979, disc_loss = 0.007823461624759468
Trained batch 136 in epoch 7, gen_loss = 3.026375377265206, disc_loss = 0.007793840563883258
Trained batch 137 in epoch 7, gen_loss = 3.02700254191523, disc_loss = 0.007777263281320263
Trained batch 138 in epoch 7, gen_loss = 3.0277957127248643, disc_loss = 0.00774307094310015
Trained batch 139 in epoch 7, gen_loss = 3.0313164591789246, disc_loss = 0.007714983578937661
Trained batch 140 in epoch 7, gen_loss = 3.0302554039244955, disc_loss = 0.00767708872857748
Trained batch 141 in epoch 7, gen_loss = 3.030217575355315, disc_loss = 0.007636416500145701
Trained batch 142 in epoch 7, gen_loss = 3.0330799259505907, disc_loss = 0.007723944150953443
Trained batch 143 in epoch 7, gen_loss = 3.0324446906646094, disc_loss = 0.00780683123998137
Trained batch 144 in epoch 7, gen_loss = 3.032299747138188, disc_loss = 0.007849282456626153
Trained batch 145 in epoch 7, gen_loss = 3.0316859451058793, disc_loss = 0.00794275096706944
Trained batch 146 in epoch 7, gen_loss = 3.0310811688299895, disc_loss = 0.008034105843477914
Trained batch 147 in epoch 7, gen_loss = 3.0324083534446924, disc_loss = 0.008047080919700297
Trained batch 148 in epoch 7, gen_loss = 3.032690904284484, disc_loss = 0.008016811518136087
Trained batch 149 in epoch 7, gen_loss = 3.032241295178731, disc_loss = 0.007995644522209962
Trained batch 150 in epoch 7, gen_loss = 3.0323357566302973, disc_loss = 0.007974697418806964
Trained batch 151 in epoch 7, gen_loss = 3.0327953257058797, disc_loss = 0.007957193623664543
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.831721782684326, disc_loss = 0.004193068947643042
Trained batch 1 in epoch 8, gen_loss = 2.9248292446136475, disc_loss = 0.00450011296197772
Trained batch 2 in epoch 8, gen_loss = 3.0105536778767905, disc_loss = 0.003880972508341074
Trained batch 3 in epoch 8, gen_loss = 3.0354371070861816, disc_loss = 0.0033566526835784316
Trained batch 4 in epoch 8, gen_loss = 3.0557933807373048, disc_loss = 0.003095214022323489
Trained batch 5 in epoch 8, gen_loss = 3.007401943206787, disc_loss = 0.0029772726508478322
Trained batch 6 in epoch 8, gen_loss = 3.0152954033442905, disc_loss = 0.002865729121757405
Trained batch 7 in epoch 8, gen_loss = 3.01288104057312, disc_loss = 0.0028992642764933407
Trained batch 8 in epoch 8, gen_loss = 2.970352464252048, disc_loss = 0.0027868469090511403
Trained batch 9 in epoch 8, gen_loss = 2.9486914396286013, disc_loss = 0.0026907636085525153
Trained batch 10 in epoch 8, gen_loss = 2.9817756956273858, disc_loss = 0.0027056276925246825
Trained batch 11 in epoch 8, gen_loss = 3.004545589288076, disc_loss = 0.0026898300663257637
Trained batch 12 in epoch 8, gen_loss = 2.9722423003270078, disc_loss = 0.0027649621300112745
Trained batch 13 in epoch 8, gen_loss = 2.9752392939158847, disc_loss = 0.002900637004391423
Trained batch 14 in epoch 8, gen_loss = 2.9694066524505613, disc_loss = 0.0031132036975274483
Trained batch 15 in epoch 8, gen_loss = 2.96269029378891, disc_loss = 0.0035619222471723333
Trained batch 16 in epoch 8, gen_loss = 2.958980406031889, disc_loss = 0.0043489660328144535
Trained batch 17 in epoch 8, gen_loss = 2.9399700694613986, disc_loss = 0.00533430900476459
Trained batch 18 in epoch 8, gen_loss = 2.9502603380303634, disc_loss = 0.006057604179276447
Trained batch 19 in epoch 8, gen_loss = 2.945366072654724, disc_loss = 0.006178838212508708
Trained batch 20 in epoch 8, gen_loss = 2.9328196389334544, disc_loss = 0.006099647166030038
Trained batch 21 in epoch 8, gen_loss = 2.939097599549727, disc_loss = 0.006043987973085182
Trained batch 22 in epoch 8, gen_loss = 2.9428845903147822, disc_loss = 0.005933558112820206
Trained batch 23 in epoch 8, gen_loss = 2.942553400993347, disc_loss = 0.005893013585591689
Trained batch 24 in epoch 8, gen_loss = 2.9468046188354493, disc_loss = 0.005845554014667869
Trained batch 25 in epoch 8, gen_loss = 2.947464475264916, disc_loss = 0.005874608168736673
Trained batch 26 in epoch 8, gen_loss = 2.9522183824468544, disc_loss = 0.006050060011653436
Trained batch 27 in epoch 8, gen_loss = 2.9481004646846225, disc_loss = 0.0060767602491458616
Trained batch 28 in epoch 8, gen_loss = 2.942835939341578, disc_loss = 0.005985139291091212
Trained batch 29 in epoch 8, gen_loss = 2.9369125604629516, disc_loss = 0.005867393927959105
Trained batch 30 in epoch 8, gen_loss = 2.934877549448321, disc_loss = 0.005719433350849056
Trained batch 31 in epoch 8, gen_loss = 2.93753419816494, disc_loss = 0.00558369524878799
Trained batch 32 in epoch 8, gen_loss = 2.936565059604067, disc_loss = 0.005513519313271073
Trained batch 33 in epoch 8, gen_loss = 2.950696910128874, disc_loss = 0.00547866866691038
Trained batch 34 in epoch 8, gen_loss = 2.9524406160627095, disc_loss = 0.005431747413240373
Trained batch 35 in epoch 8, gen_loss = 2.94973925087187, disc_loss = 0.0053574635239783674
Trained batch 36 in epoch 8, gen_loss = 2.9604364472466544, disc_loss = 0.005305133712780033
Trained batch 37 in epoch 8, gen_loss = 2.9502119767038444, disc_loss = 0.005291962067866207
Trained batch 38 in epoch 8, gen_loss = 2.944678465525309, disc_loss = 0.005252006389081287
Trained batch 39 in epoch 8, gen_loss = 2.9458834767341613, disc_loss = 0.005163035079021938
Trained batch 40 in epoch 8, gen_loss = 2.9444150924682617, disc_loss = 0.005066454069825207
Trained batch 41 in epoch 8, gen_loss = 2.938670521690732, disc_loss = 0.00496666383280951
Trained batch 42 in epoch 8, gen_loss = 2.9393283156461494, disc_loss = 0.004870218601142771
Trained batch 43 in epoch 8, gen_loss = 2.9365049438043074, disc_loss = 0.00478902259121903
Trained batch 44 in epoch 8, gen_loss = 2.936670011944241, disc_loss = 0.004701025367507504
Trained batch 45 in epoch 8, gen_loss = 2.9411247346712197, disc_loss = 0.004630151462903165
Trained batch 46 in epoch 8, gen_loss = 2.941454679407972, disc_loss = 0.004561927152222934
Trained batch 47 in epoch 8, gen_loss = 2.9348271836837134, disc_loss = 0.004500282014002248
Trained batch 48 in epoch 8, gen_loss = 2.934140735742997, disc_loss = 0.00443516263491189
Trained batch 49 in epoch 8, gen_loss = 2.934910707473755, disc_loss = 0.004364108854206279
Trained batch 50 in epoch 8, gen_loss = 2.9362881510865453, disc_loss = 0.00431574345680465
Trained batch 51 in epoch 8, gen_loss = 2.92787490441249, disc_loss = 0.004263813055541295
Trained batch 52 in epoch 8, gen_loss = 2.9289602063736826, disc_loss = 0.004214287398356663
Trained batch 53 in epoch 8, gen_loss = 2.9299444445857294, disc_loss = 0.004202750680700841
Trained batch 54 in epoch 8, gen_loss = 2.9354149861769243, disc_loss = 0.004206806062509052
Trained batch 55 in epoch 8, gen_loss = 2.9348230404513225, disc_loss = 0.004186891673141092
Trained batch 56 in epoch 8, gen_loss = 2.9382550632744504, disc_loss = 0.004208686129443282
Trained batch 57 in epoch 8, gen_loss = 2.936877024584803, disc_loss = 0.004188760598230272
Trained batch 58 in epoch 8, gen_loss = 2.9258942886934443, disc_loss = 0.0044874960874302025
Trained batch 59 in epoch 8, gen_loss = 2.9310216585795086, disc_loss = 0.004539845446318699
Trained batch 60 in epoch 8, gen_loss = 2.9309157308984974, disc_loss = 0.00460157024036696
Trained batch 61 in epoch 8, gen_loss = 2.93206851713119, disc_loss = 0.004643889178799826
Trained batch 62 in epoch 8, gen_loss = 2.936407176275102, disc_loss = 0.004649555640450369
Trained batch 63 in epoch 8, gen_loss = 2.9396935366094112, disc_loss = 0.004633188463230908
Trained batch 64 in epoch 8, gen_loss = 2.9399281098292422, disc_loss = 0.0046072290932688
Trained batch 65 in epoch 8, gen_loss = 2.942194786938754, disc_loss = 0.004596534602266426
Trained batch 66 in epoch 8, gen_loss = 2.9469418312186626, disc_loss = 0.004618304497527598
Trained batch 67 in epoch 8, gen_loss = 2.950729093130897, disc_loss = 0.004637532573884956
Trained batch 68 in epoch 8, gen_loss = 2.951391589814338, disc_loss = 0.004634795724785468
Trained batch 69 in epoch 8, gen_loss = 2.9537836619785853, disc_loss = 0.004613236914156005
Trained batch 70 in epoch 8, gen_loss = 2.951429830470555, disc_loss = 0.004598578245503644
Trained batch 71 in epoch 8, gen_loss = 2.9514919420083365, disc_loss = 0.004571404053422157
Trained batch 72 in epoch 8, gen_loss = 2.9505102569109773, disc_loss = 0.004535351638293072
Trained batch 73 in epoch 8, gen_loss = 2.9494710677378886, disc_loss = 0.004530528938630596
Trained batch 74 in epoch 8, gen_loss = 2.9454653708140057, disc_loss = 0.004529997849992166
Trained batch 75 in epoch 8, gen_loss = 2.946316326919355, disc_loss = 0.004525545905619909
Trained batch 76 in epoch 8, gen_loss = 2.946967115649929, disc_loss = 0.004499215984190875
Trained batch 77 in epoch 8, gen_loss = 2.940281461446713, disc_loss = 0.004463578145264481
Trained batch 78 in epoch 8, gen_loss = 2.942089328282996, disc_loss = 0.004420519191211773
Trained batch 79 in epoch 8, gen_loss = 2.9448679387569427, disc_loss = 0.004376805813080864
Trained batch 80 in epoch 8, gen_loss = 2.9438022978511857, disc_loss = 0.004336680086576782
Trained batch 81 in epoch 8, gen_loss = 2.9419438141148264, disc_loss = 0.004297379857900257
Trained batch 82 in epoch 8, gen_loss = 2.9394842975110893, disc_loss = 0.004256783610810133
Trained batch 83 in epoch 8, gen_loss = 2.9418303938139054, disc_loss = 0.004215531184204987
Trained batch 84 in epoch 8, gen_loss = 2.942732603409711, disc_loss = 0.004187758297056836
Trained batch 85 in epoch 8, gen_loss = 2.943979205087174, disc_loss = 0.004167434104263436
Trained batch 86 in epoch 8, gen_loss = 2.9435532147856964, disc_loss = 0.004142583861690143
Trained batch 87 in epoch 8, gen_loss = 2.9396581676873295, disc_loss = 0.004120968266347932
Trained batch 88 in epoch 8, gen_loss = 2.9401435985993802, disc_loss = 0.004091408019990064
Trained batch 89 in epoch 8, gen_loss = 2.941548458735148, disc_loss = 0.004069517296738922
Trained batch 90 in epoch 8, gen_loss = 2.943612800849663, disc_loss = 0.004044515415923772
Trained batch 91 in epoch 8, gen_loss = 2.946205302425053, disc_loss = 0.004017981366537835
Trained batch 92 in epoch 8, gen_loss = 2.9446997693789903, disc_loss = 0.004005925797466789
Trained batch 93 in epoch 8, gen_loss = 2.9465341720175235, disc_loss = 0.003979296527525529
Trained batch 94 in epoch 8, gen_loss = 2.9475990998117547, disc_loss = 0.00394908264401908
Trained batch 95 in epoch 8, gen_loss = 2.9458007564147315, disc_loss = 0.003918277910997858
Trained batch 96 in epoch 8, gen_loss = 2.946826448145601, disc_loss = 0.003901047357262026
Trained batch 97 in epoch 8, gen_loss = 2.9441952827025433, disc_loss = 0.003893252705670513
Trained batch 98 in epoch 8, gen_loss = 2.9469503128167354, disc_loss = 0.003883490474151466
Trained batch 99 in epoch 8, gen_loss = 2.9458806896209717, disc_loss = 0.003859932260820642
Trained batch 100 in epoch 8, gen_loss = 2.946376316618211, disc_loss = 0.0038344393113148535
Trained batch 101 in epoch 8, gen_loss = 2.9458814298405365, disc_loss = 0.0038221573203747325
Trained batch 102 in epoch 8, gen_loss = 2.9447280018075, disc_loss = 0.0038107483143674085
Trained batch 103 in epoch 8, gen_loss = 2.9451466454909396, disc_loss = 0.003792717298403239
Trained batch 104 in epoch 8, gen_loss = 2.9440170447031657, disc_loss = 0.0037753877451732047
Trained batch 105 in epoch 8, gen_loss = 2.942913539004776, disc_loss = 0.0037598809960983554
Trained batch 106 in epoch 8, gen_loss = 2.9444824535155965, disc_loss = 0.003743730731325868
Trained batch 107 in epoch 8, gen_loss = 2.944208142934022, disc_loss = 0.0037174785819068484
Trained batch 108 in epoch 8, gen_loss = 2.94210352810151, disc_loss = 0.0036962837778638465
Trained batch 109 in epoch 8, gen_loss = 2.9406428228725088, disc_loss = 0.0036819344804495235
Trained batch 110 in epoch 8, gen_loss = 2.941416751157056, disc_loss = 0.003669968084117549
Trained batch 111 in epoch 8, gen_loss = 2.9423201573746547, disc_loss = 0.003656086548809461
Trained batch 112 in epoch 8, gen_loss = 2.9409980710628814, disc_loss = 0.0036470753308674073
Trained batch 113 in epoch 8, gen_loss = 2.9392414825004445, disc_loss = 0.0036279932619276735
Trained batch 114 in epoch 8, gen_loss = 2.940390232334966, disc_loss = 0.003608135643678353
Trained batch 115 in epoch 8, gen_loss = 2.93894631081614, disc_loss = 0.0035931639195668735
Trained batch 116 in epoch 8, gen_loss = 2.9367364003108096, disc_loss = 0.003573846229666478
Trained batch 117 in epoch 8, gen_loss = 2.936989020493071, disc_loss = 0.003556026388018913
Trained batch 118 in epoch 8, gen_loss = 2.9347143613991618, disc_loss = 0.0035455916091572774
Trained batch 119 in epoch 8, gen_loss = 2.934653033812841, disc_loss = 0.0035487135809186537
Trained batch 120 in epoch 8, gen_loss = 2.936014827617929, disc_loss = 0.0035300576806353203
Trained batch 121 in epoch 8, gen_loss = 2.9346683533465274, disc_loss = 0.003510425093900565
Trained batch 122 in epoch 8, gen_loss = 2.9355277898834973, disc_loss = 0.003492247242749313
Trained batch 123 in epoch 8, gen_loss = 2.93679488858869, disc_loss = 0.003474117907781845
Trained batch 124 in epoch 8, gen_loss = 2.9352433166503906, disc_loss = 0.003457952623721212
Trained batch 125 in epoch 8, gen_loss = 2.9366418388154774, disc_loss = 0.003447217899577929
Trained batch 126 in epoch 8, gen_loss = 2.9400233922042247, disc_loss = 0.003435104828250895
Trained batch 127 in epoch 8, gen_loss = 2.940207626670599, disc_loss = 0.003426507505992049
Trained batch 128 in epoch 8, gen_loss = 2.938879663630049, disc_loss = 0.0034094539542263735
Trained batch 129 in epoch 8, gen_loss = 2.93901467690101, disc_loss = 0.0033971134326958026
Trained batch 130 in epoch 8, gen_loss = 2.9385520847699116, disc_loss = 0.003401108758385428
Trained batch 131 in epoch 8, gen_loss = 2.9361461400985718, disc_loss = 0.0034287579919416175
Trained batch 132 in epoch 8, gen_loss = 2.934431993871703, disc_loss = 0.0034428337747336164
Trained batch 133 in epoch 8, gen_loss = 2.935750310100726, disc_loss = 0.0034357330578539185
Trained batch 134 in epoch 8, gen_loss = 2.9344812746401185, disc_loss = 0.0034182564057927164
Trained batch 135 in epoch 8, gen_loss = 2.9337773778859306, disc_loss = 0.003400488389803179
Trained batch 136 in epoch 8, gen_loss = 2.9327556147192517, disc_loss = 0.0033939216149134737
Trained batch 137 in epoch 8, gen_loss = 2.9319869176201196, disc_loss = 0.003379445158171238
Trained batch 138 in epoch 8, gen_loss = 2.932293843879974, disc_loss = 0.0033670805671868727
Trained batch 139 in epoch 8, gen_loss = 2.9313577617917743, disc_loss = 0.0033545285143190993
Trained batch 140 in epoch 8, gen_loss = 2.929804314958288, disc_loss = 0.0033384977145523415
Trained batch 141 in epoch 8, gen_loss = 2.929539507543537, disc_loss = 0.003323674401593014
Trained batch 142 in epoch 8, gen_loss = 2.931378201171235, disc_loss = 0.003309466491430555
Trained batch 143 in epoch 8, gen_loss = 2.930461663338873, disc_loss = 0.0032978091245846977
Trained batch 144 in epoch 8, gen_loss = 2.9307453237730883, disc_loss = 0.0032932975213043393
Trained batch 145 in epoch 8, gen_loss = 2.9291003909829545, disc_loss = 0.003289559850874293
Trained batch 146 in epoch 8, gen_loss = 2.9293780213310603, disc_loss = 0.0032810408754280584
Trained batch 147 in epoch 8, gen_loss = 2.9283185730109342, disc_loss = 0.0032684735012259588
Trained batch 148 in epoch 8, gen_loss = 2.9312666838601134, disc_loss = 0.00325533672471862
Trained batch 149 in epoch 8, gen_loss = 2.928503538767497, disc_loss = 0.0032500712849044553
Trained batch 150 in epoch 8, gen_loss = 2.9273069631184963, disc_loss = 0.003242763061159667
Trained batch 151 in epoch 8, gen_loss = 2.9303835583360573, disc_loss = 0.003231013085353066
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.76507568359375, disc_loss = 0.001790615264326334
Trained batch 1 in epoch 9, gen_loss = 2.998129367828369, disc_loss = 0.002191998646594584
Trained batch 2 in epoch 9, gen_loss = 2.9446208477020264, disc_loss = 0.0027024076165010533
Trained batch 3 in epoch 9, gen_loss = 2.976859390735626, disc_loss = 0.0025891874101944268
Trained batch 4 in epoch 9, gen_loss = 2.9602126598358156, disc_loss = 0.0023135671624913813
Trained batch 5 in epoch 9, gen_loss = 2.948294679323832, disc_loss = 0.0021097701780187585
Trained batch 6 in epoch 9, gen_loss = 2.9405669144221713, disc_loss = 0.0020083648019603322
Trained batch 7 in epoch 9, gen_loss = 2.9478544890880585, disc_loss = 0.0019948170374846086
Trained batch 8 in epoch 9, gen_loss = 2.9599779182010226, disc_loss = 0.0019414921342912647
Trained batch 9 in epoch 9, gen_loss = 2.9442862272262573, disc_loss = 0.001931059593334794
Trained batch 10 in epoch 9, gen_loss = 2.953537095676769, disc_loss = 0.0019678621214221825
Trained batch 11 in epoch 9, gen_loss = 2.9332984487215676, disc_loss = 0.0019759503193199635
Trained batch 12 in epoch 9, gen_loss = 2.9254285922417274, disc_loss = 0.0019672813270097743
Trained batch 13 in epoch 9, gen_loss = 2.910682031086513, disc_loss = 0.0019318550143257848
Trained batch 14 in epoch 9, gen_loss = 2.9012450853983562, disc_loss = 0.0019429726293310524
Trained batch 15 in epoch 9, gen_loss = 2.896700546145439, disc_loss = 0.0019410577297094278
Trained batch 16 in epoch 9, gen_loss = 2.891830290065092, disc_loss = 0.0019492956138599444
Trained batch 17 in epoch 9, gen_loss = 2.9113838540183172, disc_loss = 0.0019188173981900844
Trained batch 18 in epoch 9, gen_loss = 2.906063393542641, disc_loss = 0.001912625347215094
Trained batch 19 in epoch 9, gen_loss = 2.9115487933158875, disc_loss = 0.0019130769651383162
Trained batch 20 in epoch 9, gen_loss = 2.9055810542333695, disc_loss = 0.0019258423264892329
Trained batch 21 in epoch 9, gen_loss = 2.900083834474737, disc_loss = 0.0020192080516029487
Trained batch 22 in epoch 9, gen_loss = 2.8929484305174453, disc_loss = 0.002141356144262397
Trained batch 23 in epoch 9, gen_loss = 2.892593284447988, disc_loss = 0.0023529037716798484
Trained batch 24 in epoch 9, gen_loss = 2.9000928020477295, disc_loss = 0.002603205684572458
Trained batch 25 in epoch 9, gen_loss = 2.9141397017699022, disc_loss = 0.0028289747603524188
Trained batch 26 in epoch 9, gen_loss = 2.9122645501737243, disc_loss = 0.0028765424568619993
Trained batch 27 in epoch 9, gen_loss = 2.9242487464632307, disc_loss = 0.0028449625741424306
Trained batch 28 in epoch 9, gen_loss = 2.9161928275535844, disc_loss = 0.002835557450829395
Trained batch 29 in epoch 9, gen_loss = 2.921028153101603, disc_loss = 0.002949138645393153
Trained batch 30 in epoch 9, gen_loss = 2.917663343491093, disc_loss = 0.0029868981425440117
Trained batch 31 in epoch 9, gen_loss = 2.916541337966919, disc_loss = 0.0029553749918704852
Trained batch 32 in epoch 9, gen_loss = 2.9204690022902056, disc_loss = 0.002969275073458751
Trained batch 33 in epoch 9, gen_loss = 2.9136040140600765, disc_loss = 0.002948320669341175
Trained batch 34 in epoch 9, gen_loss = 2.9280441079820907, disc_loss = 0.0029165588751701374
Trained batch 35 in epoch 9, gen_loss = 2.9230365024672613, disc_loss = 0.0028805778581752544
Trained batch 36 in epoch 9, gen_loss = 2.9293182025084623, disc_loss = 0.002843303926842841
Trained batch 37 in epoch 9, gen_loss = 2.9269110215337655, disc_loss = 0.0028042087919617955
Trained batch 38 in epoch 9, gen_loss = 2.93243145942688, disc_loss = 0.002769263714957887
Trained batch 39 in epoch 9, gen_loss = 2.9358582198619843, disc_loss = 0.0027332889672834425
Trained batch 40 in epoch 9, gen_loss = 2.928149205882375, disc_loss = 0.0026945666319168195
Trained batch 41 in epoch 9, gen_loss = 2.9328825076421103, disc_loss = 0.002684618662377553
Trained batch 42 in epoch 9, gen_loss = 2.932850765627484, disc_loss = 0.0026594565282467494
Trained batch 43 in epoch 9, gen_loss = 2.934230316768993, disc_loss = 0.0026531621591526677
Trained batch 44 in epoch 9, gen_loss = 2.9339437166849773, disc_loss = 0.0026216870147941843
Trained batch 45 in epoch 9, gen_loss = 2.9346306220344873, disc_loss = 0.002600225999586932
Trained batch 46 in epoch 9, gen_loss = 2.9348428756632705, disc_loss = 0.0025862661125931018
Trained batch 47 in epoch 9, gen_loss = 2.935571869214376, disc_loss = 0.00255388937027116
Trained batch 48 in epoch 9, gen_loss = 2.9324568874981938, disc_loss = 0.002555343700211723
Trained batch 49 in epoch 9, gen_loss = 2.9370618152618406, disc_loss = 0.002545801450032741
Trained batch 50 in epoch 9, gen_loss = 2.9405562176423916, disc_loss = 0.0025239804481137908
Trained batch 51 in epoch 9, gen_loss = 2.93659468797537, disc_loss = 0.002504913577397999
Trained batch 52 in epoch 9, gen_loss = 2.939876560894948, disc_loss = 0.002475172421842251
Trained batch 53 in epoch 9, gen_loss = 2.9405307549017445, disc_loss = 0.0024517346151966463
Trained batch 54 in epoch 9, gen_loss = 2.937651508504694, disc_loss = 0.0024292345603250643
Trained batch 55 in epoch 9, gen_loss = 2.9409482862268175, disc_loss = 0.002407007337231854
Trained batch 56 in epoch 9, gen_loss = 2.940065952769497, disc_loss = 0.002386270103191859
Trained batch 57 in epoch 9, gen_loss = 2.938476566610665, disc_loss = 0.002378227550472165
Trained batch 58 in epoch 9, gen_loss = 2.9382065352746998, disc_loss = 0.0023799656211572176
Trained batch 59 in epoch 9, gen_loss = 2.9370222091674805, disc_loss = 0.002369824005290866
Trained batch 60 in epoch 9, gen_loss = 2.938104664693113, disc_loss = 0.0023519666655538755
Trained batch 61 in epoch 9, gen_loss = 2.9403113472846245, disc_loss = 0.0023448008202737376
Trained batch 62 in epoch 9, gen_loss = 2.9397066964043512, disc_loss = 0.002344836089168749
Trained batch 63 in epoch 9, gen_loss = 2.94567933306098, disc_loss = 0.0023444598591595422
Trained batch 64 in epoch 9, gen_loss = 2.94799390572768, disc_loss = 0.0023387631580520135
Trained batch 65 in epoch 9, gen_loss = 2.945019335457773, disc_loss = 0.00233266496268863
Trained batch 66 in epoch 9, gen_loss = 2.943222255849127, disc_loss = 0.0023184364432218803
Trained batch 67 in epoch 9, gen_loss = 2.942197519190171, disc_loss = 0.002314981394995223
Trained batch 68 in epoch 9, gen_loss = 2.9444453439850737, disc_loss = 0.0023119620290463386
Trained batch 69 in epoch 9, gen_loss = 2.9428397348948887, disc_loss = 0.0023092141674299327
Trained batch 70 in epoch 9, gen_loss = 2.9451625212817123, disc_loss = 0.002292431835216326
Trained batch 71 in epoch 9, gen_loss = 2.9396578901343875, disc_loss = 0.002295341129259517
Trained batch 72 in epoch 9, gen_loss = 2.9390798300912935, disc_loss = 0.0022886740585967695
Trained batch 73 in epoch 9, gen_loss = 2.9388992045376754, disc_loss = 0.0022871346131118167
Trained batch 74 in epoch 9, gen_loss = 2.9421042887369793, disc_loss = 0.0022793046773100893
Trained batch 75 in epoch 9, gen_loss = 2.9415188933673657, disc_loss = 0.002273200452021372
Trained batch 76 in epoch 9, gen_loss = 2.939460447856358, disc_loss = 0.0022724717144866464
Trained batch 77 in epoch 9, gen_loss = 2.9380616408128004, disc_loss = 0.002265254686323878
Trained batch 78 in epoch 9, gen_loss = 2.9406377695783785, disc_loss = 0.002264430982213986
Trained batch 79 in epoch 9, gen_loss = 2.938120353221893, disc_loss = 0.0022731004690285774
Trained batch 80 in epoch 9, gen_loss = 2.9382699212910217, disc_loss = 0.0023119470311535727
Trained batch 81 in epoch 9, gen_loss = 2.938395157092955, disc_loss = 0.002311278321984701
Trained batch 82 in epoch 9, gen_loss = 2.9403443566287857, disc_loss = 0.0023008116299331367
Trained batch 83 in epoch 9, gen_loss = 2.9377448729106357, disc_loss = 0.002293021522096491
Trained batch 84 in epoch 9, gen_loss = 2.9390004915349626, disc_loss = 0.00229579590343158
Trained batch 85 in epoch 9, gen_loss = 2.937902336896852, disc_loss = 0.002308596140802513
Trained batch 86 in epoch 9, gen_loss = 2.9350591226555833, disc_loss = 0.002313391231910336
Trained batch 87 in epoch 9, gen_loss = 2.937844531102614, disc_loss = 0.0023297210586447777
Trained batch 88 in epoch 9, gen_loss = 2.9385338874345415, disc_loss = 0.0023608324444967877
Trained batch 89 in epoch 9, gen_loss = 2.9363203843434653, disc_loss = 0.002409332536626607
Trained batch 90 in epoch 9, gen_loss = 2.9383277840666717, disc_loss = 0.0024161394263341367
Trained batch 91 in epoch 9, gen_loss = 2.9378635727840923, disc_loss = 0.002404303891007262
Trained batch 92 in epoch 9, gen_loss = 2.9385177909687, disc_loss = 0.0023913032235076993
Trained batch 93 in epoch 9, gen_loss = 2.9349453981886517, disc_loss = 0.002377025202223833
Trained batch 94 in epoch 9, gen_loss = 2.9364368463817394, disc_loss = 0.0023761864053085447
Trained batch 95 in epoch 9, gen_loss = 2.936496722201506, disc_loss = 0.002384555148940611
Trained batch 96 in epoch 9, gen_loss = 2.9379098710325575, disc_loss = 0.0023869835236349827
Trained batch 97 in epoch 9, gen_loss = 2.935851834258255, disc_loss = 0.002380677080732219
Trained batch 98 in epoch 9, gen_loss = 2.9330015929058346, disc_loss = 0.00238328484460862
Trained batch 99 in epoch 9, gen_loss = 2.929179222583771, disc_loss = 0.002382620752323419
Trained batch 100 in epoch 9, gen_loss = 2.9272636800709337, disc_loss = 0.0023839837170694725
Trained batch 101 in epoch 9, gen_loss = 2.9292509742811617, disc_loss = 0.0023949294757353618
Trained batch 102 in epoch 9, gen_loss = 2.929761127360816, disc_loss = 0.0024216391250165632
Trained batch 103 in epoch 9, gen_loss = 2.929492336053115, disc_loss = 0.0024842246896766415
Trained batch 104 in epoch 9, gen_loss = 2.9280617895580474, disc_loss = 0.0025782521348446607
Trained batch 105 in epoch 9, gen_loss = 2.9269464735714896, disc_loss = 0.0027009202760450964
Trained batch 106 in epoch 9, gen_loss = 2.926538587730622, disc_loss = 0.0028314295455500065
Trained batch 107 in epoch 9, gen_loss = 2.925800592811019, disc_loss = 0.0029602179333947046
Trained batch 108 in epoch 9, gen_loss = 2.9246486961294753, disc_loss = 0.002975546611780557
Trained batch 109 in epoch 9, gen_loss = 2.922498178482056, disc_loss = 0.0029575614681975407
Trained batch 110 in epoch 9, gen_loss = 2.9209423494768574, disc_loss = 0.002942093031329883
Trained batch 111 in epoch 9, gen_loss = 2.9198575743607114, disc_loss = 0.002928807493715015
Trained batch 112 in epoch 9, gen_loss = 2.922400520966116, disc_loss = 0.002913971515001515
Trained batch 113 in epoch 9, gen_loss = 2.921397376478764, disc_loss = 0.002904461236188613
Trained batch 114 in epoch 9, gen_loss = 2.920431978806205, disc_loss = 0.002894272698777849
Trained batch 115 in epoch 9, gen_loss = 2.9197524724335504, disc_loss = 0.0028793414289950683
Trained batch 116 in epoch 9, gen_loss = 2.9197974062373495, disc_loss = 0.002862826589709864
Trained batch 117 in epoch 9, gen_loss = 2.920245334253473, disc_loss = 0.0028509717223518605
Trained batch 118 in epoch 9, gen_loss = 2.920179399121709, disc_loss = 0.0028349638837311384
Trained batch 119 in epoch 9, gen_loss = 2.9207717219988507, disc_loss = 0.0028221576450353798
Trained batch 120 in epoch 9, gen_loss = 2.9201011835050976, disc_loss = 0.0028110383889514735
Trained batch 121 in epoch 9, gen_loss = 2.9191591837367072, disc_loss = 0.0027952879976450664
Trained batch 122 in epoch 9, gen_loss = 2.9189465898808424, disc_loss = 0.002783005435315029
Trained batch 123 in epoch 9, gen_loss = 2.92067233016414, disc_loss = 0.0027753752027262725
Trained batch 124 in epoch 9, gen_loss = 2.9247600498199464, disc_loss = 0.0027711693281307816
Trained batch 125 in epoch 9, gen_loss = 2.924937399606856, disc_loss = 0.0027604386929260005
Trained batch 126 in epoch 9, gen_loss = 2.9255385624142143, disc_loss = 0.0027495612909166716
Trained batch 127 in epoch 9, gen_loss = 2.927116323262453, disc_loss = 0.002739075941462943
Trained batch 128 in epoch 9, gen_loss = 2.925576396690783, disc_loss = 0.002729994931633678
Trained batch 129 in epoch 9, gen_loss = 2.9244830479988684, disc_loss = 0.002723861546613849
Trained batch 130 in epoch 9, gen_loss = 2.9232781242778283, disc_loss = 0.0027155592470636007
Trained batch 131 in epoch 9, gen_loss = 2.9267255140073374, disc_loss = 0.002710673165204229
Trained batch 132 in epoch 9, gen_loss = 2.9255054498973645, disc_loss = 0.0027070559633027456
Trained batch 133 in epoch 9, gen_loss = 2.9227931659613082, disc_loss = 0.002695562780153618
Trained batch 134 in epoch 9, gen_loss = 2.9233801223613596, disc_loss = 0.002682574344281521
Trained batch 135 in epoch 9, gen_loss = 2.923675419653163, disc_loss = 0.0026688340239000834
Trained batch 136 in epoch 9, gen_loss = 2.9224821007164725, disc_loss = 0.0026571875124537544
Trained batch 137 in epoch 9, gen_loss = 2.921280807343082, disc_loss = 0.0026453955641414536
Trained batch 138 in epoch 9, gen_loss = 2.922990982481044, disc_loss = 0.002639377497642455
Trained batch 139 in epoch 9, gen_loss = 2.920005931173052, disc_loss = 0.002633530387538485
Trained batch 140 in epoch 9, gen_loss = 2.9182893993161247, disc_loss = 0.002627042015264775
Trained batch 141 in epoch 9, gen_loss = 2.9196111299622225, disc_loss = 0.0026257491435258793
Trained batch 142 in epoch 9, gen_loss = 2.9201999427555325, disc_loss = 0.002628348147825475
Trained batch 143 in epoch 9, gen_loss = 2.920482638809416, disc_loss = 0.0026208731817152714
Trained batch 144 in epoch 9, gen_loss = 2.9212592388021537, disc_loss = 0.0026100470287050924
Trained batch 145 in epoch 9, gen_loss = 2.9208038375802237, disc_loss = 0.0025990178927377326
Trained batch 146 in epoch 9, gen_loss = 2.922557473993626, disc_loss = 0.0025873943239919286
Trained batch 147 in epoch 9, gen_loss = 2.9225974727321313, disc_loss = 0.002575897264791451
Trained batch 148 in epoch 9, gen_loss = 2.921126143244289, disc_loss = 0.002564948813164694
Trained batch 149 in epoch 9, gen_loss = 2.922660608291626, disc_loss = 0.0025587166845798493
Trained batch 150 in epoch 9, gen_loss = 2.9218849867384953, disc_loss = 0.002555614732057843
Trained batch 151 in epoch 9, gen_loss = 2.923911342495366, disc_loss = 0.0025450391974453325
Testing Epoch 9
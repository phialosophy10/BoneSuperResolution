/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 3.5687389373779297, disc_loss = 0.6696922183036804
Trained batch 1 in epoch 0, gen_loss = 3.360426187515259, disc_loss = 0.6004595756530762
Trained batch 2 in epoch 0, gen_loss = 3.298853079477946, disc_loss = 0.6536373297373453
Trained batch 3 in epoch 0, gen_loss = 3.1551568508148193, disc_loss = 0.7070913761854172
Trained batch 4 in epoch 0, gen_loss = 3.037818431854248, disc_loss = 0.63071608543396
Trained batch 5 in epoch 0, gen_loss = 2.970658818880717, disc_loss = 0.5876289407412211
Trained batch 6 in epoch 0, gen_loss = 2.9212650571550642, disc_loss = 0.5419551602431706
Trained batch 7 in epoch 0, gen_loss = 2.8430278301239014, disc_loss = 0.5092822723090649
Trained batch 8 in epoch 0, gen_loss = 2.802937110265096, disc_loss = 0.4742507603433397
Trained batch 9 in epoch 0, gen_loss = 2.785427141189575, disc_loss = 0.4452270269393921
Trained batch 10 in epoch 0, gen_loss = 2.7740133675661953, disc_loss = 0.4192713729359887
Trained batch 11 in epoch 0, gen_loss = 2.767184317111969, disc_loss = 0.39683529486258823
Trained batch 12 in epoch 0, gen_loss = 2.7715489864349365, disc_loss = 0.3771440042899205
Trained batch 13 in epoch 0, gen_loss = 2.769164596285139, disc_loss = 0.3597154234136854
Trained batch 14 in epoch 0, gen_loss = 2.7417134761810305, disc_loss = 0.3440235808491707
Trained batch 15 in epoch 0, gen_loss = 2.7407968640327454, disc_loss = 0.32938822032883763
Trained batch 16 in epoch 0, gen_loss = 2.7540894396164837, disc_loss = 0.3170742195318727
Trained batch 17 in epoch 0, gen_loss = 2.753508355882433, disc_loss = 0.30484039874540436
Trained batch 18 in epoch 0, gen_loss = 2.7538284628014815, disc_loss = 0.29330321126862574
Trained batch 19 in epoch 0, gen_loss = 2.7591172099113463, disc_loss = 0.2826693285256624
Trained batch 20 in epoch 0, gen_loss = 2.7561775048573813, disc_loss = 0.274154363998345
Trained batch 21 in epoch 0, gen_loss = 2.7472145557403564, disc_loss = 0.2684767208993435
Trained batch 22 in epoch 0, gen_loss = 2.7547058022540547, disc_loss = 0.2656470605212709
Trained batch 23 in epoch 0, gen_loss = 2.7538191378116608, disc_loss = 0.2606387122844656
Trained batch 24 in epoch 0, gen_loss = 2.7596931743621824, disc_loss = 0.2538721114397049
Trained batch 25 in epoch 0, gen_loss = 2.7588070906125584, disc_loss = 0.24969036475970194
Trained batch 26 in epoch 0, gen_loss = 2.7736509641011557, disc_loss = 0.24993990913585382
Trained batch 27 in epoch 0, gen_loss = 2.7797177008220126, disc_loss = 0.24410747098071234
Trained batch 28 in epoch 0, gen_loss = 2.776139127797094, disc_loss = 0.2382175244134048
Trained batch 29 in epoch 0, gen_loss = 2.7816017786661784, disc_loss = 0.23271676227450372
Trained batch 30 in epoch 0, gen_loss = 2.7808544481954267, disc_loss = 0.22770089584012185
Trained batch 31 in epoch 0, gen_loss = 2.7751570716500282, disc_loss = 0.2236042022705078
Trained batch 32 in epoch 0, gen_loss = 2.777101653994936, disc_loss = 0.21907873474287265
Trained batch 33 in epoch 0, gen_loss = 2.7781877517700195, disc_loss = 0.21443201042711735
Trained batch 34 in epoch 0, gen_loss = 2.778189836229597, disc_loss = 0.21012512179357665
Trained batch 35 in epoch 0, gen_loss = 2.7816618283589682, disc_loss = 0.2060987948336535
Trained batch 36 in epoch 0, gen_loss = 2.7858618272317424, disc_loss = 0.2023408583088501
Trained batch 37 in epoch 0, gen_loss = 2.7858450851942362, disc_loss = 0.19918798469007015
Trained batch 38 in epoch 0, gen_loss = 2.7823724379906287, disc_loss = 0.1956936461994281
Trained batch 39 in epoch 0, gen_loss = 2.7871775388717652, disc_loss = 0.19199334140866994
Trained batch 40 in epoch 0, gen_loss = 2.7853831081855587, disc_loss = 0.18859190330272768
Trained batch 41 in epoch 0, gen_loss = 2.7813112281617665, disc_loss = 0.18540718255653268
Trained batch 42 in epoch 0, gen_loss = 2.786863144053969, disc_loss = 0.18212975310378296
Trained batch 43 in epoch 0, gen_loss = 2.7843652042475613, disc_loss = 0.17927324983545326
Trained batch 44 in epoch 0, gen_loss = 2.79034079975552, disc_loss = 0.17697570961382653
Trained batch 45 in epoch 0, gen_loss = 2.7896701615789663, disc_loss = 0.17513411937524442
Trained batch 46 in epoch 0, gen_loss = 2.8054342016260674, disc_loss = 0.1745500845953505
Trained batch 47 in epoch 0, gen_loss = 2.8128278901179633, disc_loss = 0.17659213851826885
Trained batch 48 in epoch 0, gen_loss = 2.8145803869987023, disc_loss = 0.1813164081956659
Trained batch 49 in epoch 0, gen_loss = 2.821347508430481, disc_loss = 0.18741798661649228
Trained batch 50 in epoch 0, gen_loss = 2.8322376503663906, disc_loss = 0.19382392680820296
Trained batch 51 in epoch 0, gen_loss = 2.8393398110683146, disc_loss = 0.1936014213670905
Trained batch 52 in epoch 0, gen_loss = 2.834304008843764, disc_loss = 0.19134804824332022
Trained batch 53 in epoch 0, gen_loss = 2.835455382311786, disc_loss = 0.18896281574335363
Trained batch 54 in epoch 0, gen_loss = 2.8376519723372025, disc_loss = 0.18628734153780072
Trained batch 55 in epoch 0, gen_loss = 2.8390947580337524, disc_loss = 0.18361793092585035
Trained batch 56 in epoch 0, gen_loss = 2.8386068093149284, disc_loss = 0.18091213977650591
Trained batch 57 in epoch 0, gen_loss = 2.8404867566865066, disc_loss = 0.17819172259548616
Trained batch 58 in epoch 0, gen_loss = 2.8405508510137008, disc_loss = 0.17557565498528843
Trained batch 59 in epoch 0, gen_loss = 2.8413895686467487, disc_loss = 0.17303575199718277
Trained batch 60 in epoch 0, gen_loss = 2.8431195939173466, disc_loss = 0.1705360293815859
Trained batch 61 in epoch 0, gen_loss = 2.844465174982625, disc_loss = 0.16810708180550607
Trained batch 62 in epoch 0, gen_loss = 2.8479210346464128, disc_loss = 0.16573366061562583
Trained batch 63 in epoch 0, gen_loss = 2.852466445416212, disc_loss = 0.16341241681948304
Trained batch 64 in epoch 0, gen_loss = 2.857052465585562, disc_loss = 0.16118393483070226
Trained batch 65 in epoch 0, gen_loss = 2.8531584017204517, disc_loss = 0.1591114325053764
Trained batch 66 in epoch 0, gen_loss = 2.8479122332672575, disc_loss = 0.15719191957987957
Trained batch 67 in epoch 0, gen_loss = 2.8486000790315518, disc_loss = 0.1551867986974471
Trained batch 68 in epoch 0, gen_loss = 2.845575505408688, disc_loss = 0.15331785780364188
Trained batch 69 in epoch 0, gen_loss = 2.846146767480033, disc_loss = 0.15141571052372454
Trained batch 70 in epoch 0, gen_loss = 2.8464238106364936, disc_loss = 0.14953843409746465
Trained batch 71 in epoch 0, gen_loss = 2.8466751045650907, disc_loss = 0.1476863189600408
Trained batch 72 in epoch 0, gen_loss = 2.849212558302161, disc_loss = 0.1458861221852776
Trained batch 73 in epoch 0, gen_loss = 2.8488054694356144, disc_loss = 0.14418084768427386
Trained batch 74 in epoch 0, gen_loss = 2.8508842309316, disc_loss = 0.14248293121655783
Trained batch 75 in epoch 0, gen_loss = 2.852933667208019, disc_loss = 0.1408141111023724
Trained batch 76 in epoch 0, gen_loss = 2.855247568774533, disc_loss = 0.13917468647871697
Trained batch 77 in epoch 0, gen_loss = 2.8551795268670106, disc_loss = 0.13757530702516818
Trained batch 78 in epoch 0, gen_loss = 2.857226637345326, disc_loss = 0.1360225351763111
Trained batch 79 in epoch 0, gen_loss = 2.858973225951195, disc_loss = 0.13450677611399442
Trained batch 80 in epoch 0, gen_loss = 2.86005327731003, disc_loss = 0.1330526785488114
Trained batch 81 in epoch 0, gen_loss = 2.858451386777366, disc_loss = 0.13169992490239987
Trained batch 82 in epoch 0, gen_loss = 2.86139873136957, disc_loss = 0.13034087700028735
Trained batch 83 in epoch 0, gen_loss = 2.8627659479777017, disc_loss = 0.12897213457507037
Trained batch 84 in epoch 0, gen_loss = 2.864637773177203, disc_loss = 0.12764759100973605
Trained batch 85 in epoch 0, gen_loss = 2.864920896153117, disc_loss = 0.1263418621600194
Trained batch 86 in epoch 0, gen_loss = 2.865979219305104, disc_loss = 0.12504262681622272
Trained batch 87 in epoch 0, gen_loss = 2.8673297329382463, disc_loss = 0.12378434793473306
Trained batch 88 in epoch 0, gen_loss = 2.868886947631836, disc_loss = 0.12254211027175188
Trained batch 89 in epoch 0, gen_loss = 2.874215830696954, disc_loss = 0.12132694588767158
Trained batch 90 in epoch 0, gen_loss = 2.8761993528722405, disc_loss = 0.1201676175735154
Trained batch 91 in epoch 0, gen_loss = 2.875447628290757, disc_loss = 0.1190069236225732
Trained batch 92 in epoch 0, gen_loss = 2.876348151955553, disc_loss = 0.11786575971912312
Trained batch 93 in epoch 0, gen_loss = 2.874551813653175, disc_loss = 0.1167598102796585
Trained batch 94 in epoch 0, gen_loss = 2.8733710790935314, disc_loss = 0.11567619880171198
Trained batch 95 in epoch 0, gen_loss = 2.874290751914183, disc_loss = 0.11461304717037517
Trained batch 96 in epoch 0, gen_loss = 2.8770538015463916, disc_loss = 0.11357916833007152
Trained batch 97 in epoch 0, gen_loss = 2.880495864517835, disc_loss = 0.11255467165147467
Trained batch 98 in epoch 0, gen_loss = 2.884255541695489, disc_loss = 0.11152583466974472
Trained batch 99 in epoch 0, gen_loss = 2.8858325123786925, disc_loss = 0.11051910734735429
Trained batch 100 in epoch 0, gen_loss = 2.8859317916454654, disc_loss = 0.1095464320595164
Trained batch 101 in epoch 0, gen_loss = 2.888478260414273, disc_loss = 0.10857640461557928
Trained batch 102 in epoch 0, gen_loss = 2.89056275654765, disc_loss = 0.10762575542717015
Trained batch 103 in epoch 0, gen_loss = 2.8906010458102593, disc_loss = 0.1066889366797673
Trained batch 104 in epoch 0, gen_loss = 2.8911105292184014, disc_loss = 0.1057834666222334
Trained batch 105 in epoch 0, gen_loss = 2.890598697482415, disc_loss = 0.10488098545245966
Trained batch 106 in epoch 0, gen_loss = 2.8902831478653668, disc_loss = 0.10400372992539517
Trained batch 107 in epoch 0, gen_loss = 2.893467987025226, disc_loss = 0.1031402160189356
Trained batch 108 in epoch 0, gen_loss = 2.8930426846950428, disc_loss = 0.10231735260832474
Trained batch 109 in epoch 0, gen_loss = 2.891983437538147, disc_loss = 0.10150519619611177
Trained batch 110 in epoch 0, gen_loss = 2.8878959922103196, disc_loss = 0.10074059178566074
Trained batch 111 in epoch 0, gen_loss = 2.889395392366818, disc_loss = 0.09996058524952137
Trained batch 112 in epoch 0, gen_loss = 2.8906880142414466, disc_loss = 0.09927491549468409
Trained batch 113 in epoch 0, gen_loss = 2.8908131164416933, disc_loss = 0.09856724069992963
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 2.9276983737945557, disc_loss = 0.014948473311960697
Trained batch 1 in epoch 1, gen_loss = 2.9851906299591064, disc_loss = 0.013695310335606337
Trained batch 2 in epoch 1, gen_loss = 3.006783644358317, disc_loss = 0.01484790351241827
Trained batch 3 in epoch 1, gen_loss = 3.0439282655715942, disc_loss = 0.014681130414828658
Trained batch 4 in epoch 1, gen_loss = 3.014885902404785, disc_loss = 0.015590600110590458
Trained batch 5 in epoch 1, gen_loss = 3.0121885935465493, disc_loss = 0.015819741257776816
Trained batch 6 in epoch 1, gen_loss = 3.0037072726658414, disc_loss = 0.016392543778887818
Trained batch 7 in epoch 1, gen_loss = 3.0257031619548798, disc_loss = 0.016518827411346138
Trained batch 8 in epoch 1, gen_loss = 3.0079964531792536, disc_loss = 0.01642246451228857
Trained batch 9 in epoch 1, gen_loss = 3.0031500339508055, disc_loss = 0.01605626503005624
Trained batch 10 in epoch 1, gen_loss = 2.994085832075639, disc_loss = 0.015903031538155945
Trained batch 11 in epoch 1, gen_loss = 3.037671387195587, disc_loss = 0.01645613422927757
Trained batch 12 in epoch 1, gen_loss = 3.030397506860586, disc_loss = 0.018739631184591696
Trained batch 13 in epoch 1, gen_loss = 3.0339342015130177, disc_loss = 0.020608475365276848
Trained batch 14 in epoch 1, gen_loss = 3.0371349811553956, disc_loss = 0.0204577075317502
Trained batch 15 in epoch 1, gen_loss = 3.034131705760956, disc_loss = 0.020730364543851465
Trained batch 16 in epoch 1, gen_loss = 3.0480914536644432, disc_loss = 0.021260744892060757
Trained batch 17 in epoch 1, gen_loss = 3.0581433375676474, disc_loss = 0.02268208082144459
Trained batch 18 in epoch 1, gen_loss = 3.0598498143647848, disc_loss = 0.02334241642567672
Trained batch 19 in epoch 1, gen_loss = 3.057726514339447, disc_loss = 0.022975398832932113
Trained batch 20 in epoch 1, gen_loss = 3.0373923437935963, disc_loss = 0.022550001962199098
Trained batch 21 in epoch 1, gen_loss = 3.0498603907498447, disc_loss = 0.022113757250322538
Trained batch 22 in epoch 1, gen_loss = 3.0562744244285254, disc_loss = 0.021855982546897038
Trained batch 23 in epoch 1, gen_loss = 3.057897369066874, disc_loss = 0.021560155126887064
Trained batch 24 in epoch 1, gen_loss = 3.040098714828491, disc_loss = 0.02144915919750929
Trained batch 25 in epoch 1, gen_loss = 3.0301208037596483, disc_loss = 0.021424465705282413
Trained batch 26 in epoch 1, gen_loss = 3.047153499391344, disc_loss = 0.02112588903832215
Trained batch 27 in epoch 1, gen_loss = 3.0477064762796675, disc_loss = 0.020836355530523827
Trained batch 28 in epoch 1, gen_loss = 3.0365869423438765, disc_loss = 0.020577650549339837
Trained batch 29 in epoch 1, gen_loss = 3.0414953867594403, disc_loss = 0.020233935490250588
Trained batch 30 in epoch 1, gen_loss = 3.0377156196102018, disc_loss = 0.01986298073203333
Trained batch 31 in epoch 1, gen_loss = 3.0326453521847725, disc_loss = 0.0195650237146765
Trained batch 32 in epoch 1, gen_loss = 3.0295851375117446, disc_loss = 0.01924433745443821
Trained batch 33 in epoch 1, gen_loss = 3.0205809158437393, disc_loss = 0.019105929059579092
Trained batch 34 in epoch 1, gen_loss = 3.025544466291155, disc_loss = 0.018879148656768457
Trained batch 35 in epoch 1, gen_loss = 3.033287935786777, disc_loss = 0.018664185733844835
Trained batch 36 in epoch 1, gen_loss = 3.0291041941256136, disc_loss = 0.018496896190619148
Trained batch 37 in epoch 1, gen_loss = 3.023886241410908, disc_loss = 0.01835750570324691
Trained batch 38 in epoch 1, gen_loss = 3.028276663560134, disc_loss = 0.018124996971052427
Trained batch 39 in epoch 1, gen_loss = 3.0218854784965514, disc_loss = 0.01788827418349683
Trained batch 40 in epoch 1, gen_loss = 3.0279143961464485, disc_loss = 0.017751465006390722
Trained batch 41 in epoch 1, gen_loss = 3.029164825166975, disc_loss = 0.017854404968342612
Trained batch 42 in epoch 1, gen_loss = 3.02906620225241, disc_loss = 0.017844974843048773
Trained batch 43 in epoch 1, gen_loss = 3.0302585796876387, disc_loss = 0.017755144720219752
Trained batch 44 in epoch 1, gen_loss = 3.026272932688395, disc_loss = 0.017791992074085605
Trained batch 45 in epoch 1, gen_loss = 3.0312310923700747, disc_loss = 0.01871374457993585
Trained batch 46 in epoch 1, gen_loss = 3.0302971271758383, disc_loss = 0.01912896903826201
Trained batch 47 in epoch 1, gen_loss = 3.0256614883740744, disc_loss = 0.018981020897626877
Trained batch 48 in epoch 1, gen_loss = 3.027332996835514, disc_loss = 0.01885060929902354
Trained batch 49 in epoch 1, gen_loss = 3.0223522901535036, disc_loss = 0.01871280562132597
Trained batch 50 in epoch 1, gen_loss = 3.0211244050194237, disc_loss = 0.018494898827709987
Trained batch 51 in epoch 1, gen_loss = 3.02046878521259, disc_loss = 0.01828818293646551
Trained batch 52 in epoch 1, gen_loss = 3.0145731961952067, disc_loss = 0.01807253208573697
Trained batch 53 in epoch 1, gen_loss = 3.0167502915417708, disc_loss = 0.01793518353736511
Trained batch 54 in epoch 1, gen_loss = 3.009061414545233, disc_loss = 0.01782681889493357
Trained batch 55 in epoch 1, gen_loss = 3.007183219705309, disc_loss = 0.017686469763118242
Trained batch 56 in epoch 1, gen_loss = 3.0090327681156626, disc_loss = 0.017599353746494704
Trained batch 57 in epoch 1, gen_loss = 3.0062318382592035, disc_loss = 0.01748604698363563
Trained batch 58 in epoch 1, gen_loss = 3.0022185414524403, disc_loss = 0.01732162506145946
Trained batch 59 in epoch 1, gen_loss = 3.00083616177241, disc_loss = 0.017182994307950138
Trained batch 60 in epoch 1, gen_loss = 3.003795627687798, disc_loss = 0.017032509089493362
Trained batch 61 in epoch 1, gen_loss = 3.004362029414023, disc_loss = 0.016878607540181088
Trained batch 62 in epoch 1, gen_loss = 3.0043188541654557, disc_loss = 0.016707449101857723
Trained batch 63 in epoch 1, gen_loss = 3.000961486250162, disc_loss = 0.016563780620344914
Trained batch 64 in epoch 1, gen_loss = 3.0011097541222207, disc_loss = 0.016445698001636908
Trained batch 65 in epoch 1, gen_loss = 2.9976880116896196, disc_loss = 0.01633624035413518
Trained batch 66 in epoch 1, gen_loss = 2.996710058468491, disc_loss = 0.016233593698090583
Trained batch 67 in epoch 1, gen_loss = 2.996901719009175, disc_loss = 0.016119338982902905
Trained batch 68 in epoch 1, gen_loss = 2.9951414543649424, disc_loss = 0.01598283752421106
Trained batch 69 in epoch 1, gen_loss = 2.9952524968555996, disc_loss = 0.01585188711594258
Trained batch 70 in epoch 1, gen_loss = 2.9936513229155204, disc_loss = 0.01572128935572757
Trained batch 71 in epoch 1, gen_loss = 2.9912921918763056, disc_loss = 0.015588700195722695
Trained batch 72 in epoch 1, gen_loss = 2.988622593553099, disc_loss = 0.015479261361776965
Trained batch 73 in epoch 1, gen_loss = 2.9864844985910364, disc_loss = 0.015384171485296777
Trained batch 74 in epoch 1, gen_loss = 2.988786786397298, disc_loss = 0.015310973214606444
Trained batch 75 in epoch 1, gen_loss = 2.9859009322367216, disc_loss = 0.015212029904911393
Trained batch 76 in epoch 1, gen_loss = 2.989650636524349, disc_loss = 0.015101548556431935
Trained batch 77 in epoch 1, gen_loss = 2.9887856245040894, disc_loss = 0.015014322456688834
Trained batch 78 in epoch 1, gen_loss = 2.984767838369442, disc_loss = 0.01493096567949728
Trained batch 79 in epoch 1, gen_loss = 2.9838376522064207, disc_loss = 0.014871066360501572
Trained batch 80 in epoch 1, gen_loss = 2.987169757301425, disc_loss = 0.014776715658099196
Trained batch 81 in epoch 1, gen_loss = 2.988237037891295, disc_loss = 0.01466318381177943
Trained batch 82 in epoch 1, gen_loss = 2.987499834543251, disc_loss = 0.014564115408224514
Trained batch 83 in epoch 1, gen_loss = 2.9869565821829296, disc_loss = 0.014540610690822913
Trained batch 84 in epoch 1, gen_loss = 2.9824478177463307, disc_loss = 0.01448442193076891
Trained batch 85 in epoch 1, gen_loss = 2.981995934663817, disc_loss = 0.014405950503207223
Trained batch 86 in epoch 1, gen_loss = 2.980182940932526, disc_loss = 0.01430622830280456
Trained batch 87 in epoch 1, gen_loss = 2.979017260399732, disc_loss = 0.014239439185158435
Trained batch 88 in epoch 1, gen_loss = 2.9795804023742676, disc_loss = 0.014164435671998208
Trained batch 89 in epoch 1, gen_loss = 2.977985125117832, disc_loss = 0.014102182418314946
Trained batch 90 in epoch 1, gen_loss = 2.977849622349163, disc_loss = 0.014014355249825743
Trained batch 91 in epoch 1, gen_loss = 2.9768712235533674, disc_loss = 0.01392116729149838
Trained batch 92 in epoch 1, gen_loss = 2.9746352703340593, disc_loss = 0.013854463139088244
Trained batch 93 in epoch 1, gen_loss = 2.975724613412898, disc_loss = 0.013815807084493498
Trained batch 94 in epoch 1, gen_loss = 2.9732724516015305, disc_loss = 0.013792271230761943
Trained batch 95 in epoch 1, gen_loss = 2.976473920047283, disc_loss = 0.013767546396896554
Trained batch 96 in epoch 1, gen_loss = 2.9776110796584296, disc_loss = 0.013735357158308484
Trained batch 97 in epoch 1, gen_loss = 2.9787045279327704, disc_loss = 0.013703485527931124
Trained batch 98 in epoch 1, gen_loss = 2.97635857023374, disc_loss = 0.013694656989301997
Trained batch 99 in epoch 1, gen_loss = 2.9756844592094422, disc_loss = 0.01371739901136607
Trained batch 100 in epoch 1, gen_loss = 2.9729130693001324, disc_loss = 0.013727842143155856
Trained batch 101 in epoch 1, gen_loss = 2.971157389528611, disc_loss = 0.013802461348948818
Trained batch 102 in epoch 1, gen_loss = 2.9718924031674283, disc_loss = 0.013872130281174356
Trained batch 103 in epoch 1, gen_loss = 2.972998341688743, disc_loss = 0.013917478808882432
Trained batch 104 in epoch 1, gen_loss = 2.9742768469310943, disc_loss = 0.014055053450699363
Trained batch 105 in epoch 1, gen_loss = 2.9733267775121726, disc_loss = 0.01411790042711457
Trained batch 106 in epoch 1, gen_loss = 2.9734765525176146, disc_loss = 0.014128869891201502
Trained batch 107 in epoch 1, gen_loss = 2.9752688540352716, disc_loss = 0.014260422649655354
Trained batch 108 in epoch 1, gen_loss = 2.9756082897886222, disc_loss = 0.014228647869558783
Trained batch 109 in epoch 1, gen_loss = 2.9755328676917334, disc_loss = 0.014217720946974375
Trained batch 110 in epoch 1, gen_loss = 2.973851017049841, disc_loss = 0.01422611320693348
Trained batch 111 in epoch 1, gen_loss = 2.972418335931642, disc_loss = 0.014225505720657696
Trained batch 112 in epoch 1, gen_loss = 2.968618842352808, disc_loss = 0.014218432808179507
Trained batch 113 in epoch 1, gen_loss = 2.9678459292963932, disc_loss = 0.014163289084344319
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 3.1048691272735596, disc_loss = 0.009922423399984837
Trained batch 1 in epoch 2, gen_loss = 2.9912341833114624, disc_loss = 0.009463040623813868
Trained batch 2 in epoch 2, gen_loss = 2.966752370198568, disc_loss = 0.008294738829135895
Trained batch 3 in epoch 2, gen_loss = 2.9633397459983826, disc_loss = 0.007925780490040779
Trained batch 4 in epoch 2, gen_loss = 2.9811315059661867, disc_loss = 0.007537410408258438
Trained batch 5 in epoch 2, gen_loss = 2.989057699839274, disc_loss = 0.007483860943466425
Trained batch 6 in epoch 2, gen_loss = 3.0211475917271207, disc_loss = 0.007517712323793343
Trained batch 7 in epoch 2, gen_loss = 3.008206367492676, disc_loss = 0.007400378643069416
Trained batch 8 in epoch 2, gen_loss = 3.030320644378662, disc_loss = 0.0072133467636174625
Trained batch 9 in epoch 2, gen_loss = 3.0165610790252684, disc_loss = 0.006970466626808047
Trained batch 10 in epoch 2, gen_loss = 3.044950008392334, disc_loss = 0.006863837342031978
Trained batch 11 in epoch 2, gen_loss = 3.0296584367752075, disc_loss = 0.007056015349614124
Trained batch 12 in epoch 2, gen_loss = 3.0434526113363414, disc_loss = 0.007369135398990833
Trained batch 13 in epoch 2, gen_loss = 3.025683947971889, disc_loss = 0.007512539791475449
Trained batch 14 in epoch 2, gen_loss = 3.037290827433268, disc_loss = 0.007409884377072255
Trained batch 15 in epoch 2, gen_loss = 3.0496062487363815, disc_loss = 0.007463163667125627
Trained batch 16 in epoch 2, gen_loss = 3.0530281768125644, disc_loss = 0.007479150176924818
Trained batch 17 in epoch 2, gen_loss = 3.0362613201141357, disc_loss = 0.007505046617653634
Trained batch 18 in epoch 2, gen_loss = 3.028079020349603, disc_loss = 0.007515166126387684
Trained batch 19 in epoch 2, gen_loss = 3.0240787982940676, disc_loss = 0.007668044161982834
Trained batch 20 in epoch 2, gen_loss = 3.0056231362479076, disc_loss = 0.007782463893471729
Trained batch 21 in epoch 2, gen_loss = 3.0054230364886196, disc_loss = 0.007886864689432761
Trained batch 22 in epoch 2, gen_loss = 2.993609552798064, disc_loss = 0.007990562741685173
Trained batch 23 in epoch 2, gen_loss = 3.0016201535860696, disc_loss = 0.007944060392522564
Trained batch 24 in epoch 2, gen_loss = 2.9992137336730957, disc_loss = 0.007832587417215108
Trained batch 25 in epoch 2, gen_loss = 3.0038904410142164, disc_loss = 0.007800939027220011
Trained batch 26 in epoch 2, gen_loss = 3.0062187159502947, disc_loss = 0.007807911925569728
Trained batch 27 in epoch 2, gen_loss = 2.9988923583711897, disc_loss = 0.007817222237853068
Trained batch 28 in epoch 2, gen_loss = 2.9875323114723993, disc_loss = 0.007828419706944761
Trained batch 29 in epoch 2, gen_loss = 2.984524671236674, disc_loss = 0.00781707080701987
Trained batch 30 in epoch 2, gen_loss = 2.9815964621882283, disc_loss = 0.007826411856278297
Trained batch 31 in epoch 2, gen_loss = 2.973264403641224, disc_loss = 0.007754412188660353
Trained batch 32 in epoch 2, gen_loss = 2.9755834377173223, disc_loss = 0.007712343637125961
Trained batch 33 in epoch 2, gen_loss = 2.970554456991308, disc_loss = 0.007641779601245242
Trained batch 34 in epoch 2, gen_loss = 2.965559046609061, disc_loss = 0.0075732518519674025
Trained batch 35 in epoch 2, gen_loss = 2.964695930480957, disc_loss = 0.007511499363722073
Trained batch 36 in epoch 2, gen_loss = 2.957835442311055, disc_loss = 0.0074433691145197765
Trained batch 37 in epoch 2, gen_loss = 2.953611505659003, disc_loss = 0.007377651985734701
Trained batch 38 in epoch 2, gen_loss = 2.954541774896475, disc_loss = 0.007318527592966954
Trained batch 39 in epoch 2, gen_loss = 2.9506054401397703, disc_loss = 0.0072741414071060715
Trained batch 40 in epoch 2, gen_loss = 2.952206640708737, disc_loss = 0.00721302059501773
Trained batch 41 in epoch 2, gen_loss = 2.9518239895502725, disc_loss = 0.007148985473793887
Trained batch 42 in epoch 2, gen_loss = 2.941732401071593, disc_loss = 0.007111296999853018
Trained batch 43 in epoch 2, gen_loss = 2.9445399804548784, disc_loss = 0.007044623976319351
Trained batch 44 in epoch 2, gen_loss = 2.9450758510165747, disc_loss = 0.00697929175156686
Trained batch 45 in epoch 2, gen_loss = 2.9411426886268286, disc_loss = 0.00692830280319828
Trained batch 46 in epoch 2, gen_loss = 2.9437223190956927, disc_loss = 0.006881353871381664
Trained batch 47 in epoch 2, gen_loss = 2.9442671040693917, disc_loss = 0.006857744388980791
Trained batch 48 in epoch 2, gen_loss = 2.946191135717898, disc_loss = 0.006803198641508209
Trained batch 49 in epoch 2, gen_loss = 2.948770055770874, disc_loss = 0.006795161794871092
Trained batch 50 in epoch 2, gen_loss = 2.947111681395886, disc_loss = 0.006777539237530208
Trained batch 51 in epoch 2, gen_loss = 2.9528106405184817, disc_loss = 0.006756042022831165
Trained batch 52 in epoch 2, gen_loss = 2.9503829164325066, disc_loss = 0.006706457233653878
Trained batch 53 in epoch 2, gen_loss = 2.95624546651487, disc_loss = 0.006670684070774802
Trained batch 54 in epoch 2, gen_loss = 2.9534185366197065, disc_loss = 0.0066541059958663855
Trained batch 55 in epoch 2, gen_loss = 2.952634389911379, disc_loss = 0.006638386852240988
Trained batch 56 in epoch 2, gen_loss = 2.949679403974299, disc_loss = 0.006622161046324069
Trained batch 57 in epoch 2, gen_loss = 2.9473155654709915, disc_loss = 0.0065874063554380476
Trained batch 58 in epoch 2, gen_loss = 2.941585892337864, disc_loss = 0.0065648853542062185
Trained batch 59 in epoch 2, gen_loss = 2.9461906711260477, disc_loss = 0.006538077094592154
Trained batch 60 in epoch 2, gen_loss = 2.9419960584796843, disc_loss = 0.00652057316429058
Trained batch 61 in epoch 2, gen_loss = 2.9454632228420627, disc_loss = 0.006498248421496922
Trained batch 62 in epoch 2, gen_loss = 2.9497494886791897, disc_loss = 0.0064822859943859164
Trained batch 63 in epoch 2, gen_loss = 2.9475443474948406, disc_loss = 0.0064756233332445845
Trained batch 64 in epoch 2, gen_loss = 2.948506153546847, disc_loss = 0.00644333938566538
Trained batch 65 in epoch 2, gen_loss = 2.950232249317747, disc_loss = 0.006428335186545596
Trained batch 66 in epoch 2, gen_loss = 2.9492487160127556, disc_loss = 0.006393810108637632
Trained batch 67 in epoch 2, gen_loss = 2.952228917795069, disc_loss = 0.006392123403630275
Trained batch 68 in epoch 2, gen_loss = 2.9526142590287803, disc_loss = 0.006376744436936966
Trained batch 69 in epoch 2, gen_loss = 2.953086338724409, disc_loss = 0.006359750391649348
Trained batch 70 in epoch 2, gen_loss = 2.9502913078791657, disc_loss = 0.006338603027217405
Trained batch 71 in epoch 2, gen_loss = 2.9497497843371496, disc_loss = 0.006318366374923951
Trained batch 72 in epoch 2, gen_loss = 2.948432768860908, disc_loss = 0.006295927774722446
Trained batch 73 in epoch 2, gen_loss = 2.949544935613065, disc_loss = 0.006269163502430594
Trained batch 74 in epoch 2, gen_loss = 2.9482761923472087, disc_loss = 0.006239824270208676
Trained batch 75 in epoch 2, gen_loss = 2.947440470519819, disc_loss = 0.006216200975407111
Trained batch 76 in epoch 2, gen_loss = 2.945264333254331, disc_loss = 0.006194087180804896
Trained batch 77 in epoch 2, gen_loss = 2.9414395491282144, disc_loss = 0.006174538403940506
Trained batch 78 in epoch 2, gen_loss = 2.941007556794565, disc_loss = 0.006161037301998349
Trained batch 79 in epoch 2, gen_loss = 2.9399358838796616, disc_loss = 0.006174225668655708
Trained batch 80 in epoch 2, gen_loss = 2.9404680022486933, disc_loss = 0.00618068128824234
Trained batch 81 in epoch 2, gen_loss = 2.943894531668686, disc_loss = 0.006181343844751033
Trained batch 82 in epoch 2, gen_loss = 2.943884843803314, disc_loss = 0.006164616983698075
Trained batch 83 in epoch 2, gen_loss = 2.9442625159309026, disc_loss = 0.006139881232576002
Trained batch 84 in epoch 2, gen_loss = 2.9460529355441825, disc_loss = 0.006121540842029978
Trained batch 85 in epoch 2, gen_loss = 2.946423813354137, disc_loss = 0.006091291880841518
Trained batch 86 in epoch 2, gen_loss = 2.9459468879918944, disc_loss = 0.006077682412090315
Trained batch 87 in epoch 2, gen_loss = 2.94491631063548, disc_loss = 0.006068685986313291
Trained batch 88 in epoch 2, gen_loss = 2.9420285546377802, disc_loss = 0.006074749990209435
Trained batch 89 in epoch 2, gen_loss = 2.9419268978966606, disc_loss = 0.006072758479664723
Trained batch 90 in epoch 2, gen_loss = 2.9420195673848246, disc_loss = 0.006059987040666433
Trained batch 91 in epoch 2, gen_loss = 2.9408807132555093, disc_loss = 0.006035969865953793
Trained batch 92 in epoch 2, gen_loss = 2.9367282672594954, disc_loss = 0.006029521370486867
Trained batch 93 in epoch 2, gen_loss = 2.936189811280433, disc_loss = 0.006024972332562221
Trained batch 94 in epoch 2, gen_loss = 2.9366639413331685, disc_loss = 0.006013345007637613
Trained batch 95 in epoch 2, gen_loss = 2.9336414709687233, disc_loss = 0.006016402005722436
Trained batch 96 in epoch 2, gen_loss = 2.9370774337925862, disc_loss = 0.00607063173383628
Trained batch 97 in epoch 2, gen_loss = 2.9357703169997857, disc_loss = 0.006089170677207259
Trained batch 98 in epoch 2, gen_loss = 2.936616543567542, disc_loss = 0.006092684028312714
Trained batch 99 in epoch 2, gen_loss = 2.936511814594269, disc_loss = 0.0060843705805018545
Trained batch 100 in epoch 2, gen_loss = 2.9348302005541207, disc_loss = 0.00608293924683539
Trained batch 101 in epoch 2, gen_loss = 2.9375017554152247, disc_loss = 0.006096828582824445
Trained batch 102 in epoch 2, gen_loss = 2.937475141969699, disc_loss = 0.006089765171619873
Trained batch 103 in epoch 2, gen_loss = 2.9372950265040765, disc_loss = 0.006084346924371158
Trained batch 104 in epoch 2, gen_loss = 2.935049231847127, disc_loss = 0.006085216307214328
Trained batch 105 in epoch 2, gen_loss = 2.9380442983699293, disc_loss = 0.00607406235089139
Trained batch 106 in epoch 2, gen_loss = 2.9362669057935196, disc_loss = 0.006060715394843126
Trained batch 107 in epoch 2, gen_loss = 2.9368082262851574, disc_loss = 0.006045105720490769
Trained batch 108 in epoch 2, gen_loss = 2.9379143714904785, disc_loss = 0.006043024668726352
Trained batch 109 in epoch 2, gen_loss = 2.936270685629411, disc_loss = 0.006035882217640226
Trained batch 110 in epoch 2, gen_loss = 2.9386962319279575, disc_loss = 0.006026417717572536
Trained batch 111 in epoch 2, gen_loss = 2.939536737544196, disc_loss = 0.006021912454993331
Trained batch 112 in epoch 2, gen_loss = 2.936486128157219, disc_loss = 0.0060244065800071816
Trained batch 113 in epoch 2, gen_loss = 2.938597083091736, disc_loss = 0.006061203516366189
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.7747676372528076, disc_loss = 0.008995435200631618
Trained batch 1 in epoch 3, gen_loss = 2.8599504232406616, disc_loss = 0.00753588555380702
Trained batch 2 in epoch 3, gen_loss = 2.957536458969116, disc_loss = 0.00651564821600914
Trained batch 3 in epoch 3, gen_loss = 2.9345977306365967, disc_loss = 0.006867903750389814
Trained batch 4 in epoch 3, gen_loss = 2.983727502822876, disc_loss = 0.007585175335407257
Trained batch 5 in epoch 3, gen_loss = 2.955013950665792, disc_loss = 0.008123730619748434
Trained batch 6 in epoch 3, gen_loss = 2.954358066831316, disc_loss = 0.008236156244363104
Trained batch 7 in epoch 3, gen_loss = 2.9540187418460846, disc_loss = 0.007951478706672788
Trained batch 8 in epoch 3, gen_loss = 2.9423571162753634, disc_loss = 0.007503136682013671
Trained batch 9 in epoch 3, gen_loss = 2.9478435754776, disc_loss = 0.007185039389878511
Trained batch 10 in epoch 3, gen_loss = 2.929138031872836, disc_loss = 0.007320177148688923
Trained batch 11 in epoch 3, gen_loss = 2.9361053109169006, disc_loss = 0.007182329737891753
Trained batch 12 in epoch 3, gen_loss = 2.948545914429885, disc_loss = 0.007064311980054929
Trained batch 13 in epoch 3, gen_loss = 2.959253362246922, disc_loss = 0.006928971170314721
Trained batch 14 in epoch 3, gen_loss = 2.9504125754038495, disc_loss = 0.006722377535576622
Trained batch 15 in epoch 3, gen_loss = 2.97466342151165, disc_loss = 0.006621851425734349
Trained batch 16 in epoch 3, gen_loss = 2.972187406876508, disc_loss = 0.006466741522993235
Trained batch 17 in epoch 3, gen_loss = 2.9725743664635553, disc_loss = 0.00637350822540207
Trained batch 18 in epoch 3, gen_loss = 2.9488093225579513, disc_loss = 0.006282370917401032
Trained batch 19 in epoch 3, gen_loss = 2.938578391075134, disc_loss = 0.006182205572258681
Trained batch 20 in epoch 3, gen_loss = 2.9375654629298618, disc_loss = 0.006139015235627691
Trained batch 21 in epoch 3, gen_loss = 2.944344238801436, disc_loss = 0.006079469415867193
Trained batch 22 in epoch 3, gen_loss = 2.9338280221690303, disc_loss = 0.006030463623692808
Trained batch 23 in epoch 3, gen_loss = 2.9180171291033425, disc_loss = 0.005979703011689708
Trained batch 24 in epoch 3, gen_loss = 2.9193177223205566, disc_loss = 0.0058973752055317165
Trained batch 25 in epoch 3, gen_loss = 2.923343199949998, disc_loss = 0.0058234406617255164
Trained batch 26 in epoch 3, gen_loss = 2.9128374170373985, disc_loss = 0.005785824963822961
Trained batch 27 in epoch 3, gen_loss = 2.915471911430359, disc_loss = 0.005727516911325178
Trained batch 28 in epoch 3, gen_loss = 2.917581163603684, disc_loss = 0.005701750364347264
Trained batch 29 in epoch 3, gen_loss = 2.925234810511271, disc_loss = 0.005670017353259027
Trained batch 30 in epoch 3, gen_loss = 2.927617011531707, disc_loss = 0.005621620040807513
Trained batch 31 in epoch 3, gen_loss = 2.9294206351041794, disc_loss = 0.0055428066771128215
Trained batch 32 in epoch 3, gen_loss = 2.927892930579908, disc_loss = 0.005529326563136596
Trained batch 33 in epoch 3, gen_loss = 2.9268251306870403, disc_loss = 0.00557357695309774
Trained batch 34 in epoch 3, gen_loss = 2.9218530927385604, disc_loss = 0.005535296117886901
Trained batch 35 in epoch 3, gen_loss = 2.923741559187571, disc_loss = 0.005528883031931602
Trained batch 36 in epoch 3, gen_loss = 2.9261825857935726, disc_loss = 0.005539297937994471
Trained batch 37 in epoch 3, gen_loss = 2.9231585389689396, disc_loss = 0.005541290738619864
Trained batch 38 in epoch 3, gen_loss = 2.9213587381900887, disc_loss = 0.005495698346445958
Trained batch 39 in epoch 3, gen_loss = 2.923500883579254, disc_loss = 0.005519696802366525
Trained batch 40 in epoch 3, gen_loss = 2.9217812491626276, disc_loss = 0.005539308994917608
Trained batch 41 in epoch 3, gen_loss = 2.9238573028927757, disc_loss = 0.005545239019695492
Trained batch 42 in epoch 3, gen_loss = 2.923971697341564, disc_loss = 0.005511336721653162
Trained batch 43 in epoch 3, gen_loss = 2.920619910413569, disc_loss = 0.0054977691139687195
Trained batch 44 in epoch 3, gen_loss = 2.9192065556844073, disc_loss = 0.005455104044328133
Trained batch 45 in epoch 3, gen_loss = 2.915160894393921, disc_loss = 0.005413746653610598
Trained batch 46 in epoch 3, gen_loss = 2.9130382030568223, disc_loss = 0.005381995405843283
Trained batch 47 in epoch 3, gen_loss = 2.918256019552549, disc_loss = 0.00538751464531136
Trained batch 48 in epoch 3, gen_loss = 2.914007668592492, disc_loss = 0.005389411544085157
Trained batch 49 in epoch 3, gen_loss = 2.914497485160828, disc_loss = 0.005347991967573762
Trained batch 50 in epoch 3, gen_loss = 2.9083624540590773, disc_loss = 0.005327899218993444
Trained batch 51 in epoch 3, gen_loss = 2.906685622838827, disc_loss = 0.005326524538059647
Trained batch 52 in epoch 3, gen_loss = 2.9131083443479717, disc_loss = 0.00534245265507192
Trained batch 53 in epoch 3, gen_loss = 2.9148114831359297, disc_loss = 0.005308415438910878
Trained batch 54 in epoch 3, gen_loss = 2.914775159142234, disc_loss = 0.005293094663118774
Trained batch 55 in epoch 3, gen_loss = 2.917500023330961, disc_loss = 0.005280359523437385
Trained batch 56 in epoch 3, gen_loss = 2.9219121891155577, disc_loss = 0.005266713264414616
Trained batch 57 in epoch 3, gen_loss = 2.9242349534199157, disc_loss = 0.0052487111393490745
Trained batch 58 in epoch 3, gen_loss = 2.9226838653370484, disc_loss = 0.005204322763671309
Trained batch 59 in epoch 3, gen_loss = 2.920332109928131, disc_loss = 0.005168027221225202
Trained batch 60 in epoch 3, gen_loss = 2.9196802436328326, disc_loss = 0.00513442565274776
Trained batch 61 in epoch 3, gen_loss = 2.919323763539714, disc_loss = 0.0051012440817430615
Trained batch 62 in epoch 3, gen_loss = 2.9233393782661077, disc_loss = 0.005068022510155089
Trained batch 63 in epoch 3, gen_loss = 2.929157018661499, disc_loss = 0.005035008780396311
Trained batch 64 in epoch 3, gen_loss = 2.9263366992657, disc_loss = 0.0050159580468271785
Trained batch 65 in epoch 3, gen_loss = 2.927712462165139, disc_loss = 0.004987341383556751
Trained batch 66 in epoch 3, gen_loss = 2.924381426910856, disc_loss = 0.0049562071616858685
Trained batch 67 in epoch 3, gen_loss = 2.9233686257811153, disc_loss = 0.004949931212810471
Trained batch 68 in epoch 3, gen_loss = 2.921873196311619, disc_loss = 0.004932914759315874
Trained batch 69 in epoch 3, gen_loss = 2.921121174948556, disc_loss = 0.004906776773610285
Trained batch 70 in epoch 3, gen_loss = 2.925181852260106, disc_loss = 0.0048881891629540585
Trained batch 71 in epoch 3, gen_loss = 2.9240225752194724, disc_loss = 0.004861228420243909
Trained batch 72 in epoch 3, gen_loss = 2.921094891143172, disc_loss = 0.004850178657176151
Trained batch 73 in epoch 3, gen_loss = 2.9215373574076473, disc_loss = 0.004828402876375696
Trained batch 74 in epoch 3, gen_loss = 2.9228978474934895, disc_loss = 0.004808229900275667
Trained batch 75 in epoch 3, gen_loss = 2.9205856762434306, disc_loss = 0.004782801380650581
Trained batch 76 in epoch 3, gen_loss = 2.921003920691354, disc_loss = 0.004763309447723743
Trained batch 77 in epoch 3, gen_loss = 2.919429231912662, disc_loss = 0.0047444338784911316
Trained batch 78 in epoch 3, gen_loss = 2.918053527421589, disc_loss = 0.004745144382284223
Trained batch 79 in epoch 3, gen_loss = 2.9169995903968813, disc_loss = 0.004731278846156784
Trained batch 80 in epoch 3, gen_loss = 2.9164986492675027, disc_loss = 0.004705148553590716
Trained batch 81 in epoch 3, gen_loss = 2.918628099488049, disc_loss = 0.004684690198656626
Trained batch 82 in epoch 3, gen_loss = 2.923074150659952, disc_loss = 0.004667574691260795
Trained batch 83 in epoch 3, gen_loss = 2.922515162399837, disc_loss = 0.004647231577629489
Trained batch 84 in epoch 3, gen_loss = 2.922110891342163, disc_loss = 0.004633611900841488
Trained batch 85 in epoch 3, gen_loss = 2.920054604840833, disc_loss = 0.004623482520908637
Trained batch 86 in epoch 3, gen_loss = 2.91523368605252, disc_loss = 0.004621295592929611
Trained batch 87 in epoch 3, gen_loss = 2.9141436625610697, disc_loss = 0.004621359146602283
Trained batch 88 in epoch 3, gen_loss = 2.9140590523066146, disc_loss = 0.004605924399318487
Trained batch 89 in epoch 3, gen_loss = 2.915322740872701, disc_loss = 0.004591190786514845
Trained batch 90 in epoch 3, gen_loss = 2.914388054019802, disc_loss = 0.004596225295604749
Trained batch 91 in epoch 3, gen_loss = 2.9148809469264485, disc_loss = 0.004603813663023808
Trained batch 92 in epoch 3, gen_loss = 2.913299132418889, disc_loss = 0.0046172262524925576
Trained batch 93 in epoch 3, gen_loss = 2.9181516094410673, disc_loss = 0.004614386695159718
Trained batch 94 in epoch 3, gen_loss = 2.916809812345003, disc_loss = 0.004609785942164691
Trained batch 95 in epoch 3, gen_loss = 2.9172222539782524, disc_loss = 0.00462993642577203
Trained batch 96 in epoch 3, gen_loss = 2.9158349971181337, disc_loss = 0.004612707170494592
Trained batch 97 in epoch 3, gen_loss = 2.915150931903294, disc_loss = 0.004612514395171738
Trained batch 98 in epoch 3, gen_loss = 2.9152779145674272, disc_loss = 0.004599048504417743
Trained batch 99 in epoch 3, gen_loss = 2.9187491273880006, disc_loss = 0.00458695005858317
Trained batch 100 in epoch 3, gen_loss = 2.9188906792366858, disc_loss = 0.004567873177791734
Trained batch 101 in epoch 3, gen_loss = 2.916809577567905, disc_loss = 0.0045495920326085945
Trained batch 102 in epoch 3, gen_loss = 2.9158269872943174, disc_loss = 0.004530915809632505
Trained batch 103 in epoch 3, gen_loss = 2.9176955360632677, disc_loss = 0.004527085066701357
Trained batch 104 in epoch 3, gen_loss = 2.9178849197569345, disc_loss = 0.004512757306829805
Trained batch 105 in epoch 3, gen_loss = 2.9194011530786192, disc_loss = 0.004501841404422556
Trained batch 106 in epoch 3, gen_loss = 2.9210492628757083, disc_loss = 0.004501952015072386
Trained batch 107 in epoch 3, gen_loss = 2.9220490521854825, disc_loss = 0.0044935979768288906
Trained batch 108 in epoch 3, gen_loss = 2.921197151919024, disc_loss = 0.004494649464896786
Trained batch 109 in epoch 3, gen_loss = 2.92096859108318, disc_loss = 0.004487365657802333
Trained batch 110 in epoch 3, gen_loss = 2.9212422048723377, disc_loss = 0.004479148139891861
Trained batch 111 in epoch 3, gen_loss = 2.924924162881715, disc_loss = 0.004495451559445688
Trained batch 112 in epoch 3, gen_loss = 2.923569888140248, disc_loss = 0.004485047292541218
Trained batch 113 in epoch 3, gen_loss = 2.923118915474206, disc_loss = 0.004506370749144831
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 2.7307584285736084, disc_loss = 0.003345056204125285
Trained batch 1 in epoch 4, gen_loss = 2.8880573511123657, disc_loss = 0.0036120390286669135
Trained batch 2 in epoch 4, gen_loss = 2.8871657848358154, disc_loss = 0.0032784813859810433
Trained batch 3 in epoch 4, gen_loss = 2.9822317957878113, disc_loss = 0.003032613138202578
Trained batch 4 in epoch 4, gen_loss = 2.9542616844177245, disc_loss = 0.002961357543244958
Trained batch 5 in epoch 4, gen_loss = 2.955793023109436, disc_loss = 0.0028712590768312416
Trained batch 6 in epoch 4, gen_loss = 2.975839614868164, disc_loss = 0.0028600955847650766
Trained batch 7 in epoch 4, gen_loss = 2.9352972507476807, disc_loss = 0.002916610479587689
Trained batch 8 in epoch 4, gen_loss = 2.931184583240085, disc_loss = 0.0029088675510138273
Trained batch 9 in epoch 4, gen_loss = 2.9375688791275025, disc_loss = 0.0028667265782132746
Trained batch 10 in epoch 4, gen_loss = 2.935713681307706, disc_loss = 0.0028874093497341328
Trained batch 11 in epoch 4, gen_loss = 2.96966552734375, disc_loss = 0.0029159083302753666
Trained batch 12 in epoch 4, gen_loss = 2.968135576981765, disc_loss = 0.002967163920402527
Trained batch 13 in epoch 4, gen_loss = 2.986068231718881, disc_loss = 0.0029790736901174697
Trained batch 14 in epoch 4, gen_loss = 2.979300530751546, disc_loss = 0.0030344020885725814
Trained batch 15 in epoch 4, gen_loss = 2.9798299074172974, disc_loss = 0.0030902720463927835
Trained batch 16 in epoch 4, gen_loss = 2.9827531926772175, disc_loss = 0.003040256553932148
Trained batch 17 in epoch 4, gen_loss = 2.958205540974935, disc_loss = 0.0030499403623657096
Trained batch 18 in epoch 4, gen_loss = 2.9673741114766976, disc_loss = 0.0030158499231267917
Trained batch 19 in epoch 4, gen_loss = 2.9691336035728453, disc_loss = 0.0030343258171342314
Trained batch 20 in epoch 4, gen_loss = 2.9679588136218844, disc_loss = 0.003048882342963701
Trained batch 21 in epoch 4, gen_loss = 2.9727812030098657, disc_loss = 0.0030435438754714346
Trained batch 22 in epoch 4, gen_loss = 2.975184378416642, disc_loss = 0.003078912698623279
Trained batch 23 in epoch 4, gen_loss = 2.963626762231191, disc_loss = 0.003176338999764994
Trained batch 24 in epoch 4, gen_loss = 2.964911947250366, disc_loss = 0.0032506273593753575
Trained batch 25 in epoch 4, gen_loss = 2.9585497195904074, disc_loss = 0.0033391025006914367
Trained batch 26 in epoch 4, gen_loss = 2.9524547347316035, disc_loss = 0.0034341603189844776
Trained batch 27 in epoch 4, gen_loss = 2.94366626228605, disc_loss = 0.00347904020288427
Trained batch 28 in epoch 4, gen_loss = 2.9384433401042016, disc_loss = 0.0035104978235502697
Trained batch 29 in epoch 4, gen_loss = 2.937151137987773, disc_loss = 0.003494276781566441
Trained batch 30 in epoch 4, gen_loss = 2.9323890363016436, disc_loss = 0.003456305261821516
Trained batch 31 in epoch 4, gen_loss = 2.9237082079052925, disc_loss = 0.003423156405915506
Trained batch 32 in epoch 4, gen_loss = 2.9318415974125718, disc_loss = 0.003400765923839627
Trained batch 33 in epoch 4, gen_loss = 2.9315058764289406, disc_loss = 0.0033922361976960126
Trained batch 34 in epoch 4, gen_loss = 2.932771989277431, disc_loss = 0.0033664542649473462
Trained batch 35 in epoch 4, gen_loss = 2.928121520413293, disc_loss = 0.0033733499909026753
Trained batch 36 in epoch 4, gen_loss = 2.9263378929447486, disc_loss = 0.003356880885926453
Trained batch 37 in epoch 4, gen_loss = 2.9209814636330855, disc_loss = 0.003363661982707287
Trained batch 38 in epoch 4, gen_loss = 2.9138254202329197, disc_loss = 0.0033600787835147902
Trained batch 39 in epoch 4, gen_loss = 2.916240519285202, disc_loss = 0.003365677472902462
Trained batch 40 in epoch 4, gen_loss = 2.914455245180828, disc_loss = 0.0033540476068127448
Trained batch 41 in epoch 4, gen_loss = 2.9124515453974404, disc_loss = 0.003348998248665815
Trained batch 42 in epoch 4, gen_loss = 2.913240299668423, disc_loss = 0.0033603317245061316
Trained batch 43 in epoch 4, gen_loss = 2.9163046045736833, disc_loss = 0.0033691545620306647
Trained batch 44 in epoch 4, gen_loss = 2.9158278518252905, disc_loss = 0.00334506092282633
Trained batch 45 in epoch 4, gen_loss = 2.9129037805225537, disc_loss = 0.003326584013057468
Trained batch 46 in epoch 4, gen_loss = 2.9126382939358977, disc_loss = 0.003328146398107105
Trained batch 47 in epoch 4, gen_loss = 2.9172957887252173, disc_loss = 0.0033481952026098347
Trained batch 48 in epoch 4, gen_loss = 2.9123113252678694, disc_loss = 0.003376665235287985
Trained batch 49 in epoch 4, gen_loss = 2.9118310022354126, disc_loss = 0.0033816763060167433
Trained batch 50 in epoch 4, gen_loss = 2.9130037952871883, disc_loss = 0.0033630834728041116
Trained batch 51 in epoch 4, gen_loss = 2.917534209214724, disc_loss = 0.0033525696131758965
Trained batch 52 in epoch 4, gen_loss = 2.917473941479089, disc_loss = 0.0033534954671027525
Trained batch 53 in epoch 4, gen_loss = 2.9181682533688016, disc_loss = 0.003348357212315831
Trained batch 54 in epoch 4, gen_loss = 2.9186878117648036, disc_loss = 0.0033317979975518853
Trained batch 55 in epoch 4, gen_loss = 2.9278655094759807, disc_loss = 0.003342345677083358
Trained batch 56 in epoch 4, gen_loss = 2.928611910134031, disc_loss = 0.003327983035297509
Trained batch 57 in epoch 4, gen_loss = 2.9230271906688294, disc_loss = 0.003319778411392251
Trained batch 58 in epoch 4, gen_loss = 2.9276866953251726, disc_loss = 0.003316067585374339
Trained batch 59 in epoch 4, gen_loss = 2.9313556512196857, disc_loss = 0.0033347438865651688
Trained batch 60 in epoch 4, gen_loss = 2.9390812545526224, disc_loss = 0.003356067830177604
Trained batch 61 in epoch 4, gen_loss = 2.935707361467423, disc_loss = 0.003352661508195583
Trained batch 62 in epoch 4, gen_loss = 2.938992057527815, disc_loss = 0.0033439366324316887
Trained batch 63 in epoch 4, gen_loss = 2.9386055134236813, disc_loss = 0.0033355834166286513
Trained batch 64 in epoch 4, gen_loss = 2.9383724175966703, disc_loss = 0.0033319895370648458
Trained batch 65 in epoch 4, gen_loss = 2.9391371553594414, disc_loss = 0.0033360394987870345
Trained batch 66 in epoch 4, gen_loss = 2.937666053202615, disc_loss = 0.0033483387652172973
Trained batch 67 in epoch 4, gen_loss = 2.9324873159913456, disc_loss = 0.003359133185928359
Trained batch 68 in epoch 4, gen_loss = 2.9313088983729267, disc_loss = 0.0033589909932967544
Trained batch 69 in epoch 4, gen_loss = 2.928990112032209, disc_loss = 0.0033684057316609793
Trained batch 70 in epoch 4, gen_loss = 2.9300302888306096, disc_loss = 0.003403698605760722
Trained batch 71 in epoch 4, gen_loss = 2.9341894818676844, disc_loss = 0.003425439140604188
Trained batch 72 in epoch 4, gen_loss = 2.930808609479094, disc_loss = 0.0034466579569222993
Trained batch 73 in epoch 4, gen_loss = 2.92628242840638, disc_loss = 0.003440903635015963
Trained batch 74 in epoch 4, gen_loss = 2.9275134372711182, disc_loss = 0.003420603449145953
Trained batch 75 in epoch 4, gen_loss = 2.929215264947791, disc_loss = 0.003400788936567934
Trained batch 76 in epoch 4, gen_loss = 2.930542818911664, disc_loss = 0.0033975205650287016
Trained batch 77 in epoch 4, gen_loss = 2.9304534319119577, disc_loss = 0.003392398578281968
Trained batch 78 in epoch 4, gen_loss = 2.9297889455964294, disc_loss = 0.0033975127683598784
Trained batch 79 in epoch 4, gen_loss = 2.928476858139038, disc_loss = 0.0034007966285571458
Trained batch 80 in epoch 4, gen_loss = 2.927144895365209, disc_loss = 0.003398179990687856
Trained batch 81 in epoch 4, gen_loss = 2.931840701801021, disc_loss = 0.0033836091368845325
Trained batch 82 in epoch 4, gen_loss = 2.929763009749263, disc_loss = 0.0033774240817650257
Trained batch 83 in epoch 4, gen_loss = 2.927741351581755, disc_loss = 0.0033676427389894214
Trained batch 84 in epoch 4, gen_loss = 2.9265343694125905, disc_loss = 0.003354400453869911
Trained batch 85 in epoch 4, gen_loss = 2.9228732807691706, disc_loss = 0.0033447006717324257
Trained batch 86 in epoch 4, gen_loss = 2.918026926873744, disc_loss = 0.003334737024216474
Trained batch 87 in epoch 4, gen_loss = 2.9216766953468323, disc_loss = 0.00332611803737977
Trained batch 88 in epoch 4, gen_loss = 2.92444097861815, disc_loss = 0.0033324452279282087
Trained batch 89 in epoch 4, gen_loss = 2.919870636198256, disc_loss = 0.0033328101970255377
Trained batch 90 in epoch 4, gen_loss = 2.9175404873523085, disc_loss = 0.0033294139327583734
Trained batch 91 in epoch 4, gen_loss = 2.918996733167897, disc_loss = 0.003317076237062397
Trained batch 92 in epoch 4, gen_loss = 2.918406109656057, disc_loss = 0.003302727029809067
Trained batch 93 in epoch 4, gen_loss = 2.917587049463962, disc_loss = 0.0032876770846803297
Trained batch 94 in epoch 4, gen_loss = 2.9133506523935417, disc_loss = 0.0032788669947828902
Trained batch 95 in epoch 4, gen_loss = 2.916772479812304, disc_loss = 0.003271124962338945
Trained batch 96 in epoch 4, gen_loss = 2.9209309263327685, disc_loss = 0.003266495228841056
Trained batch 97 in epoch 4, gen_loss = 2.920314783952674, disc_loss = 0.0032576175195126967
Trained batch 98 in epoch 4, gen_loss = 2.918557398246996, disc_loss = 0.003247393416287848
Trained batch 99 in epoch 4, gen_loss = 2.917219123840332, disc_loss = 0.0032417921803425996
Trained batch 100 in epoch 4, gen_loss = 2.9194785014237508, disc_loss = 0.0032347097709350806
Trained batch 101 in epoch 4, gen_loss = 2.920916564324323, disc_loss = 0.003221142392231188
Trained batch 102 in epoch 4, gen_loss = 2.9178504041097697, disc_loss = 0.003220017259099602
Trained batch 103 in epoch 4, gen_loss = 2.9188542434802422, disc_loss = 0.003216222596865219
Trained batch 104 in epoch 4, gen_loss = 2.9162679218110585, disc_loss = 0.003207833547189477
Trained batch 105 in epoch 4, gen_loss = 2.9153615663636407, disc_loss = 0.003194884272986355
Trained batch 106 in epoch 4, gen_loss = 2.9163481743536264, disc_loss = 0.0031805517343438676
Trained batch 107 in epoch 4, gen_loss = 2.913960383998023, disc_loss = 0.0031721498192012034
Trained batch 108 in epoch 4, gen_loss = 2.912765142020829, disc_loss = 0.0031666021704366176
Trained batch 109 in epoch 4, gen_loss = 2.914036896012046, disc_loss = 0.0031593391396613282
Trained batch 110 in epoch 4, gen_loss = 2.9127530213948845, disc_loss = 0.0031480034981090743
Trained batch 111 in epoch 4, gen_loss = 2.9152530325310573, disc_loss = 0.0031406117944113377
Trained batch 112 in epoch 4, gen_loss = 2.9162560880711648, disc_loss = 0.0031449574692817652
Trained batch 113 in epoch 4, gen_loss = 2.918573128549676, disc_loss = 0.0031663023258085574
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 3.0011239051818848, disc_loss = 0.0048670778051018715
Trained batch 1 in epoch 5, gen_loss = 3.089761734008789, disc_loss = 0.004874527920037508
Trained batch 2 in epoch 5, gen_loss = 3.0050384203592935, disc_loss = 0.004312903930743535
Trained batch 3 in epoch 5, gen_loss = 2.8874127864837646, disc_loss = 0.003912640153430402
Trained batch 4 in epoch 5, gen_loss = 2.894525957107544, disc_loss = 0.003700890252366662
Trained batch 5 in epoch 5, gen_loss = 2.8709529638290405, disc_loss = 0.0037066430474321046
Trained batch 6 in epoch 5, gen_loss = 2.889498267854963, disc_loss = 0.003638702178640025
Trained batch 7 in epoch 5, gen_loss = 2.865368366241455, disc_loss = 0.0034694643691182137
Trained batch 8 in epoch 5, gen_loss = 2.8922403123643665, disc_loss = 0.0032811866840347648
Trained batch 9 in epoch 5, gen_loss = 2.8735788345336912, disc_loss = 0.00318714928580448
Trained batch 10 in epoch 5, gen_loss = 2.848304965279319, disc_loss = 0.003381019278260117
Trained batch 11 in epoch 5, gen_loss = 2.847352981567383, disc_loss = 0.003380767331691459
Trained batch 12 in epoch 5, gen_loss = 2.8283408605135403, disc_loss = 0.0033601793156077084
Trained batch 13 in epoch 5, gen_loss = 2.8247372763497487, disc_loss = 0.003275225163503949
Trained batch 14 in epoch 5, gen_loss = 2.822313435872396, disc_loss = 0.0032707661623135207
Trained batch 15 in epoch 5, gen_loss = 2.8358136117458344, disc_loss = 0.0032081619938253425
Trained batch 16 in epoch 5, gen_loss = 2.844091583700741, disc_loss = 0.003162549007410074
Trained batch 17 in epoch 5, gen_loss = 2.8497138023376465, disc_loss = 0.003128599110318141
Trained batch 18 in epoch 5, gen_loss = 2.841502540989926, disc_loss = 0.0031099634330817743
Trained batch 19 in epoch 5, gen_loss = 2.8436620473861693, disc_loss = 0.0031079149048309773
Trained batch 20 in epoch 5, gen_loss = 2.8483574163346064, disc_loss = 0.0030589959794832837
Trained batch 21 in epoch 5, gen_loss = 2.8532214273105967, disc_loss = 0.0030014097679999063
Trained batch 22 in epoch 5, gen_loss = 2.8665109717327617, disc_loss = 0.002958858967758715
Trained batch 23 in epoch 5, gen_loss = 2.8636240859826407, disc_loss = 0.002918343345906275
Trained batch 24 in epoch 5, gen_loss = 2.861861448287964, disc_loss = 0.0028979016421362756
Trained batch 25 in epoch 5, gen_loss = 2.8617484752948465, disc_loss = 0.0028678563718970576
Trained batch 26 in epoch 5, gen_loss = 2.849732487289994, disc_loss = 0.002891221070765621
Trained batch 27 in epoch 5, gen_loss = 2.861920407840184, disc_loss = 0.002929489365279941
Trained batch 28 in epoch 5, gen_loss = 2.873378613899494, disc_loss = 0.002959189426699846
Trained batch 29 in epoch 5, gen_loss = 2.87675629456838, disc_loss = 0.0029674008294629556
Trained batch 30 in epoch 5, gen_loss = 2.8965090859320854, disc_loss = 0.0029427820118144155
Trained batch 31 in epoch 5, gen_loss = 2.8947993963956833, disc_loss = 0.002907146768848179
Trained batch 32 in epoch 5, gen_loss = 2.895636226191665, disc_loss = 0.0029024564569364443
Trained batch 33 in epoch 5, gen_loss = 2.8987635794807884, disc_loss = 0.002941582663505174
Trained batch 34 in epoch 5, gen_loss = 2.8977089064461845, disc_loss = 0.0029940603666805793
Trained batch 35 in epoch 5, gen_loss = 2.88656167851554, disc_loss = 0.0030668589590479517
Trained batch 36 in epoch 5, gen_loss = 2.8843930283108272, disc_loss = 0.003088169828736903
Trained batch 37 in epoch 5, gen_loss = 2.883402134242811, disc_loss = 0.0031248303222175884
Trained batch 38 in epoch 5, gen_loss = 2.8915026554694543, disc_loss = 0.003248179770218065
Trained batch 39 in epoch 5, gen_loss = 2.8853913962841036, disc_loss = 0.0033283308235695585
Trained batch 40 in epoch 5, gen_loss = 2.8921990976101015, disc_loss = 0.0033504801274209122
Trained batch 41 in epoch 5, gen_loss = 2.8940076487404958, disc_loss = 0.0033508934374410835
Trained batch 42 in epoch 5, gen_loss = 2.898779275805451, disc_loss = 0.003362015596331032
Trained batch 43 in epoch 5, gen_loss = 2.8988873904401604, disc_loss = 0.0033925375080963768
Trained batch 44 in epoch 5, gen_loss = 2.89663331773546, disc_loss = 0.0034306383821078473
Trained batch 45 in epoch 5, gen_loss = 2.8957913751187534, disc_loss = 0.0034389022115172575
Trained batch 46 in epoch 5, gen_loss = 2.892077897457366, disc_loss = 0.003430159750117108
Trained batch 47 in epoch 5, gen_loss = 2.8944025735060372, disc_loss = 0.0034189684156444855
Trained batch 48 in epoch 5, gen_loss = 2.8975473909961935, disc_loss = 0.0034127479148268395
Trained batch 49 in epoch 5, gen_loss = 2.8988023948669435, disc_loss = 0.0034534755046479403
Trained batch 50 in epoch 5, gen_loss = 2.900600797989789, disc_loss = 0.0034600638250327285
Trained batch 51 in epoch 5, gen_loss = 2.9055704336899977, disc_loss = 0.003437567088090313
Trained batch 52 in epoch 5, gen_loss = 2.903795197324933, disc_loss = 0.003433081398296328
Trained batch 53 in epoch 5, gen_loss = 2.9062687202736184, disc_loss = 0.0034059486632166363
Trained batch 54 in epoch 5, gen_loss = 2.908571754802357, disc_loss = 0.003398142570883713
Trained batch 55 in epoch 5, gen_loss = 2.9102806321212222, disc_loss = 0.00337493273504411
Trained batch 56 in epoch 5, gen_loss = 2.9110401931561922, disc_loss = 0.0033661857994861507
Trained batch 57 in epoch 5, gen_loss = 2.911337766154059, disc_loss = 0.003346255263875656
Trained batch 58 in epoch 5, gen_loss = 2.908833580502009, disc_loss = 0.003337018742320775
Trained batch 59 in epoch 5, gen_loss = 2.9135955890019734, disc_loss = 0.0033333886007312686
Trained batch 60 in epoch 5, gen_loss = 2.9130401767668177, disc_loss = 0.003319920584574708
Trained batch 61 in epoch 5, gen_loss = 2.9183936426716466, disc_loss = 0.0033454158317087397
Trained batch 62 in epoch 5, gen_loss = 2.9166900392562622, disc_loss = 0.0033483544885668727
Trained batch 63 in epoch 5, gen_loss = 2.915540289133787, disc_loss = 0.0033403052784706233
Trained batch 64 in epoch 5, gen_loss = 2.9143411196195164, disc_loss = 0.0033236311085952015
Trained batch 65 in epoch 5, gen_loss = 2.916648015831456, disc_loss = 0.0033352788251994007
Trained batch 66 in epoch 5, gen_loss = 2.9163424434946545, disc_loss = 0.0033194239185288994
Trained batch 67 in epoch 5, gen_loss = 2.914143081973581, disc_loss = 0.0033090747567578495
Trained batch 68 in epoch 5, gen_loss = 2.9142648897309233, disc_loss = 0.0032873304621518955
Trained batch 69 in epoch 5, gen_loss = 2.912723306247166, disc_loss = 0.003274442222235458
Trained batch 70 in epoch 5, gen_loss = 2.9118384945560507, disc_loss = 0.0032649982038518073
Trained batch 71 in epoch 5, gen_loss = 2.9090595146020255, disc_loss = 0.0032459572345639267
Trained batch 72 in epoch 5, gen_loss = 2.9086011925788773, disc_loss = 0.003237670966845057
Trained batch 73 in epoch 5, gen_loss = 2.9119547218889803, disc_loss = 0.003226252744679113
Trained batch 74 in epoch 5, gen_loss = 2.913576291402181, disc_loss = 0.003207001599172751
Trained batch 75 in epoch 5, gen_loss = 2.9115673240862394, disc_loss = 0.0031974397961197325
Trained batch 76 in epoch 5, gen_loss = 2.911748656978855, disc_loss = 0.003184115245043264
Trained batch 77 in epoch 5, gen_loss = 2.9092329006928663, disc_loss = 0.003167380771348969
Trained batch 78 in epoch 5, gen_loss = 2.9100532984431786, disc_loss = 0.0031493312422822737
Trained batch 79 in epoch 5, gen_loss = 2.907536193728447, disc_loss = 0.0031360207256511787
Trained batch 80 in epoch 5, gen_loss = 2.908765469068362, disc_loss = 0.0031192065432184826
Trained batch 81 in epoch 5, gen_loss = 2.9112263161961627, disc_loss = 0.0031035854892873366
Trained batch 82 in epoch 5, gen_loss = 2.910712885569377, disc_loss = 0.003089919194006866
Trained batch 83 in epoch 5, gen_loss = 2.912006369658879, disc_loss = 0.003076830655724431
Trained batch 84 in epoch 5, gen_loss = 2.9136414331548353, disc_loss = 0.0030722874860443614
Trained batch 85 in epoch 5, gen_loss = 2.9129101731056393, disc_loss = 0.0030683528748340905
Trained batch 86 in epoch 5, gen_loss = 2.9095723272740157, disc_loss = 0.00305648276116699
Trained batch 87 in epoch 5, gen_loss = 2.9090676009655, disc_loss = 0.0030496567342197523
Trained batch 88 in epoch 5, gen_loss = 2.9101555025979375, disc_loss = 0.003036856738944653
Trained batch 89 in epoch 5, gen_loss = 2.9103316995832653, disc_loss = 0.0030395910234397483
Trained batch 90 in epoch 5, gen_loss = 2.9102249302706875, disc_loss = 0.00303058536687436
Trained batch 91 in epoch 5, gen_loss = 2.9106494965760605, disc_loss = 0.0030318235145861527
Trained batch 92 in epoch 5, gen_loss = 2.9155791523636028, disc_loss = 0.0030306136092892095
Trained batch 93 in epoch 5, gen_loss = 2.9121511033240783, disc_loss = 0.0030404516493287336
Trained batch 94 in epoch 5, gen_loss = 2.9120887455187345, disc_loss = 0.0030307853827252983
Trained batch 95 in epoch 5, gen_loss = 2.912448965013027, disc_loss = 0.003028916722541908
Trained batch 96 in epoch 5, gen_loss = 2.9117086474428473, disc_loss = 0.0030249506703184286
Trained batch 97 in epoch 5, gen_loss = 2.911251240847062, disc_loss = 0.0030250400150365823
Trained batch 98 in epoch 5, gen_loss = 2.9089483612715594, disc_loss = 0.0030369265933963235
Trained batch 99 in epoch 5, gen_loss = 2.9080100774765016, disc_loss = 0.003047051512403414
Trained batch 100 in epoch 5, gen_loss = 2.9083760091573887, disc_loss = 0.0030477295876342324
Trained batch 101 in epoch 5, gen_loss = 2.9100212443108653, disc_loss = 0.0030436332362667458
Trained batch 102 in epoch 5, gen_loss = 2.9100018033703554, disc_loss = 0.003036866347685239
Trained batch 103 in epoch 5, gen_loss = 2.9081912361658535, disc_loss = 0.003031076557817869
Trained batch 104 in epoch 5, gen_loss = 2.9070522217523482, disc_loss = 0.0030250317805136243
Trained batch 105 in epoch 5, gen_loss = 2.9090408379176877, disc_loss = 0.003012002295296077
Trained batch 106 in epoch 5, gen_loss = 2.9102620365463685, disc_loss = 0.00299942173242186
Trained batch 107 in epoch 5, gen_loss = 2.9113408503709017, disc_loss = 0.0029845472524391006
Trained batch 108 in epoch 5, gen_loss = 2.9108442122783136, disc_loss = 0.0029750405992338552
Trained batch 109 in epoch 5, gen_loss = 2.911098191954873, disc_loss = 0.002964738468554887
Trained batch 110 in epoch 5, gen_loss = 2.910424840342891, disc_loss = 0.002955842939381664
Trained batch 111 in epoch 5, gen_loss = 2.912222085254533, disc_loss = 0.0029545211603233057
Trained batch 112 in epoch 5, gen_loss = 2.911794567530134, disc_loss = 0.002946477739832702
Trained batch 113 in epoch 5, gen_loss = 2.9134849602716013, disc_loss = 0.002944514665981395
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 3.2292118072509766, disc_loss = 0.002118748379871249
Trained batch 1 in epoch 6, gen_loss = 3.1001871824264526, disc_loss = 0.001919497677590698
Trained batch 2 in epoch 6, gen_loss = 3.028242826461792, disc_loss = 0.0018607862293720245
Trained batch 3 in epoch 6, gen_loss = 2.9829347729682922, disc_loss = 0.0018552455585449934
Trained batch 4 in epoch 6, gen_loss = 2.9507163047790526, disc_loss = 0.0019036614801734685
Trained batch 5 in epoch 6, gen_loss = 2.948715567588806, disc_loss = 0.0019293853935475151
Trained batch 6 in epoch 6, gen_loss = 2.940744365964617, disc_loss = 0.0019341304432600737
Trained batch 7 in epoch 6, gen_loss = 2.934906303882599, disc_loss = 0.0021201082854531705
Trained batch 8 in epoch 6, gen_loss = 2.9325020843082004, disc_loss = 0.002271175125820769
Trained batch 9 in epoch 6, gen_loss = 2.942119860649109, disc_loss = 0.0025309936609119177
Trained batch 10 in epoch 6, gen_loss = 2.9121592911806973, disc_loss = 0.0028002839112146335
Trained batch 11 in epoch 6, gen_loss = 2.9180009166399636, disc_loss = 0.0030265920407449207
Trained batch 12 in epoch 6, gen_loss = 2.921954393386841, disc_loss = 0.0030382251044592033
Trained batch 13 in epoch 6, gen_loss = 2.9443674428122386, disc_loss = 0.0030603964779792087
Trained batch 14 in epoch 6, gen_loss = 2.951271136601766, disc_loss = 0.0030470715680470067
Trained batch 15 in epoch 6, gen_loss = 2.951929748058319, disc_loss = 0.0030105391779216006
Trained batch 16 in epoch 6, gen_loss = 2.9582242124220905, disc_loss = 0.002971864620442776
Trained batch 17 in epoch 6, gen_loss = 2.938289999961853, disc_loss = 0.002920584067598813
Trained batch 18 in epoch 6, gen_loss = 2.9294650303690055, disc_loss = 0.002855667084651558
Trained batch 19 in epoch 6, gen_loss = 2.944219875335693, disc_loss = 0.002784735395107418
Trained batch 20 in epoch 6, gen_loss = 2.940169924781436, disc_loss = 0.0027162834580632903
Trained batch 21 in epoch 6, gen_loss = 2.948326663537459, disc_loss = 0.002650430801705542
Trained batch 22 in epoch 6, gen_loss = 2.954261655392854, disc_loss = 0.002645763826718473
Trained batch 23 in epoch 6, gen_loss = 2.9431949655214944, disc_loss = 0.002702135025174357
Trained batch 24 in epoch 6, gen_loss = 2.93709753036499, disc_loss = 0.0027881780778989196
Trained batch 25 in epoch 6, gen_loss = 2.9323975214591393, disc_loss = 0.002841636301197398
Trained batch 26 in epoch 6, gen_loss = 2.933637292296798, disc_loss = 0.002872014146608611
Trained batch 27 in epoch 6, gen_loss = 2.931304786886488, disc_loss = 0.0028612192296090405
Trained batch 28 in epoch 6, gen_loss = 2.934430410122049, disc_loss = 0.0028303115074683367
Trained batch 29 in epoch 6, gen_loss = 2.9298092285792032, disc_loss = 0.0028060020064003765
Trained batch 30 in epoch 6, gen_loss = 2.927914434863675, disc_loss = 0.0027726783019099985
Trained batch 31 in epoch 6, gen_loss = 2.9276837557554245, disc_loss = 0.0027520391122379806
Trained batch 32 in epoch 6, gen_loss = 2.9265823797746138, disc_loss = 0.0027175961612639103
Trained batch 33 in epoch 6, gen_loss = 2.9294115515316235, disc_loss = 0.0026832634363980856
Trained batch 34 in epoch 6, gen_loss = 2.9293072836739675, disc_loss = 0.0026534648844972254
Trained batch 35 in epoch 6, gen_loss = 2.9352079563670688, disc_loss = 0.0026215325374828857
Trained batch 36 in epoch 6, gen_loss = 2.9321617242452263, disc_loss = 0.0026014865174688196
Trained batch 37 in epoch 6, gen_loss = 2.931923006710253, disc_loss = 0.0025719294912720982
Trained batch 38 in epoch 6, gen_loss = 2.9361656262324405, disc_loss = 0.0025530455257886876
Trained batch 39 in epoch 6, gen_loss = 2.9324917912483217, disc_loss = 0.002548400228261016
Trained batch 40 in epoch 6, gen_loss = 2.9283441450537704, disc_loss = 0.002546405195394849
Trained batch 41 in epoch 6, gen_loss = 2.929630745024908, disc_loss = 0.0025487814148488852
Trained batch 42 in epoch 6, gen_loss = 2.922545843346174, disc_loss = 0.002554627657911285
Trained batch 43 in epoch 6, gen_loss = 2.9204793951728125, disc_loss = 0.002539008149390363
Trained batch 44 in epoch 6, gen_loss = 2.9205459541744654, disc_loss = 0.002522126445546746
Trained batch 45 in epoch 6, gen_loss = 2.9227879202884175, disc_loss = 0.00250546244205907
Trained batch 46 in epoch 6, gen_loss = 2.9162951378112143, disc_loss = 0.0024884831274245333
Trained batch 47 in epoch 6, gen_loss = 2.913440391421318, disc_loss = 0.0024997994066022025
Trained batch 48 in epoch 6, gen_loss = 2.9204347133636475, disc_loss = 0.002482333360715028
Trained batch 49 in epoch 6, gen_loss = 2.9214137315750124, disc_loss = 0.0024938891199417414
Trained batch 50 in epoch 6, gen_loss = 2.9185770212435256, disc_loss = 0.0024810779460833644
Trained batch 51 in epoch 6, gen_loss = 2.9307677424871006, disc_loss = 0.002474405464734166
Trained batch 52 in epoch 6, gen_loss = 2.927603010861379, disc_loss = 0.002458926055246507
Trained batch 53 in epoch 6, gen_loss = 2.9249616199069552, disc_loss = 0.002442584271732442
Trained batch 54 in epoch 6, gen_loss = 2.923034511912953, disc_loss = 0.0024335461562838066
Trained batch 55 in epoch 6, gen_loss = 2.924609124660492, disc_loss = 0.002451258435030468
Trained batch 56 in epoch 6, gen_loss = 2.9210904104667796, disc_loss = 0.0024753051560796927
Trained batch 57 in epoch 6, gen_loss = 2.9199950242864676, disc_loss = 0.0025001075981859245
Trained batch 58 in epoch 6, gen_loss = 2.9174814587932523, disc_loss = 0.002519086131557696
Trained batch 59 in epoch 6, gen_loss = 2.917375377813975, disc_loss = 0.0025222260679583996
Trained batch 60 in epoch 6, gen_loss = 2.9134421426741803, disc_loss = 0.002527255498132378
Trained batch 61 in epoch 6, gen_loss = 2.9154108070558116, disc_loss = 0.0025214952352877345
Trained batch 62 in epoch 6, gen_loss = 2.9171438406384183, disc_loss = 0.0025093358357451737
Trained batch 63 in epoch 6, gen_loss = 2.914281699806452, disc_loss = 0.002506025877664797
Trained batch 64 in epoch 6, gen_loss = 2.9124346329615665, disc_loss = 0.0024987311102449895
Trained batch 65 in epoch 6, gen_loss = 2.909551161708254, disc_loss = 0.0024924381022256884
Trained batch 66 in epoch 6, gen_loss = 2.9104409395758783, disc_loss = 0.0024826765953521453
Trained batch 67 in epoch 6, gen_loss = 2.914483459556804, disc_loss = 0.00247011476141565
Trained batch 68 in epoch 6, gen_loss = 2.9155449072519937, disc_loss = 0.002464047481265405
Trained batch 69 in epoch 6, gen_loss = 2.912236394201006, disc_loss = 0.0024578887337286556
Trained batch 70 in epoch 6, gen_loss = 2.910123311297994, disc_loss = 0.0024464508013563677
Trained batch 71 in epoch 6, gen_loss = 2.9068521890375347, disc_loss = 0.0024402195542481625
Trained batch 72 in epoch 6, gen_loss = 2.9045036100361443, disc_loss = 0.002428199789703709
Trained batch 73 in epoch 6, gen_loss = 2.9067194494041235, disc_loss = 0.0024212242176479383
Trained batch 74 in epoch 6, gen_loss = 2.910237512588501, disc_loss = 0.00241511523257941
Trained batch 75 in epoch 6, gen_loss = 2.9140798606370626, disc_loss = 0.0024030011416854044
Trained batch 76 in epoch 6, gen_loss = 2.9114915922090603, disc_loss = 0.0023953468620462656
Trained batch 77 in epoch 6, gen_loss = 2.9115245709052453, disc_loss = 0.0023956267948214635
Trained batch 78 in epoch 6, gen_loss = 2.908516530749164, disc_loss = 0.0024002899955132906
Trained batch 79 in epoch 6, gen_loss = 2.905470219254494, disc_loss = 0.002405450305377599
Trained batch 80 in epoch 6, gen_loss = 2.900727969628793, disc_loss = 0.002406922774101941
Trained batch 81 in epoch 6, gen_loss = 2.902650734273399, disc_loss = 0.0024073525436972155
Trained batch 82 in epoch 6, gen_loss = 2.9036039157086106, disc_loss = 0.0024122425722496875
Trained batch 83 in epoch 6, gen_loss = 2.901401854696728, disc_loss = 0.0024090698335341933
Trained batch 84 in epoch 6, gen_loss = 2.9053938893710867, disc_loss = 0.0024035126066711894
Trained batch 85 in epoch 6, gen_loss = 2.9055425954419514, disc_loss = 0.002393421951172397
Trained batch 86 in epoch 6, gen_loss = 2.904967080587628, disc_loss = 0.0023858972554812313
Trained batch 87 in epoch 6, gen_loss = 2.906820833683014, disc_loss = 0.002377500626607798
Trained batch 88 in epoch 6, gen_loss = 2.906735682755374, disc_loss = 0.002369512051731097
Trained batch 89 in epoch 6, gen_loss = 2.9098680708143445, disc_loss = 0.0023663455115941665
Trained batch 90 in epoch 6, gen_loss = 2.9121797373006633, disc_loss = 0.0023703904768738607
Trained batch 91 in epoch 6, gen_loss = 2.9127009044522825, disc_loss = 0.0023739561982675577
Trained batch 92 in epoch 6, gen_loss = 2.9132880421094995, disc_loss = 0.002383802217551537
Trained batch 93 in epoch 6, gen_loss = 2.9116379961054375, disc_loss = 0.0023947255673540876
Trained batch 94 in epoch 6, gen_loss = 2.914819476478978, disc_loss = 0.0023965800879523157
Trained batch 95 in epoch 6, gen_loss = 2.915249635775884, disc_loss = 0.002394718126500569
Trained batch 96 in epoch 6, gen_loss = 2.915613562790389, disc_loss = 0.0023848804076365437
Trained batch 97 in epoch 6, gen_loss = 2.91361052892646, disc_loss = 0.002377599471828387
Trained batch 98 in epoch 6, gen_loss = 2.911712482722119, disc_loss = 0.0023727998962964525
Trained batch 99 in epoch 6, gen_loss = 2.9117080545425416, disc_loss = 0.0023642158310394736
Trained batch 100 in epoch 6, gen_loss = 2.9118346270948354, disc_loss = 0.002358312957164011
Trained batch 101 in epoch 6, gen_loss = 2.9117617466870476, disc_loss = 0.0023565137035249932
Trained batch 102 in epoch 6, gen_loss = 2.912932601947229, disc_loss = 0.0023548105060240453
Trained batch 103 in epoch 6, gen_loss = 2.9150298283650327, disc_loss = 0.00235391084145074
Trained batch 104 in epoch 6, gen_loss = 2.9117477916535877, disc_loss = 0.0023457203470613986
Trained batch 105 in epoch 6, gen_loss = 2.9110586418295807, disc_loss = 0.002344350825845844
Trained batch 106 in epoch 6, gen_loss = 2.912588709982756, disc_loss = 0.002337221641563506
Trained batch 107 in epoch 6, gen_loss = 2.912799334084546, disc_loss = 0.0023402870477487645
Trained batch 108 in epoch 6, gen_loss = 2.911557029146667, disc_loss = 0.0023415956278801512
Trained batch 109 in epoch 6, gen_loss = 2.90955042405562, disc_loss = 0.0023471392564136874
Trained batch 110 in epoch 6, gen_loss = 2.9084486274031907, disc_loss = 0.002350560167116356
Trained batch 111 in epoch 6, gen_loss = 2.9115573359387263, disc_loss = 0.002363898785136241
Trained batch 112 in epoch 6, gen_loss = 2.911040050793538, disc_loss = 0.0023579325411567644
Trained batch 113 in epoch 6, gen_loss = 2.911344519832678, disc_loss = 0.002364723939089137
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.741297960281372, disc_loss = 0.0019477488240227103
Trained batch 1 in epoch 7, gen_loss = 2.894925594329834, disc_loss = 0.002131328859832138
Trained batch 2 in epoch 7, gen_loss = 2.8767759799957275, disc_loss = 0.002171149205726882
Trained batch 3 in epoch 7, gen_loss = 2.8579317927360535, disc_loss = 0.0022591091983485967
Trained batch 4 in epoch 7, gen_loss = 2.92181191444397, disc_loss = 0.0025423568906262515
Trained batch 5 in epoch 7, gen_loss = 2.963813583056132, disc_loss = 0.002967753855045885
Trained batch 6 in epoch 7, gen_loss = 2.938630070005144, disc_loss = 0.0033359885648159044
Trained batch 7 in epoch 7, gen_loss = 2.9479677975177765, disc_loss = 0.0036306325491750613
Trained batch 8 in epoch 7, gen_loss = 2.9396381113264294, disc_loss = 0.00384454187264459
Trained batch 9 in epoch 7, gen_loss = 2.9194137811660767, disc_loss = 0.003895205131266266
Trained batch 10 in epoch 7, gen_loss = 2.899144844575362, disc_loss = 0.003796860501593487
Trained batch 11 in epoch 7, gen_loss = 2.896369477113088, disc_loss = 0.0037084856788472584
Trained batch 12 in epoch 7, gen_loss = 2.8673326602348914, disc_loss = 0.003613915160083427
Trained batch 13 in epoch 7, gen_loss = 2.882431592260088, disc_loss = 0.003595489601138979
Trained batch 14 in epoch 7, gen_loss = 2.87368426322937, disc_loss = 0.003596825439793368
Trained batch 15 in epoch 7, gen_loss = 2.878687009215355, disc_loss = 0.003594595043978188
Trained batch 16 in epoch 7, gen_loss = 2.8812444771037384, disc_loss = 0.0035367132890421677
Trained batch 17 in epoch 7, gen_loss = 2.8868962791230945, disc_loss = 0.003460502905201995
Trained batch 18 in epoch 7, gen_loss = 2.88101023121884, disc_loss = 0.003396270263596977
Trained batch 19 in epoch 7, gen_loss = 2.8880910754203795, disc_loss = 0.003336342115653679
Trained batch 20 in epoch 7, gen_loss = 2.887305043992542, disc_loss = 0.003281664197510552
Trained batch 21 in epoch 7, gen_loss = 2.888133395801891, disc_loss = 0.003220945400905541
Trained batch 22 in epoch 7, gen_loss = 2.8912825999052627, disc_loss = 0.0031589572166052203
Trained batch 23 in epoch 7, gen_loss = 2.881326913833618, disc_loss = 0.0030846226145513356
Trained batch 24 in epoch 7, gen_loss = 2.8705498123168947, disc_loss = 0.0030233566649258137
Trained batch 25 in epoch 7, gen_loss = 2.8717641555345974, disc_loss = 0.0029690593409423646
Trained batch 26 in epoch 7, gen_loss = 2.8776727694052235, disc_loss = 0.002915123581058449
Trained batch 27 in epoch 7, gen_loss = 2.880618989467621, disc_loss = 0.0028492181611779544
Trained batch 28 in epoch 7, gen_loss = 2.884350242285893, disc_loss = 0.00280509112756057
Trained batch 29 in epoch 7, gen_loss = 2.878467011451721, disc_loss = 0.002774093917105347
Trained batch 30 in epoch 7, gen_loss = 2.8858152897127214, disc_loss = 0.002780406626932804
Trained batch 31 in epoch 7, gen_loss = 2.8915342688560486, disc_loss = 0.0027872626051248517
Trained batch 32 in epoch 7, gen_loss = 2.8917055996981533, disc_loss = 0.0027722518531266937
Trained batch 33 in epoch 7, gen_loss = 2.888384124811958, disc_loss = 0.0027430439196691357
Trained batch 34 in epoch 7, gen_loss = 2.8862562928880964, disc_loss = 0.0027344323861013564
Trained batch 35 in epoch 7, gen_loss = 2.882699853844113, disc_loss = 0.0027064472831423497
Trained batch 36 in epoch 7, gen_loss = 2.886479210209202, disc_loss = 0.002684649989336125
Trained batch 37 in epoch 7, gen_loss = 2.8875709834851717, disc_loss = 0.002659961087996826
Trained batch 38 in epoch 7, gen_loss = 2.8951127590277257, disc_loss = 0.0026356513516452066
Trained batch 39 in epoch 7, gen_loss = 2.893395519256592, disc_loss = 0.0026106552104465663
Trained batch 40 in epoch 7, gen_loss = 2.8903724216833346, disc_loss = 0.0025872542642102372
Trained batch 41 in epoch 7, gen_loss = 2.8916985931850614, disc_loss = 0.0025606166676706856
Trained batch 42 in epoch 7, gen_loss = 2.891171616177226, disc_loss = 0.002527599176933426
Trained batch 43 in epoch 7, gen_loss = 2.8960664976726878, disc_loss = 0.00249728847252713
Trained batch 44 in epoch 7, gen_loss = 2.8995387342241075, disc_loss = 0.0024707353570395047
Trained batch 45 in epoch 7, gen_loss = 2.9058475546214892, disc_loss = 0.002454461302081852
Trained batch 46 in epoch 7, gen_loss = 2.905417538703756, disc_loss = 0.0024523730290696975
Trained batch 47 in epoch 7, gen_loss = 2.9090265880028405, disc_loss = 0.0024381962988021164
Trained batch 48 in epoch 7, gen_loss = 2.902257671161574, disc_loss = 0.0024274477583109116
Trained batch 49 in epoch 7, gen_loss = 2.904229989051819, disc_loss = 0.0024149757297709583
Trained batch 50 in epoch 7, gen_loss = 2.901783120398428, disc_loss = 0.002412496175726547
Trained batch 51 in epoch 7, gen_loss = 2.909085663465353, disc_loss = 0.002415885526436166
Trained batch 52 in epoch 7, gen_loss = 2.908831353457469, disc_loss = 0.0024097006776774266
Trained batch 53 in epoch 7, gen_loss = 2.9081973985389427, disc_loss = 0.002392275819416951
Trained batch 54 in epoch 7, gen_loss = 2.909717910939997, disc_loss = 0.0023735325275497004
Trained batch 55 in epoch 7, gen_loss = 2.90751627939088, disc_loss = 0.0023550978263041805
Trained batch 56 in epoch 7, gen_loss = 2.9090743148536014, disc_loss = 0.0023372603269914785
Trained batch 57 in epoch 7, gen_loss = 2.912252496028769, disc_loss = 0.0023191838308462293
Trained batch 58 in epoch 7, gen_loss = 2.910485825296176, disc_loss = 0.002313781588859225
Trained batch 59 in epoch 7, gen_loss = 2.909482312202454, disc_loss = 0.0023113451975708206
Trained batch 60 in epoch 7, gen_loss = 2.9130021626832057, disc_loss = 0.002308408134296292
Trained batch 61 in epoch 7, gen_loss = 2.9108469217054305, disc_loss = 0.00230695134509475
Trained batch 62 in epoch 7, gen_loss = 2.9064113866715204, disc_loss = 0.002310678514371079
Trained batch 63 in epoch 7, gen_loss = 2.9065796583890915, disc_loss = 0.002311355336132692
Trained batch 64 in epoch 7, gen_loss = 2.902150718982403, disc_loss = 0.002312533955018108
Trained batch 65 in epoch 7, gen_loss = 2.903104558135524, disc_loss = 0.0023102919098384905
Trained batch 66 in epoch 7, gen_loss = 2.8999417753361945, disc_loss = 0.0023160606115333626
Trained batch 67 in epoch 7, gen_loss = 2.9028384860824135, disc_loss = 0.0023407062536160298
Trained batch 68 in epoch 7, gen_loss = 2.90185761106187, disc_loss = 0.0023798580801087446
Trained batch 69 in epoch 7, gen_loss = 2.9028238705226355, disc_loss = 0.0024023582726450904
Trained batch 70 in epoch 7, gen_loss = 2.901244865336888, disc_loss = 0.002405696558359433
Trained batch 71 in epoch 7, gen_loss = 2.8993828230433993, disc_loss = 0.0023949580693927905
Trained batch 72 in epoch 7, gen_loss = 2.9001116099422926, disc_loss = 0.0023823545381350263
Trained batch 73 in epoch 7, gen_loss = 2.9054842414082707, disc_loss = 0.002364640235837952
Trained batch 74 in epoch 7, gen_loss = 2.905230852762858, disc_loss = 0.0023514870197201766
Trained batch 75 in epoch 7, gen_loss = 2.9041142651909277, disc_loss = 0.0023393437257159108
Trained batch 76 in epoch 7, gen_loss = 2.9038279118475976, disc_loss = 0.002337255084270297
Trained batch 77 in epoch 7, gen_loss = 2.905620425175398, disc_loss = 0.002353955551277464
Trained batch 78 in epoch 7, gen_loss = 2.9080315511437913, disc_loss = 0.0023613997125007872
Trained batch 79 in epoch 7, gen_loss = 2.9077133506536486, disc_loss = 0.002352582734602038
Trained batch 80 in epoch 7, gen_loss = 2.9079640941855347, disc_loss = 0.0023408409920923504
Trained batch 81 in epoch 7, gen_loss = 2.905934842621408, disc_loss = 0.0023353562772660177
Trained batch 82 in epoch 7, gen_loss = 2.9062747581895576, disc_loss = 0.0023557922805670694
Trained batch 83 in epoch 7, gen_loss = 2.9039083123207092, disc_loss = 0.0024108386701083787
Trained batch 84 in epoch 7, gen_loss = 2.9055474477655747, disc_loss = 0.00248012415763429
Trained batch 85 in epoch 7, gen_loss = 2.904087693192238, disc_loss = 0.002529485650674635
Trained batch 86 in epoch 7, gen_loss = 2.9013415588729683, disc_loss = 0.0025610015152193522
Trained batch 87 in epoch 7, gen_loss = 2.8995427299629557, disc_loss = 0.0025682261502052743
Trained batch 88 in epoch 7, gen_loss = 2.8982485894406778, disc_loss = 0.00256265462716267
Trained batch 89 in epoch 7, gen_loss = 2.897475020090739, disc_loss = 0.0025589088042680588
Trained batch 90 in epoch 7, gen_loss = 2.896465469192673, disc_loss = 0.002559337909538094
Trained batch 91 in epoch 7, gen_loss = 2.8980596713397815, disc_loss = 0.0025705158490302933
Trained batch 92 in epoch 7, gen_loss = 2.896476414895827, disc_loss = 0.002575771704125869
Trained batch 93 in epoch 7, gen_loss = 2.8946730101362186, disc_loss = 0.0025716865140488964
Trained batch 94 in epoch 7, gen_loss = 2.899273920059204, disc_loss = 0.002561990538072821
Trained batch 95 in epoch 7, gen_loss = 2.900356916089853, disc_loss = 0.0025557494094149056
Trained batch 96 in epoch 7, gen_loss = 2.9024799804097596, disc_loss = 0.0025498299708244265
Trained batch 97 in epoch 7, gen_loss = 2.9016867949038136, disc_loss = 0.002541700835406248
Trained batch 98 in epoch 7, gen_loss = 2.901326651525016, disc_loss = 0.0025295244713285656
Trained batch 99 in epoch 7, gen_loss = 2.902091827392578, disc_loss = 0.002516395791899413
Trained batch 100 in epoch 7, gen_loss = 2.9023245632058323, disc_loss = 0.002505915505710141
Trained batch 101 in epoch 7, gen_loss = 2.903687044685962, disc_loss = 0.0024940302953872758
Trained batch 102 in epoch 7, gen_loss = 2.9055195826928593, disc_loss = 0.002481605877955128
Trained batch 103 in epoch 7, gen_loss = 2.9046509105425615, disc_loss = 0.0024740938242757693
Trained batch 104 in epoch 7, gen_loss = 2.9075600646791004, disc_loss = 0.0024630566316080236
Trained batch 105 in epoch 7, gen_loss = 2.9100331877762415, disc_loss = 0.0024572814548968003
Trained batch 106 in epoch 7, gen_loss = 2.9131256197100486, disc_loss = 0.0024626117523881457
Trained batch 107 in epoch 7, gen_loss = 2.9115080656828702, disc_loss = 0.002466193595426847
Trained batch 108 in epoch 7, gen_loss = 2.910254027865349, disc_loss = 0.002469902675504873
Trained batch 109 in epoch 7, gen_loss = 2.907026212865656, disc_loss = 0.002485804713796824
Trained batch 110 in epoch 7, gen_loss = 2.90945924939336, disc_loss = 0.002481871528911765
Trained batch 111 in epoch 7, gen_loss = 2.910618381840842, disc_loss = 0.0024760278164259425
Trained batch 112 in epoch 7, gen_loss = 2.911409283106306, disc_loss = 0.0024640315296787737
Trained batch 113 in epoch 7, gen_loss = 2.910982330640157, disc_loss = 0.002453050963180303
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 2.7535858154296875, disc_loss = 0.0020303456112742424
Trained batch 1 in epoch 8, gen_loss = 2.66408908367157, disc_loss = 0.0025522992946207523
Trained batch 2 in epoch 8, gen_loss = 2.723461071650187, disc_loss = 0.003206671060373386
Trained batch 3 in epoch 8, gen_loss = 2.8657544255256653, disc_loss = 0.0031536175520159304
Trained batch 4 in epoch 8, gen_loss = 2.93278489112854, disc_loss = 0.0029782725032418966
Trained batch 5 in epoch 8, gen_loss = 2.9150737524032593, disc_loss = 0.002842081982331971
Trained batch 6 in epoch 8, gen_loss = 2.93966691834586, disc_loss = 0.0026694095826574732
Trained batch 7 in epoch 8, gen_loss = 2.8924171924591064, disc_loss = 0.002585500158602372
Trained batch 8 in epoch 8, gen_loss = 2.902158578236898, disc_loss = 0.0027343010167694753
Trained batch 9 in epoch 8, gen_loss = 2.886249876022339, disc_loss = 0.0026007458800449967
Trained batch 10 in epoch 8, gen_loss = 2.8899530063975942, disc_loss = 0.002632129577581178
Trained batch 11 in epoch 8, gen_loss = 2.8876459995905557, disc_loss = 0.0025540504818006107
Trained batch 12 in epoch 8, gen_loss = 2.8710119174076962, disc_loss = 0.0026034195459662722
Trained batch 13 in epoch 8, gen_loss = 2.8578782081604004, disc_loss = 0.002551700678720538
Trained batch 14 in epoch 8, gen_loss = 2.849536657333374, disc_loss = 0.0025143792464708287
Trained batch 15 in epoch 8, gen_loss = 2.8438479155302048, disc_loss = 0.0024823591447784565
Trained batch 16 in epoch 8, gen_loss = 2.856655471465167, disc_loss = 0.002445945023175548
Trained batch 17 in epoch 8, gen_loss = 2.861001584264967, disc_loss = 0.002386590097254763
Trained batch 18 in epoch 8, gen_loss = 2.8496902992850854, disc_loss = 0.002345939197479502
Trained batch 19 in epoch 8, gen_loss = 2.860226237773895, disc_loss = 0.0023167390434537085
Trained batch 20 in epoch 8, gen_loss = 2.859619151978266, disc_loss = 0.0022811292271528926
Trained batch 21 in epoch 8, gen_loss = 2.8613040230490943, disc_loss = 0.002259143046103418
Trained batch 22 in epoch 8, gen_loss = 2.87053862861965, disc_loss = 0.002235634890182511
Trained batch 23 in epoch 8, gen_loss = 2.8707139094670615, disc_loss = 0.0022488571994472295
Trained batch 24 in epoch 8, gen_loss = 2.875884647369385, disc_loss = 0.002260390240699053
Trained batch 25 in epoch 8, gen_loss = 2.8714503966844998, disc_loss = 0.0022414472769014537
Trained batch 26 in epoch 8, gen_loss = 2.878282803076285, disc_loss = 0.0022285380357600472
Trained batch 27 in epoch 8, gen_loss = 2.868138475077493, disc_loss = 0.002211471412530435
Trained batch 28 in epoch 8, gen_loss = 2.8690835689676217, disc_loss = 0.0022033075962601036
Trained batch 29 in epoch 8, gen_loss = 2.868673499425252, disc_loss = 0.0021817590459249914
Trained batch 30 in epoch 8, gen_loss = 2.865414127226799, disc_loss = 0.002156115621478567
Trained batch 31 in epoch 8, gen_loss = 2.8634598404169083, disc_loss = 0.0021364428794186097
Trained batch 32 in epoch 8, gen_loss = 2.871879808830492, disc_loss = 0.0021031467018253875
Trained batch 33 in epoch 8, gen_loss = 2.8673047177931843, disc_loss = 0.0020814695505096633
Trained batch 34 in epoch 8, gen_loss = 2.8734535694122316, disc_loss = 0.0020754636697737235
Trained batch 35 in epoch 8, gen_loss = 2.867954088581933, disc_loss = 0.0020564071213205657
Trained batch 36 in epoch 8, gen_loss = 2.872365210507367, disc_loss = 0.002040243537693813
Trained batch 37 in epoch 8, gen_loss = 2.8780383059853003, disc_loss = 0.0020196426531152896
Trained batch 38 in epoch 8, gen_loss = 2.878443412291698, disc_loss = 0.001995922197611668
Trained batch 39 in epoch 8, gen_loss = 2.880563831329346, disc_loss = 0.001976781993289478
Trained batch 40 in epoch 8, gen_loss = 2.88171997302916, disc_loss = 0.0019510086290765462
Trained batch 41 in epoch 8, gen_loss = 2.8850105490003313, disc_loss = 0.0019350362958253495
Trained batch 42 in epoch 8, gen_loss = 2.883599181507909, disc_loss = 0.0019414216187934195
Trained batch 43 in epoch 8, gen_loss = 2.885546424172141, disc_loss = 0.001931633220837367
Trained batch 44 in epoch 8, gen_loss = 2.8817858907911513, disc_loss = 0.0019244148602916135
Trained batch 45 in epoch 8, gen_loss = 2.8760895418084185, disc_loss = 0.001912874088663122
Trained batch 46 in epoch 8, gen_loss = 2.8740041357405643, disc_loss = 0.0019114714368504095
Trained batch 47 in epoch 8, gen_loss = 2.872111236055692, disc_loss = 0.001918093517209248
Trained batch 48 in epoch 8, gen_loss = 2.868112880356458, disc_loss = 0.0019352654189973765
Trained batch 49 in epoch 8, gen_loss = 2.868346972465515, disc_loss = 0.0019494632980786265
Trained batch 50 in epoch 8, gen_loss = 2.864550927106072, disc_loss = 0.0019580923071058063
Trained batch 51 in epoch 8, gen_loss = 2.86179479268881, disc_loss = 0.001964915828116668
Trained batch 52 in epoch 8, gen_loss = 2.864758356562201, disc_loss = 0.00196429880617081
Trained batch 53 in epoch 8, gen_loss = 2.867585367626614, disc_loss = 0.0019650246896263626
Trained batch 54 in epoch 8, gen_loss = 2.8687789786945688, disc_loss = 0.0019528195261955261
Trained batch 55 in epoch 8, gen_loss = 2.868903862578528, disc_loss = 0.0019455577566986904
Trained batch 56 in epoch 8, gen_loss = 2.8653294496368944, disc_loss = 0.0019340293477861244
Trained batch 57 in epoch 8, gen_loss = 2.872907383688565, disc_loss = 0.001935155241316634
Trained batch 58 in epoch 8, gen_loss = 2.873006667120982, disc_loss = 0.0019378232536837459
Trained batch 59 in epoch 8, gen_loss = 2.8744473298390707, disc_loss = 0.0019607334029084693
Trained batch 60 in epoch 8, gen_loss = 2.8772188561861634, disc_loss = 0.0019774413305014126
Trained batch 61 in epoch 8, gen_loss = 2.878553294366406, disc_loss = 0.00197970257478676
Trained batch 62 in epoch 8, gen_loss = 2.886638645141844, disc_loss = 0.0019671739954944876
Trained batch 63 in epoch 8, gen_loss = 2.8874971829354763, disc_loss = 0.0019578462870413205
Trained batch 64 in epoch 8, gen_loss = 2.8879765033721925, disc_loss = 0.0019462691781182702
Trained batch 65 in epoch 8, gen_loss = 2.888851624546629, disc_loss = 0.001941973015412011
Trained batch 66 in epoch 8, gen_loss = 2.886159060606316, disc_loss = 0.0019372351686539713
Trained batch 67 in epoch 8, gen_loss = 2.8855261837734894, disc_loss = 0.0019365628301302956
Trained batch 68 in epoch 8, gen_loss = 2.884960198747939, disc_loss = 0.0019328573776031103
Trained batch 69 in epoch 8, gen_loss = 2.8860670600618636, disc_loss = 0.001934327496149178
Trained batch 70 in epoch 8, gen_loss = 2.887783557596341, disc_loss = 0.0019383838082152143
Trained batch 71 in epoch 8, gen_loss = 2.8933962318632336, disc_loss = 0.0019445522193564102
Trained batch 72 in epoch 8, gen_loss = 2.889454779559619, disc_loss = 0.0019454933297884179
Trained batch 73 in epoch 8, gen_loss = 2.8874060495479688, disc_loss = 0.0019403237336617265
Trained batch 74 in epoch 8, gen_loss = 2.8872524388631184, disc_loss = 0.0019400427211076021
Trained batch 75 in epoch 8, gen_loss = 2.8875476121902466, disc_loss = 0.0019408534648583124
Trained batch 76 in epoch 8, gen_loss = 2.8888709018756815, disc_loss = 0.001940012573833009
Trained batch 77 in epoch 8, gen_loss = 2.8887546062469482, disc_loss = 0.0019334499718239291
Trained batch 78 in epoch 8, gen_loss = 2.8842699738997446, disc_loss = 0.0019256150161352339
Trained batch 79 in epoch 8, gen_loss = 2.8866309821605682, disc_loss = 0.0019299478823086246
Trained batch 80 in epoch 8, gen_loss = 2.8892578342814503, disc_loss = 0.0019402870488709506
Trained batch 81 in epoch 8, gen_loss = 2.8904461569902375, disc_loss = 0.001956200945509098
Trained batch 82 in epoch 8, gen_loss = 2.8932196835437454, disc_loss = 0.0019525673425565642
Trained batch 83 in epoch 8, gen_loss = 2.8944661106382097, disc_loss = 0.0019505603011653182
Trained batch 84 in epoch 8, gen_loss = 2.8953426613527187, disc_loss = 0.0019449600018560886
Trained batch 85 in epoch 8, gen_loss = 2.897451120753621, disc_loss = 0.0019460377651591633
Trained batch 86 in epoch 8, gen_loss = 2.900677864578949, disc_loss = 0.0019524517982941248
Trained batch 87 in epoch 8, gen_loss = 2.9001486762003466, disc_loss = 0.0019423115987923336
Trained batch 88 in epoch 8, gen_loss = 2.8965085302845814, disc_loss = 0.0019357600667922015
Trained batch 89 in epoch 8, gen_loss = 2.897245348824395, disc_loss = 0.001932728712240027
Trained batch 90 in epoch 8, gen_loss = 2.8964192867279053, disc_loss = 0.0019366982045000071
Trained batch 91 in epoch 8, gen_loss = 2.900325067665266, disc_loss = 0.0019399412634337077
Trained batch 92 in epoch 8, gen_loss = 2.900935447344216, disc_loss = 0.0019450438814738425
Trained batch 93 in epoch 8, gen_loss = 2.90259827451503, disc_loss = 0.0019396218208675372
Trained batch 94 in epoch 8, gen_loss = 2.9018317975495993, disc_loss = 0.0019311677689026845
Trained batch 95 in epoch 8, gen_loss = 2.9074900125463805, disc_loss = 0.0019224515951160963
Trained batch 96 in epoch 8, gen_loss = 2.9073150796988574, disc_loss = 0.0019182984587573207
Trained batch 97 in epoch 8, gen_loss = 2.906384572690847, disc_loss = 0.0019113815719812956
Trained batch 98 in epoch 8, gen_loss = 2.906562908731326, disc_loss = 0.0019027692291678654
Trained batch 99 in epoch 8, gen_loss = 2.9103155851364138, disc_loss = 0.0018943322158884257
Trained batch 100 in epoch 8, gen_loss = 2.910923766617728, disc_loss = 0.001886555427076793
Trained batch 101 in epoch 8, gen_loss = 2.9123235005958406, disc_loss = 0.0018866207706285459
Trained batch 102 in epoch 8, gen_loss = 2.9147121512774126, disc_loss = 0.0018873477888121768
Trained batch 103 in epoch 8, gen_loss = 2.9116749740563908, disc_loss = 0.0018823705300187261
Trained batch 104 in epoch 8, gen_loss = 2.9113893713269916, disc_loss = 0.001877782167866826
Trained batch 105 in epoch 8, gen_loss = 2.911353536371915, disc_loss = 0.001888606866452632
Trained batch 106 in epoch 8, gen_loss = 2.91024326832495, disc_loss = 0.001902266651409391
Trained batch 107 in epoch 8, gen_loss = 2.9078084694014654, disc_loss = 0.001903927984164545
Trained batch 108 in epoch 8, gen_loss = 2.908130381085457, disc_loss = 0.0019016812508498584
Trained batch 109 in epoch 8, gen_loss = 2.9092009739442304, disc_loss = 0.0019038145049390467
Trained batch 110 in epoch 8, gen_loss = 2.909909626385113, disc_loss = 0.0019079364567726582
Trained batch 111 in epoch 8, gen_loss = 2.9091300517320633, disc_loss = 0.0019118780764983967
Trained batch 112 in epoch 8, gen_loss = 2.90897524462337, disc_loss = 0.001917366163013915
Trained batch 113 in epoch 8, gen_loss = 2.9069243334887322, disc_loss = 0.0019185284924644389
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 2.4285006523132324, disc_loss = 0.00183460908010602
Trained batch 1 in epoch 9, gen_loss = 2.7245755195617676, disc_loss = 0.001794756855815649
Trained batch 2 in epoch 9, gen_loss = 2.7726425329844155, disc_loss = 0.0016738988536720474
Trained batch 3 in epoch 9, gen_loss = 2.7950424551963806, disc_loss = 0.0016785940970294178
Trained batch 4 in epoch 9, gen_loss = 2.8076865673065186, disc_loss = 0.0016276022884994744
Trained batch 5 in epoch 9, gen_loss = 2.834433833758036, disc_loss = 0.001623090822249651
Trained batch 6 in epoch 9, gen_loss = 2.8438503742218018, disc_loss = 0.0016048547279621875
Trained batch 7 in epoch 9, gen_loss = 2.842488020658493, disc_loss = 0.0015677282644901425
Trained batch 8 in epoch 9, gen_loss = 2.833110120561388, disc_loss = 0.0016561168918593063
Trained batch 9 in epoch 9, gen_loss = 2.8200475454330443, disc_loss = 0.0017679353943094612
Trained batch 10 in epoch 9, gen_loss = 2.8045589490370317, disc_loss = 0.0018475561783733692
Trained batch 11 in epoch 9, gen_loss = 2.7943750619888306, disc_loss = 0.001882980208999167
Trained batch 12 in epoch 9, gen_loss = 2.7937350273132324, disc_loss = 0.0019095822488172697
Trained batch 13 in epoch 9, gen_loss = 2.8013287442071095, disc_loss = 0.0019238662872729556
Trained batch 14 in epoch 9, gen_loss = 2.811655886967977, disc_loss = 0.0019124329245338836
Trained batch 15 in epoch 9, gen_loss = 2.8122623711824417, disc_loss = 0.00186486365419114
Trained batch 16 in epoch 9, gen_loss = 2.835809581420001, disc_loss = 0.0018328319317387307
Trained batch 17 in epoch 9, gen_loss = 2.8319945202933416, disc_loss = 0.0017878774023200902
Trained batch 18 in epoch 9, gen_loss = 2.835209319466039, disc_loss = 0.0017592929928612552
Trained batch 19 in epoch 9, gen_loss = 2.8615819096565245, disc_loss = 0.0017816775303799658
Trained batch 20 in epoch 9, gen_loss = 2.8478997889019193, disc_loss = 0.0017802624552998515
Trained batch 21 in epoch 9, gen_loss = 2.842706810344349, disc_loss = 0.0017714793688024986
Trained batch 22 in epoch 9, gen_loss = 2.8478684425354004, disc_loss = 0.0017643577783651974
Trained batch 23 in epoch 9, gen_loss = 2.856378823518753, disc_loss = 0.0017350769291321437
Trained batch 24 in epoch 9, gen_loss = 2.8575601291656496, disc_loss = 0.0017088359501212834
Trained batch 25 in epoch 9, gen_loss = 2.860943601681636, disc_loss = 0.0016834254537780697
Trained batch 26 in epoch 9, gen_loss = 2.8575270970662436, disc_loss = 0.0016659368519429808
Trained batch 27 in epoch 9, gen_loss = 2.8708776320729936, disc_loss = 0.0016539173167464988
Trained batch 28 in epoch 9, gen_loss = 2.876054788457936, disc_loss = 0.001639261416255914
Trained batch 29 in epoch 9, gen_loss = 2.8807358264923097, disc_loss = 0.0016202336875721813
Trained batch 30 in epoch 9, gen_loss = 2.8751454814787833, disc_loss = 0.0016090211105502903
Trained batch 31 in epoch 9, gen_loss = 2.870059959590435, disc_loss = 0.0015941555029712617
Trained batch 32 in epoch 9, gen_loss = 2.8679655826453008, disc_loss = 0.0015794970800705028
Trained batch 33 in epoch 9, gen_loss = 2.8688413676093605, disc_loss = 0.0015713312964448158
Trained batch 34 in epoch 9, gen_loss = 2.8729514939444405, disc_loss = 0.0015573792126295821
Trained batch 35 in epoch 9, gen_loss = 2.87534589237637, disc_loss = 0.0015548514428600255
Trained batch 36 in epoch 9, gen_loss = 2.8789429406862, disc_loss = 0.0015927763762757987
Trained batch 37 in epoch 9, gen_loss = 2.8834012056651868, disc_loss = 0.001664033542558747
Trained batch 38 in epoch 9, gen_loss = 2.876215800260886, disc_loss = 0.0017365410547846784
Trained batch 39 in epoch 9, gen_loss = 2.874403065443039, disc_loss = 0.0017846783943241463
Trained batch 40 in epoch 9, gen_loss = 2.87397723663144, disc_loss = 0.001804518658190784
Trained batch 41 in epoch 9, gen_loss = 2.8790941465468634, disc_loss = 0.001810997333710215
Trained batch 42 in epoch 9, gen_loss = 2.875414637632148, disc_loss = 0.0018090560171363313
Trained batch 43 in epoch 9, gen_loss = 2.8727533979849382, disc_loss = 0.0018073690113272858
Trained batch 44 in epoch 9, gen_loss = 2.872629107369317, disc_loss = 0.0017948662862181664
Trained batch 45 in epoch 9, gen_loss = 2.867642957231273, disc_loss = 0.0017727368989574682
Trained batch 46 in epoch 9, gen_loss = 2.874087135842506, disc_loss = 0.0017642279792121276
Trained batch 47 in epoch 9, gen_loss = 2.871889660755793, disc_loss = 0.0017621044450303696
Trained batch 48 in epoch 9, gen_loss = 2.8717371979538275, disc_loss = 0.0017652944103358503
Trained batch 49 in epoch 9, gen_loss = 2.8714392471313475, disc_loss = 0.0017766518250573427
Trained batch 50 in epoch 9, gen_loss = 2.880388100941976, disc_loss = 0.0018079380023147107
Trained batch 51 in epoch 9, gen_loss = 2.874445621783917, disc_loss = 0.0018575666035758331
Trained batch 52 in epoch 9, gen_loss = 2.8722398146143497, disc_loss = 0.0019426323607440968
Trained batch 53 in epoch 9, gen_loss = 2.8719188372294107, disc_loss = 0.0020239219614908237
Trained batch 54 in epoch 9, gen_loss = 2.8708656657825817, disc_loss = 0.002059981710573828
Trained batch 55 in epoch 9, gen_loss = 2.8667348282677785, disc_loss = 0.002061154540569987
Trained batch 56 in epoch 9, gen_loss = 2.8622159706918815, disc_loss = 0.0020507014236053485
Trained batch 57 in epoch 9, gen_loss = 2.863034823845173, disc_loss = 0.0020473755962327764
Trained batch 58 in epoch 9, gen_loss = 2.8648833218267407, disc_loss = 0.002070746247427759
Trained batch 59 in epoch 9, gen_loss = 2.864358838399251, disc_loss = 0.002087310341691288
Trained batch 60 in epoch 9, gen_loss = 2.8674285099154613, disc_loss = 0.0020829665132981465
Trained batch 61 in epoch 9, gen_loss = 2.867127183944948, disc_loss = 0.002070788638628719
Trained batch 62 in epoch 9, gen_loss = 2.8695219660562183, disc_loss = 0.002056273944964189
Trained batch 63 in epoch 9, gen_loss = 2.875854216516018, disc_loss = 0.0020475348965192097
Trained batch 64 in epoch 9, gen_loss = 2.8768152126899134, disc_loss = 0.002032875401290277
Trained batch 65 in epoch 9, gen_loss = 2.8771545164512866, disc_loss = 0.002020071654855697
Trained batch 66 in epoch 9, gen_loss = 2.8776128256498876, disc_loss = 0.0020184548156433253
Trained batch 67 in epoch 9, gen_loss = 2.8737537299885467, disc_loss = 0.0020234561362646192
Trained batch 68 in epoch 9, gen_loss = 2.8734204941901607, disc_loss = 0.002021538469083337
Trained batch 69 in epoch 9, gen_loss = 2.8706736496516636, disc_loss = 0.002014896585439731
Trained batch 70 in epoch 9, gen_loss = 2.8713607015744063, disc_loss = 0.0020125506939300875
Trained batch 71 in epoch 9, gen_loss = 2.8733226226435766, disc_loss = 0.002000624031805071
Trained batch 72 in epoch 9, gen_loss = 2.8702868925382012, disc_loss = 0.002000190610263803
Trained batch 73 in epoch 9, gen_loss = 2.8704445104341247, disc_loss = 0.0020036673341638635
Trained batch 74 in epoch 9, gen_loss = 2.8701150544484455, disc_loss = 0.0019931404983314373
Trained batch 75 in epoch 9, gen_loss = 2.870456428904282, disc_loss = 0.0019960851097589752
Trained batch 76 in epoch 9, gen_loss = 2.8724200694591966, disc_loss = 0.0019912151143547485
Trained batch 77 in epoch 9, gen_loss = 2.8738855765416074, disc_loss = 0.0019869562872769073
Trained batch 78 in epoch 9, gen_loss = 2.875040603589408, disc_loss = 0.0019874213642110646
Trained batch 79 in epoch 9, gen_loss = 2.875300833582878, disc_loss = 0.001978205567138502
Trained batch 80 in epoch 9, gen_loss = 2.87722341808272, disc_loss = 0.001969773290006237
Trained batch 81 in epoch 9, gen_loss = 2.879601068613006, disc_loss = 0.0019625038974748063
Trained batch 82 in epoch 9, gen_loss = 2.8811262630554566, disc_loss = 0.00195612570941336
Trained batch 83 in epoch 9, gen_loss = 2.8820781196866716, disc_loss = 0.0019475501772138245
Trained batch 84 in epoch 9, gen_loss = 2.8901556744295007, disc_loss = 0.0019445981275673736
Trained batch 85 in epoch 9, gen_loss = 2.8891001745711926, disc_loss = 0.0019402012092245438
Trained batch 86 in epoch 9, gen_loss = 2.8880180490428002, disc_loss = 0.0019398969524518598
Trained batch 87 in epoch 9, gen_loss = 2.8910466866059736, disc_loss = 0.001949524624003309
Trained batch 88 in epoch 9, gen_loss = 2.888824211077744, disc_loss = 0.0019752538842776938
Trained batch 89 in epoch 9, gen_loss = 2.8892693281173707, disc_loss = 0.00200229956729648
Trained batch 90 in epoch 9, gen_loss = 2.8900818719968693, disc_loss = 0.0020109081012708555
Trained batch 91 in epoch 9, gen_loss = 2.888904120611108, disc_loss = 0.002007636192897537
Trained batch 92 in epoch 9, gen_loss = 2.8900907014005925, disc_loss = 0.0019988154032347743
Trained batch 93 in epoch 9, gen_loss = 2.8932541634174105, disc_loss = 0.001994539888828319
Trained batch 94 in epoch 9, gen_loss = 2.8930560111999513, disc_loss = 0.0020076878044117045
Trained batch 95 in epoch 9, gen_loss = 2.8916557878255844, disc_loss = 0.002033090390492968
Trained batch 96 in epoch 9, gen_loss = 2.889282103666325, disc_loss = 0.0020576251122246007
Trained batch 97 in epoch 9, gen_loss = 2.8891816431162307, disc_loss = 0.0020695286583183904
Trained batch 98 in epoch 9, gen_loss = 2.889102572142476, disc_loss = 0.0020835289838629766
Trained batch 99 in epoch 9, gen_loss = 2.892977011203766, disc_loss = 0.0021014578867470848
Trained batch 100 in epoch 9, gen_loss = 2.8967193636563744, disc_loss = 0.0021144712965077916
Trained batch 101 in epoch 9, gen_loss = 2.8989750614353254, disc_loss = 0.0021264616019941646
Trained batch 102 in epoch 9, gen_loss = 2.896707634324009, disc_loss = 0.002177783328185346
Trained batch 103 in epoch 9, gen_loss = 2.8978656301131616, disc_loss = 0.002215283425287523
Trained batch 104 in epoch 9, gen_loss = 2.896960076831636, disc_loss = 0.002239942794022638
Trained batch 105 in epoch 9, gen_loss = 2.897636350595726, disc_loss = 0.002289405417132174
Trained batch 106 in epoch 9, gen_loss = 2.896666136857505, disc_loss = 0.0023261045457177282
Trained batch 107 in epoch 9, gen_loss = 2.89474857295001, disc_loss = 0.002352132452802767
Trained batch 108 in epoch 9, gen_loss = 2.896604463594769, disc_loss = 0.002362814481442777
Trained batch 109 in epoch 9, gen_loss = 2.8981894969940187, disc_loss = 0.0023996231543027204
Trained batch 110 in epoch 9, gen_loss = 2.900117571289475, disc_loss = 0.0025820557068957873
Trained batch 111 in epoch 9, gen_loss = 2.901206061244011, disc_loss = 0.0027019751365254968
Trained batch 112 in epoch 9, gen_loss = 2.9016584527176037, disc_loss = 0.0027288741497034454
Trained batch 113 in epoch 9, gen_loss = 2.901011952182703, disc_loss = 0.0027624823274540206
Testing Epoch 9
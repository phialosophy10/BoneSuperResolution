/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 3.2791330814361572, disc_loss = 0.6767676472663879
Trained batch 1 in epoch 0, gen_loss = 3.3198156356811523, disc_loss = 1.0058829486370087
Trained batch 2 in epoch 0, gen_loss = 3.2453814347585044, disc_loss = 0.8826240499814352
Trained batch 3 in epoch 0, gen_loss = 3.1399495005607605, disc_loss = 0.768182098865509
Trained batch 4 in epoch 0, gen_loss = 3.030225133895874, disc_loss = 0.6943138182163239
Trained batch 5 in epoch 0, gen_loss = 2.9509101708730063, disc_loss = 0.6314101964235306
Trained batch 6 in epoch 0, gen_loss = 2.91917507989066, disc_loss = 0.5809616574219295
Trained batch 7 in epoch 0, gen_loss = 2.8868857324123383, disc_loss = 0.5386565886437893
Trained batch 8 in epoch 0, gen_loss = 2.8677910963694253, disc_loss = 0.5023150924179289
Trained batch 9 in epoch 0, gen_loss = 2.827340340614319, disc_loss = 0.4697842881083488
Trained batch 10 in epoch 0, gen_loss = 2.802884166890925, disc_loss = 0.44225516237995843
Trained batch 11 in epoch 0, gen_loss = 2.8000125885009766, disc_loss = 0.4179910272359848
Trained batch 12 in epoch 0, gen_loss = 2.7865936756134033, disc_loss = 0.396330489562108
Trained batch 13 in epoch 0, gen_loss = 2.7740901708602905, disc_loss = 0.3776881865092686
Trained batch 14 in epoch 0, gen_loss = 2.7758535226186116, disc_loss = 0.3611483484506607
Trained batch 15 in epoch 0, gen_loss = 2.773692086338997, disc_loss = 0.34556266479194164
Trained batch 16 in epoch 0, gen_loss = 2.7731863891377166, disc_loss = 0.3312092291958192
Trained batch 17 in epoch 0, gen_loss = 2.790730463133918, disc_loss = 0.31801804444856113
Trained batch 18 in epoch 0, gen_loss = 2.788859204242104, disc_loss = 0.306750677918133
Trained batch 19 in epoch 0, gen_loss = 2.7837585330009462, disc_loss = 0.29752201288938523
Trained batch 20 in epoch 0, gen_loss = 2.7871131102244058, disc_loss = 0.2905315976767313
Trained batch 21 in epoch 0, gen_loss = 2.797416567802429, disc_loss = 0.28746639124371787
Trained batch 22 in epoch 0, gen_loss = 2.8064684142237124, disc_loss = 0.28245060923306836
Trained batch 23 in epoch 0, gen_loss = 2.8064034084479013, disc_loss = 0.27455642136434716
Trained batch 24 in epoch 0, gen_loss = 2.8049613571166994, disc_loss = 0.2669739186763763
Trained batch 25 in epoch 0, gen_loss = 2.807950652562655, disc_loss = 0.2592526631286511
Trained batch 26 in epoch 0, gen_loss = 2.8107790328838207, disc_loss = 0.2518581189215183
Trained batch 27 in epoch 0, gen_loss = 2.8090668065207347, disc_loss = 0.24477327854505607
Trained batch 28 in epoch 0, gen_loss = 2.807783611889543, disc_loss = 0.23854524513770795
Trained batch 29 in epoch 0, gen_loss = 2.807381844520569, disc_loss = 0.2325824889043967
Trained batch 30 in epoch 0, gen_loss = 2.808069098380304, disc_loss = 0.22703419457520208
Trained batch 31 in epoch 0, gen_loss = 2.818497233092785, disc_loss = 0.22237953543663025
Trained batch 32 in epoch 0, gen_loss = 2.8206184632850415, disc_loss = 0.21961894179835464
Trained batch 33 in epoch 0, gen_loss = 2.839330988771775, disc_loss = 0.21808303454343012
Trained batch 34 in epoch 0, gen_loss = 2.8471101692744663, disc_loss = 0.21517101632697241
Trained batch 35 in epoch 0, gen_loss = 2.8492117987738714, disc_loss = 0.21164125845664078
Trained batch 36 in epoch 0, gen_loss = 2.857082785786809, disc_loss = 0.20759964623563998
Trained batch 37 in epoch 0, gen_loss = 2.8679112446935555, disc_loss = 0.20328166855401114
Trained batch 38 in epoch 0, gen_loss = 2.8658580780029297, disc_loss = 0.1993039516875377
Trained batch 39 in epoch 0, gen_loss = 2.8714617788791656, disc_loss = 0.19531646715477108
Trained batch 40 in epoch 0, gen_loss = 2.8704615278941827, disc_loss = 0.1914639538381158
Trained batch 41 in epoch 0, gen_loss = 2.8732792820249284, disc_loss = 0.187753832322501
Trained batch 42 in epoch 0, gen_loss = 2.8774562769157943, disc_loss = 0.18419172796745634
Trained batch 43 in epoch 0, gen_loss = 2.8794982975179497, disc_loss = 0.1807640129700303
Trained batch 44 in epoch 0, gen_loss = 2.8854025310940212, disc_loss = 0.17764646278487312
Trained batch 45 in epoch 0, gen_loss = 2.8844300560329272, disc_loss = 0.1745341535171737
Trained batch 46 in epoch 0, gen_loss = 2.8828192213748363, disc_loss = 0.1715151180929326
Trained batch 47 in epoch 0, gen_loss = 2.88366607328256, disc_loss = 0.1685603936202824
Trained batch 48 in epoch 0, gen_loss = 2.8828262163668263, disc_loss = 0.16574568696776215
Trained batch 49 in epoch 0, gen_loss = 2.882388367652893, disc_loss = 0.1629923851042986
Trained batch 50 in epoch 0, gen_loss = 2.8843915883232567, disc_loss = 0.16031612642109394
Trained batch 51 in epoch 0, gen_loss = 2.887148985495934, disc_loss = 0.15786153167629471
Trained batch 52 in epoch 0, gen_loss = 2.8866506252648696, disc_loss = 0.15539396635063416
Trained batch 53 in epoch 0, gen_loss = 2.885496073298984, disc_loss = 0.15299594081524345
Trained batch 54 in epoch 0, gen_loss = 2.8895824735814877, disc_loss = 0.15070216337388212
Trained batch 55 in epoch 0, gen_loss = 2.8883737921714783, disc_loss = 0.14863596949726343
Trained batch 56 in epoch 0, gen_loss = 2.8887791131672107, disc_loss = 0.1468723060138393
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 3.0377039909362793, disc_loss = 0.0721893459558487
Trained batch 1 in epoch 1, gen_loss = 3.0828096866607666, disc_loss = 0.07826968654990196
Trained batch 2 in epoch 1, gen_loss = 2.9716505209604898, disc_loss = 0.07568869243065517
Trained batch 3 in epoch 1, gen_loss = 2.95099800825119, disc_loss = 0.0679761003702879
Trained batch 4 in epoch 1, gen_loss = 2.958669567108154, disc_loss = 0.059599870815873146
Trained batch 5 in epoch 1, gen_loss = 2.9414056142171225, disc_loss = 0.054904933708409466
Trained batch 6 in epoch 1, gen_loss = 2.9663491589682445, disc_loss = 0.05033945105969906
Trained batch 7 in epoch 1, gen_loss = 2.954627186059952, disc_loss = 0.046852651285007596
Trained batch 8 in epoch 1, gen_loss = 2.9783344798617892, disc_loss = 0.04406462257934941
Trained batch 9 in epoch 1, gen_loss = 2.9788660526275637, disc_loss = 0.0417329927906394
Trained batch 10 in epoch 1, gen_loss = 2.984623843973333, disc_loss = 0.039646231146021324
Trained batch 11 in epoch 1, gen_loss = 2.9753121932347617, disc_loss = 0.03791648071880142
Trained batch 12 in epoch 1, gen_loss = 2.955225210923415, disc_loss = 0.03640937747863623
Trained batch 13 in epoch 1, gen_loss = 2.967476180621556, disc_loss = 0.035081839987209866
Trained batch 14 in epoch 1, gen_loss = 2.970066547393799, disc_loss = 0.0338719146947066
Trained batch 15 in epoch 1, gen_loss = 2.97784361243248, disc_loss = 0.03283556713722646
Trained batch 16 in epoch 1, gen_loss = 2.9833640210768757, disc_loss = 0.03195991903981742
Trained batch 17 in epoch 1, gen_loss = 2.970671229892307, disc_loss = 0.031256101404627167
Trained batch 18 in epoch 1, gen_loss = 2.982734015113429, disc_loss = 0.030537788609140797
Trained batch 19 in epoch 1, gen_loss = 2.974730336666107, disc_loss = 0.029972282145172356
Trained batch 20 in epoch 1, gen_loss = 2.970761401312692, disc_loss = 0.029320567048021724
Trained batch 21 in epoch 1, gen_loss = 2.977520845153115, disc_loss = 0.028773451139303772
Trained batch 22 in epoch 1, gen_loss = 2.9843893154807715, disc_loss = 0.028237799020565075
Trained batch 23 in epoch 1, gen_loss = 2.9850146571795144, disc_loss = 0.027792734016353886
Trained batch 24 in epoch 1, gen_loss = 2.983914976119995, disc_loss = 0.027323238924145697
Trained batch 25 in epoch 1, gen_loss = 2.9725451194323025, disc_loss = 0.026959276471573573
Trained batch 26 in epoch 1, gen_loss = 2.970350389127378, disc_loss = 0.0265900278808894
Trained batch 27 in epoch 1, gen_loss = 2.9732543400355746, disc_loss = 0.02624050501201834
Trained batch 28 in epoch 1, gen_loss = 2.9677143014710525, disc_loss = 0.02607585605362366
Trained batch 29 in epoch 1, gen_loss = 2.9684595982233684, disc_loss = 0.02598027673860391
Trained batch 30 in epoch 1, gen_loss = 2.9672566767661803, disc_loss = 0.02604475124709068
Trained batch 31 in epoch 1, gen_loss = 2.9637139663100243, disc_loss = 0.026119690504856408
Trained batch 32 in epoch 1, gen_loss = 2.965677832112168, disc_loss = 0.026092221903981583
Trained batch 33 in epoch 1, gen_loss = 2.957031144815333, disc_loss = 0.026044139857677853
Trained batch 34 in epoch 1, gen_loss = 2.960712616784232, disc_loss = 0.025905479543975422
Trained batch 35 in epoch 1, gen_loss = 2.9632054236200123, disc_loss = 0.025683885698931083
Trained batch 36 in epoch 1, gen_loss = 2.9587454344775224, disc_loss = 0.025638320911172276
Trained batch 37 in epoch 1, gen_loss = 2.9667347355892786, disc_loss = 0.02571447384788802
Trained batch 38 in epoch 1, gen_loss = 2.966694862414629, disc_loss = 0.02558216180365819
Trained batch 39 in epoch 1, gen_loss = 2.9586405754089355, disc_loss = 0.02560701034963131
Trained batch 40 in epoch 1, gen_loss = 2.9628244376764066, disc_loss = 0.025455509108014224
Trained batch 41 in epoch 1, gen_loss = 2.9639798346019925, disc_loss = 0.02519472777133896
Trained batch 42 in epoch 1, gen_loss = 2.961745533832284, disc_loss = 0.024963217549199283
Trained batch 43 in epoch 1, gen_loss = 2.958633000200445, disc_loss = 0.02473407223905352
Trained batch 44 in epoch 1, gen_loss = 2.9619053416781957, disc_loss = 0.02450549915019009
Trained batch 45 in epoch 1, gen_loss = 2.96816377017809, disc_loss = 0.024228877347448597
Trained batch 46 in epoch 1, gen_loss = 2.964609480918722, disc_loss = 0.024058423857105538
Trained batch 47 in epoch 1, gen_loss = 2.967534750699997, disc_loss = 0.023922969897588093
Trained batch 48 in epoch 1, gen_loss = 2.971441852803133, disc_loss = 0.02377173905165828
Trained batch 49 in epoch 1, gen_loss = 2.968025026321411, disc_loss = 0.023758734315633773
Trained batch 50 in epoch 1, gen_loss = 2.9694919773176607, disc_loss = 0.02372754777909494
Trained batch 51 in epoch 1, gen_loss = 2.9746234096013584, disc_loss = 0.02366491253129565
Trained batch 52 in epoch 1, gen_loss = 2.9760427160083123, disc_loss = 0.023510555666432065
Trained batch 53 in epoch 1, gen_loss = 2.9737407322283143, disc_loss = 0.02330407176028799
Trained batch 54 in epoch 1, gen_loss = 2.978345346450806, disc_loss = 0.02317170731045983
Trained batch 55 in epoch 1, gen_loss = 2.977994224854878, disc_loss = 0.023149414220824838
Trained batch 56 in epoch 1, gen_loss = 2.97549817854898, disc_loss = 0.023015242380400498
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 2.5822203159332275, disc_loss = 0.015575495548546314
Trained batch 1 in epoch 2, gen_loss = 2.774896502494812, disc_loss = 0.014408158604055643
Trained batch 2 in epoch 2, gen_loss = 2.9592721462249756, disc_loss = 0.014414116740226746
Trained batch 3 in epoch 2, gen_loss = 2.93499892950058, disc_loss = 0.014007197692990303
Trained batch 4 in epoch 2, gen_loss = 2.9135657787322997, disc_loss = 0.014433505758643151
Trained batch 5 in epoch 2, gen_loss = 2.9860370556513467, disc_loss = 0.016606625479956467
Trained batch 6 in epoch 2, gen_loss = 2.9371245247977122, disc_loss = 0.02499703344489847
Trained batch 7 in epoch 2, gen_loss = 2.9895734190940857, disc_loss = 0.03694327757693827
Trained batch 8 in epoch 2, gen_loss = 2.8904136021931968, disc_loss = 0.04958671683238612
Trained batch 9 in epoch 2, gen_loss = 2.9237097978591917, disc_loss = 0.07293101269751787
Trained batch 10 in epoch 2, gen_loss = 2.9709872982718726, disc_loss = 0.09352786720476368
Trained batch 11 in epoch 2, gen_loss = 3.0245123902956643, disc_loss = 0.1634938445252677
Trained batch 12 in epoch 2, gen_loss = 3.084612387877244, disc_loss = 0.2701498202693004
Trained batch 13 in epoch 2, gen_loss = 3.070372326033456, disc_loss = 0.27567566093057394
Trained batch 14 in epoch 2, gen_loss = 3.042899560928345, disc_loss = 0.2680179219692945
Trained batch 15 in epoch 2, gen_loss = 3.0206040143966675, disc_loss = 0.2579564881743863
Trained batch 16 in epoch 2, gen_loss = 3.0138786680558147, disc_loss = 0.2460795444819857
Trained batch 17 in epoch 2, gen_loss = 2.988560954729716, disc_loss = 0.2350817849445674
Trained batch 18 in epoch 2, gen_loss = 2.984460629914936, disc_loss = 0.22410807415450873
Trained batch 19 in epoch 2, gen_loss = 2.976316499710083, disc_loss = 0.21403197972103954
Trained batch 20 in epoch 2, gen_loss = 2.9728847231183733, disc_loss = 0.20471672562971002
Trained batch 21 in epoch 2, gen_loss = 2.9719568490982056, disc_loss = 0.19628964897922493
Trained batch 22 in epoch 2, gen_loss = 2.970007730566937, disc_loss = 0.18835707348973854
Trained batch 23 in epoch 2, gen_loss = 2.964798390865326, disc_loss = 0.18105885976304611
Trained batch 24 in epoch 2, gen_loss = 2.9655214595794677, disc_loss = 0.17432589396834375
Trained batch 25 in epoch 2, gen_loss = 2.9748807503626895, disc_loss = 0.1680678467337902
Trained batch 26 in epoch 2, gen_loss = 2.975178118105288, disc_loss = 0.16234420195083926
Trained batch 27 in epoch 2, gen_loss = 2.974282673427037, disc_loss = 0.15704000950790942
Trained batch 28 in epoch 2, gen_loss = 2.9728771653668633, disc_loss = 0.15205145604780007
Trained batch 29 in epoch 2, gen_loss = 2.968497935930888, disc_loss = 0.14733307401960094
Trained batch 30 in epoch 2, gen_loss = 2.966679103912846, disc_loss = 0.14291715285470408
Trained batch 31 in epoch 2, gen_loss = 2.9740770384669304, disc_loss = 0.13877072761533782
Trained batch 32 in epoch 2, gen_loss = 2.9771432226354424, disc_loss = 0.1348564254515099
Trained batch 33 in epoch 2, gen_loss = 2.985758332645192, disc_loss = 0.13115753033472335
Trained batch 34 in epoch 2, gen_loss = 2.9896914209638323, disc_loss = 0.12765845794762884
Trained batch 35 in epoch 2, gen_loss = 2.982450670666165, disc_loss = 0.12457242349369659
Trained batch 36 in epoch 2, gen_loss = 2.982313774727486, disc_loss = 0.1214800075300642
Trained batch 37 in epoch 2, gen_loss = 2.9831898588883248, disc_loss = 0.11853757564370569
Trained batch 38 in epoch 2, gen_loss = 2.98055449510232, disc_loss = 0.11574079951223655
Trained batch 39 in epoch 2, gen_loss = 2.9780931949615477, disc_loss = 0.11308588767424226
Trained batch 40 in epoch 2, gen_loss = 2.9790312953111604, disc_loss = 0.11057182624027496
Trained batch 41 in epoch 2, gen_loss = 2.977531387692406, disc_loss = 0.10815947713507783
Trained batch 42 in epoch 2, gen_loss = 2.9723657785460005, disc_loss = 0.10588537336348794
Trained batch 43 in epoch 2, gen_loss = 2.9716031442989004, disc_loss = 0.10366633883677423
Trained batch 44 in epoch 2, gen_loss = 2.9703963650597465, disc_loss = 0.1015291371072332
Trained batch 45 in epoch 2, gen_loss = 2.9694065270216567, disc_loss = 0.09948809346710534
Trained batch 46 in epoch 2, gen_loss = 2.971994369588, disc_loss = 0.09752472888361266
Trained batch 47 in epoch 2, gen_loss = 2.9687848885854087, disc_loss = 0.09579572824683662
Trained batch 48 in epoch 2, gen_loss = 2.963504732871542, disc_loss = 0.09407865805361344
Trained batch 49 in epoch 2, gen_loss = 2.965526275634766, disc_loss = 0.09240265773609281
Trained batch 50 in epoch 2, gen_loss = 2.9671517587175558, disc_loss = 0.09074758115571503
Trained batch 51 in epoch 2, gen_loss = 2.9675177106490502, disc_loss = 0.0891623344952957
Trained batch 52 in epoch 2, gen_loss = 2.9656675671631434, disc_loss = 0.0876187755603273
Trained batch 53 in epoch 2, gen_loss = 2.965393825813576, disc_loss = 0.08612719515373034
Trained batch 54 in epoch 2, gen_loss = 2.96501033522866, disc_loss = 0.0846861419945278
Trained batch 55 in epoch 2, gen_loss = 2.9629224921975816, disc_loss = 0.08331826880540964
Trained batch 56 in epoch 2, gen_loss = 2.9707148995315817, disc_loss = 0.08198690792676389
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 2.9589524269104004, disc_loss = 0.0068975226022303104
Trained batch 1 in epoch 3, gen_loss = 2.984807848930359, disc_loss = 0.0066018677316606045
Trained batch 2 in epoch 3, gen_loss = 2.9471634229024253, disc_loss = 0.006524808704853058
Trained batch 3 in epoch 3, gen_loss = 2.868395149707794, disc_loss = 0.007123696617782116
Trained batch 4 in epoch 3, gen_loss = 2.90926251411438, disc_loss = 0.0071386007592082025
Trained batch 5 in epoch 3, gen_loss = 2.8841915925343833, disc_loss = 0.007161047775298357
Trained batch 6 in epoch 3, gen_loss = 2.9288361413138255, disc_loss = 0.007096728110419852
Trained batch 7 in epoch 3, gen_loss = 2.9219116270542145, disc_loss = 0.006951636867597699
Trained batch 8 in epoch 3, gen_loss = 2.9072718885209827, disc_loss = 0.006882745151718457
Trained batch 9 in epoch 3, gen_loss = 2.885070824623108, disc_loss = 0.006888655060902238
Trained batch 10 in epoch 3, gen_loss = 2.885676232251254, disc_loss = 0.0068339113230732355
Trained batch 11 in epoch 3, gen_loss = 2.8825963536898294, disc_loss = 0.006806808329808216
Trained batch 12 in epoch 3, gen_loss = 2.890358246289767, disc_loss = 0.006786225363612175
Trained batch 13 in epoch 3, gen_loss = 2.898690973009382, disc_loss = 0.00675264499815447
Trained batch 14 in epoch 3, gen_loss = 2.9062612215677897, disc_loss = 0.006713874327639739
Trained batch 15 in epoch 3, gen_loss = 2.921070381999016, disc_loss = 0.006663909211056307
Trained batch 16 in epoch 3, gen_loss = 2.9200908857233383, disc_loss = 0.006704187075443128
Trained batch 17 in epoch 3, gen_loss = 2.9303096532821655, disc_loss = 0.006742553242171804
Trained batch 18 in epoch 3, gen_loss = 2.938011458045558, disc_loss = 0.006937296154271615
Trained batch 19 in epoch 3, gen_loss = 2.9475521564483644, disc_loss = 0.00717138855252415
Trained batch 20 in epoch 3, gen_loss = 2.9464990411485945, disc_loss = 0.007389533932187727
Trained batch 21 in epoch 3, gen_loss = 2.9432429617101494, disc_loss = 0.007490340429781513
Trained batch 22 in epoch 3, gen_loss = 2.941843789556752, disc_loss = 0.007525562652913125
Trained batch 23 in epoch 3, gen_loss = 2.9380777974923453, disc_loss = 0.007530254331262161
Trained batch 24 in epoch 3, gen_loss = 2.9407513523101807, disc_loss = 0.007601435799151659
Trained batch 25 in epoch 3, gen_loss = 2.9480499029159546, disc_loss = 0.007777919652513587
Trained batch 26 in epoch 3, gen_loss = 2.939116327850907, disc_loss = 0.007969243814133935
Trained batch 27 in epoch 3, gen_loss = 2.9311443056379045, disc_loss = 0.00805425998156092
Trained batch 28 in epoch 3, gen_loss = 2.9376233692826896, disc_loss = 0.008174642936551365
Trained batch 29 in epoch 3, gen_loss = 2.937146719296773, disc_loss = 0.008291841220731537
Trained batch 30 in epoch 3, gen_loss = 2.941006821970786, disc_loss = 0.008384507915545856
Trained batch 31 in epoch 3, gen_loss = 2.9409062266349792, disc_loss = 0.008382981948670931
Trained batch 32 in epoch 3, gen_loss = 2.9361464327031914, disc_loss = 0.008373506550648899
Trained batch 33 in epoch 3, gen_loss = 2.935406404383042, disc_loss = 0.008341904811780243
Trained batch 34 in epoch 3, gen_loss = 2.9325301442827496, disc_loss = 0.008317592261093004
Trained batch 35 in epoch 3, gen_loss = 2.9332288106282554, disc_loss = 0.008266543089929555
Trained batch 36 in epoch 3, gen_loss = 2.9386359549857475, disc_loss = 0.008291935573357183
Trained batch 37 in epoch 3, gen_loss = 2.940898054524472, disc_loss = 0.008296156449145392
Trained batch 38 in epoch 3, gen_loss = 2.943639889741555, disc_loss = 0.008333147861636601
Trained batch 39 in epoch 3, gen_loss = 2.943244385719299, disc_loss = 0.008341906080022454
Trained batch 40 in epoch 3, gen_loss = 2.944220327749485, disc_loss = 0.008472741286202175
Trained batch 41 in epoch 3, gen_loss = 2.944351519857134, disc_loss = 0.008669922616155375
Trained batch 42 in epoch 3, gen_loss = 2.9494846920634425, disc_loss = 0.008823254145681858
Trained batch 43 in epoch 3, gen_loss = 2.950413768941706, disc_loss = 0.00880025917748836
Trained batch 44 in epoch 3, gen_loss = 2.950695843166775, disc_loss = 0.008816806392537223
Trained batch 45 in epoch 3, gen_loss = 2.953259333320286, disc_loss = 0.008875668615750645
Trained batch 46 in epoch 3, gen_loss = 2.956201248980583, disc_loss = 0.008817183141140862
Trained batch 47 in epoch 3, gen_loss = 2.951794554789861, disc_loss = 0.00882369307995153
Trained batch 48 in epoch 3, gen_loss = 2.956444876534598, disc_loss = 0.008789928040790315
Trained batch 49 in epoch 3, gen_loss = 2.957565259933472, disc_loss = 0.008770411778241395
Trained batch 50 in epoch 3, gen_loss = 2.9569194363612756, disc_loss = 0.00875048586806538
Trained batch 51 in epoch 3, gen_loss = 2.955326419610244, disc_loss = 0.008724831277504563
Trained batch 52 in epoch 3, gen_loss = 2.9543806336960703, disc_loss = 0.00866930934442383
Trained batch 53 in epoch 3, gen_loss = 2.957595781043724, disc_loss = 0.00862290548954021
Trained batch 54 in epoch 3, gen_loss = 2.9612380374561655, disc_loss = 0.008662847996774045
Trained batch 55 in epoch 3, gen_loss = 2.962217160633632, disc_loss = 0.008705168954163258
Trained batch 56 in epoch 3, gen_loss = 2.9647224995127894, disc_loss = 0.008668056468626386
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 3.050846815109253, disc_loss = 0.005407384596765041
Trained batch 1 in epoch 4, gen_loss = 2.981653571128845, disc_loss = 0.005560637451708317
Trained batch 2 in epoch 4, gen_loss = 3.0929078261057534, disc_loss = 0.006156073572734992
Trained batch 3 in epoch 4, gen_loss = 3.1028690338134766, disc_loss = 0.007184932474046946
Trained batch 4 in epoch 4, gen_loss = 3.04502534866333, disc_loss = 0.007520459778606892
Trained batch 5 in epoch 4, gen_loss = 3.0540882349014282, disc_loss = 0.007652904372662306
Trained batch 6 in epoch 4, gen_loss = 3.0566169193812778, disc_loss = 0.00788195843675307
Trained batch 7 in epoch 4, gen_loss = 3.0189270079135895, disc_loss = 0.008213861146941781
Trained batch 8 in epoch 4, gen_loss = 3.0201655758751764, disc_loss = 0.008476524510317378
Trained batch 9 in epoch 4, gen_loss = 3.0019832611083985, disc_loss = 0.008819507528096437
Trained batch 10 in epoch 4, gen_loss = 2.989384261044589, disc_loss = 0.00884502652016553
Trained batch 11 in epoch 4, gen_loss = 2.98443071047465, disc_loss = 0.0086709123570472
Trained batch 12 in epoch 4, gen_loss = 2.9958571837498593, disc_loss = 0.00880970605290853
Trained batch 13 in epoch 4, gen_loss = 2.9889810596193587, disc_loss = 0.009245698739375387
Trained batch 14 in epoch 4, gen_loss = 2.9926002184549967, disc_loss = 0.00927474678804477
Trained batch 15 in epoch 4, gen_loss = 2.9756971448659897, disc_loss = 0.009112477506278083
Trained batch 16 in epoch 4, gen_loss = 2.9712434375987335, disc_loss = 0.008946340010665795
Trained batch 17 in epoch 4, gen_loss = 2.965759211116367, disc_loss = 0.008830218731115261
Trained batch 18 in epoch 4, gen_loss = 2.9601379821175025, disc_loss = 0.008734012169665411
Trained batch 19 in epoch 4, gen_loss = 2.967352020740509, disc_loss = 0.008657204359769822
Trained batch 20 in epoch 4, gen_loss = 2.9688530535925004, disc_loss = 0.008577037114827405
Trained batch 21 in epoch 4, gen_loss = 2.9603980671275747, disc_loss = 0.008413297293538397
Trained batch 22 in epoch 4, gen_loss = 2.9643486271733823, disc_loss = 0.008365069273049417
Trained batch 23 in epoch 4, gen_loss = 2.9667490422725677, disc_loss = 0.008409682118023435
Trained batch 24 in epoch 4, gen_loss = 2.9624511051177977, disc_loss = 0.008519426099956035
Trained batch 25 in epoch 4, gen_loss = 2.9681543753697324, disc_loss = 0.008499136875168635
Trained batch 26 in epoch 4, gen_loss = 2.9728447596232095, disc_loss = 0.00837728348388164
Trained batch 27 in epoch 4, gen_loss = 2.9781474556241716, disc_loss = 0.008359771238506905
Trained batch 28 in epoch 4, gen_loss = 2.9788129822961213, disc_loss = 0.008281373884528875
Trained batch 29 in epoch 4, gen_loss = 2.9783642292022705, disc_loss = 0.008203704018766682
Trained batch 30 in epoch 4, gen_loss = 2.98277311940347, disc_loss = 0.008090715780253372
Trained batch 31 in epoch 4, gen_loss = 2.9778986796736717, disc_loss = 0.008105199769488536
Trained batch 32 in epoch 4, gen_loss = 2.98525366638646, disc_loss = 0.008096661404565428
Trained batch 33 in epoch 4, gen_loss = 2.988792300224304, disc_loss = 0.008012099396985243
Trained batch 34 in epoch 4, gen_loss = 2.9900387695857455, disc_loss = 0.007890007358842663
Trained batch 35 in epoch 4, gen_loss = 2.985870447423723, disc_loss = 0.007826129187985012
Trained batch 36 in epoch 4, gen_loss = 2.989833864005836, disc_loss = 0.007768331718555576
Trained batch 37 in epoch 4, gen_loss = 2.9860483219749048, disc_loss = 0.007745824490771874
Trained batch 38 in epoch 4, gen_loss = 2.9800039193569083, disc_loss = 0.007740873156879575
Trained batch 39 in epoch 4, gen_loss = 2.979468309879303, disc_loss = 0.007705509039806202
Trained batch 40 in epoch 4, gen_loss = 2.9797605188881477, disc_loss = 0.0076396622774531926
Trained batch 41 in epoch 4, gen_loss = 2.974013646443685, disc_loss = 0.0075930625566148335
Trained batch 42 in epoch 4, gen_loss = 2.9710249235463695, disc_loss = 0.007534148545156038
Trained batch 43 in epoch 4, gen_loss = 2.973513505675576, disc_loss = 0.007515926787164062
Trained batch 44 in epoch 4, gen_loss = 2.969719558291965, disc_loss = 0.007474122067085571
Trained batch 45 in epoch 4, gen_loss = 2.967158042866251, disc_loss = 0.007415621647732737
Trained batch 46 in epoch 4, gen_loss = 2.9660552562551294, disc_loss = 0.007378765832672411
Trained batch 47 in epoch 4, gen_loss = 2.965310280521711, disc_loss = 0.007311461876573351
Trained batch 48 in epoch 4, gen_loss = 2.9616808064129887, disc_loss = 0.007251428435461557
Trained batch 49 in epoch 4, gen_loss = 2.964362301826477, disc_loss = 0.007204192862845957
Trained batch 50 in epoch 4, gen_loss = 2.964755016214707, disc_loss = 0.007156899148671359
Trained batch 51 in epoch 4, gen_loss = 2.9666655567976146, disc_loss = 0.007116502370291318
Trained batch 52 in epoch 4, gen_loss = 2.965081601772668, disc_loss = 0.007072657087536634
Trained batch 53 in epoch 4, gen_loss = 2.9623440813135216, disc_loss = 0.007071713283140626
Trained batch 54 in epoch 4, gen_loss = 2.9622726700522684, disc_loss = 0.0070635606831108986
Trained batch 55 in epoch 4, gen_loss = 2.9659884018557414, disc_loss = 0.0071170128191754755
Trained batch 56 in epoch 4, gen_loss = 2.9678889450274015, disc_loss = 0.007085153575692522
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 2.985567092895508, disc_loss = 0.007207018323242664
Trained batch 1 in epoch 5, gen_loss = 3.023464798927307, disc_loss = 0.006299692904576659
Trained batch 2 in epoch 5, gen_loss = 2.9442684650421143, disc_loss = 0.006133666882912318
Trained batch 3 in epoch 5, gen_loss = 2.95731121301651, disc_loss = 0.005806555971503258
Trained batch 4 in epoch 5, gen_loss = 2.945951318740845, disc_loss = 0.006101714726537466
Trained batch 5 in epoch 5, gen_loss = 2.920874079068502, disc_loss = 0.006025086157023907
Trained batch 6 in epoch 5, gen_loss = 2.91112950869969, disc_loss = 0.006273516786417791
Trained batch 7 in epoch 5, gen_loss = 2.9284805953502655, disc_loss = 0.006693260453175753
Trained batch 8 in epoch 5, gen_loss = 2.9349789354536266, disc_loss = 0.006697856769379642
Trained batch 9 in epoch 5, gen_loss = 2.9248921871185303, disc_loss = 0.006522864894941449
Trained batch 10 in epoch 5, gen_loss = 2.9140571030703457, disc_loss = 0.006903747646984729
Trained batch 11 in epoch 5, gen_loss = 2.928922454516093, disc_loss = 0.007319685420952737
Trained batch 12 in epoch 5, gen_loss = 2.931798678178054, disc_loss = 0.007143812791372721
Trained batch 13 in epoch 5, gen_loss = 2.9176968847002303, disc_loss = 0.007128954432638628
Trained batch 14 in epoch 5, gen_loss = 2.912991015116374, disc_loss = 0.007373295072466135
Trained batch 15 in epoch 5, gen_loss = 2.913811907172203, disc_loss = 0.007654622400877997
Trained batch 16 in epoch 5, gen_loss = 2.930680373135735, disc_loss = 0.007756637053235489
Trained batch 17 in epoch 5, gen_loss = 2.942353473769294, disc_loss = 0.0076904582221888835
Trained batch 18 in epoch 5, gen_loss = 2.92392709380702, disc_loss = 0.007656817275442575
Trained batch 19 in epoch 5, gen_loss = 2.9314412236213685, disc_loss = 0.0076011406723409895
Trained batch 20 in epoch 5, gen_loss = 2.929109527951195, disc_loss = 0.007512178737670183
Trained batch 21 in epoch 5, gen_loss = 2.9364982626654883, disc_loss = 0.007422474085945974
Trained batch 22 in epoch 5, gen_loss = 2.9412612604058306, disc_loss = 0.007413211278617382
Trained batch 23 in epoch 5, gen_loss = 2.9389936327934265, disc_loss = 0.007295424002222717
Trained batch 24 in epoch 5, gen_loss = 2.9417669010162353, disc_loss = 0.007218947727233171
Trained batch 25 in epoch 5, gen_loss = 2.9493636167966404, disc_loss = 0.0071634902583005335
Trained batch 26 in epoch 5, gen_loss = 2.9488364502235695, disc_loss = 0.007020706681672622
Trained batch 27 in epoch 5, gen_loss = 2.947537694658552, disc_loss = 0.0069284868077374995
Trained batch 28 in epoch 5, gen_loss = 2.944608737682474, disc_loss = 0.006883670840861982
Trained batch 29 in epoch 5, gen_loss = 2.949937629699707, disc_loss = 0.006849550742966433
Trained batch 30 in epoch 5, gen_loss = 2.950734323070895, disc_loss = 0.0067518218044912625
Trained batch 31 in epoch 5, gen_loss = 2.946271874010563, disc_loss = 0.006679648453427944
Trained batch 32 in epoch 5, gen_loss = 2.9424255616737134, disc_loss = 0.00662101731127636
Trained batch 33 in epoch 5, gen_loss = 2.941200375556946, disc_loss = 0.00661452893195126
Trained batch 34 in epoch 5, gen_loss = 2.9384633132389615, disc_loss = 0.006573423776509506
Trained batch 35 in epoch 5, gen_loss = 2.9472059408823648, disc_loss = 0.00652941965058239
Trained batch 36 in epoch 5, gen_loss = 2.946520631377761, disc_loss = 0.0064717358469056924
Trained batch 37 in epoch 5, gen_loss = 2.947293024314077, disc_loss = 0.0063882421542841355
Trained batch 38 in epoch 5, gen_loss = 2.949921760803614, disc_loss = 0.00630763010121882
Trained batch 39 in epoch 5, gen_loss = 2.952716809511185, disc_loss = 0.00627289492986165
Trained batch 40 in epoch 5, gen_loss = 2.95184474456601, disc_loss = 0.006233523457833543
Trained batch 41 in epoch 5, gen_loss = 2.950959461075919, disc_loss = 0.006202917318746802
Trained batch 42 in epoch 5, gen_loss = 2.9473258007404417, disc_loss = 0.006158226359159101
Trained batch 43 in epoch 5, gen_loss = 2.9453635703433645, disc_loss = 0.006114196259824728
Trained batch 44 in epoch 5, gen_loss = 2.9432187027401393, disc_loss = 0.006061463684050574
Trained batch 45 in epoch 5, gen_loss = 2.9431203862895137, disc_loss = 0.00600609371094438
Trained batch 46 in epoch 5, gen_loss = 2.94350850328486, disc_loss = 0.005946056738971395
Trained batch 47 in epoch 5, gen_loss = 2.9467400312423706, disc_loss = 0.005935086441847186
Trained batch 48 in epoch 5, gen_loss = 2.9490097980110015, disc_loss = 0.005918777243671369
Trained batch 49 in epoch 5, gen_loss = 2.9474854278564453, disc_loss = 0.0059112940728664395
Trained batch 50 in epoch 5, gen_loss = 2.9497601845685173, disc_loss = 0.00591282961050085
Trained batch 51 in epoch 5, gen_loss = 2.9454228694622335, disc_loss = 0.005901769609548724
Trained batch 52 in epoch 5, gen_loss = 2.9428377916228095, disc_loss = 0.005873259411738167
Trained batch 53 in epoch 5, gen_loss = 2.941705505053202, disc_loss = 0.005854920078827827
Trained batch 54 in epoch 5, gen_loss = 2.945240662314675, disc_loss = 0.005836701503192837
Trained batch 55 in epoch 5, gen_loss = 2.9487946161202023, disc_loss = 0.005806867099766221
Trained batch 56 in epoch 5, gen_loss = 2.9549064970853034, disc_loss = 0.00580929530163606
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 3.217352867126465, disc_loss = 0.005691244266927242
Trained batch 1 in epoch 6, gen_loss = 2.9741095304489136, disc_loss = 0.004970927955582738
Trained batch 2 in epoch 6, gen_loss = 3.007177750269572, disc_loss = 0.005135917260001103
Trained batch 3 in epoch 6, gen_loss = 3.0022770762443542, disc_loss = 0.005049380590207875
Trained batch 4 in epoch 6, gen_loss = 3.0218069076538088, disc_loss = 0.004897468071430921
Trained batch 5 in epoch 6, gen_loss = 3.0160417954126992, disc_loss = 0.005867812239254515
Trained batch 6 in epoch 6, gen_loss = 3.0043536594935825, disc_loss = 0.006284955290279218
Trained batch 7 in epoch 6, gen_loss = 2.978123426437378, disc_loss = 0.0061178457690402865
Trained batch 8 in epoch 6, gen_loss = 2.9762467543284097, disc_loss = 0.006167167021582524
Trained batch 9 in epoch 6, gen_loss = 2.95403847694397, disc_loss = 0.006076720589771867
Trained batch 10 in epoch 6, gen_loss = 2.9396696524186567, disc_loss = 0.006028532346879894
Trained batch 11 in epoch 6, gen_loss = 2.9488449494043985, disc_loss = 0.005924957532746096
Trained batch 12 in epoch 6, gen_loss = 2.948213283832257, disc_loss = 0.005754717876418279
Trained batch 13 in epoch 6, gen_loss = 2.9691102504730225, disc_loss = 0.005608239211142063
Trained batch 14 in epoch 6, gen_loss = 2.970845874150594, disc_loss = 0.005691702850162983
Trained batch 15 in epoch 6, gen_loss = 2.975173309445381, disc_loss = 0.005874076334293932
Trained batch 16 in epoch 6, gen_loss = 2.9760199434616985, disc_loss = 0.005913470022599487
Trained batch 17 in epoch 6, gen_loss = 2.9646788703070746, disc_loss = 0.00586874151809348
Trained batch 18 in epoch 6, gen_loss = 2.948802809966238, disc_loss = 0.005867638135034787
Trained batch 19 in epoch 6, gen_loss = 2.957687592506409, disc_loss = 0.005857564858160913
Trained batch 20 in epoch 6, gen_loss = 2.9652992203122093, disc_loss = 0.005772889746973912
Trained batch 21 in epoch 6, gen_loss = 2.9605310396714644, disc_loss = 0.005660111402076754
Trained batch 22 in epoch 6, gen_loss = 2.9632303611091944, disc_loss = 0.005613358893796154
Trained batch 23 in epoch 6, gen_loss = 2.97304967045784, disc_loss = 0.005542381065121542
Trained batch 24 in epoch 6, gen_loss = 2.9718486881256103, disc_loss = 0.005440551387146116
Trained batch 25 in epoch 6, gen_loss = 2.9642867033298197, disc_loss = 0.005402545793913305
Trained batch 26 in epoch 6, gen_loss = 2.96352164833634, disc_loss = 0.005383781442004774
Trained batch 27 in epoch 6, gen_loss = 2.9617108021463667, disc_loss = 0.005344851732453597
Trained batch 28 in epoch 6, gen_loss = 2.9630504476613013, disc_loss = 0.005324332742020488
Trained batch 29 in epoch 6, gen_loss = 2.955418316523234, disc_loss = 0.005261864000931382
Trained batch 30 in epoch 6, gen_loss = 2.9507226943969727, disc_loss = 0.005216342029011538
Trained batch 31 in epoch 6, gen_loss = 2.951552763581276, disc_loss = 0.00518868744984502
Trained batch 32 in epoch 6, gen_loss = 2.9561318773211855, disc_loss = 0.005147185691660552
Trained batch 33 in epoch 6, gen_loss = 2.9503981085384594, disc_loss = 0.005091469954041874
Trained batch 34 in epoch 6, gen_loss = 2.9492618765149796, disc_loss = 0.005068036967090198
Trained batch 35 in epoch 6, gen_loss = 2.951573199696011, disc_loss = 0.0050268592312932014
Trained batch 36 in epoch 6, gen_loss = 2.949049118402842, disc_loss = 0.004996778242088653
Trained batch 37 in epoch 6, gen_loss = 2.951588247951708, disc_loss = 0.004956983520012153
Trained batch 38 in epoch 6, gen_loss = 2.9506191045810013, disc_loss = 0.004938693705182045
Trained batch 39 in epoch 6, gen_loss = 2.9508611857891083, disc_loss = 0.00489766426035203
Trained batch 40 in epoch 6, gen_loss = 2.948995590209961, disc_loss = 0.004869603143050903
Trained batch 41 in epoch 6, gen_loss = 2.9490361554282054, disc_loss = 0.004839894140050525
Trained batch 42 in epoch 6, gen_loss = 2.947481776392737, disc_loss = 0.004816384850676323
Trained batch 43 in epoch 6, gen_loss = 2.9482340162450615, disc_loss = 0.004797828547783534
Trained batch 44 in epoch 6, gen_loss = 2.9520300229390464, disc_loss = 0.004777432124440869
Trained batch 45 in epoch 6, gen_loss = 2.9538656524989917, disc_loss = 0.004757576672684239
Trained batch 46 in epoch 6, gen_loss = 2.9575305238683174, disc_loss = 0.004757968738595856
Trained batch 47 in epoch 6, gen_loss = 2.9566922237475715, disc_loss = 0.0047416702630774426
Trained batch 48 in epoch 6, gen_loss = 2.9546302240722033, disc_loss = 0.004703784209429001
Trained batch 49 in epoch 6, gen_loss = 2.9533983659744263, disc_loss = 0.0046863208897411825
Trained batch 50 in epoch 6, gen_loss = 2.953032091552136, disc_loss = 0.004653808396017435
Trained batch 51 in epoch 6, gen_loss = 2.9518308272728553, disc_loss = 0.004626266026976877
Trained batch 52 in epoch 6, gen_loss = 2.9523720651302696, disc_loss = 0.004592318948850317
Trained batch 53 in epoch 6, gen_loss = 2.9535314595257796, disc_loss = 0.0045681308385812575
Trained batch 54 in epoch 6, gen_loss = 2.9527769912372936, disc_loss = 0.004533037670295347
Trained batch 55 in epoch 6, gen_loss = 2.951410072190421, disc_loss = 0.004509664107380169
Trained batch 56 in epoch 6, gen_loss = 2.947528554682146, disc_loss = 0.004475913901012717
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 2.9742279052734375, disc_loss = 0.0032790512777864933
Trained batch 1 in epoch 7, gen_loss = 2.930622100830078, disc_loss = 0.003675726242363453
Trained batch 2 in epoch 7, gen_loss = 2.898810625076294, disc_loss = 0.003732308279722929
Trained batch 3 in epoch 7, gen_loss = 2.8945438265800476, disc_loss = 0.0035880684736184776
Trained batch 4 in epoch 7, gen_loss = 2.8815943241119384, disc_loss = 0.00351437758654356
Trained batch 5 in epoch 7, gen_loss = 2.914620280265808, disc_loss = 0.003487104161952933
Trained batch 6 in epoch 7, gen_loss = 2.914588451385498, disc_loss = 0.0034714735645268646
Trained batch 7 in epoch 7, gen_loss = 2.8845669627189636, disc_loss = 0.0034373902599327266
Trained batch 8 in epoch 7, gen_loss = 2.887666702270508, disc_loss = 0.003380795552705725
Trained batch 9 in epoch 7, gen_loss = 2.9153557300567625, disc_loss = 0.0034891890594735742
Trained batch 10 in epoch 7, gen_loss = 2.9225656769492407, disc_loss = 0.0038511536549776793
Trained batch 11 in epoch 7, gen_loss = 2.91924516359965, disc_loss = 0.003824387715818981
Trained batch 12 in epoch 7, gen_loss = 2.8981297199542704, disc_loss = 0.003930423981868303
Trained batch 13 in epoch 7, gen_loss = 2.907315969467163, disc_loss = 0.0038975533430597614
Trained batch 14 in epoch 7, gen_loss = 2.9072699228922527, disc_loss = 0.0038036840967833998
Trained batch 15 in epoch 7, gen_loss = 2.9092725217342377, disc_loss = 0.0037970706180203706
Trained batch 16 in epoch 7, gen_loss = 2.912658270667581, disc_loss = 0.0037880489630076814
Trained batch 17 in epoch 7, gen_loss = 2.910368733935886, disc_loss = 0.003749846028060549
Trained batch 18 in epoch 7, gen_loss = 2.915043918710006, disc_loss = 0.003700410444779616
Trained batch 19 in epoch 7, gen_loss = 2.913573920726776, disc_loss = 0.003652880771551281
Trained batch 20 in epoch 7, gen_loss = 2.9187046005612327, disc_loss = 0.003609651311611136
Trained batch 21 in epoch 7, gen_loss = 2.926890156485818, disc_loss = 0.0035638874502513895
Trained batch 22 in epoch 7, gen_loss = 2.9217064587966255, disc_loss = 0.0035360395280725283
Trained batch 23 in epoch 7, gen_loss = 2.9212182064851127, disc_loss = 0.0034902425638089576
Trained batch 24 in epoch 7, gen_loss = 2.9206151866912844, disc_loss = 0.0034635582752525805
Trained batch 25 in epoch 7, gen_loss = 2.917594341131357, disc_loss = 0.00346078764862166
Trained batch 26 in epoch 7, gen_loss = 2.91361747847663, disc_loss = 0.0034378152685584844
Trained batch 27 in epoch 7, gen_loss = 2.919316692011697, disc_loss = 0.003443724093293505
Trained batch 28 in epoch 7, gen_loss = 2.91731308246481, disc_loss = 0.0034485027868429133
Trained batch 29 in epoch 7, gen_loss = 2.9242597341537477, disc_loss = 0.0034270880976691844
Trained batch 30 in epoch 7, gen_loss = 2.9287726494573776, disc_loss = 0.003404979871946477
Trained batch 31 in epoch 7, gen_loss = 2.9263694882392883, disc_loss = 0.003421757028263528
Trained batch 32 in epoch 7, gen_loss = 2.923580025181626, disc_loss = 0.0033995318367625728
Trained batch 33 in epoch 7, gen_loss = 2.931859717649572, disc_loss = 0.003420581835705568
Trained batch 34 in epoch 7, gen_loss = 2.9314586775643483, disc_loss = 0.0034707777202129366
Trained batch 35 in epoch 7, gen_loss = 2.9280581871668496, disc_loss = 0.0034669204809082053
Trained batch 36 in epoch 7, gen_loss = 2.922135572175722, disc_loss = 0.0034481927727323934
Trained batch 37 in epoch 7, gen_loss = 2.921138223848845, disc_loss = 0.0034372044825240187
Trained batch 38 in epoch 7, gen_loss = 2.918098828731439, disc_loss = 0.0034198476395641384
Trained batch 39 in epoch 7, gen_loss = 2.9180874943733217, disc_loss = 0.003413659322541207
Trained batch 40 in epoch 7, gen_loss = 2.917776677666641, disc_loss = 0.003440773125919627
Trained batch 41 in epoch 7, gen_loss = 2.9194922276905606, disc_loss = 0.003489015923280801
Trained batch 42 in epoch 7, gen_loss = 2.920868895774664, disc_loss = 0.0034697895739660705
Trained batch 43 in epoch 7, gen_loss = 2.9196809096769853, disc_loss = 0.0034577215450223198
Trained batch 44 in epoch 7, gen_loss = 2.921212175157335, disc_loss = 0.003450739269869195
Trained batch 45 in epoch 7, gen_loss = 2.917409575503805, disc_loss = 0.003428054214252726
Trained batch 46 in epoch 7, gen_loss = 2.9205342150749045, disc_loss = 0.0034080277633001194
Trained batch 47 in epoch 7, gen_loss = 2.9208770593007407, disc_loss = 0.003403737175782832
Trained batch 48 in epoch 7, gen_loss = 2.9241702994521783, disc_loss = 0.003426597391882417
Trained batch 49 in epoch 7, gen_loss = 2.924509325027466, disc_loss = 0.00341287761926651
Trained batch 50 in epoch 7, gen_loss = 2.9269878817539587, disc_loss = 0.0034035207913713714
Trained batch 51 in epoch 7, gen_loss = 2.930837924663837, disc_loss = 0.0033843642539488007
Trained batch 52 in epoch 7, gen_loss = 2.9304262737058244, disc_loss = 0.003362804084559375
Trained batch 53 in epoch 7, gen_loss = 2.929934015980473, disc_loss = 0.0033499507742278554
Trained batch 54 in epoch 7, gen_loss = 2.928937781940807, disc_loss = 0.0033464413009245287
Trained batch 55 in epoch 7, gen_loss = 2.9289881714752743, disc_loss = 0.00333016348304227
Trained batch 56 in epoch 7, gen_loss = 2.9261799025953863, disc_loss = 0.003327366724414261
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 3.0848140716552734, disc_loss = 0.0026318610180169344
Trained batch 1 in epoch 8, gen_loss = 3.038167357444763, disc_loss = 0.002411231747828424
Trained batch 2 in epoch 8, gen_loss = 3.0504915714263916, disc_loss = 0.0023254065308719873
Trained batch 3 in epoch 8, gen_loss = 3.033772051334381, disc_loss = 0.0023021732922643423
Trained batch 4 in epoch 8, gen_loss = 2.9652669429779053, disc_loss = 0.0023303224239498376
Trained batch 5 in epoch 8, gen_loss = 2.965990742047628, disc_loss = 0.0023512057960033417
Trained batch 6 in epoch 8, gen_loss = 2.953158072062901, disc_loss = 0.0025718462254319873
Trained batch 7 in epoch 8, gen_loss = 2.961901158094406, disc_loss = 0.0025592472520656884
Trained batch 8 in epoch 8, gen_loss = 2.9472038480970593, disc_loss = 0.002591709037207895
Trained batch 9 in epoch 8, gen_loss = 2.935543966293335, disc_loss = 0.002564877853728831
Trained batch 10 in epoch 8, gen_loss = 2.945915699005127, disc_loss = 0.0026489321819760585
Trained batch 11 in epoch 8, gen_loss = 2.9368249575297036, disc_loss = 0.00264797848649323
Trained batch 12 in epoch 8, gen_loss = 2.927176989041842, disc_loss = 0.002610681865077752
Trained batch 13 in epoch 8, gen_loss = 2.9213758536747525, disc_loss = 0.0025706936472228597
Trained batch 14 in epoch 8, gen_loss = 2.9215584278106688, disc_loss = 0.0025443255435675383
Trained batch 15 in epoch 8, gen_loss = 2.919376164674759, disc_loss = 0.002523993593058549
Trained batch 16 in epoch 8, gen_loss = 2.9310309466193702, disc_loss = 0.0025308318025268174
Trained batch 17 in epoch 8, gen_loss = 2.922754552629259, disc_loss = 0.002593687011135949
Trained batch 18 in epoch 8, gen_loss = 2.933511683815404, disc_loss = 0.0026725784287248786
Trained batch 19 in epoch 8, gen_loss = 2.9364696979522704, disc_loss = 0.0027503601741045713
Trained batch 20 in epoch 8, gen_loss = 2.9365795793987455, disc_loss = 0.0027621775599462645
Trained batch 21 in epoch 8, gen_loss = 2.93234139139002, disc_loss = 0.0027486085150898857
Trained batch 22 in epoch 8, gen_loss = 2.9363477126411768, disc_loss = 0.002730040821125326
Trained batch 23 in epoch 8, gen_loss = 2.9404400984446206, disc_loss = 0.0027114706172142178
Trained batch 24 in epoch 8, gen_loss = 2.9395520973205564, disc_loss = 0.002698711361736059
Trained batch 25 in epoch 8, gen_loss = 2.940426386319674, disc_loss = 0.002682574039611679
Trained batch 26 in epoch 8, gen_loss = 2.9367252544120506, disc_loss = 0.002679935880695228
Trained batch 27 in epoch 8, gen_loss = 2.934266814163753, disc_loss = 0.002682649114701365
Trained batch 28 in epoch 8, gen_loss = 2.934302535550348, disc_loss = 0.002681148174250948
Trained batch 29 in epoch 8, gen_loss = 2.941172218322754, disc_loss = 0.002691584212395052
Trained batch 30 in epoch 8, gen_loss = 2.9329923506705993, disc_loss = 0.002680695916135465
Trained batch 31 in epoch 8, gen_loss = 2.9262927919626236, disc_loss = 0.002683366743440274
Trained batch 32 in epoch 8, gen_loss = 2.925403053110296, disc_loss = 0.0027092374000472555
Trained batch 33 in epoch 8, gen_loss = 2.9224576599457683, disc_loss = 0.0027475441217093785
Trained batch 34 in epoch 8, gen_loss = 2.9280666419437953, disc_loss = 0.0027674940481249776
Trained batch 35 in epoch 8, gen_loss = 2.9251743886205883, disc_loss = 0.0027470196364447474
Trained batch 36 in epoch 8, gen_loss = 2.9222131419826196, disc_loss = 0.00274218332551017
Trained batch 37 in epoch 8, gen_loss = 2.9215317023427865, disc_loss = 0.0027620011609733887
Trained batch 38 in epoch 8, gen_loss = 2.924362757267096, disc_loss = 0.002779377940803384
Trained batch 39 in epoch 8, gen_loss = 2.923816215991974, disc_loss = 0.002770490467082709
Trained batch 40 in epoch 8, gen_loss = 2.9241325913405998, disc_loss = 0.002762421210319167
Trained batch 41 in epoch 8, gen_loss = 2.926634192466736, disc_loss = 0.0027517297781915182
Trained batch 42 in epoch 8, gen_loss = 2.9290891137234, disc_loss = 0.0027806723197965426
Trained batch 43 in epoch 8, gen_loss = 2.9258873029188677, disc_loss = 0.0027685009779154575
Trained batch 44 in epoch 8, gen_loss = 2.923452091217041, disc_loss = 0.002779956379284461
Trained batch 45 in epoch 8, gen_loss = 2.9251707429471225, disc_loss = 0.0027804791562907076
Trained batch 46 in epoch 8, gen_loss = 2.9221950693333403, disc_loss = 0.002773561118606557
Trained batch 47 in epoch 8, gen_loss = 2.9250964323679605, disc_loss = 0.002771062897712303
Trained batch 48 in epoch 8, gen_loss = 2.9259667834457086, disc_loss = 0.002768761834737902
Trained batch 49 in epoch 8, gen_loss = 2.9252738428115843, disc_loss = 0.002769615869037807
Trained batch 50 in epoch 8, gen_loss = 2.9251124064127603, disc_loss = 0.0027589070492004064
Trained batch 51 in epoch 8, gen_loss = 2.9261755851598887, disc_loss = 0.002753189849989632
Trained batch 52 in epoch 8, gen_loss = 2.922652887848188, disc_loss = 0.002766261874469665
Trained batch 53 in epoch 8, gen_loss = 2.9215053496537386, disc_loss = 0.0027576847890116
Trained batch 54 in epoch 8, gen_loss = 2.9201626084067605, disc_loss = 0.002749774884432554
Trained batch 55 in epoch 8, gen_loss = 2.9224894302231923, disc_loss = 0.002739101170196331
Trained batch 56 in epoch 8, gen_loss = 2.923996586548655, disc_loss = 0.0027366344400338435
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 3.1656012535095215, disc_loss = 0.00263933720998466
Trained batch 1 in epoch 9, gen_loss = 3.0609787702560425, disc_loss = 0.002422187593765557
Trained batch 2 in epoch 9, gen_loss = 2.971801201502482, disc_loss = 0.0024078444112092257
Trained batch 3 in epoch 9, gen_loss = 2.9243964552879333, disc_loss = 0.0024729236029088497
Trained batch 4 in epoch 9, gen_loss = 2.9038789749145506, disc_loss = 0.0024605309125036003
Trained batch 5 in epoch 9, gen_loss = 2.9160587390263877, disc_loss = 0.0024321717210114002
Trained batch 6 in epoch 9, gen_loss = 2.926476853234427, disc_loss = 0.002449043161634888
Trained batch 7 in epoch 9, gen_loss = 2.892119348049164, disc_loss = 0.0024541643797419965
Trained batch 8 in epoch 9, gen_loss = 2.8820966614617243, disc_loss = 0.002428367113073667
Trained batch 9 in epoch 9, gen_loss = 2.8817131519317627, disc_loss = 0.002440606663003564
Trained batch 10 in epoch 9, gen_loss = 2.8695976083928887, disc_loss = 0.002390132592567666
Trained batch 11 in epoch 9, gen_loss = 2.887949824333191, disc_loss = 0.002435326430713758
Trained batch 12 in epoch 9, gen_loss = 2.89235833974985, disc_loss = 0.002430114707049842
Trained batch 13 in epoch 9, gen_loss = 2.889272723879133, disc_loss = 0.002440834925177374
Trained batch 14 in epoch 9, gen_loss = 2.9027218500773113, disc_loss = 0.002455555236277481
Trained batch 15 in epoch 9, gen_loss = 2.9056171774864197, disc_loss = 0.0024913347806432284
Trained batch 16 in epoch 9, gen_loss = 2.9013548738816204, disc_loss = 0.002471472225699793
Trained batch 17 in epoch 9, gen_loss = 2.91978120803833, disc_loss = 0.0024764517697298694
Trained batch 18 in epoch 9, gen_loss = 2.923074747386732, disc_loss = 0.002496496584315441
Trained batch 19 in epoch 9, gen_loss = 2.9284262657165527, disc_loss = 0.0025202186370734125
Trained batch 20 in epoch 9, gen_loss = 2.9210634458632696, disc_loss = 0.0025452182328860673
Trained batch 21 in epoch 9, gen_loss = 2.9246869412335483, disc_loss = 0.0025470530963502824
Trained batch 22 in epoch 9, gen_loss = 2.9225771738135298, disc_loss = 0.0025741353722127237
Trained batch 23 in epoch 9, gen_loss = 2.932846814393997, disc_loss = 0.0025552527561861402
Trained batch 24 in epoch 9, gen_loss = 2.9353298854827883, disc_loss = 0.0025833962159231305
Trained batch 25 in epoch 9, gen_loss = 2.938330989617568, disc_loss = 0.0026086559653497087
Trained batch 26 in epoch 9, gen_loss = 2.942553829263758, disc_loss = 0.0025919737958314793
Trained batch 27 in epoch 9, gen_loss = 2.9414564115660533, disc_loss = 0.0025836315180640668
Trained batch 28 in epoch 9, gen_loss = 2.9431464014382196, disc_loss = 0.002590818503261383
Trained batch 29 in epoch 9, gen_loss = 2.940377394358317, disc_loss = 0.002625898035087933
Trained batch 30 in epoch 9, gen_loss = 2.9374092317396596, disc_loss = 0.0026228526464453145
Trained batch 31 in epoch 9, gen_loss = 2.933625839650631, disc_loss = 0.0026071955180668738
Trained batch 32 in epoch 9, gen_loss = 2.9330767067995938, disc_loss = 0.0026004475534357357
Trained batch 33 in epoch 9, gen_loss = 2.9248996131560383, disc_loss = 0.002596494080909692
Trained batch 34 in epoch 9, gen_loss = 2.9281466143471855, disc_loss = 0.002592314869564559
Trained batch 35 in epoch 9, gen_loss = 2.9319567614131503, disc_loss = 0.0026040558619166
Trained batch 36 in epoch 9, gen_loss = 2.935233025937467, disc_loss = 0.0026075036950862487
Trained batch 37 in epoch 9, gen_loss = 2.936462766245792, disc_loss = 0.00262116061486794
Trained batch 38 in epoch 9, gen_loss = 2.9382413717416616, disc_loss = 0.0026266703961226037
Trained batch 39 in epoch 9, gen_loss = 2.9333342254161834, disc_loss = 0.0026239301339956002
Trained batch 40 in epoch 9, gen_loss = 2.9335954305602283, disc_loss = 0.00262591601974081
Trained batch 41 in epoch 9, gen_loss = 2.9326854830696467, disc_loss = 0.0026142679437595817
Trained batch 42 in epoch 9, gen_loss = 2.9308502285979516, disc_loss = 0.002611850212371453
Trained batch 43 in epoch 9, gen_loss = 2.9267177148298784, disc_loss = 0.0025976140089121395
Trained batch 44 in epoch 9, gen_loss = 2.927952586279975, disc_loss = 0.002577686291705403
Trained batch 45 in epoch 9, gen_loss = 2.9272481462229853, disc_loss = 0.0025753803252566445
Trained batch 46 in epoch 9, gen_loss = 2.926129310689074, disc_loss = 0.0025629451612327646
Trained batch 47 in epoch 9, gen_loss = 2.9227768778800964, disc_loss = 0.0025508002703039287
Trained batch 48 in epoch 9, gen_loss = 2.91976311742043, disc_loss = 0.002551867500688805
Trained batch 49 in epoch 9, gen_loss = 2.9202687883377076, disc_loss = 0.002557597679551691
Trained batch 50 in epoch 9, gen_loss = 2.9217895853753184, disc_loss = 0.0025778030634255092
Trained batch 51 in epoch 9, gen_loss = 2.9247552569095907, disc_loss = 0.0025679502622761694
Trained batch 52 in epoch 9, gen_loss = 2.9214517530405297, disc_loss = 0.0025745141210104776
Trained batch 53 in epoch 9, gen_loss = 2.919822370564496, disc_loss = 0.0025707837690047367
Trained batch 54 in epoch 9, gen_loss = 2.9215998692946, disc_loss = 0.002558756109581075
Trained batch 55 in epoch 9, gen_loss = 2.9220007615430013, disc_loss = 0.0025500070249628542
Trained batch 56 in epoch 9, gen_loss = 2.922612002021388, disc_loss = 0.0025437309574172424
Testing Epoch 9
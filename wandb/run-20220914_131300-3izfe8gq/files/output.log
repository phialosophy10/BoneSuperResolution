/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5623784065246582, disc_loss = 0.4901978373527527
Trained batch 1 in epoch 0, gen_loss = 0.5703472793102264, disc_loss = 0.5721631348133087
Trained batch 2 in epoch 0, gen_loss = 0.5796255866686503, disc_loss = 0.6656697392463684
Trained batch 3 in epoch 0, gen_loss = 0.5578222051262856, disc_loss = 0.5775746926665306
Trained batch 4 in epoch 0, gen_loss = 0.5380477011203766, disc_loss = 0.5159522950649261
Trained batch 5 in epoch 0, gen_loss = 0.5197051664193472, disc_loss = 0.46220891426006955
Trained batch 6 in epoch 0, gen_loss = 0.5168008591447558, disc_loss = 0.42403204313346315
Trained batch 7 in epoch 0, gen_loss = 0.5064769126474857, disc_loss = 0.3866327740252018
Trained batch 8 in epoch 0, gen_loss = 0.4943503638108571, disc_loss = 0.35541237476799226
Trained batch 9 in epoch 0, gen_loss = 0.4910791128873825, disc_loss = 0.33327112123370173
Trained batch 10 in epoch 0, gen_loss = 0.4912952049212022, disc_loss = 0.3141889199614525
Trained batch 11 in epoch 0, gen_loss = 0.48939747363328934, disc_loss = 0.2965078993390004
Trained batch 12 in epoch 0, gen_loss = 0.49118765730124253, disc_loss = 0.2813939263041203
Trained batch 13 in epoch 0, gen_loss = 0.49561092044625965, disc_loss = 0.2689145670405456
Trained batch 14 in epoch 0, gen_loss = 0.4977780759334564, disc_loss = 0.2571940779685974
Trained batch 15 in epoch 0, gen_loss = 0.49455793760716915, disc_loss = 0.24570937221869826
Trained batch 16 in epoch 0, gen_loss = 0.4940376334330615, disc_loss = 0.23652711028561874
Trained batch 17 in epoch 0, gen_loss = 0.49348272383213043, disc_loss = 0.22833959096007878
Trained batch 18 in epoch 0, gen_loss = 0.4917358050220891, disc_loss = 0.21977976631177099
Trained batch 19 in epoch 0, gen_loss = 0.4925568953156471, disc_loss = 0.21728118397295476
Trained batch 20 in epoch 0, gen_loss = 0.49715043675331844, disc_loss = 0.21523754263208025
Trained batch 21 in epoch 0, gen_loss = 0.49816399677233264, disc_loss = 0.21051335029981352
Trained batch 22 in epoch 0, gen_loss = 0.49696468529493915, disc_loss = 0.20679987157168594
Trained batch 23 in epoch 0, gen_loss = 0.4958743912478288, disc_loss = 0.20317054074257612
Trained batch 24 in epoch 0, gen_loss = 0.4938411557674408, disc_loss = 0.19990511924028398
Trained batch 25 in epoch 0, gen_loss = 0.49388137001257676, disc_loss = 0.19665741376005685
Trained batch 26 in epoch 0, gen_loss = 0.49499549909874246, disc_loss = 0.19270345679035894
Trained batch 27 in epoch 0, gen_loss = 0.49738249608448576, disc_loss = 0.18758761111114705
Trained batch 28 in epoch 0, gen_loss = 0.4990436352532485, disc_loss = 0.18287899987450962
Trained batch 29 in epoch 0, gen_loss = 0.500600544611613, disc_loss = 0.17836801012357076
Trained batch 30 in epoch 0, gen_loss = 0.499537423733742, disc_loss = 0.17423731941849954
Trained batch 31 in epoch 0, gen_loss = 0.4985527163371444, disc_loss = 0.17189116298686713
Trained batch 32 in epoch 0, gen_loss = 0.5000678923997012, disc_loss = 0.1688788929446177
Trained batch 33 in epoch 0, gen_loss = 0.5022590134073707, disc_loss = 0.16516888437463956
Trained batch 34 in epoch 0, gen_loss = 0.5025592352662768, disc_loss = 0.16163169369101524
Trained batch 35 in epoch 0, gen_loss = 0.5031091628803147, disc_loss = 0.15859920117590162
Trained batch 36 in epoch 0, gen_loss = 0.5043784839075964, disc_loss = 0.1555680018421766
Trained batch 37 in epoch 0, gen_loss = 0.5054128083743548, disc_loss = 0.1525770035621367
Trained batch 38 in epoch 0, gen_loss = 0.5053035639799558, disc_loss = 0.1495508445570102
Trained batch 39 in epoch 0, gen_loss = 0.5062741495668888, disc_loss = 0.14673453280702234
Trained batch 40 in epoch 0, gen_loss = 0.5072829934155069, disc_loss = 0.14390565541277572
Trained batch 41 in epoch 0, gen_loss = 0.5083224808885938, disc_loss = 0.14134383480995893
Trained batch 42 in epoch 0, gen_loss = 0.5100587419299192, disc_loss = 0.13885676492612029
Trained batch 43 in epoch 0, gen_loss = 0.5110844326290217, disc_loss = 0.1364776767705652
Trained batch 44 in epoch 0, gen_loss = 0.5116637196805742, disc_loss = 0.13413612051970428
Trained batch 45 in epoch 0, gen_loss = 0.5117184254138366, disc_loss = 0.131885278241142
Trained batch 46 in epoch 0, gen_loss = 0.5132358334165938, disc_loss = 0.12968862544190377
Trained batch 47 in epoch 0, gen_loss = 0.5145749890555938, disc_loss = 0.12751283698404828
Trained batch 48 in epoch 0, gen_loss = 0.516247069957305, disc_loss = 0.12540392824733743
Trained batch 49 in epoch 0, gen_loss = 0.5160179680585861, disc_loss = 0.1234817710518837
Trained batch 50 in epoch 0, gen_loss = 0.5161678820264106, disc_loss = 0.12159558929795143
Trained batch 51 in epoch 0, gen_loss = 0.5155894280626223, disc_loss = 0.1199865358738372
Trained batch 52 in epoch 0, gen_loss = 0.5163666375403134, disc_loss = 0.11887054422975711
Trained batch 53 in epoch 0, gen_loss = 0.5163868671214139, disc_loss = 0.11795249853835062
Trained batch 54 in epoch 0, gen_loss = 0.5169839680194854, disc_loss = 0.11706275733357126
Trained batch 55 in epoch 0, gen_loss = 0.5177925883659295, disc_loss = 0.11556615430994757
Trained batch 56 in epoch 0, gen_loss = 0.5178799906320739, disc_loss = 0.11399006408949693
Trained batch 57 in epoch 0, gen_loss = 0.5166368880148592, disc_loss = 0.11243846977193808
Trained batch 58 in epoch 0, gen_loss = 0.5156663378416482, disc_loss = 0.11107889105076507
Trained batch 59 in epoch 0, gen_loss = 0.5162957633535067, disc_loss = 0.10961064842219154
Trained batch 60 in epoch 0, gen_loss = 0.5172880316366915, disc_loss = 0.1081880624177026
Trained batch 61 in epoch 0, gen_loss = 0.5163924799811456, disc_loss = 0.10675039983564807
Trained batch 62 in epoch 0, gen_loss = 0.515305273116581, disc_loss = 0.10542100759607459
Trained batch 63 in epoch 0, gen_loss = 0.5151093546301126, disc_loss = 0.10406518692616373
Trained batch 64 in epoch 0, gen_loss = 0.5153690796632033, disc_loss = 0.10274904396098394
Trained batch 65 in epoch 0, gen_loss = 0.5158179546847488, disc_loss = 0.10154161610725251
Trained batch 66 in epoch 0, gen_loss = 0.5152129250675884, disc_loss = 0.1003414833390001
Trained batch 67 in epoch 0, gen_loss = 0.5148901750936228, disc_loss = 0.09915125720641192
Trained batch 68 in epoch 0, gen_loss = 0.5143853037253671, disc_loss = 0.09793395594950172
Trained batch 69 in epoch 0, gen_loss = 0.5138175870691027, disc_loss = 0.09679749280746494
Trained batch 70 in epoch 0, gen_loss = 0.5135144939724828, disc_loss = 0.09571462531219906
Trained batch 71 in epoch 0, gen_loss = 0.5130852017965581, disc_loss = 0.09459435386169288
Trained batch 72 in epoch 0, gen_loss = 0.5128699769712475, disc_loss = 0.09349756797597017
Trained batch 73 in epoch 0, gen_loss = 0.5117123412924844, disc_loss = 0.09244061095287671
Trained batch 74 in epoch 0, gen_loss = 0.5111596095561981, disc_loss = 0.09159695600469907
Trained batch 75 in epoch 0, gen_loss = 0.5108443231959092, disc_loss = 0.09070736713903516
Trained batch 76 in epoch 0, gen_loss = 0.509915376251394, disc_loss = 0.08979038349897056
Trained batch 77 in epoch 0, gen_loss = 0.510127951319401, disc_loss = 0.08902376945106646
Trained batch 78 in epoch 0, gen_loss = 0.5094275527362582, disc_loss = 0.0882542276684242
Trained batch 79 in epoch 0, gen_loss = 0.5097870469093323, disc_loss = 0.08758383542299271
Trained batch 80 in epoch 0, gen_loss = 0.5090569070091954, disc_loss = 0.08678753138232378
Trained batch 81 in epoch 0, gen_loss = 0.5085619095622039, disc_loss = 0.0860672270333985
Trained batch 82 in epoch 0, gen_loss = 0.5085341696997723, disc_loss = 0.0854100017886923
Trained batch 83 in epoch 0, gen_loss = 0.5078213477418536, disc_loss = 0.08499181534474094
Trained batch 84 in epoch 0, gen_loss = 0.5067785322666168, disc_loss = 0.08468801245531615
Trained batch 85 in epoch 0, gen_loss = 0.5065672886232997, disc_loss = 0.08433042477469804
Trained batch 86 in epoch 0, gen_loss = 0.506796065760755, disc_loss = 0.08382358686762979
Trained batch 87 in epoch 0, gen_loss = 0.5068476840176366, disc_loss = 0.08333571164191446
Trained batch 88 in epoch 0, gen_loss = 0.5068752474329444, disc_loss = 0.08274556271564425
Trained batch 89 in epoch 0, gen_loss = 0.5077468213107851, disc_loss = 0.082135835600396
Trained batch 90 in epoch 0, gen_loss = 0.5077637365231147, disc_loss = 0.0814614797440859
Trained batch 91 in epoch 0, gen_loss = 0.5080185924535212, disc_loss = 0.08082133442487406
Trained batch 92 in epoch 0, gen_loss = 0.5080688804067591, disc_loss = 0.08025712910438737
Trained batch 93 in epoch 0, gen_loss = 0.5086440485208592, disc_loss = 0.07959552915727204
Trained batch 94 in epoch 0, gen_loss = 0.5084977463672036, disc_loss = 0.07904533961493718
Trained batch 95 in epoch 0, gen_loss = 0.5090290270745754, disc_loss = 0.07856139193366592
Trained batch 96 in epoch 0, gen_loss = 0.5087200108262682, disc_loss = 0.07812139862361028
Trained batch 97 in epoch 0, gen_loss = 0.5089105835982731, disc_loss = 0.07768717307445346
Trained batch 98 in epoch 0, gen_loss = 0.5080939799246161, disc_loss = 0.0773707071902475
Trained batch 99 in epoch 0, gen_loss = 0.5085698345303535, disc_loss = 0.07690054653212428
Trained batch 100 in epoch 0, gen_loss = 0.5091276502255166, disc_loss = 0.07629622107758971
Trained batch 101 in epoch 0, gen_loss = 0.5091276481455448, disc_loss = 0.07570288217096936
Trained batch 102 in epoch 0, gen_loss = 0.5091905284275129, disc_loss = 0.07524391538599162
Trained batch 103 in epoch 0, gen_loss = 0.5091461931856779, disc_loss = 0.07465447436194293
Trained batch 104 in epoch 0, gen_loss = 0.5087326100894383, disc_loss = 0.0743534879049375
Trained batch 105 in epoch 0, gen_loss = 0.5082958666783459, disc_loss = 0.0743037448616101
Trained batch 106 in epoch 0, gen_loss = 0.5077392564755734, disc_loss = 0.07413687352439231
Trained batch 107 in epoch 0, gen_loss = 0.5079926765627332, disc_loss = 0.07544070810803936
Trained batch 108 in epoch 0, gen_loss = 0.5068622619733898, disc_loss = 0.07734408561960546
Trained batch 109 in epoch 0, gen_loss = 0.5067026376724243, disc_loss = 0.07732301643118263
Trained batch 110 in epoch 0, gen_loss = 0.5065973733996486, disc_loss = 0.07762353676832742
Trained batch 111 in epoch 0, gen_loss = 0.5063118780297893, disc_loss = 0.07758705495091688
Trained batch 112 in epoch 0, gen_loss = 0.506658091481808, disc_loss = 0.07730437443484511
Trained batch 113 in epoch 0, gen_loss = 0.5059107032261396, disc_loss = 0.07685392104056582
Trained batch 114 in epoch 0, gen_loss = 0.5058215672555177, disc_loss = 0.07642723589973605
Trained batch 115 in epoch 0, gen_loss = 0.5055524521860583, disc_loss = 0.07591304423062709
Trained batch 116 in epoch 0, gen_loss = 0.5053527278777881, disc_loss = 0.07536645828244778
Trained batch 117 in epoch 0, gen_loss = 0.5051112978135125, disc_loss = 0.07483179370825321
Trained batch 118 in epoch 0, gen_loss = 0.5049265002002236, disc_loss = 0.07430333583889638
Trained batch 119 in epoch 0, gen_loss = 0.505118743578593, disc_loss = 0.07377600293451299
Trained batch 120 in epoch 0, gen_loss = 0.5054301008705265, disc_loss = 0.07327657548541372
Trained batch 121 in epoch 0, gen_loss = 0.5051760656423256, disc_loss = 0.07288132490376469
Trained batch 122 in epoch 0, gen_loss = 0.505166337015183, disc_loss = 0.07243564847584177
Trained batch 123 in epoch 0, gen_loss = 0.5048972373047182, disc_loss = 0.07196233625854215
Trained batch 124 in epoch 0, gen_loss = 0.5052750644683838, disc_loss = 0.07148460110276937
Trained batch 125 in epoch 0, gen_loss = 0.5052745749079992, disc_loss = 0.07101465690703619
Trained batch 126 in epoch 0, gen_loss = 0.5052373352951891, disc_loss = 0.07060828164043859
Trained batch 127 in epoch 0, gen_loss = 0.505376048386097, disc_loss = 0.07014754504052689
Trained batch 128 in epoch 0, gen_loss = 0.5055642409842144, disc_loss = 0.0698438950908161
Trained batch 129 in epoch 0, gen_loss = 0.5055668798776773, disc_loss = 0.07092139731662778
Trained batch 130 in epoch 0, gen_loss = 0.5047163785868929, disc_loss = 0.07408867730183229
Trained batch 131 in epoch 0, gen_loss = 0.5042960585066767, disc_loss = 0.07478045061879764
Trained batch 132 in epoch 0, gen_loss = 0.5044045201817849, disc_loss = 0.07538076808774158
Trained batch 133 in epoch 0, gen_loss = 0.5049066254452094, disc_loss = 0.07549035804235
Trained batch 134 in epoch 0, gen_loss = 0.5043664285430202, disc_loss = 0.07538983374144193
Trained batch 135 in epoch 0, gen_loss = 0.5043777304098886, disc_loss = 0.07542616747292306
Trained batch 136 in epoch 0, gen_loss = 0.504529331939934, disc_loss = 0.0751239182835404
Trained batch 137 in epoch 0, gen_loss = 0.5046163834091546, disc_loss = 0.07481169192444372
Trained batch 138 in epoch 0, gen_loss = 0.5044236732043809, disc_loss = 0.07439906091811202
Trained batch 139 in epoch 0, gen_loss = 0.5045677027532033, disc_loss = 0.07404810720389443
Trained batch 140 in epoch 0, gen_loss = 0.504370225659499, disc_loss = 0.07365886771272048
Trained batch 141 in epoch 0, gen_loss = 0.504751808626551, disc_loss = 0.07324362445858792
Trained batch 142 in epoch 0, gen_loss = 0.5049131141675935, disc_loss = 0.07282028459924293
Trained batch 143 in epoch 0, gen_loss = 0.5046508912411001, disc_loss = 0.07250145263323146
Trained batch 144 in epoch 0, gen_loss = 0.5045746018146646, disc_loss = 0.07218009428089035
Trained batch 145 in epoch 0, gen_loss = 0.5049470463027693, disc_loss = 0.07183804861206101
Trained batch 146 in epoch 0, gen_loss = 0.5053640429665442, disc_loss = 0.0715512035059787
Trained batch 147 in epoch 0, gen_loss = 0.5056707802656535, disc_loss = 0.07177937919953586
Trained batch 148 in epoch 0, gen_loss = 0.5053014643240294, disc_loss = 0.07414505108815912
Trained batch 149 in epoch 0, gen_loss = 0.506184930006663, disc_loss = 0.07416506834949056
Trained batch 150 in epoch 0, gen_loss = 0.5067587096170084, disc_loss = 0.07400424749473271
Trained batch 151 in epoch 0, gen_loss = 0.5064838601178244, disc_loss = 0.07397926918010374
Trained batch 152 in epoch 0, gen_loss = 0.5064061289908839, disc_loss = 0.0741850193285572
Trained batch 153 in epoch 0, gen_loss = 0.506704363149482, disc_loss = 0.07408362047069451
Trained batch 154 in epoch 0, gen_loss = 0.5070436760302512, disc_loss = 0.07374954325177016
Trained batch 155 in epoch 0, gen_loss = 0.5071787675603842, disc_loss = 0.0734893261299779
Trained batch 156 in epoch 0, gen_loss = 0.5072505753131429, disc_loss = 0.07321534301658535
Trained batch 157 in epoch 0, gen_loss = 0.5076316483790362, disc_loss = 0.07291641307381701
Trained batch 158 in epoch 0, gen_loss = 0.5077692853204859, disc_loss = 0.07266632394291132
Trained batch 159 in epoch 0, gen_loss = 0.5077346654608845, disc_loss = 0.0728317626460921
Trained batch 160 in epoch 0, gen_loss = 0.5072704381454065, disc_loss = 0.07596516689598005
Trained batch 161 in epoch 0, gen_loss = 0.5071914856448586, disc_loss = 0.07642443981136621
Trained batch 162 in epoch 0, gen_loss = 0.5077762185064562, disc_loss = 0.07675668237833706
Trained batch 163 in epoch 0, gen_loss = 0.5080953449374292, disc_loss = 0.07690071425309813
Trained batch 164 in epoch 0, gen_loss = 0.5083861977765054, disc_loss = 0.07697729226201773
Trained batch 165 in epoch 0, gen_loss = 0.5082888371614088, disc_loss = 0.07700338144506137
Trained batch 166 in epoch 0, gen_loss = 0.5082289328475198, disc_loss = 0.07721581467856725
Trained batch 167 in epoch 0, gen_loss = 0.508163553973039, disc_loss = 0.0772221982201916
Trained batch 168 in epoch 0, gen_loss = 0.5083594865347507, disc_loss = 0.07715983893281433
Trained batch 169 in epoch 0, gen_loss = 0.5083629061194027, disc_loss = 0.07722582639030674
Trained batch 170 in epoch 0, gen_loss = 0.5081124924428282, disc_loss = 0.07943140533997824
Trained batch 171 in epoch 0, gen_loss = 0.5080657367442929, disc_loss = 0.07949353959736262
Trained batch 172 in epoch 0, gen_loss = 0.5087025763326987, disc_loss = 0.07984967949138039
Trained batch 173 in epoch 0, gen_loss = 0.5086271915285067, disc_loss = 0.0799108075416893
Trained batch 174 in epoch 0, gen_loss = 0.5081137253556933, disc_loss = 0.08042765120842627
Trained batch 175 in epoch 0, gen_loss = 0.5082714745605533, disc_loss = 0.0803689285848205
Trained batch 176 in epoch 0, gen_loss = 0.5080588505429736, disc_loss = 0.08028441471295
Trained batch 177 in epoch 0, gen_loss = 0.5078995262973764, disc_loss = 0.08020494691504354
Trained batch 178 in epoch 0, gen_loss = 0.5080189040586269, disc_loss = 0.0801630700007081
Trained batch 179 in epoch 0, gen_loss = 0.5079727795388963, disc_loss = 0.08077002703212202
Trained batch 180 in epoch 0, gen_loss = 0.5083644057505697, disc_loss = 0.0832636946380056
Trained batch 181 in epoch 0, gen_loss = 0.5082172918450701, disc_loss = 0.08451195345209031
Trained batch 182 in epoch 0, gen_loss = 0.5081027816227877, disc_loss = 0.08475285244830807
Trained batch 183 in epoch 0, gen_loss = 0.5077715336304643, disc_loss = 0.0851441872579491
Trained batch 184 in epoch 0, gen_loss = 0.5076477018562523, disc_loss = 0.08540027960631492
Trained batch 185 in epoch 0, gen_loss = 0.5074854379379621, disc_loss = 0.08558763332805165
Trained batch 186 in epoch 0, gen_loss = 0.5069841415805613, disc_loss = 0.08577627000862105
Trained batch 187 in epoch 0, gen_loss = 0.5069387223809323, disc_loss = 0.08584390181869744
Trained batch 188 in epoch 0, gen_loss = 0.5070427525295782, disc_loss = 0.08595947039722608
Trained batch 189 in epoch 0, gen_loss = 0.5073358019715861, disc_loss = 0.08616537570855336
Trained batch 190 in epoch 0, gen_loss = 0.5069104419016713, disc_loss = 0.08612841259961197
Trained batch 191 in epoch 0, gen_loss = 0.5066534437549611, disc_loss = 0.0867611630189155
Trained batch 192 in epoch 0, gen_loss = 0.5070018847062798, disc_loss = 0.08655867105533267
Trained batch 193 in epoch 0, gen_loss = 0.5074592618290911, disc_loss = 0.08634082644160107
Trained batch 194 in epoch 0, gen_loss = 0.5072960072602981, disc_loss = 0.08631928614221322
Trained batch 195 in epoch 0, gen_loss = 0.5067928056327664, disc_loss = 0.08687753159533806
Trained batch 196 in epoch 0, gen_loss = 0.5073621714780778, disc_loss = 0.08670752742776865
Trained batch 197 in epoch 0, gen_loss = 0.5075948497261664, disc_loss = 0.08694570520516447
Trained batch 198 in epoch 0, gen_loss = 0.5072545582924656, disc_loss = 0.08829975234410121
Trained batch 199 in epoch 0, gen_loss = 0.5073798653483391, disc_loss = 0.08885897906031459
Trained batch 200 in epoch 0, gen_loss = 0.5073382594988713, disc_loss = 0.08955827690382946
Trained batch 201 in epoch 0, gen_loss = 0.5071046206325588, disc_loss = 0.09006089511982138
Trained batch 202 in epoch 0, gen_loss = 0.5071763465263573, disc_loss = 0.09048196271043546
Trained batch 203 in epoch 0, gen_loss = 0.5073043743477148, disc_loss = 0.09096852611001655
Trained batch 204 in epoch 0, gen_loss = 0.50729986763582, disc_loss = 0.09134474245422497
Trained batch 205 in epoch 0, gen_loss = 0.5071264692012546, disc_loss = 0.09151412106742993
Trained batch 206 in epoch 0, gen_loss = 0.5069758596915553, disc_loss = 0.09199757573019335
Trained batch 207 in epoch 0, gen_loss = 0.5069933669784894, disc_loss = 0.09257674175583255
Trained batch 208 in epoch 0, gen_loss = 0.5068206765720148, disc_loss = 0.09333690717085555
Trained batch 209 in epoch 0, gen_loss = 0.5066534143118632, disc_loss = 0.09340507825836539
Trained batch 210 in epoch 0, gen_loss = 0.5068938391751022, disc_loss = 0.09335808877466838
Trained batch 211 in epoch 0, gen_loss = 0.5066332350362022, disc_loss = 0.09330768620964351
Trained batch 212 in epoch 0, gen_loss = 0.5064819190703648, disc_loss = 0.0932510447045657
Trained batch 213 in epoch 0, gen_loss = 0.5064296172322514, disc_loss = 0.09340232786087092
Trained batch 214 in epoch 0, gen_loss = 0.506222266236017, disc_loss = 0.09381968096158533
Trained batch 215 in epoch 0, gen_loss = 0.5062558357086446, disc_loss = 0.09392174538138702
Trained batch 216 in epoch 0, gen_loss = 0.5058442844498542, disc_loss = 0.09434798934544149
Trained batch 217 in epoch 0, gen_loss = 0.505952998995781, disc_loss = 0.09433731250037704
Trained batch 218 in epoch 0, gen_loss = 0.5061787370949575, disc_loss = 0.09415242327249622
Trained batch 219 in epoch 0, gen_loss = 0.5061699091033502, disc_loss = 0.09414487629705533
Trained batch 220 in epoch 0, gen_loss = 0.5064286836401909, disc_loss = 0.0946298550384549
Trained batch 221 in epoch 0, gen_loss = 0.506112325970117, disc_loss = 0.09451429565596553
Trained batch 222 in epoch 0, gen_loss = 0.5062029635692391, disc_loss = 0.0952739609288461
Trained batch 223 in epoch 0, gen_loss = 0.5064792456105351, disc_loss = 0.09677588427023563
Trained batch 224 in epoch 0, gen_loss = 0.5063763380050659, disc_loss = 0.09691481324947543
Trained batch 225 in epoch 0, gen_loss = 0.5060301889887954, disc_loss = 0.09759690513240948
Trained batch 226 in epoch 0, gen_loss = 0.5058665929386794, disc_loss = 0.09772992685092573
Trained batch 227 in epoch 0, gen_loss = 0.5057621557723012, disc_loss = 0.09790200347554658
Trained batch 228 in epoch 0, gen_loss = 0.5052974786300326, disc_loss = 0.09798428754212424
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.4448881447315216, disc_loss = 0.16556166112422943
Trained batch 1 in epoch 1, gen_loss = 0.48242856562137604, disc_loss = 0.1373233087360859
Trained batch 2 in epoch 1, gen_loss = 0.47482022643089294, disc_loss = 0.13333120693763098
Trained batch 3 in epoch 1, gen_loss = 0.4663287401199341, disc_loss = 0.1753698792308569
Trained batch 4 in epoch 1, gen_loss = 0.47301748394966125, disc_loss = 0.17781172543764115
Trained batch 5 in epoch 1, gen_loss = 0.47370360294977826, disc_loss = 0.17024050280451775
Trained batch 6 in epoch 1, gen_loss = 0.4713500908442906, disc_loss = 0.1657950697200639
Trained batch 7 in epoch 1, gen_loss = 0.4791645482182503, disc_loss = 0.16483734641224146
Trained batch 8 in epoch 1, gen_loss = 0.4807745615641276, disc_loss = 0.1647941561208831
Trained batch 9 in epoch 1, gen_loss = 0.47989252805709837, disc_loss = 0.16141255274415017
Trained batch 10 in epoch 1, gen_loss = 0.482561393217607, disc_loss = 0.15426981110464444
Trained batch 11 in epoch 1, gen_loss = 0.4787142500281334, disc_loss = 0.15144003741443157
Trained batch 12 in epoch 1, gen_loss = 0.471933167714339, disc_loss = 0.1478931479729139
Trained batch 13 in epoch 1, gen_loss = 0.47198512085846495, disc_loss = 0.14958656685692923
Trained batch 14 in epoch 1, gen_loss = 0.4739823639392853, disc_loss = 0.15302008688449859
Trained batch 15 in epoch 1, gen_loss = 0.47258744202554226, disc_loss = 0.1648374879732728
Trained batch 16 in epoch 1, gen_loss = 0.4768248358193566, disc_loss = 0.16029051340678158
Trained batch 17 in epoch 1, gen_loss = 0.4782959239350425, disc_loss = 0.16639045418964493
Trained batch 18 in epoch 1, gen_loss = 0.47528536382474396, disc_loss = 0.16985877603292465
Trained batch 19 in epoch 1, gen_loss = 0.4716060280799866, disc_loss = 0.16732309013605118
Trained batch 20 in epoch 1, gen_loss = 0.4707379795256115, disc_loss = 0.16726267479714893
Trained batch 21 in epoch 1, gen_loss = 0.46875704553994263, disc_loss = 0.16547107019207694
Trained batch 22 in epoch 1, gen_loss = 0.46785064754278766, disc_loss = 0.1637461366860763
Trained batch 23 in epoch 1, gen_loss = 0.4663289785385132, disc_loss = 0.1614309068148335
Trained batch 24 in epoch 1, gen_loss = 0.46665225982666014, disc_loss = 0.15961935073137284
Trained batch 25 in epoch 1, gen_loss = 0.46618340336359465, disc_loss = 0.15689830138133123
Trained batch 26 in epoch 1, gen_loss = 0.46900691367961744, disc_loss = 0.15411640538109672
Trained batch 27 in epoch 1, gen_loss = 0.4703815153666905, disc_loss = 0.15233276119189604
Trained batch 28 in epoch 1, gen_loss = 0.46928151208778907, disc_loss = 0.1500292430663931
Trained batch 29 in epoch 1, gen_loss = 0.4680494248867035, disc_loss = 0.1489855205019315
Trained batch 30 in epoch 1, gen_loss = 0.47094778283949823, disc_loss = 0.15378959765357356
Trained batch 31 in epoch 1, gen_loss = 0.4694303134456277, disc_loss = 0.16192222712561488
Trained batch 32 in epoch 1, gen_loss = 0.46945704293973517, disc_loss = 0.16177224841984836
Trained batch 33 in epoch 1, gen_loss = 0.46818981275838967, disc_loss = 0.16349634440506206
Trained batch 34 in epoch 1, gen_loss = 0.4669679088251931, disc_loss = 0.16342892476490567
Trained batch 35 in epoch 1, gen_loss = 0.46472662025027806, disc_loss = 0.1659995433357027
Trained batch 36 in epoch 1, gen_loss = 0.4651834562018111, disc_loss = 0.16881568770150882
Trained batch 37 in epoch 1, gen_loss = 0.4652901346746244, disc_loss = 0.16738859995415337
Trained batch 38 in epoch 1, gen_loss = 0.4652297183489188, disc_loss = 0.16689800528379586
Trained batch 39 in epoch 1, gen_loss = 0.4637106657028198, disc_loss = 0.1664007917046547
Trained batch 40 in epoch 1, gen_loss = 0.4635168575659031, disc_loss = 0.1662251295112982
Trained batch 41 in epoch 1, gen_loss = 0.463173875496501, disc_loss = 0.16657621768258868
Trained batch 42 in epoch 1, gen_loss = 0.46074911674787833, disc_loss = 0.16805432736873627
Trained batch 43 in epoch 1, gen_loss = 0.4602304764769294, disc_loss = 0.1684012169187719
Trained batch 44 in epoch 1, gen_loss = 0.4610526919364929, disc_loss = 0.1723230712943607
Trained batch 45 in epoch 1, gen_loss = 0.4605182461116625, disc_loss = 0.172285925111045
Trained batch 46 in epoch 1, gen_loss = 0.45947618623997305, disc_loss = 0.17239165686546487
Trained batch 47 in epoch 1, gen_loss = 0.45916140886644524, disc_loss = 0.17142583119372526
Trained batch 48 in epoch 1, gen_loss = 0.4584055275333171, disc_loss = 0.1711554259670024
Trained batch 49 in epoch 1, gen_loss = 0.45733543038368224, disc_loss = 0.17138374090194702
Trained batch 50 in epoch 1, gen_loss = 0.4560907927213931, disc_loss = 0.17180940742586173
Trained batch 51 in epoch 1, gen_loss = 0.4557875572488858, disc_loss = 0.17175724930488145
Trained batch 52 in epoch 1, gen_loss = 0.4551464572267712, disc_loss = 0.17168839725683321
Trained batch 53 in epoch 1, gen_loss = 0.4544153649497915, disc_loss = 0.17054382656459455
Trained batch 54 in epoch 1, gen_loss = 0.4548364742235704, disc_loss = 0.16982306133617053
Trained batch 55 in epoch 1, gen_loss = 0.455711874046496, disc_loss = 0.1707784921995231
Trained batch 56 in epoch 1, gen_loss = 0.4543188188159675, disc_loss = 0.17295353140747338
Trained batch 57 in epoch 1, gen_loss = 0.4546666433071268, disc_loss = 0.1722498530971593
Trained batch 58 in epoch 1, gen_loss = 0.45584233332488494, disc_loss = 0.17424246921377667
Trained batch 59 in epoch 1, gen_loss = 0.4558475653330485, disc_loss = 0.17466258009274802
Trained batch 60 in epoch 1, gen_loss = 0.456230028730924, disc_loss = 0.17459925716040564
Trained batch 61 in epoch 1, gen_loss = 0.456426338322701, disc_loss = 0.1741400257714333
Trained batch 62 in epoch 1, gen_loss = 0.455936807961691, disc_loss = 0.1737773766120275
Trained batch 63 in epoch 1, gen_loss = 0.45484669459983706, disc_loss = 0.17361774179153144
Trained batch 64 in epoch 1, gen_loss = 0.45450366001862746, disc_loss = 0.1731206061748358
Trained batch 65 in epoch 1, gen_loss = 0.4540581874775164, disc_loss = 0.17358095605265011
Trained batch 66 in epoch 1, gen_loss = 0.45370671820284714, disc_loss = 0.1726915528302762
Trained batch 67 in epoch 1, gen_loss = 0.4537968916051528, disc_loss = 0.17217552672852487
Trained batch 68 in epoch 1, gen_loss = 0.4544693680777066, disc_loss = 0.17211022638324378
Trained batch 69 in epoch 1, gen_loss = 0.4547294565609523, disc_loss = 0.1726464559989316
Trained batch 70 in epoch 1, gen_loss = 0.45552350181928825, disc_loss = 0.1719453524745686
Trained batch 71 in epoch 1, gen_loss = 0.4553215487135781, disc_loss = 0.17277622729953793
Trained batch 72 in epoch 1, gen_loss = 0.45553442958283097, disc_loss = 0.17700615208851148
Trained batch 73 in epoch 1, gen_loss = 0.4550278408301843, disc_loss = 0.17651077953947558
Trained batch 74 in epoch 1, gen_loss = 0.4552005926767985, disc_loss = 0.17644524067640305
Trained batch 75 in epoch 1, gen_loss = 0.45516861426202876, disc_loss = 0.17648583581965221
Trained batch 76 in epoch 1, gen_loss = 0.45520305440023345, disc_loss = 0.17653623755489076
Trained batch 77 in epoch 1, gen_loss = 0.45505757515247053, disc_loss = 0.17582729678505507
Trained batch 78 in epoch 1, gen_loss = 0.4549716839307471, disc_loss = 0.17527983828058727
Trained batch 79 in epoch 1, gen_loss = 0.45502455830574035, disc_loss = 0.17485830476507544
Trained batch 80 in epoch 1, gen_loss = 0.4544098682609605, disc_loss = 0.17437252558675814
Trained batch 81 in epoch 1, gen_loss = 0.45445130801782374, disc_loss = 0.17391954062551987
Trained batch 82 in epoch 1, gen_loss = 0.45460528278925333, disc_loss = 0.1747014387005783
Trained batch 83 in epoch 1, gen_loss = 0.4540798259632928, disc_loss = 0.1752643192275649
Trained batch 84 in epoch 1, gen_loss = 0.45335432922138885, disc_loss = 0.1748132362961769
Trained batch 85 in epoch 1, gen_loss = 0.4532732152661612, disc_loss = 0.17514439628914344
Trained batch 86 in epoch 1, gen_loss = 0.45282480017892246, disc_loss = 0.17515348129231353
Trained batch 87 in epoch 1, gen_loss = 0.45241266692226584, disc_loss = 0.175315573557534
Trained batch 88 in epoch 1, gen_loss = 0.45174034492353377, disc_loss = 0.1753427896104502
Trained batch 89 in epoch 1, gen_loss = 0.45130327178372276, disc_loss = 0.1756626697878043
Trained batch 90 in epoch 1, gen_loss = 0.4504255092406011, disc_loss = 0.176453156376278
Trained batch 91 in epoch 1, gen_loss = 0.44970333511414734, disc_loss = 0.17842879267814366
Trained batch 92 in epoch 1, gen_loss = 0.4492726508648165, disc_loss = 0.17933191943873641
Trained batch 93 in epoch 1, gen_loss = 0.4481593646267627, disc_loss = 0.17967763693725808
Trained batch 94 in epoch 1, gen_loss = 0.4476169234827945, disc_loss = 0.18028066275935423
Trained batch 95 in epoch 1, gen_loss = 0.4481720781574647, disc_loss = 0.18087638177288076
Trained batch 96 in epoch 1, gen_loss = 0.4474445839518124, disc_loss = 0.18077715363391897
Trained batch 97 in epoch 1, gen_loss = 0.44709139058784564, disc_loss = 0.1809215739521445
Trained batch 98 in epoch 1, gen_loss = 0.44738622205425993, disc_loss = 0.18066551852406879
Trained batch 99 in epoch 1, gen_loss = 0.44680134028196333, disc_loss = 0.1812752940505743
Trained batch 100 in epoch 1, gen_loss = 0.44634281585712243, disc_loss = 0.18235256404864905
Trained batch 101 in epoch 1, gen_loss = 0.4459030558081234, disc_loss = 0.18210147416182593
Trained batch 102 in epoch 1, gen_loss = 0.44598028034839815, disc_loss = 0.1820615866375201
Trained batch 103 in epoch 1, gen_loss = 0.44523041494763815, disc_loss = 0.18260332490675724
Trained batch 104 in epoch 1, gen_loss = 0.4449197814578102, disc_loss = 0.18240026157526743
Trained batch 105 in epoch 1, gen_loss = 0.44516346983189853, disc_loss = 0.18227561907667034
Trained batch 106 in epoch 1, gen_loss = 0.44480862071580973, disc_loss = 0.18318884610851235
Trained batch 107 in epoch 1, gen_loss = 0.4440094632682977, disc_loss = 0.18359802546048606
Trained batch 108 in epoch 1, gen_loss = 0.44355452361456843, disc_loss = 0.1836939330358024
Trained batch 109 in epoch 1, gen_loss = 0.4434384359554811, disc_loss = 0.18352745425972072
Trained batch 110 in epoch 1, gen_loss = 0.4426764504866557, disc_loss = 0.18372649900816582
Trained batch 111 in epoch 1, gen_loss = 0.4426310695707798, disc_loss = 0.1838089980051986
Trained batch 112 in epoch 1, gen_loss = 0.44253169435315426, disc_loss = 0.18342596140846743
Trained batch 113 in epoch 1, gen_loss = 0.4425299659109952, disc_loss = 0.18328709475565375
Trained batch 114 in epoch 1, gen_loss = 0.4425559844659722, disc_loss = 0.1831759402933328
Trained batch 115 in epoch 1, gen_loss = 0.4421298984309723, disc_loss = 0.18366456680513663
Trained batch 116 in epoch 1, gen_loss = 0.44118957539908904, disc_loss = 0.18432746464625382
Trained batch 117 in epoch 1, gen_loss = 0.4412005382069087, disc_loss = 0.18431556306905666
Trained batch 118 in epoch 1, gen_loss = 0.4415345124336852, disc_loss = 0.18480131662442906
Trained batch 119 in epoch 1, gen_loss = 0.44080373346805574, disc_loss = 0.1848579685514172
Trained batch 120 in epoch 1, gen_loss = 0.44055192505032564, disc_loss = 0.18474182763621827
Trained batch 121 in epoch 1, gen_loss = 0.44052990342749926, disc_loss = 0.1852390583543504
Trained batch 122 in epoch 1, gen_loss = 0.43995901457662506, disc_loss = 0.1851672413266771
Trained batch 123 in epoch 1, gen_loss = 0.4394206330180168, disc_loss = 0.1851803662195321
Trained batch 124 in epoch 1, gen_loss = 0.4390164532661438, disc_loss = 0.18513513225317002
Trained batch 125 in epoch 1, gen_loss = 0.4390634388204605, disc_loss = 0.18497035942143863
Trained batch 126 in epoch 1, gen_loss = 0.43841982075548547, disc_loss = 0.18510862181740484
Trained batch 127 in epoch 1, gen_loss = 0.43815768975764513, disc_loss = 0.18566257954807952
Trained batch 128 in epoch 1, gen_loss = 0.43826169168302254, disc_loss = 0.18546565102283344
Trained batch 129 in epoch 1, gen_loss = 0.43852709463009465, disc_loss = 0.18510984279788456
Trained batch 130 in epoch 1, gen_loss = 0.4377855158034172, disc_loss = 0.18509925657328757
Trained batch 131 in epoch 1, gen_loss = 0.43745102101203165, disc_loss = 0.1853881487905076
Trained batch 132 in epoch 1, gen_loss = 0.4372968646816741, disc_loss = 0.1858183758935534
Trained batch 133 in epoch 1, gen_loss = 0.4372216641013302, disc_loss = 0.18593637561842577
Trained batch 134 in epoch 1, gen_loss = 0.43679058772546275, disc_loss = 0.18623344605719602
Trained batch 135 in epoch 1, gen_loss = 0.43640775408814936, disc_loss = 0.1863459591370295
Trained batch 136 in epoch 1, gen_loss = 0.4362819708176773, disc_loss = 0.18608532035655348
Trained batch 137 in epoch 1, gen_loss = 0.4363552871821583, disc_loss = 0.1859239939654219
Trained batch 138 in epoch 1, gen_loss = 0.4360203588609215, disc_loss = 0.18574364660240764
Trained batch 139 in epoch 1, gen_loss = 0.4357315257191658, disc_loss = 0.18545528879123074
Trained batch 140 in epoch 1, gen_loss = 0.4353812850536184, disc_loss = 0.18547688303052956
Trained batch 141 in epoch 1, gen_loss = 0.43521623544290033, disc_loss = 0.18554555514538792
Trained batch 142 in epoch 1, gen_loss = 0.43530264205032293, disc_loss = 0.18532560135309512
Trained batch 143 in epoch 1, gen_loss = 0.434989074865977, disc_loss = 0.18510099402111438
Trained batch 144 in epoch 1, gen_loss = 0.43503167135962123, disc_loss = 0.18510426873790806
Trained batch 145 in epoch 1, gen_loss = 0.4350621516573919, disc_loss = 0.1855105183610361
Trained batch 146 in epoch 1, gen_loss = 0.4348057054338001, disc_loss = 0.18627542333335292
Trained batch 147 in epoch 1, gen_loss = 0.43539727902090225, disc_loss = 0.18579795196451046
Trained batch 148 in epoch 1, gen_loss = 0.43568249676851617, disc_loss = 0.18546088514912049
Trained batch 149 in epoch 1, gen_loss = 0.43583152651786805, disc_loss = 0.18504126727581025
Trained batch 150 in epoch 1, gen_loss = 0.4354447489542677, disc_loss = 0.18486740070068283
Trained batch 151 in epoch 1, gen_loss = 0.4349384978413582, disc_loss = 0.18474242914664118
Trained batch 152 in epoch 1, gen_loss = 0.4351881645084207, disc_loss = 0.18446150013044768
Trained batch 153 in epoch 1, gen_loss = 0.43550733680074866, disc_loss = 0.18386778051589991
Trained batch 154 in epoch 1, gen_loss = 0.4351023668243039, disc_loss = 0.18339867101561638
Trained batch 155 in epoch 1, gen_loss = 0.4345487279769702, disc_loss = 0.18332640301340666
Trained batch 156 in epoch 1, gen_loss = 0.43483376768743914, disc_loss = 0.18367306413544213
Trained batch 157 in epoch 1, gen_loss = 0.43412442939190926, disc_loss = 0.18420968336772314
Trained batch 158 in epoch 1, gen_loss = 0.434003676445979, disc_loss = 0.18427447421745685
Trained batch 159 in epoch 1, gen_loss = 0.4335798164829612, disc_loss = 0.1840874807909131
Trained batch 160 in epoch 1, gen_loss = 0.4333498603808954, disc_loss = 0.18438174135936714
Trained batch 161 in epoch 1, gen_loss = 0.43334422012170154, disc_loss = 0.18389831290200906
Trained batch 162 in epoch 1, gen_loss = 0.4339328607532876, disc_loss = 0.18362279053480346
Trained batch 163 in epoch 1, gen_loss = 0.43384558925541433, disc_loss = 0.18399307304402676
Trained batch 164 in epoch 1, gen_loss = 0.4340863515030254, disc_loss = 0.18381303630091927
Trained batch 165 in epoch 1, gen_loss = 0.4339707876185337, disc_loss = 0.18380653122103358
Trained batch 166 in epoch 1, gen_loss = 0.4342671987896194, disc_loss = 0.18452117150415204
Trained batch 167 in epoch 1, gen_loss = 0.4343818656745411, disc_loss = 0.1845521360990547
Trained batch 168 in epoch 1, gen_loss = 0.43421735654215843, disc_loss = 0.18397253328526514
Trained batch 169 in epoch 1, gen_loss = 0.4337274961611804, disc_loss = 0.18378432130112368
Trained batch 170 in epoch 1, gen_loss = 0.4334586691438106, disc_loss = 0.18341927456925486
Trained batch 171 in epoch 1, gen_loss = 0.4332929788980373, disc_loss = 0.18361076842560325
Trained batch 172 in epoch 1, gen_loss = 0.4330959401034206, disc_loss = 0.1834073401772218
Trained batch 173 in epoch 1, gen_loss = 0.4330774249359109, disc_loss = 0.182767271652989
Trained batch 174 in epoch 1, gen_loss = 0.43272173626082283, disc_loss = 0.1830770650080272
Trained batch 175 in epoch 1, gen_loss = 0.43267154202542524, disc_loss = 0.18323153900829228
Trained batch 176 in epoch 1, gen_loss = 0.43252957153455013, disc_loss = 0.18288677695107325
Trained batch 177 in epoch 1, gen_loss = 0.432143947214223, disc_loss = 0.18277617008163688
Trained batch 178 in epoch 1, gen_loss = 0.43182634691286353, disc_loss = 0.18321904964620175
Trained batch 179 in epoch 1, gen_loss = 0.4322829195194774, disc_loss = 0.18372978791594505
Trained batch 180 in epoch 1, gen_loss = 0.43217383481520977, disc_loss = 0.18331011796359858
Trained batch 181 in epoch 1, gen_loss = 0.431901984326132, disc_loss = 0.18288431455800822
Trained batch 182 in epoch 1, gen_loss = 0.4315317339910184, disc_loss = 0.18263565207439694
Trained batch 183 in epoch 1, gen_loss = 0.43177931237479916, disc_loss = 0.18211059555735276
Trained batch 184 in epoch 1, gen_loss = 0.4317727733302761, disc_loss = 0.18193592364723618
Trained batch 185 in epoch 1, gen_loss = 0.43194961852283886, disc_loss = 0.18184768528707565
Trained batch 186 in epoch 1, gen_loss = 0.4319942317863199, disc_loss = 0.18168944502896803
Trained batch 187 in epoch 1, gen_loss = 0.43198150031744165, disc_loss = 0.18144700057963106
Trained batch 188 in epoch 1, gen_loss = 0.432184368687332, disc_loss = 0.18067635765309056
Trained batch 189 in epoch 1, gen_loss = 0.43199490308761596, disc_loss = 0.18128400009713674
Trained batch 190 in epoch 1, gen_loss = 0.4321999955551787, disc_loss = 0.1832989779208343
Trained batch 191 in epoch 1, gen_loss = 0.43212996640553075, disc_loss = 0.18352973426226526
Trained batch 192 in epoch 1, gen_loss = 0.43177244931922676, disc_loss = 0.18351119907254382
Trained batch 193 in epoch 1, gen_loss = 0.43168225991971715, disc_loss = 0.18349136569604432
Trained batch 194 in epoch 1, gen_loss = 0.43140910940292554, disc_loss = 0.18342249412567188
Trained batch 195 in epoch 1, gen_loss = 0.4310927197945361, disc_loss = 0.18330655250774355
Trained batch 196 in epoch 1, gen_loss = 0.43126936052656417, disc_loss = 0.1832236690342729
Trained batch 197 in epoch 1, gen_loss = 0.4312901153708949, disc_loss = 0.18343256041407585
Trained batch 198 in epoch 1, gen_loss = 0.4309884311266281, disc_loss = 0.1833639573586646
Trained batch 199 in epoch 1, gen_loss = 0.43081233233213423, disc_loss = 0.18337730567902327
Trained batch 200 in epoch 1, gen_loss = 0.43083304834009994, disc_loss = 0.18324048301918588
Trained batch 201 in epoch 1, gen_loss = 0.4310204366056046, disc_loss = 0.18294020240554715
Trained batch 202 in epoch 1, gen_loss = 0.43045954325516234, disc_loss = 0.18290113176911924
Trained batch 203 in epoch 1, gen_loss = 0.4299081273230852, disc_loss = 0.1828876497844855
Trained batch 204 in epoch 1, gen_loss = 0.42989227931673935, disc_loss = 0.18297572841004628
Trained batch 205 in epoch 1, gen_loss = 0.4296406054670371, disc_loss = 0.18265906641784224
Trained batch 206 in epoch 1, gen_loss = 0.4293234676554583, disc_loss = 0.18253882740430785
Trained batch 207 in epoch 1, gen_loss = 0.42947659784784686, disc_loss = 0.18255077617672774
Trained batch 208 in epoch 1, gen_loss = 0.4293427625626468, disc_loss = 0.18254549851257834
Trained batch 209 in epoch 1, gen_loss = 0.42921519591694784, disc_loss = 0.18258001477945418
Trained batch 210 in epoch 1, gen_loss = 0.4292425010441604, disc_loss = 0.1830584848944045
Trained batch 211 in epoch 1, gen_loss = 0.4288513114992178, disc_loss = 0.18295167836378207
Trained batch 212 in epoch 1, gen_loss = 0.4286697944844832, disc_loss = 0.18275227268257052
Trained batch 213 in epoch 1, gen_loss = 0.42870352034256837, disc_loss = 0.1825877385579537
Trained batch 214 in epoch 1, gen_loss = 0.4289270826550417, disc_loss = 0.18227572441101075
Trained batch 215 in epoch 1, gen_loss = 0.42873090312436773, disc_loss = 0.18247244348404584
Trained batch 216 in epoch 1, gen_loss = 0.4288294370273291, disc_loss = 0.1822890495100329
Trained batch 217 in epoch 1, gen_loss = 0.42879669040168095, disc_loss = 0.182028022176082
Trained batch 218 in epoch 1, gen_loss = 0.4283001682801878, disc_loss = 0.18214380040288516
Trained batch 219 in epoch 1, gen_loss = 0.4285734937949614, disc_loss = 0.18196843598376622
Trained batch 220 in epoch 1, gen_loss = 0.4285718968551083, disc_loss = 0.18200480047933656
Trained batch 221 in epoch 1, gen_loss = 0.4283293960867701, disc_loss = 0.18195709203546112
Trained batch 222 in epoch 1, gen_loss = 0.4282870165703008, disc_loss = 0.18199268892206955
Trained batch 223 in epoch 1, gen_loss = 0.42843223669167074, disc_loss = 0.18197173046480333
Trained batch 224 in epoch 1, gen_loss = 0.42853727208243475, disc_loss = 0.18195672313372294
Trained batch 225 in epoch 1, gen_loss = 0.42853164277245515, disc_loss = 0.18173869679459428
Trained batch 226 in epoch 1, gen_loss = 0.4285838059129169, disc_loss = 0.18150802980698152
Trained batch 227 in epoch 1, gen_loss = 0.4286750101468019, disc_loss = 0.18131733300131664
Trained batch 228 in epoch 1, gen_loss = 0.42869744407558025, disc_loss = 0.18107777827431543
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4032650887966156, disc_loss = 0.12351737916469574
Trained batch 1 in epoch 2, gen_loss = 0.4143116772174835, disc_loss = 0.15136221051216125
Trained batch 2 in epoch 2, gen_loss = 0.4385523200035095, disc_loss = 0.1743688682715098
Trained batch 3 in epoch 2, gen_loss = 0.42298711091279984, disc_loss = 0.1690496876835823
Trained batch 4 in epoch 2, gen_loss = 0.4149386942386627, disc_loss = 0.15813666731119155
Trained batch 5 in epoch 2, gen_loss = 0.4166276653607686, disc_loss = 0.15123812605937323
Trained batch 6 in epoch 2, gen_loss = 0.4176314004829952, disc_loss = 0.18617634900978633
Trained batch 7 in epoch 2, gen_loss = 0.41477610543370247, disc_loss = 0.18716496042907238
Trained batch 8 in epoch 2, gen_loss = 0.4145347509119246, disc_loss = 0.17962801456451416
Trained batch 9 in epoch 2, gen_loss = 0.4202955275774002, disc_loss = 0.17981575131416322
Trained batch 10 in epoch 2, gen_loss = 0.4106712314215573, disc_loss = 0.18734248930757696
Trained batch 11 in epoch 2, gen_loss = 0.41231535126765567, disc_loss = 0.18172617070376873
Trained batch 12 in epoch 2, gen_loss = 0.4129439959159264, disc_loss = 0.18110926048113749
Trained batch 13 in epoch 2, gen_loss = 0.4134038005556379, disc_loss = 0.17988963584814752
Trained batch 14 in epoch 2, gen_loss = 0.4138849496841431, disc_loss = 0.18377685298522314
Trained batch 15 in epoch 2, gen_loss = 0.4100194592028856, disc_loss = 0.1810477408580482
Trained batch 16 in epoch 2, gen_loss = 0.4074742653790642, disc_loss = 0.18219780176877975
Trained batch 17 in epoch 2, gen_loss = 0.4074236883057488, disc_loss = 0.19351640798979336
Trained batch 18 in epoch 2, gen_loss = 0.40607734416660507, disc_loss = 0.19386824847836243
Trained batch 19 in epoch 2, gen_loss = 0.4038615584373474, disc_loss = 0.19234902150928973
Trained batch 20 in epoch 2, gen_loss = 0.400551153080804, disc_loss = 0.19186026744899295
Trained batch 21 in epoch 2, gen_loss = 0.40023781901056116, disc_loss = 0.19038856198841875
Trained batch 22 in epoch 2, gen_loss = 0.4006247844385064, disc_loss = 0.18832754862049353
Trained batch 23 in epoch 2, gen_loss = 0.39950187255938846, disc_loss = 0.18683410218606392
Trained batch 24 in epoch 2, gen_loss = 0.4030964708328247, disc_loss = 0.18565831691026688
Trained batch 25 in epoch 2, gen_loss = 0.4018602646314181, disc_loss = 0.1841256948044667
Trained batch 26 in epoch 2, gen_loss = 0.3995380125663899, disc_loss = 0.18230372308580964
Trained batch 27 in epoch 2, gen_loss = 0.3982488683291844, disc_loss = 0.18139408289321832
Trained batch 28 in epoch 2, gen_loss = 0.3996529353076014, disc_loss = 0.18313974630216073
Trained batch 29 in epoch 2, gen_loss = 0.3977923850218455, disc_loss = 0.18659817948937416
Trained batch 30 in epoch 2, gen_loss = 0.39955796733979254, disc_loss = 0.18712949728773487
Trained batch 31 in epoch 2, gen_loss = 0.3987515466287732, disc_loss = 0.18725079693831503
Trained batch 32 in epoch 2, gen_loss = 0.3995444720441645, disc_loss = 0.18620596081018448
Trained batch 33 in epoch 2, gen_loss = 0.3987565040588379, disc_loss = 0.1858410504372681
Trained batch 34 in epoch 2, gen_loss = 0.3994889140129089, disc_loss = 0.18528439551591874
Trained batch 35 in epoch 2, gen_loss = 0.3995959104763137, disc_loss = 0.18577318369514412
Trained batch 36 in epoch 2, gen_loss = 0.40057957655674703, disc_loss = 0.18584858867767695
Trained batch 37 in epoch 2, gen_loss = 0.4015297074066965, disc_loss = 0.18661110750154444
Trained batch 38 in epoch 2, gen_loss = 0.40228360967758375, disc_loss = 0.18626718662488154
Trained batch 39 in epoch 2, gen_loss = 0.40206518694758414, disc_loss = 0.18597054947167635
Trained batch 40 in epoch 2, gen_loss = 0.40274580004738597, disc_loss = 0.18573195923392366
Trained batch 41 in epoch 2, gen_loss = 0.4016604260319755, disc_loss = 0.1856485436714831
Trained batch 42 in epoch 2, gen_loss = 0.39921556517135265, disc_loss = 0.1853768924294516
Trained batch 43 in epoch 2, gen_loss = 0.39973589981144125, disc_loss = 0.18390267850323158
Trained batch 44 in epoch 2, gen_loss = 0.3998263458410899, disc_loss = 0.18301439583301543
Trained batch 45 in epoch 2, gen_loss = 0.4009734949339991, disc_loss = 0.18263894999804703
Trained batch 46 in epoch 2, gen_loss = 0.40059052566264536, disc_loss = 0.18267460421044776
Trained batch 47 in epoch 2, gen_loss = 0.40090829382340115, disc_loss = 0.18284546863287687
Trained batch 48 in epoch 2, gen_loss = 0.40120484026110903, disc_loss = 0.1808479778012451
Trained batch 49 in epoch 2, gen_loss = 0.4001253664493561, disc_loss = 0.18064693063497544
Trained batch 50 in epoch 2, gen_loss = 0.4011576210751253, disc_loss = 0.17982295827538358
Trained batch 51 in epoch 2, gen_loss = 0.4024359182669566, disc_loss = 0.1786881831402962
Trained batch 52 in epoch 2, gen_loss = 0.4021881621963573, disc_loss = 0.1776590733876768
Trained batch 53 in epoch 2, gen_loss = 0.40223565642480497, disc_loss = 0.17667670134041044
Trained batch 54 in epoch 2, gen_loss = 0.4040764803236181, disc_loss = 0.17702455927025187
Trained batch 55 in epoch 2, gen_loss = 0.4067758827337197, disc_loss = 0.18653092187430179
Trained batch 56 in epoch 2, gen_loss = 0.40682110138106764, disc_loss = 0.18782377321469157
Trained batch 57 in epoch 2, gen_loss = 0.405620642777147, disc_loss = 0.1880038573310293
Trained batch 58 in epoch 2, gen_loss = 0.4045399210210574, disc_loss = 0.1885888644699323
Trained batch 59 in epoch 2, gen_loss = 0.4041461224357287, disc_loss = 0.18970062707861265
Trained batch 60 in epoch 2, gen_loss = 0.40408509578861174, disc_loss = 0.18951660687806177
Trained batch 61 in epoch 2, gen_loss = 0.4045517050450848, disc_loss = 0.1888089860158582
Trained batch 62 in epoch 2, gen_loss = 0.40425363088411, disc_loss = 0.1882374601231681
Trained batch 63 in epoch 2, gen_loss = 0.40347501588985324, disc_loss = 0.1886230984237045
Trained batch 64 in epoch 2, gen_loss = 0.40404181526257443, disc_loss = 0.1882739388025724
Trained batch 65 in epoch 2, gen_loss = 0.4041262092915448, disc_loss = 0.18774039975621484
Trained batch 66 in epoch 2, gen_loss = 0.40345248980308646, disc_loss = 0.18774978994433558
Trained batch 67 in epoch 2, gen_loss = 0.4040404409170151, disc_loss = 0.18721267734380329
Trained batch 68 in epoch 2, gen_loss = 0.40499146001926367, disc_loss = 0.18696056133595065
Trained batch 69 in epoch 2, gen_loss = 0.4058745775903974, disc_loss = 0.18683138915470668
Trained batch 70 in epoch 2, gen_loss = 0.4048689498867787, disc_loss = 0.1872882710796007
Trained batch 71 in epoch 2, gen_loss = 0.4049191599090894, disc_loss = 0.18641050677332613
Trained batch 72 in epoch 2, gen_loss = 0.4048125678545808, disc_loss = 0.18632117852772753
Trained batch 73 in epoch 2, gen_loss = 0.4049695359693991, disc_loss = 0.18590204538525762
Trained batch 74 in epoch 2, gen_loss = 0.40504225293795265, disc_loss = 0.18514737764994305
Trained batch 75 in epoch 2, gen_loss = 0.4053406052683529, disc_loss = 0.18506592139601707
Trained batch 76 in epoch 2, gen_loss = 0.405473980423692, disc_loss = 0.18406379077728693
Trained batch 77 in epoch 2, gen_loss = 0.4055612415839464, disc_loss = 0.18259447440505028
Trained batch 78 in epoch 2, gen_loss = 0.4064789576620995, disc_loss = 0.1815661015578463
Trained batch 79 in epoch 2, gen_loss = 0.4061397608369589, disc_loss = 0.18002446941100061
Trained batch 80 in epoch 2, gen_loss = 0.40594250552448224, disc_loss = 0.17969773466020456
Trained batch 81 in epoch 2, gen_loss = 0.4068269762324124, disc_loss = 0.1816539774853282
Trained batch 82 in epoch 2, gen_loss = 0.4071492919002671, disc_loss = 0.18111856977444096
Trained batch 83 in epoch 2, gen_loss = 0.4068688679309118, disc_loss = 0.1809328410863167
Trained batch 84 in epoch 2, gen_loss = 0.4070788976024179, disc_loss = 0.1802622233681819
Trained batch 85 in epoch 2, gen_loss = 0.40762126237847085, disc_loss = 0.1788562152881262
Trained batch 86 in epoch 2, gen_loss = 0.40776887947115403, disc_loss = 0.17745703103384752
Trained batch 87 in epoch 2, gen_loss = 0.40780836276032706, disc_loss = 0.17865272700278598
Trained batch 88 in epoch 2, gen_loss = 0.40853614016865075, disc_loss = 0.18299789195147792
Trained batch 89 in epoch 2, gen_loss = 0.40853074623478786, disc_loss = 0.18309302516281606
Trained batch 90 in epoch 2, gen_loss = 0.40791833040478465, disc_loss = 0.18352181018217578
Trained batch 91 in epoch 2, gen_loss = 0.407775038610334, disc_loss = 0.18359195720404387
Trained batch 92 in epoch 2, gen_loss = 0.4071846636392737, disc_loss = 0.18397940058381326
Trained batch 93 in epoch 2, gen_loss = 0.40689637274184126, disc_loss = 0.18413887240309665
Trained batch 94 in epoch 2, gen_loss = 0.4059977672602001, disc_loss = 0.1843720656084387
Trained batch 95 in epoch 2, gen_loss = 0.4053246791784962, disc_loss = 0.184218348042729
Trained batch 96 in epoch 2, gen_loss = 0.40496836679497944, disc_loss = 0.18390953006971741
Trained batch 97 in epoch 2, gen_loss = 0.4051535269435571, disc_loss = 0.1835048963904989
Trained batch 98 in epoch 2, gen_loss = 0.4047614236672719, disc_loss = 0.18298267373683477
Trained batch 99 in epoch 2, gen_loss = 0.40470884799957274, disc_loss = 0.18281870741397144
Trained batch 100 in epoch 2, gen_loss = 0.405106651015801, disc_loss = 0.18262553130193512
Trained batch 101 in epoch 2, gen_loss = 0.4049181567103255, disc_loss = 0.1829102305585847
Trained batch 102 in epoch 2, gen_loss = 0.405135443777714, disc_loss = 0.18315657542891872
Trained batch 103 in epoch 2, gen_loss = 0.40518323675944257, disc_loss = 0.1824162373534189
Trained batch 104 in epoch 2, gen_loss = 0.40528377720287867, disc_loss = 0.18242504628641265
Trained batch 105 in epoch 2, gen_loss = 0.4057738589790632, disc_loss = 0.18334155238040215
Trained batch 106 in epoch 2, gen_loss = 0.40530836749299665, disc_loss = 0.18322046786964497
Trained batch 107 in epoch 2, gen_loss = 0.4054037092460526, disc_loss = 0.18338639389171643
Trained batch 108 in epoch 2, gen_loss = 0.40569757321558964, disc_loss = 0.18317324199944462
Trained batch 109 in epoch 2, gen_loss = 0.4051230463114652, disc_loss = 0.18276317691938443
Trained batch 110 in epoch 2, gen_loss = 0.405543786179912, disc_loss = 0.18247733006740477
Trained batch 111 in epoch 2, gen_loss = 0.4054952436791999, disc_loss = 0.18241074604780547
Trained batch 112 in epoch 2, gen_loss = 0.4051809279264602, disc_loss = 0.18201121717559554
Trained batch 113 in epoch 2, gen_loss = 0.40485266504580514, disc_loss = 0.18279017249873855
Trained batch 114 in epoch 2, gen_loss = 0.4047731700150863, disc_loss = 0.18291974783591602
Trained batch 115 in epoch 2, gen_loss = 0.40414377738689555, disc_loss = 0.18303222353730736
Trained batch 116 in epoch 2, gen_loss = 0.40414815886407834, disc_loss = 0.18332015159420478
Trained batch 117 in epoch 2, gen_loss = 0.40384059841349973, disc_loss = 0.18317508094517862
Trained batch 118 in epoch 2, gen_loss = 0.4037274933662735, disc_loss = 0.1828948342311783
Trained batch 119 in epoch 2, gen_loss = 0.4035240237911542, disc_loss = 0.18265843878810603
Trained batch 120 in epoch 2, gen_loss = 0.4030100272214117, disc_loss = 0.18230441720648247
Trained batch 121 in epoch 2, gen_loss = 0.4027936754168057, disc_loss = 0.1818643042848247
Trained batch 122 in epoch 2, gen_loss = 0.4029230281589477, disc_loss = 0.18110008413592973
Trained batch 123 in epoch 2, gen_loss = 0.4028277019819906, disc_loss = 0.18101703384590725
Trained batch 124 in epoch 2, gen_loss = 0.4029989047050476, disc_loss = 0.18114523014426231
Trained batch 125 in epoch 2, gen_loss = 0.40245334141784245, disc_loss = 0.1806004899775698
Trained batch 126 in epoch 2, gen_loss = 0.4027437203981745, disc_loss = 0.18015240088809192
Trained batch 127 in epoch 2, gen_loss = 0.4031615958083421, disc_loss = 0.18058841666788794
Trained batch 128 in epoch 2, gen_loss = 0.40286786680997805, disc_loss = 0.1805349506668804
Trained batch 129 in epoch 2, gen_loss = 0.40329407659860755, disc_loss = 0.17993713081456147
Trained batch 130 in epoch 2, gen_loss = 0.40319339146140876, disc_loss = 0.17946984422684625
Trained batch 131 in epoch 2, gen_loss = 0.40319539245330926, disc_loss = 0.17938026777383956
Trained batch 132 in epoch 2, gen_loss = 0.40291241080241097, disc_loss = 0.179429170696583
Trained batch 133 in epoch 2, gen_loss = 0.40287257486314915, disc_loss = 0.1795382136340017
Trained batch 134 in epoch 2, gen_loss = 0.40331211730285926, disc_loss = 0.17937587921818096
Trained batch 135 in epoch 2, gen_loss = 0.40347515966962366, disc_loss = 0.179097956402556
Trained batch 136 in epoch 2, gen_loss = 0.40329114733821286, disc_loss = 0.17916716953372433
Trained batch 137 in epoch 2, gen_loss = 0.40350886315539264, disc_loss = 0.17895536915655585
Trained batch 138 in epoch 2, gen_loss = 0.40352029444502413, disc_loss = 0.17898585419539068
Trained batch 139 in epoch 2, gen_loss = 0.4033098054783685, disc_loss = 0.17906134205737284
Trained batch 140 in epoch 2, gen_loss = 0.4038365221192651, disc_loss = 0.1785055877944679
Trained batch 141 in epoch 2, gen_loss = 0.40419285733934857, disc_loss = 0.1786078633609372
Trained batch 142 in epoch 2, gen_loss = 0.40386883549756936, disc_loss = 0.17980346075825757
Trained batch 143 in epoch 2, gen_loss = 0.40430155396461487, disc_loss = 0.1796492269107451
Trained batch 144 in epoch 2, gen_loss = 0.40397247240461154, disc_loss = 0.17945251292709646
Trained batch 145 in epoch 2, gen_loss = 0.40365760844864257, disc_loss = 0.17925198695124828
Trained batch 146 in epoch 2, gen_loss = 0.403741455402504, disc_loss = 0.17899524995765717
Trained batch 147 in epoch 2, gen_loss = 0.40390006593755773, disc_loss = 0.17871685942785964
Trained batch 148 in epoch 2, gen_loss = 0.4040462876726317, disc_loss = 0.17872506952625794
Trained batch 149 in epoch 2, gen_loss = 0.40429484645525615, disc_loss = 0.17843299609919389
Trained batch 150 in epoch 2, gen_loss = 0.4043220001340702, disc_loss = 0.17849330399308774
Trained batch 151 in epoch 2, gen_loss = 0.4045380834293993, disc_loss = 0.17822558435268307
Trained batch 152 in epoch 2, gen_loss = 0.40450288287175246, disc_loss = 0.17802783459717153
Trained batch 153 in epoch 2, gen_loss = 0.4044642485194392, disc_loss = 0.17783175024216052
Trained batch 154 in epoch 2, gen_loss = 0.40464459984533246, disc_loss = 0.17735878029657948
Trained batch 155 in epoch 2, gen_loss = 0.4049680830958562, disc_loss = 0.177010633266316
Trained batch 156 in epoch 2, gen_loss = 0.40537946011610093, disc_loss = 0.17655221636223187
Trained batch 157 in epoch 2, gen_loss = 0.4052649066795277, disc_loss = 0.176038480611353
Trained batch 158 in epoch 2, gen_loss = 0.40545888779298317, disc_loss = 0.1753154254325156
Trained batch 159 in epoch 2, gen_loss = 0.4055982420220971, disc_loss = 0.17459887405857444
Trained batch 160 in epoch 2, gen_loss = 0.40615784659148746, disc_loss = 0.17374905575969204
Trained batch 161 in epoch 2, gen_loss = 0.40648928634178494, disc_loss = 0.17275943377135713
Trained batch 162 in epoch 2, gen_loss = 0.40624954089796617, disc_loss = 0.1733650667535747
Trained batch 163 in epoch 2, gen_loss = 0.406944013405137, disc_loss = 0.17471886662448324
Trained batch 164 in epoch 2, gen_loss = 0.40658468459591723, disc_loss = 0.17477884834462945
Trained batch 165 in epoch 2, gen_loss = 0.40645077483481673, disc_loss = 0.17498649261802077
Trained batch 166 in epoch 2, gen_loss = 0.4064868206749419, disc_loss = 0.17485634001072295
Trained batch 167 in epoch 2, gen_loss = 0.4064024060609795, disc_loss = 0.17468477554974102
Trained batch 168 in epoch 2, gen_loss = 0.40621342637835167, disc_loss = 0.1744065538665952
Trained batch 169 in epoch 2, gen_loss = 0.4059876229833154, disc_loss = 0.17441797975231618
Trained batch 170 in epoch 2, gen_loss = 0.4059155037877155, disc_loss = 0.1742277132314548
Trained batch 171 in epoch 2, gen_loss = 0.4060176349309988, disc_loss = 0.17370834197242593
Trained batch 172 in epoch 2, gen_loss = 0.4062043977955173, disc_loss = 0.17301269306268305
Trained batch 173 in epoch 2, gen_loss = 0.4060415954425417, disc_loss = 0.17328281743430543
Trained batch 174 in epoch 2, gen_loss = 0.4063137332030705, disc_loss = 0.17438316234520504
Trained batch 175 in epoch 2, gen_loss = 0.40614447268572723, disc_loss = 0.17499269367280332
Trained batch 176 in epoch 2, gen_loss = 0.4060083535094719, disc_loss = 0.17478188619775287
Trained batch 177 in epoch 2, gen_loss = 0.4060602472739273, disc_loss = 0.17487341081828214
Trained batch 178 in epoch 2, gen_loss = 0.40630423240155483, disc_loss = 0.17540588641965854
Trained batch 179 in epoch 2, gen_loss = 0.4057813162604968, disc_loss = 0.17522097842560874
Trained batch 180 in epoch 2, gen_loss = 0.4057437953698701, disc_loss = 0.17606482947070295
Trained batch 181 in epoch 2, gen_loss = 0.4062714791232413, disc_loss = 0.1763724175455806
Trained batch 182 in epoch 2, gen_loss = 0.40628547551201993, disc_loss = 0.17639581085554237
Trained batch 183 in epoch 2, gen_loss = 0.40657475007616956, disc_loss = 0.17580199743742528
Trained batch 184 in epoch 2, gen_loss = 0.4064205947759989, disc_loss = 0.17594638096319662
Trained batch 185 in epoch 2, gen_loss = 0.4066690792960505, disc_loss = 0.17578424521351374
Trained batch 186 in epoch 2, gen_loss = 0.4071791793573349, disc_loss = 0.17522823045597993
Trained batch 187 in epoch 2, gen_loss = 0.40698653380287453, disc_loss = 0.1749595343432528
Trained batch 188 in epoch 2, gen_loss = 0.40676272893078114, disc_loss = 0.17481017317721453
Trained batch 189 in epoch 2, gen_loss = 0.40670847014376993, disc_loss = 0.17467525773926784
Trained batch 190 in epoch 2, gen_loss = 0.4064449521259488, disc_loss = 0.17455603346150583
Trained batch 191 in epoch 2, gen_loss = 0.4063724856823683, disc_loss = 0.17449780770887932
Trained batch 192 in epoch 2, gen_loss = 0.40627595087407165, disc_loss = 0.17455279564610418
Trained batch 193 in epoch 2, gen_loss = 0.4063422991750167, disc_loss = 0.174280626065645
Trained batch 194 in epoch 2, gen_loss = 0.4064107425701924, disc_loss = 0.1739193551433392
Trained batch 195 in epoch 2, gen_loss = 0.40625384130648207, disc_loss = 0.1734156795986453
Trained batch 196 in epoch 2, gen_loss = 0.4061316607264698, disc_loss = 0.173807620586175
Trained batch 197 in epoch 2, gen_loss = 0.40636027762384125, disc_loss = 0.1745165916479597
Trained batch 198 in epoch 2, gen_loss = 0.40630880791937285, disc_loss = 0.17406226732023997
Trained batch 199 in epoch 2, gen_loss = 0.40594062075018883, disc_loss = 0.17395749613642691
Trained batch 200 in epoch 2, gen_loss = 0.40597944235920314, disc_loss = 0.17497709571425593
Trained batch 201 in epoch 2, gen_loss = 0.4061396661961433, disc_loss = 0.17563187972743913
Trained batch 202 in epoch 2, gen_loss = 0.4059786555802294, disc_loss = 0.17555120264368104
Trained batch 203 in epoch 2, gen_loss = 0.4058850214761846, disc_loss = 0.17528126622531928
Trained batch 204 in epoch 2, gen_loss = 0.4059326971449503, disc_loss = 0.17480653916917196
Trained batch 205 in epoch 2, gen_loss = 0.40553200389575034, disc_loss = 0.1750432623242869
Trained batch 206 in epoch 2, gen_loss = 0.4056268677043454, disc_loss = 0.17489450248543192
Trained batch 207 in epoch 2, gen_loss = 0.40565284714102745, disc_loss = 0.1746401096550891
Trained batch 208 in epoch 2, gen_loss = 0.4056842717827792, disc_loss = 0.1742449678373679
Trained batch 209 in epoch 2, gen_loss = 0.4054227739572525, disc_loss = 0.17414347532959212
Trained batch 210 in epoch 2, gen_loss = 0.40530923630388993, disc_loss = 0.17379465759224236
Trained batch 211 in epoch 2, gen_loss = 0.40536256261029335, disc_loss = 0.17383163158764253
Trained batch 212 in epoch 2, gen_loss = 0.4051294455505873, disc_loss = 0.17430091005675669
Trained batch 213 in epoch 2, gen_loss = 0.40512032361231115, disc_loss = 0.17406936529501577
Trained batch 214 in epoch 2, gen_loss = 0.40519827451816826, disc_loss = 0.17371330098357313
Trained batch 215 in epoch 2, gen_loss = 0.4053358677084799, disc_loss = 0.173339513613394
Trained batch 216 in epoch 2, gen_loss = 0.40524015173934025, disc_loss = 0.17296729569885588
Trained batch 217 in epoch 2, gen_loss = 0.40553336884450475, disc_loss = 0.1726541888959911
Trained batch 218 in epoch 2, gen_loss = 0.4053134673262296, disc_loss = 0.17215735492504894
Trained batch 219 in epoch 2, gen_loss = 0.40523736625909806, disc_loss = 0.17207000922750343
Trained batch 220 in epoch 2, gen_loss = 0.40580444112082953, disc_loss = 0.17243398318058764
Trained batch 221 in epoch 2, gen_loss = 0.4058543458446726, disc_loss = 0.17200884917700612
Trained batch 222 in epoch 2, gen_loss = 0.405745879016115, disc_loss = 0.17224337818777616
Trained batch 223 in epoch 2, gen_loss = 0.4057474108412862, disc_loss = 0.17214828240685165
Trained batch 224 in epoch 2, gen_loss = 0.40558787147204084, disc_loss = 0.17212724649243885
Trained batch 225 in epoch 2, gen_loss = 0.4054505571854853, disc_loss = 0.17189412329972317
Trained batch 226 in epoch 2, gen_loss = 0.4054678755972354, disc_loss = 0.17156656040494137
Trained batch 227 in epoch 2, gen_loss = 0.40546012395306635, disc_loss = 0.17098414214948812
Trained batch 228 in epoch 2, gen_loss = 0.4056766915529576, disc_loss = 0.1703478576509713
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4227679967880249, disc_loss = 0.15039855241775513
Trained batch 1 in epoch 3, gen_loss = 0.4195083975791931, disc_loss = 0.28221163153648376
Trained batch 2 in epoch 3, gen_loss = 0.4093372126420339, disc_loss = 0.2496238648891449
Trained batch 3 in epoch 3, gen_loss = 0.39659248292446136, disc_loss = 0.21978209912776947
Trained batch 4 in epoch 3, gen_loss = 0.39223684668540953, disc_loss = 0.21136581301689147
Trained batch 5 in epoch 3, gen_loss = 0.39745249847571057, disc_loss = 0.1976491610209147
Trained batch 6 in epoch 3, gen_loss = 0.3937600553035736, disc_loss = 0.18244272151163646
Trained batch 7 in epoch 3, gen_loss = 0.39155618473887444, disc_loss = 0.1736988751217723
Trained batch 8 in epoch 3, gen_loss = 0.3956342471970452, disc_loss = 0.17519614514377382
Trained batch 9 in epoch 3, gen_loss = 0.39296016097068787, disc_loss = 0.17428973987698554
Trained batch 10 in epoch 3, gen_loss = 0.39610550891269336, disc_loss = 0.1737056164578958
Trained batch 11 in epoch 3, gen_loss = 0.39464538792769116, disc_loss = 0.17604920826852322
Trained batch 12 in epoch 3, gen_loss = 0.3914292844442221, disc_loss = 0.1731812203159699
Trained batch 13 in epoch 3, gen_loss = 0.39142967973436626, disc_loss = 0.17122889256903104
Trained batch 14 in epoch 3, gen_loss = 0.3929758052031199, disc_loss = 0.16980627030134202
Trained batch 15 in epoch 3, gen_loss = 0.3918492067605257, disc_loss = 0.16687607811763883
Trained batch 16 in epoch 3, gen_loss = 0.38988441930097695, disc_loss = 0.16770455547991922
Trained batch 17 in epoch 3, gen_loss = 0.39302872286902535, disc_loss = 0.16634696018364695
Trained batch 18 in epoch 3, gen_loss = 0.3928528804528086, disc_loss = 0.16449624103935143
Trained batch 19 in epoch 3, gen_loss = 0.3914357736706734, disc_loss = 0.16412124149501323
Trained batch 20 in epoch 3, gen_loss = 0.3920283445290157, disc_loss = 0.16372764146044141
Trained batch 21 in epoch 3, gen_loss = 0.3931084221059626, disc_loss = 0.1597319133579731
Trained batch 22 in epoch 3, gen_loss = 0.3930078395034956, disc_loss = 0.15767757950917535
Trained batch 23 in epoch 3, gen_loss = 0.39733966315786046, disc_loss = 0.15509037487208843
Trained batch 24 in epoch 3, gen_loss = 0.3991398513317108, disc_loss = 0.15071116149425506
Trained batch 25 in epoch 3, gen_loss = 0.3983771331035174, disc_loss = 0.14618538234096307
Trained batch 26 in epoch 3, gen_loss = 0.3999052831420192, disc_loss = 0.15373282106938185
Trained batch 27 in epoch 3, gen_loss = 0.40333730088812964, disc_loss = 0.16480328275689057
Trained batch 28 in epoch 3, gen_loss = 0.40364561820852346, disc_loss = 0.16273806346901531
Trained batch 29 in epoch 3, gen_loss = 0.4033942610025406, disc_loss = 0.16234060749411583
Trained batch 30 in epoch 3, gen_loss = 0.40287418038614337, disc_loss = 0.1620288349447712
Trained batch 31 in epoch 3, gen_loss = 0.40293439757078886, disc_loss = 0.16125869122333825
Trained batch 32 in epoch 3, gen_loss = 0.4034278997869203, disc_loss = 0.15954497975833487
Trained batch 33 in epoch 3, gen_loss = 0.4032498755875756, disc_loss = 0.1591075362966341
Trained batch 34 in epoch 3, gen_loss = 0.40380016565322874, disc_loss = 0.16241558300597328
Trained batch 35 in epoch 3, gen_loss = 0.401469412777159, disc_loss = 0.16161124635901716
Trained batch 36 in epoch 3, gen_loss = 0.4016510626754245, disc_loss = 0.1613470019923674
Trained batch 37 in epoch 3, gen_loss = 0.4016561390537965, disc_loss = 0.16396208283932587
Trained batch 38 in epoch 3, gen_loss = 0.40013401936262083, disc_loss = 0.16378785650699568
Trained batch 39 in epoch 3, gen_loss = 0.39964430704712867, disc_loss = 0.16323528792709113
Trained batch 40 in epoch 3, gen_loss = 0.39998172696043804, disc_loss = 0.16227107876684607
Trained batch 41 in epoch 3, gen_loss = 0.40038944426037015, disc_loss = 0.1616355081399282
Trained batch 42 in epoch 3, gen_loss = 0.39872650906097057, disc_loss = 0.16173342909923819
Trained batch 43 in epoch 3, gen_loss = 0.3995142084631053, disc_loss = 0.16173532164909624
Trained batch 44 in epoch 3, gen_loss = 0.3986571417914497, disc_loss = 0.16090399192439186
Trained batch 45 in epoch 3, gen_loss = 0.39798481114532636, disc_loss = 0.16063952316408572
Trained batch 46 in epoch 3, gen_loss = 0.3971786968251492, disc_loss = 0.1602001462845092
Trained batch 47 in epoch 3, gen_loss = 0.39686270120243233, disc_loss = 0.1615953864529729
Trained batch 48 in epoch 3, gen_loss = 0.3986764325171101, disc_loss = 0.16303507618758142
Trained batch 49 in epoch 3, gen_loss = 0.39842797338962554, disc_loss = 0.16163086712360383
Trained batch 50 in epoch 3, gen_loss = 0.39793940852670107, disc_loss = 0.1610155421144822
Trained batch 51 in epoch 3, gen_loss = 0.3974983256596785, disc_loss = 0.15938268343989664
Trained batch 52 in epoch 3, gen_loss = 0.3983558382628099, disc_loss = 0.15831007991196974
Trained batch 53 in epoch 3, gen_loss = 0.39920644241350667, disc_loss = 0.15764612952868143
Trained batch 54 in epoch 3, gen_loss = 0.39968974156813186, disc_loss = 0.1554197923703627
Trained batch 55 in epoch 3, gen_loss = 0.39874163110341343, disc_loss = 0.1539255597495607
Trained batch 56 in epoch 3, gen_loss = 0.3994851567243275, disc_loss = 0.15245122554009422
Trained batch 57 in epoch 3, gen_loss = 0.39905397593975067, disc_loss = 0.15172847257605915
Trained batch 58 in epoch 3, gen_loss = 0.3976484607842009, disc_loss = 0.1507727847260944
Trained batch 59 in epoch 3, gen_loss = 0.3988769034544627, disc_loss = 0.14969013594090938
Trained batch 60 in epoch 3, gen_loss = 0.4006193299762538, disc_loss = 0.15277211258157355
Trained batch 61 in epoch 3, gen_loss = 0.4002025838821165, disc_loss = 0.1595539245153627
Trained batch 62 in epoch 3, gen_loss = 0.400604334142473, disc_loss = 0.15933127358319268
Trained batch 63 in epoch 3, gen_loss = 0.40046091563999653, disc_loss = 0.15850817505270243
Trained batch 64 in epoch 3, gen_loss = 0.3999187441972586, disc_loss = 0.15834800555155829
Trained batch 65 in epoch 3, gen_loss = 0.4003416999722972, disc_loss = 0.15882162975542474
Trained batch 66 in epoch 3, gen_loss = 0.39995215321654703, disc_loss = 0.16107145974885173
Trained batch 67 in epoch 3, gen_loss = 0.3997287715182585, disc_loss = 0.16099736510830767
Trained batch 68 in epoch 3, gen_loss = 0.3991724226785743, disc_loss = 0.1603689608366593
Trained batch 69 in epoch 3, gen_loss = 0.3988165604216712, disc_loss = 0.1598952508398465
Trained batch 70 in epoch 3, gen_loss = 0.3983586287834275, disc_loss = 0.1591201817065897
Trained batch 71 in epoch 3, gen_loss = 0.3984111232890023, disc_loss = 0.15806256420910358
Trained batch 72 in epoch 3, gen_loss = 0.39852891882804975, disc_loss = 0.15722301316587892
Trained batch 73 in epoch 3, gen_loss = 0.39887279997000824, disc_loss = 0.15590346579414768
Trained batch 74 in epoch 3, gen_loss = 0.3995010495185852, disc_loss = 0.15582489863038063
Trained batch 75 in epoch 3, gen_loss = 0.3998155515444906, disc_loss = 0.15587140065862945
Trained batch 76 in epoch 3, gen_loss = 0.3999968542681112, disc_loss = 0.15596438184767575
Trained batch 77 in epoch 3, gen_loss = 0.4002056305225079, disc_loss = 0.1558140905526204
Trained batch 78 in epoch 3, gen_loss = 0.4005091163931014, disc_loss = 0.15518436038607283
Trained batch 79 in epoch 3, gen_loss = 0.40022996701300145, disc_loss = 0.15531171183101833
Trained batch 80 in epoch 3, gen_loss = 0.40106225492041786, disc_loss = 0.15842797464610617
Trained batch 81 in epoch 3, gen_loss = 0.4011809575121577, disc_loss = 0.15812922319079317
Trained batch 82 in epoch 3, gen_loss = 0.40049843508076954, disc_loss = 0.15855011626718993
Trained batch 83 in epoch 3, gen_loss = 0.400179199164822, disc_loss = 0.15988328693700687
Trained batch 84 in epoch 3, gen_loss = 0.399721677163068, disc_loss = 0.15932906598729246
Trained batch 85 in epoch 3, gen_loss = 0.39935151435608085, disc_loss = 0.1583801309123289
Trained batch 86 in epoch 3, gen_loss = 0.3993425862542514, disc_loss = 0.15774934032353863
Trained batch 87 in epoch 3, gen_loss = 0.39905853095379745, disc_loss = 0.15776310696012594
Trained batch 88 in epoch 3, gen_loss = 0.39940383829427567, disc_loss = 0.15749559078491135
Trained batch 89 in epoch 3, gen_loss = 0.39949288268884026, disc_loss = 0.15687007328702343
Trained batch 90 in epoch 3, gen_loss = 0.39962183086426706, disc_loss = 0.15691474395302626
Trained batch 91 in epoch 3, gen_loss = 0.40052927479795786, disc_loss = 0.1576181668383272
Trained batch 92 in epoch 3, gen_loss = 0.4013856729512574, disc_loss = 0.15759245254179483
Trained batch 93 in epoch 3, gen_loss = 0.4012968441907396, disc_loss = 0.15731383356800738
Trained batch 94 in epoch 3, gen_loss = 0.4010455539352015, disc_loss = 0.15665698714162174
Trained batch 95 in epoch 3, gen_loss = 0.4005039365341266, disc_loss = 0.15689845588834336
Trained batch 96 in epoch 3, gen_loss = 0.40097119206005766, disc_loss = 0.15839021280407906
Trained batch 97 in epoch 3, gen_loss = 0.40064927266568556, disc_loss = 0.15910360661848466
Trained batch 98 in epoch 3, gen_loss = 0.40075737027206804, disc_loss = 0.15940943123264747
Trained batch 99 in epoch 3, gen_loss = 0.40076081663370133, disc_loss = 0.1600132480636239
Trained batch 100 in epoch 3, gen_loss = 0.4009352170004703, disc_loss = 0.16033115278523746
Trained batch 101 in epoch 3, gen_loss = 0.4003632413405998, disc_loss = 0.16009364616783225
Trained batch 102 in epoch 3, gen_loss = 0.4004350732831122, disc_loss = 0.15992147066784138
Trained batch 103 in epoch 3, gen_loss = 0.401157974337156, disc_loss = 0.1599788795082042
Trained batch 104 in epoch 3, gen_loss = 0.4022457182407379, disc_loss = 0.15885188905965714
Trained batch 105 in epoch 3, gen_loss = 0.402211531434419, disc_loss = 0.1609981249807016
Trained batch 106 in epoch 3, gen_loss = 0.40338863139954684, disc_loss = 0.1608405420991862
Trained batch 107 in epoch 3, gen_loss = 0.4045390892359946, disc_loss = 0.15970700689487988
Trained batch 108 in epoch 3, gen_loss = 0.40504434376681614, disc_loss = 0.158814455630309
Trained batch 109 in epoch 3, gen_loss = 0.4053119949319146, disc_loss = 0.15808384665711359
Trained batch 110 in epoch 3, gen_loss = 0.40546066991917723, disc_loss = 0.15795315899424725
Trained batch 111 in epoch 3, gen_loss = 0.40569956467619966, disc_loss = 0.1573703507560172
Trained batch 112 in epoch 3, gen_loss = 0.40549496264584295, disc_loss = 0.1579567851020699
Trained batch 113 in epoch 3, gen_loss = 0.40537300130777193, disc_loss = 0.15895092203036734
Trained batch 114 in epoch 3, gen_loss = 0.4055121898651123, disc_loss = 0.15987070879858473
Trained batch 115 in epoch 3, gen_loss = 0.4052616075195115, disc_loss = 0.15924641570269032
Trained batch 116 in epoch 3, gen_loss = 0.4058488566651304, disc_loss = 0.15825416806798714
Trained batch 117 in epoch 3, gen_loss = 0.40523315587286224, disc_loss = 0.1579310224407305
Trained batch 118 in epoch 3, gen_loss = 0.4049436750532198, disc_loss = 0.1577612359170653
Trained batch 119 in epoch 3, gen_loss = 0.4051654102901618, disc_loss = 0.15781022431328892
Trained batch 120 in epoch 3, gen_loss = 0.4052179458220143, disc_loss = 0.15765672931370656
Trained batch 121 in epoch 3, gen_loss = 0.4051096505317532, disc_loss = 0.15783382692664374
Trained batch 122 in epoch 3, gen_loss = 0.40526432453132255, disc_loss = 0.15785801213810113
Trained batch 123 in epoch 3, gen_loss = 0.4060219194619886, disc_loss = 0.15846443149231135
Trained batch 124 in epoch 3, gen_loss = 0.4060523958206177, disc_loss = 0.15854884752631188
Trained batch 125 in epoch 3, gen_loss = 0.4060340074319688, disc_loss = 0.15844166666151038
Trained batch 126 in epoch 3, gen_loss = 0.4058950541056986, disc_loss = 0.15818583809836642
Trained batch 127 in epoch 3, gen_loss = 0.40593361179344356, disc_loss = 0.1579168744792696
Trained batch 128 in epoch 3, gen_loss = 0.40581211170484854, disc_loss = 0.1575468518417473
Trained batch 129 in epoch 3, gen_loss = 0.4058263320189256, disc_loss = 0.1572632405333794
Trained batch 130 in epoch 3, gen_loss = 0.4053316505355689, disc_loss = 0.15687746864580016
Trained batch 131 in epoch 3, gen_loss = 0.40543140516136633, disc_loss = 0.156347463048543
Trained batch 132 in epoch 3, gen_loss = 0.40554950739208023, disc_loss = 0.155839653307558
Trained batch 133 in epoch 3, gen_loss = 0.40544937595502656, disc_loss = 0.15698818053438593
Trained batch 134 in epoch 3, gen_loss = 0.405935161864316, disc_loss = 0.15752344343949248
Trained batch 135 in epoch 3, gen_loss = 0.40512891354806285, disc_loss = 0.15758670288521578
Trained batch 136 in epoch 3, gen_loss = 0.4046884194342759, disc_loss = 0.15790244374070725
Trained batch 137 in epoch 3, gen_loss = 0.4046350350414497, disc_loss = 0.15754089199438476
Trained batch 138 in epoch 3, gen_loss = 0.404696017074928, disc_loss = 0.1573319048922268
Trained batch 139 in epoch 3, gen_loss = 0.4045640027948788, disc_loss = 0.1571359345689416
Trained batch 140 in epoch 3, gen_loss = 0.40406646014105346, disc_loss = 0.15671903637389764
Trained batch 141 in epoch 3, gen_loss = 0.4049138915790638, disc_loss = 0.15649407994474324
Trained batch 142 in epoch 3, gen_loss = 0.40466616641391406, disc_loss = 0.1560431719086804
Trained batch 143 in epoch 3, gen_loss = 0.40461440156731343, disc_loss = 0.15775563322111136
Trained batch 144 in epoch 3, gen_loss = 0.40482094143999037, disc_loss = 0.15770749678385668
Trained batch 145 in epoch 3, gen_loss = 0.4049377292394638, disc_loss = 0.1570684789641671
Trained batch 146 in epoch 3, gen_loss = 0.40497981386930765, disc_loss = 0.15662627325070147
Trained batch 147 in epoch 3, gen_loss = 0.4050463397760649, disc_loss = 0.15642870929897637
Trained batch 148 in epoch 3, gen_loss = 0.40460988559178857, disc_loss = 0.1568514173412883
Trained batch 149 in epoch 3, gen_loss = 0.404417098959287, disc_loss = 0.1567008350044489
Trained batch 150 in epoch 3, gen_loss = 0.40377442193347096, disc_loss = 0.15677051589090302
Trained batch 151 in epoch 3, gen_loss = 0.4036031492838734, disc_loss = 0.15762459817587546
Trained batch 152 in epoch 3, gen_loss = 0.40317919558169796, disc_loss = 0.15793254813240246
Trained batch 153 in epoch 3, gen_loss = 0.4030726478471384, disc_loss = 0.15799320999581318
Trained batch 154 in epoch 3, gen_loss = 0.4032135974976324, disc_loss = 0.15825757449192385
Trained batch 155 in epoch 3, gen_loss = 0.4035027178052144, disc_loss = 0.15823233364006647
Trained batch 156 in epoch 3, gen_loss = 0.40361720342544993, disc_loss = 0.1580874055007081
Trained batch 157 in epoch 3, gen_loss = 0.4035185475515414, disc_loss = 0.15808016314065154
Trained batch 158 in epoch 3, gen_loss = 0.4033794714219915, disc_loss = 0.15788633350587492
Trained batch 159 in epoch 3, gen_loss = 0.4031922908499837, disc_loss = 0.1573792801471427
Trained batch 160 in epoch 3, gen_loss = 0.4030469544926045, disc_loss = 0.15725530797372694
Trained batch 161 in epoch 3, gen_loss = 0.4032289693017065, disc_loss = 0.15712145396312813
Trained batch 162 in epoch 3, gen_loss = 0.4035659278828674, disc_loss = 0.15655518956253864
Trained batch 163 in epoch 3, gen_loss = 0.40385144985303645, disc_loss = 0.15607842891590623
Trained batch 164 in epoch 3, gen_loss = 0.4041027798797145, disc_loss = 0.15614343770977224
Trained batch 165 in epoch 3, gen_loss = 0.4042665175644748, disc_loss = 0.1556302905755948
Trained batch 166 in epoch 3, gen_loss = 0.40409517002676776, disc_loss = 0.155522549736821
Trained batch 167 in epoch 3, gen_loss = 0.4042520663213162, disc_loss = 0.1553770540326479
Trained batch 168 in epoch 3, gen_loss = 0.40433268610542344, disc_loss = 0.15514555699109325
Trained batch 169 in epoch 3, gen_loss = 0.4040249542278402, disc_loss = 0.15517197998569293
Trained batch 170 in epoch 3, gen_loss = 0.404096574985493, disc_loss = 0.15556768900905435
Trained batch 171 in epoch 3, gen_loss = 0.40408835386814074, disc_loss = 0.1551025764756771
Trained batch 172 in epoch 3, gen_loss = 0.4041505235468032, disc_loss = 0.15473645669273559
Trained batch 173 in epoch 3, gen_loss = 0.4040684648628893, disc_loss = 0.15438676049568872
Trained batch 174 in epoch 3, gen_loss = 0.4042954925128392, disc_loss = 0.1543174709379673
Trained batch 175 in epoch 3, gen_loss = 0.4039852593771436, disc_loss = 0.15411855032752184
Trained batch 176 in epoch 3, gen_loss = 0.4038256381527852, disc_loss = 0.15369677263717194
Trained batch 177 in epoch 3, gen_loss = 0.4037206172943115, disc_loss = 0.15307221835834928
Trained batch 178 in epoch 3, gen_loss = 0.40377501485734013, disc_loss = 0.1525544241153994
Trained batch 179 in epoch 3, gen_loss = 0.4037036246723599, disc_loss = 0.1520911518484354
Trained batch 180 in epoch 3, gen_loss = 0.4038229736175326, disc_loss = 0.1518212434583606
Trained batch 181 in epoch 3, gen_loss = 0.4040534943342209, disc_loss = 0.15200716146564747
Trained batch 182 in epoch 3, gen_loss = 0.40394762826096164, disc_loss = 0.15187006126173208
Trained batch 183 in epoch 3, gen_loss = 0.40377604264927947, disc_loss = 0.15162682626396418
Trained batch 184 in epoch 3, gen_loss = 0.4041267198485297, disc_loss = 0.15150016767753138
Trained batch 185 in epoch 3, gen_loss = 0.4041200816951772, disc_loss = 0.15144888227505068
Trained batch 186 in epoch 3, gen_loss = 0.40426108767004576, disc_loss = 0.15104890578889593
Trained batch 187 in epoch 3, gen_loss = 0.4046791466943761, disc_loss = 0.15142252129760195
Trained batch 188 in epoch 3, gen_loss = 0.40477566696979383, disc_loss = 0.15150618529508983
Trained batch 189 in epoch 3, gen_loss = 0.4046999380776757, disc_loss = 0.1520848160511569
Trained batch 190 in epoch 3, gen_loss = 0.40497126769645053, disc_loss = 0.1523585550448033
Trained batch 191 in epoch 3, gen_loss = 0.40495159026856226, disc_loss = 0.15212053782306612
Trained batch 192 in epoch 3, gen_loss = 0.40471865862144707, disc_loss = 0.15221905824125123
Trained batch 193 in epoch 3, gen_loss = 0.40479814745101733, disc_loss = 0.1519112573149278
Trained batch 194 in epoch 3, gen_loss = 0.4050429701805115, disc_loss = 0.15178511578303117
Trained batch 195 in epoch 3, gen_loss = 0.40495373992895595, disc_loss = 0.15155681123842998
Trained batch 196 in epoch 3, gen_loss = 0.40486336359517827, disc_loss = 0.15157770853357266
Trained batch 197 in epoch 3, gen_loss = 0.4046243700114163, disc_loss = 0.1517276917443131
Trained batch 198 in epoch 3, gen_loss = 0.4045022796446355, disc_loss = 0.1518396168348178
Trained batch 199 in epoch 3, gen_loss = 0.40448995396494863, disc_loss = 0.15149999931454658
Trained batch 200 in epoch 3, gen_loss = 0.40440332963692016, disc_loss = 0.15139801125621322
Trained batch 201 in epoch 3, gen_loss = 0.40426485225705816, disc_loss = 0.1511104568691537
Trained batch 202 in epoch 3, gen_loss = 0.4041420237477777, disc_loss = 0.15102841341730408
Trained batch 203 in epoch 3, gen_loss = 0.40409403732594323, disc_loss = 0.1508378742591423
Trained batch 204 in epoch 3, gen_loss = 0.40399393206689416, disc_loss = 0.1502899875182931
Trained batch 205 in epoch 3, gen_loss = 0.40393691965677203, disc_loss = 0.15013584358961257
Trained batch 206 in epoch 3, gen_loss = 0.4041682677568445, disc_loss = 0.1502925325455009
Trained batch 207 in epoch 3, gen_loss = 0.4039684561296151, disc_loss = 0.15052047287687087
Trained batch 208 in epoch 3, gen_loss = 0.40400095077222614, disc_loss = 0.1507979583119947
Trained batch 209 in epoch 3, gen_loss = 0.40421882030509765, disc_loss = 0.1505089869988816
Trained batch 210 in epoch 3, gen_loss = 0.40409569731820816, disc_loss = 0.15029264991811667
Trained batch 211 in epoch 3, gen_loss = 0.4040584357560806, disc_loss = 0.1498964283228764
Trained batch 212 in epoch 3, gen_loss = 0.40396422469559967, disc_loss = 0.14982374766273118
Trained batch 213 in epoch 3, gen_loss = 0.40397166342378776, disc_loss = 0.14955738474066568
Trained batch 214 in epoch 3, gen_loss = 0.4041511288909025, disc_loss = 0.14906058216164278
Trained batch 215 in epoch 3, gen_loss = 0.40399395853832915, disc_loss = 0.14928641006419505
Trained batch 216 in epoch 3, gen_loss = 0.40419436311392193, disc_loss = 0.14980799194923194
Trained batch 217 in epoch 3, gen_loss = 0.40436304681891694, disc_loss = 0.14969941066287526
Trained batch 218 in epoch 3, gen_loss = 0.4043715057307727, disc_loss = 0.14945213600448823
Trained batch 219 in epoch 3, gen_loss = 0.40427062958478927, disc_loss = 0.14925423472781074
Trained batch 220 in epoch 3, gen_loss = 0.40469061694533576, disc_loss = 0.14885480273767834
Trained batch 221 in epoch 3, gen_loss = 0.4045237896141705, disc_loss = 0.14981459856436058
Trained batch 222 in epoch 3, gen_loss = 0.4047535297047397, disc_loss = 0.1500873749766649
Trained batch 223 in epoch 3, gen_loss = 0.4050978807998555, disc_loss = 0.14975560064028418
Trained batch 224 in epoch 3, gen_loss = 0.40510843329959445, disc_loss = 0.14993830038441552
Trained batch 225 in epoch 3, gen_loss = 0.40527629984163605, disc_loss = 0.14977131718027908
Trained batch 226 in epoch 3, gen_loss = 0.40533188366154743, disc_loss = 0.1498490734772535
Trained batch 227 in epoch 3, gen_loss = 0.4056075442778437, disc_loss = 0.14933198865241648
Trained batch 228 in epoch 3, gen_loss = 0.4056821773926764, disc_loss = 0.14908533144791053
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.3798689544200897, disc_loss = 0.11532330513000488
Trained batch 1 in epoch 4, gen_loss = 0.44918204843997955, disc_loss = 0.16509748250246048
Trained batch 2 in epoch 4, gen_loss = 0.4258864223957062, disc_loss = 0.1874124507109324
Trained batch 3 in epoch 4, gen_loss = 0.43806077539920807, disc_loss = 0.17664822190999985
Trained batch 4 in epoch 4, gen_loss = 0.43421943187713624, disc_loss = 0.17849128246307372
Trained batch 5 in epoch 4, gen_loss = 0.42851794759432477, disc_loss = 0.17060600717862448
Trained batch 6 in epoch 4, gen_loss = 0.41910499334335327, disc_loss = 0.15847212927682058
Trained batch 7 in epoch 4, gen_loss = 0.41711001098155975, disc_loss = 0.14959899429231882
Trained batch 8 in epoch 4, gen_loss = 0.42257095707787407, disc_loss = 0.14090333133935928
Trained batch 9 in epoch 4, gen_loss = 0.42070183753967283, disc_loss = 0.13575723245739937
Trained batch 10 in epoch 4, gen_loss = 0.4281865520910783, disc_loss = 0.12924386899579654
Trained batch 11 in epoch 4, gen_loss = 0.4307745446761449, disc_loss = 0.12684264965355396
Trained batch 12 in epoch 4, gen_loss = 0.4271221458911896, disc_loss = 0.12016418891457412
Trained batch 13 in epoch 4, gen_loss = 0.42435306097779957, disc_loss = 0.11744287264134202
Trained batch 14 in epoch 4, gen_loss = 0.4250373284022013, disc_loss = 0.11522652780016264
Trained batch 15 in epoch 4, gen_loss = 0.424435755237937, disc_loss = 0.11174439545720816
Trained batch 16 in epoch 4, gen_loss = 0.42573754927691293, disc_loss = 0.1127142599400352
Trained batch 17 in epoch 4, gen_loss = 0.42646154595745933, disc_loss = 0.12117416742775175
Trained batch 18 in epoch 4, gen_loss = 0.42792521652422455, disc_loss = 0.1289579860473934
Trained batch 19 in epoch 4, gen_loss = 0.4262507393956184, disc_loss = 0.13009016290307046
Trained batch 20 in epoch 4, gen_loss = 0.42215231912476675, disc_loss = 0.12854761523859842
Trained batch 21 in epoch 4, gen_loss = 0.42207457667047327, disc_loss = 0.12646541609005493
Trained batch 22 in epoch 4, gen_loss = 0.4209211598271909, disc_loss = 0.12559227256671243
Trained batch 23 in epoch 4, gen_loss = 0.42400964473684627, disc_loss = 0.12454282026737928
Trained batch 24 in epoch 4, gen_loss = 0.4207939696311951, disc_loss = 0.12745695263147355
Trained batch 25 in epoch 4, gen_loss = 0.4185321159087695, disc_loss = 0.12716815649316862
Trained batch 26 in epoch 4, gen_loss = 0.41784276013021115, disc_loss = 0.13418567263417774
Trained batch 27 in epoch 4, gen_loss = 0.4173182834471975, disc_loss = 0.1366757114550897
Trained batch 28 in epoch 4, gen_loss = 0.41579003272385434, disc_loss = 0.13899219318710523
Trained batch 29 in epoch 4, gen_loss = 0.4161172598600388, disc_loss = 0.13986236726244292
Trained batch 30 in epoch 4, gen_loss = 0.4166182510314449, disc_loss = 0.1400104782754375
Trained batch 31 in epoch 4, gen_loss = 0.41757631953805685, disc_loss = 0.14052599971182644
Trained batch 32 in epoch 4, gen_loss = 0.41764127937230194, disc_loss = 0.14007546255985895
Trained batch 33 in epoch 4, gen_loss = 0.4163958929917392, disc_loss = 0.13996772270868807
Trained batch 34 in epoch 4, gen_loss = 0.41556218862533567, disc_loss = 0.13958496004343032
Trained batch 35 in epoch 4, gen_loss = 0.41463151739703286, disc_loss = 0.13998131764431795
Trained batch 36 in epoch 4, gen_loss = 0.41425675878653656, disc_loss = 0.14191106384670413
Trained batch 37 in epoch 4, gen_loss = 0.4113462183036302, disc_loss = 0.1415764769833339
Trained batch 38 in epoch 4, gen_loss = 0.41096263589003146, disc_loss = 0.14087681300365007
Trained batch 39 in epoch 4, gen_loss = 0.41179993078112603, disc_loss = 0.14118514787405728
Trained batch 40 in epoch 4, gen_loss = 0.41075417980915163, disc_loss = 0.1407003202816335
Trained batch 41 in epoch 4, gen_loss = 0.41076618291082834, disc_loss = 0.13879899068602494
Trained batch 42 in epoch 4, gen_loss = 0.41138929752416387, disc_loss = 0.137957185420186
Trained batch 43 in epoch 4, gen_loss = 0.4101680679754777, disc_loss = 0.13606864815069872
Trained batch 44 in epoch 4, gen_loss = 0.4089807795153724, disc_loss = 0.13680813734730085
Trained batch 45 in epoch 4, gen_loss = 0.41015745116316754, disc_loss = 0.1357760639132365
Trained batch 46 in epoch 4, gen_loss = 0.41136672141704156, disc_loss = 0.13349068473945272
Trained batch 47 in epoch 4, gen_loss = 0.4113967039932807, disc_loss = 0.1319530518570294
Trained batch 48 in epoch 4, gen_loss = 0.4139180724718133, disc_loss = 0.13143868402254824
Trained batch 49 in epoch 4, gen_loss = 0.4125408142805099, disc_loss = 0.13443302862346174
Trained batch 50 in epoch 4, gen_loss = 0.41399773312549965, disc_loss = 0.1351253494766413
Trained batch 51 in epoch 4, gen_loss = 0.4139127553655551, disc_loss = 0.13566615740553692
Trained batch 52 in epoch 4, gen_loss = 0.41449985920258287, disc_loss = 0.1367650053832891
Trained batch 53 in epoch 4, gen_loss = 0.41434878993917396, disc_loss = 0.13680248562660483
Trained batch 54 in epoch 4, gen_loss = 0.41510641249743374, disc_loss = 0.13591280789537863
Trained batch 55 in epoch 4, gen_loss = 0.4146770755095141, disc_loss = 0.13456167859424437
Trained batch 56 in epoch 4, gen_loss = 0.4141905245028044, disc_loss = 0.13357429513544367
Trained batch 57 in epoch 4, gen_loss = 0.41412212160126916, disc_loss = 0.13295482773462247
Trained batch 58 in epoch 4, gen_loss = 0.4151200732942355, disc_loss = 0.13182442389049773
Trained batch 59 in epoch 4, gen_loss = 0.4162197137872378, disc_loss = 0.13024163525551558
Trained batch 60 in epoch 4, gen_loss = 0.4156894205046482, disc_loss = 0.12928317652129737
Trained batch 61 in epoch 4, gen_loss = 0.4163269059311959, disc_loss = 0.12734579586333805
Trained batch 62 in epoch 4, gen_loss = 0.41583626563586884, disc_loss = 0.1265218946491442
Trained batch 63 in epoch 4, gen_loss = 0.41634943149983883, disc_loss = 0.1265058534045238
Trained batch 64 in epoch 4, gen_loss = 0.4159482254431798, disc_loss = 0.12552033791748377
Trained batch 65 in epoch 4, gen_loss = 0.4155821931181532, disc_loss = 0.1256853056732904
Trained batch 66 in epoch 4, gen_loss = 0.4159100718462645, disc_loss = 0.13118853489520835
Trained batch 67 in epoch 4, gen_loss = 0.41579807944157543, disc_loss = 0.1305459381957703
Trained batch 68 in epoch 4, gen_loss = 0.41669844155726227, disc_loss = 0.1316954069433437
Trained batch 69 in epoch 4, gen_loss = 0.4165417786155428, disc_loss = 0.13236911459160702
Trained batch 70 in epoch 4, gen_loss = 0.4155892272230605, disc_loss = 0.1322619995023583
Trained batch 71 in epoch 4, gen_loss = 0.4157900557749801, disc_loss = 0.13254950736235413
Trained batch 72 in epoch 4, gen_loss = 0.41554323206209154, disc_loss = 0.13210689952622537
Trained batch 73 in epoch 4, gen_loss = 0.4147810501021308, disc_loss = 0.1309941623712311
Trained batch 74 in epoch 4, gen_loss = 0.4139805428187052, disc_loss = 0.1302414821833372
Trained batch 75 in epoch 4, gen_loss = 0.41402429734405716, disc_loss = 0.1305315105587636
Trained batch 76 in epoch 4, gen_loss = 0.4139947852531037, disc_loss = 0.12958241672581666
Trained batch 77 in epoch 4, gen_loss = 0.41362021710628116, disc_loss = 0.13092304997814772
Trained batch 78 in epoch 4, gen_loss = 0.4144418382946449, disc_loss = 0.13101786660336995
Trained batch 79 in epoch 4, gen_loss = 0.41486537605524065, disc_loss = 0.13051350901369005
Trained batch 80 in epoch 4, gen_loss = 0.4140984702993322, disc_loss = 0.13044710422831554
Trained batch 81 in epoch 4, gen_loss = 0.4138325358309397, disc_loss = 0.12972424908473
Trained batch 82 in epoch 4, gen_loss = 0.41370494214885206, disc_loss = 0.13011731137802085
Trained batch 83 in epoch 4, gen_loss = 0.41344471133890603, disc_loss = 0.13029140750655815
Trained batch 84 in epoch 4, gen_loss = 0.41392487918629367, disc_loss = 0.1309619935338988
Trained batch 85 in epoch 4, gen_loss = 0.41389207853827364, disc_loss = 0.13112191303611495
Trained batch 86 in epoch 4, gen_loss = 0.4142365736522894, disc_loss = 0.1313311567465807
Trained batch 87 in epoch 4, gen_loss = 0.4136157045987519, disc_loss = 0.1321293962484395
Trained batch 88 in epoch 4, gen_loss = 0.41449885053581065, disc_loss = 0.1317336813996682
Trained batch 89 in epoch 4, gen_loss = 0.4150372819768058, disc_loss = 0.13115834206756619
Trained batch 90 in epoch 4, gen_loss = 0.41513827737871106, disc_loss = 0.13103152805386664
Trained batch 91 in epoch 4, gen_loss = 0.4145943451186885, disc_loss = 0.13060910345824517
Trained batch 92 in epoch 4, gen_loss = 0.4142517832017714, disc_loss = 0.13016256411629978
Trained batch 93 in epoch 4, gen_loss = 0.414506196975708, disc_loss = 0.12955100487600615
Trained batch 94 in epoch 4, gen_loss = 0.4146005006212937, disc_loss = 0.12844189156435037
Trained batch 95 in epoch 4, gen_loss = 0.41460007273902494, disc_loss = 0.12950180674670264
Trained batch 96 in epoch 4, gen_loss = 0.41543917158215315, disc_loss = 0.13105864701888612
Trained batch 97 in epoch 4, gen_loss = 0.41504875068761865, disc_loss = 0.13037316229346455
Trained batch 98 in epoch 4, gen_loss = 0.414779250669961, disc_loss = 0.1304438328088233
Trained batch 99 in epoch 4, gen_loss = 0.41456860929727557, disc_loss = 0.13034790219739079
Trained batch 100 in epoch 4, gen_loss = 0.4153349520546375, disc_loss = 0.13087149084278263
Trained batch 101 in epoch 4, gen_loss = 0.4149680871005152, disc_loss = 0.1306658897950661
Trained batch 102 in epoch 4, gen_loss = 0.41481702912201, disc_loss = 0.1304512385061933
Trained batch 103 in epoch 4, gen_loss = 0.41482685363063443, disc_loss = 0.13040508080918628
Trained batch 104 in epoch 4, gen_loss = 0.4146843362422217, disc_loss = 0.1301839517163379
Trained batch 105 in epoch 4, gen_loss = 0.41484264888853395, disc_loss = 0.12960410450216173
Trained batch 106 in epoch 4, gen_loss = 0.4152474684692989, disc_loss = 0.12961962799950738
Trained batch 107 in epoch 4, gen_loss = 0.4150293193481587, disc_loss = 0.12924841565459413
Trained batch 108 in epoch 4, gen_loss = 0.4146049132040881, disc_loss = 0.12847222751775467
Trained batch 109 in epoch 4, gen_loss = 0.41443559364839033, disc_loss = 0.12844111223451116
Trained batch 110 in epoch 4, gen_loss = 0.4154260346481392, disc_loss = 0.12861352965974057
Trained batch 111 in epoch 4, gen_loss = 0.41580616123974323, disc_loss = 0.1278412566420489
Trained batch 112 in epoch 4, gen_loss = 0.4148981302185396, disc_loss = 0.12832009668700992
Trained batch 113 in epoch 4, gen_loss = 0.41521887324358286, disc_loss = 0.1284836477910479
Trained batch 114 in epoch 4, gen_loss = 0.4153355844642805, disc_loss = 0.12841509523922984
Trained batch 115 in epoch 4, gen_loss = 0.41533330519651546, disc_loss = 0.12800799356773496
Trained batch 116 in epoch 4, gen_loss = 0.4154308407734602, disc_loss = 0.1279485195907008
Trained batch 117 in epoch 4, gen_loss = 0.4155131767866975, disc_loss = 0.12851079371836732
Trained batch 118 in epoch 4, gen_loss = 0.4156738549721341, disc_loss = 0.12897910548671454
Trained batch 119 in epoch 4, gen_loss = 0.41551973049839336, disc_loss = 0.12915767153414587
Trained batch 120 in epoch 4, gen_loss = 0.41535741952825184, disc_loss = 0.13015806399408944
Trained batch 121 in epoch 4, gen_loss = 0.41481923983722435, disc_loss = 0.13018638330710228
Trained batch 122 in epoch 4, gen_loss = 0.4145197502481259, disc_loss = 0.129786698329376
Trained batch 123 in epoch 4, gen_loss = 0.41415099847701287, disc_loss = 0.12934501338449697
Trained batch 124 in epoch 4, gen_loss = 0.41371129727363587, disc_loss = 0.12917662574350833
Trained batch 125 in epoch 4, gen_loss = 0.4133662075277359, disc_loss = 0.12910453131097177
Trained batch 126 in epoch 4, gen_loss = 0.4145426689170477, disc_loss = 0.12965677228323588
Trained batch 127 in epoch 4, gen_loss = 0.4147576887626201, disc_loss = 0.12900711841939483
Trained batch 128 in epoch 4, gen_loss = 0.41431795557339984, disc_loss = 0.1294694510685612
Trained batch 129 in epoch 4, gen_loss = 0.4141259083381066, disc_loss = 0.12924742757414395
Trained batch 130 in epoch 4, gen_loss = 0.4137875471861308, disc_loss = 0.12915920598418204
Trained batch 131 in epoch 4, gen_loss = 0.41401344153917197, disc_loss = 0.12869710945100946
Trained batch 132 in epoch 4, gen_loss = 0.4140644582142507, disc_loss = 0.1289496733982088
Trained batch 133 in epoch 4, gen_loss = 0.4138430245776675, disc_loss = 0.12859947096778832
Trained batch 134 in epoch 4, gen_loss = 0.4136360088984172, disc_loss = 0.12874156000713508
Trained batch 135 in epoch 4, gen_loss = 0.4136456145959742, disc_loss = 0.1288566279964631
Trained batch 136 in epoch 4, gen_loss = 0.4135959616107662, disc_loss = 0.12845432585662733
Trained batch 137 in epoch 4, gen_loss = 0.41391355339167774, disc_loss = 0.12811729151323653
Trained batch 138 in epoch 4, gen_loss = 0.414107271450029, disc_loss = 0.12774857783542692
Trained batch 139 in epoch 4, gen_loss = 0.4137336818235261, disc_loss = 0.1272458141536585
Trained batch 140 in epoch 4, gen_loss = 0.41372116596986214, disc_loss = 0.12690136244797962
Trained batch 141 in epoch 4, gen_loss = 0.4138337184845562, disc_loss = 0.12737641059859117
Trained batch 142 in epoch 4, gen_loss = 0.41386166610917846, disc_loss = 0.12876318328707784
Trained batch 143 in epoch 4, gen_loss = 0.4139369219127629, disc_loss = 0.12893773031990147
Trained batch 144 in epoch 4, gen_loss = 0.4137910168746422, disc_loss = 0.1296218301330147
Trained batch 145 in epoch 4, gen_loss = 0.4138287342574498, disc_loss = 0.129431545696132
Trained batch 146 in epoch 4, gen_loss = 0.4137771210702909, disc_loss = 0.12918483310055975
Trained batch 147 in epoch 4, gen_loss = 0.41361342672560664, disc_loss = 0.12909231280807304
Trained batch 148 in epoch 4, gen_loss = 0.41378895968398793, disc_loss = 0.12842021439999543
Trained batch 149 in epoch 4, gen_loss = 0.4133452808856964, disc_loss = 0.12828733218212923
Trained batch 150 in epoch 4, gen_loss = 0.4132105139707098, disc_loss = 0.128041394622318
Trained batch 151 in epoch 4, gen_loss = 0.4132865596758692, disc_loss = 0.12769922925355404
Trained batch 152 in epoch 4, gen_loss = 0.41348865004925944, disc_loss = 0.12763775609969313
Trained batch 153 in epoch 4, gen_loss = 0.41306994603825853, disc_loss = 0.12736163160146832
Trained batch 154 in epoch 4, gen_loss = 0.41271225214004514, disc_loss = 0.12741527045446058
Trained batch 155 in epoch 4, gen_loss = 0.41242393373678893, disc_loss = 0.12797983943556362
Trained batch 156 in epoch 4, gen_loss = 0.4127396470422198, disc_loss = 0.12883945120273121
Trained batch 157 in epoch 4, gen_loss = 0.41272347561920747, disc_loss = 0.12893635786692553
Trained batch 158 in epoch 4, gen_loss = 0.41262673244536296, disc_loss = 0.13003902837821524
Trained batch 159 in epoch 4, gen_loss = 0.41264915410429237, disc_loss = 0.13005842703860254
Trained batch 160 in epoch 4, gen_loss = 0.41260181987507744, disc_loss = 0.130299486428129
Trained batch 161 in epoch 4, gen_loss = 0.4127776424090068, disc_loss = 0.13057111661283322
Trained batch 162 in epoch 4, gen_loss = 0.4123738400775231, disc_loss = 0.13024510422641514
Trained batch 163 in epoch 4, gen_loss = 0.41224374331352187, disc_loss = 0.13068441417431687
Trained batch 164 in epoch 4, gen_loss = 0.41201598246892296, disc_loss = 0.1305664239733508
Trained batch 165 in epoch 4, gen_loss = 0.4119438157383218, disc_loss = 0.13061002410768743
Trained batch 166 in epoch 4, gen_loss = 0.41170469800869147, disc_loss = 0.13057684945221432
Trained batch 167 in epoch 4, gen_loss = 0.4118824688096841, disc_loss = 0.1306054359967155
Trained batch 168 in epoch 4, gen_loss = 0.4112595884052254, disc_loss = 0.13081251942282598
Trained batch 169 in epoch 4, gen_loss = 0.41081887869273914, disc_loss = 0.13048660989631625
Trained batch 170 in epoch 4, gen_loss = 0.4106837538947836, disc_loss = 0.130229427865897
Trained batch 171 in epoch 4, gen_loss = 0.4108612795555314, disc_loss = 0.13032658993764673
Trained batch 172 in epoch 4, gen_loss = 0.4106769794329053, disc_loss = 0.13023099051303946
Trained batch 173 in epoch 4, gen_loss = 0.4105761448542277, disc_loss = 0.1302419164185894
Trained batch 174 in epoch 4, gen_loss = 0.41034841758864266, disc_loss = 0.1297557185803141
Trained batch 175 in epoch 4, gen_loss = 0.41039290075952356, disc_loss = 0.129318366038867
Trained batch 176 in epoch 4, gen_loss = 0.41046668294459415, disc_loss = 0.1288615156196605
Trained batch 177 in epoch 4, gen_loss = 0.4102193522319365, disc_loss = 0.1287304913060049
Trained batch 178 in epoch 4, gen_loss = 0.41101736762670166, disc_loss = 0.12867587059736252
Trained batch 179 in epoch 4, gen_loss = 0.4110118438800176, disc_loss = 0.12815773280130494
Trained batch 180 in epoch 4, gen_loss = 0.4103801762530817, disc_loss = 0.12791298864954742
Trained batch 181 in epoch 4, gen_loss = 0.41048701336750615, disc_loss = 0.12808159124720228
Trained batch 182 in epoch 4, gen_loss = 0.4102235617207699, disc_loss = 0.12897140764799275
Trained batch 183 in epoch 4, gen_loss = 0.4107144372942655, disc_loss = 0.13035343635989272
Trained batch 184 in epoch 4, gen_loss = 0.4108168695424054, disc_loss = 0.13026641893225746
Trained batch 185 in epoch 4, gen_loss = 0.4103334568521028, disc_loss = 0.1303277423064555
Trained batch 186 in epoch 4, gen_loss = 0.4104971170106674, disc_loss = 0.1302095940485995
Trained batch 187 in epoch 4, gen_loss = 0.41059719929669763, disc_loss = 0.1301562612915927
Trained batch 188 in epoch 4, gen_loss = 0.41089943382475114, disc_loss = 0.12972404993085004
Trained batch 189 in epoch 4, gen_loss = 0.4108710687411459, disc_loss = 0.12955796632327532
Trained batch 190 in epoch 4, gen_loss = 0.41087043691055936, disc_loss = 0.12960964784572263
Trained batch 191 in epoch 4, gen_loss = 0.41071878047659993, disc_loss = 0.12966305498654643
Trained batch 192 in epoch 4, gen_loss = 0.4108491683562185, disc_loss = 0.1295281718509185
Trained batch 193 in epoch 4, gen_loss = 0.4107368585375166, disc_loss = 0.12941239731981583
Trained batch 194 in epoch 4, gen_loss = 0.41104492682677046, disc_loss = 0.12916117215003722
Trained batch 195 in epoch 4, gen_loss = 0.4108889802378051, disc_loss = 0.12905828130184388
Trained batch 196 in epoch 4, gen_loss = 0.4107876392790509, disc_loss = 0.1292376948643457
Trained batch 197 in epoch 4, gen_loss = 0.41065988877807, disc_loss = 0.1292200085490641
Trained batch 198 in epoch 4, gen_loss = 0.41075232250606597, disc_loss = 0.1292858745285015
Trained batch 199 in epoch 4, gen_loss = 0.4107255561649799, disc_loss = 0.1289460255205631
Trained batch 200 in epoch 4, gen_loss = 0.41074438133643043, disc_loss = 0.12897709449428824
Trained batch 201 in epoch 4, gen_loss = 0.4108457734974304, disc_loss = 0.12918612980606534
Trained batch 202 in epoch 4, gen_loss = 0.41063438260496543, disc_loss = 0.12909394190669646
Trained batch 203 in epoch 4, gen_loss = 0.41073861718177795, disc_loss = 0.12881581379356338
Trained batch 204 in epoch 4, gen_loss = 0.41048205000598254, disc_loss = 0.128725338999818
Trained batch 205 in epoch 4, gen_loss = 0.41039627414305235, disc_loss = 0.12842181672170325
Trained batch 206 in epoch 4, gen_loss = 0.4101729459232754, disc_loss = 0.12833407891977236
Trained batch 207 in epoch 4, gen_loss = 0.4102386294935758, disc_loss = 0.1283397267286021
Trained batch 208 in epoch 4, gen_loss = 0.41030061658489647, disc_loss = 0.12830372208185745
Trained batch 209 in epoch 4, gen_loss = 0.41032999186288743, disc_loss = 0.12812044808552378
Trained batch 210 in epoch 4, gen_loss = 0.4100387159964485, disc_loss = 0.12816766818976516
Trained batch 211 in epoch 4, gen_loss = 0.4099769100265683, disc_loss = 0.12790592397861886
Trained batch 212 in epoch 4, gen_loss = 0.4099541415630932, disc_loss = 0.1274575128136946
Trained batch 213 in epoch 4, gen_loss = 0.40978052933639453, disc_loss = 0.12732295241102437
Trained batch 214 in epoch 4, gen_loss = 0.40961123344510103, disc_loss = 0.1270405679767908
Trained batch 215 in epoch 4, gen_loss = 0.4097883192201455, disc_loss = 0.12685649136633234
Trained batch 216 in epoch 4, gen_loss = 0.40978956936691213, disc_loss = 0.1269568961439869
Trained batch 217 in epoch 4, gen_loss = 0.4097275578100747, disc_loss = 0.12672574659211372
Trained batch 218 in epoch 4, gen_loss = 0.40965300743982674, disc_loss = 0.12661340518016792
Trained batch 219 in epoch 4, gen_loss = 0.4095164713534442, disc_loss = 0.12643861535259268
Trained batch 220 in epoch 4, gen_loss = 0.4094880111346957, disc_loss = 0.1262621940766794
Trained batch 221 in epoch 4, gen_loss = 0.40998248782780794, disc_loss = 0.12631947250180953
Trained batch 222 in epoch 4, gen_loss = 0.41012252780354075, disc_loss = 0.12640739982371374
Trained batch 223 in epoch 4, gen_loss = 0.4102805971301028, disc_loss = 0.1264227317213746
Trained batch 224 in epoch 4, gen_loss = 0.41109154237641227, disc_loss = 0.12801910570926137
Trained batch 225 in epoch 4, gen_loss = 0.4108877932339643, disc_loss = 0.12994529489856377
Trained batch 226 in epoch 4, gen_loss = 0.4107264998463282, disc_loss = 0.13022266661477508
Trained batch 227 in epoch 4, gen_loss = 0.4105688008038621, disc_loss = 0.13105620337617502
Trained batch 228 in epoch 4, gen_loss = 0.4106229174085059, disc_loss = 0.13220246830816873
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.39837855100631714, disc_loss = 0.3147137761116028
Trained batch 1 in epoch 5, gen_loss = 0.4481499195098877, disc_loss = 0.24361468106508255
Trained batch 2 in epoch 5, gen_loss = 0.414126992225647, disc_loss = 0.21906963984171549
Trained batch 3 in epoch 5, gen_loss = 0.4231239855289459, disc_loss = 0.1851956583559513
Trained batch 4 in epoch 5, gen_loss = 0.42431685924530027, disc_loss = 0.15884854048490524
Trained batch 5 in epoch 5, gen_loss = 0.4227864593267441, disc_loss = 0.13988245837390423
Trained batch 6 in epoch 5, gen_loss = 0.4166337719985417, disc_loss = 0.14261292187230928
Trained batch 7 in epoch 5, gen_loss = 0.40660419315099716, disc_loss = 0.13561339350417256
Trained batch 8 in epoch 5, gen_loss = 0.4131320052676731, disc_loss = 0.1356233892341455
Trained batch 9 in epoch 5, gen_loss = 0.4182699918746948, disc_loss = 0.1271312240511179
Trained batch 10 in epoch 5, gen_loss = 0.41037831523201684, disc_loss = 0.12572686949914152
Trained batch 11 in epoch 5, gen_loss = 0.4081111550331116, disc_loss = 0.12370952870696783
Trained batch 12 in epoch 5, gen_loss = 0.41545819777708787, disc_loss = 0.12350757334094781
Trained batch 13 in epoch 5, gen_loss = 0.40907034277915955, disc_loss = 0.12583115084895066
Trained batch 14 in epoch 5, gen_loss = 0.40968377590179444, disc_loss = 0.12785914465785025
Trained batch 15 in epoch 5, gen_loss = 0.41507767140865326, disc_loss = 0.13009595521725714
Trained batch 16 in epoch 5, gen_loss = 0.41548845873159523, disc_loss = 0.12561022950445905
Trained batch 17 in epoch 5, gen_loss = 0.4167129513290193, disc_loss = 0.12001685094502237
Trained batch 18 in epoch 5, gen_loss = 0.4143420442154533, disc_loss = 0.1210690944602615
Trained batch 19 in epoch 5, gen_loss = 0.41590668708086015, disc_loss = 0.11910861879587173
Trained batch 20 in epoch 5, gen_loss = 0.4158532434985751, disc_loss = 0.11716464126393908
Trained batch 21 in epoch 5, gen_loss = 0.4187884019179778, disc_loss = 0.11386763998730616
Trained batch 22 in epoch 5, gen_loss = 0.41814342270726745, disc_loss = 0.11220566653039145
Trained batch 23 in epoch 5, gen_loss = 0.424301544825236, disc_loss = 0.11095133377239108
Trained batch 24 in epoch 5, gen_loss = 0.4236164975166321, disc_loss = 0.10882436707615853
Trained batch 25 in epoch 5, gen_loss = 0.4219763783308176, disc_loss = 0.10850257927981707
Trained batch 26 in epoch 5, gen_loss = 0.4224009237907551, disc_loss = 0.11166439936668784
Trained batch 27 in epoch 5, gen_loss = 0.4254178223865373, disc_loss = 0.10833074019423553
Trained batch 28 in epoch 5, gen_loss = 0.42254053107623396, disc_loss = 0.10922026146074822
Trained batch 29 in epoch 5, gen_loss = 0.4225072751442591, disc_loss = 0.1071567140519619
Trained batch 30 in epoch 5, gen_loss = 0.4216349672886633, disc_loss = 0.10970698417194429
Trained batch 31 in epoch 5, gen_loss = 0.42150012496858835, disc_loss = 0.11488042469136417
Trained batch 32 in epoch 5, gen_loss = 0.42235099817767285, disc_loss = 0.11347380145029588
Trained batch 33 in epoch 5, gen_loss = 0.42229189679903145, disc_loss = 0.11381643616101321
Trained batch 34 in epoch 5, gen_loss = 0.4219192930630275, disc_loss = 0.11600817739963531
Trained batch 35 in epoch 5, gen_loss = 0.42133428570297027, disc_loss = 0.11782185733318329
Trained batch 36 in epoch 5, gen_loss = 0.4218755388582075, disc_loss = 0.1183886459550342
Trained batch 37 in epoch 5, gen_loss = 0.4229793540741268, disc_loss = 0.11971187552339152
Trained batch 38 in epoch 5, gen_loss = 0.4231698826337472, disc_loss = 0.12014965980480878
Trained batch 39 in epoch 5, gen_loss = 0.42201580181717874, disc_loss = 0.12041056156158447
Trained batch 40 in epoch 5, gen_loss = 0.42295425039965934, disc_loss = 0.11850618925399897
Trained batch 41 in epoch 5, gen_loss = 0.42116566711948034, disc_loss = 0.11803964676246756
Trained batch 42 in epoch 5, gen_loss = 0.42154035595960393, disc_loss = 0.11825636661676474
Trained batch 43 in epoch 5, gen_loss = 0.4204136228019541, disc_loss = 0.11889424318955703
Trained batch 44 in epoch 5, gen_loss = 0.4201428837246365, disc_loss = 0.11854516259498066
Trained batch 45 in epoch 5, gen_loss = 0.422058008287264, disc_loss = 0.1190401836419883
Trained batch 46 in epoch 5, gen_loss = 0.4222227176453205, disc_loss = 0.11846788124518191
Trained batch 47 in epoch 5, gen_loss = 0.42208503372967243, disc_loss = 0.11799035741326709
Trained batch 48 in epoch 5, gen_loss = 0.4205971998827798, disc_loss = 0.11923009757788813
Trained batch 49 in epoch 5, gen_loss = 0.41915989339351656, disc_loss = 0.11976121060550213
Trained batch 50 in epoch 5, gen_loss = 0.4184607150507908, disc_loss = 0.11957557594367102
Trained batch 51 in epoch 5, gen_loss = 0.4182710905487721, disc_loss = 0.11910460008165011
Trained batch 52 in epoch 5, gen_loss = 0.41715688188121003, disc_loss = 0.1193125456712156
Trained batch 53 in epoch 5, gen_loss = 0.4163307232989205, disc_loss = 0.11997440188295311
Trained batch 54 in epoch 5, gen_loss = 0.41554933461275967, disc_loss = 0.12069633393125101
Trained batch 55 in epoch 5, gen_loss = 0.4169406528983797, disc_loss = 0.1191390655003488
Trained batch 56 in epoch 5, gen_loss = 0.416444950982144, disc_loss = 0.11855613590593923
Trained batch 57 in epoch 5, gen_loss = 0.4172268278639892, disc_loss = 0.11758951116995565
Trained batch 58 in epoch 5, gen_loss = 0.41635601702383007, disc_loss = 0.11796638868370299
Trained batch 59 in epoch 5, gen_loss = 0.41686450839042666, disc_loss = 0.12015918213874102
Trained batch 60 in epoch 5, gen_loss = 0.4169801600643846, disc_loss = 0.12055025353539185
Trained batch 61 in epoch 5, gen_loss = 0.41614113219322696, disc_loss = 0.1203543656175175
Trained batch 62 in epoch 5, gen_loss = 0.4163590830469888, disc_loss = 0.12060846902784847
Trained batch 63 in epoch 5, gen_loss = 0.4166009435430169, disc_loss = 0.11975373135646805
Trained batch 64 in epoch 5, gen_loss = 0.41638642641214224, disc_loss = 0.12017340906537496
Trained batch 65 in epoch 5, gen_loss = 0.416319596044945, disc_loss = 0.12019253482647015
Trained batch 66 in epoch 5, gen_loss = 0.4169531491265368, disc_loss = 0.11903805602619898
Trained batch 67 in epoch 5, gen_loss = 0.4157191922559458, disc_loss = 0.11912205656442572
Trained batch 68 in epoch 5, gen_loss = 0.4162447625312252, disc_loss = 0.1200611556245797
Trained batch 69 in epoch 5, gen_loss = 0.4161178018365588, disc_loss = 0.12350100656705243
Trained batch 70 in epoch 5, gen_loss = 0.4158354359613338, disc_loss = 0.12334881560273574
Trained batch 71 in epoch 5, gen_loss = 0.41654154823886025, disc_loss = 0.123294186209225
Trained batch 72 in epoch 5, gen_loss = 0.41542362554432594, disc_loss = 0.12366646074064791
Trained batch 73 in epoch 5, gen_loss = 0.414957675982166, disc_loss = 0.12295666513209408
Trained batch 74 in epoch 5, gen_loss = 0.4147461120287577, disc_loss = 0.12456796899437904
Trained batch 75 in epoch 5, gen_loss = 0.4142425138699381, disc_loss = 0.12492225549526904
Trained batch 76 in epoch 5, gen_loss = 0.41414138558623076, disc_loss = 0.12360520544764284
Trained batch 77 in epoch 5, gen_loss = 0.4136476104076092, disc_loss = 0.12302635581447528
Trained batch 78 in epoch 5, gen_loss = 0.41365518864197065, disc_loss = 0.12193253414728973
Trained batch 79 in epoch 5, gen_loss = 0.41404635794460776, disc_loss = 0.12129384917207062
Trained batch 80 in epoch 5, gen_loss = 0.4142352909217646, disc_loss = 0.12075534393941914
Trained batch 81 in epoch 5, gen_loss = 0.4140432382502207, disc_loss = 0.12007271330349328
Trained batch 82 in epoch 5, gen_loss = 0.41338665119136675, disc_loss = 0.1201850064098835
Trained batch 83 in epoch 5, gen_loss = 0.4129920169001534, disc_loss = 0.1200491279984514
Trained batch 84 in epoch 5, gen_loss = 0.4136562431559843, disc_loss = 0.12019267007708549
Trained batch 85 in epoch 5, gen_loss = 0.41407432528429255, disc_loss = 0.1201583537338085
Trained batch 86 in epoch 5, gen_loss = 0.41418700999227065, disc_loss = 0.12063490166917615
Trained batch 87 in epoch 5, gen_loss = 0.4149306274273179, disc_loss = 0.12209072002125057
Trained batch 88 in epoch 5, gen_loss = 0.41520636738016364, disc_loss = 0.12146086434132597
Trained batch 89 in epoch 5, gen_loss = 0.4161042782995436, disc_loss = 0.12111573148932722
Trained batch 90 in epoch 5, gen_loss = 0.4158650017701663, disc_loss = 0.12071423384023237
Trained batch 91 in epoch 5, gen_loss = 0.41599375495444174, disc_loss = 0.12106725901527249
Trained batch 92 in epoch 5, gen_loss = 0.4152321408512772, disc_loss = 0.12084926821051105
Trained batch 93 in epoch 5, gen_loss = 0.4152136873057548, disc_loss = 0.12007699082506464
Trained batch 94 in epoch 5, gen_loss = 0.4148579732367867, disc_loss = 0.11950417357055765
Trained batch 95 in epoch 5, gen_loss = 0.414690926981469, disc_loss = 0.11987271447045107
Trained batch 96 in epoch 5, gen_loss = 0.4151202818167578, disc_loss = 0.12086784570794745
Trained batch 97 in epoch 5, gen_loss = 0.4144454318649915, disc_loss = 0.12266146475259139
Trained batch 98 in epoch 5, gen_loss = 0.41503753866812193, disc_loss = 0.12247142143020726
Trained batch 99 in epoch 5, gen_loss = 0.41477513253688814, disc_loss = 0.12211008690297603
Trained batch 100 in epoch 5, gen_loss = 0.4147946746042459, disc_loss = 0.1224056680751319
Trained batch 101 in epoch 5, gen_loss = 0.41432929973976285, disc_loss = 0.12283919086935473
Trained batch 102 in epoch 5, gen_loss = 0.4140755470516612, disc_loss = 0.12233337499562977
Trained batch 103 in epoch 5, gen_loss = 0.4136635893239425, disc_loss = 0.12227323178488475
Trained batch 104 in epoch 5, gen_loss = 0.4139757167725336, disc_loss = 0.1219423798578126
Trained batch 105 in epoch 5, gen_loss = 0.4139680381653444, disc_loss = 0.12187295653066545
Trained batch 106 in epoch 5, gen_loss = 0.4137319189922832, disc_loss = 0.12277876112227128
Trained batch 107 in epoch 5, gen_loss = 0.41404355179380486, disc_loss = 0.12270260271098879
Trained batch 108 in epoch 5, gen_loss = 0.41444301523199867, disc_loss = 0.122198582584158
Trained batch 109 in epoch 5, gen_loss = 0.41384007768197495, disc_loss = 0.12181678238240155
Trained batch 110 in epoch 5, gen_loss = 0.41365318201683665, disc_loss = 0.12147624549028035
Trained batch 111 in epoch 5, gen_loss = 0.41365494871778147, disc_loss = 0.12106028305632728
Trained batch 112 in epoch 5, gen_loss = 0.41445910851512335, disc_loss = 0.12095108034863936
Trained batch 113 in epoch 5, gen_loss = 0.41441395643510315, disc_loss = 0.12197407112832655
Trained batch 114 in epoch 5, gen_loss = 0.41460827329884403, disc_loss = 0.12224105324434198
Trained batch 115 in epoch 5, gen_loss = 0.4146547795369707, disc_loss = 0.12208421239308243
Trained batch 116 in epoch 5, gen_loss = 0.4144830795434805, disc_loss = 0.1216242613318639
Trained batch 117 in epoch 5, gen_loss = 0.4145429407135915, disc_loss = 0.12134069753652912
Trained batch 118 in epoch 5, gen_loss = 0.41416515071852866, disc_loss = 0.12065293126496948
Trained batch 119 in epoch 5, gen_loss = 0.41403919806083045, disc_loss = 0.12103119598080715
Trained batch 120 in epoch 5, gen_loss = 0.4143460168818797, disc_loss = 0.12054497853290937
Trained batch 121 in epoch 5, gen_loss = 0.41390629381429955, disc_loss = 0.12037988458989096
Trained batch 122 in epoch 5, gen_loss = 0.41417979636812596, disc_loss = 0.12058643718075947
Trained batch 123 in epoch 5, gen_loss = 0.4140218623703526, disc_loss = 0.12144150248458309
Trained batch 124 in epoch 5, gen_loss = 0.4137981605529785, disc_loss = 0.1211631731390953
Trained batch 125 in epoch 5, gen_loss = 0.4144828731105441, disc_loss = 0.12237988335509149
Trained batch 126 in epoch 5, gen_loss = 0.41431097979620685, disc_loss = 0.1231046799482323
Trained batch 127 in epoch 5, gen_loss = 0.41436170949600637, disc_loss = 0.12313493486726657
Trained batch 128 in epoch 5, gen_loss = 0.4145523039407508, disc_loss = 0.12313408635614455
Trained batch 129 in epoch 5, gen_loss = 0.41432347160119276, disc_loss = 0.12290724154848319
Trained batch 130 in epoch 5, gen_loss = 0.4140237283160668, disc_loss = 0.12272656413207528
Trained batch 131 in epoch 5, gen_loss = 0.4135248805537368, disc_loss = 0.12266116267578168
Trained batch 132 in epoch 5, gen_loss = 0.4133062768251376, disc_loss = 0.12261890967313509
Trained batch 133 in epoch 5, gen_loss = 0.4129526248173927, disc_loss = 0.12280440780876288
Trained batch 134 in epoch 5, gen_loss = 0.41239950943876197, disc_loss = 0.12267765375199141
Trained batch 135 in epoch 5, gen_loss = 0.41261068578152094, disc_loss = 0.12282697785207454
Trained batch 136 in epoch 5, gen_loss = 0.41234048265610296, disc_loss = 0.1222514756513338
Trained batch 137 in epoch 5, gen_loss = 0.41240098489367444, disc_loss = 0.12157393376464429
Trained batch 138 in epoch 5, gen_loss = 0.41210045488618263, disc_loss = 0.12427268279113358
Trained batch 139 in epoch 5, gen_loss = 0.41256285990987507, disc_loss = 0.12599028402141163
Trained batch 140 in epoch 5, gen_loss = 0.4122920440021136, disc_loss = 0.12588292360305786
Trained batch 141 in epoch 5, gen_loss = 0.412302498876209, disc_loss = 0.12585032794257284
Trained batch 142 in epoch 5, gen_loss = 0.4120520743039938, disc_loss = 0.12549808178539876
Trained batch 143 in epoch 5, gen_loss = 0.41178533455563915, disc_loss = 0.12529768396375907
Trained batch 144 in epoch 5, gen_loss = 0.41177672332730786, disc_loss = 0.12491783741219291
Trained batch 145 in epoch 5, gen_loss = 0.41143621504306793, disc_loss = 0.12491982016865522
Trained batch 146 in epoch 5, gen_loss = 0.41139938900259887, disc_loss = 0.1250593937477287
Trained batch 147 in epoch 5, gen_loss = 0.4116133231971715, disc_loss = 0.1251731405689104
Trained batch 148 in epoch 5, gen_loss = 0.4117023550824031, disc_loss = 0.1262951354752451
Trained batch 149 in epoch 5, gen_loss = 0.4117222438255946, disc_loss = 0.1259840238591035
Trained batch 150 in epoch 5, gen_loss = 0.4117063096422233, disc_loss = 0.1259471917191878
Trained batch 151 in epoch 5, gen_loss = 0.4115780531183669, disc_loss = 0.12547358390139907
Trained batch 152 in epoch 5, gen_loss = 0.4118852593929939, disc_loss = 0.12549729635512907
Trained batch 153 in epoch 5, gen_loss = 0.4113240185883138, disc_loss = 0.12614500958037067
Trained batch 154 in epoch 5, gen_loss = 0.4118714149921171, disc_loss = 0.12559568550317518
Trained batch 155 in epoch 5, gen_loss = 0.4118474672238032, disc_loss = 0.1260907504325494
Trained batch 156 in epoch 5, gen_loss = 0.4114986001306279, disc_loss = 0.12672500051320737
Trained batch 157 in epoch 5, gen_loss = 0.4117683819200419, disc_loss = 0.1264722390642649
Trained batch 158 in epoch 5, gen_loss = 0.4113554127936093, disc_loss = 0.12615042976425878
Trained batch 159 in epoch 5, gen_loss = 0.4110367387533188, disc_loss = 0.12625497351400555
Trained batch 160 in epoch 5, gen_loss = 0.4108275517543651, disc_loss = 0.12610395854304296
Trained batch 161 in epoch 5, gen_loss = 0.41121534745634336, disc_loss = 0.12583010376971446
Trained batch 162 in epoch 5, gen_loss = 0.4112439864983588, disc_loss = 0.12546158536263038
Trained batch 163 in epoch 5, gen_loss = 0.4108504832881253, disc_loss = 0.12659128341914677
Trained batch 164 in epoch 5, gen_loss = 0.4111672898133596, disc_loss = 0.1267465767083746
Trained batch 165 in epoch 5, gen_loss = 0.41132458595626326, disc_loss = 0.12714198406740843
Trained batch 166 in epoch 5, gen_loss = 0.4110394942903233, disc_loss = 0.12889679637319312
Trained batch 167 in epoch 5, gen_loss = 0.4111813317452158, disc_loss = 0.12865763020125173
Trained batch 168 in epoch 5, gen_loss = 0.41135621793876737, disc_loss = 0.1287096184650822
Trained batch 169 in epoch 5, gen_loss = 0.4116044589701821, disc_loss = 0.1288307130775031
Trained batch 170 in epoch 5, gen_loss = 0.4112265376668227, disc_loss = 0.12864602060868727
Trained batch 171 in epoch 5, gen_loss = 0.4107707787391751, disc_loss = 0.12863299930684788
Trained batch 172 in epoch 5, gen_loss = 0.41068079034028027, disc_loss = 0.1283781159819895
Trained batch 173 in epoch 5, gen_loss = 0.410510231194825, disc_loss = 0.12920746104470615
Trained batch 174 in epoch 5, gen_loss = 0.4103073227405548, disc_loss = 0.12909621004547392
Trained batch 175 in epoch 5, gen_loss = 0.4100869292901321, disc_loss = 0.12989249965175986
Trained batch 176 in epoch 5, gen_loss = 0.41016619168432417, disc_loss = 0.1294664797809838
Trained batch 177 in epoch 5, gen_loss = 0.4102485598473067, disc_loss = 0.12925159830725594
Trained batch 178 in epoch 5, gen_loss = 0.41060942844305626, disc_loss = 0.12875393667783816
Trained batch 179 in epoch 5, gen_loss = 0.4101744285888142, disc_loss = 0.12843416430470017
Trained batch 180 in epoch 5, gen_loss = 0.40984922285238023, disc_loss = 0.1284814247892377
Trained batch 181 in epoch 5, gen_loss = 0.4099611373065592, disc_loss = 0.1284718382284864
Trained batch 182 in epoch 5, gen_loss = 0.41004524595750486, disc_loss = 0.12796178751223075
Trained batch 183 in epoch 5, gen_loss = 0.40945969473408617, disc_loss = 0.12800109449207134
Trained batch 184 in epoch 5, gen_loss = 0.4092046270499358, disc_loss = 0.1278559059508749
Trained batch 185 in epoch 5, gen_loss = 0.40899325410525006, disc_loss = 0.12798813704441311
Trained batch 186 in epoch 5, gen_loss = 0.40899476616140357, disc_loss = 0.12779807456754108
Trained batch 187 in epoch 5, gen_loss = 0.40885658990195456, disc_loss = 0.12765856049558583
Trained batch 188 in epoch 5, gen_loss = 0.4091819589415555, disc_loss = 0.12740154735862264
Trained batch 189 in epoch 5, gen_loss = 0.4093176986041822, disc_loss = 0.12756834075246987
Trained batch 190 in epoch 5, gen_loss = 0.4097465744817444, disc_loss = 0.12714760976780148
Trained batch 191 in epoch 5, gen_loss = 0.40972514854123193, disc_loss = 0.12685541051905602
Trained batch 192 in epoch 5, gen_loss = 0.40951164892918085, disc_loss = 0.1269000064137686
Trained batch 193 in epoch 5, gen_loss = 0.40978290094542746, disc_loss = 0.12687161345918155
Trained batch 194 in epoch 5, gen_loss = 0.4098590205877255, disc_loss = 0.1265880836126132
Trained batch 195 in epoch 5, gen_loss = 0.4098004130076389, disc_loss = 0.12725233172579686
Trained batch 196 in epoch 5, gen_loss = 0.4102201879327067, disc_loss = 0.12685786558286793
Trained batch 197 in epoch 5, gen_loss = 0.41029244902158024, disc_loss = 0.12702831640990095
Trained batch 198 in epoch 5, gen_loss = 0.41014426632143147, disc_loss = 0.12678075484444748
Trained batch 199 in epoch 5, gen_loss = 0.4099265030026436, disc_loss = 0.12648357659578324
Trained batch 200 in epoch 5, gen_loss = 0.4100235196488414, disc_loss = 0.1262654671028479
Trained batch 201 in epoch 5, gen_loss = 0.41003127086280594, disc_loss = 0.12605778791821828
Trained batch 202 in epoch 5, gen_loss = 0.4097983634530617, disc_loss = 0.12587341614838304
Trained batch 203 in epoch 5, gen_loss = 0.4099481941438189, disc_loss = 0.12603868156963705
Trained batch 204 in epoch 5, gen_loss = 0.4100714501811237, disc_loss = 0.12601334714308018
Trained batch 205 in epoch 5, gen_loss = 0.4101379638158002, disc_loss = 0.12564884278091412
Trained batch 206 in epoch 5, gen_loss = 0.41022619489886336, disc_loss = 0.12612633529492623
Trained batch 207 in epoch 5, gen_loss = 0.41019643599597305, disc_loss = 0.12740016313126454
Trained batch 208 in epoch 5, gen_loss = 0.4102169983980188, disc_loss = 0.12783481259095042
Trained batch 209 in epoch 5, gen_loss = 0.4103153496980667, disc_loss = 0.12756415399767104
Trained batch 210 in epoch 5, gen_loss = 0.40998078225913204, disc_loss = 0.1276923600955032
Trained batch 211 in epoch 5, gen_loss = 0.4099183531021172, disc_loss = 0.12755307231871588
Trained batch 212 in epoch 5, gen_loss = 0.40999216051168846, disc_loss = 0.1277221570692152
Trained batch 213 in epoch 5, gen_loss = 0.4102063045323452, disc_loss = 0.12785757124145455
Trained batch 214 in epoch 5, gen_loss = 0.410315827020379, disc_loss = 0.12751679701167484
Trained batch 215 in epoch 5, gen_loss = 0.41031921696331763, disc_loss = 0.12743456768630831
Trained batch 216 in epoch 5, gen_loss = 0.4100674250708198, disc_loss = 0.12705723165367055
Trained batch 217 in epoch 5, gen_loss = 0.4100872163378864, disc_loss = 0.126747424705723
Trained batch 218 in epoch 5, gen_loss = 0.4102471397347646, disc_loss = 0.1267228102541133
Trained batch 219 in epoch 5, gen_loss = 0.4105043586004864, disc_loss = 0.1263781585815278
Trained batch 220 in epoch 5, gen_loss = 0.4106888063083407, disc_loss = 0.12599507560827075
Trained batch 221 in epoch 5, gen_loss = 0.41056693123804555, disc_loss = 0.12582464871911314
Trained batch 222 in epoch 5, gen_loss = 0.4104885867892894, disc_loss = 0.12555748534977704
Trained batch 223 in epoch 5, gen_loss = 0.4104808010160923, disc_loss = 0.12524162886464701
Trained batch 224 in epoch 5, gen_loss = 0.4106481864717272, disc_loss = 0.12550397894448703
Trained batch 225 in epoch 5, gen_loss = 0.4105621574990517, disc_loss = 0.1263463619305233
Trained batch 226 in epoch 5, gen_loss = 0.4107028834095085, disc_loss = 0.12614929487329749
Trained batch 227 in epoch 5, gen_loss = 0.4107951602914877, disc_loss = 0.1258274999757608
Trained batch 228 in epoch 5, gen_loss = 0.4106899410095798, disc_loss = 0.12562756058170285
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.36679738759994507, disc_loss = 0.10250656306743622
Trained batch 1 in epoch 6, gen_loss = 0.3686160445213318, disc_loss = 0.09254897013306618
Trained batch 2 in epoch 6, gen_loss = 0.38025981187820435, disc_loss = 0.13213111708561578
Trained batch 3 in epoch 6, gen_loss = 0.3893849551677704, disc_loss = 0.11192370485514402
Trained batch 4 in epoch 6, gen_loss = 0.38765600323677063, disc_loss = 0.09769715294241905
Trained batch 5 in epoch 6, gen_loss = 0.3874682237704595, disc_loss = 0.10271902320285638
Trained batch 6 in epoch 6, gen_loss = 0.38087684767586844, disc_loss = 0.10605102511388916
Trained batch 7 in epoch 6, gen_loss = 0.3864820599555969, disc_loss = 0.10572993801906705
Trained batch 8 in epoch 6, gen_loss = 0.3885473046037886, disc_loss = 0.11262548507915603
Trained batch 9 in epoch 6, gen_loss = 0.3870202124118805, disc_loss = 0.10972804687917233
Trained batch 10 in epoch 6, gen_loss = 0.38784429160031403, disc_loss = 0.10842614587057721
Trained batch 11 in epoch 6, gen_loss = 0.39064925412336987, disc_loss = 0.10313367564231157
Trained batch 12 in epoch 6, gen_loss = 0.3946157212440784, disc_loss = 0.10503411722870973
Trained batch 13 in epoch 6, gen_loss = 0.4046522613082613, disc_loss = 0.103171367464321
Trained batch 14 in epoch 6, gen_loss = 0.4104835251967112, disc_loss = 0.09801498427987099
Trained batch 15 in epoch 6, gen_loss = 0.40878303349018097, disc_loss = 0.09663332183845341
Trained batch 16 in epoch 6, gen_loss = 0.40704262256622314, disc_loss = 0.0986121658454923
Trained batch 17 in epoch 6, gen_loss = 0.40742145147588515, disc_loss = 0.09773605089220735
Trained batch 18 in epoch 6, gen_loss = 0.40808749198913574, disc_loss = 0.10597381172211547
Trained batch 19 in epoch 6, gen_loss = 0.40536086559295653, disc_loss = 0.10790772605687379
Trained batch 20 in epoch 6, gen_loss = 0.40493387551534743, disc_loss = 0.10567995852657727
Trained batch 21 in epoch 6, gen_loss = 0.4032320556315509, disc_loss = 0.10616648146374659
Trained batch 22 in epoch 6, gen_loss = 0.4039669503336367, disc_loss = 0.10431838991201442
Trained batch 23 in epoch 6, gen_loss = 0.40112663557132083, disc_loss = 0.10390690419202049
Trained batch 24 in epoch 6, gen_loss = 0.40129422783851626, disc_loss = 0.10446179822087288
Trained batch 25 in epoch 6, gen_loss = 0.3997607838649016, disc_loss = 0.10388379902220689
Trained batch 26 in epoch 6, gen_loss = 0.3984704779254066, disc_loss = 0.10534769531201434
Trained batch 27 in epoch 6, gen_loss = 0.4007806746023042, disc_loss = 0.10669302474707365
Trained batch 28 in epoch 6, gen_loss = 0.4016529444990487, disc_loss = 0.10957272363633945
Trained batch 29 in epoch 6, gen_loss = 0.4003431578477224, disc_loss = 0.11003215524057547
Trained batch 30 in epoch 6, gen_loss = 0.399187542738453, disc_loss = 0.11259332695795644
Trained batch 31 in epoch 6, gen_loss = 0.40174976736307144, disc_loss = 0.11125262745190412
Trained batch 32 in epoch 6, gen_loss = 0.399535823952068, disc_loss = 0.11411234386491054
Trained batch 33 in epoch 6, gen_loss = 0.3995436149484971, disc_loss = 0.113238879972521
Trained batch 34 in epoch 6, gen_loss = 0.40291309697287425, disc_loss = 0.11280202429209436
Trained batch 35 in epoch 6, gen_loss = 0.4028097631202804, disc_loss = 0.11558804236766365
Trained batch 36 in epoch 6, gen_loss = 0.40227804715568954, disc_loss = 0.11365538019988988
Trained batch 37 in epoch 6, gen_loss = 0.40248274724734456, disc_loss = 0.11287344825503073
Trained batch 38 in epoch 6, gen_loss = 0.4039683082164862, disc_loss = 0.11072093052550769
Trained batch 39 in epoch 6, gen_loss = 0.40507872402668, disc_loss = 0.10933071100153029
Trained batch 40 in epoch 6, gen_loss = 0.4084172801273625, disc_loss = 0.10828388032571572
Trained batch 41 in epoch 6, gen_loss = 0.4102494404429481, disc_loss = 0.10853392848124106
Trained batch 42 in epoch 6, gen_loss = 0.41280537012011503, disc_loss = 0.10703115065603755
Trained batch 43 in epoch 6, gen_loss = 0.41235360299999063, disc_loss = 0.10509134829044342
Trained batch 44 in epoch 6, gen_loss = 0.4171479165554047, disc_loss = 0.10402713136540519
Trained batch 45 in epoch 6, gen_loss = 0.41947141872799915, disc_loss = 0.10270645461328652
Trained batch 46 in epoch 6, gen_loss = 0.4207799586843937, disc_loss = 0.10117173551561985
Trained batch 47 in epoch 6, gen_loss = 0.42224752840896446, disc_loss = 0.09986539138481021
Trained batch 48 in epoch 6, gen_loss = 0.42303164090429035, disc_loss = 0.09813593981825576
Trained batch 49 in epoch 6, gen_loss = 0.4229352682828903, disc_loss = 0.09777166992425919
Trained batch 50 in epoch 6, gen_loss = 0.4248758852481842, disc_loss = 0.09703208155491773
Trained batch 51 in epoch 6, gen_loss = 0.4246240957425191, disc_loss = 0.09584175365475509
Trained batch 52 in epoch 6, gen_loss = 0.42491328378893295, disc_loss = 0.09507312442896501
Trained batch 53 in epoch 6, gen_loss = 0.42597752643956077, disc_loss = 0.09376566926086391
Trained batch 54 in epoch 6, gen_loss = 0.42605065432461825, disc_loss = 0.09234090924940326
Trained batch 55 in epoch 6, gen_loss = 0.4252772538789681, disc_loss = 0.09198540745169989
Trained batch 56 in epoch 6, gen_loss = 0.4252125699269144, disc_loss = 0.09215717818261239
Trained batch 57 in epoch 6, gen_loss = 0.42588513524367894, disc_loss = 0.0960250511315876
Trained batch 58 in epoch 6, gen_loss = 0.42446430052741096, disc_loss = 0.09581560442634558
Trained batch 59 in epoch 6, gen_loss = 0.42353850305080415, disc_loss = 0.09585837551082174
Trained batch 60 in epoch 6, gen_loss = 0.4223232015234525, disc_loss = 0.09488531082990717
Trained batch 61 in epoch 6, gen_loss = 0.4228908708018641, disc_loss = 0.09416656036891284
Trained batch 62 in epoch 6, gen_loss = 0.4237435408054836, disc_loss = 0.09327905592582529
Trained batch 63 in epoch 6, gen_loss = 0.42253075586631894, disc_loss = 0.09361941055976786
Trained batch 64 in epoch 6, gen_loss = 0.4223709762096405, disc_loss = 0.09259973443471468
Trained batch 65 in epoch 6, gen_loss = 0.4214924704847914, disc_loss = 0.09285076289917484
Trained batch 66 in epoch 6, gen_loss = 0.42315064570797023, disc_loss = 0.09306199793050539
Trained batch 67 in epoch 6, gen_loss = 0.42274974330383186, disc_loss = 0.0931940890629502
Trained batch 68 in epoch 6, gen_loss = 0.42251922902853595, disc_loss = 0.0938735149692798
Trained batch 69 in epoch 6, gen_loss = 0.4224831815276827, disc_loss = 0.0934939648423876
Trained batch 70 in epoch 6, gen_loss = 0.4224058452626349, disc_loss = 0.09310008239158442
Trained batch 71 in epoch 6, gen_loss = 0.4235018230974674, disc_loss = 0.09228180090172423
Trained batch 72 in epoch 6, gen_loss = 0.4225981162018972, disc_loss = 0.09276399598137973
Trained batch 73 in epoch 6, gen_loss = 0.42182970167817296, disc_loss = 0.09366043083168366
Trained batch 74 in epoch 6, gen_loss = 0.4220796549320221, disc_loss = 0.09327735821406047
Trained batch 75 in epoch 6, gen_loss = 0.42242303372997986, disc_loss = 0.09339627927463305
Trained batch 76 in epoch 6, gen_loss = 0.4220659194828628, disc_loss = 0.09273395421249526
Trained batch 77 in epoch 6, gen_loss = 0.42117336086737805, disc_loss = 0.09284933708990231
Trained batch 78 in epoch 6, gen_loss = 0.4218068556695045, disc_loss = 0.09382887311939951
Trained batch 79 in epoch 6, gen_loss = 0.42223884761333463, disc_loss = 0.09364767945371569
Trained batch 80 in epoch 6, gen_loss = 0.4216241520128132, disc_loss = 0.0943001039142226
Trained batch 81 in epoch 6, gen_loss = 0.4220198898053751, disc_loss = 0.09512747565238941
Trained batch 82 in epoch 6, gen_loss = 0.4226020158055317, disc_loss = 0.09472792196166084
Trained batch 83 in epoch 6, gen_loss = 0.4218017529873621, disc_loss = 0.09555247075678337
Trained batch 84 in epoch 6, gen_loss = 0.42173806183478413, disc_loss = 0.09635552926098599
Trained batch 85 in epoch 6, gen_loss = 0.42098475403563923, disc_loss = 0.09596844749568506
Trained batch 86 in epoch 6, gen_loss = 0.42038557652769415, disc_loss = 0.09564604417517267
Trained batch 87 in epoch 6, gen_loss = 0.4197450764477253, disc_loss = 0.09537295611913908
Trained batch 88 in epoch 6, gen_loss = 0.4198208273796553, disc_loss = 0.09586859054947167
Trained batch 89 in epoch 6, gen_loss = 0.4199374659193887, disc_loss = 0.0963544152263138
Trained batch 90 in epoch 6, gen_loss = 0.4194681444665888, disc_loss = 0.09670634424457183
Trained batch 91 in epoch 6, gen_loss = 0.4186873912163403, disc_loss = 0.09652598254868518
Trained batch 92 in epoch 6, gen_loss = 0.41936945338403026, disc_loss = 0.09648961794152054
Trained batch 93 in epoch 6, gen_loss = 0.4197817793551912, disc_loss = 0.09793698236821814
Trained batch 94 in epoch 6, gen_loss = 0.41904132742630806, disc_loss = 0.09800445794274933
Trained batch 95 in epoch 6, gen_loss = 0.41929751510421437, disc_loss = 0.09747886778010677
Trained batch 96 in epoch 6, gen_loss = 0.418962969915154, disc_loss = 0.09725775496707749
Trained batch 97 in epoch 6, gen_loss = 0.41890877454864733, disc_loss = 0.09800031260416216
Trained batch 98 in epoch 6, gen_loss = 0.4181567860974206, disc_loss = 0.09770021922510079
Trained batch 99 in epoch 6, gen_loss = 0.4178245621919632, disc_loss = 0.09879605498164892
Trained batch 100 in epoch 6, gen_loss = 0.4186073311484686, disc_loss = 0.09972538596185127
Trained batch 101 in epoch 6, gen_loss = 0.41863279891949073, disc_loss = 0.09974029693095122
Trained batch 102 in epoch 6, gen_loss = 0.4185720456456675, disc_loss = 0.0992689138838967
Trained batch 103 in epoch 6, gen_loss = 0.4188826809135767, disc_loss = 0.09906964774171893
Trained batch 104 in epoch 6, gen_loss = 0.41896501098360334, disc_loss = 0.09994833664525123
Trained batch 105 in epoch 6, gen_loss = 0.4188735729680871, disc_loss = 0.1009969221744335
Trained batch 106 in epoch 6, gen_loss = 0.418905927477596, disc_loss = 0.10085361976629105
Trained batch 107 in epoch 6, gen_loss = 0.4183551147580147, disc_loss = 0.10086547386729056
Trained batch 108 in epoch 6, gen_loss = 0.4190950401879232, disc_loss = 0.10215381659362294
Trained batch 109 in epoch 6, gen_loss = 0.4182260158387097, disc_loss = 0.10251388112929734
Trained batch 110 in epoch 6, gen_loss = 0.418416846442867, disc_loss = 0.1022408959363495
Trained batch 111 in epoch 6, gen_loss = 0.41827482357621193, disc_loss = 0.10186220585767712
Trained batch 112 in epoch 6, gen_loss = 0.41828779203701866, disc_loss = 0.10280160223488259
Trained batch 113 in epoch 6, gen_loss = 0.4175471012529574, disc_loss = 0.10542314486545429
Trained batch 114 in epoch 6, gen_loss = 0.4177157534205395, disc_loss = 0.10588868364043857
Trained batch 115 in epoch 6, gen_loss = 0.41728413336235903, disc_loss = 0.10599882406150472
Trained batch 116 in epoch 6, gen_loss = 0.4174252590562543, disc_loss = 0.10572578420496395
Trained batch 117 in epoch 6, gen_loss = 0.4172526974294145, disc_loss = 0.10544497715467113
Trained batch 118 in epoch 6, gen_loss = 0.41722965115258676, disc_loss = 0.10505043934373294
Trained batch 119 in epoch 6, gen_loss = 0.4176800735294819, disc_loss = 0.10466196524600188
Trained batch 120 in epoch 6, gen_loss = 0.41732112090449686, disc_loss = 0.10439564792577885
Trained batch 121 in epoch 6, gen_loss = 0.4175114968761069, disc_loss = 0.1040828751369578
Trained batch 122 in epoch 6, gen_loss = 0.417206060837924, disc_loss = 0.10367451326512708
Trained batch 123 in epoch 6, gen_loss = 0.4179878121902866, disc_loss = 0.10314666434761978
Trained batch 124 in epoch 6, gen_loss = 0.4180384407043457, disc_loss = 0.10349740639328957
Trained batch 125 in epoch 6, gen_loss = 0.4187017929932428, disc_loss = 0.10489073670690968
Trained batch 126 in epoch 6, gen_loss = 0.41851630267195816, disc_loss = 0.10496726623318327
Trained batch 127 in epoch 6, gen_loss = 0.41826626914553344, disc_loss = 0.10523927505710162
Trained batch 128 in epoch 6, gen_loss = 0.4180126670719117, disc_loss = 0.10511856061197067
Trained batch 129 in epoch 6, gen_loss = 0.4181106929595654, disc_loss = 0.10520887595529739
Trained batch 130 in epoch 6, gen_loss = 0.41751074199458116, disc_loss = 0.10529955587428035
Trained batch 131 in epoch 6, gen_loss = 0.4179624260374994, disc_loss = 0.10529638999000643
Trained batch 132 in epoch 6, gen_loss = 0.4181936219670719, disc_loss = 0.10469291986603486
Trained batch 133 in epoch 6, gen_loss = 0.4180603549996419, disc_loss = 0.10421148012044715
Trained batch 134 in epoch 6, gen_loss = 0.41839521946730435, disc_loss = 0.1036920490640181
Trained batch 135 in epoch 6, gen_loss = 0.41900017112493515, disc_loss = 0.1033062868313316
Trained batch 136 in epoch 6, gen_loss = 0.4185825296997154, disc_loss = 0.10365504953656754
Trained batch 137 in epoch 6, gen_loss = 0.4189404577448748, disc_loss = 0.10362696121244327
Trained batch 138 in epoch 6, gen_loss = 0.4188183462448257, disc_loss = 0.10348478058795277
Trained batch 139 in epoch 6, gen_loss = 0.41910921037197113, disc_loss = 0.10335791720343487
Trained batch 140 in epoch 6, gen_loss = 0.419354463088597, disc_loss = 0.10299680485053266
Trained batch 141 in epoch 6, gen_loss = 0.41922721371684274, disc_loss = 0.10302398146563013
Trained batch 142 in epoch 6, gen_loss = 0.419299198405726, disc_loss = 0.10357048933010002
Trained batch 143 in epoch 6, gen_loss = 0.4189948954929908, disc_loss = 0.10411856543376213
Trained batch 144 in epoch 6, gen_loss = 0.41927873882754096, disc_loss = 0.10432568215604486
Trained batch 145 in epoch 6, gen_loss = 0.4190452437694759, disc_loss = 0.10419830345637994
Trained batch 146 in epoch 6, gen_loss = 0.4187644142277387, disc_loss = 0.10374685270445687
Trained batch 147 in epoch 6, gen_loss = 0.41832685752494914, disc_loss = 0.10346822274496427
Trained batch 148 in epoch 6, gen_loss = 0.4184368602781488, disc_loss = 0.10342278741550126
Trained batch 149 in epoch 6, gen_loss = 0.4184406586488088, disc_loss = 0.10346077377597492
Trained batch 150 in epoch 6, gen_loss = 0.41873462823842533, disc_loss = 0.10328114679120234
Trained batch 151 in epoch 6, gen_loss = 0.4184024114357798, disc_loss = 0.10347937032776444
Trained batch 152 in epoch 6, gen_loss = 0.41839513202118717, disc_loss = 0.10347006309266184
Trained batch 153 in epoch 6, gen_loss = 0.41859822594500207, disc_loss = 0.10320893413834757
Trained batch 154 in epoch 6, gen_loss = 0.4187751087450212, disc_loss = 0.10294321095270495
Trained batch 155 in epoch 6, gen_loss = 0.4189437610598711, disc_loss = 0.10319851837956752
Trained batch 156 in epoch 6, gen_loss = 0.41980411045870203, disc_loss = 0.10324341872600233
Trained batch 157 in epoch 6, gen_loss = 0.4198335254494148, disc_loss = 0.10274805669684577
Trained batch 158 in epoch 6, gen_loss = 0.41990176068162016, disc_loss = 0.10287413857408664
Trained batch 159 in epoch 6, gen_loss = 0.42017911802977326, disc_loss = 0.10280550968600437
Trained batch 160 in epoch 6, gen_loss = 0.4203469890244999, disc_loss = 0.10232443809046508
Trained batch 161 in epoch 6, gen_loss = 0.41995901458057355, disc_loss = 0.10298318156029707
Trained batch 162 in epoch 6, gen_loss = 0.42009618549259164, disc_loss = 0.10312000380977532
Trained batch 163 in epoch 6, gen_loss = 0.42043641282290944, disc_loss = 0.10380502606219635
Trained batch 164 in epoch 6, gen_loss = 0.41992142236594, disc_loss = 0.10428731926914417
Trained batch 165 in epoch 6, gen_loss = 0.4195587356765586, disc_loss = 0.10396225537251995
Trained batch 166 in epoch 6, gen_loss = 0.41975339622554664, disc_loss = 0.10391320161030677
Trained batch 167 in epoch 6, gen_loss = 0.41971697338989805, disc_loss = 0.10388417539763309
Trained batch 168 in epoch 6, gen_loss = 0.4198820337035952, disc_loss = 0.10342737141798233
Trained batch 169 in epoch 6, gen_loss = 0.4198291005457149, disc_loss = 0.10327778151806663
Trained batch 170 in epoch 6, gen_loss = 0.4200329458155827, disc_loss = 0.10303427109069992
Trained batch 171 in epoch 6, gen_loss = 0.4198271427736726, disc_loss = 0.10292596521592418
Trained batch 172 in epoch 6, gen_loss = 0.42054965420265417, disc_loss = 0.10334644776720532
Trained batch 173 in epoch 6, gen_loss = 0.42037035062395295, disc_loss = 0.10311796614664724
Trained batch 174 in epoch 6, gen_loss = 0.42027354615075246, disc_loss = 0.10283697747758457
Trained batch 175 in epoch 6, gen_loss = 0.4200093001127243, disc_loss = 0.10360098509541289
Trained batch 176 in epoch 6, gen_loss = 0.42049634086210175, disc_loss = 0.1042907124143199
Trained batch 177 in epoch 6, gen_loss = 0.4202902169709795, disc_loss = 0.1048385262949748
Trained batch 178 in epoch 6, gen_loss = 0.42016085449543744, disc_loss = 0.10500110483952074
Trained batch 179 in epoch 6, gen_loss = 0.42021933645009996, disc_loss = 0.10474977362900972
Trained batch 180 in epoch 6, gen_loss = 0.4198977891252844, disc_loss = 0.10479766486511045
Trained batch 181 in epoch 6, gen_loss = 0.4199208649960193, disc_loss = 0.10482690919313457
Trained batch 182 in epoch 6, gen_loss = 0.4199849937131496, disc_loss = 0.10450980046896335
Trained batch 183 in epoch 6, gen_loss = 0.4197461271415586, disc_loss = 0.10519993924738272
Trained batch 184 in epoch 6, gen_loss = 0.4194560619624885, disc_loss = 0.10533172145888613
Trained batch 185 in epoch 6, gen_loss = 0.4191150516271591, disc_loss = 0.10538052282826875
Trained batch 186 in epoch 6, gen_loss = 0.41953613907895626, disc_loss = 0.10571056648212321
Trained batch 187 in epoch 6, gen_loss = 0.41904025065137984, disc_loss = 0.1060998010587819
Trained batch 188 in epoch 6, gen_loss = 0.41910789662568027, disc_loss = 0.10606513298535473
Trained batch 189 in epoch 6, gen_loss = 0.41889671181377613, disc_loss = 0.10632410421967506
Trained batch 190 in epoch 6, gen_loss = 0.41937062627982097, disc_loss = 0.10617729346633581
Trained batch 191 in epoch 6, gen_loss = 0.4189828564412892, disc_loss = 0.10618514012700568
Trained batch 192 in epoch 6, gen_loss = 0.41909200169261873, disc_loss = 0.10580215782621982
Trained batch 193 in epoch 6, gen_loss = 0.419231404348747, disc_loss = 0.10558376559200361
Trained batch 194 in epoch 6, gen_loss = 0.4193764885266622, disc_loss = 0.1054304298108969
Trained batch 195 in epoch 6, gen_loss = 0.4192854064155598, disc_loss = 0.1055817988187987
Trained batch 196 in epoch 6, gen_loss = 0.4192912217021594, disc_loss = 0.10550711060009027
Trained batch 197 in epoch 6, gen_loss = 0.41930929639122705, disc_loss = 0.10629640355931991
Trained batch 198 in epoch 6, gen_loss = 0.4190509211477922, disc_loss = 0.10636514749134605
Trained batch 199 in epoch 6, gen_loss = 0.4194036591053009, disc_loss = 0.10593266269192099
Trained batch 200 in epoch 6, gen_loss = 0.41919637749444194, disc_loss = 0.10623438661890243
Trained batch 201 in epoch 6, gen_loss = 0.4191808445323812, disc_loss = 0.1064536842047283
Trained batch 202 in epoch 6, gen_loss = 0.41887294482715026, disc_loss = 0.10671545343079003
Trained batch 203 in epoch 6, gen_loss = 0.4186400943527035, disc_loss = 0.10668270682514298
Trained batch 204 in epoch 6, gen_loss = 0.41866684381554764, disc_loss = 0.10623369752088697
Trained batch 205 in epoch 6, gen_loss = 0.4183275403038969, disc_loss = 0.10607755398468195
Trained batch 206 in epoch 6, gen_loss = 0.41815873937330383, disc_loss = 0.1059081737347991
Trained batch 207 in epoch 6, gen_loss = 0.4182019064632746, disc_loss = 0.10580395062704785
Trained batch 208 in epoch 6, gen_loss = 0.4181587358125659, disc_loss = 0.10571659738688093
Trained batch 209 in epoch 6, gen_loss = 0.41812584017004284, disc_loss = 0.10541451143189555
Trained batch 210 in epoch 6, gen_loss = 0.4183654378375736, disc_loss = 0.10525180356162137
Trained batch 211 in epoch 6, gen_loss = 0.4186452469735775, disc_loss = 0.1051294243683652
Trained batch 212 in epoch 6, gen_loss = 0.4189686509365207, disc_loss = 0.10484758238942131
Trained batch 213 in epoch 6, gen_loss = 0.41899724485718204, disc_loss = 0.10478172502611006
Trained batch 214 in epoch 6, gen_loss = 0.41911336862763693, disc_loss = 0.10518394634993963
Trained batch 215 in epoch 6, gen_loss = 0.41923250285563646, disc_loss = 0.10490880852254729
Trained batch 216 in epoch 6, gen_loss = 0.41890946909579263, disc_loss = 0.1048719359450214
Trained batch 217 in epoch 6, gen_loss = 0.41885073209574464, disc_loss = 0.10469590343637478
Trained batch 218 in epoch 6, gen_loss = 0.41893496238477695, disc_loss = 0.10459525302290644
Trained batch 219 in epoch 6, gen_loss = 0.4188310861587524, disc_loss = 0.10434378445656463
Trained batch 220 in epoch 6, gen_loss = 0.4184852951792031, disc_loss = 0.10479602877606903
Trained batch 221 in epoch 6, gen_loss = 0.41877689568309096, disc_loss = 0.10460415100762704
Trained batch 222 in epoch 6, gen_loss = 0.4193801394759807, disc_loss = 0.10449958356272747
Trained batch 223 in epoch 6, gen_loss = 0.4191399553258504, disc_loss = 0.10533575288718566
Trained batch 224 in epoch 6, gen_loss = 0.41933243301179673, disc_loss = 0.10570245889325937
Trained batch 225 in epoch 6, gen_loss = 0.4192133651370496, disc_loss = 0.10560902485838242
Trained batch 226 in epoch 6, gen_loss = 0.4190397060390086, disc_loss = 0.10547002185841751
Trained batch 227 in epoch 6, gen_loss = 0.41904187333165555, disc_loss = 0.10527280568586368
Trained batch 228 in epoch 6, gen_loss = 0.41919571174284254, disc_loss = 0.10525365545532328
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4136583209037781, disc_loss = 0.08539102226495743
Trained batch 1 in epoch 7, gen_loss = 0.4093187302350998, disc_loss = 0.07160400226712227
Trained batch 2 in epoch 7, gen_loss = 0.42274122436841327, disc_loss = 0.08190583686033885
Trained batch 3 in epoch 7, gen_loss = 0.4389133155345917, disc_loss = 0.07344451174139977
Trained batch 4 in epoch 7, gen_loss = 0.4240183770656586, disc_loss = 0.10196101665496826
Trained batch 5 in epoch 7, gen_loss = 0.42078575988610584, disc_loss = 0.10089429840445518
Trained batch 6 in epoch 7, gen_loss = 0.4244091383048466, disc_loss = 0.0999870342867715
Trained batch 7 in epoch 7, gen_loss = 0.4154712073504925, disc_loss = 0.10337594337761402
Trained batch 8 in epoch 7, gen_loss = 0.41640812158584595, disc_loss = 0.09965640058120091
Trained batch 9 in epoch 7, gen_loss = 0.4214840292930603, disc_loss = 0.0954370692372322
Trained batch 10 in epoch 7, gen_loss = 0.42122999104586517, disc_loss = 0.08862824416296049
Trained batch 11 in epoch 7, gen_loss = 0.41974441707134247, disc_loss = 0.08783641162638862
Trained batch 12 in epoch 7, gen_loss = 0.42509475579628575, disc_loss = 0.08480642291788872
Trained batch 13 in epoch 7, gen_loss = 0.42857961995261057, disc_loss = 0.08052578927682978
Trained batch 14 in epoch 7, gen_loss = 0.42666664520899455, disc_loss = 0.08367712534964085
Trained batch 15 in epoch 7, gen_loss = 0.42795474268496037, disc_loss = 0.0830890437355265
Trained batch 16 in epoch 7, gen_loss = 0.42868950612404766, disc_loss = 0.08113381891127895
Trained batch 17 in epoch 7, gen_loss = 0.4262666453917821, disc_loss = 0.07847730080700582
Trained batch 18 in epoch 7, gen_loss = 0.4260052850371913, disc_loss = 0.07733128445321008
Trained batch 19 in epoch 7, gen_loss = 0.4284734159708023, disc_loss = 0.08076213328167796
Trained batch 20 in epoch 7, gen_loss = 0.42495326201121014, disc_loss = 0.08185862102324054
Trained batch 21 in epoch 7, gen_loss = 0.4259556152603843, disc_loss = 0.08254721684550698
Trained batch 22 in epoch 7, gen_loss = 0.4288779652636984, disc_loss = 0.08627389428084312
Trained batch 23 in epoch 7, gen_loss = 0.4283357957998912, disc_loss = 0.08368191751651466
Trained batch 24 in epoch 7, gen_loss = 0.4260099518299103, disc_loss = 0.08346798963844776
Trained batch 25 in epoch 7, gen_loss = 0.42442587018013, disc_loss = 0.08177636055132517
Trained batch 26 in epoch 7, gen_loss = 0.42563702993922764, disc_loss = 0.08439194169585351
Trained batch 27 in epoch 7, gen_loss = 0.42665792469467434, disc_loss = 0.08463524128975612
Trained batch 28 in epoch 7, gen_loss = 0.42415201047371176, disc_loss = 0.08532692190131237
Trained batch 29 in epoch 7, gen_loss = 0.4252074579397837, disc_loss = 0.08407970449576775
Trained batch 30 in epoch 7, gen_loss = 0.4240787923336029, disc_loss = 0.08334310094435368
Trained batch 31 in epoch 7, gen_loss = 0.42461721505969763, disc_loss = 0.08437646582024172
Trained batch 32 in epoch 7, gen_loss = 0.4217721765691584, disc_loss = 0.08448626625944268
Trained batch 33 in epoch 7, gen_loss = 0.42099325446521535, disc_loss = 0.08440368518452435
Trained batch 34 in epoch 7, gen_loss = 0.4218977638653347, disc_loss = 0.08410491288772651
Trained batch 35 in epoch 7, gen_loss = 0.42264225002792144, disc_loss = 0.08346093471886383
Trained batch 36 in epoch 7, gen_loss = 0.4234585053211934, disc_loss = 0.08156435639672988
Trained batch 37 in epoch 7, gen_loss = 0.4212362954491063, disc_loss = 0.08451998513191938
Trained batch 38 in epoch 7, gen_loss = 0.4219419192045163, disc_loss = 0.08868468614916007
Trained batch 39 in epoch 7, gen_loss = 0.4210974760353565, disc_loss = 0.0874504974577576
Trained batch 40 in epoch 7, gen_loss = 0.41929572966040635, disc_loss = 0.09048231259533544
Trained batch 41 in epoch 7, gen_loss = 0.42109687342530205, disc_loss = 0.09000492401953254
Trained batch 42 in epoch 7, gen_loss = 0.42167048052299855, disc_loss = 0.09490638923679673
Trained batch 43 in epoch 7, gen_loss = 0.420025534927845, disc_loss = 0.0956186623820527
Trained batch 44 in epoch 7, gen_loss = 0.41783399515681796, disc_loss = 0.10021171689861351
Trained batch 45 in epoch 7, gen_loss = 0.4181949366693911, disc_loss = 0.10811318898492533
Trained batch 46 in epoch 7, gen_loss = 0.41818939688357903, disc_loss = 0.10977482213143339
Trained batch 47 in epoch 7, gen_loss = 0.41644149584074813, disc_loss = 0.11081403109710664
Trained batch 48 in epoch 7, gen_loss = 0.4146655165419287, disc_loss = 0.11163184643552011
Trained batch 49 in epoch 7, gen_loss = 0.41451016545295716, disc_loss = 0.11156286124140025
Trained batch 50 in epoch 7, gen_loss = 0.41415226284195394, disc_loss = 0.11100269565541371
Trained batch 51 in epoch 7, gen_loss = 0.4139463471678587, disc_loss = 0.11053720636006731
Trained batch 52 in epoch 7, gen_loss = 0.41336142623199607, disc_loss = 0.10931991655730976
Trained batch 53 in epoch 7, gen_loss = 0.41314751240942216, disc_loss = 0.11009897012263536
Trained batch 54 in epoch 7, gen_loss = 0.4119543958793987, disc_loss = 0.11094751761040904
Trained batch 55 in epoch 7, gen_loss = 0.41156633517571856, disc_loss = 0.11227047307017658
Trained batch 56 in epoch 7, gen_loss = 0.41067152065143253, disc_loss = 0.1129431400055948
Trained batch 57 in epoch 7, gen_loss = 0.40999458370537595, disc_loss = 0.11468000501265814
Trained batch 58 in epoch 7, gen_loss = 0.40959894404572955, disc_loss = 0.11482211009804476
Trained batch 59 in epoch 7, gen_loss = 0.41066058774789177, disc_loss = 0.11489289101834098
Trained batch 60 in epoch 7, gen_loss = 0.41035096518328934, disc_loss = 0.11672115396158617
Trained batch 61 in epoch 7, gen_loss = 0.4110162796512727, disc_loss = 0.11682875655711658
Trained batch 62 in epoch 7, gen_loss = 0.4114488174044897, disc_loss = 0.11582403987764366
Trained batch 63 in epoch 7, gen_loss = 0.41121999314054847, disc_loss = 0.11505161636159755
Trained batch 64 in epoch 7, gen_loss = 0.41043524054380565, disc_loss = 0.115164151472541
Trained batch 65 in epoch 7, gen_loss = 0.41085164790803735, disc_loss = 0.11629040937193415
Trained batch 66 in epoch 7, gen_loss = 0.410076098210776, disc_loss = 0.11655115516884114
Trained batch 67 in epoch 7, gen_loss = 0.4090306438943919, disc_loss = 0.11629368772949367
Trained batch 68 in epoch 7, gen_loss = 0.4093051064705503, disc_loss = 0.1152490832829389
Trained batch 69 in epoch 7, gen_loss = 0.4087616149868284, disc_loss = 0.1146939738254462
Trained batch 70 in epoch 7, gen_loss = 0.4089838073287212, disc_loss = 0.1142714903755507
Trained batch 71 in epoch 7, gen_loss = 0.408483300358057, disc_loss = 0.11347860141864254
Trained batch 72 in epoch 7, gen_loss = 0.4087197927579488, disc_loss = 0.11261110194027424
Trained batch 73 in epoch 7, gen_loss = 0.40955423261668233, disc_loss = 0.11261681912819275
Trained batch 74 in epoch 7, gen_loss = 0.40957855025927226, disc_loss = 0.11211435926457246
Trained batch 75 in epoch 7, gen_loss = 0.4098462419290292, disc_loss = 0.11130678165998113
Trained batch 76 in epoch 7, gen_loss = 0.409830548546531, disc_loss = 0.11095445828101078
Trained batch 77 in epoch 7, gen_loss = 0.4104824280127501, disc_loss = 0.11158712688260354
Trained batch 78 in epoch 7, gen_loss = 0.409681133454359, disc_loss = 0.11164841133676752
Trained batch 79 in epoch 7, gen_loss = 0.40973663218319417, disc_loss = 0.11227334516588598
Trained batch 80 in epoch 7, gen_loss = 0.409950523464768, disc_loss = 0.11295432700879043
Trained batch 81 in epoch 7, gen_loss = 0.41030634249128944, disc_loss = 0.11287317027496856
Trained batch 82 in epoch 7, gen_loss = 0.4099395249981478, disc_loss = 0.11345952715590057
Trained batch 83 in epoch 7, gen_loss = 0.41009627495493206, disc_loss = 0.11317723894137002
Trained batch 84 in epoch 7, gen_loss = 0.41041931650217844, disc_loss = 0.11286184369202923
Trained batch 85 in epoch 7, gen_loss = 0.41018258728260215, disc_loss = 0.11213128777697336
Trained batch 86 in epoch 7, gen_loss = 0.4096881116943798, disc_loss = 0.11175009374902851
Trained batch 87 in epoch 7, gen_loss = 0.4103695442053405, disc_loss = 0.11073787959123199
Trained batch 88 in epoch 7, gen_loss = 0.41015419062603725, disc_loss = 0.11049558599008603
Trained batch 89 in epoch 7, gen_loss = 0.4106795648733775, disc_loss = 0.10972131776312986
Trained batch 90 in epoch 7, gen_loss = 0.4114852370796623, disc_loss = 0.1089718484698416
Trained batch 91 in epoch 7, gen_loss = 0.41070972966111224, disc_loss = 0.10903572473351074
Trained batch 92 in epoch 7, gen_loss = 0.41161454589136187, disc_loss = 0.11026515583357503
Trained batch 93 in epoch 7, gen_loss = 0.4119914240659551, disc_loss = 0.10926746983239626
Trained batch 94 in epoch 7, gen_loss = 0.4122856626385137, disc_loss = 0.11045475737436822
Trained batch 95 in epoch 7, gen_loss = 0.41272891126573086, disc_loss = 0.10987786271531756
Trained batch 96 in epoch 7, gen_loss = 0.41344687557712045, disc_loss = 0.10965390071349661
Trained batch 97 in epoch 7, gen_loss = 0.4141464485805862, disc_loss = 0.1090369403780419
Trained batch 98 in epoch 7, gen_loss = 0.41413492536303975, disc_loss = 0.11023679087785157
Trained batch 99 in epoch 7, gen_loss = 0.4141019585728645, disc_loss = 0.1101480402611196
Trained batch 100 in epoch 7, gen_loss = 0.4147120245022349, disc_loss = 0.11110857134629594
Trained batch 101 in epoch 7, gen_loss = 0.41493841216844674, disc_loss = 0.11030213408829535
Trained batch 102 in epoch 7, gen_loss = 0.414520516268258, disc_loss = 0.11080708888187571
Trained batch 103 in epoch 7, gen_loss = 0.4152314809079354, disc_loss = 0.1105378434742586
Trained batch 104 in epoch 7, gen_loss = 0.41570815216927304, disc_loss = 0.11007317231879347
Trained batch 105 in epoch 7, gen_loss = 0.4151146746468994, disc_loss = 0.11054773191165812
Trained batch 106 in epoch 7, gen_loss = 0.41522998063363764, disc_loss = 0.10997810352280318
Trained batch 107 in epoch 7, gen_loss = 0.41509586738215554, disc_loss = 0.10925814555957913
Trained batch 108 in epoch 7, gen_loss = 0.41506422495623246, disc_loss = 0.10877473254201062
Trained batch 109 in epoch 7, gen_loss = 0.4149506249211051, disc_loss = 0.10916382898999887
Trained batch 110 in epoch 7, gen_loss = 0.41448617867521337, disc_loss = 0.10845229304857082
Trained batch 111 in epoch 7, gen_loss = 0.4144624226859638, disc_loss = 0.10826018539124302
Trained batch 112 in epoch 7, gen_loss = 0.41423839884521685, disc_loss = 0.10842828511928035
Trained batch 113 in epoch 7, gen_loss = 0.41474720914112895, disc_loss = 0.10933144031125203
Trained batch 114 in epoch 7, gen_loss = 0.41476759340452113, disc_loss = 0.10909387061129446
Trained batch 115 in epoch 7, gen_loss = 0.4145016528922936, disc_loss = 0.10900978666955027
Trained batch 116 in epoch 7, gen_loss = 0.41430734772967476, disc_loss = 0.10925705692706963
Trained batch 117 in epoch 7, gen_loss = 0.41400642162662443, disc_loss = 0.10975189746941551
Trained batch 118 in epoch 7, gen_loss = 0.4135384214024584, disc_loss = 0.10929543243235901
Trained batch 119 in epoch 7, gen_loss = 0.4127714936931928, disc_loss = 0.11003360487520694
Trained batch 120 in epoch 7, gen_loss = 0.4132698449221524, disc_loss = 0.11178649469348025
Trained batch 121 in epoch 7, gen_loss = 0.4133608922606609, disc_loss = 0.11152717135235911
Trained batch 122 in epoch 7, gen_loss = 0.41349906892311283, disc_loss = 0.11208034076584064
Trained batch 123 in epoch 7, gen_loss = 0.4133519965314096, disc_loss = 0.11244847307041768
Trained batch 124 in epoch 7, gen_loss = 0.413480327129364, disc_loss = 0.11191330772638321
Trained batch 125 in epoch 7, gen_loss = 0.41299422960432747, disc_loss = 0.11168402870969167
Trained batch 126 in epoch 7, gen_loss = 0.41340102806804685, disc_loss = 0.11094418700461782
Trained batch 127 in epoch 7, gen_loss = 0.4133729594759643, disc_loss = 0.11124578076123726
Trained batch 128 in epoch 7, gen_loss = 0.41342620932778645, disc_loss = 0.11099842841946339
Trained batch 129 in epoch 7, gen_loss = 0.4135711096800291, disc_loss = 0.11185625176876783
Trained batch 130 in epoch 7, gen_loss = 0.41253124029581784, disc_loss = 0.11207679088959713
Trained batch 131 in epoch 7, gen_loss = 0.4122252297220808, disc_loss = 0.112333615889039
Trained batch 132 in epoch 7, gen_loss = 0.41221856421097774, disc_loss = 0.11328880000103236
Trained batch 133 in epoch 7, gen_loss = 0.4123076009216593, disc_loss = 0.11305230387500417
Trained batch 134 in epoch 7, gen_loss = 0.4117571515065652, disc_loss = 0.11373296610459134
Trained batch 135 in epoch 7, gen_loss = 0.4126466646352235, disc_loss = 0.11443212813259486
Trained batch 136 in epoch 7, gen_loss = 0.41241978489569503, disc_loss = 0.11467422239047333
Trained batch 137 in epoch 7, gen_loss = 0.4120140740836876, disc_loss = 0.11568970987708241
Trained batch 138 in epoch 7, gen_loss = 0.4124588072299957, disc_loss = 0.11551896518886946
Trained batch 139 in epoch 7, gen_loss = 0.4128552713564464, disc_loss = 0.1154151830156999
Trained batch 140 in epoch 7, gen_loss = 0.41272370675776865, disc_loss = 0.11517937458945927
Trained batch 141 in epoch 7, gen_loss = 0.41304283326780294, disc_loss = 0.11458661211785716
Trained batch 142 in epoch 7, gen_loss = 0.4130796879738361, disc_loss = 0.11505766321051787
Trained batch 143 in epoch 7, gen_loss = 0.4127278098215659, disc_loss = 0.11473919827646266
Trained batch 144 in epoch 7, gen_loss = 0.41251442144657, disc_loss = 0.11517981993484086
Trained batch 145 in epoch 7, gen_loss = 0.4126178581420689, disc_loss = 0.11486034155249188
Trained batch 146 in epoch 7, gen_loss = 0.41274375068087155, disc_loss = 0.11539269891269759
Trained batch 147 in epoch 7, gen_loss = 0.41251598620736923, disc_loss = 0.11572395817603211
Trained batch 148 in epoch 7, gen_loss = 0.4121916534116604, disc_loss = 0.1167697757357519
Trained batch 149 in epoch 7, gen_loss = 0.4121803496281306, disc_loss = 0.11722727704793215
Trained batch 150 in epoch 7, gen_loss = 0.4125966348790175, disc_loss = 0.11748797292296854
Trained batch 151 in epoch 7, gen_loss = 0.4124476507698235, disc_loss = 0.11742950111970697
Trained batch 152 in epoch 7, gen_loss = 0.4124208776389851, disc_loss = 0.11768606615563233
Trained batch 153 in epoch 7, gen_loss = 0.41211397307259695, disc_loss = 0.11790516158541689
Trained batch 154 in epoch 7, gen_loss = 0.41226835270081796, disc_loss = 0.11772078476365536
Trained batch 155 in epoch 7, gen_loss = 0.41235110125480556, disc_loss = 0.11730677392094946
Trained batch 156 in epoch 7, gen_loss = 0.4119947370450208, disc_loss = 0.11703715522055792
Trained batch 157 in epoch 7, gen_loss = 0.41179716153235374, disc_loss = 0.11659523652559972
Trained batch 158 in epoch 7, gen_loss = 0.41210574399000444, disc_loss = 0.11658033247123349
Trained batch 159 in epoch 7, gen_loss = 0.41185160595923664, disc_loss = 0.11608532563550397
Trained batch 160 in epoch 7, gen_loss = 0.41200190875100795, disc_loss = 0.11556842945145894
Trained batch 161 in epoch 7, gen_loss = 0.41223111656712896, disc_loss = 0.11496039606446837
Trained batch 162 in epoch 7, gen_loss = 0.41212390043252817, disc_loss = 0.11463195238650942
Trained batch 163 in epoch 7, gen_loss = 0.411994841222356, disc_loss = 0.11411086277945376
Trained batch 164 in epoch 7, gen_loss = 0.4122001698522857, disc_loss = 0.11369621260373881
Trained batch 165 in epoch 7, gen_loss = 0.4122571914669979, disc_loss = 0.1134949563834143
Trained batch 166 in epoch 7, gen_loss = 0.41253852183947304, disc_loss = 0.11322393606299769
Trained batch 167 in epoch 7, gen_loss = 0.41267276147291776, disc_loss = 0.1129480748814309
Trained batch 168 in epoch 7, gen_loss = 0.41310688324228545, disc_loss = 0.11249075284415096
Trained batch 169 in epoch 7, gen_loss = 0.4128387351246441, disc_loss = 0.11271052571999676
Trained batch 170 in epoch 7, gen_loss = 0.4126295334065867, disc_loss = 0.11309655438781831
Trained batch 171 in epoch 7, gen_loss = 0.41281114189430723, disc_loss = 0.11299860461203512
Trained batch 172 in epoch 7, gen_loss = 0.41338389784614477, disc_loss = 0.11349145733250704
Trained batch 173 in epoch 7, gen_loss = 0.41314014107331465, disc_loss = 0.1135776353057945
Trained batch 174 in epoch 7, gen_loss = 0.4131456075395857, disc_loss = 0.11395031010465963
Trained batch 175 in epoch 7, gen_loss = 0.41333883272653277, disc_loss = 0.11458842525131661
Trained batch 176 in epoch 7, gen_loss = 0.4134632700917411, disc_loss = 0.11412368353856149
Trained batch 177 in epoch 7, gen_loss = 0.41338601021954186, disc_loss = 0.11411152659716566
Trained batch 178 in epoch 7, gen_loss = 0.4133006585709876, disc_loss = 0.1139536399768884
Trained batch 179 in epoch 7, gen_loss = 0.4136840139826139, disc_loss = 0.11369719771254394
Trained batch 180 in epoch 7, gen_loss = 0.4138106763033577, disc_loss = 0.11361927202599154
Trained batch 181 in epoch 7, gen_loss = 0.413598609658388, disc_loss = 0.11354148671399433
Trained batch 182 in epoch 7, gen_loss = 0.4139126723255616, disc_loss = 0.11332939798266836
Trained batch 183 in epoch 7, gen_loss = 0.41412213136968407, disc_loss = 0.11283278211181902
Trained batch 184 in epoch 7, gen_loss = 0.41401437730402557, disc_loss = 0.11320022849013676
Trained batch 185 in epoch 7, gen_loss = 0.4144758715104031, disc_loss = 0.11347432872180337
Trained batch 186 in epoch 7, gen_loss = 0.41426598372306417, disc_loss = 0.11307674312695144
Trained batch 187 in epoch 7, gen_loss = 0.41420977356586053, disc_loss = 0.11331422968787398
Trained batch 188 in epoch 7, gen_loss = 0.4140688458447734, disc_loss = 0.11307749271432244
Trained batch 189 in epoch 7, gen_loss = 0.41451273497782254, disc_loss = 0.11331999616599396
Trained batch 190 in epoch 7, gen_loss = 0.41417019451475895, disc_loss = 0.11351436720819685
Trained batch 191 in epoch 7, gen_loss = 0.41458670794963837, disc_loss = 0.11356048737070523
Trained batch 192 in epoch 7, gen_loss = 0.41437017778658497, disc_loss = 0.11364638852679358
Trained batch 193 in epoch 7, gen_loss = 0.41413554779647554, disc_loss = 0.11351380359919108
Trained batch 194 in epoch 7, gen_loss = 0.41395246783892314, disc_loss = 0.1133008040774327
Trained batch 195 in epoch 7, gen_loss = 0.41372103563376833, disc_loss = 0.11325604925692385
Trained batch 196 in epoch 7, gen_loss = 0.41362817411495345, disc_loss = 0.11303286032212265
Trained batch 197 in epoch 7, gen_loss = 0.41335718092894314, disc_loss = 0.1131130021648726
Trained batch 198 in epoch 7, gen_loss = 0.4136061325444648, disc_loss = 0.11317497459076457
Trained batch 199 in epoch 7, gen_loss = 0.4133972436189651, disc_loss = 0.11311131590045989
Trained batch 200 in epoch 7, gen_loss = 0.4133490429292271, disc_loss = 0.11298734780901404
Trained batch 201 in epoch 7, gen_loss = 0.4132099445208465, disc_loss = 0.113040643947033
Trained batch 202 in epoch 7, gen_loss = 0.41314969949534375, disc_loss = 0.1131450402197139
Trained batch 203 in epoch 7, gen_loss = 0.4129148914533503, disc_loss = 0.11288283116129391
Trained batch 204 in epoch 7, gen_loss = 0.4133928040178811, disc_loss = 0.11245784965775361
Trained batch 205 in epoch 7, gen_loss = 0.4134384845066996, disc_loss = 0.11233686861012457
Trained batch 206 in epoch 7, gen_loss = 0.4132649108119633, disc_loss = 0.11201563332643774
Trained batch 207 in epoch 7, gen_loss = 0.4134790844355638, disc_loss = 0.11194324782655503
Trained batch 208 in epoch 7, gen_loss = 0.413414774328898, disc_loss = 0.1115893119741142
Trained batch 209 in epoch 7, gen_loss = 0.41341298279308136, disc_loss = 0.11206306693631979
Trained batch 210 in epoch 7, gen_loss = 0.41379290056454626, disc_loss = 0.11193204497238754
Trained batch 211 in epoch 7, gen_loss = 0.41360514400140297, disc_loss = 0.11178082346318746
Trained batch 212 in epoch 7, gen_loss = 0.41357392996129855, disc_loss = 0.11190018833488086
Trained batch 213 in epoch 7, gen_loss = 0.41323291586938304, disc_loss = 0.11225410515146557
Trained batch 214 in epoch 7, gen_loss = 0.41305956895961315, disc_loss = 0.11230953795792059
Trained batch 215 in epoch 7, gen_loss = 0.4129235967993736, disc_loss = 0.11246335246876159
Trained batch 216 in epoch 7, gen_loss = 0.4128891799581765, disc_loss = 0.11291888963070608
Trained batch 217 in epoch 7, gen_loss = 0.4129727142393042, disc_loss = 0.11266895996218701
Trained batch 218 in epoch 7, gen_loss = 0.4134003888798631, disc_loss = 0.11326452148185201
Trained batch 219 in epoch 7, gen_loss = 0.41330803727561777, disc_loss = 0.11330755956640298
Trained batch 220 in epoch 7, gen_loss = 0.41314828625092137, disc_loss = 0.11304700823829454
Trained batch 221 in epoch 7, gen_loss = 0.4131214754270004, disc_loss = 0.11294680901777905
Trained batch 222 in epoch 7, gen_loss = 0.4133376231909867, disc_loss = 0.11271446762030167
Trained batch 223 in epoch 7, gen_loss = 0.41336199122348, disc_loss = 0.11243866968600612
Trained batch 224 in epoch 7, gen_loss = 0.4133271541860368, disc_loss = 0.11228693312240971
Trained batch 225 in epoch 7, gen_loss = 0.4134768850244252, disc_loss = 0.11224246967122355
Trained batch 226 in epoch 7, gen_loss = 0.41363787782349776, disc_loss = 0.11194976941899844
Trained batch 227 in epoch 7, gen_loss = 0.41362006178027705, disc_loss = 0.11160235820142062
Trained batch 228 in epoch 7, gen_loss = 0.41354167838804584, disc_loss = 0.11141435474189869
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.477748304605484, disc_loss = 0.039667461067438126
Trained batch 1 in epoch 8, gen_loss = 0.42045608162879944, disc_loss = 0.08566305227577686
Trained batch 2 in epoch 8, gen_loss = 0.40287251273790997, disc_loss = 0.09352748716870944
Trained batch 3 in epoch 8, gen_loss = 0.4111384376883507, disc_loss = 0.10053851176053286
Trained batch 4 in epoch 8, gen_loss = 0.40239723920822146, disc_loss = 0.10449632480740548
Trained batch 5 in epoch 8, gen_loss = 0.4043526848157247, disc_loss = 0.11794599207739036
Trained batch 6 in epoch 8, gen_loss = 0.40537301131657194, disc_loss = 0.14960726084453718
Trained batch 7 in epoch 8, gen_loss = 0.3995700068771839, disc_loss = 0.18965420359745622
Trained batch 8 in epoch 8, gen_loss = 0.40549609065055847, disc_loss = 0.18517010120881927
Trained batch 9 in epoch 8, gen_loss = 0.4077571213245392, disc_loss = 0.18164036758244037
Trained batch 10 in epoch 8, gen_loss = 0.4039502604441209, disc_loss = 0.1880371506241235
Trained batch 11 in epoch 8, gen_loss = 0.4098875547448794, disc_loss = 0.17916934782018265
Trained batch 12 in epoch 8, gen_loss = 0.41494830067341143, disc_loss = 0.17415097613747305
Trained batch 13 in epoch 8, gen_loss = 0.4145458447081702, disc_loss = 0.16757074663681643
Trained batch 14 in epoch 8, gen_loss = 0.4136144022146861, disc_loss = 0.16629945362607637
Trained batch 15 in epoch 8, gen_loss = 0.41581685096025467, disc_loss = 0.16561394021846354
Trained batch 16 in epoch 8, gen_loss = 0.41374899008694815, disc_loss = 0.16301805547931614
Trained batch 17 in epoch 8, gen_loss = 0.4095470739735497, disc_loss = 0.16223245838450062
Trained batch 18 in epoch 8, gen_loss = 0.40691018888824865, disc_loss = 0.16075378401499046
Trained batch 19 in epoch 8, gen_loss = 0.407256156206131, disc_loss = 0.15727165732532739
Trained batch 20 in epoch 8, gen_loss = 0.40427788098653156, disc_loss = 0.15341105152453696
Trained batch 21 in epoch 8, gen_loss = 0.4048516398126429, disc_loss = 0.1506500398232178
Trained batch 22 in epoch 8, gen_loss = 0.4030443352201711, disc_loss = 0.1456070877611637
Trained batch 23 in epoch 8, gen_loss = 0.4041283192733924, disc_loss = 0.14677258937930068
Trained batch 24 in epoch 8, gen_loss = 0.40212408781051634, disc_loss = 0.14411673411726952
Trained batch 25 in epoch 8, gen_loss = 0.4022608376466311, disc_loss = 0.1426196300352995
Trained batch 26 in epoch 8, gen_loss = 0.40416709471631934, disc_loss = 0.13984007650503405
Trained batch 27 in epoch 8, gen_loss = 0.40663223820073263, disc_loss = 0.1410443555297596
Trained batch 28 in epoch 8, gen_loss = 0.40689852730981235, disc_loss = 0.13907328543478045
Trained batch 29 in epoch 8, gen_loss = 0.4063601185878118, disc_loss = 0.1374052910755078
Trained batch 30 in epoch 8, gen_loss = 0.4061146868813422, disc_loss = 0.13715983434550225
Trained batch 31 in epoch 8, gen_loss = 0.4064032919704914, disc_loss = 0.1418034484377131
Trained batch 32 in epoch 8, gen_loss = 0.4037738424358946, disc_loss = 0.14420114717248714
Trained batch 33 in epoch 8, gen_loss = 0.402193142210736, disc_loss = 0.14510576065410585
Trained batch 34 in epoch 8, gen_loss = 0.40377680999892096, disc_loss = 0.14682626287852016
Trained batch 35 in epoch 8, gen_loss = 0.4026815825038486, disc_loss = 0.14694103422678179
Trained batch 36 in epoch 8, gen_loss = 0.40310598144660126, disc_loss = 0.1452097895781736
Trained batch 37 in epoch 8, gen_loss = 0.4043610660653365, disc_loss = 0.14427802211752064
Trained batch 38 in epoch 8, gen_loss = 0.40500244956750137, disc_loss = 0.14281832550962767
Trained batch 39 in epoch 8, gen_loss = 0.40647233128547666, disc_loss = 0.14128110306337477
Trained batch 40 in epoch 8, gen_loss = 0.40700820669895266, disc_loss = 0.13923701961956372
Trained batch 41 in epoch 8, gen_loss = 0.4084443946679433, disc_loss = 0.13621788749116517
Trained batch 42 in epoch 8, gen_loss = 0.4086000503495682, disc_loss = 0.1341974347353328
Trained batch 43 in epoch 8, gen_loss = 0.4091613895513795, disc_loss = 0.1319238004401665
Trained batch 44 in epoch 8, gen_loss = 0.4090364032321506, disc_loss = 0.131271892061664
Trained batch 45 in epoch 8, gen_loss = 0.4079416031422822, disc_loss = 0.12961540510877967
Trained batch 46 in epoch 8, gen_loss = 0.4073702940281401, disc_loss = 0.1279073582882894
Trained batch 47 in epoch 8, gen_loss = 0.40914918792744476, disc_loss = 0.1273436481327129
Trained batch 48 in epoch 8, gen_loss = 0.40875419122832163, disc_loss = 0.12579318943756576
Trained batch 49 in epoch 8, gen_loss = 0.40865659892559053, disc_loss = 0.12377906451001763
Trained batch 50 in epoch 8, gen_loss = 0.407906081162247, disc_loss = 0.12382440979355107
Trained batch 51 in epoch 8, gen_loss = 0.4087932367737477, disc_loss = 0.12246740059568904
Trained batch 52 in epoch 8, gen_loss = 0.4106285127828706, disc_loss = 0.12359970971449928
Trained batch 53 in epoch 8, gen_loss = 0.4096936594556879, disc_loss = 0.12331557365272332
Trained batch 54 in epoch 8, gen_loss = 0.4094157115979628, disc_loss = 0.12346782503141598
Trained batch 55 in epoch 8, gen_loss = 0.41054096658314976, disc_loss = 0.12480406125541776
Trained batch 56 in epoch 8, gen_loss = 0.4092797715412943, disc_loss = 0.12526244560681415
Trained batch 57 in epoch 8, gen_loss = 0.40825603028823587, disc_loss = 0.1243248878143214
Trained batch 58 in epoch 8, gen_loss = 0.407874392755961, disc_loss = 0.12274579200262235
Trained batch 59 in epoch 8, gen_loss = 0.40753596474726994, disc_loss = 0.1219031987246126
Trained batch 60 in epoch 8, gen_loss = 0.4082627384389033, disc_loss = 0.12069626483821967
Trained batch 61 in epoch 8, gen_loss = 0.40831384399244863, disc_loss = 0.12004497300292696
Trained batch 62 in epoch 8, gen_loss = 0.4078062522032904, disc_loss = 0.11859244523599508
Trained batch 63 in epoch 8, gen_loss = 0.40774514246731997, disc_loss = 0.11997697841434274
Trained batch 64 in epoch 8, gen_loss = 0.4090083681620084, disc_loss = 0.12135088181552979
Trained batch 65 in epoch 8, gen_loss = 0.4086270666483677, disc_loss = 0.1201547900299457
Trained batch 66 in epoch 8, gen_loss = 0.40752632093073715, disc_loss = 0.12127518999988018
Trained batch 67 in epoch 8, gen_loss = 0.4073251271072556, disc_loss = 0.12183927844607216
Trained batch 68 in epoch 8, gen_loss = 0.40787740634835284, disc_loss = 0.12064328164780054
Trained batch 69 in epoch 8, gen_loss = 0.4070567037378039, disc_loss = 0.12189627780712077
Trained batch 70 in epoch 8, gen_loss = 0.40764357254538736, disc_loss = 0.12184760437517518
Trained batch 71 in epoch 8, gen_loss = 0.40754667876495254, disc_loss = 0.12109877832699567
Trained batch 72 in epoch 8, gen_loss = 0.4076420832170199, disc_loss = 0.12064070378315367
Trained batch 73 in epoch 8, gen_loss = 0.40717536976208557, disc_loss = 0.11967760315668341
Trained batch 74 in epoch 8, gen_loss = 0.4074111819267273, disc_loss = 0.12084059070795775
Trained batch 75 in epoch 8, gen_loss = 0.4075297544661321, disc_loss = 0.12095560928757645
Trained batch 76 in epoch 8, gen_loss = 0.4075377986028597, disc_loss = 0.12016273542706456
Trained batch 77 in epoch 8, gen_loss = 0.40760244543735796, disc_loss = 0.11924551762879276
Trained batch 78 in epoch 8, gen_loss = 0.40818481505671633, disc_loss = 0.11973101024433405
Trained batch 79 in epoch 8, gen_loss = 0.40890932083129883, disc_loss = 0.11849005135009065
Trained batch 80 in epoch 8, gen_loss = 0.40935714450883276, disc_loss = 0.1177345138664047
Trained batch 81 in epoch 8, gen_loss = 0.40987321516362635, disc_loss = 0.11757818642413108
Trained batch 82 in epoch 8, gen_loss = 0.4106789015861879, disc_loss = 0.11735223436795444
Trained batch 83 in epoch 8, gen_loss = 0.41129087124552044, disc_loss = 0.11643757982667358
Trained batch 84 in epoch 8, gen_loss = 0.411928412844153, disc_loss = 0.11606038818683695
Trained batch 85 in epoch 8, gen_loss = 0.4119165491226108, disc_loss = 0.11660260110443761
Trained batch 86 in epoch 8, gen_loss = 0.4122700328114389, disc_loss = 0.11597417625759182
Trained batch 87 in epoch 8, gen_loss = 0.41302196749232034, disc_loss = 0.11604815870735118
Trained batch 88 in epoch 8, gen_loss = 0.4126667537715998, disc_loss = 0.11666767681122162
Trained batch 89 in epoch 8, gen_loss = 0.41223377618524765, disc_loss = 0.11634639870996276
Trained batch 90 in epoch 8, gen_loss = 0.41185327218129086, disc_loss = 0.11616111633746506
Trained batch 91 in epoch 8, gen_loss = 0.41231625429961993, disc_loss = 0.1164913710065024
Trained batch 92 in epoch 8, gen_loss = 0.41165871741951154, disc_loss = 0.11589735515055156
Trained batch 93 in epoch 8, gen_loss = 0.41166243496093347, disc_loss = 0.11586687897153675
Trained batch 94 in epoch 8, gen_loss = 0.41154294578652634, disc_loss = 0.11591640837294491
Trained batch 95 in epoch 8, gen_loss = 0.4119587106009324, disc_loss = 0.11571743829214635
Trained batch 96 in epoch 8, gen_loss = 0.41169272777960475, disc_loss = 0.1158331363106665
Trained batch 97 in epoch 8, gen_loss = 0.4116606499467577, disc_loss = 0.11537161500820396
Trained batch 98 in epoch 8, gen_loss = 0.41238788643268626, disc_loss = 0.11708053465782091
Trained batch 99 in epoch 8, gen_loss = 0.411161225438118, disc_loss = 0.117390006640926
Trained batch 100 in epoch 8, gen_loss = 0.4110443320604834, disc_loss = 0.11714353073978483
Trained batch 101 in epoch 8, gen_loss = 0.4108184441631916, disc_loss = 0.1169810691099687
Trained batch 102 in epoch 8, gen_loss = 0.4108573559997151, disc_loss = 0.11626288447601413
Trained batch 103 in epoch 8, gen_loss = 0.4103875793516636, disc_loss = 0.11626857892574313
Trained batch 104 in epoch 8, gen_loss = 0.4106695490224021, disc_loss = 0.11660327543282793
Trained batch 105 in epoch 8, gen_loss = 0.4110263386424982, disc_loss = 0.11582229919907339
Trained batch 106 in epoch 8, gen_loss = 0.41067239948522266, disc_loss = 0.11573418321209812
Trained batch 107 in epoch 8, gen_loss = 0.4106658446016135, disc_loss = 0.1155509805324039
Trained batch 108 in epoch 8, gen_loss = 0.41030541773236123, disc_loss = 0.11481927209661914
Trained batch 109 in epoch 8, gen_loss = 0.41143778372894635, disc_loss = 0.11443140307780017
Trained batch 110 in epoch 8, gen_loss = 0.4114412198195586, disc_loss = 0.11410030834209006
Trained batch 111 in epoch 8, gen_loss = 0.41107984552425997, disc_loss = 0.11361104689837832
Trained batch 112 in epoch 8, gen_loss = 0.41143361472450524, disc_loss = 0.11273269114636741
Trained batch 113 in epoch 8, gen_loss = 0.41256145139535266, disc_loss = 0.1126674405511534
Trained batch 114 in epoch 8, gen_loss = 0.4121481048024219, disc_loss = 0.11225185267951178
Trained batch 115 in epoch 8, gen_loss = 0.4120728923328992, disc_loss = 0.11202556887191945
Trained batch 116 in epoch 8, gen_loss = 0.41296146364293546, disc_loss = 0.1147007240762568
Trained batch 117 in epoch 8, gen_loss = 0.41296869642653705, disc_loss = 0.11391301490997864
Trained batch 118 in epoch 8, gen_loss = 0.41243103171597006, disc_loss = 0.11485655543183078
Trained batch 119 in epoch 8, gen_loss = 0.4122119863828023, disc_loss = 0.11456372110793987
Trained batch 120 in epoch 8, gen_loss = 0.41208598017692566, disc_loss = 0.11439688928610037
Trained batch 121 in epoch 8, gen_loss = 0.4120538718387729, disc_loss = 0.11367911992014432
Trained batch 122 in epoch 8, gen_loss = 0.41161808420002943, disc_loss = 0.11413629789177965
Trained batch 123 in epoch 8, gen_loss = 0.4126972039380381, disc_loss = 0.11390109594550825
Trained batch 124 in epoch 8, gen_loss = 0.41311323618888857, disc_loss = 0.1132511826455593
Trained batch 125 in epoch 8, gen_loss = 0.41339938271613347, disc_loss = 0.11344329454004765
Trained batch 126 in epoch 8, gen_loss = 0.4130845557986282, disc_loss = 0.1133269855063262
Trained batch 127 in epoch 8, gen_loss = 0.4130695026833564, disc_loss = 0.11290728763560764
Trained batch 128 in epoch 8, gen_loss = 0.4134397952593574, disc_loss = 0.11338978436912676
Trained batch 129 in epoch 8, gen_loss = 0.4134729511462725, disc_loss = 0.11337107485876634
Trained batch 130 in epoch 8, gen_loss = 0.413108650964635, disc_loss = 0.11322111343495718
Trained batch 131 in epoch 8, gen_loss = 0.4125344364932089, disc_loss = 0.11382067810292497
Trained batch 132 in epoch 8, gen_loss = 0.41271790324297164, disc_loss = 0.11399678468592185
Trained batch 133 in epoch 8, gen_loss = 0.4122406838100348, disc_loss = 0.11400601409598073
Trained batch 134 in epoch 8, gen_loss = 0.41182190930401835, disc_loss = 0.11407023141229594
Trained batch 135 in epoch 8, gen_loss = 0.4113193022854188, disc_loss = 0.11441403454827036
Trained batch 136 in epoch 8, gen_loss = 0.41107553026101884, disc_loss = 0.11458814212114271
Trained batch 137 in epoch 8, gen_loss = 0.41142445349175, disc_loss = 0.11442388461875742
Trained batch 138 in epoch 8, gen_loss = 0.4112406233660609, disc_loss = 0.11575937804451092
Trained batch 139 in epoch 8, gen_loss = 0.4115854874253273, disc_loss = 0.1163025344855019
Trained batch 140 in epoch 8, gen_loss = 0.41151660236906495, disc_loss = 0.11650349884062794
Trained batch 141 in epoch 8, gen_loss = 0.4112067377903092, disc_loss = 0.1179424985771028
Trained batch 142 in epoch 8, gen_loss = 0.4111946029262943, disc_loss = 0.11746538011031551
Trained batch 143 in epoch 8, gen_loss = 0.41132204172511894, disc_loss = 0.11786106345243752
Trained batch 144 in epoch 8, gen_loss = 0.41085058717892087, disc_loss = 0.11787611700851341
Trained batch 145 in epoch 8, gen_loss = 0.41036840171030126, disc_loss = 0.11840225758719934
Trained batch 146 in epoch 8, gen_loss = 0.41037046503858504, disc_loss = 0.11856177370665835
Trained batch 147 in epoch 8, gen_loss = 0.4104128536340353, disc_loss = 0.11904594163737588
Trained batch 148 in epoch 8, gen_loss = 0.4099298245554802, disc_loss = 0.11869513540959999
Trained batch 149 in epoch 8, gen_loss = 0.40975322743256887, disc_loss = 0.11864313008884589
Trained batch 150 in epoch 8, gen_loss = 0.4098871395682657, disc_loss = 0.11829699321791826
Trained batch 151 in epoch 8, gen_loss = 0.41007534179248306, disc_loss = 0.11787151334513175
Trained batch 152 in epoch 8, gen_loss = 0.41005805271123746, disc_loss = 0.11731989591632014
Trained batch 153 in epoch 8, gen_loss = 0.40993622080846265, disc_loss = 0.11743353585434424
Trained batch 154 in epoch 8, gen_loss = 0.4104560475195608, disc_loss = 0.11769036436753888
Trained batch 155 in epoch 8, gen_loss = 0.41052060631605297, disc_loss = 0.11716359591063781
Trained batch 156 in epoch 8, gen_loss = 0.41032005628203133, disc_loss = 0.1168477551382818
Trained batch 157 in epoch 8, gen_loss = 0.41040652084954177, disc_loss = 0.11687230337646944
Trained batch 158 in epoch 8, gen_loss = 0.4101687304253848, disc_loss = 0.11665716790740595
Trained batch 159 in epoch 8, gen_loss = 0.4101945847272873, disc_loss = 0.11673294208012522
Trained batch 160 in epoch 8, gen_loss = 0.4101576531155509, disc_loss = 0.11617635595409767
Trained batch 161 in epoch 8, gen_loss = 0.41065454685393676, disc_loss = 0.1155441205051762
Trained batch 162 in epoch 8, gen_loss = 0.41042388143714953, disc_loss = 0.11497040032380564
Trained batch 163 in epoch 8, gen_loss = 0.4104838969140518, disc_loss = 0.11465833825627114
Trained batch 164 in epoch 8, gen_loss = 0.410596685517918, disc_loss = 0.11441638473082673
Trained batch 165 in epoch 8, gen_loss = 0.4109218332422785, disc_loss = 0.11428550548896373
Trained batch 166 in epoch 8, gen_loss = 0.41093420339915565, disc_loss = 0.1136995786075999
Trained batch 167 in epoch 8, gen_loss = 0.4115524756766501, disc_loss = 0.11356287765582758
Trained batch 168 in epoch 8, gen_loss = 0.41180514407581126, disc_loss = 0.11320478476848475
Trained batch 169 in epoch 8, gen_loss = 0.411858594417572, disc_loss = 0.1126902386546135
Trained batch 170 in epoch 8, gen_loss = 0.4118533599794957, disc_loss = 0.1122181293124344
Trained batch 171 in epoch 8, gen_loss = 0.4123523547205814, disc_loss = 0.11207845629474451
Trained batch 172 in epoch 8, gen_loss = 0.41298906306999955, disc_loss = 0.11212179676301218
Trained batch 173 in epoch 8, gen_loss = 0.41289133432952835, disc_loss = 0.1118851012882145
Trained batch 174 in epoch 8, gen_loss = 0.41292634419032503, disc_loss = 0.11139954636139529
Trained batch 175 in epoch 8, gen_loss = 0.41308885745026847, disc_loss = 0.11087132244243879
Trained batch 176 in epoch 8, gen_loss = 0.41317736075422856, disc_loss = 0.11097709319980467
Trained batch 177 in epoch 8, gen_loss = 0.4128431597452485, disc_loss = 0.11169827820502976
Trained batch 178 in epoch 8, gen_loss = 0.41307241773472153, disc_loss = 0.11118966074629202
Trained batch 179 in epoch 8, gen_loss = 0.41304536478386983, disc_loss = 0.1116145355006059
Trained batch 180 in epoch 8, gen_loss = 0.41290649508244426, disc_loss = 0.11181125135382236
Trained batch 181 in epoch 8, gen_loss = 0.4130377148861413, disc_loss = 0.11150894768454217
Trained batch 182 in epoch 8, gen_loss = 0.4133819437743536, disc_loss = 0.11136401542386071
Trained batch 183 in epoch 8, gen_loss = 0.41314369618244795, disc_loss = 0.1110825166106224
Trained batch 184 in epoch 8, gen_loss = 0.4130810610345892, disc_loss = 0.11098999558268367
Trained batch 185 in epoch 8, gen_loss = 0.41308833722786237, disc_loss = 0.11114554259405342
Trained batch 186 in epoch 8, gen_loss = 0.41304207931865344, disc_loss = 0.11130847746038182
Trained batch 187 in epoch 8, gen_loss = 0.41314055469441924, disc_loss = 0.11110213343450363
Trained batch 188 in epoch 8, gen_loss = 0.4136013253025277, disc_loss = 0.11076743575552153
Trained batch 189 in epoch 8, gen_loss = 0.41394948347618704, disc_loss = 0.11038690148607681
Trained batch 190 in epoch 8, gen_loss = 0.4136153665512644, disc_loss = 0.11016672839903083
Trained batch 191 in epoch 8, gen_loss = 0.41368678910657763, disc_loss = 0.10975068122691785
Trained batch 192 in epoch 8, gen_loss = 0.41394439910977615, disc_loss = 0.1096240936590291
Trained batch 193 in epoch 8, gen_loss = 0.413901906038068, disc_loss = 0.10915335642231494
Trained batch 194 in epoch 8, gen_loss = 0.4142896306820405, disc_loss = 0.10867502801120281
Trained batch 195 in epoch 8, gen_loss = 0.41414460524612545, disc_loss = 0.10862786453027203
Trained batch 196 in epoch 8, gen_loss = 0.4140754555385125, disc_loss = 0.10898803311593944
Trained batch 197 in epoch 8, gen_loss = 0.4140060619272367, disc_loss = 0.10897667101123418
Trained batch 198 in epoch 8, gen_loss = 0.4140328203313914, disc_loss = 0.10885432696709381
Trained batch 199 in epoch 8, gen_loss = 0.41405281916260717, disc_loss = 0.10900513631291688
Trained batch 200 in epoch 8, gen_loss = 0.41432636249717786, disc_loss = 0.10864946512106936
Trained batch 201 in epoch 8, gen_loss = 0.4139988118469125, disc_loss = 0.10857640582109147
Trained batch 202 in epoch 8, gen_loss = 0.41386405646507374, disc_loss = 0.10892199962560473
Trained batch 203 in epoch 8, gen_loss = 0.41377642604650233, disc_loss = 0.10880327578086187
Trained batch 204 in epoch 8, gen_loss = 0.4140428966138421, disc_loss = 0.10920784948620854
Trained batch 205 in epoch 8, gen_loss = 0.4136977422873951, disc_loss = 0.10978024600308786
Trained batch 206 in epoch 8, gen_loss = 0.413666314980834, disc_loss = 0.10977631565273384
Trained batch 207 in epoch 8, gen_loss = 0.41390677957007516, disc_loss = 0.10965903557371348
Trained batch 208 in epoch 8, gen_loss = 0.41409034492296465, disc_loss = 0.10926348631354896
Trained batch 209 in epoch 8, gen_loss = 0.41397077512173425, disc_loss = 0.10927668001857542
Trained batch 210 in epoch 8, gen_loss = 0.4143109303232618, disc_loss = 0.10896132571260793
Trained batch 211 in epoch 8, gen_loss = 0.41440665651604813, disc_loss = 0.10888375513220452
Trained batch 212 in epoch 8, gen_loss = 0.4142560712608373, disc_loss = 0.10870436787990058
Trained batch 213 in epoch 8, gen_loss = 0.4146578420545453, disc_loss = 0.10832697857240929
Trained batch 214 in epoch 8, gen_loss = 0.4146128007145815, disc_loss = 0.10800904966890812
Trained batch 215 in epoch 8, gen_loss = 0.41508301526859953, disc_loss = 0.10781036754552689
Trained batch 216 in epoch 8, gen_loss = 0.4149790733091293, disc_loss = 0.1078855210168433
Trained batch 217 in epoch 8, gen_loss = 0.41498570417592284, disc_loss = 0.10755465978568574
Trained batch 218 in epoch 8, gen_loss = 0.41503617630157297, disc_loss = 0.10804191904491213
Trained batch 219 in epoch 8, gen_loss = 0.4148095599629662, disc_loss = 0.10859978353943336
Trained batch 220 in epoch 8, gen_loss = 0.4147740402912123, disc_loss = 0.10847445323692458
Trained batch 221 in epoch 8, gen_loss = 0.41477763787046207, disc_loss = 0.10882921267703578
Trained batch 222 in epoch 8, gen_loss = 0.4144312576328158, disc_loss = 0.10912552174397916
Trained batch 223 in epoch 8, gen_loss = 0.41436180991253685, disc_loss = 0.10961221137716036
Trained batch 224 in epoch 8, gen_loss = 0.41461911731296114, disc_loss = 0.10982663981616497
Trained batch 225 in epoch 8, gen_loss = 0.4145780878256908, disc_loss = 0.10968293789444508
Trained batch 226 in epoch 8, gen_loss = 0.4145305982507798, disc_loss = 0.10971182682407847
Trained batch 227 in epoch 8, gen_loss = 0.4144897506686679, disc_loss = 0.10953388172773677
Trained batch 228 in epoch 8, gen_loss = 0.4144153861760052, disc_loss = 0.10932049336619512
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.43934574723243713, disc_loss = 0.017330285161733627
Trained batch 1 in epoch 9, gen_loss = 0.45950861275196075, disc_loss = 0.015086360275745392
Trained batch 2 in epoch 9, gen_loss = 0.45925699671109516, disc_loss = 0.025788200398286183
Trained batch 3 in epoch 9, gen_loss = 0.4582524821162224, disc_loss = 0.04038122482597828
Trained batch 4 in epoch 9, gen_loss = 0.45042853951454165, disc_loss = 0.06844925433397293
Trained batch 5 in epoch 9, gen_loss = 0.44561806817849475, disc_loss = 0.08187585944930713
Trained batch 6 in epoch 9, gen_loss = 0.44253923637526377, disc_loss = 0.07496535458735057
Trained batch 7 in epoch 9, gen_loss = 0.4425858333706856, disc_loss = 0.07497575227171183
Trained batch 8 in epoch 9, gen_loss = 0.430363698138131, disc_loss = 0.07853148215346867
Trained batch 9 in epoch 9, gen_loss = 0.43105662763118746, disc_loss = 0.09169297516345978
Trained batch 10 in epoch 9, gen_loss = 0.4273389767516743, disc_loss = 0.08813744173808531
Trained batch 11 in epoch 9, gen_loss = 0.41991832107305527, disc_loss = 0.09124457029004891
Trained batch 12 in epoch 9, gen_loss = 0.42420894595292896, disc_loss = 0.08780993005404106
Trained batch 13 in epoch 9, gen_loss = 0.42566930821963717, disc_loss = 0.08350605185010604
Trained batch 14 in epoch 9, gen_loss = 0.42364065448443095, disc_loss = 0.08237520096202691
Trained batch 15 in epoch 9, gen_loss = 0.42087223939597607, disc_loss = 0.0819633201463148
Trained batch 16 in epoch 9, gen_loss = 0.4195062921327703, disc_loss = 0.08065019230193951
Trained batch 17 in epoch 9, gen_loss = 0.42001911004384357, disc_loss = 0.07857742915964788
Trained batch 18 in epoch 9, gen_loss = 0.42387238929146215, disc_loss = 0.08537764072810348
Trained batch 19 in epoch 9, gen_loss = 0.4206185579299927, disc_loss = 0.08856742242351175
Trained batch 20 in epoch 9, gen_loss = 0.42310048994563876, disc_loss = 0.08602377692503589
Trained batch 21 in epoch 9, gen_loss = 0.42231189527294855, disc_loss = 0.0839499586515806
Trained batch 22 in epoch 9, gen_loss = 0.4202111622561579, disc_loss = 0.08539367037946763
Trained batch 23 in epoch 9, gen_loss = 0.4223630266884963, disc_loss = 0.08329394250176847
Trained batch 24 in epoch 9, gen_loss = 0.4260582292079926, disc_loss = 0.08167428977787494
Trained batch 25 in epoch 9, gen_loss = 0.4260311768605159, disc_loss = 0.08518011645915416
Trained batch 26 in epoch 9, gen_loss = 0.42809212428552135, disc_loss = 0.08301666661821029
Trained batch 27 in epoch 9, gen_loss = 0.42689830916268484, disc_loss = 0.08051743172109127
Trained batch 28 in epoch 9, gen_loss = 0.42425162319479315, disc_loss = 0.08312201577013936
Trained batch 29 in epoch 9, gen_loss = 0.4239005078872045, disc_loss = 0.08484656984607379
Trained batch 30 in epoch 9, gen_loss = 0.42423449793169576, disc_loss = 0.08302268734382044
Trained batch 31 in epoch 9, gen_loss = 0.42476673517376184, disc_loss = 0.08147011150140315
Trained batch 32 in epoch 9, gen_loss = 0.42417081287412933, disc_loss = 0.07989031194963238
Trained batch 33 in epoch 9, gen_loss = 0.4255642242291394, disc_loss = 0.07789217165726073
Trained batch 34 in epoch 9, gen_loss = 0.4269398561545781, disc_loss = 0.0781348959675857
Trained batch 35 in epoch 9, gen_loss = 0.42828380730417037, disc_loss = 0.07750155414558119
Trained batch 36 in epoch 9, gen_loss = 0.42745922304488515, disc_loss = 0.07785420109694069
Trained batch 37 in epoch 9, gen_loss = 0.4273979122701444, disc_loss = 0.07748781193635966
Trained batch 38 in epoch 9, gen_loss = 0.4281328297578372, disc_loss = 0.07605337743193676
Trained batch 39 in epoch 9, gen_loss = 0.42880808711051943, disc_loss = 0.07542690681293607
Trained batch 40 in epoch 9, gen_loss = 0.4284266727726634, disc_loss = 0.07464889664112068
Trained batch 41 in epoch 9, gen_loss = 0.42822658447992235, disc_loss = 0.07553438726989996
Trained batch 42 in epoch 9, gen_loss = 0.42938925914986187, disc_loss = 0.0745724881457728
Trained batch 43 in epoch 9, gen_loss = 0.4298644959926605, disc_loss = 0.07571395418860695
Trained batch 44 in epoch 9, gen_loss = 0.42950292030970255, disc_loss = 0.07481467102964719
Trained batch 45 in epoch 9, gen_loss = 0.42895209400550177, disc_loss = 0.07413931612087332
Trained batch 46 in epoch 9, gen_loss = 0.42959865610650244, disc_loss = 0.07373446574870576
Trained batch 47 in epoch 9, gen_loss = 0.43256603305538494, disc_loss = 0.07561997106919686
Trained batch 48 in epoch 9, gen_loss = 0.4324480149210716, disc_loss = 0.07713229832600574
Trained batch 49 in epoch 9, gen_loss = 0.43165440440177916, disc_loss = 0.0771637973189354
Trained batch 50 in epoch 9, gen_loss = 0.43210143318363264, disc_loss = 0.0790171506358128
Trained batch 51 in epoch 9, gen_loss = 0.4312119191655746, disc_loss = 0.07804576200074874
Trained batch 52 in epoch 9, gen_loss = 0.43001520127620335, disc_loss = 0.07719016039990029
Trained batch 53 in epoch 9, gen_loss = 0.4306778262058894, disc_loss = 0.07771998747355408
Trained batch 54 in epoch 9, gen_loss = 0.4291531405665658, disc_loss = 0.07861549305644902
Trained batch 55 in epoch 9, gen_loss = 0.42876145775829044, disc_loss = 0.0783934689659093
Trained batch 56 in epoch 9, gen_loss = 0.43049615412427666, disc_loss = 0.0783770943812111
Trained batch 57 in epoch 9, gen_loss = 0.43026475248665647, disc_loss = 0.07823387475620056
Trained batch 58 in epoch 9, gen_loss = 0.42987914560204843, disc_loss = 0.0777903074177645
Trained batch 59 in epoch 9, gen_loss = 0.4308087433377902, disc_loss = 0.07677966834356388
Trained batch 60 in epoch 9, gen_loss = 0.4309452884509915, disc_loss = 0.0764652739172099
Trained batch 61 in epoch 9, gen_loss = 0.4319999684249201, disc_loss = 0.07720123862306918
Trained batch 62 in epoch 9, gen_loss = 0.43298749318198554, disc_loss = 0.07617134263827688
Trained batch 63 in epoch 9, gen_loss = 0.43319924315437675, disc_loss = 0.07602114492328838
Trained batch 64 in epoch 9, gen_loss = 0.43330663671860326, disc_loss = 0.07499339154993112
Trained batch 65 in epoch 9, gen_loss = 0.4333888685161417, disc_loss = 0.07418284710553108
Trained batch 66 in epoch 9, gen_loss = 0.4328265603798539, disc_loss = 0.07486578798505353
Trained batch 67 in epoch 9, gen_loss = 0.4325459130546626, disc_loss = 0.07723912770640762
Trained batch 68 in epoch 9, gen_loss = 0.43226481131885364, disc_loss = 0.0764120843504434
Trained batch 69 in epoch 9, gen_loss = 0.4321351817675999, disc_loss = 0.0797934128104576
Trained batch 70 in epoch 9, gen_loss = 0.4325343286487418, disc_loss = 0.0819923834035724
Trained batch 71 in epoch 9, gen_loss = 0.4318932278288735, disc_loss = 0.08183033375017759
Trained batch 72 in epoch 9, gen_loss = 0.4320497827170646, disc_loss = 0.08276921922774756
Trained batch 73 in epoch 9, gen_loss = 0.4310636145843042, disc_loss = 0.08286715604717264
Trained batch 74 in epoch 9, gen_loss = 0.43064375638961794, disc_loss = 0.08281612320492665
Trained batch 75 in epoch 9, gen_loss = 0.4303195790240639, disc_loss = 0.08369266970916406
Trained batch 76 in epoch 9, gen_loss = 0.4311723794255938, disc_loss = 0.0829492463766561
Trained batch 77 in epoch 9, gen_loss = 0.4309184287603085, disc_loss = 0.08279477832361291
Trained batch 78 in epoch 9, gen_loss = 0.43203875724273394, disc_loss = 0.08212348775160086
Trained batch 79 in epoch 9, gen_loss = 0.4313988022506237, disc_loss = 0.08169144819257781
Trained batch 80 in epoch 9, gen_loss = 0.4304477200831896, disc_loss = 0.08195921952295819
Trained batch 81 in epoch 9, gen_loss = 0.43185045479274375, disc_loss = 0.08166133447709244
Trained batch 82 in epoch 9, gen_loss = 0.4326111372694912, disc_loss = 0.08141440843198314
Trained batch 83 in epoch 9, gen_loss = 0.4322719641384624, disc_loss = 0.08193945040970686
Trained batch 84 in epoch 9, gen_loss = 0.4320708783233867, disc_loss = 0.08130648902014774
Trained batch 85 in epoch 9, gen_loss = 0.4310389895771825, disc_loss = 0.08234060948801249
Trained batch 86 in epoch 9, gen_loss = 0.43038968964554797, disc_loss = 0.08219684209760236
Trained batch 87 in epoch 9, gen_loss = 0.42973172292113304, disc_loss = 0.08210795248900964
Trained batch 88 in epoch 9, gen_loss = 0.42987323242626835, disc_loss = 0.08171363630112302
Trained batch 89 in epoch 9, gen_loss = 0.4295164386431376, disc_loss = 0.08167398707527253
Trained batch 90 in epoch 9, gen_loss = 0.42868174137649956, disc_loss = 0.0823917796958115
Trained batch 91 in epoch 9, gen_loss = 0.42811118033917056, disc_loss = 0.08175206134784156
Trained batch 92 in epoch 9, gen_loss = 0.42837524830654106, disc_loss = 0.08261404273610923
Trained batch 93 in epoch 9, gen_loss = 0.4284890309927311, disc_loss = 0.08263032430624391
Trained batch 94 in epoch 9, gen_loss = 0.42820765376091, disc_loss = 0.0835616893576164
Trained batch 95 in epoch 9, gen_loss = 0.428720242343843, disc_loss = 0.08525191487084764
Trained batch 96 in epoch 9, gen_loss = 0.4276121215721996, disc_loss = 0.08583131331719995
Trained batch 97 in epoch 9, gen_loss = 0.42736601069265484, disc_loss = 0.0856315548987869
Trained batch 98 in epoch 9, gen_loss = 0.4271700538770117, disc_loss = 0.0863810669950614
Trained batch 99 in epoch 9, gen_loss = 0.42734428703784944, disc_loss = 0.08670948936603963
Trained batch 100 in epoch 9, gen_loss = 0.4268836559045433, disc_loss = 0.08723189776744877
Trained batch 101 in epoch 9, gen_loss = 0.42646604834818375, disc_loss = 0.08765413041463961
Trained batch 102 in epoch 9, gen_loss = 0.4265174194447045, disc_loss = 0.0892065015431602
Trained batch 103 in epoch 9, gen_loss = 0.42611401356183565, disc_loss = 0.08914149659148489
Trained batch 104 in epoch 9, gen_loss = 0.42544998129208883, disc_loss = 0.09088322171675307
Trained batch 105 in epoch 9, gen_loss = 0.42547636183927645, disc_loss = 0.09059324037318803
Trained batch 106 in epoch 9, gen_loss = 0.4255649121565239, disc_loss = 0.09054554921409516
Trained batch 107 in epoch 9, gen_loss = 0.4251406741914926, disc_loss = 0.09102733577256678
Trained batch 108 in epoch 9, gen_loss = 0.4254449357133393, disc_loss = 0.09046553858820724
Trained batch 109 in epoch 9, gen_loss = 0.42500882230021736, disc_loss = 0.09024454820054499
Trained batch 110 in epoch 9, gen_loss = 0.4248883270465576, disc_loss = 0.08995182725793875
Trained batch 111 in epoch 9, gen_loss = 0.4244098061961787, disc_loss = 0.08965671066627172
Trained batch 112 in epoch 9, gen_loss = 0.4242868573792213, disc_loss = 0.09050238308026991
Trained batch 113 in epoch 9, gen_loss = 0.42364188950312764, disc_loss = 0.09032366376598938
Trained batch 114 in epoch 9, gen_loss = 0.4236649075280065, disc_loss = 0.09013772701601619
Trained batch 115 in epoch 9, gen_loss = 0.42357600557393044, disc_loss = 0.0897769066103702
Trained batch 116 in epoch 9, gen_loss = 0.4233238643560654, disc_loss = 0.08937843399456678
Trained batch 117 in epoch 9, gen_loss = 0.423475374357175, disc_loss = 0.0890201710054051
Trained batch 118 in epoch 9, gen_loss = 0.42264785185581494, disc_loss = 0.08865897079632312
Trained batch 119 in epoch 9, gen_loss = 0.4225784952441851, disc_loss = 0.08863062309877326
Trained batch 120 in epoch 9, gen_loss = 0.42255778844691505, disc_loss = 0.08898313353530878
Trained batch 121 in epoch 9, gen_loss = 0.42339053896606943, disc_loss = 0.08847775277452635
Trained batch 122 in epoch 9, gen_loss = 0.4225327900754727, disc_loss = 0.08894520989672197
Trained batch 123 in epoch 9, gen_loss = 0.423563911068824, disc_loss = 0.08963618275048511
Trained batch 124 in epoch 9, gen_loss = 0.4229221692085266, disc_loss = 0.08926392046362161
Trained batch 125 in epoch 9, gen_loss = 0.42251174341118525, disc_loss = 0.08911540469391242
Trained batch 126 in epoch 9, gen_loss = 0.42206906169418273, disc_loss = 0.08867096127282212
Trained batch 127 in epoch 9, gen_loss = 0.42238713428378105, disc_loss = 0.08844104212039383
Trained batch 128 in epoch 9, gen_loss = 0.4226922279642534, disc_loss = 0.0893438727659888
Trained batch 129 in epoch 9, gen_loss = 0.4229478379854789, disc_loss = 0.08886030921712518
Trained batch 130 in epoch 9, gen_loss = 0.422992184644437, disc_loss = 0.08840336796351289
Trained batch 131 in epoch 9, gen_loss = 0.4231454255906018, disc_loss = 0.08823813738611837
Trained batch 132 in epoch 9, gen_loss = 0.4231743709485334, disc_loss = 0.08783166881482628
Trained batch 133 in epoch 9, gen_loss = 0.4234924730080277, disc_loss = 0.08744137470763344
Trained batch 134 in epoch 9, gen_loss = 0.4235505627261268, disc_loss = 0.08702364688808167
Trained batch 135 in epoch 9, gen_loss = 0.4232833655003239, disc_loss = 0.08705064131850924
Trained batch 136 in epoch 9, gen_loss = 0.42326268009895823, disc_loss = 0.08713303330306807
Trained batch 137 in epoch 9, gen_loss = 0.42309708936490875, disc_loss = 0.08671861890352507
Trained batch 138 in epoch 9, gen_loss = 0.4229759488174384, disc_loss = 0.08637749235541058
Trained batch 139 in epoch 9, gen_loss = 0.4229855599147933, disc_loss = 0.08596518323756755
Trained batch 140 in epoch 9, gen_loss = 0.42287423488096143, disc_loss = 0.08599358661668309
Trained batch 141 in epoch 9, gen_loss = 0.42244606874358487, disc_loss = 0.08585496164832107
Trained batch 142 in epoch 9, gen_loss = 0.4228738485933184, disc_loss = 0.08538530419834635
Trained batch 143 in epoch 9, gen_loss = 0.42357327768372166, disc_loss = 0.08517361475646289
Trained batch 144 in epoch 9, gen_loss = 0.42357092273646385, disc_loss = 0.08594415765255689
Trained batch 145 in epoch 9, gen_loss = 0.42354047053480803, disc_loss = 0.08555775719426878
Trained batch 146 in epoch 9, gen_loss = 0.4240428827652315, disc_loss = 0.08520439410974988
Trained batch 147 in epoch 9, gen_loss = 0.4240430422328614, disc_loss = 0.08477231033926678
Trained batch 148 in epoch 9, gen_loss = 0.4249162559941311, disc_loss = 0.08464852554861131
Trained batch 149 in epoch 9, gen_loss = 0.4248855706055959, disc_loss = 0.0841999728915592
Trained batch 150 in epoch 9, gen_loss = 0.4248389804994823, disc_loss = 0.08453528873548405
Trained batch 151 in epoch 9, gen_loss = 0.42540761102971275, disc_loss = 0.08477804975853742
Trained batch 152 in epoch 9, gen_loss = 0.4253623123262443, disc_loss = 0.0846719084843214
Trained batch 153 in epoch 9, gen_loss = 0.4252857354941306, disc_loss = 0.08456406383714699
Trained batch 154 in epoch 9, gen_loss = 0.42493289670636575, disc_loss = 0.0845740647025166
Trained batch 155 in epoch 9, gen_loss = 0.42512243795089233, disc_loss = 0.08425940520082338
Trained batch 156 in epoch 9, gen_loss = 0.4251149310048219, disc_loss = 0.08409601995116396
Trained batch 157 in epoch 9, gen_loss = 0.42466736613195155, disc_loss = 0.08436145863931956
Trained batch 158 in epoch 9, gen_loss = 0.42480663645942257, disc_loss = 0.08429221194471766
Trained batch 159 in epoch 9, gen_loss = 0.424938865378499, disc_loss = 0.08417334881960414
Trained batch 160 in epoch 9, gen_loss = 0.4246969215618157, disc_loss = 0.08429971022057052
Trained batch 161 in epoch 9, gen_loss = 0.42485438416033616, disc_loss = 0.08414967288550587
Trained batch 162 in epoch 9, gen_loss = 0.4251393646550325, disc_loss = 0.08381724331893621
Trained batch 163 in epoch 9, gen_loss = 0.4252634150225942, disc_loss = 0.08397967906146334
Trained batch 164 in epoch 9, gen_loss = 0.42452771952657986, disc_loss = 0.08530086957934228
Trained batch 165 in epoch 9, gen_loss = 0.42509567845298585, disc_loss = 0.08571767718923917
Trained batch 166 in epoch 9, gen_loss = 0.42529464446142046, disc_loss = 0.08538595201659524
Trained batch 167 in epoch 9, gen_loss = 0.42503281789166586, disc_loss = 0.0851131879913044
Trained batch 168 in epoch 9, gen_loss = 0.42481665568944266, disc_loss = 0.08498339298230832
Trained batch 169 in epoch 9, gen_loss = 0.42465523569022906, disc_loss = 0.08468017572098795
Trained batch 170 in epoch 9, gen_loss = 0.42434469632237976, disc_loss = 0.08496438396539081
Trained batch 171 in epoch 9, gen_loss = 0.42443163398393363, disc_loss = 0.08494217939090071
Trained batch 172 in epoch 9, gen_loss = 0.4238462031232139, disc_loss = 0.08554559638669898
Trained batch 173 in epoch 9, gen_loss = 0.42413304078167885, disc_loss = 0.08562960247134511
Trained batch 174 in epoch 9, gen_loss = 0.42445197207587104, disc_loss = 0.0859656880849174
Trained batch 175 in epoch 9, gen_loss = 0.4239330386573618, disc_loss = 0.08637242360485041
Trained batch 176 in epoch 9, gen_loss = 0.4238066654757591, disc_loss = 0.0864121851032484
Trained batch 177 in epoch 9, gen_loss = 0.42414307979385507, disc_loss = 0.08743635584401448
Trained batch 178 in epoch 9, gen_loss = 0.42381633110552525, disc_loss = 0.08929186038069385
Trained batch 179 in epoch 9, gen_loss = 0.4240346857243114, disc_loss = 0.0901271014008671
Trained batch 180 in epoch 9, gen_loss = 0.4241929490592598, disc_loss = 0.08990890378883695
Trained batch 181 in epoch 9, gen_loss = 0.42392845697455356, disc_loss = 0.09020975721836254
Trained batch 182 in epoch 9, gen_loss = 0.4239666185092405, disc_loss = 0.09028329368924996
Trained batch 183 in epoch 9, gen_loss = 0.4236388062329396, disc_loss = 0.09024852314336307
Trained batch 184 in epoch 9, gen_loss = 0.4235310304809261, disc_loss = 0.08990564796872236
Trained batch 185 in epoch 9, gen_loss = 0.42334941157730677, disc_loss = 0.09022354886877121
Trained batch 186 in epoch 9, gen_loss = 0.42342803169061793, disc_loss = 0.09062167411958948
Trained batch 187 in epoch 9, gen_loss = 0.42322864145674605, disc_loss = 0.09061644408118694
Trained batch 188 in epoch 9, gen_loss = 0.42267946481073976, disc_loss = 0.09117891327551907
Trained batch 189 in epoch 9, gen_loss = 0.4228920338969482, disc_loss = 0.09092824568383788
Trained batch 190 in epoch 9, gen_loss = 0.4231826611526349, disc_loss = 0.09110223610656268
Trained batch 191 in epoch 9, gen_loss = 0.4226326333979766, disc_loss = 0.09132537916593719
Trained batch 192 in epoch 9, gen_loss = 0.42234154578317634, disc_loss = 0.09117172387732589
Trained batch 193 in epoch 9, gen_loss = 0.42184817959967347, disc_loss = 0.09096043758075108
Trained batch 194 in epoch 9, gen_loss = 0.4216153896771945, disc_loss = 0.09081617958175066
Trained batch 195 in epoch 9, gen_loss = 0.42175955264544, disc_loss = 0.09131422583298872
Trained batch 196 in epoch 9, gen_loss = 0.4221032432795781, disc_loss = 0.09118449042650498
Trained batch 197 in epoch 9, gen_loss = 0.4223950848434911, disc_loss = 0.09086939957312713
Trained batch 198 in epoch 9, gen_loss = 0.42209401382273765, disc_loss = 0.09093756271273497
Trained batch 199 in epoch 9, gen_loss = 0.42179868921637537, disc_loss = 0.09100414128508419
Trained batch 200 in epoch 9, gen_loss = 0.42144634845244944, disc_loss = 0.09109444183700566
Trained batch 201 in epoch 9, gen_loss = 0.42157668937550913, disc_loss = 0.09070989325421282
Trained batch 202 in epoch 9, gen_loss = 0.4217857700850576, disc_loss = 0.09041969957096237
Trained batch 203 in epoch 9, gen_loss = 0.421834626326374, disc_loss = 0.09042599251238155
Trained batch 204 in epoch 9, gen_loss = 0.42172595189838874, disc_loss = 0.09042773237679062
Trained batch 205 in epoch 9, gen_loss = 0.4220320593963549, disc_loss = 0.0904814944358416
Trained batch 206 in epoch 9, gen_loss = 0.42194292309203585, disc_loss = 0.0902558068614363
Trained batch 207 in epoch 9, gen_loss = 0.42172147491230416, disc_loss = 0.09022069946289636
Trained batch 208 in epoch 9, gen_loss = 0.4218623427112707, disc_loss = 0.0899293915185917
Trained batch 209 in epoch 9, gen_loss = 0.42210463257063, disc_loss = 0.09066202667142664
Trained batch 210 in epoch 9, gen_loss = 0.42197700642861463, disc_loss = 0.09127057020627492
Trained batch 211 in epoch 9, gen_loss = 0.42190006361255106, disc_loss = 0.09141453156985764
Trained batch 212 in epoch 9, gen_loss = 0.42183352720009887, disc_loss = 0.09124750103539145
Trained batch 213 in epoch 9, gen_loss = 0.4220336140873276, disc_loss = 0.09125735518461633
Trained batch 214 in epoch 9, gen_loss = 0.42156833867694055, disc_loss = 0.09106417579013248
Trained batch 215 in epoch 9, gen_loss = 0.4212323991512811, disc_loss = 0.0909442377311212
Trained batch 216 in epoch 9, gen_loss = 0.42125201637294435, disc_loss = 0.09074773838580479
Trained batch 217 in epoch 9, gen_loss = 0.4215708823379027, disc_loss = 0.09045809831196835
Trained batch 218 in epoch 9, gen_loss = 0.4213747831240092, disc_loss = 0.09068875282696665
Trained batch 219 in epoch 9, gen_loss = 0.42164569889957254, disc_loss = 0.09074656600132584
Trained batch 220 in epoch 9, gen_loss = 0.421496610296258, disc_loss = 0.09055740149413569
Trained batch 221 in epoch 9, gen_loss = 0.4212424564468968, disc_loss = 0.09025785725496642
Trained batch 222 in epoch 9, gen_loss = 0.42101408213777924, disc_loss = 0.09001826864955403
Trained batch 223 in epoch 9, gen_loss = 0.42142115999013186, disc_loss = 0.0897299584882733
Trained batch 224 in epoch 9, gen_loss = 0.42145233896043566, disc_loss = 0.08969941136737665
Trained batch 225 in epoch 9, gen_loss = 0.42117374528825813, disc_loss = 0.0903319157083082
Trained batch 226 in epoch 9, gen_loss = 0.4215496794242691, disc_loss = 0.09007146958639181
Trained batch 227 in epoch 9, gen_loss = 0.42183937498351987, disc_loss = 0.09124265183907068
Trained batch 228 in epoch 9, gen_loss = 0.4218927304297035, disc_loss = 0.09102130942371996
Testing Epoch 9
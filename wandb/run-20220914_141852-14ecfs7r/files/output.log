/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5750296115875244, disc_loss = 0.6442620754241943
Trained batch 1 in epoch 0, gen_loss = 0.5552175045013428, disc_loss = 0.5545972138643265
Trained batch 2 in epoch 0, gen_loss = 0.5259964366753896, disc_loss = 0.5730158388614655
Trained batch 3 in epoch 0, gen_loss = 0.5130768418312073, disc_loss = 0.542096234858036
Trained batch 4 in epoch 0, gen_loss = 0.5123360514640808, disc_loss = 0.5446787893772125
Trained batch 5 in epoch 0, gen_loss = 0.5063773542642593, disc_loss = 0.5040562599897385
Trained batch 6 in epoch 0, gen_loss = 0.49863761237689425, disc_loss = 0.4765284700053079
Trained batch 7 in epoch 0, gen_loss = 0.49614090099930763, disc_loss = 0.45028190687298775
Trained batch 8 in epoch 0, gen_loss = 0.4885575903786553, disc_loss = 0.41903029051091933
Trained batch 9 in epoch 0, gen_loss = 0.485135543346405, disc_loss = 0.39089206904172896
Trained batch 10 in epoch 0, gen_loss = 0.48597434163093567, disc_loss = 0.3670065606182272
Trained batch 11 in epoch 0, gen_loss = 0.4891749545931816, disc_loss = 0.34639991261065006
Trained batch 12 in epoch 0, gen_loss = 0.4869886407485375, disc_loss = 0.3282489679180659
Trained batch 13 in epoch 0, gen_loss = 0.4857359677553177, disc_loss = 0.31232542970350813
Trained batch 14 in epoch 0, gen_loss = 0.48858747680981957, disc_loss = 0.2973154659072558
Trained batch 15 in epoch 0, gen_loss = 0.4925848562270403, disc_loss = 0.28409659350290895
Trained batch 16 in epoch 0, gen_loss = 0.49658193132456613, disc_loss = 0.2714831986848046
Trained batch 17 in epoch 0, gen_loss = 0.4979787783490287, disc_loss = 0.2598102918515603
Trained batch 18 in epoch 0, gen_loss = 0.4984308559643595, disc_loss = 0.24897624081686923
Trained batch 19 in epoch 0, gen_loss = 0.49930733293294904, disc_loss = 0.2393439570441842
Trained batch 20 in epoch 0, gen_loss = 0.4979022145271301, disc_loss = 0.2310169922808806
Trained batch 21 in epoch 0, gen_loss = 0.49816799705678766, disc_loss = 0.22466852329671383
Trained batch 22 in epoch 0, gen_loss = 0.5002582384192426, disc_loss = 0.22002726874273756
Trained batch 23 in epoch 0, gen_loss = 0.49977073942621547, disc_loss = 0.21462642665331563
Trained batch 24 in epoch 0, gen_loss = 0.49925057649612425, disc_loss = 0.20888707652688027
Trained batch 25 in epoch 0, gen_loss = 0.498182285290498, disc_loss = 0.2031883389617388
Trained batch 26 in epoch 0, gen_loss = 0.49966861142052543, disc_loss = 0.19749110978510645
Trained batch 27 in epoch 0, gen_loss = 0.4998603399310793, disc_loss = 0.19244740969900573
Trained batch 28 in epoch 0, gen_loss = 0.4996414503146862, disc_loss = 0.1874927394092083
Trained batch 29 in epoch 0, gen_loss = 0.4998852620522181, disc_loss = 0.1826431499173244
Trained batch 30 in epoch 0, gen_loss = 0.5002471929596316, disc_loss = 0.17799499931354676
Trained batch 31 in epoch 0, gen_loss = 0.4989671912044287, disc_loss = 0.1742403912357986
Trained batch 32 in epoch 0, gen_loss = 0.4975003816864707, disc_loss = 0.17455926492358698
Trained batch 33 in epoch 0, gen_loss = 0.4983146681505091, disc_loss = 0.17390518766992233
Trained batch 34 in epoch 0, gen_loss = 0.49865811382021225, disc_loss = 0.17085331422942027
Trained batch 35 in epoch 0, gen_loss = 0.4971306473016739, disc_loss = 0.1686053927987814
Trained batch 36 in epoch 0, gen_loss = 0.4975099386395635, disc_loss = 0.16546852544352814
Trained batch 37 in epoch 0, gen_loss = 0.49734535970185934, disc_loss = 0.16262255314933627
Trained batch 38 in epoch 0, gen_loss = 0.49793675465461534, disc_loss = 0.15947398400077453
Trained batch 39 in epoch 0, gen_loss = 0.4981966897845268, disc_loss = 0.15624622981995345
Trained batch 40 in epoch 0, gen_loss = 0.49801126485917624, disc_loss = 0.1530644615612379
Trained batch 41 in epoch 0, gen_loss = 0.4971654400939033, disc_loss = 0.1499758864797297
Trained batch 42 in epoch 0, gen_loss = 0.4959712042364963, disc_loss = 0.14710457471394262
Trained batch 43 in epoch 0, gen_loss = 0.49564480713822623, disc_loss = 0.14444054290652275
Trained batch 44 in epoch 0, gen_loss = 0.49524567855728996, disc_loss = 0.14179044047163591
Trained batch 45 in epoch 0, gen_loss = 0.49543277530566504, disc_loss = 0.13921814391632442
Trained batch 46 in epoch 0, gen_loss = 0.4957200700932361, disc_loss = 0.13677540556230444
Trained batch 47 in epoch 0, gen_loss = 0.49460733619829017, disc_loss = 0.13456162763759494
Trained batch 48 in epoch 0, gen_loss = 0.49514287771010884, disc_loss = 0.13243851248098878
Trained batch 49 in epoch 0, gen_loss = 0.4960396856069565, disc_loss = 0.13028274461627007
Trained batch 50 in epoch 0, gen_loss = 0.4963399913965487, disc_loss = 0.1282295435667038
Trained batch 51 in epoch 0, gen_loss = 0.4967745089760193, disc_loss = 0.1266030014420931
Trained batch 52 in epoch 0, gen_loss = 0.4976083327014491, disc_loss = 0.1250842846227142
Trained batch 53 in epoch 0, gen_loss = 0.49895379443963367, disc_loss = 0.12353737804072874
Trained batch 54 in epoch 0, gen_loss = 0.49977233030579304, disc_loss = 0.12234403612938795
Trained batch 55 in epoch 0, gen_loss = 0.5001133057687964, disc_loss = 0.12244393264076539
Trained batch 56 in epoch 0, gen_loss = 0.5024125528962988, disc_loss = 0.12494811794736929
Trained batch 57 in epoch 0, gen_loss = 0.5042253933076201, disc_loss = 0.12472228500349768
Trained batch 58 in epoch 0, gen_loss = 0.5039716029571275, disc_loss = 0.12460676946882475
Trained batch 59 in epoch 0, gen_loss = 0.5054587244987487, disc_loss = 0.12356600438555082
Trained batch 60 in epoch 0, gen_loss = 0.5059795301468646, disc_loss = 0.12237903658972411
Trained batch 61 in epoch 0, gen_loss = 0.5066703067671868, disc_loss = 0.12095611969069127
Trained batch 62 in epoch 0, gen_loss = 0.5064636762180026, disc_loss = 0.1195547744513504
Trained batch 63 in epoch 0, gen_loss = 0.5061120926402509, disc_loss = 0.1181389166158624
Trained batch 64 in epoch 0, gen_loss = 0.5065901815891266, disc_loss = 0.1166707864174476
Trained batch 65 in epoch 0, gen_loss = 0.5068967762318525, disc_loss = 0.11519351985418436
Trained batch 66 in epoch 0, gen_loss = 0.5065241673989083, disc_loss = 0.11377501988144063
Trained batch 67 in epoch 0, gen_loss = 0.5066630651845652, disc_loss = 0.11235533282160759
Trained batch 68 in epoch 0, gen_loss = 0.506881779950598, disc_loss = 0.11095660633367041
Trained batch 69 in epoch 0, gen_loss = 0.50669609776565, disc_loss = 0.10969497697161777
Trained batch 70 in epoch 0, gen_loss = 0.5065683915581501, disc_loss = 0.10841707523230096
Trained batch 71 in epoch 0, gen_loss = 0.5062785036861897, disc_loss = 0.10712888898948829
Trained batch 72 in epoch 0, gen_loss = 0.5064808354802328, disc_loss = 0.10592351210852193
Trained batch 73 in epoch 0, gen_loss = 0.5062233878148569, disc_loss = 0.10475421465329222
Trained batch 74 in epoch 0, gen_loss = 0.5063672971725464, disc_loss = 0.10373145312070847
Trained batch 75 in epoch 0, gen_loss = 0.506862978401937, disc_loss = 0.1026077424911292
Trained batch 76 in epoch 0, gen_loss = 0.5075113378561936, disc_loss = 0.10162489183924416
Trained batch 77 in epoch 0, gen_loss = 0.5084634629579691, disc_loss = 0.10057146340990678
Trained batch 78 in epoch 0, gen_loss = 0.5086219763454003, disc_loss = 0.09955033735383916
Trained batch 79 in epoch 0, gen_loss = 0.5088021472096443, disc_loss = 0.09852157977875323
Trained batch 80 in epoch 0, gen_loss = 0.5095443644641359, disc_loss = 0.09756155339656053
Trained batch 81 in epoch 0, gen_loss = 0.5098731844890408, disc_loss = 0.09660154256242805
Trained batch 82 in epoch 0, gen_loss = 0.5099063350493649, disc_loss = 0.09562796711113798
Trained batch 83 in epoch 0, gen_loss = 0.5102681985923222, disc_loss = 0.09469307732901402
Trained batch 84 in epoch 0, gen_loss = 0.5101908852072323, disc_loss = 0.09373538301271551
Trained batch 85 in epoch 0, gen_loss = 0.5100195487571317, disc_loss = 0.09280305966561617
Trained batch 86 in epoch 0, gen_loss = 0.5097441255361185, disc_loss = 0.09187658977876792
Trained batch 87 in epoch 0, gen_loss = 0.5101066224954345, disc_loss = 0.09096044929571111
Trained batch 88 in epoch 0, gen_loss = 0.5099766308002258, disc_loss = 0.09007456194441975
Trained batch 89 in epoch 0, gen_loss = 0.5096251593695746, disc_loss = 0.08919124579471019
Trained batch 90 in epoch 0, gen_loss = 0.5100899672770238, disc_loss = 0.08833826698649389
Trained batch 91 in epoch 0, gen_loss = 0.5100275621466015, disc_loss = 0.08752256404082089
Trained batch 92 in epoch 0, gen_loss = 0.5100447061241314, disc_loss = 0.08671933399533392
Trained batch 93 in epoch 0, gen_loss = 0.510029120014069, disc_loss = 0.08592697148746316
Trained batch 94 in epoch 0, gen_loss = 0.5101298476520337, disc_loss = 0.08514330323393407
Trained batch 95 in epoch 0, gen_loss = 0.5097612428168455, disc_loss = 0.08437296735549656
Trained batch 96 in epoch 0, gen_loss = 0.5094951833646322, disc_loss = 0.08361310401412937
Trained batch 97 in epoch 0, gen_loss = 0.5092006219284875, disc_loss = 0.08286600535241317
Trained batch 98 in epoch 0, gen_loss = 0.5092523245498387, disc_loss = 0.08214840633474817
Trained batch 99 in epoch 0, gen_loss = 0.5088669216632843, disc_loss = 0.08142730886116624
Trained batch 100 in epoch 0, gen_loss = 0.509100618928966, disc_loss = 0.08072399694730739
Trained batch 101 in epoch 0, gen_loss = 0.5088691875046375, disc_loss = 0.08004789764755497
Trained batch 102 in epoch 0, gen_loss = 0.5087639596855756, disc_loss = 0.07936738870893288
Trained batch 103 in epoch 0, gen_loss = 0.5087157046565642, disc_loss = 0.07869612475713858
Trained batch 104 in epoch 0, gen_loss = 0.5082460264364879, disc_loss = 0.07803034784183616
Trained batch 105 in epoch 0, gen_loss = 0.5080402232003662, disc_loss = 0.07739407902161749
Trained batch 106 in epoch 0, gen_loss = 0.5080711760810602, disc_loss = 0.07678080951603496
Trained batch 107 in epoch 0, gen_loss = 0.508188359439373, disc_loss = 0.07615843873160581
Trained batch 108 in epoch 0, gen_loss = 0.5079710737827721, disc_loss = 0.0755334110896385
Trained batch 109 in epoch 0, gen_loss = 0.5081427116285671, disc_loss = 0.0749269623563371
Trained batch 110 in epoch 0, gen_loss = 0.5078923358573569, disc_loss = 0.07433686123506443
Trained batch 111 in epoch 0, gen_loss = 0.5077180394104549, disc_loss = 0.07377976484297376
Trained batch 112 in epoch 0, gen_loss = 0.5080345246644147, disc_loss = 0.07322530441019123
Trained batch 113 in epoch 0, gen_loss = 0.5074451709525627, disc_loss = 0.0727896713161547
Trained batch 114 in epoch 0, gen_loss = 0.5070233381312826, disc_loss = 0.07235464684503234
Trained batch 115 in epoch 0, gen_loss = 0.506882323273297, disc_loss = 0.07181889646493926
Trained batch 116 in epoch 0, gen_loss = 0.5069070025386974, disc_loss = 0.07134366604602999
Trained batch 117 in epoch 0, gen_loss = 0.5071356321795512, disc_loss = 0.07081836645128363
Trained batch 118 in epoch 0, gen_loss = 0.5070059324512962, disc_loss = 0.07032413947388154
Trained batch 119 in epoch 0, gen_loss = 0.5071009074648222, disc_loss = 0.06981460227786253
Trained batch 120 in epoch 0, gen_loss = 0.507132906559085, disc_loss = 0.06933449906073819
Trained batch 121 in epoch 0, gen_loss = 0.5071103704757378, disc_loss = 0.06886892553541016
Trained batch 122 in epoch 0, gen_loss = 0.5072288770016616, disc_loss = 0.06841496799171455
Trained batch 123 in epoch 0, gen_loss = 0.5069127851916898, disc_loss = 0.06797742566484358
Trained batch 124 in epoch 0, gen_loss = 0.5065536313056945, disc_loss = 0.06755517622828483
Trained batch 125 in epoch 0, gen_loss = 0.5065907916379353, disc_loss = 0.06715753840075599
Trained batch 126 in epoch 0, gen_loss = 0.5066935804885203, disc_loss = 0.06675651167908053
Trained batch 127 in epoch 0, gen_loss = 0.5063351814169437, disc_loss = 0.06645094190025702
Trained batch 128 in epoch 0, gen_loss = 0.5061209691587345, disc_loss = 0.06622560411807178
Trained batch 129 in epoch 0, gen_loss = 0.5063327628832597, disc_loss = 0.06583945487554256
Trained batch 130 in epoch 0, gen_loss = 0.5062249464388112, disc_loss = 0.06556799801649484
Trained batch 131 in epoch 0, gen_loss = 0.505674463104118, disc_loss = 0.06562952995018075
Trained batch 132 in epoch 0, gen_loss = 0.5062922873443231, disc_loss = 0.06610295830532573
Trained batch 133 in epoch 0, gen_loss = 0.5060835954413485, disc_loss = 0.06613414805493693
Trained batch 134 in epoch 0, gen_loss = 0.5056460367308723, disc_loss = 0.06585556946142956
Trained batch 135 in epoch 0, gen_loss = 0.5057734198430005, disc_loss = 0.06552419593722067
Trained batch 136 in epoch 0, gen_loss = 0.5056442814151736, disc_loss = 0.0651813059039142
Trained batch 137 in epoch 0, gen_loss = 0.5059548180172408, disc_loss = 0.0648493256986789
Trained batch 138 in epoch 0, gen_loss = 0.505450658232188, disc_loss = 0.06458516851764359
Trained batch 139 in epoch 0, gen_loss = 0.5055367278201239, disc_loss = 0.06429942042699882
Trained batch 140 in epoch 0, gen_loss = 0.5052163746762783, disc_loss = 0.06402126469827712
Trained batch 141 in epoch 0, gen_loss = 0.5053988672058347, disc_loss = 0.06370352982530292
Trained batch 142 in epoch 0, gen_loss = 0.5058592955966096, disc_loss = 0.06337323625917202
Trained batch 143 in epoch 0, gen_loss = 0.5060822630508078, disc_loss = 0.06302478992923473
Trained batch 144 in epoch 0, gen_loss = 0.5060980881082601, disc_loss = 0.06265752178070874
Trained batch 145 in epoch 0, gen_loss = 0.5060852327167171, disc_loss = 0.06229463787366674
Trained batch 146 in epoch 0, gen_loss = 0.5060805538479163, disc_loss = 0.06199275167519543
Trained batch 147 in epoch 0, gen_loss = 0.5060348609412039, disc_loss = 0.06166268923521243
Trained batch 148 in epoch 0, gen_loss = 0.5056638881664148, disc_loss = 0.061366112921511964
Trained batch 149 in epoch 0, gen_loss = 0.5054516788323721, disc_loss = 0.061052415010829766
Trained batch 150 in epoch 0, gen_loss = 0.5055480030988226, disc_loss = 0.06080714513282508
Trained batch 151 in epoch 0, gen_loss = 0.5058062339299604, disc_loss = 0.06055495269155424
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.5905253887176514, disc_loss = 0.01642303541302681
Trained batch 1 in epoch 1, gen_loss = 0.5401850640773773, disc_loss = 0.019394567236304283
Trained batch 2 in epoch 1, gen_loss = 0.5157152314980825, disc_loss = 0.045384728660186134
Trained batch 3 in epoch 1, gen_loss = 0.5326848849654198, disc_loss = 0.052528596483170986
Trained batch 4 in epoch 1, gen_loss = 0.5380629360675812, disc_loss = 0.04800737462937832
Trained batch 5 in epoch 1, gen_loss = 0.5286938895781835, disc_loss = 0.04306278905520836
Trained batch 6 in epoch 1, gen_loss = 0.5289667121001652, disc_loss = 0.03859190456569195
Trained batch 7 in epoch 1, gen_loss = 0.5294393338263035, disc_loss = 0.03502447658684105
Trained batch 8 in epoch 1, gen_loss = 0.5212548077106476, disc_loss = 0.03245024186455541
Trained batch 9 in epoch 1, gen_loss = 0.5201652973890305, disc_loss = 0.030382068175822497
Trained batch 10 in epoch 1, gen_loss = 0.51705186475407, disc_loss = 0.028892915949902752
Trained batch 11 in epoch 1, gen_loss = 0.5138905048370361, disc_loss = 0.02752444815511505
Trained batch 12 in epoch 1, gen_loss = 0.511855994279568, disc_loss = 0.026113873562560633
Trained batch 13 in epoch 1, gen_loss = 0.5088023841381073, disc_loss = 0.02472063180591379
Trained batch 14 in epoch 1, gen_loss = 0.5062797745068868, disc_loss = 0.023548803105950356
Trained batch 15 in epoch 1, gen_loss = 0.5037828236818314, disc_loss = 0.022907939564902335
Trained batch 16 in epoch 1, gen_loss = 0.5010780762223637, disc_loss = 0.02219037722577067
Trained batch 17 in epoch 1, gen_loss = 0.49823253353436786, disc_loss = 0.021489945550759632
Trained batch 18 in epoch 1, gen_loss = 0.4993528033557691, disc_loss = 0.021038536619591087
Trained batch 19 in epoch 1, gen_loss = 0.49939967393875123, disc_loss = 0.020709467073902487
Trained batch 20 in epoch 1, gen_loss = 0.49790578087170917, disc_loss = 0.02022377033496187
Trained batch 21 in epoch 1, gen_loss = 0.4969630403952165, disc_loss = 0.01957986446690153
Trained batch 22 in epoch 1, gen_loss = 0.49678195041158923, disc_loss = 0.019051902522535427
Trained batch 23 in epoch 1, gen_loss = 0.4962163244684537, disc_loss = 0.018501848545080673
Trained batch 24 in epoch 1, gen_loss = 0.49386980295181276, disc_loss = 0.018111948389559984
Trained batch 25 in epoch 1, gen_loss = 0.4926551981614186, disc_loss = 0.017649978667927477
Trained batch 26 in epoch 1, gen_loss = 0.49103408058484393, disc_loss = 0.017220772371661884
Trained batch 27 in epoch 1, gen_loss = 0.48866589473826544, disc_loss = 0.01681301912425884
Trained batch 28 in epoch 1, gen_loss = 0.4893445999457918, disc_loss = 0.016481459911527305
Trained batch 29 in epoch 1, gen_loss = 0.4908594340085983, disc_loss = 0.016192475613206626
Trained batch 30 in epoch 1, gen_loss = 0.4894601212393853, disc_loss = 0.015836159233003855
Trained batch 31 in epoch 1, gen_loss = 0.4901593467220664, disc_loss = 0.015601369566866197
Trained batch 32 in epoch 1, gen_loss = 0.48841261502468225, disc_loss = 0.015440999008150715
Trained batch 33 in epoch 1, gen_loss = 0.48801568676443663, disc_loss = 0.01530895903980469
Trained batch 34 in epoch 1, gen_loss = 0.4876666920525687, disc_loss = 0.015082570777407715
Trained batch 35 in epoch 1, gen_loss = 0.4873325129350026, disc_loss = 0.01479912159912702
Trained batch 36 in epoch 1, gen_loss = 0.48624042079255386, disc_loss = 0.014544152906416235
Trained batch 37 in epoch 1, gen_loss = 0.4850636555960304, disc_loss = 0.014290784828756986
Trained batch 38 in epoch 1, gen_loss = 0.4839757100129739, disc_loss = 0.014056853639582792
Trained batch 39 in epoch 1, gen_loss = 0.4827791914343834, disc_loss = 0.013850936689414084
Trained batch 40 in epoch 1, gen_loss = 0.4831817499021204, disc_loss = 0.013646129609608069
Trained batch 41 in epoch 1, gen_loss = 0.48232742576372056, disc_loss = 0.013433127109670923
Trained batch 42 in epoch 1, gen_loss = 0.4814516063346419, disc_loss = 0.013237436735179535
Trained batch 43 in epoch 1, gen_loss = 0.4810153902931647, disc_loss = 0.013049453391100873
Trained batch 44 in epoch 1, gen_loss = 0.4801420662138197, disc_loss = 0.012858971487730742
Trained batch 45 in epoch 1, gen_loss = 0.47940879606682324, disc_loss = 0.012658181681257227
Trained batch 46 in epoch 1, gen_loss = 0.4783744399851941, disc_loss = 0.012472719251316912
Trained batch 47 in epoch 1, gen_loss = 0.4780204476167758, disc_loss = 0.012310238613281399
Trained batch 48 in epoch 1, gen_loss = 0.4780199035089843, disc_loss = 0.01217374209390611
Trained batch 49 in epoch 1, gen_loss = 0.4778666859865189, disc_loss = 0.012017439790070058
Trained batch 50 in epoch 1, gen_loss = 0.47760457384820076, disc_loss = 0.01186871653714893
Trained batch 51 in epoch 1, gen_loss = 0.4767705752299382, disc_loss = 0.01172719409581847
Trained batch 52 in epoch 1, gen_loss = 0.47653637685865724, disc_loss = 0.01158627705156522
Trained batch 53 in epoch 1, gen_loss = 0.47651385322765066, disc_loss = 0.011446797883965902
Trained batch 54 in epoch 1, gen_loss = 0.4767272721637379, disc_loss = 0.011315423766659064
Trained batch 55 in epoch 1, gen_loss = 0.47566443362406324, disc_loss = 0.01123200376085671
Trained batch 56 in epoch 1, gen_loss = 0.4752141686907986, disc_loss = 0.011172322107054163
Trained batch 57 in epoch 1, gen_loss = 0.4751609707700795, disc_loss = 0.011066345538109028
Trained batch 58 in epoch 1, gen_loss = 0.4759873656903283, disc_loss = 0.010966025766427233
Trained batch 59 in epoch 1, gen_loss = 0.4751892363031705, disc_loss = 0.010872627515345812
Trained batch 60 in epoch 1, gen_loss = 0.475131520970923, disc_loss = 0.010784641854831429
Trained batch 61 in epoch 1, gen_loss = 0.475050556563562, disc_loss = 0.010693988462369288
Trained batch 62 in epoch 1, gen_loss = 0.47507668818746296, disc_loss = 0.010590540725619548
Trained batch 63 in epoch 1, gen_loss = 0.47456044889986515, disc_loss = 0.010481921079190215
Trained batch 64 in epoch 1, gen_loss = 0.474193969139686, disc_loss = 0.010384931576509888
Trained batch 65 in epoch 1, gen_loss = 0.47369682788848877, disc_loss = 0.010283096153712408
Trained batch 66 in epoch 1, gen_loss = 0.47367942333221436, disc_loss = 0.010186616473817337
Trained batch 67 in epoch 1, gen_loss = 0.4733782353646615, disc_loss = 0.010098097068668507
Trained batch 68 in epoch 1, gen_loss = 0.4728293898312942, disc_loss = 0.010004613956814443
Trained batch 69 in epoch 1, gen_loss = 0.4723963060549327, disc_loss = 0.009916181729308197
Trained batch 70 in epoch 1, gen_loss = 0.4722418478676971, disc_loss = 0.009833105643030624
Trained batch 71 in epoch 1, gen_loss = 0.47235453377167386, disc_loss = 0.009751255093659792
Trained batch 72 in epoch 1, gen_loss = 0.47230297980243213, disc_loss = 0.009662566129245783
Trained batch 73 in epoch 1, gen_loss = 0.47205977826505097, disc_loss = 0.00958372578905845
Trained batch 74 in epoch 1, gen_loss = 0.47177303115526836, disc_loss = 0.009496888493498166
Trained batch 75 in epoch 1, gen_loss = 0.4722633412794063, disc_loss = 0.009425234625508127
Trained batch 76 in epoch 1, gen_loss = 0.4717871879602408, disc_loss = 0.009345760357312181
Trained batch 77 in epoch 1, gen_loss = 0.4715827046296535, disc_loss = 0.009273392930388069
Trained batch 78 in epoch 1, gen_loss = 0.4713938100428521, disc_loss = 0.00920293534681484
Trained batch 79 in epoch 1, gen_loss = 0.4713222779333591, disc_loss = 0.009128514866461046
Trained batch 80 in epoch 1, gen_loss = 0.4715208654050474, disc_loss = 0.009067101636901498
Trained batch 81 in epoch 1, gen_loss = 0.4714076573528895, disc_loss = 0.009022902052781386
Trained batch 82 in epoch 1, gen_loss = 0.471182334494878, disc_loss = 0.008974787742684943
Trained batch 83 in epoch 1, gen_loss = 0.47070444871981937, disc_loss = 0.00892498268513009
Trained batch 84 in epoch 1, gen_loss = 0.47062636719030493, disc_loss = 0.008870144788285388
Trained batch 85 in epoch 1, gen_loss = 0.47004959229813065, disc_loss = 0.008810716897769029
Trained batch 86 in epoch 1, gen_loss = 0.46952679102448214, disc_loss = 0.00874613633850354
Trained batch 87 in epoch 1, gen_loss = 0.46839199689301575, disc_loss = 0.008749394026711921
Trained batch 88 in epoch 1, gen_loss = 0.4682349395216181, disc_loss = 0.008809800338251203
Trained batch 89 in epoch 1, gen_loss = 0.46789744562572905, disc_loss = 0.008802492414704627
Trained batch 90 in epoch 1, gen_loss = 0.4675099908650576, disc_loss = 0.008803280269993203
Trained batch 91 in epoch 1, gen_loss = 0.46770968774090643, disc_loss = 0.008802675029627331
Trained batch 92 in epoch 1, gen_loss = 0.4675852246181939, disc_loss = 0.008789141216785997
Trained batch 93 in epoch 1, gen_loss = 0.4672274576856735, disc_loss = 0.008915784218883577
Trained batch 94 in epoch 1, gen_loss = 0.46835405952052067, disc_loss = 0.009006124288824044
Trained batch 95 in epoch 1, gen_loss = 0.4688066244125366, disc_loss = 0.009115867709624581
Trained batch 96 in epoch 1, gen_loss = 0.46820421839497756, disc_loss = 0.009369693970134886
Trained batch 97 in epoch 1, gen_loss = 0.46861490151103663, disc_loss = 0.009406375190319151
Trained batch 98 in epoch 1, gen_loss = 0.4691219073955459, disc_loss = 0.009467303211979493
Trained batch 99 in epoch 1, gen_loss = 0.4695107588171959, disc_loss = 0.009491050126962363
Trained batch 100 in epoch 1, gen_loss = 0.4695228329389402, disc_loss = 0.009478760786391425
Trained batch 101 in epoch 1, gen_loss = 0.4694388745462193, disc_loss = 0.009447562083711518
Trained batch 102 in epoch 1, gen_loss = 0.46972426772117615, disc_loss = 0.009423689292834221
Trained batch 103 in epoch 1, gen_loss = 0.4697806001282655, disc_loss = 0.009475984906132977
Trained batch 104 in epoch 1, gen_loss = 0.4697834903285617, disc_loss = 0.009705704459477039
Trained batch 105 in epoch 1, gen_loss = 0.47022834954396736, disc_loss = 0.010072678863510208
Trained batch 106 in epoch 1, gen_loss = 0.4699614967141196, disc_loss = 0.012448997114932983
Trained batch 107 in epoch 1, gen_loss = 0.47082265825183306, disc_loss = 0.019361439100639137
Trained batch 108 in epoch 1, gen_loss = 0.470767214484171, disc_loss = 0.02120161737494786
Trained batch 109 in epoch 1, gen_loss = 0.4697991365736181, disc_loss = 0.023587610479444264
Trained batch 110 in epoch 1, gen_loss = 0.46945545157870733, disc_loss = 0.024806469653707905
Trained batch 111 in epoch 1, gen_loss = 0.4693459751350539, disc_loss = 0.025763326831760684
Trained batch 112 in epoch 1, gen_loss = 0.4695296116107333, disc_loss = 0.026377709541239042
Trained batch 113 in epoch 1, gen_loss = 0.46958186699633014, disc_loss = 0.026633118924668485
Trained batch 114 in epoch 1, gen_loss = 0.46926678445028225, disc_loss = 0.026595474528553695
Trained batch 115 in epoch 1, gen_loss = 0.4691843313389811, disc_loss = 0.026489046177473562
Trained batch 116 in epoch 1, gen_loss = 0.4689352303488642, disc_loss = 0.02638662226784688
Trained batch 117 in epoch 1, gen_loss = 0.4688659951848499, disc_loss = 0.02623191042566451
Trained batch 118 in epoch 1, gen_loss = 0.4684650852900593, disc_loss = 0.0261326330721754
Trained batch 119 in epoch 1, gen_loss = 0.46856624682744347, disc_loss = 0.026173174823634328
Trained batch 120 in epoch 1, gen_loss = 0.4685861894414445, disc_loss = 0.026226572084340673
Trained batch 121 in epoch 1, gen_loss = 0.46872488372638577, disc_loss = 0.02638091959944758
Trained batch 122 in epoch 1, gen_loss = 0.4691526926145321, disc_loss = 0.026599622634428787
Trained batch 123 in epoch 1, gen_loss = 0.47015249753190624, disc_loss = 0.0275429479191981
Trained batch 124 in epoch 1, gen_loss = 0.470370320558548, disc_loss = 0.030688334859907625
Trained batch 125 in epoch 1, gen_loss = 0.47148422944167306, disc_loss = 0.03244938161076298
Trained batch 126 in epoch 1, gen_loss = 0.47193686488106495, disc_loss = 0.03317974136012981
Trained batch 127 in epoch 1, gen_loss = 0.472140418831259, disc_loss = 0.033784568986447994
Trained batch 128 in epoch 1, gen_loss = 0.4729906865792681, disc_loss = 0.03385897457975057
Trained batch 129 in epoch 1, gen_loss = 0.4736648724629329, disc_loss = 0.03373549754659717
Trained batch 130 in epoch 1, gen_loss = 0.47385778477173723, disc_loss = 0.03359742678047819
Trained batch 131 in epoch 1, gen_loss = 0.4736132307937651, disc_loss = 0.0335470146824126
Trained batch 132 in epoch 1, gen_loss = 0.47344401142650977, disc_loss = 0.033583392249070164
Trained batch 133 in epoch 1, gen_loss = 0.4732278022748321, disc_loss = 0.03458698864664827
Trained batch 134 in epoch 1, gen_loss = 0.4738619201713138, disc_loss = 0.03744964128429139
Trained batch 135 in epoch 1, gen_loss = 0.47360537683262544, disc_loss = 0.038177108426359206
Trained batch 136 in epoch 1, gen_loss = 0.4733726832553418, disc_loss = 0.03870283826560217
Trained batch 137 in epoch 1, gen_loss = 0.47352631843608356, disc_loss = 0.03912043483064011
Trained batch 138 in epoch 1, gen_loss = 0.4735725873665844, disc_loss = 0.03958110359209261
Trained batch 139 in epoch 1, gen_loss = 0.4733326888510159, disc_loss = 0.040205966767721944
Trained batch 140 in epoch 1, gen_loss = 0.4740550274967302, disc_loss = 0.04062133285725582
Trained batch 141 in epoch 1, gen_loss = 0.4740953044572347, disc_loss = 0.04173652290589583
Trained batch 142 in epoch 1, gen_loss = 0.47494670165168656, disc_loss = 0.045964390540925354
Trained batch 143 in epoch 1, gen_loss = 0.4749141498986218, disc_loss = 0.04764949352506341
Trained batch 144 in epoch 1, gen_loss = 0.4744692339979369, disc_loss = 0.048697806001994116
Trained batch 145 in epoch 1, gen_loss = 0.47387289204826094, disc_loss = 0.0494164150680275
Trained batch 146 in epoch 1, gen_loss = 0.47361478493327186, disc_loss = 0.04975212368556634
Trained batch 147 in epoch 1, gen_loss = 0.47367190106495005, disc_loss = 0.04987933092146508
Trained batch 148 in epoch 1, gen_loss = 0.47367359927836683, disc_loss = 0.0500269202490481
Trained batch 149 in epoch 1, gen_loss = 0.473901797135671, disc_loss = 0.050204649847000835
Trained batch 150 in epoch 1, gen_loss = 0.4738888902379977, disc_loss = 0.05098616956603645
Trained batch 151 in epoch 1, gen_loss = 0.4747908221263635, disc_loss = 0.0533922404651285
Testing Epoch 1
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.4610948860645294, disc_loss = 0.1880754977464676
Trained batch 1 in epoch 2, gen_loss = 0.4532931298017502, disc_loss = 0.1942652389407158
Trained batch 2 in epoch 2, gen_loss = 0.4486008584499359, disc_loss = 0.20768126348654428
Trained batch 3 in epoch 2, gen_loss = 0.4497932344675064, disc_loss = 0.22018222883343697
Trained batch 4 in epoch 2, gen_loss = 0.4522743999958038, disc_loss = 0.2470945507287979
Trained batch 5 in epoch 2, gen_loss = 0.444054181377093, disc_loss = 0.24282126873731613
Trained batch 6 in epoch 2, gen_loss = 0.44101202487945557, disc_loss = 0.2393202143056052
Trained batch 7 in epoch 2, gen_loss = 0.4335227385163307, disc_loss = 0.2313622422516346
Trained batch 8 in epoch 2, gen_loss = 0.43479786647690666, disc_loss = 0.22231195039219326
Trained batch 9 in epoch 2, gen_loss = 0.4355208337306976, disc_loss = 0.2133335515856743
Trained batch 10 in epoch 2, gen_loss = 0.4342328635129062, disc_loss = 0.2074116360057484
Trained batch 11 in epoch 2, gen_loss = 0.43149764835834503, disc_loss = 0.21345403293768564
Trained batch 12 in epoch 2, gen_loss = 0.4319632970369779, disc_loss = 0.23440887148563677
Trained batch 13 in epoch 2, gen_loss = 0.43059384184224264, disc_loss = 0.23925034488950456
Trained batch 14 in epoch 2, gen_loss = 0.4314728617668152, disc_loss = 0.24028399189313251
Trained batch 15 in epoch 2, gen_loss = 0.43094212748110294, disc_loss = 0.2382909031584859
Trained batch 16 in epoch 2, gen_loss = 0.430158290792914, disc_loss = 0.2352692055351594
Trained batch 17 in epoch 2, gen_loss = 0.4311395105388429, disc_loss = 0.23137136879894468
Trained batch 18 in epoch 2, gen_loss = 0.431226604863217, disc_loss = 0.22686197412641426
Trained batch 19 in epoch 2, gen_loss = 0.42789831906557085, disc_loss = 0.22329231053590776
Trained batch 20 in epoch 2, gen_loss = 0.42845724594025386, disc_loss = 0.21846547758295423
Trained batch 21 in epoch 2, gen_loss = 0.427588014440103, disc_loss = 0.21728640896352855
Trained batch 22 in epoch 2, gen_loss = 0.42943579606387927, disc_loss = 0.22089578891577927
Trained batch 23 in epoch 2, gen_loss = 0.4301310752828916, disc_loss = 0.23145091130087772
Trained batch 24 in epoch 2, gen_loss = 0.42950897336006166, disc_loss = 0.23581631749868393
Trained batch 25 in epoch 2, gen_loss = 0.4274610292453032, disc_loss = 0.23484287439630583
Trained batch 26 in epoch 2, gen_loss = 0.425604537681297, disc_loss = 0.23358930178262569
Trained batch 27 in epoch 2, gen_loss = 0.42461625060864855, disc_loss = 0.23151268251240253
Trained batch 28 in epoch 2, gen_loss = 0.42290283379883603, disc_loss = 0.2288351801448855
Trained batch 29 in epoch 2, gen_loss = 0.4234491576751073, disc_loss = 0.22557806993524235
Trained batch 30 in epoch 2, gen_loss = 0.424251857303804, disc_loss = 0.22205853486253369
Trained batch 31 in epoch 2, gen_loss = 0.4241095334291458, disc_loss = 0.2189924034755677
Trained batch 32 in epoch 2, gen_loss = 0.4245948348984574, disc_loss = 0.2169446608785427
Trained batch 33 in epoch 2, gen_loss = 0.4245750904083252, disc_loss = 0.21683012277764432
Trained batch 34 in epoch 2, gen_loss = 0.42400913408824376, disc_loss = 0.21832715336765562
Trained batch 35 in epoch 2, gen_loss = 0.42554978612396455, disc_loss = 0.22070041774875587
Trained batch 36 in epoch 2, gen_loss = 0.4238827389639777, disc_loss = 0.22032425512333173
Trained batch 37 in epoch 2, gen_loss = 0.42521889272489044, disc_loss = 0.2244210021668359
Trained batch 38 in epoch 2, gen_loss = 0.4270419432566716, disc_loss = 0.22950452929123855
Trained batch 39 in epoch 2, gen_loss = 0.42782252877950666, disc_loss = 0.23217737283557655
Trained batch 40 in epoch 2, gen_loss = 0.42740751330445453, disc_loss = 0.23233053942279117
Trained batch 41 in epoch 2, gen_loss = 0.4267710894346237, disc_loss = 0.23205524274990671
Trained batch 42 in epoch 2, gen_loss = 0.4253229658270991, disc_loss = 0.2317925624029581
Trained batch 43 in epoch 2, gen_loss = 0.4236384325406768, disc_loss = 0.2310503489253196
Trained batch 44 in epoch 2, gen_loss = 0.42228529453277586, disc_loss = 0.22962621963686414
Trained batch 45 in epoch 2, gen_loss = 0.4217910358439321, disc_loss = 0.2283539770414
Trained batch 46 in epoch 2, gen_loss = 0.41976514141610327, disc_loss = 0.2276862287457953
Trained batch 47 in epoch 2, gen_loss = 0.4181981571018696, disc_loss = 0.22645880080138645
Trained batch 48 in epoch 2, gen_loss = 0.41805110902202375, disc_loss = 0.2249316194531869
Trained batch 49 in epoch 2, gen_loss = 0.41786023795604704, disc_loss = 0.22380110666155814
Trained batch 50 in epoch 2, gen_loss = 0.41777113781255837, disc_loss = 0.22325104401976453
Trained batch 51 in epoch 2, gen_loss = 0.41779168809835726, disc_loss = 0.2231730823046886
Trained batch 52 in epoch 2, gen_loss = 0.4172013969916218, disc_loss = 0.2230189137582509
Trained batch 53 in epoch 2, gen_loss = 0.41768451035022736, disc_loss = 0.22321399535845826
Trained batch 54 in epoch 2, gen_loss = 0.4171920716762543, disc_loss = 0.22304043783382935
Trained batch 55 in epoch 2, gen_loss = 0.41743441405040876, disc_loss = 0.22303991778088467
Trained batch 56 in epoch 2, gen_loss = 0.41901427977963496, disc_loss = 0.22395376325176472
Trained batch 57 in epoch 2, gen_loss = 0.4191547519174115, disc_loss = 0.2242817011629713
Trained batch 58 in epoch 2, gen_loss = 0.41993227196952043, disc_loss = 0.2260370144652108
Trained batch 59 in epoch 2, gen_loss = 0.4214606796701749, disc_loss = 0.2272371924171845
Trained batch 60 in epoch 2, gen_loss = 0.42107314262233797, disc_loss = 0.22827378269590315
Trained batch 61 in epoch 2, gen_loss = 0.4197453130637446, disc_loss = 0.22810057057969033
Trained batch 62 in epoch 2, gen_loss = 0.4188714027404785, disc_loss = 0.22797058439917034
Trained batch 63 in epoch 2, gen_loss = 0.41892195492982864, disc_loss = 0.22703526110854
Trained batch 64 in epoch 2, gen_loss = 0.4188993380619929, disc_loss = 0.22653451481690773
Trained batch 65 in epoch 2, gen_loss = 0.4187886823307384, disc_loss = 0.22577966106208888
Trained batch 66 in epoch 2, gen_loss = 0.4180016953553726, disc_loss = 0.22516322347210416
Trained batch 67 in epoch 2, gen_loss = 0.4181284049854559, disc_loss = 0.22451524074901552
Trained batch 68 in epoch 2, gen_loss = 0.4177140982254692, disc_loss = 0.22411150377297748
Trained batch 69 in epoch 2, gen_loss = 0.4173465094396046, disc_loss = 0.2233186848461628
Trained batch 70 in epoch 2, gen_loss = 0.41717265315458807, disc_loss = 0.22263046584918467
Trained batch 71 in epoch 2, gen_loss = 0.41701392125752235, disc_loss = 0.22240868490189314
Trained batch 72 in epoch 2, gen_loss = 0.4180360999825883, disc_loss = 0.22265368546933345
Trained batch 73 in epoch 2, gen_loss = 0.41768377777692434, disc_loss = 0.22324863529285868
Trained batch 74 in epoch 2, gen_loss = 0.41762069463729856, disc_loss = 0.22246065706014634
Trained batch 75 in epoch 2, gen_loss = 0.4170726016163826, disc_loss = 0.22307476371918855
Trained batch 76 in epoch 2, gen_loss = 0.41732906714662327, disc_loss = 0.22330424953977784
Trained batch 77 in epoch 2, gen_loss = 0.4177276965899345, disc_loss = 0.2231494817787256
Trained batch 78 in epoch 2, gen_loss = 0.41737794838374176, disc_loss = 0.2223988538490066
Trained batch 79 in epoch 2, gen_loss = 0.4168084029108286, disc_loss = 0.22178932512179017
Trained batch 80 in epoch 2, gen_loss = 0.41669962325213866, disc_loss = 0.22115706707592364
Trained batch 81 in epoch 2, gen_loss = 0.4171386223013808, disc_loss = 0.21967515467507084
Trained batch 82 in epoch 2, gen_loss = 0.41754464535828095, disc_loss = 0.21880659290465965
Trained batch 83 in epoch 2, gen_loss = 0.4187276750093415, disc_loss = 0.21770058829514755
Trained batch 84 in epoch 2, gen_loss = 0.4181618308319765, disc_loss = 0.21852564224425483
Trained batch 85 in epoch 2, gen_loss = 0.418676326787749, disc_loss = 0.22013662868114406
Trained batch 86 in epoch 2, gen_loss = 0.4185602195646571, disc_loss = 0.22017396806642928
Trained batch 87 in epoch 2, gen_loss = 0.4179354438727552, disc_loss = 0.22071246201680464
Trained batch 88 in epoch 2, gen_loss = 0.41721839348921613, disc_loss = 0.22054905276954845
Trained batch 89 in epoch 2, gen_loss = 0.41699004040824045, disc_loss = 0.22022854329811203
Trained batch 90 in epoch 2, gen_loss = 0.4166662057677468, disc_loss = 0.22009248532109207
Trained batch 91 in epoch 2, gen_loss = 0.416055865585804, disc_loss = 0.22006501492274844
Trained batch 92 in epoch 2, gen_loss = 0.41572127098678263, disc_loss = 0.22054282639936734
Trained batch 93 in epoch 2, gen_loss = 0.41632527303188405, disc_loss = 0.2204896624576538
Trained batch 94 in epoch 2, gen_loss = 0.41612534805348045, disc_loss = 0.22037397944613507
Trained batch 95 in epoch 2, gen_loss = 0.4155578038965662, disc_loss = 0.22073325677774847
Trained batch 96 in epoch 2, gen_loss = 0.4157099782191601, disc_loss = 0.22073026777235502
Trained batch 97 in epoch 2, gen_loss = 0.41596932648396007, disc_loss = 0.22064131688402625
Trained batch 98 in epoch 2, gen_loss = 0.41594310992895955, disc_loss = 0.22051902514214466
Trained batch 99 in epoch 2, gen_loss = 0.4158327254652977, disc_loss = 0.22019710324704647
Trained batch 100 in epoch 2, gen_loss = 0.4156560779798149, disc_loss = 0.2201446891568675
Trained batch 101 in epoch 2, gen_loss = 0.41568077516322044, disc_loss = 0.21955815344756724
Trained batch 102 in epoch 2, gen_loss = 0.4153271896167866, disc_loss = 0.2192022404769092
Trained batch 103 in epoch 2, gen_loss = 0.4147283641191629, disc_loss = 0.2188382650940464
Trained batch 104 in epoch 2, gen_loss = 0.41416339902650745, disc_loss = 0.21857755588633673
Trained batch 105 in epoch 2, gen_loss = 0.41427858426885783, disc_loss = 0.21797943459648006
Trained batch 106 in epoch 2, gen_loss = 0.4135764681290243, disc_loss = 0.21808755613654573
Trained batch 107 in epoch 2, gen_loss = 0.4138026154703564, disc_loss = 0.21978609256998258
Trained batch 108 in epoch 2, gen_loss = 0.41457792624421075, disc_loss = 0.22141176181922265
Trained batch 109 in epoch 2, gen_loss = 0.41478856801986697, disc_loss = 0.221613582494584
Trained batch 110 in epoch 2, gen_loss = 0.41461505250887826, disc_loss = 0.22179784786862297
Trained batch 111 in epoch 2, gen_loss = 0.4143217152782849, disc_loss = 0.22152680085439766
Trained batch 112 in epoch 2, gen_loss = 0.4142614560844624, disc_loss = 0.2214012171710487
Trained batch 113 in epoch 2, gen_loss = 0.41376546521981555, disc_loss = 0.2213025454497128
Trained batch 114 in epoch 2, gen_loss = 0.41379259436026866, disc_loss = 0.22083113251820854
Trained batch 115 in epoch 2, gen_loss = 0.41325941270795363, disc_loss = 0.22050242196640063
Trained batch 116 in epoch 2, gen_loss = 0.41292299648635405, disc_loss = 0.22018206520722464
Trained batch 117 in epoch 2, gen_loss = 0.4126288820121248, disc_loss = 0.21987784256116819
Trained batch 118 in epoch 2, gen_loss = 0.41258068670745657, disc_loss = 0.21950132124313787
Trained batch 119 in epoch 2, gen_loss = 0.41268128007650373, disc_loss = 0.21899539760003486
Trained batch 120 in epoch 2, gen_loss = 0.41236004184100256, disc_loss = 0.21868180643674756
Trained batch 121 in epoch 2, gen_loss = 0.41208543469671344, disc_loss = 0.21849987442131902
Trained batch 122 in epoch 2, gen_loss = 0.41248900764356783, disc_loss = 0.21806829895188168
Trained batch 123 in epoch 2, gen_loss = 0.4123228103403122, disc_loss = 0.2176695990586473
Trained batch 124 in epoch 2, gen_loss = 0.4121614353656769, disc_loss = 0.21759679669141768
Trained batch 125 in epoch 2, gen_loss = 0.4122446207773118, disc_loss = 0.2181280862599138
Trained batch 126 in epoch 2, gen_loss = 0.4121333865199502, disc_loss = 0.21796394726188165
Trained batch 127 in epoch 2, gen_loss = 0.41222670767456293, disc_loss = 0.2176067346590571
Trained batch 128 in epoch 2, gen_loss = 0.4123943727607875, disc_loss = 0.21724052802305813
Trained batch 129 in epoch 2, gen_loss = 0.4122913411030403, disc_loss = 0.21697343467519833
Trained batch 130 in epoch 2, gen_loss = 0.41244798193451104, disc_loss = 0.2165689619101641
Trained batch 131 in epoch 2, gen_loss = 0.41274184665896674, disc_loss = 0.21596370507596116
Trained batch 132 in epoch 2, gen_loss = 0.4127721652052456, disc_loss = 0.21533811400483424
Trained batch 133 in epoch 2, gen_loss = 0.4124657109157363, disc_loss = 0.21483531110544704
Trained batch 134 in epoch 2, gen_loss = 0.4123516411693008, disc_loss = 0.21574679442025996
Trained batch 135 in epoch 2, gen_loss = 0.4126516620025915, disc_loss = 0.21670715056140633
Trained batch 136 in epoch 2, gen_loss = 0.4131029578891114, disc_loss = 0.21622291506424438
Trained batch 137 in epoch 2, gen_loss = 0.4127378835194353, disc_loss = 0.21621985922473064
Trained batch 138 in epoch 2, gen_loss = 0.4126218195013005, disc_loss = 0.21589328225353638
Trained batch 139 in epoch 2, gen_loss = 0.41254112614052635, disc_loss = 0.2152863793607269
Trained batch 140 in epoch 2, gen_loss = 0.4122807356059974, disc_loss = 0.21503250750032724
Trained batch 141 in epoch 2, gen_loss = 0.4122209977096235, disc_loss = 0.2148160835282064
Trained batch 142 in epoch 2, gen_loss = 0.4121500901825778, disc_loss = 0.21445265646789458
Trained batch 143 in epoch 2, gen_loss = 0.4120771603451835, disc_loss = 0.21450656336835688
Trained batch 144 in epoch 2, gen_loss = 0.41182379290975374, disc_loss = 0.21524719364684203
Trained batch 145 in epoch 2, gen_loss = 0.41224252034540043, disc_loss = 0.21546798796482283
Trained batch 146 in epoch 2, gen_loss = 0.41207417926820766, disc_loss = 0.21542667394795387
Trained batch 147 in epoch 2, gen_loss = 0.4116863549963848, disc_loss = 0.21531547480136962
Trained batch 148 in epoch 2, gen_loss = 0.41183005843386555, disc_loss = 0.21541412459723902
Trained batch 149 in epoch 2, gen_loss = 0.41194450577100117, disc_loss = 0.21553937678535778
Trained batch 150 in epoch 2, gen_loss = 0.4120134336269454, disc_loss = 0.21508901635345246
Trained batch 151 in epoch 2, gen_loss = 0.4117818204195876, disc_loss = 0.21489414950146488
Testing Epoch 2
Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.4095849096775055, disc_loss = 0.15667618811130524
Trained batch 1 in epoch 3, gen_loss = 0.40657177567481995, disc_loss = 0.1618684083223343
Trained batch 2 in epoch 3, gen_loss = 0.3987873395284017, disc_loss = 0.16067170600096384
Trained batch 3 in epoch 3, gen_loss = 0.4025871381163597, disc_loss = 0.1625262089073658
Trained batch 4 in epoch 3, gen_loss = 0.4024951756000519, disc_loss = 0.16215886771678925
Trained batch 5 in epoch 3, gen_loss = 0.40284232298533124, disc_loss = 0.163905568420887
Trained batch 6 in epoch 3, gen_loss = 0.40526363253593445, disc_loss = 0.16583517832415445
Trained batch 7 in epoch 3, gen_loss = 0.40333908796310425, disc_loss = 0.17624308168888092
Trained batch 8 in epoch 3, gen_loss = 0.4045616520775689, disc_loss = 0.1915259195698632
Trained batch 9 in epoch 3, gen_loss = 0.40358739495277407, disc_loss = 0.19013203978538512
Trained batch 10 in epoch 3, gen_loss = 0.39956636320460925, disc_loss = 0.19161922958764163
Trained batch 11 in epoch 3, gen_loss = 0.40061113735040027, disc_loss = 0.1911529762049516
Trained batch 12 in epoch 3, gen_loss = 0.4017245563176962, disc_loss = 0.19056384494671455
Trained batch 13 in epoch 3, gen_loss = 0.40349208457129343, disc_loss = 0.1843133643269539
Trained batch 14 in epoch 3, gen_loss = 0.40485506455103554, disc_loss = 0.18061334987481434
Trained batch 15 in epoch 3, gen_loss = 0.4059249795973301, disc_loss = 0.17839386593550444
Trained batch 16 in epoch 3, gen_loss = 0.40996479462174806, disc_loss = 0.17881105664898367
Trained batch 17 in epoch 3, gen_loss = 0.4072402020295461, disc_loss = 0.18162662618690067
Trained batch 18 in epoch 3, gen_loss = 0.40759323772631195, disc_loss = 0.18278149005613828
Trained batch 19 in epoch 3, gen_loss = 0.4052332952618599, disc_loss = 0.18168445751070977
Trained batch 20 in epoch 3, gen_loss = 0.40329363090651377, disc_loss = 0.18429453670978546
Trained batch 21 in epoch 3, gen_loss = 0.4038327661427585, disc_loss = 0.18627221137285233
Trained batch 22 in epoch 3, gen_loss = 0.4045666650585506, disc_loss = 0.18610728240531424
Trained batch 23 in epoch 3, gen_loss = 0.4053208902478218, disc_loss = 0.18640372095008692
Trained batch 24 in epoch 3, gen_loss = 0.4051896893978119, disc_loss = 0.18523382246494294
Trained batch 25 in epoch 3, gen_loss = 0.40666231513023376, disc_loss = 0.1828752329143194
Trained batch 26 in epoch 3, gen_loss = 0.40433423276300784, disc_loss = 0.18464747761134748
Trained batch 27 in epoch 3, gen_loss = 0.40557524242571424, disc_loss = 0.18242620144571578
Trained batch 28 in epoch 3, gen_loss = 0.40486342948058557, disc_loss = 0.18013270430523773
Trained batch 29 in epoch 3, gen_loss = 0.40510739187399547, disc_loss = 0.1774138224621614
Trained batch 30 in epoch 3, gen_loss = 0.405930055725959, disc_loss = 0.17556798914747854
Trained batch 31 in epoch 3, gen_loss = 0.4066958976909518, disc_loss = 0.17272745841182768
Trained batch 32 in epoch 3, gen_loss = 0.4082359319383448, disc_loss = 0.17324726622213016
Trained batch 33 in epoch 3, gen_loss = 0.40793567632927613, disc_loss = 0.17142696656724987
Trained batch 34 in epoch 3, gen_loss = 0.40875898940222605, disc_loss = 0.16839323426995959
Trained batch 35 in epoch 3, gen_loss = 0.40912771390544045, disc_loss = 0.16690926253795624
Trained batch 36 in epoch 3, gen_loss = 0.410852508770453, disc_loss = 0.16595003008842468
Trained batch 37 in epoch 3, gen_loss = 0.41392985535295385, disc_loss = 0.16187839303165674
Trained batch 38 in epoch 3, gen_loss = 0.4125929459547385, disc_loss = 0.1698196035069533
Trained batch 39 in epoch 3, gen_loss = 0.41420934349298477, disc_loss = 0.17860938697122036
Trained batch 40 in epoch 3, gen_loss = 0.4129724095507366, disc_loss = 0.17902004841442515
Trained batch 41 in epoch 3, gen_loss = 0.4128756139959608, disc_loss = 0.180861468604278
Trained batch 42 in epoch 3, gen_loss = 0.41095380103865337, disc_loss = 0.18167692782400652
Trained batch 43 in epoch 3, gen_loss = 0.4106941135092215, disc_loss = 0.1818041951734234
Trained batch 44 in epoch 3, gen_loss = 0.4120086305671268, disc_loss = 0.17933746688067914
Trained batch 45 in epoch 3, gen_loss = 0.4106822091600169, disc_loss = 0.18095739489502233
Trained batch 46 in epoch 3, gen_loss = 0.41011237717689353, disc_loss = 0.18215366290446292
Trained batch 47 in epoch 3, gen_loss = 0.4103477808336417, disc_loss = 0.18262129630117366
Trained batch 48 in epoch 3, gen_loss = 0.40945775350745844, disc_loss = 0.18210894306551437
Trained batch 49 in epoch 3, gen_loss = 0.40880835711956026, disc_loss = 0.1832779399678111
Trained batch 50 in epoch 3, gen_loss = 0.4082706944615233, disc_loss = 0.18335565438895834
Trained batch 51 in epoch 3, gen_loss = 0.40775065983717257, disc_loss = 0.182923548317586
Trained batch 52 in epoch 3, gen_loss = 0.40735321281091225, disc_loss = 0.18235401735412624
Trained batch 53 in epoch 3, gen_loss = 0.40667883555094403, disc_loss = 0.18169476267778212
Trained batch 54 in epoch 3, gen_loss = 0.40679713541811163, disc_loss = 0.17954607345163823
Trained batch 55 in epoch 3, gen_loss = 0.40649678504892756, disc_loss = 0.17742476515871072
Trained batch 56 in epoch 3, gen_loss = 0.4051300193134107, disc_loss = 0.17885043704065315
Trained batch 57 in epoch 3, gen_loss = 0.4056008052209328, disc_loss = 0.18211142471509761
Trained batch 58 in epoch 3, gen_loss = 0.4064452092526323, disc_loss = 0.1823096026240264
Trained batch 59 in epoch 3, gen_loss = 0.4057522068421046, disc_loss = 0.18204201245680451
Trained batch 60 in epoch 3, gen_loss = 0.4066035156367255, disc_loss = 0.1809429355026757
Trained batch 61 in epoch 3, gen_loss = 0.4066114382397744, disc_loss = 0.18276633607644227
Trained batch 62 in epoch 3, gen_loss = 0.4076407315239074, disc_loss = 0.18279293554997633
Trained batch 63 in epoch 3, gen_loss = 0.4073046240955591, disc_loss = 0.18226090256939642
Trained batch 64 in epoch 3, gen_loss = 0.40653150448432335, disc_loss = 0.18163153755550202
Trained batch 65 in epoch 3, gen_loss = 0.4070327692862713, disc_loss = 0.18032762766674612
Trained batch 66 in epoch 3, gen_loss = 0.4068845666166562, disc_loss = 0.1804004644891664
Trained batch 67 in epoch 3, gen_loss = 0.4069325774908066, disc_loss = 0.18095684267909212
Trained batch 68 in epoch 3, gen_loss = 0.4063197616217793, disc_loss = 0.1799679706008106
Trained batch 69 in epoch 3, gen_loss = 0.40696832622800555, disc_loss = 0.17920029086193867
Trained batch 70 in epoch 3, gen_loss = 0.4073950774233106, disc_loss = 0.1799977393165021
Trained batch 71 in epoch 3, gen_loss = 0.4082201648917463, disc_loss = 0.18237200842445922
Trained batch 72 in epoch 3, gen_loss = 0.407711776152049, disc_loss = 0.1831223759289882
Trained batch 73 in epoch 3, gen_loss = 0.407056296596656, disc_loss = 0.18335362974352934
Trained batch 74 in epoch 3, gen_loss = 0.4062764811515808, disc_loss = 0.18315973031024138
Trained batch 75 in epoch 3, gen_loss = 0.40621410349481984, disc_loss = 0.1825527457373315
Trained batch 76 in epoch 3, gen_loss = 0.40565299097593727, disc_loss = 0.1817455676614077
Trained batch 77 in epoch 3, gen_loss = 0.4053970667032095, disc_loss = 0.18124600268231753
Trained batch 78 in epoch 3, gen_loss = 0.4047926754891118, disc_loss = 0.18097687670607357
Trained batch 79 in epoch 3, gen_loss = 0.4047377463430166, disc_loss = 0.18007123766001315
Trained batch 80 in epoch 3, gen_loss = 0.40503056439352625, disc_loss = 0.17891299023212473
Trained batch 81 in epoch 3, gen_loss = 0.4047316676232873, disc_loss = 0.17878068181708817
Trained batch 82 in epoch 3, gen_loss = 0.4046527150883732, disc_loss = 0.17932651450027184
Trained batch 83 in epoch 3, gen_loss = 0.40453087183691205, disc_loss = 0.18000273741338224
Trained batch 84 in epoch 3, gen_loss = 0.40403354799046237, disc_loss = 0.18051568004576599
Trained batch 85 in epoch 3, gen_loss = 0.4039212004389874, disc_loss = 0.18052283706966527
Trained batch 86 in epoch 3, gen_loss = 0.4038868097738288, disc_loss = 0.18154981952888527
Trained batch 87 in epoch 3, gen_loss = 0.4039900607683442, disc_loss = 0.18221081892790442
Trained batch 88 in epoch 3, gen_loss = 0.4046612181020587, disc_loss = 0.18201297753898615
Trained batch 89 in epoch 3, gen_loss = 0.4038128892580668, disc_loss = 0.1820082396061884
Trained batch 90 in epoch 3, gen_loss = 0.4032734154344915, disc_loss = 0.1827302201558928
Trained batch 91 in epoch 3, gen_loss = 0.4034739946541579, disc_loss = 0.18312003461482085
Trained batch 92 in epoch 3, gen_loss = 0.4033550177851031, disc_loss = 0.18277271907095627
Trained batch 93 in epoch 3, gen_loss = 0.4033940894172547, disc_loss = 0.18223160598427057
Trained batch 94 in epoch 3, gen_loss = 0.40365916898376064, disc_loss = 0.18232078236576757
Trained batch 95 in epoch 3, gen_loss = 0.4033540577317278, disc_loss = 0.18240710796089843
Trained batch 96 in epoch 3, gen_loss = 0.4030922095185703, disc_loss = 0.18213726086638024
Trained batch 97 in epoch 3, gen_loss = 0.4031576660214638, disc_loss = 0.181934769797538
Trained batch 98 in epoch 3, gen_loss = 0.403386055219053, disc_loss = 0.18195927005750362
Trained batch 99 in epoch 3, gen_loss = 0.4035215222835541, disc_loss = 0.18152316568419338
Trained batch 100 in epoch 3, gen_loss = 0.4029178374474592, disc_loss = 0.18134418246105755
Trained batch 101 in epoch 3, gen_loss = 0.404259833927248, disc_loss = 0.18103997948049916
Trained batch 102 in epoch 3, gen_loss = 0.40397809170982213, disc_loss = 0.18058817708882893
Trained batch 103 in epoch 3, gen_loss = 0.4037578168969888, disc_loss = 0.1820321813619767
Trained batch 104 in epoch 3, gen_loss = 0.4038726003397079, disc_loss = 0.18317537078899995
Trained batch 105 in epoch 3, gen_loss = 0.4039976731786188, disc_loss = 0.18354103332912586
Trained batch 106 in epoch 3, gen_loss = 0.4034994584377681, disc_loss = 0.18401281784558407
Trained batch 107 in epoch 3, gen_loss = 0.40341478475817927, disc_loss = 0.18392978441315117
Trained batch 108 in epoch 3, gen_loss = 0.4034277731125508, disc_loss = 0.18408785444265657
Trained batch 109 in epoch 3, gen_loss = 0.4032432022419843, disc_loss = 0.1837685341015458
Trained batch 110 in epoch 3, gen_loss = 0.40322994756269026, disc_loss = 0.18402559664268214
Trained batch 111 in epoch 3, gen_loss = 0.4040806306792157, disc_loss = 0.18411839605375593
Trained batch 112 in epoch 3, gen_loss = 0.4037080064284063, disc_loss = 0.18377636582384596
Trained batch 113 in epoch 3, gen_loss = 0.4029308097404346, disc_loss = 0.18440237391347947
Trained batch 114 in epoch 3, gen_loss = 0.40297618301018423, disc_loss = 0.1843700305113326
Trained batch 115 in epoch 3, gen_loss = 0.4029514504403904, disc_loss = 0.18378304148992075
Trained batch 116 in epoch 3, gen_loss = 0.40268616187266815, disc_loss = 0.1841212714679985
Trained batch 117 in epoch 3, gen_loss = 0.40290268952563657, disc_loss = 0.18403857906933052
Trained batch 118 in epoch 3, gen_loss = 0.4028737805470699, disc_loss = 0.18354790086443185
Trained batch 119 in epoch 3, gen_loss = 0.40259146094322207, disc_loss = 0.18402028243678312
Trained batch 120 in epoch 3, gen_loss = 0.4022997102954171, disc_loss = 0.18443277562883767
Trained batch 121 in epoch 3, gen_loss = 0.4020831751041725, disc_loss = 0.1838989486673572
Trained batch 122 in epoch 3, gen_loss = 0.4016665590972435, disc_loss = 0.18319099722051524
Trained batch 123 in epoch 3, gen_loss = 0.4016109039225886, disc_loss = 0.18298332397675804
Trained batch 124 in epoch 3, gen_loss = 0.40162788939476013, disc_loss = 0.1833974518030882
Trained batch 125 in epoch 3, gen_loss = 0.4014740962357748, disc_loss = 0.18342090402508066
Trained batch 126 in epoch 3, gen_loss = 0.40149539967221537, disc_loss = 0.18316274076172218
Trained batch 127 in epoch 3, gen_loss = 0.4012923939153552, disc_loss = 0.1836321488226531
Trained batch 128 in epoch 3, gen_loss = 0.40165629728819974, disc_loss = 0.1844331374204205
Trained batch 129 in epoch 3, gen_loss = 0.4018611227090542, disc_loss = 0.18449632988239711
Trained batch 130 in epoch 3, gen_loss = 0.4015758952111688, disc_loss = 0.18436710301871972
Trained batch 131 in epoch 3, gen_loss = 0.4015646461736072, disc_loss = 0.18414912873766187
Trained batch 132 in epoch 3, gen_loss = 0.40157757150499446, disc_loss = 0.18416542199937472
Trained batch 133 in epoch 3, gen_loss = 0.40190740952740855, disc_loss = 0.18397983112163954
Trained batch 134 in epoch 3, gen_loss = 0.40199135034172623, disc_loss = 0.18372800453669494
Trained batch 135 in epoch 3, gen_loss = 0.40183667641352205, disc_loss = 0.18367161857895553
Trained batch 136 in epoch 3, gen_loss = 0.40169960129870114, disc_loss = 0.18353444461567994
Trained batch 137 in epoch 3, gen_loss = 0.4018362216327501, disc_loss = 0.183483159021083
Trained batch 138 in epoch 3, gen_loss = 0.40174456894826543, disc_loss = 0.18310503494128477
Trained batch 139 in epoch 3, gen_loss = 0.4019224051918302, disc_loss = 0.1821851549537054
Trained batch 140 in epoch 3, gen_loss = 0.4014494964416991, disc_loss = 0.18191659536397625
Trained batch 141 in epoch 3, gen_loss = 0.40180752038116185, disc_loss = 0.18225570297209728
Trained batch 142 in epoch 3, gen_loss = 0.4016351706081337, disc_loss = 0.18129412544617704
Trained batch 143 in epoch 3, gen_loss = 0.401476604036159, disc_loss = 0.18133297807071358
Trained batch 144 in epoch 3, gen_loss = 0.40150519527237993, disc_loss = 0.1811925217637728
Trained batch 145 in epoch 3, gen_loss = 0.40172671312338687, disc_loss = 0.1816132914351478
Trained batch 146 in epoch 3, gen_loss = 0.4019390362866071, disc_loss = 0.18134442971525144
Trained batch 147 in epoch 3, gen_loss = 0.4022766553066872, disc_loss = 0.18062725382529804
Trained batch 148 in epoch 3, gen_loss = 0.40264073834323244, disc_loss = 0.1807252851833633
Trained batch 149 in epoch 3, gen_loss = 0.40282149116198224, disc_loss = 0.17993478264659643
Trained batch 150 in epoch 3, gen_loss = 0.40296970337431953, disc_loss = 0.178894497626862
Trained batch 151 in epoch 3, gen_loss = 0.4027399757975026, disc_loss = 0.17927757731491797
Testing Epoch 3
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.5032111406326294, disc_loss = 0.39310067892074585
Trained batch 1 in epoch 4, gen_loss = 0.4748276323080063, disc_loss = 0.22848261147737503
Trained batch 2 in epoch 4, gen_loss = 0.4379077156384786, disc_loss = 0.31384863952795666
Trained batch 3 in epoch 4, gen_loss = 0.4311598464846611, disc_loss = 0.29173940792679787
Trained batch 4 in epoch 4, gen_loss = 0.43047029972076417, disc_loss = 0.27851223647594453
Trained batch 5 in epoch 4, gen_loss = 0.41864843169848126, disc_loss = 0.25824231654405594
Trained batch 6 in epoch 4, gen_loss = 0.41196054220199585, disc_loss = 0.26531065574714113
Trained batch 7 in epoch 4, gen_loss = 0.40703173354268074, disc_loss = 0.25433080457150936
Trained batch 8 in epoch 4, gen_loss = 0.4076387948460049, disc_loss = 0.24255667295720842
Trained batch 9 in epoch 4, gen_loss = 0.40182613134384154, disc_loss = 0.24011718034744262
Trained batch 10 in epoch 4, gen_loss = 0.39963048696517944, disc_loss = 0.2329901158809662
Trained batch 11 in epoch 4, gen_loss = 0.4003935555617015, disc_loss = 0.23265442624688148
Trained batch 12 in epoch 4, gen_loss = 0.39948017322100127, disc_loss = 0.22488405612798837
Trained batch 13 in epoch 4, gen_loss = 0.39599932730197906, disc_loss = 0.2229553067258426
Trained batch 14 in epoch 4, gen_loss = 0.3962863266468048, disc_loss = 0.21821307142575583
Trained batch 15 in epoch 4, gen_loss = 0.39771767891943455, disc_loss = 0.21209803828969598
Trained batch 16 in epoch 4, gen_loss = 0.39684632245232077, disc_loss = 0.2154021390220698
Trained batch 17 in epoch 4, gen_loss = 0.39701181319024825, disc_loss = 0.2138444139725632
Trained batch 18 in epoch 4, gen_loss = 0.39909221310364573, disc_loss = 0.20836942329218514
Trained batch 19 in epoch 4, gen_loss = 0.39873200953006743, disc_loss = 0.20251967012882233
Trained batch 20 in epoch 4, gen_loss = 0.39721724674815223, disc_loss = 0.20414192974567413
Trained batch 21 in epoch 4, gen_loss = 0.3997289551929994, disc_loss = 0.20719853924079376
Trained batch 22 in epoch 4, gen_loss = 0.400749102882717, disc_loss = 0.2026564002684925
Trained batch 23 in epoch 4, gen_loss = 0.3981551056106885, disc_loss = 0.20281546966483197
Trained batch 24 in epoch 4, gen_loss = 0.39664297580718993, disc_loss = 0.20188983172178268
Trained batch 25 in epoch 4, gen_loss = 0.39642453079040235, disc_loss = 0.20244221589886224
Trained batch 26 in epoch 4, gen_loss = 0.39713257882330155, disc_loss = 0.19989507148663202
Trained batch 27 in epoch 4, gen_loss = 0.39638478628226687, disc_loss = 0.2001653401447194
Trained batch 28 in epoch 4, gen_loss = 0.3962981104850769, disc_loss = 0.19598666475764637
Trained batch 29 in epoch 4, gen_loss = 0.3956955522298813, disc_loss = 0.1948978823920091
Trained batch 30 in epoch 4, gen_loss = 0.3979957478661691, disc_loss = 0.19519440709583222
Trained batch 31 in epoch 4, gen_loss = 0.3975200420245528, disc_loss = 0.19478110340423882
Trained batch 32 in epoch 4, gen_loss = 0.3963088591893514, disc_loss = 0.19405043238040173
Trained batch 33 in epoch 4, gen_loss = 0.3963792332831551, disc_loss = 0.1932374355109299
Trained batch 34 in epoch 4, gen_loss = 0.3987136815275465, disc_loss = 0.19193181842565538
Trained batch 35 in epoch 4, gen_loss = 0.398846040169398, disc_loss = 0.19051476298934883
Trained batch 36 in epoch 4, gen_loss = 0.40013660852973526, disc_loss = 0.1883875190003498
Trained batch 37 in epoch 4, gen_loss = 0.4013602098352031, disc_loss = 0.18582574513397718
Trained batch 38 in epoch 4, gen_loss = 0.4007486884410565, disc_loss = 0.18280662729954109
Trained batch 39 in epoch 4, gen_loss = 0.40109371170401575, disc_loss = 0.18774860594421625
Trained batch 40 in epoch 4, gen_loss = 0.40335734661032513, disc_loss = 0.19198866606485554
Trained batch 41 in epoch 4, gen_loss = 0.4031037262507847, disc_loss = 0.19143826390306154
Trained batch 42 in epoch 4, gen_loss = 0.4024539825528167, disc_loss = 0.19319634780634282
Trained batch 43 in epoch 4, gen_loss = 0.4032581678845666, disc_loss = 0.19248124059628358
Trained batch 44 in epoch 4, gen_loss = 0.40316353837649027, disc_loss = 0.19128063006533516
Trained batch 45 in epoch 4, gen_loss = 0.4037212275940439, disc_loss = 0.18954459124285242
Trained batch 46 in epoch 4, gen_loss = 0.40354784181777464, disc_loss = 0.1890529860207375
Trained batch 47 in epoch 4, gen_loss = 0.4032776951789856, disc_loss = 0.18827989976853132
Trained batch 48 in epoch 4, gen_loss = 0.4031626934907874, disc_loss = 0.1888731912690766
Trained batch 49 in epoch 4, gen_loss = 0.4019086980819702, disc_loss = 0.19193785071372985
Trained batch 50 in epoch 4, gen_loss = 0.40223729961058674, disc_loss = 0.19150752705686233
Trained batch 51 in epoch 4, gen_loss = 0.4029224279981393, disc_loss = 0.19058005454448554
Trained batch 52 in epoch 4, gen_loss = 0.40257224496805444, disc_loss = 0.19101731141783157
Trained batch 53 in epoch 4, gen_loss = 0.4026293257872264, disc_loss = 0.18983725706736246
Trained batch 54 in epoch 4, gen_loss = 0.402573042566126, disc_loss = 0.18888774785128506
Trained batch 55 in epoch 4, gen_loss = 0.4021524079144001, disc_loss = 0.18718758584665401
Trained batch 56 in epoch 4, gen_loss = 0.401579080966481, disc_loss = 0.1887562838301324
Trained batch 57 in epoch 4, gen_loss = 0.40129501809333934, disc_loss = 0.189060488779997
Trained batch 58 in epoch 4, gen_loss = 0.4010192428605031, disc_loss = 0.18878395085112523
Trained batch 59 in epoch 4, gen_loss = 0.40048610121011735, disc_loss = 0.1890417413165172
Trained batch 60 in epoch 4, gen_loss = 0.4005153193825581, disc_loss = 0.18924709091909597
Trained batch 61 in epoch 4, gen_loss = 0.40074366859851346, disc_loss = 0.18858175280113373
Trained batch 62 in epoch 4, gen_loss = 0.4010430858248756, disc_loss = 0.18771130851809942
Trained batch 63 in epoch 4, gen_loss = 0.40149728395044804, disc_loss = 0.186784079647623
Trained batch 64 in epoch 4, gen_loss = 0.4007088913367345, disc_loss = 0.18607209634322386
Trained batch 65 in epoch 4, gen_loss = 0.40060628228115314, disc_loss = 0.18465061993761497
Trained batch 66 in epoch 4, gen_loss = 0.4008392095565796, disc_loss = 0.1828884852688704
Trained batch 67 in epoch 4, gen_loss = 0.3996693382368368, disc_loss = 0.18264609542401397
Trained batch 68 in epoch 4, gen_loss = 0.4000600939211638, disc_loss = 0.1820716472423595
Trained batch 69 in epoch 4, gen_loss = 0.4005547719342368, disc_loss = 0.1821217386850289
Trained batch 70 in epoch 4, gen_loss = 0.40075029034010123, disc_loss = 0.18309544834872366
Trained batch 71 in epoch 4, gen_loss = 0.40031751576397157, disc_loss = 0.183987511218422
Trained batch 72 in epoch 4, gen_loss = 0.39962785782879345, disc_loss = 0.18449458347199715
Trained batch 73 in epoch 4, gen_loss = 0.39984465934134816, disc_loss = 0.18393400522905426
Trained batch 74 in epoch 4, gen_loss = 0.3996009639898936, disc_loss = 0.1837744332353274
Trained batch 75 in epoch 4, gen_loss = 0.39971574709603663, disc_loss = 0.1834978358329911
Trained batch 76 in epoch 4, gen_loss = 0.39969726468061473, disc_loss = 0.18293888121843338
Trained batch 77 in epoch 4, gen_loss = 0.3992155419710355, disc_loss = 0.18331524662864515
Trained batch 78 in epoch 4, gen_loss = 0.3995300799230986, disc_loss = 0.1844016808686377
Trained batch 79 in epoch 4, gen_loss = 0.3991716716438532, disc_loss = 0.18388330144807696
Trained batch 80 in epoch 4, gen_loss = 0.39849655311784626, disc_loss = 0.18370936378652666
Trained batch 81 in epoch 4, gen_loss = 0.39885484300008633, disc_loss = 0.18401221703828835
Trained batch 82 in epoch 4, gen_loss = 0.3986749857305044, disc_loss = 0.18372182018426528
Trained batch 83 in epoch 4, gen_loss = 0.3982982976096017, disc_loss = 0.18338759890979245
Trained batch 84 in epoch 4, gen_loss = 0.39879843732889964, disc_loss = 0.1826780988013043
Trained batch 85 in epoch 4, gen_loss = 0.39809378184551414, disc_loss = 0.18225955503971078
Trained batch 86 in epoch 4, gen_loss = 0.3979927482961238, disc_loss = 0.18248913402872524
Trained batch 87 in epoch 4, gen_loss = 0.39757323603738437, disc_loss = 0.18211416722359983
Trained batch 88 in epoch 4, gen_loss = 0.3971565134739608, disc_loss = 0.18230965457270654
Trained batch 89 in epoch 4, gen_loss = 0.397634325755967, disc_loss = 0.18270414231552018
Trained batch 90 in epoch 4, gen_loss = 0.39742325983204685, disc_loss = 0.18232882980789458
Trained batch 91 in epoch 4, gen_loss = 0.39755539207354834, disc_loss = 0.1812631197111762
Trained batch 92 in epoch 4, gen_loss = 0.39750321289544466, disc_loss = 0.18047995633015068
Trained batch 93 in epoch 4, gen_loss = 0.39721325832478543, disc_loss = 0.180953202650268
Trained batch 94 in epoch 4, gen_loss = 0.3972671778578507, disc_loss = 0.18102562372621736
Trained batch 95 in epoch 4, gen_loss = 0.39772841334342957, disc_loss = 0.17986068944446743
Trained batch 96 in epoch 4, gen_loss = 0.39764505010290246, disc_loss = 0.17860075597142436
Trained batch 97 in epoch 4, gen_loss = 0.3971324830639119, disc_loss = 0.17921428713111245
Trained batch 98 in epoch 4, gen_loss = 0.3976961783688478, disc_loss = 0.17963652610026223
Trained batch 99 in epoch 4, gen_loss = 0.39789333939552307, disc_loss = 0.17901936184614897
Trained batch 100 in epoch 4, gen_loss = 0.39815393414827854, disc_loss = 0.17806753305958048
Trained batch 101 in epoch 4, gen_loss = 0.39838137463027357, disc_loss = 0.177056107852681
Trained batch 102 in epoch 4, gen_loss = 0.398041776372391, disc_loss = 0.17621664626939784
Trained batch 103 in epoch 4, gen_loss = 0.39815287578564423, disc_loss = 0.17543460210212147
Trained batch 104 in epoch 4, gen_loss = 0.39832392249788556, disc_loss = 0.17492488917140733
Trained batch 105 in epoch 4, gen_loss = 0.3989614861191444, disc_loss = 0.17378044131932394
Trained batch 106 in epoch 4, gen_loss = 0.3991668642124283, disc_loss = 0.173312259159077
Trained batch 107 in epoch 4, gen_loss = 0.39930293874608147, disc_loss = 0.172729278155775
Trained batch 108 in epoch 4, gen_loss = 0.3996191590750983, disc_loss = 0.17215157112260476
Trained batch 109 in epoch 4, gen_loss = 0.39974522373893046, disc_loss = 0.17134029462256214
Trained batch 110 in epoch 4, gen_loss = 0.4001414561056876, disc_loss = 0.17043666350277695
Trained batch 111 in epoch 4, gen_loss = 0.400839847113405, disc_loss = 0.1690762212300407
Trained batch 112 in epoch 4, gen_loss = 0.401104852689051, disc_loss = 0.1694511240100966
Trained batch 113 in epoch 4, gen_loss = 0.4024032077245545, disc_loss = 0.1698230327548165
Trained batch 114 in epoch 4, gen_loss = 0.4021593477415002, disc_loss = 0.16939256842369618
Trained batch 115 in epoch 4, gen_loss = 0.40172695085920135, disc_loss = 0.17019242154241637
Trained batch 116 in epoch 4, gen_loss = 0.40193029295684946, disc_loss = 0.17012498282596597
Trained batch 117 in epoch 4, gen_loss = 0.4019279593633393, disc_loss = 0.17014028223515568
Trained batch 118 in epoch 4, gen_loss = 0.4015317328837739, disc_loss = 0.17050396510157265
Trained batch 119 in epoch 4, gen_loss = 0.4018129609525204, disc_loss = 0.17103903756166497
Trained batch 120 in epoch 4, gen_loss = 0.4015779901634563, disc_loss = 0.171429537205903
Trained batch 121 in epoch 4, gen_loss = 0.4018976541816211, disc_loss = 0.1713860664272406
Trained batch 122 in epoch 4, gen_loss = 0.40195959903360384, disc_loss = 0.17135556360206952
Trained batch 123 in epoch 4, gen_loss = 0.4020030123572196, disc_loss = 0.17148385115809017
Trained batch 124 in epoch 4, gen_loss = 0.40164159321784976, disc_loss = 0.17227681508660317
Trained batch 125 in epoch 4, gen_loss = 0.401665783827267, disc_loss = 0.17259799360874153
Trained batch 126 in epoch 4, gen_loss = 0.40165916507638344, disc_loss = 0.17233430438740985
Trained batch 127 in epoch 4, gen_loss = 0.40135290613397956, disc_loss = 0.17222082152147777
Trained batch 128 in epoch 4, gen_loss = 0.40103559785111004, disc_loss = 0.1717441542030767
Trained batch 129 in epoch 4, gen_loss = 0.40114005230940303, disc_loss = 0.17121535055339338
Trained batch 130 in epoch 4, gen_loss = 0.40096538348962335, disc_loss = 0.17162617708321745
Trained batch 131 in epoch 4, gen_loss = 0.40110763184952014, disc_loss = 0.1713367738676342
Trained batch 132 in epoch 4, gen_loss = 0.40111511968132246, disc_loss = 0.17065386661797538
Trained batch 133 in epoch 4, gen_loss = 0.4005358210250513, disc_loss = 0.17062911844409223
Trained batch 134 in epoch 4, gen_loss = 0.4004077207159113, disc_loss = 0.17069180351164606
Trained batch 135 in epoch 4, gen_loss = 0.40050409033018, disc_loss = 0.17109539762468023
Trained batch 136 in epoch 4, gen_loss = 0.40035419873077505, disc_loss = 0.1709613932473381
Trained batch 137 in epoch 4, gen_loss = 0.4003838300704956, disc_loss = 0.1703915251283974
Trained batch 138 in epoch 4, gen_loss = 0.4004133721049741, disc_loss = 0.17026397883356045
Trained batch 139 in epoch 4, gen_loss = 0.40036764932530267, disc_loss = 0.17000415152204887
Trained batch 140 in epoch 4, gen_loss = 0.40060550397169503, disc_loss = 0.16973876443209376
Trained batch 141 in epoch 4, gen_loss = 0.40073578416461675, disc_loss = 0.16912988476245336
Trained batch 142 in epoch 4, gen_loss = 0.401140924933907, disc_loss = 0.16816206889917384
Trained batch 143 in epoch 4, gen_loss = 0.4009560058928198, disc_loss = 0.16778419936437988
Trained batch 144 in epoch 4, gen_loss = 0.40154863842602434, disc_loss = 0.16816326506949705
Trained batch 145 in epoch 4, gen_loss = 0.4014912719187671, disc_loss = 0.16753713254599947
Trained batch 146 in epoch 4, gen_loss = 0.4013293308465659, disc_loss = 0.1673262605735031
Trained batch 147 in epoch 4, gen_loss = 0.40141830855124705, disc_loss = 0.16630436833696188
Trained batch 148 in epoch 4, gen_loss = 0.4009211305403869, disc_loss = 0.165988205075764
Trained batch 149 in epoch 4, gen_loss = 0.40098512430985767, disc_loss = 0.16582037420322498
Trained batch 150 in epoch 4, gen_loss = 0.4010790835153188, disc_loss = 0.16649015031952336
Trained batch 151 in epoch 4, gen_loss = 0.4010071219190171, disc_loss = 0.166286410776114
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.41688093543052673, disc_loss = 0.24891024827957153
Trained batch 1 in epoch 5, gen_loss = 0.4261590838432312, disc_loss = 0.20366079360246658
Trained batch 2 in epoch 5, gen_loss = 0.4184582432111104, disc_loss = 0.15743608276049295
Trained batch 3 in epoch 5, gen_loss = 0.4138983190059662, disc_loss = 0.14199012704193592
Trained batch 4 in epoch 5, gen_loss = 0.399354362487793, disc_loss = 0.14826220124959946
Trained batch 5 in epoch 5, gen_loss = 0.3988952189683914, disc_loss = 0.15386371687054634
Trained batch 6 in epoch 5, gen_loss = 0.40250421847615925, disc_loss = 0.16878081113100052
Trained batch 7 in epoch 5, gen_loss = 0.4054884500801563, disc_loss = 0.1586528504267335
Trained batch 8 in epoch 5, gen_loss = 0.4035147296057807, disc_loss = 0.1804939384261767
Trained batch 9 in epoch 5, gen_loss = 0.4087699860334396, disc_loss = 0.18752948120236396
Trained batch 10 in epoch 5, gen_loss = 0.4045998589559035, disc_loss = 0.1935965669426051
Trained batch 11 in epoch 5, gen_loss = 0.4064321493109067, disc_loss = 0.19538168422877789
Trained batch 12 in epoch 5, gen_loss = 0.4043888610142928, disc_loss = 0.19495075654525024
Trained batch 13 in epoch 5, gen_loss = 0.40502449444362093, disc_loss = 0.1964742216680731
Trained batch 14 in epoch 5, gen_loss = 0.4017340064048767, disc_loss = 0.19684408654769261
Trained batch 15 in epoch 5, gen_loss = 0.4044794663786888, disc_loss = 0.19725683564320207
Trained batch 16 in epoch 5, gen_loss = 0.40258150942185345, disc_loss = 0.1970585667911698
Trained batch 17 in epoch 5, gen_loss = 0.4018385062615077, disc_loss = 0.1962508000433445
Trained batch 18 in epoch 5, gen_loss = 0.4010773363866304, disc_loss = 0.19662778667713465
Trained batch 19 in epoch 5, gen_loss = 0.4018824338912964, disc_loss = 0.19599600769579412
Trained batch 20 in epoch 5, gen_loss = 0.3991540613628569, disc_loss = 0.19561515287274406
Trained batch 21 in epoch 5, gen_loss = 0.3977936248887669, disc_loss = 0.19717814536257225
Trained batch 22 in epoch 5, gen_loss = 0.3974627917227538, disc_loss = 0.20365177516056143
Trained batch 23 in epoch 5, gen_loss = 0.3952788437406222, disc_loss = 0.2061481149867177
Trained batch 24 in epoch 5, gen_loss = 0.395259028673172, disc_loss = 0.2094400045275688
Trained batch 25 in epoch 5, gen_loss = 0.39526420487807346, disc_loss = 0.21266258880496025
Trained batch 26 in epoch 5, gen_loss = 0.39430754604162993, disc_loss = 0.2160834523814696
Trained batch 27 in epoch 5, gen_loss = 0.39406740558998926, disc_loss = 0.2152056728622743
Trained batch 28 in epoch 5, gen_loss = 0.3945713259022811, disc_loss = 0.21474235710398903
Trained batch 29 in epoch 5, gen_loss = 0.3932598869005839, disc_loss = 0.21458656266331672
Trained batch 30 in epoch 5, gen_loss = 0.3927011211072245, disc_loss = 0.21437240728447515
Trained batch 31 in epoch 5, gen_loss = 0.3921290095895529, disc_loss = 0.21364380954764783
Trained batch 32 in epoch 5, gen_loss = 0.3913296036648028, disc_loss = 0.21367811411619186
Trained batch 33 in epoch 5, gen_loss = 0.3924611359834671, disc_loss = 0.2111915601965259
Trained batch 34 in epoch 5, gen_loss = 0.39505893758365085, disc_loss = 0.20765660341296877
Trained batch 35 in epoch 5, gen_loss = 0.3940405324101448, disc_loss = 0.21111455000936985
Trained batch 36 in epoch 5, gen_loss = 0.3942531508368415, disc_loss = 0.2101363662529636
Trained batch 37 in epoch 5, gen_loss = 0.39449405513311686, disc_loss = 0.21191850167356038
Trained batch 38 in epoch 5, gen_loss = 0.3946926226982704, disc_loss = 0.20802723310696772
Trained batch 39 in epoch 5, gen_loss = 0.3925613060593605, disc_loss = 0.21001013536006213
Trained batch 40 in epoch 5, gen_loss = 0.3927592220829754, disc_loss = 0.20761523904596887
Trained batch 41 in epoch 5, gen_loss = 0.3928398475760505, disc_loss = 0.20842666728865533
Trained batch 42 in epoch 5, gen_loss = 0.39354685919229376, disc_loss = 0.20625070118626884
Trained batch 43 in epoch 5, gen_loss = 0.39218456975438376, disc_loss = 0.20517000860788606
Trained batch 44 in epoch 5, gen_loss = 0.39209321075015596, disc_loss = 0.2036872641907798
Trained batch 45 in epoch 5, gen_loss = 0.3936965802441473, disc_loss = 0.2021644760085189
Trained batch 46 in epoch 5, gen_loss = 0.39325300239502115, disc_loss = 0.20131894660756944
Trained batch 47 in epoch 5, gen_loss = 0.39168623213966686, disc_loss = 0.2007907604177793
Trained batch 48 in epoch 5, gen_loss = 0.3916278645700338, disc_loss = 0.19972056880289193
Trained batch 49 in epoch 5, gen_loss = 0.39180612444877627, disc_loss = 0.2001095801591873
Trained batch 50 in epoch 5, gen_loss = 0.3913676405654234, disc_loss = 0.19931001318436042
Trained batch 51 in epoch 5, gen_loss = 0.3908606584255512, disc_loss = 0.1987254613867173
Trained batch 52 in epoch 5, gen_loss = 0.39099886226204206, disc_loss = 0.19803186154590463
Trained batch 53 in epoch 5, gen_loss = 0.3906564684929671, disc_loss = 0.19666958365727355
Trained batch 54 in epoch 5, gen_loss = 0.39090940843928945, disc_loss = 0.1956402454863895
Trained batch 55 in epoch 5, gen_loss = 0.3914825644876276, disc_loss = 0.19334669118481024
Trained batch 56 in epoch 5, gen_loss = 0.3919409623271541, disc_loss = 0.1925314102779355
Trained batch 57 in epoch 5, gen_loss = 0.3926803680329487, disc_loss = 0.19248425189791055
Trained batch 58 in epoch 5, gen_loss = 0.3925242085578078, disc_loss = 0.1925209934933711
Trained batch 59 in epoch 5, gen_loss = 0.39275973439216616, disc_loss = 0.19191200360655786
Trained batch 60 in epoch 5, gen_loss = 0.39378362796345695, disc_loss = 0.189919080157749
Trained batch 61 in epoch 5, gen_loss = 0.39409913555268317, disc_loss = 0.18877702711089964
Trained batch 62 in epoch 5, gen_loss = 0.39402514033847386, disc_loss = 0.18887932385717118
Trained batch 63 in epoch 5, gen_loss = 0.3948428579606116, disc_loss = 0.18746718915645033
Trained batch 64 in epoch 5, gen_loss = 0.39467307237478405, disc_loss = 0.18669415311171458
Trained batch 65 in epoch 5, gen_loss = 0.3952258306019234, disc_loss = 0.18488144581065033
Trained batch 66 in epoch 5, gen_loss = 0.39673451656725867, disc_loss = 0.18283057012664738
Trained batch 67 in epoch 5, gen_loss = 0.3972179254188257, disc_loss = 0.18063333318294847
Trained batch 68 in epoch 5, gen_loss = 0.3973010476084723, disc_loss = 0.17836573663289132
Trained batch 69 in epoch 5, gen_loss = 0.3977155212845121, disc_loss = 0.17648880095886332
Trained batch 70 in epoch 5, gen_loss = 0.39797462753846613, disc_loss = 0.17470345874382576
Trained batch 71 in epoch 5, gen_loss = 0.398559785551495, disc_loss = 0.17284425847335821
Trained batch 72 in epoch 5, gen_loss = 0.3992350583207117, disc_loss = 0.1708473371061152
Trained batch 73 in epoch 5, gen_loss = 0.39969084754183487, disc_loss = 0.16907108230264606
Trained batch 74 in epoch 5, gen_loss = 0.40092949708302816, disc_loss = 0.16728817957142988
Trained batch 75 in epoch 5, gen_loss = 0.40222271178898056, disc_loss = 0.1653867474708118
Trained batch 76 in epoch 5, gen_loss = 0.40373203506717437, disc_loss = 0.163416724047297
Trained batch 77 in epoch 5, gen_loss = 0.4058022231627733, disc_loss = 0.16163135558748856
Trained batch 78 in epoch 5, gen_loss = 0.40680195938182784, disc_loss = 0.1599237771256815
Trained batch 79 in epoch 5, gen_loss = 0.4079432811588049, disc_loss = 0.15878425813280045
Trained batch 80 in epoch 5, gen_loss = 0.40989229450991127, disc_loss = 0.15784183517098427
Trained batch 81 in epoch 5, gen_loss = 0.4107563564690148, disc_loss = 0.15682684616526452
Trained batch 82 in epoch 5, gen_loss = 0.41168536910091535, disc_loss = 0.15547441206423632
Trained batch 83 in epoch 5, gen_loss = 0.41252841906888144, disc_loss = 0.15401463343628816
Trained batch 84 in epoch 5, gen_loss = 0.4129340245443232, disc_loss = 0.15252870584235473
Trained batch 85 in epoch 5, gen_loss = 0.41351807914501015, disc_loss = 0.15099586319005073
Trained batch 86 in epoch 5, gen_loss = 0.412559076629836, disc_loss = 0.1517844715466102
Trained batch 87 in epoch 5, gen_loss = 0.4124224463647062, disc_loss = 0.15322976201688024
Trained batch 88 in epoch 5, gen_loss = 0.41357729876979016, disc_loss = 0.15209986895239086
Trained batch 89 in epoch 5, gen_loss = 0.413860841261016, disc_loss = 0.15081453221953578
Trained batch 90 in epoch 5, gen_loss = 0.41410835332922885, disc_loss = 0.15096261014568282
Trained batch 91 in epoch 5, gen_loss = 0.41325146445761557, disc_loss = 0.1528122777969617
Trained batch 92 in epoch 5, gen_loss = 0.41394857245106853, disc_loss = 0.15497160436565516
Trained batch 93 in epoch 5, gen_loss = 0.41512206704058546, disc_loss = 0.15402747355797825
Trained batch 94 in epoch 5, gen_loss = 0.41514699615930256, disc_loss = 0.15299129209628232
Trained batch 95 in epoch 5, gen_loss = 0.41434035636484623, disc_loss = 0.15376084412370497
Trained batch 96 in epoch 5, gen_loss = 0.4146031141281128, disc_loss = 0.15450792250789933
Trained batch 97 in epoch 5, gen_loss = 0.4149656931356508, disc_loss = 0.15534213905659866
Trained batch 98 in epoch 5, gen_loss = 0.41433969802326626, disc_loss = 0.1557437392760708
Trained batch 99 in epoch 5, gen_loss = 0.41398860603570936, disc_loss = 0.15596310725435614
Trained batch 100 in epoch 5, gen_loss = 0.41427574004277146, disc_loss = 0.1559657754542509
Trained batch 101 in epoch 5, gen_loss = 0.4136755273622625, disc_loss = 0.15613023007252053
Trained batch 102 in epoch 5, gen_loss = 0.4134318281724615, disc_loss = 0.15632214221777846
Trained batch 103 in epoch 5, gen_loss = 0.413446497458678, disc_loss = 0.15663119869378322
Trained batch 104 in epoch 5, gen_loss = 0.4134875916299366, disc_loss = 0.1569955042962517
Trained batch 105 in epoch 5, gen_loss = 0.4132847937772859, disc_loss = 0.15670177683163927
Trained batch 106 in epoch 5, gen_loss = 0.4127554698525188, disc_loss = 0.15702975678875625
Trained batch 107 in epoch 5, gen_loss = 0.4124203655454848, disc_loss = 0.15710829493279257
Trained batch 108 in epoch 5, gen_loss = 0.4121774120615163, disc_loss = 0.15732458143264327
Trained batch 109 in epoch 5, gen_loss = 0.41233129772272975, disc_loss = 0.15765411899509754
Trained batch 110 in epoch 5, gen_loss = 0.4118807699766245, disc_loss = 0.15758421391181582
Trained batch 111 in epoch 5, gen_loss = 0.41169542499950956, disc_loss = 0.15766512993390538
Trained batch 112 in epoch 5, gen_loss = 0.4118336175395324, disc_loss = 0.15836293617906297
Trained batch 113 in epoch 5, gen_loss = 0.4111590351451907, disc_loss = 0.158365142499015
Trained batch 114 in epoch 5, gen_loss = 0.41097938133322676, disc_loss = 0.15846358516617962
Trained batch 115 in epoch 5, gen_loss = 0.4107393640382537, disc_loss = 0.15817035842237287
Trained batch 116 in epoch 5, gen_loss = 0.41099093357721966, disc_loss = 0.15829336036665317
Trained batch 117 in epoch 5, gen_loss = 0.410746124336275, disc_loss = 0.15833847229447912
Trained batch 118 in epoch 5, gen_loss = 0.41093917403902325, disc_loss = 0.15881349551765359
Trained batch 119 in epoch 5, gen_loss = 0.4106403008103371, disc_loss = 0.15874221838700275
Trained batch 120 in epoch 5, gen_loss = 0.41054575083669553, disc_loss = 0.15859897303864484
Trained batch 121 in epoch 5, gen_loss = 0.4102870443316757, disc_loss = 0.15877064835035898
Trained batch 122 in epoch 5, gen_loss = 0.4097986366690659, disc_loss = 0.15890504206280884
Trained batch 123 in epoch 5, gen_loss = 0.40930277565794604, disc_loss = 0.15952292077183242
Trained batch 124 in epoch 5, gen_loss = 0.40935461640357973, disc_loss = 0.16066687409579755
Trained batch 125 in epoch 5, gen_loss = 0.40873700191104223, disc_loss = 0.16052915089364564
Trained batch 126 in epoch 5, gen_loss = 0.4078753822901118, disc_loss = 0.16075744959489097
Trained batch 127 in epoch 5, gen_loss = 0.4078249582089484, disc_loss = 0.16060541376646142
Trained batch 128 in epoch 5, gen_loss = 0.4075950074565503, disc_loss = 0.1608233543531608
Trained batch 129 in epoch 5, gen_loss = 0.4070271005997291, disc_loss = 0.16124715729115102
Trained batch 130 in epoch 5, gen_loss = 0.4064594859840306, disc_loss = 0.16213773900486586
Trained batch 131 in epoch 5, gen_loss = 0.40663264511209546, disc_loss = 0.16281094033779067
Trained batch 132 in epoch 5, gen_loss = 0.40645857233750193, disc_loss = 0.16288487337305582
Trained batch 133 in epoch 5, gen_loss = 0.40644775108614967, disc_loss = 0.16298590182090428
Trained batch 134 in epoch 5, gen_loss = 0.40649526119232177, disc_loss = 0.16292406103953166
Trained batch 135 in epoch 5, gen_loss = 0.40652216138208613, disc_loss = 0.16293777661014566
Trained batch 136 in epoch 5, gen_loss = 0.40663917199538574, disc_loss = 0.16298281845983362
Trained batch 137 in epoch 5, gen_loss = 0.4064759238474611, disc_loss = 0.16311763274226931
Trained batch 138 in epoch 5, gen_loss = 0.4064691821448237, disc_loss = 0.16297534090741503
Trained batch 139 in epoch 5, gen_loss = 0.40634175751890456, disc_loss = 0.16299280847555825
Trained batch 140 in epoch 5, gen_loss = 0.4059842567071847, disc_loss = 0.16417160739871203
Trained batch 141 in epoch 5, gen_loss = 0.40674958556470736, disc_loss = 0.16524896197493227
Trained batch 142 in epoch 5, gen_loss = 0.40667490567360726, disc_loss = 0.16509435918520798
Trained batch 143 in epoch 5, gen_loss = 0.40654073531428975, disc_loss = 0.1653911644567011
Trained batch 144 in epoch 5, gen_loss = 0.40679179286134654, disc_loss = 0.16535992615952574
Trained batch 145 in epoch 5, gen_loss = 0.4070591922492197, disc_loss = 0.16496495692033883
Trained batch 146 in epoch 5, gen_loss = 0.4070735492673861, disc_loss = 0.16452593132093243
Trained batch 147 in epoch 5, gen_loss = 0.4070212313452283, disc_loss = 0.1646108202812438
Trained batch 148 in epoch 5, gen_loss = 0.40700541706693255, disc_loss = 0.16445554616617275
Trained batch 149 in epoch 5, gen_loss = 0.40686836739381155, disc_loss = 0.1641225353255868
Trained batch 150 in epoch 5, gen_loss = 0.4065857231616974, disc_loss = 0.16443496926484125
Trained batch 151 in epoch 5, gen_loss = 0.4066471675116765, disc_loss = 0.16459139793081895
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.39502254128456116, disc_loss = 0.1580682396888733
Trained batch 1 in epoch 6, gen_loss = 0.3839087188243866, disc_loss = 0.15144983679056168
Trained batch 2 in epoch 6, gen_loss = 0.3794596989949544, disc_loss = 0.15460648636023203
Trained batch 3 in epoch 6, gen_loss = 0.3845045492053032, disc_loss = 0.1717718355357647
Trained batch 4 in epoch 6, gen_loss = 0.3888578712940216, disc_loss = 0.16267123818397522
Trained batch 5 in epoch 6, gen_loss = 0.3863542874654134, disc_loss = 0.15988140801588693
Trained batch 6 in epoch 6, gen_loss = 0.3903583586215973, disc_loss = 0.15888551303318568
Trained batch 7 in epoch 6, gen_loss = 0.3886149004101753, disc_loss = 0.1600729040801525
Trained batch 8 in epoch 6, gen_loss = 0.39240627487500507, disc_loss = 0.1677215745051702
Trained batch 9 in epoch 6, gen_loss = 0.39941125810146333, disc_loss = 0.16841499954462053
Trained batch 10 in epoch 6, gen_loss = 0.39595492590557446, disc_loss = 0.16346791860732166
Trained batch 11 in epoch 6, gen_loss = 0.38901418695847195, disc_loss = 0.16797489114105701
Trained batch 12 in epoch 6, gen_loss = 0.3876182184769557, disc_loss = 0.16827678623107764
Trained batch 13 in epoch 6, gen_loss = 0.38730707338878084, disc_loss = 0.16398261966449873
Trained batch 14 in epoch 6, gen_loss = 0.3858458956082662, disc_loss = 0.16311008582512537
Trained batch 15 in epoch 6, gen_loss = 0.38764687068760395, disc_loss = 0.1651071789674461
Trained batch 16 in epoch 6, gen_loss = 0.3902455498190487, disc_loss = 0.17235452068202636
Trained batch 17 in epoch 6, gen_loss = 0.3880037979947196, disc_loss = 0.16995221914516556
Trained batch 18 in epoch 6, gen_loss = 0.3870280981063843, disc_loss = 0.16940937504956596
Trained batch 19 in epoch 6, gen_loss = 0.38554605692625044, disc_loss = 0.16815639697015286
Trained batch 20 in epoch 6, gen_loss = 0.3865771009808495, disc_loss = 0.16546990935291564
Trained batch 21 in epoch 6, gen_loss = 0.38614497536962683, disc_loss = 0.164159299636429
Trained batch 22 in epoch 6, gen_loss = 0.3859739718229874, disc_loss = 0.16401690924945084
Trained batch 23 in epoch 6, gen_loss = 0.3855701833963394, disc_loss = 0.16481492513169846
Trained batch 24 in epoch 6, gen_loss = 0.386338050365448, disc_loss = 0.16610683172941207
Trained batch 25 in epoch 6, gen_loss = 0.3844145651047046, disc_loss = 0.16617207028544867
Trained batch 26 in epoch 6, gen_loss = 0.383540161229946, disc_loss = 0.1671579306324323
Trained batch 27 in epoch 6, gen_loss = 0.38399568093674524, disc_loss = 0.17143662087619305
Trained batch 28 in epoch 6, gen_loss = 0.38098171661640035, disc_loss = 0.17179784821025257
Trained batch 29 in epoch 6, gen_loss = 0.38085059225559237, disc_loss = 0.17167740191022554
Trained batch 30 in epoch 6, gen_loss = 0.38081733065266765, disc_loss = 0.17226164547666425
Trained batch 31 in epoch 6, gen_loss = 0.38021494541317225, disc_loss = 0.1734614388551563
Trained batch 32 in epoch 6, gen_loss = 0.3809004398909482, disc_loss = 0.17653624645688318
Trained batch 33 in epoch 6, gen_loss = 0.38077955386217904, disc_loss = 0.1765415175434421
Trained batch 34 in epoch 6, gen_loss = 0.38061544384275164, disc_loss = 0.17628019345658166
Trained batch 35 in epoch 6, gen_loss = 0.38083719793293214, disc_loss = 0.17449507075879309
Trained batch 36 in epoch 6, gen_loss = 0.38250930808685923, disc_loss = 0.17330736123226784
Trained batch 37 in epoch 6, gen_loss = 0.3838324813466323, disc_loss = 0.17338429509024872
Trained batch 38 in epoch 6, gen_loss = 0.38309178826136464, disc_loss = 0.17426401988053933
Trained batch 39 in epoch 6, gen_loss = 0.3829853408038616, disc_loss = 0.17610525265336036
Trained batch 40 in epoch 6, gen_loss = 0.38443897192071125, disc_loss = 0.18128284230464842
Trained batch 41 in epoch 6, gen_loss = 0.38396619473184856, disc_loss = 0.1813743185429346
Trained batch 42 in epoch 6, gen_loss = 0.38399587606274804, disc_loss = 0.18092328171397365
Trained batch 43 in epoch 6, gen_loss = 0.38533519208431244, disc_loss = 0.1797955401919105
Trained batch 44 in epoch 6, gen_loss = 0.38550416628519696, disc_loss = 0.1787362429830763
Trained batch 45 in epoch 6, gen_loss = 0.38465925727201544, disc_loss = 0.17791257895853207
Trained batch 46 in epoch 6, gen_loss = 0.3853137474110786, disc_loss = 0.17656937336668055
Trained batch 47 in epoch 6, gen_loss = 0.38529589710136253, disc_loss = 0.1753358943387866
Trained batch 48 in epoch 6, gen_loss = 0.3850836741681002, disc_loss = 0.17483810228960855
Trained batch 49 in epoch 6, gen_loss = 0.38534763634204866, disc_loss = 0.17594419568777084
Trained batch 50 in epoch 6, gen_loss = 0.38464442012356775, disc_loss = 0.1756297531081181
Trained batch 51 in epoch 6, gen_loss = 0.38370706943365246, disc_loss = 0.17529548446719462
Trained batch 52 in epoch 6, gen_loss = 0.38400114707227023, disc_loss = 0.175515815615654
Trained batch 53 in epoch 6, gen_loss = 0.38423983973485454, disc_loss = 0.17629817624886832
Trained batch 54 in epoch 6, gen_loss = 0.38470392769033257, disc_loss = 0.17512152804569764
Trained batch 55 in epoch 6, gen_loss = 0.38464091664978434, disc_loss = 0.17517986481211015
Trained batch 56 in epoch 6, gen_loss = 0.3845963342147961, disc_loss = 0.17561387375258564
Trained batch 57 in epoch 6, gen_loss = 0.3842543964755946, disc_loss = 0.17464501937401705
Trained batch 58 in epoch 6, gen_loss = 0.38402602480629744, disc_loss = 0.1735085021641295
Trained batch 59 in epoch 6, gen_loss = 0.38434569040934247, disc_loss = 0.1725847378373146
Trained batch 60 in epoch 6, gen_loss = 0.3839415946944815, disc_loss = 0.171716784844633
Trained batch 61 in epoch 6, gen_loss = 0.38449248767668204, disc_loss = 0.17099888742931427
Trained batch 62 in epoch 6, gen_loss = 0.38480318822557963, disc_loss = 0.16976195431890942
Trained batch 63 in epoch 6, gen_loss = 0.38425931241363287, disc_loss = 0.16895381570793688
Trained batch 64 in epoch 6, gen_loss = 0.38407370402262764, disc_loss = 0.1698809238580557
Trained batch 65 in epoch 6, gen_loss = 0.3855125976331306, disc_loss = 0.17226170093724222
Trained batch 66 in epoch 6, gen_loss = 0.3847511855523978, disc_loss = 0.1725829692918863
Trained batch 67 in epoch 6, gen_loss = 0.38491836190223694, disc_loss = 0.1731204822221223
Trained batch 68 in epoch 6, gen_loss = 0.38556284533030744, disc_loss = 0.17264379064242044
Trained batch 69 in epoch 6, gen_loss = 0.38629108582224164, disc_loss = 0.17236767028059277
Trained batch 70 in epoch 6, gen_loss = 0.38710118473415644, disc_loss = 0.17276757451849925
Trained batch 71 in epoch 6, gen_loss = 0.38716693222522736, disc_loss = 0.1736353226006031
Trained batch 72 in epoch 6, gen_loss = 0.3880152114450115, disc_loss = 0.17362576212785016
Trained batch 73 in epoch 6, gen_loss = 0.3885749022702913, disc_loss = 0.1731220785830472
Trained batch 74 in epoch 6, gen_loss = 0.3886647156874339, disc_loss = 0.1736220399538676
Trained batch 75 in epoch 6, gen_loss = 0.3897698451029627, disc_loss = 0.17390499852205576
Trained batch 76 in epoch 6, gen_loss = 0.38880313100752895, disc_loss = 0.17364801040717534
Trained batch 77 in epoch 6, gen_loss = 0.38830270637304354, disc_loss = 0.17331977284107453
Trained batch 78 in epoch 6, gen_loss = 0.3882663664938528, disc_loss = 0.17216556641874434
Trained batch 79 in epoch 6, gen_loss = 0.38860232532024386, disc_loss = 0.1721714675426483
Trained batch 80 in epoch 6, gen_loss = 0.389185560706221, disc_loss = 0.17231277919109958
Trained batch 81 in epoch 6, gen_loss = 0.38990580926581125, disc_loss = 0.1711391610343282
Trained batch 82 in epoch 6, gen_loss = 0.38977471101714906, disc_loss = 0.17073391377925873
Trained batch 83 in epoch 6, gen_loss = 0.3899576933611007, disc_loss = 0.17056531973537944
Trained batch 84 in epoch 6, gen_loss = 0.3899231258560629, disc_loss = 0.17043809101862065
Trained batch 85 in epoch 6, gen_loss = 0.39043420518553534, disc_loss = 0.1695652073032634
Trained batch 86 in epoch 6, gen_loss = 0.39008576294471475, disc_loss = 0.16934944184004574
Trained batch 87 in epoch 6, gen_loss = 0.3914474946531383, disc_loss = 0.17079511140896517
Trained batch 88 in epoch 6, gen_loss = 0.39047331655963086, disc_loss = 0.1744517817088727
Trained batch 89 in epoch 6, gen_loss = 0.39115728471014233, disc_loss = 0.17573516691724458
Trained batch 90 in epoch 6, gen_loss = 0.3910606323362707, disc_loss = 0.17586491551700528
Trained batch 91 in epoch 6, gen_loss = 0.391574966194837, disc_loss = 0.17628070201886736
Trained batch 92 in epoch 6, gen_loss = 0.3915225228955669, disc_loss = 0.17672403020563945
Trained batch 93 in epoch 6, gen_loss = 0.39137687137786376, disc_loss = 0.17657944599681713
Trained batch 94 in epoch 6, gen_loss = 0.3915937313908025, disc_loss = 0.1765391350576752
Trained batch 95 in epoch 6, gen_loss = 0.3921448728069663, disc_loss = 0.1764557492764046
Trained batch 96 in epoch 6, gen_loss = 0.3922097775125012, disc_loss = 0.17676233024019555
Trained batch 97 in epoch 6, gen_loss = 0.39174204699847165, disc_loss = 0.17703542744322698
Trained batch 98 in epoch 6, gen_loss = 0.3916836149162716, disc_loss = 0.1771638144296829
Trained batch 99 in epoch 6, gen_loss = 0.39173961549997327, disc_loss = 0.177388152256608
Trained batch 100 in epoch 6, gen_loss = 0.39151452821080046, disc_loss = 0.17696271770366348
Trained batch 101 in epoch 6, gen_loss = 0.391341440817889, disc_loss = 0.17655027825750558
Trained batch 102 in epoch 6, gen_loss = 0.3919966825582449, disc_loss = 0.17657184825070854
Trained batch 103 in epoch 6, gen_loss = 0.3919651336394824, disc_loss = 0.17727542847681504
Trained batch 104 in epoch 6, gen_loss = 0.3928206018039158, disc_loss = 0.178551678785256
Trained batch 105 in epoch 6, gen_loss = 0.39281744608339275, disc_loss = 0.1796376461268596
Trained batch 106 in epoch 6, gen_loss = 0.39285859409893786, disc_loss = 0.18006755321103834
Trained batch 107 in epoch 6, gen_loss = 0.3931445451798262, disc_loss = 0.1796710610527683
Trained batch 108 in epoch 6, gen_loss = 0.3928837757044976, disc_loss = 0.17890949417418295
Trained batch 109 in epoch 6, gen_loss = 0.39238666648214515, disc_loss = 0.17894470048221675
Trained batch 110 in epoch 6, gen_loss = 0.39248258868853253, disc_loss = 0.17862007887782277
Trained batch 111 in epoch 6, gen_loss = 0.39242429312850746, disc_loss = 0.1787343403723623
Trained batch 112 in epoch 6, gen_loss = 0.3921817870794144, disc_loss = 0.1786821479950331
Trained batch 113 in epoch 6, gen_loss = 0.39223137367189975, disc_loss = 0.17834924821529471
Trained batch 114 in epoch 6, gen_loss = 0.3925882119199504, disc_loss = 0.17869964287332865
Trained batch 115 in epoch 6, gen_loss = 0.3921425324575654, disc_loss = 0.17843050066510152
Trained batch 116 in epoch 6, gen_loss = 0.3917227076669025, disc_loss = 0.17899777982224765
Trained batch 117 in epoch 6, gen_loss = 0.3918742234424009, disc_loss = 0.1788350965638282
Trained batch 118 in epoch 6, gen_loss = 0.3919991142108661, disc_loss = 0.17838526492108817
Trained batch 119 in epoch 6, gen_loss = 0.39224786013364793, disc_loss = 0.17867479380220175
Trained batch 120 in epoch 6, gen_loss = 0.39267112573316276, disc_loss = 0.17873730375008148
Trained batch 121 in epoch 6, gen_loss = 0.39310334622859955, disc_loss = 0.17882072162188467
Trained batch 122 in epoch 6, gen_loss = 0.3931378305442934, disc_loss = 0.1783865202612024
Trained batch 123 in epoch 6, gen_loss = 0.39310310300319423, disc_loss = 0.17760015831839654
Trained batch 124 in epoch 6, gen_loss = 0.39351269602775574, disc_loss = 0.17702003872394562
Trained batch 125 in epoch 6, gen_loss = 0.3934360524964711, disc_loss = 0.1766049468091556
Trained batch 126 in epoch 6, gen_loss = 0.3934830288718066, disc_loss = 0.17606873340963378
Trained batch 127 in epoch 6, gen_loss = 0.3939483251888305, disc_loss = 0.17583580070640892
Trained batch 128 in epoch 6, gen_loss = 0.39386954926705176, disc_loss = 0.17525878225186076
Trained batch 129 in epoch 6, gen_loss = 0.3938473336971723, disc_loss = 0.17557828976557804
Trained batch 130 in epoch 6, gen_loss = 0.39405984255193754, disc_loss = 0.1755438050013462
Trained batch 131 in epoch 6, gen_loss = 0.3942097998929746, disc_loss = 0.175136857186303
Trained batch 132 in epoch 6, gen_loss = 0.39381741648329827, disc_loss = 0.17539170552465252
Trained batch 133 in epoch 6, gen_loss = 0.394030835646302, disc_loss = 0.17484960015585174
Trained batch 134 in epoch 6, gen_loss = 0.39420466908702145, disc_loss = 0.17417600375634654
Trained batch 135 in epoch 6, gen_loss = 0.39409735163345055, disc_loss = 0.17415893494206316
Trained batch 136 in epoch 6, gen_loss = 0.3943265846175869, disc_loss = 0.17432794888524245
Trained batch 137 in epoch 6, gen_loss = 0.39405440787474316, disc_loss = 0.1741488800532576
Trained batch 138 in epoch 6, gen_loss = 0.39474197493182667, disc_loss = 0.17312682800584558
Trained batch 139 in epoch 6, gen_loss = 0.39499633269650597, disc_loss = 0.17297003460781915
Trained batch 140 in epoch 6, gen_loss = 0.3955095203210276, disc_loss = 0.17333492192816227
Trained batch 141 in epoch 6, gen_loss = 0.39568934012466755, disc_loss = 0.17310104183327985
Trained batch 142 in epoch 6, gen_loss = 0.3957501631099861, disc_loss = 0.17283979047845294
Trained batch 143 in epoch 6, gen_loss = 0.3961020395573642, disc_loss = 0.17287844988620943
Trained batch 144 in epoch 6, gen_loss = 0.3960122926481839, disc_loss = 0.17257968896421894
Trained batch 145 in epoch 6, gen_loss = 0.39595366279556327, disc_loss = 0.17249100502223186
Trained batch 146 in epoch 6, gen_loss = 0.39645716223586985, disc_loss = 0.17334717958151888
Trained batch 147 in epoch 6, gen_loss = 0.39595613668899277, disc_loss = 0.17336266950981036
Trained batch 148 in epoch 6, gen_loss = 0.39597645681976473, disc_loss = 0.17455414797635688
Trained batch 149 in epoch 6, gen_loss = 0.3960268117984136, disc_loss = 0.17509802202383676
Trained batch 150 in epoch 6, gen_loss = 0.39619939571974294, disc_loss = 0.1747886459559005
Trained batch 151 in epoch 6, gen_loss = 0.39603400995072563, disc_loss = 0.17453520362706562
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.4177316427230835, disc_loss = 0.13592569530010223
Trained batch 1 in epoch 7, gen_loss = 0.40601518750190735, disc_loss = 0.12034043297171593
Trained batch 2 in epoch 7, gen_loss = 0.3984228769938151, disc_loss = 0.12054045250018437
Trained batch 3 in epoch 7, gen_loss = 0.38312292844057083, disc_loss = 0.11775301210582256
Trained batch 4 in epoch 7, gen_loss = 0.38480297327041624, disc_loss = 0.13049584478139878
Trained batch 5 in epoch 7, gen_loss = 0.39416419466336566, disc_loss = 0.1435286539296309
Trained batch 6 in epoch 7, gen_loss = 0.39561168210847036, disc_loss = 0.14779509710414068
Trained batch 7 in epoch 7, gen_loss = 0.3980383053421974, disc_loss = 0.14877610001713037
Trained batch 8 in epoch 7, gen_loss = 0.39928921394877964, disc_loss = 0.14840509245793024
Trained batch 9 in epoch 7, gen_loss = 0.401579949259758, disc_loss = 0.15698466673493386
Trained batch 10 in epoch 7, gen_loss = 0.3985961811109023, disc_loss = 0.15670630809935657
Trained batch 11 in epoch 7, gen_loss = 0.3984900986154874, disc_loss = 0.1537488903850317
Trained batch 12 in epoch 7, gen_loss = 0.40073283589803255, disc_loss = 0.15179300136291063
Trained batch 13 in epoch 7, gen_loss = 0.3980237820318767, disc_loss = 0.1514447900865759
Trained batch 14 in epoch 7, gen_loss = 0.39791491627693176, disc_loss = 0.1516668066382408
Trained batch 15 in epoch 7, gen_loss = 0.39811139926314354, disc_loss = 0.1522386302240193
Trained batch 16 in epoch 7, gen_loss = 0.39607788534725413, disc_loss = 0.15018474091501796
Trained batch 17 in epoch 7, gen_loss = 0.39700335760911304, disc_loss = 0.1467507059375445
Trained batch 18 in epoch 7, gen_loss = 0.39774610808021144, disc_loss = 0.14463930459398971
Trained batch 19 in epoch 7, gen_loss = 0.39818660318851473, disc_loss = 0.1411901295185089
Trained batch 20 in epoch 7, gen_loss = 0.3984831160023099, disc_loss = 0.13608075838003839
Trained batch 21 in epoch 7, gen_loss = 0.40045376257462934, disc_loss = 0.13320350122045388
Trained batch 22 in epoch 7, gen_loss = 0.40191545305044757, disc_loss = 0.13184580028704976
Trained batch 23 in epoch 7, gen_loss = 0.40608614310622215, disc_loss = 0.13317113385225335
Trained batch 24 in epoch 7, gen_loss = 0.4043427300453186, disc_loss = 0.141380964666605
Trained batch 25 in epoch 7, gen_loss = 0.40419585429705107, disc_loss = 0.14247593813790724
Trained batch 26 in epoch 7, gen_loss = 0.4038686586750878, disc_loss = 0.14366442475605895
Trained batch 27 in epoch 7, gen_loss = 0.4026686762060438, disc_loss = 0.1443643778828638
Trained batch 28 in epoch 7, gen_loss = 0.40290545800636557, disc_loss = 0.14517939514641104
Trained batch 29 in epoch 7, gen_loss = 0.4026210278272629, disc_loss = 0.14445810727775096
Trained batch 30 in epoch 7, gen_loss = 0.4032370073180045, disc_loss = 0.14730549399410525
Trained batch 31 in epoch 7, gen_loss = 0.40241330210119486, disc_loss = 0.14995423110667616
Trained batch 32 in epoch 7, gen_loss = 0.4019390985821233, disc_loss = 0.1503427955463077
Trained batch 33 in epoch 7, gen_loss = 0.4015665799379349, disc_loss = 0.15212954372605858
Trained batch 34 in epoch 7, gen_loss = 0.3997758652482714, disc_loss = 0.15647391644971712
Trained batch 35 in epoch 7, gen_loss = 0.4005851124723752, disc_loss = 0.15719064087089565
Trained batch 36 in epoch 7, gen_loss = 0.3997095420553878, disc_loss = 0.15564078787291372
Trained batch 37 in epoch 7, gen_loss = 0.40019578133758743, disc_loss = 0.15854737603742824
Trained batch 38 in epoch 7, gen_loss = 0.40225893411880886, disc_loss = 0.1577875836728475
Trained batch 39 in epoch 7, gen_loss = 0.40308322906494143, disc_loss = 0.15763127813115715
Trained batch 40 in epoch 7, gen_loss = 0.4020696064321006, disc_loss = 0.15619124263161566
Trained batch 41 in epoch 7, gen_loss = 0.4025497294607617, disc_loss = 0.15487819493171714
Trained batch 42 in epoch 7, gen_loss = 0.40247569666352384, disc_loss = 0.15354341415818348
Trained batch 43 in epoch 7, gen_loss = 0.40189459919929504, disc_loss = 0.15384209977293556
Trained batch 44 in epoch 7, gen_loss = 0.40216506123542783, disc_loss = 0.1546647473341889
Trained batch 45 in epoch 7, gen_loss = 0.4027763138646665, disc_loss = 0.1540506758281718
Trained batch 46 in epoch 7, gen_loss = 0.4023297682721564, disc_loss = 0.15273017222259908
Trained batch 47 in epoch 7, gen_loss = 0.4019486742715041, disc_loss = 0.1517730262906601
Trained batch 48 in epoch 7, gen_loss = 0.40130550155834277, disc_loss = 0.1513652209268541
Trained batch 49 in epoch 7, gen_loss = 0.4011595863103867, disc_loss = 0.15031430043280125
Trained batch 50 in epoch 7, gen_loss = 0.40058349803382276, disc_loss = 0.15028563704268605
Trained batch 51 in epoch 7, gen_loss = 0.40034264612656373, disc_loss = 0.15256508017102113
Trained batch 52 in epoch 7, gen_loss = 0.4019398554316107, disc_loss = 0.15346594724171567
Trained batch 53 in epoch 7, gen_loss = 0.4013129323720932, disc_loss = 0.15216362027934305
Trained batch 54 in epoch 7, gen_loss = 0.40037148649042303, disc_loss = 0.15327711369503627
Trained batch 55 in epoch 7, gen_loss = 0.40110601271901813, disc_loss = 0.154860217589885
Trained batch 56 in epoch 7, gen_loss = 0.4002251212011304, disc_loss = 0.15429597354510374
Trained batch 57 in epoch 7, gen_loss = 0.4005912773568055, disc_loss = 0.1536139354495139
Trained batch 58 in epoch 7, gen_loss = 0.4015471233149706, disc_loss = 0.15321386056178707
Trained batch 59 in epoch 7, gen_loss = 0.40065258045991264, disc_loss = 0.15250984424104294
Trained batch 60 in epoch 7, gen_loss = 0.3997705788885961, disc_loss = 0.15178210611958973
Trained batch 61 in epoch 7, gen_loss = 0.4005254694531041, disc_loss = 0.15127522997077433
Trained batch 62 in epoch 7, gen_loss = 0.40088375220223077, disc_loss = 0.15030231510126402
Trained batch 63 in epoch 7, gen_loss = 0.40134116262197495, disc_loss = 0.14833496825303882
Trained batch 64 in epoch 7, gen_loss = 0.40060684314140904, disc_loss = 0.14875623022134488
Trained batch 65 in epoch 7, gen_loss = 0.40088696055340045, disc_loss = 0.14970091019164433
Trained batch 66 in epoch 7, gen_loss = 0.4000436801518967, disc_loss = 0.1499082289302527
Trained batch 67 in epoch 7, gen_loss = 0.40072624867453294, disc_loss = 0.14947524436694734
Trained batch 68 in epoch 7, gen_loss = 0.40129763794981915, disc_loss = 0.15096603863049243
Trained batch 69 in epoch 7, gen_loss = 0.40105787473065513, disc_loss = 0.1499790959060192
Trained batch 70 in epoch 7, gen_loss = 0.4007396018001395, disc_loss = 0.1498101644322906
Trained batch 71 in epoch 7, gen_loss = 0.4005717717938953, disc_loss = 0.14911652925527757
Trained batch 72 in epoch 7, gen_loss = 0.4013561418611709, disc_loss = 0.14919568404351194
Trained batch 73 in epoch 7, gen_loss = 0.4008571916335338, disc_loss = 0.15004573490571332
Trained batch 74 in epoch 7, gen_loss = 0.40138090451558434, disc_loss = 0.14965584297974904
Trained batch 75 in epoch 7, gen_loss = 0.4019686450299464, disc_loss = 0.1498790418631152
Trained batch 76 in epoch 7, gen_loss = 0.40153106930968047, disc_loss = 0.15097252734295732
Trained batch 77 in epoch 7, gen_loss = 0.4013257187146407, disc_loss = 0.15156733989715576
Trained batch 78 in epoch 7, gen_loss = 0.40158677063410797, disc_loss = 0.15142393602600582
Trained batch 79 in epoch 7, gen_loss = 0.4015506159514189, disc_loss = 0.15108607402071356
Trained batch 80 in epoch 7, gen_loss = 0.4009420095402517, disc_loss = 0.1514775472474687
Trained batch 81 in epoch 7, gen_loss = 0.4008114436050741, disc_loss = 0.15045177364131299
Trained batch 82 in epoch 7, gen_loss = 0.40104343912687646, disc_loss = 0.1501779275306736
Trained batch 83 in epoch 7, gen_loss = 0.40084654092788696, disc_loss = 0.14977419571507544
Trained batch 84 in epoch 7, gen_loss = 0.40070480458876667, disc_loss = 0.14946407465373768
Trained batch 85 in epoch 7, gen_loss = 0.4002695028171983, disc_loss = 0.14899720346858336
Trained batch 86 in epoch 7, gen_loss = 0.4002287507742301, disc_loss = 0.14928012735199656
Trained batch 87 in epoch 7, gen_loss = 0.4013388038358905, disc_loss = 0.14838258659636433
Trained batch 88 in epoch 7, gen_loss = 0.40183140387695826, disc_loss = 0.14734713147195538
Trained batch 89 in epoch 7, gen_loss = 0.40142519308461083, disc_loss = 0.1481470823287964
Trained batch 90 in epoch 7, gen_loss = 0.4016591667473971, disc_loss = 0.14750726512827717
Trained batch 91 in epoch 7, gen_loss = 0.4022953254373177, disc_loss = 0.14740179292857647
Trained batch 92 in epoch 7, gen_loss = 0.4024933099105794, disc_loss = 0.1475312201085911
Trained batch 93 in epoch 7, gen_loss = 0.40191784088915966, disc_loss = 0.15166914058809586
Trained batch 94 in epoch 7, gen_loss = 0.40228133295711715, disc_loss = 0.15042753717616986
Trained batch 95 in epoch 7, gen_loss = 0.40307346855600673, disc_loss = 0.1504937878732259
Trained batch 96 in epoch 7, gen_loss = 0.40294102295157835, disc_loss = 0.14991459461677933
Trained batch 97 in epoch 7, gen_loss = 0.4023504950562302, disc_loss = 0.15156075628284288
Trained batch 98 in epoch 7, gen_loss = 0.4029597308900621, disc_loss = 0.15105638807319632
Trained batch 99 in epoch 7, gen_loss = 0.40339936822652817, disc_loss = 0.1513512232527137
Trained batch 100 in epoch 7, gen_loss = 0.4034088971001087, disc_loss = 0.15236860982114725
Trained batch 101 in epoch 7, gen_loss = 0.4034456344796162, disc_loss = 0.15214976854622364
Trained batch 102 in epoch 7, gen_loss = 0.40350211158539484, disc_loss = 0.15265273422147463
Trained batch 103 in epoch 7, gen_loss = 0.403839639459665, disc_loss = 0.15248409798368812
Trained batch 104 in epoch 7, gen_loss = 0.4041343226319268, disc_loss = 0.1512036439563547
Trained batch 105 in epoch 7, gen_loss = 0.40414971085089557, disc_loss = 0.15031461913208916
Trained batch 106 in epoch 7, gen_loss = 0.40365129987770154, disc_loss = 0.15074331114921613
Trained batch 107 in epoch 7, gen_loss = 0.4040483724739816, disc_loss = 0.15099075039917673
Trained batch 108 in epoch 7, gen_loss = 0.40408200572390074, disc_loss = 0.15063066100445363
Trained batch 109 in epoch 7, gen_loss = 0.40419539294459605, disc_loss = 0.15021914125166155
Trained batch 110 in epoch 7, gen_loss = 0.40448094729904654, disc_loss = 0.14988280527360803
Trained batch 111 in epoch 7, gen_loss = 0.40490493710551945, disc_loss = 0.14938879841273384
Trained batch 112 in epoch 7, gen_loss = 0.40461281759549034, disc_loss = 0.14875684629103778
Trained batch 113 in epoch 7, gen_loss = 0.40445950914893236, disc_loss = 0.14897220781105652
Trained batch 114 in epoch 7, gen_loss = 0.4046968846217446, disc_loss = 0.149095784743195
Trained batch 115 in epoch 7, gen_loss = 0.40485792221694156, disc_loss = 0.1482313441369554
Trained batch 116 in epoch 7, gen_loss = 0.404876849335483, disc_loss = 0.14749371021603927
Trained batch 117 in epoch 7, gen_loss = 0.40455168283591836, disc_loss = 0.14823496048101933
Trained batch 118 in epoch 7, gen_loss = 0.4050764123431775, disc_loss = 0.14990903408963138
Trained batch 119 in epoch 7, gen_loss = 0.40493371387322746, disc_loss = 0.15039593276257315
Trained batch 120 in epoch 7, gen_loss = 0.40475959324639693, disc_loss = 0.15060676274097656
Trained batch 121 in epoch 7, gen_loss = 0.40421220318215795, disc_loss = 0.15092765939895247
Trained batch 122 in epoch 7, gen_loss = 0.40394058120929127, disc_loss = 0.15105050641710197
Trained batch 123 in epoch 7, gen_loss = 0.404078739785379, disc_loss = 0.1511402054119014
Trained batch 124 in epoch 7, gen_loss = 0.4040232675075531, disc_loss = 0.15107264384627342
Trained batch 125 in epoch 7, gen_loss = 0.40400461048360853, disc_loss = 0.15107760516305765
Trained batch 126 in epoch 7, gen_loss = 0.40429515491320395, disc_loss = 0.15120048489509605
Trained batch 127 in epoch 7, gen_loss = 0.40431722719222307, disc_loss = 0.15079438578686677
Trained batch 128 in epoch 7, gen_loss = 0.40457505542178485, disc_loss = 0.15023525911130647
Trained batch 129 in epoch 7, gen_loss = 0.40473229449528914, disc_loss = 0.1497761874531324
Trained batch 130 in epoch 7, gen_loss = 0.4046155321234055, disc_loss = 0.1489826910880231
Trained batch 131 in epoch 7, gen_loss = 0.40413188685973483, disc_loss = 0.14914635989363445
Trained batch 132 in epoch 7, gen_loss = 0.4047027765808249, disc_loss = 0.14916711028917393
Trained batch 133 in epoch 7, gen_loss = 0.4048077848865025, disc_loss = 0.14850780059263777
Trained batch 134 in epoch 7, gen_loss = 0.40495581229527794, disc_loss = 0.14783166956018517
Trained batch 135 in epoch 7, gen_loss = 0.40461158467566266, disc_loss = 0.14754380756879554
Trained batch 136 in epoch 7, gen_loss = 0.4051294389867435, disc_loss = 0.14716152205084362
Trained batch 137 in epoch 7, gen_loss = 0.4059497128794159, disc_loss = 0.14671536254278128
Trained batch 138 in epoch 7, gen_loss = 0.4062320903050814, disc_loss = 0.14657355287521007
Trained batch 139 in epoch 7, gen_loss = 0.40632405962262835, disc_loss = 0.14628190164055144
Trained batch 140 in epoch 7, gen_loss = 0.4064977044332112, disc_loss = 0.1461106134010545
Trained batch 141 in epoch 7, gen_loss = 0.4065885562712038, disc_loss = 0.14537175293539611
Trained batch 142 in epoch 7, gen_loss = 0.4063910987827328, disc_loss = 0.14520274727911384
Trained batch 143 in epoch 7, gen_loss = 0.4062177131159438, disc_loss = 0.14501662464398477
Trained batch 144 in epoch 7, gen_loss = 0.40599336932445396, disc_loss = 0.14526236977042822
Trained batch 145 in epoch 7, gen_loss = 0.40597646203759596, disc_loss = 0.1450585562174451
Trained batch 146 in epoch 7, gen_loss = 0.40575734916187467, disc_loss = 0.14505852774089698
Trained batch 147 in epoch 7, gen_loss = 0.40574875836436813, disc_loss = 0.14504317078437354
Trained batch 148 in epoch 7, gen_loss = 0.40592203504287155, disc_loss = 0.14549290718848273
Trained batch 149 in epoch 7, gen_loss = 0.4059885040918986, disc_loss = 0.1459629877905051
Trained batch 150 in epoch 7, gen_loss = 0.40632051643946315, disc_loss = 0.14650178927656832
Trained batch 151 in epoch 7, gen_loss = 0.4065094107860013, disc_loss = 0.1466147353088385
Testing Epoch 7

Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.41056713461875916, disc_loss = 0.07943136990070343
Trained batch 1 in epoch 8, gen_loss = 0.40004177391529083, disc_loss = 0.1174747422337532
Trained batch 2 in epoch 8, gen_loss = 0.41089649001757306, disc_loss = 0.1283335487047831
Trained batch 3 in epoch 8, gen_loss = 0.4053695872426033, disc_loss = 0.12643602304160595
Trained batch 4 in epoch 8, gen_loss = 0.4022190451622009, disc_loss = 0.12652557641267775
Trained batch 5 in epoch 8, gen_loss = 0.4111630568901698, disc_loss = 0.134670606503884
Trained batch 6 in epoch 8, gen_loss = 0.40881999475615366, disc_loss = 0.1355931024466242
Trained batch 7 in epoch 8, gen_loss = 0.410467017441988, disc_loss = 0.12936951965093613
Trained batch 8 in epoch 8, gen_loss = 0.4205919603506724, disc_loss = 0.14660190211402047
Trained batch 9 in epoch 8, gen_loss = 0.41296049058437345, disc_loss = 0.15574823468923568
Trained batch 10 in epoch 8, gen_loss = 0.41671528057618573, disc_loss = 0.16238456829027695
Trained batch 11 in epoch 8, gen_loss = 0.4147875557343165, disc_loss = 0.17429895823200545
Trained batch 12 in epoch 8, gen_loss = 0.4156096348395714, disc_loss = 0.18822301694980034
Trained batch 13 in epoch 8, gen_loss = 0.4150282336132867, disc_loss = 0.19087953865528107
Trained batch 14 in epoch 8, gen_loss = 0.41327829162279767, disc_loss = 0.1879021108150482
Trained batch 15 in epoch 8, gen_loss = 0.412279698997736, disc_loss = 0.18387859361246228
Trained batch 16 in epoch 8, gen_loss = 0.4122171822716208, disc_loss = 0.1793894474120701
Trained batch 17 in epoch 8, gen_loss = 0.4116227858596378, disc_loss = 0.17481888996230233
Trained batch 18 in epoch 8, gen_loss = 0.4130171866793382, disc_loss = 0.17091127759531924
Trained batch 19 in epoch 8, gen_loss = 0.4142468228936195, disc_loss = 0.16666298322379589
Trained batch 20 in epoch 8, gen_loss = 0.41153831141335623, disc_loss = 0.16666774132422038
Trained batch 21 in epoch 8, gen_loss = 0.4102313234047456, disc_loss = 0.16810363632711497
Trained batch 22 in epoch 8, gen_loss = 0.4093285125234853, disc_loss = 0.1696228135539138
Trained batch 23 in epoch 8, gen_loss = 0.4101277564962705, disc_loss = 0.16932454612106085
Trained batch 24 in epoch 8, gen_loss = 0.40918698072433474, disc_loss = 0.16792021900415421
Trained batch 25 in epoch 8, gen_loss = 0.40876277134968686, disc_loss = 0.1674924627519571
Trained batch 26 in epoch 8, gen_loss = 0.4086477789613936, disc_loss = 0.16859717363560642
Trained batch 27 in epoch 8, gen_loss = 0.4071095532604626, disc_loss = 0.17068290949932166
Trained batch 28 in epoch 8, gen_loss = 0.40603956066328906, disc_loss = 0.1686817065908991
Trained batch 29 in epoch 8, gen_loss = 0.4075515886147817, disc_loss = 0.16819665258129438
Trained batch 30 in epoch 8, gen_loss = 0.4075411721583336, disc_loss = 0.166662952592296
Trained batch 31 in epoch 8, gen_loss = 0.40724766813218594, disc_loss = 0.16519834101200104
Trained batch 32 in epoch 8, gen_loss = 0.40708518299189483, disc_loss = 0.16417456756938587
Trained batch 33 in epoch 8, gen_loss = 0.4083696936859804, disc_loss = 0.16326505778466954
Trained batch 34 in epoch 8, gen_loss = 0.40728481837681363, disc_loss = 0.16188065728970935
Trained batch 35 in epoch 8, gen_loss = 0.407033019595676, disc_loss = 0.16055555683043268
Trained batch 36 in epoch 8, gen_loss = 0.4065580432479446, disc_loss = 0.15917612269923492
Trained batch 37 in epoch 8, gen_loss = 0.40763006084843684, disc_loss = 0.15618060754710122
Trained batch 38 in epoch 8, gen_loss = 0.40726729157643443, disc_loss = 0.1570961516446028
Trained batch 39 in epoch 8, gen_loss = 0.4088521644473076, disc_loss = 0.15975504843518137
Trained batch 40 in epoch 8, gen_loss = 0.4080588890285027, disc_loss = 0.16038583318998173
Trained batch 41 in epoch 8, gen_loss = 0.4075011674846922, disc_loss = 0.16030437561372915
Trained batch 42 in epoch 8, gen_loss = 0.40768556678017903, disc_loss = 0.16053753770714582
Trained batch 43 in epoch 8, gen_loss = 0.40702301399274304, disc_loss = 0.1616945154118267
Trained batch 44 in epoch 8, gen_loss = 0.40800866021050347, disc_loss = 0.16378536779019567
Trained batch 45 in epoch 8, gen_loss = 0.40761467620082525, disc_loss = 0.1664863179397324
Trained batch 46 in epoch 8, gen_loss = 0.40783375818678674, disc_loss = 0.1661515384119876
Trained batch 47 in epoch 8, gen_loss = 0.40797368561228115, disc_loss = 0.16470914015856883
Trained batch 48 in epoch 8, gen_loss = 0.40782447737090444, disc_loss = 0.1638115008114552
Trained batch 49 in epoch 8, gen_loss = 0.407251119017601, disc_loss = 0.1622590284794569
Trained batch 50 in epoch 8, gen_loss = 0.4090270604573044, disc_loss = 0.1602830433231943
Trained batch 51 in epoch 8, gen_loss = 0.40966157615184784, disc_loss = 0.15928334563684005
Trained batch 52 in epoch 8, gen_loss = 0.4088336414885971, disc_loss = 0.157960638755335
Trained batch 53 in epoch 8, gen_loss = 0.40790511005454594, disc_loss = 0.1573110224886073
Trained batch 54 in epoch 8, gen_loss = 0.4083064626563679, disc_loss = 0.15668540454723617
Trained batch 55 in epoch 8, gen_loss = 0.40872233573879513, disc_loss = 0.15640547306143812
Trained batch 56 in epoch 8, gen_loss = 0.4097332583184828, disc_loss = 0.15539099138818288
Trained batch 57 in epoch 8, gen_loss = 0.4093030382846964, disc_loss = 0.15489149909338046
Trained batch 58 in epoch 8, gen_loss = 0.40940691000324186, disc_loss = 0.15434651752397166
Trained batch 59 in epoch 8, gen_loss = 0.409720770517985, disc_loss = 0.1537176078185439
Trained batch 60 in epoch 8, gen_loss = 0.40935006395715184, disc_loss = 0.15398199960100847
Trained batch 61 in epoch 8, gen_loss = 0.4098239267064679, disc_loss = 0.15692659954149876
Trained batch 62 in epoch 8, gen_loss = 0.410969062457009, disc_loss = 0.15734426848708638
Trained batch 63 in epoch 8, gen_loss = 0.41098114429041743, disc_loss = 0.15647686627926305
Trained batch 64 in epoch 8, gen_loss = 0.410858365205618, disc_loss = 0.1558520785317971
Trained batch 65 in epoch 8, gen_loss = 0.41119240269516455, disc_loss = 0.15621456690132618
Trained batch 66 in epoch 8, gen_loss = 0.41216359387582807, disc_loss = 0.1583583226510838
Trained batch 67 in epoch 8, gen_loss = 0.41119320778285756, disc_loss = 0.16105357343878815
Trained batch 68 in epoch 8, gen_loss = 0.4114048407561537, disc_loss = 0.160812893477471
Trained batch 69 in epoch 8, gen_loss = 0.41146313164915355, disc_loss = 0.16138745615524905
Trained batch 70 in epoch 8, gen_loss = 0.4118762490615039, disc_loss = 0.16083877108676334
Trained batch 71 in epoch 8, gen_loss = 0.41234242874715066, disc_loss = 0.16041298215794894
Trained batch 72 in epoch 8, gen_loss = 0.4118706518656587, disc_loss = 0.1606081659357025
Trained batch 73 in epoch 8, gen_loss = 0.4114053378234038, disc_loss = 0.16019018684085962
Trained batch 74 in epoch 8, gen_loss = 0.41119981090227764, disc_loss = 0.16025662168860436
Trained batch 75 in epoch 8, gen_loss = 0.4113105178663605, disc_loss = 0.15972385315322563
Trained batch 76 in epoch 8, gen_loss = 0.41140717500216, disc_loss = 0.15895497242545154
Trained batch 77 in epoch 8, gen_loss = 0.4111259701924446, disc_loss = 0.15871148484830672
Trained batch 78 in epoch 8, gen_loss = 0.41049842743933956, disc_loss = 0.15855525174661528
Trained batch 79 in epoch 8, gen_loss = 0.4103122539818287, disc_loss = 0.158269794145599
Trained batch 80 in epoch 8, gen_loss = 0.4109434150619271, disc_loss = 0.1584419257203002
Trained batch 81 in epoch 8, gen_loss = 0.4109371925999479, disc_loss = 0.15853315014846442
Trained batch 82 in epoch 8, gen_loss = 0.4107361622603543, disc_loss = 0.1581139471606318
Trained batch 83 in epoch 8, gen_loss = 0.4109645897433871, disc_loss = 0.15798944860164607
Trained batch 84 in epoch 8, gen_loss = 0.4108041843947242, disc_loss = 0.15880243694957566
Trained batch 85 in epoch 8, gen_loss = 0.4116236286800961, disc_loss = 0.15833059460097967
Trained batch 86 in epoch 8, gen_loss = 0.41154963291924573, disc_loss = 0.15690828281743774
Trained batch 87 in epoch 8, gen_loss = 0.4111763635142283, disc_loss = 0.1604192269204015
Trained batch 88 in epoch 8, gen_loss = 0.4109036323059811, disc_loss = 0.16081977999779615
Trained batch 89 in epoch 8, gen_loss = 0.41081513199541303, disc_loss = 0.16068910331361824
Trained batch 90 in epoch 8, gen_loss = 0.4104999130243783, disc_loss = 0.16111306948484955
Trained batch 91 in epoch 8, gen_loss = 0.4105980561479278, disc_loss = 0.1606704904090451
Trained batch 92 in epoch 8, gen_loss = 0.4113308915527918, disc_loss = 0.16032833425748733
Trained batch 93 in epoch 8, gen_loss = 0.4111700302108805, disc_loss = 0.15911340725390202
Trained batch 94 in epoch 8, gen_loss = 0.4112360872720417, disc_loss = 0.1581294963626485
Trained batch 95 in epoch 8, gen_loss = 0.4112360452612241, disc_loss = 0.15720385829141983
Trained batch 96 in epoch 8, gen_loss = 0.411055414332557, disc_loss = 0.15683806921864293
Trained batch 97 in epoch 8, gen_loss = 0.4116800688967413, disc_loss = 0.15683780013754658
Trained batch 98 in epoch 8, gen_loss = 0.4120387952737134, disc_loss = 0.1567799173144981
Trained batch 99 in epoch 8, gen_loss = 0.41179441541433337, disc_loss = 0.15644467186182737
Trained batch 100 in epoch 8, gen_loss = 0.41102638102994105, disc_loss = 0.15641381300174365
Trained batch 101 in epoch 8, gen_loss = 0.4111790703792198, disc_loss = 0.15586301242457887
Trained batch 102 in epoch 8, gen_loss = 0.4118835746663288, disc_loss = 0.1563527434702637
Trained batch 103 in epoch 8, gen_loss = 0.41142978032047933, disc_loss = 0.15604726092603344
Trained batch 104 in epoch 8, gen_loss = 0.4111947732312339, disc_loss = 0.15551358003701482
Trained batch 105 in epoch 8, gen_loss = 0.4109333725470417, disc_loss = 0.15518637630596477
Trained batch 106 in epoch 8, gen_loss = 0.41076414858069377, disc_loss = 0.1552379803610182
Trained batch 107 in epoch 8, gen_loss = 0.410519957266472, disc_loss = 0.15569065562966797
Trained batch 108 in epoch 8, gen_loss = 0.4104647852412058, disc_loss = 0.1561929148476605
Trained batch 109 in epoch 8, gen_loss = 0.4101091875271364, disc_loss = 0.1574786963449283
Trained batch 110 in epoch 8, gen_loss = 0.4102118971111538, disc_loss = 0.15756666173671816
Trained batch 111 in epoch 8, gen_loss = 0.4102968307478087, disc_loss = 0.15688091007593488
Trained batch 112 in epoch 8, gen_loss = 0.41048234041813203, disc_loss = 0.15602580342540698
Trained batch 113 in epoch 8, gen_loss = 0.41057317612463967, disc_loss = 0.15538102607324458
Trained batch 114 in epoch 8, gen_loss = 0.4102832312169282, disc_loss = 0.15518255411930706
Trained batch 115 in epoch 8, gen_loss = 0.41021600365638733, disc_loss = 0.15457726626432147
Trained batch 116 in epoch 8, gen_loss = 0.41021891180266684, disc_loss = 0.15394498926834163
Trained batch 117 in epoch 8, gen_loss = 0.4104710302110446, disc_loss = 0.15337125840202226
Trained batch 118 in epoch 8, gen_loss = 0.41045803232353273, disc_loss = 0.15278263098928108
Trained batch 119 in epoch 8, gen_loss = 0.4100182749330997, disc_loss = 0.1527842849182586
Trained batch 120 in epoch 8, gen_loss = 0.41016700395867844, disc_loss = 0.15255848370677183
Trained batch 121 in epoch 8, gen_loss = 0.4103036127129539, disc_loss = 0.15276668950548913
Trained batch 122 in epoch 8, gen_loss = 0.4097507109002369, disc_loss = 0.15265072273408495
Trained batch 123 in epoch 8, gen_loss = 0.40925238449727336, disc_loss = 0.15306817220463867
Trained batch 124 in epoch 8, gen_loss = 0.4094227902889252, disc_loss = 0.1540062116086483
Trained batch 125 in epoch 8, gen_loss = 0.4093137766633715, disc_loss = 0.15381255825715406
Trained batch 126 in epoch 8, gen_loss = 0.40930127205811145, disc_loss = 0.1536432307242878
Trained batch 127 in epoch 8, gen_loss = 0.4090095842257142, disc_loss = 0.15385584204341285
Trained batch 128 in epoch 8, gen_loss = 0.4088575142298558, disc_loss = 0.15453586880435316
Trained batch 129 in epoch 8, gen_loss = 0.40906928456746616, disc_loss = 0.15417792536318303
Trained batch 130 in epoch 8, gen_loss = 0.40927090581136805, disc_loss = 0.15478150867892584
Trained batch 131 in epoch 8, gen_loss = 0.4084581138961243, disc_loss = 0.1557457744228569
Trained batch 132 in epoch 8, gen_loss = 0.40842133491559135, disc_loss = 0.15534146693079992
Trained batch 133 in epoch 8, gen_loss = 0.40850176762289075, disc_loss = 0.15537011748485602
Trained batch 134 in epoch 8, gen_loss = 0.40822242829534744, disc_loss = 0.15519525676413817
Trained batch 135 in epoch 8, gen_loss = 0.4080045593573767, disc_loss = 0.15554358977276614
Trained batch 136 in epoch 8, gen_loss = 0.40791507511243336, disc_loss = 0.1551351421342714
Trained batch 137 in epoch 8, gen_loss = 0.40788867616135144, disc_loss = 0.15462677707166775
Trained batch 138 in epoch 8, gen_loss = 0.4081316909772887, disc_loss = 0.15412464654810137
Trained batch 139 in epoch 8, gen_loss = 0.4085909019623484, disc_loss = 0.15397184419312648
Trained batch 140 in epoch 8, gen_loss = 0.40843001092579345, disc_loss = 0.15347953153945876
Trained batch 141 in epoch 8, gen_loss = 0.4085939715445881, disc_loss = 0.15300826647017204
Trained batch 142 in epoch 8, gen_loss = 0.40840038469621354, disc_loss = 0.1528235909665798
Trained batch 143 in epoch 8, gen_loss = 0.40832343076666194, disc_loss = 0.1536112972276492
Trained batch 144 in epoch 8, gen_loss = 0.408682677047006, disc_loss = 0.15447885478878842
Trained batch 145 in epoch 8, gen_loss = 0.40863699659909286, disc_loss = 0.15377227888021566
Trained batch 146 in epoch 8, gen_loss = 0.40882139688446406, disc_loss = 0.1530375013596752
Trained batch 147 in epoch 8, gen_loss = 0.4088443948610409, disc_loss = 0.15249613740456266
Trained batch 148 in epoch 8, gen_loss = 0.40858725353375375, disc_loss = 0.1526022320175731
Trained batch 149 in epoch 8, gen_loss = 0.4086495568354925, disc_loss = 0.15302522666752338
Trained batch 150 in epoch 8, gen_loss = 0.40838073795994384, disc_loss = 0.15289971180605572
Trained batch 151 in epoch 8, gen_loss = 0.4084466721274351, disc_loss = 0.15236328245679798
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.43264758586883545, disc_loss = 0.10115014016628265
Trained batch 1 in epoch 9, gen_loss = 0.4035431742668152, disc_loss = 0.07034963555634022
Trained batch 2 in epoch 9, gen_loss = 0.37911654512087506, disc_loss = 0.20482106134295464
Trained batch 3 in epoch 9, gen_loss = 0.4030003175139427, disc_loss = 0.19060163293033838
Trained batch 4 in epoch 9, gen_loss = 0.39501752257347106, disc_loss = 0.1769493229687214
Trained batch 5 in epoch 9, gen_loss = 0.3990977356831233, disc_loss = 0.1542957021544377
Trained batch 6 in epoch 9, gen_loss = 0.4108131527900696, disc_loss = 0.1381062992981502
Trained batch 7 in epoch 9, gen_loss = 0.4103914499282837, disc_loss = 0.1418889444321394
Trained batch 8 in epoch 9, gen_loss = 0.41735202736324734, disc_loss = 0.13865572545263502
Trained batch 9 in epoch 9, gen_loss = 0.4132366955280304, disc_loss = 0.1434843897819519
Trained batch 10 in epoch 9, gen_loss = 0.4145017320459539, disc_loss = 0.14171916178681634
Trained batch 11 in epoch 9, gen_loss = 0.4151047021150589, disc_loss = 0.13992898228267828
Trained batch 12 in epoch 9, gen_loss = 0.41600408920874965, disc_loss = 0.14002485630603936
Trained batch 13 in epoch 9, gen_loss = 0.42094172324453083, disc_loss = 0.13371146097779274
Trained batch 14 in epoch 9, gen_loss = 0.4192055702209473, disc_loss = 0.12780361920595168
Trained batch 15 in epoch 9, gen_loss = 0.41487803496420383, disc_loss = 0.13186081824824214
Trained batch 16 in epoch 9, gen_loss = 0.41854187846183777, disc_loss = 0.13546115817392573
Trained batch 17 in epoch 9, gen_loss = 0.41761167844136554, disc_loss = 0.13514785427186224
Trained batch 18 in epoch 9, gen_loss = 0.4163568537486227, disc_loss = 0.1339013474552255
Trained batch 19 in epoch 9, gen_loss = 0.41328779309988023, disc_loss = 0.13289398215711118
Trained batch 20 in epoch 9, gen_loss = 0.4131659311907632, disc_loss = 0.13493505794377553
Trained batch 21 in epoch 9, gen_loss = 0.4132363931699233, disc_loss = 0.13823418420824138
Trained batch 22 in epoch 9, gen_loss = 0.41929361872051074, disc_loss = 0.13361388525885085
Trained batch 23 in epoch 9, gen_loss = 0.41592709595958394, disc_loss = 0.1396134627672533
Trained batch 24 in epoch 9, gen_loss = 0.41710843563079836, disc_loss = 0.1399707831442356
Trained batch 25 in epoch 9, gen_loss = 0.41617527489478773, disc_loss = 0.14030980734297863
Trained batch 26 in epoch 9, gen_loss = 0.41315730412801105, disc_loss = 0.13869299725801856
Trained batch 27 in epoch 9, gen_loss = 0.41274459872926983, disc_loss = 0.13792886704738652
Trained batch 28 in epoch 9, gen_loss = 0.4122122423402194, disc_loss = 0.13896607851673817
Trained batch 29 in epoch 9, gen_loss = 0.41075145204861957, disc_loss = 0.1404252947618564
Trained batch 30 in epoch 9, gen_loss = 0.4108118722515722, disc_loss = 0.14046352633064793
Trained batch 31 in epoch 9, gen_loss = 0.4120655879378319, disc_loss = 0.14119318139273673
Trained batch 32 in epoch 9, gen_loss = 0.41123686505086493, disc_loss = 0.14133690354047398
Trained batch 33 in epoch 9, gen_loss = 0.4115001988761565, disc_loss = 0.14055959716000976
Trained batch 34 in epoch 9, gen_loss = 0.41058456386838643, disc_loss = 0.14018622391990254
Trained batch 35 in epoch 9, gen_loss = 0.4093244887060589, disc_loss = 0.14085819996479484
Trained batch 36 in epoch 9, gen_loss = 0.4089489007318342, disc_loss = 0.1402435923951703
Trained batch 37 in epoch 9, gen_loss = 0.4098597012068096, disc_loss = 0.13884459034000574
Trained batch 38 in epoch 9, gen_loss = 0.41019161695089096, disc_loss = 0.13749661115117562
Trained batch 39 in epoch 9, gen_loss = 0.4092951320111752, disc_loss = 0.14080735137686134
Trained batch 40 in epoch 9, gen_loss = 0.4119126411472879, disc_loss = 0.14516546513612677
Trained batch 41 in epoch 9, gen_loss = 0.4117480864127477, disc_loss = 0.14415169462916397
Trained batch 42 in epoch 9, gen_loss = 0.4109305753264316, disc_loss = 0.1438483127154583
Trained batch 43 in epoch 9, gen_loss = 0.4120656827634031, disc_loss = 0.14392256186428395
Trained batch 44 in epoch 9, gen_loss = 0.4116601076391008, disc_loss = 0.14231170871191554
Trained batch 45 in epoch 9, gen_loss = 0.4111494726460913, disc_loss = 0.14156616730210575
Trained batch 46 in epoch 9, gen_loss = 0.4113822680838565, disc_loss = 0.13998534031053808
Trained batch 47 in epoch 9, gen_loss = 0.4117924788345893, disc_loss = 0.13903817154156664
Trained batch 48 in epoch 9, gen_loss = 0.41096615548036536, disc_loss = 0.1399474459491214
Trained batch 49 in epoch 9, gen_loss = 0.4095337641239166, disc_loss = 0.1399786438792944
Trained batch 50 in epoch 9, gen_loss = 0.4096857928762249, disc_loss = 0.1393967595900975
Trained batch 51 in epoch 9, gen_loss = 0.4090481543770203, disc_loss = 0.140120803235242
Trained batch 52 in epoch 9, gen_loss = 0.4085881198352238, disc_loss = 0.1396842082294653
Trained batch 53 in epoch 9, gen_loss = 0.4089493547324781, disc_loss = 0.13934985293006455
Trained batch 54 in epoch 9, gen_loss = 0.41011977141553707, disc_loss = 0.1394413134591146
Trained batch 55 in epoch 9, gen_loss = 0.4098171591758728, disc_loss = 0.13960258523002267
Trained batch 56 in epoch 9, gen_loss = 0.41075088423595096, disc_loss = 0.13973725959658623
Trained batch 57 in epoch 9, gen_loss = 0.41065932296473406, disc_loss = 0.13944309403927163
Trained batch 58 in epoch 9, gen_loss = 0.4102985399254298, disc_loss = 0.14186338619407962
Trained batch 59 in epoch 9, gen_loss = 0.41136069347461063, disc_loss = 0.1435624660924077
Trained batch 60 in epoch 9, gen_loss = 0.41034843736007565, disc_loss = 0.1442596220457163
Trained batch 61 in epoch 9, gen_loss = 0.41058143204258335, disc_loss = 0.14406846722047176
Trained batch 62 in epoch 9, gen_loss = 0.4099960469064258, disc_loss = 0.14401346320907274
Trained batch 63 in epoch 9, gen_loss = 0.4100368400104344, disc_loss = 0.14332813321379945
Trained batch 64 in epoch 9, gen_loss = 0.4103575601027562, disc_loss = 0.14222272170277742
Trained batch 65 in epoch 9, gen_loss = 0.40969836350643274, disc_loss = 0.1415019068641193
Trained batch 66 in epoch 9, gen_loss = 0.4095270704867235, disc_loss = 0.14174127995745459
Trained batch 67 in epoch 9, gen_loss = 0.40991004863206076, disc_loss = 0.14151979276143453
Trained batch 68 in epoch 9, gen_loss = 0.4096377219842828, disc_loss = 0.14135364988359853
Trained batch 69 in epoch 9, gen_loss = 0.40867990936551774, disc_loss = 0.14221242533198425
Trained batch 70 in epoch 9, gen_loss = 0.4096159171050703, disc_loss = 0.14215766496851412
Trained batch 71 in epoch 9, gen_loss = 0.40909460311134654, disc_loss = 0.1423337744652397
Trained batch 72 in epoch 9, gen_loss = 0.4092028594180329, disc_loss = 0.1432941110472973
Trained batch 73 in epoch 9, gen_loss = 0.4092316728185963, disc_loss = 0.14376601833548094
Trained batch 74 in epoch 9, gen_loss = 0.40939536174138386, disc_loss = 0.14311269397536913
Trained batch 75 in epoch 9, gen_loss = 0.40943049796317754, disc_loss = 0.14266882204499684
Trained batch 76 in epoch 9, gen_loss = 0.40896402125234727, disc_loss = 0.14357415165800552
Trained batch 77 in epoch 9, gen_loss = 0.40958086802409244, disc_loss = 0.14340161317243025
Trained batch 78 in epoch 9, gen_loss = 0.41033832672276077, disc_loss = 0.14252041200105148
Trained batch 79 in epoch 9, gen_loss = 0.409766535833478, disc_loss = 0.14431748925708235
Trained batch 80 in epoch 9, gen_loss = 0.4104343093471763, disc_loss = 0.14429506930856056
Trained batch 81 in epoch 9, gen_loss = 0.4108678055245702, disc_loss = 0.14334300155864982
Trained batch 82 in epoch 9, gen_loss = 0.41031390931232864, disc_loss = 0.1427817762526403
Trained batch 83 in epoch 9, gen_loss = 0.40975287024463924, disc_loss = 0.14224180601359832
Trained batch 84 in epoch 9, gen_loss = 0.4092324302476995, disc_loss = 0.1416695885360241
Trained batch 85 in epoch 9, gen_loss = 0.4087012763633284, disc_loss = 0.14134430057953956
Trained batch 86 in epoch 9, gen_loss = 0.4093269359791416, disc_loss = 0.140857490272015
Trained batch 87 in epoch 9, gen_loss = 0.40952126173810527, disc_loss = 0.14084011464464394
Trained batch 88 in epoch 9, gen_loss = 0.40957504678308293, disc_loss = 0.14022868716817224
Trained batch 89 in epoch 9, gen_loss = 0.40934345854653253, disc_loss = 0.14006736208167342
Trained batch 90 in epoch 9, gen_loss = 0.40881683538248254, disc_loss = 0.14154603516498765
Trained batch 91 in epoch 9, gen_loss = 0.41004730113174603, disc_loss = 0.14249217198432787
Trained batch 92 in epoch 9, gen_loss = 0.41051499369323896, disc_loss = 0.14157629201328883
Trained batch 93 in epoch 9, gen_loss = 0.40996731881131515, disc_loss = 0.14076157377913912
Trained batch 94 in epoch 9, gen_loss = 0.40930428818652503, disc_loss = 0.14143747565777678
Trained batch 95 in epoch 9, gen_loss = 0.40956767306973535, disc_loss = 0.1421385578578338
Trained batch 96 in epoch 9, gen_loss = 0.40930093840225457, disc_loss = 0.14239245534096798
Trained batch 97 in epoch 9, gen_loss = 0.40929006131327883, disc_loss = 0.14251619413951222
Trained batch 98 in epoch 9, gen_loss = 0.40910306693327547, disc_loss = 0.1418613287610839
Trained batch 99 in epoch 9, gen_loss = 0.4092817857861519, disc_loss = 0.14144916210323571
Trained batch 100 in epoch 9, gen_loss = 0.4093592084280335, disc_loss = 0.14127688718461753
Trained batch 101 in epoch 9, gen_loss = 0.4098761888111339, disc_loss = 0.14129581174575814
Trained batch 102 in epoch 9, gen_loss = 0.40996404585329077, disc_loss = 0.14062591558955248
Trained batch 103 in epoch 9, gen_loss = 0.4100968250288413, disc_loss = 0.14048881939827249
Trained batch 104 in epoch 9, gen_loss = 0.41051169350033717, disc_loss = 0.14106234265934853
Trained batch 105 in epoch 9, gen_loss = 0.4109019209753792, disc_loss = 0.13992192070790618
Trained batch 106 in epoch 9, gen_loss = 0.41084107756614685, disc_loss = 0.14056682762489697
Trained batch 107 in epoch 9, gen_loss = 0.41216587330456134, disc_loss = 0.14062091909969845
Trained batch 108 in epoch 9, gen_loss = 0.4125053117034632, disc_loss = 0.14002015040076654
Trained batch 109 in epoch 9, gen_loss = 0.41210249066352844, disc_loss = 0.14014715228907088
Trained batch 110 in epoch 9, gen_loss = 0.4122157617732211, disc_loss = 0.1414170407664937
Trained batch 111 in epoch 9, gen_loss = 0.4116025742675577, disc_loss = 0.14147298784726964
Trained batch 112 in epoch 9, gen_loss = 0.4110444789439176, disc_loss = 0.14186852064346317
Trained batch 113 in epoch 9, gen_loss = 0.41099719467915985, disc_loss = 0.14160227809885614
Trained batch 114 in epoch 9, gen_loss = 0.4115652716678122, disc_loss = 0.14184079631839108
Trained batch 115 in epoch 9, gen_loss = 0.4116541884582618, disc_loss = 0.14173083773268194
Trained batch 116 in epoch 9, gen_loss = 0.4114720319580828, disc_loss = 0.14155789020542914
Trained batch 117 in epoch 9, gen_loss = 0.41127268414376145, disc_loss = 0.1412797864621221
Trained batch 118 in epoch 9, gen_loss = 0.41111377006819266, disc_loss = 0.14112027178855002
Trained batch 119 in epoch 9, gen_loss = 0.4107890864213308, disc_loss = 0.14095313674770296
Trained batch 120 in epoch 9, gen_loss = 0.41087146879227693, disc_loss = 0.14087774957076085
Trained batch 121 in epoch 9, gen_loss = 0.411174439993061, disc_loss = 0.14091481269932674
Trained batch 122 in epoch 9, gen_loss = 0.4111888723644784, disc_loss = 0.14091579447977426
Trained batch 123 in epoch 9, gen_loss = 0.41074623071378275, disc_loss = 0.14102085825476435
Trained batch 124 in epoch 9, gen_loss = 0.4103601665496826, disc_loss = 0.14103622759878637
Trained batch 125 in epoch 9, gen_loss = 0.4100937479072147, disc_loss = 0.1410436462463131
Trained batch 126 in epoch 9, gen_loss = 0.4101600032153092, disc_loss = 0.14156135190718286
Trained batch 127 in epoch 9, gen_loss = 0.4102100853342563, disc_loss = 0.14231364383886103
Trained batch 128 in epoch 9, gen_loss = 0.4101609576118085, disc_loss = 0.14243893061093119
Trained batch 129 in epoch 9, gen_loss = 0.410067545909148, disc_loss = 0.14212785399017425
Trained batch 130 in epoch 9, gen_loss = 0.4101209076306292, disc_loss = 0.1419516215029791
Trained batch 131 in epoch 9, gen_loss = 0.4100587065472747, disc_loss = 0.14134877893339956
Trained batch 132 in epoch 9, gen_loss = 0.4097857795711747, disc_loss = 0.14129426712660412
Trained batch 133 in epoch 9, gen_loss = 0.41024350719665414, disc_loss = 0.14067052939990118
Trained batch 134 in epoch 9, gen_loss = 0.41042813504183734, disc_loss = 0.14032961970402136
Trained batch 135 in epoch 9, gen_loss = 0.4104347739587812, disc_loss = 0.14044600091052845
Trained batch 136 in epoch 9, gen_loss = 0.4104371775675864, disc_loss = 0.14017713060398607
Trained batch 137 in epoch 9, gen_loss = 0.41066439363403595, disc_loss = 0.1402989696252389
Trained batch 138 in epoch 9, gen_loss = 0.4103682041168213, disc_loss = 0.1406803989930333
Trained batch 139 in epoch 9, gen_loss = 0.41048132330179216, disc_loss = 0.14164448945916125
Trained batch 140 in epoch 9, gen_loss = 0.4101034825575267, disc_loss = 0.14212988698788992
Trained batch 141 in epoch 9, gen_loss = 0.410267249169484, disc_loss = 0.1420409042571842
Trained batch 142 in epoch 9, gen_loss = 0.41018639640374616, disc_loss = 0.14225691120576608
Trained batch 143 in epoch 9, gen_loss = 0.4103421134253343, disc_loss = 0.14198290025039265
Trained batch 144 in epoch 9, gen_loss = 0.4102923043842973, disc_loss = 0.14206229023121555
Trained batch 145 in epoch 9, gen_loss = 0.41047731082733363, disc_loss = 0.14178674572389827
Trained batch 146 in epoch 9, gen_loss = 0.41016467979976107, disc_loss = 0.14260374380871146
Trained batch 147 in epoch 9, gen_loss = 0.4102638859201122, disc_loss = 0.14289208719305493
Trained batch 148 in epoch 9, gen_loss = 0.4097254998331902, disc_loss = 0.1430270703471947
Trained batch 149 in epoch 9, gen_loss = 0.4097637619574865, disc_loss = 0.14311257477849723
Trained batch 150 in epoch 9, gen_loss = 0.409993333137588, disc_loss = 0.14301706471831988
Trained batch 151 in epoch 9, gen_loss = 0.4097599520495063, disc_loss = 0.1429983319249004
Testing Epoch 9
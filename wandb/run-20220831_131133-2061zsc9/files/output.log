wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/work3/soeba/HALOS/halos/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Training Epoch 0
Trained batch 0 in epoch 0, gen_loss = 0.5134774446487427, disc_loss = 0.5741719603538513
Trained batch 1 in epoch 0, gen_loss = 0.5270460844039917, disc_loss = 0.6081432402133942
Trained batch 2 in epoch 0, gen_loss = 0.5065239071846008, disc_loss = 0.5698888500531515
Trained batch 3 in epoch 0, gen_loss = 0.507585346698761, disc_loss = 0.5169628709554672
Trained batch 4 in epoch 0, gen_loss = 0.49194822311401365, disc_loss = 0.46155036985874176
Trained batch 5 in epoch 0, gen_loss = 0.48022573192914325, disc_loss = 0.41487208753824234
Trained batch 6 in epoch 0, gen_loss = 0.4757654879774366, disc_loss = 0.3829454630613327
Trained batch 7 in epoch 0, gen_loss = 0.4748796299099922, disc_loss = 0.35205385833978653
Trained batch 8 in epoch 0, gen_loss = 0.47043827507230973, disc_loss = 0.32391640212800765
Trained batch 9 in epoch 0, gen_loss = 0.4704753279685974, disc_loss = 0.3000779554247856
Trained batch 10 in epoch 0, gen_loss = 0.46770523623986676, disc_loss = 0.2802944921634414
Trained batch 11 in epoch 0, gen_loss = 0.46195685615142185, disc_loss = 0.26260229138036567
Trained batch 12 in epoch 0, gen_loss = 0.458802363047233, disc_loss = 0.24813413218810007
Trained batch 13 in epoch 0, gen_loss = 0.456985096846308, disc_loss = 0.23696289796914374
Trained batch 14 in epoch 0, gen_loss = 0.45781525572141013, disc_loss = 0.23064215232928595
Trained batch 15 in epoch 0, gen_loss = 0.45710891857743263, disc_loss = 0.22865453409031034
Trained batch 16 in epoch 0, gen_loss = 0.45512129804667306, disc_loss = 0.2301276190315976
Trained batch 17 in epoch 0, gen_loss = 0.4563219878408644, disc_loss = 0.23915350147419506
Trained batch 18 in epoch 0, gen_loss = 0.45896370159952266, disc_loss = 0.23651015170310674
Trained batch 19 in epoch 0, gen_loss = 0.46230529248714447, disc_loss = 0.23115952946245671
Trained batch 20 in epoch 0, gen_loss = 0.46217010418574017, disc_loss = 0.22441744875340236
Trained batch 21 in epoch 0, gen_loss = 0.4585762349042026, disc_loss = 0.2189387469129129
Trained batch 22 in epoch 0, gen_loss = 0.45504815293395, disc_loss = 0.2146639461102693
Trained batch 23 in epoch 0, gen_loss = 0.458100538700819, disc_loss = 0.20912636226663986
Trained batch 24 in epoch 0, gen_loss = 0.4579662549495697, disc_loss = 0.20355529844760895
Trained batch 25 in epoch 0, gen_loss = 0.45663671768628633, disc_loss = 0.20081301377369806
Trained batch 26 in epoch 0, gen_loss = 0.45760193687898143, disc_loss = 0.19600178328929124
Trained batch 27 in epoch 0, gen_loss = 0.45630945158856256, disc_loss = 0.19187513180077076
Trained batch 28 in epoch 0, gen_loss = 0.4534528882339083, disc_loss = 0.1867965231167859
Trained batch 29 in epoch 0, gen_loss = 0.4537822544574738, disc_loss = 0.1849092441300551
Trained batch 30 in epoch 0, gen_loss = 0.45508718490600586, disc_loss = 0.1808330181144899
Trained batch 31 in epoch 0, gen_loss = 0.45895177498459816, disc_loss = 0.1777790654450655
Trained batch 32 in epoch 0, gen_loss = 0.4592717732443954, disc_loss = 0.1751815608956597
Trained batch 33 in epoch 0, gen_loss = 0.4572717459762798, disc_loss = 0.17446409384993947
Trained batch 34 in epoch 0, gen_loss = 0.459522693497794, disc_loss = 0.1712983135666166
Trained batch 35 in epoch 0, gen_loss = 0.45904208140240776, disc_loss = 0.16804734410511124
Trained batch 36 in epoch 0, gen_loss = 0.4588755200038085, disc_loss = 0.1647976284494271
Trained batch 37 in epoch 0, gen_loss = 0.45749064887824814, disc_loss = 0.16161844448039406
Trained batch 38 in epoch 0, gen_loss = 0.4580187637072343, disc_loss = 0.1588363508001352
Trained batch 39 in epoch 0, gen_loss = 0.4587870940566063, disc_loss = 0.15578201375901699
Trained batch 40 in epoch 0, gen_loss = 0.4608506589401059, disc_loss = 0.15276451381604847
Trained batch 41 in epoch 0, gen_loss = 0.46242546751385644, disc_loss = 0.14975707392607415
Trained batch 42 in epoch 0, gen_loss = 0.4617521672747856, disc_loss = 0.14700988428883774
Trained batch 43 in epoch 0, gen_loss = 0.4609061438928951, disc_loss = 0.14450681116431952
Trained batch 44 in epoch 0, gen_loss = 0.4592330574989319, disc_loss = 0.14345679009954135
Trained batch 45 in epoch 0, gen_loss = 0.4579636752605438, disc_loss = 0.14506371246407862
Trained batch 46 in epoch 0, gen_loss = 0.4587825929864924, disc_loss = 0.14413665353934815
Trained batch 47 in epoch 0, gen_loss = 0.4604608416557312, disc_loss = 0.14228359974610308
Trained batch 48 in epoch 0, gen_loss = 0.46206670634600583, disc_loss = 0.14052446771945273
Trained batch 49 in epoch 0, gen_loss = 0.4620400667190552, disc_loss = 0.1384053211659193
Trained batch 50 in epoch 0, gen_loss = 0.46234916121351954, disc_loss = 0.13636762919087037
Trained batch 51 in epoch 0, gen_loss = 0.4616689716394131, disc_loss = 0.1345016916927237
Trained batch 52 in epoch 0, gen_loss = 0.46237780069405177, disc_loss = 0.13260231588808996
Trained batch 53 in epoch 0, gen_loss = 0.4614002561127698, disc_loss = 0.13098002625284372
Trained batch 54 in epoch 0, gen_loss = 0.46045493320985276, disc_loss = 0.12942857227542184
Trained batch 55 in epoch 0, gen_loss = 0.45998202157872065, disc_loss = 0.127835805727435
Trained batch 56 in epoch 0, gen_loss = 0.46154989171446414, disc_loss = 0.12625906727554506
Trained batch 57 in epoch 0, gen_loss = 0.4609873762418484, disc_loss = 0.1252581335218816
Trained batch 58 in epoch 0, gen_loss = 0.45919569720656184, disc_loss = 0.1252073973291001
Trained batch 59 in epoch 0, gen_loss = 0.46077215125163395, disc_loss = 0.12414161829898755
Trained batch 60 in epoch 0, gen_loss = 0.46168878088231946, disc_loss = 0.12263934314250946
Trained batch 61 in epoch 0, gen_loss = 0.46196594305576816, disc_loss = 0.12139922572720435
Trained batch 62 in epoch 0, gen_loss = 0.46107212560517447, disc_loss = 0.12013239443065628
Trained batch 63 in epoch 0, gen_loss = 0.46183800557628274, disc_loss = 0.11883828038116917
Trained batch 64 in epoch 0, gen_loss = 0.4623798384116246, disc_loss = 0.11748206503689289
Trained batch 65 in epoch 0, gen_loss = 0.46229188866687543, disc_loss = 0.11609077699143779
Trained batch 66 in epoch 0, gen_loss = 0.46131301949273296, disc_loss = 0.1147812679131974
Trained batch 67 in epoch 0, gen_loss = 0.46192896760561886, disc_loss = 0.11389483245747055
Trained batch 68 in epoch 0, gen_loss = 0.4617655061293339, disc_loss = 0.11322424039784548
Trained batch 69 in epoch 0, gen_loss = 0.4630484529903957, disc_loss = 0.11226693894714117
Trained batch 70 in epoch 0, gen_loss = 0.46365812630720543, disc_loss = 0.1110600301549888
Trained batch 71 in epoch 0, gen_loss = 0.4634283085664113, disc_loss = 0.10999627807177603
Trained batch 72 in epoch 0, gen_loss = 0.4631262254225065, disc_loss = 0.10892983645915169
Trained batch 73 in epoch 0, gen_loss = 0.46330398562792185, disc_loss = 0.10779020995707125
Trained batch 74 in epoch 0, gen_loss = 0.4635335369904836, disc_loss = 0.1067296892652909
Trained batch 75 in epoch 0, gen_loss = 0.46453746094515447, disc_loss = 0.10567353825133882
Trained batch 76 in epoch 0, gen_loss = 0.46484017488244295, disc_loss = 0.1045314667915756
Trained batch 77 in epoch 0, gen_loss = 0.4646241855927003, disc_loss = 0.10348187594746168
Trained batch 78 in epoch 0, gen_loss = 0.4651438495780848, disc_loss = 0.10252696337013305
Trained batch 79 in epoch 0, gen_loss = 0.4652012262493372, disc_loss = 0.10156896975822746
Trained batch 80 in epoch 0, gen_loss = 0.46509584269405885, disc_loss = 0.10061512537944464
Trained batch 81 in epoch 0, gen_loss = 0.4657765732305806, disc_loss = 0.09963009197537492
Trained batch 82 in epoch 0, gen_loss = 0.4655612771769604, disc_loss = 0.09908733840089247
Trained batch 83 in epoch 0, gen_loss = 0.46598011751969654, disc_loss = 0.09886013193144685
Trained batch 84 in epoch 0, gen_loss = 0.4669532895088196, disc_loss = 0.09835031733793372
Trained batch 85 in epoch 0, gen_loss = 0.4675221152083818, disc_loss = 0.09817582377514174
Trained batch 86 in epoch 0, gen_loss = 0.4674507869386125, disc_loss = 0.09737826791731105
Trained batch 87 in epoch 0, gen_loss = 0.4668240225450559, disc_loss = 0.09686554530212148
Trained batch 88 in epoch 0, gen_loss = 0.4670204580499885, disc_loss = 0.09616055190981773
Trained batch 89 in epoch 0, gen_loss = 0.4673122869597541, disc_loss = 0.09611721272683806
Trained batch 90 in epoch 0, gen_loss = 0.46688778911318096, disc_loss = 0.09654355738926065
Trained batch 91 in epoch 0, gen_loss = 0.46648935779281286, disc_loss = 0.096374344424871
Trained batch 92 in epoch 0, gen_loss = 0.46658123436794485, disc_loss = 0.09563650240901336
Trained batch 93 in epoch 0, gen_loss = 0.46615813228678193, disc_loss = 0.09503363070890625
Trained batch 94 in epoch 0, gen_loss = 0.466742815155732, disc_loss = 0.09464468620717525
Trained batch 95 in epoch 0, gen_loss = 0.4675795941924055, disc_loss = 0.09456001899282758
Trained batch 96 in epoch 0, gen_loss = 0.46760678322044846, disc_loss = 0.09501073864701483
Trained batch 97 in epoch 0, gen_loss = 0.4675922332977762, disc_loss = 0.09507538152060338
Trained batch 98 in epoch 0, gen_loss = 0.467278484744255, disc_loss = 0.09691656706384336
Trained batch 99 in epoch 0, gen_loss = 0.4676083368062973, disc_loss = 0.09874868975952268
Trained batch 100 in epoch 0, gen_loss = 0.46652500936300445, disc_loss = 0.09973923185157894
Trained batch 101 in epoch 0, gen_loss = 0.46620190552636687, disc_loss = 0.10348072722919431
Trained batch 102 in epoch 0, gen_loss = 0.4660478075152462, disc_loss = 0.1057839042244895
Trained batch 103 in epoch 0, gen_loss = 0.46612565133434075, disc_loss = 0.10881763884726052
Trained batch 104 in epoch 0, gen_loss = 0.46651834618477594, disc_loss = 0.1098261373561053
Trained batch 105 in epoch 0, gen_loss = 0.4663415728312618, disc_loss = 0.11029304256487005
Trained batch 106 in epoch 0, gen_loss = 0.4662172591017785, disc_loss = 0.11121222824206418
Trained batch 107 in epoch 0, gen_loss = 0.46607792956961525, disc_loss = 0.11288928683778202
Trained batch 108 in epoch 0, gen_loss = 0.4657065160230759, disc_loss = 0.11419455093596506
Trained batch 109 in epoch 0, gen_loss = 0.46540296592495656, disc_loss = 0.114575414782898
Trained batch 110 in epoch 0, gen_loss = 0.4646564056207468, disc_loss = 0.11502496926701283
Trained batch 111 in epoch 0, gen_loss = 0.4646873391632523, disc_loss = 0.11559370880214763
Trained batch 112 in epoch 0, gen_loss = 0.4645364157921445, disc_loss = 0.1165441636127972
Trained batch 113 in epoch 0, gen_loss = 0.46391516087348, disc_loss = 0.11706161971220322
Trained batch 114 in epoch 0, gen_loss = 0.4633526343366374, disc_loss = 0.11733680084023787
Trained batch 115 in epoch 0, gen_loss = 0.4640399420569683, disc_loss = 0.11716839248828333
Trained batch 116 in epoch 0, gen_loss = 0.46391071977778375, disc_loss = 0.11717715485292113
Trained batch 117 in epoch 0, gen_loss = 0.4633773701675868, disc_loss = 0.11719127847039598
Trained batch 118 in epoch 0, gen_loss = 0.4635564744973383, disc_loss = 0.1174459750568416
Trained batch 119 in epoch 0, gen_loss = 0.46297260125478107, disc_loss = 0.11914274445734918
Trained batch 120 in epoch 0, gen_loss = 0.4636783456999408, disc_loss = 0.12041359254705512
Trained batch 121 in epoch 0, gen_loss = 0.4628956496226983, disc_loss = 0.12038879855306911
Trained batch 122 in epoch 0, gen_loss = 0.46265544421304533, disc_loss = 0.12114222349250704
Trained batch 123 in epoch 0, gen_loss = 0.4624781087040901, disc_loss = 0.1237222092196105
Trained batch 124 in epoch 0, gen_loss = 0.4615075373649597, disc_loss = 0.12435127903521061
Trained batch 125 in epoch 0, gen_loss = 0.4615311598966992, disc_loss = 0.12520859261885994
Trained batch 126 in epoch 0, gen_loss = 0.4608534041821487, disc_loss = 0.12554464672552787
Trained batch 127 in epoch 0, gen_loss = 0.4603952483739704, disc_loss = 0.12546855096297804
Trained batch 128 in epoch 0, gen_loss = 0.460327429364818, disc_loss = 0.1251941167482341
Trained batch 129 in epoch 0, gen_loss = 0.4602956166634193, disc_loss = 0.12491734453405325
Trained batch 130 in epoch 0, gen_loss = 0.46013233179354485, disc_loss = 0.12452587213736908
Trained batch 131 in epoch 0, gen_loss = 0.45989204175544507, disc_loss = 0.12408394932351781
Trained batch 132 in epoch 0, gen_loss = 0.4594856402031461, disc_loss = 0.12379751591137926
Trained batch 133 in epoch 0, gen_loss = 0.4598569238363807, disc_loss = 0.12331452783641976
Trained batch 134 in epoch 0, gen_loss = 0.4599306007226308, disc_loss = 0.12277774083669539
Trained batch 135 in epoch 0, gen_loss = 0.46002154578180876, disc_loss = 0.1224770336822771
Trained batch 136 in epoch 0, gen_loss = 0.45996726407621896, disc_loss = 0.12309266552057145
Trained batch 137 in epoch 0, gen_loss = 0.460205423011296, disc_loss = 0.12370713639572478
Trained batch 138 in epoch 0, gen_loss = 0.46012866711444994, disc_loss = 0.123523289203751
Trained batch 139 in epoch 0, gen_loss = 0.4599321007728577, disc_loss = 0.12346143346013767
Trained batch 140 in epoch 0, gen_loss = 0.4602130173791385, disc_loss = 0.12377107815803788
Trained batch 141 in epoch 0, gen_loss = 0.4596873834519319, disc_loss = 0.12371262599727217
Trained batch 142 in epoch 0, gen_loss = 0.4598584404358497, disc_loss = 0.12324207905237075
Trained batch 143 in epoch 0, gen_loss = 0.4598321086830563, disc_loss = 0.12263742783882965
Trained batch 144 in epoch 0, gen_loss = 0.45971007244340306, disc_loss = 0.1222374584268907
Trained batch 145 in epoch 0, gen_loss = 0.4597769410234608, disc_loss = 0.12180180603969995
Trained batch 146 in epoch 0, gen_loss = 0.4592978698866708, disc_loss = 0.12128415966064346
Trained batch 147 in epoch 0, gen_loss = 0.4593364274179613, disc_loss = 0.12062255661884272
Trained batch 148 in epoch 0, gen_loss = 0.45979967453335757, disc_loss = 0.1200082663371659
Trained batch 149 in epoch 0, gen_loss = 0.460291181008021, disc_loss = 0.11947103880345822
Trained batch 150 in epoch 0, gen_loss = 0.4602230049126985, disc_loss = 0.11898039626759409
Trained batch 151 in epoch 0, gen_loss = 0.4606509726298483, disc_loss = 0.11851515422428124
Trained batch 152 in epoch 0, gen_loss = 0.46082886566523634, disc_loss = 0.1181028880958074
Trained batch 153 in epoch 0, gen_loss = 0.4611398419002434, disc_loss = 0.11823296636439763
Trained batch 154 in epoch 0, gen_loss = 0.46130240175031845, disc_loss = 0.12077697719777784
Trained batch 155 in epoch 0, gen_loss = 0.46108984354978955, disc_loss = 0.12094347439228724
Trained batch 156 in epoch 0, gen_loss = 0.4614778850108955, disc_loss = 0.12193656359223803
Trained batch 157 in epoch 0, gen_loss = 0.4609694247004352, disc_loss = 0.12215975042479703
Trained batch 158 in epoch 0, gen_loss = 0.46004932219127437, disc_loss = 0.12238233468536311
Trained batch 159 in epoch 0, gen_loss = 0.45966391284018754, disc_loss = 0.1226691639283672
Trained batch 160 in epoch 0, gen_loss = 0.45922690704002145, disc_loss = 0.12339671013980918
Trained batch 161 in epoch 0, gen_loss = 0.4589830177065767, disc_loss = 0.12405077572682022
Trained batch 162 in epoch 0, gen_loss = 0.45846392040603734, disc_loss = 0.12394364847818766
Trained batch 163 in epoch 0, gen_loss = 0.458549967626246, disc_loss = 0.123749638862181
Trained batch 164 in epoch 0, gen_loss = 0.45792477654688285, disc_loss = 0.12368431906356955
Trained batch 165 in epoch 0, gen_loss = 0.4574138690908271, disc_loss = 0.12397538558636086
Trained batch 166 in epoch 0, gen_loss = 0.45723464603195646, disc_loss = 0.12545381408340917
Trained batch 167 in epoch 0, gen_loss = 0.45680023658843266, disc_loss = 0.12563822323101617
Trained batch 168 in epoch 0, gen_loss = 0.45673581605126873, disc_loss = 0.12573194197384563
Trained batch 169 in epoch 0, gen_loss = 0.4567412004751318, disc_loss = 0.12540945737239192
Trained batch 170 in epoch 0, gen_loss = 0.4562946155405881, disc_loss = 0.12522659692586513
Trained batch 171 in epoch 0, gen_loss = 0.4552864045944325, disc_loss = 0.12564900675571936
Trained batch 172 in epoch 0, gen_loss = 0.45556442982199563, disc_loss = 0.12600815384460323
Trained batch 173 in epoch 0, gen_loss = 0.45523947460212927, disc_loss = 0.12587560557000255
Trained batch 174 in epoch 0, gen_loss = 0.45500439626829964, disc_loss = 0.1261170725950173
Trained batch 175 in epoch 0, gen_loss = 0.4544973759488626, disc_loss = 0.12651611032726412
Trained batch 176 in epoch 0, gen_loss = 0.45463383702908533, disc_loss = 0.1269090869121969
Trained batch 177 in epoch 0, gen_loss = 0.4544961326912548, disc_loss = 0.12648738864181416
Trained batch 178 in epoch 0, gen_loss = 0.4539989184733876, disc_loss = 0.1263710949465882
Trained batch 179 in epoch 0, gen_loss = 0.45422494990958107, disc_loss = 0.12592599898990658
Trained batch 180 in epoch 0, gen_loss = 0.45398533196080454, disc_loss = 0.12614399468454207
Trained batch 181 in epoch 0, gen_loss = 0.45347491217838537, disc_loss = 0.12764757046742098
Trained batch 182 in epoch 0, gen_loss = 0.4526237840535211, disc_loss = 0.12779569334752572
Trained batch 183 in epoch 0, gen_loss = 0.45253447038323985, disc_loss = 0.12774270005605143
Trained batch 184 in epoch 0, gen_loss = 0.4526035473153398, disc_loss = 0.1275771873424182
Trained batch 185 in epoch 0, gen_loss = 0.45275707158350176, disc_loss = 0.12711778184979833
Trained batch 186 in epoch 0, gen_loss = 0.45272628684094884, disc_loss = 0.12664650093744145
Trained batch 187 in epoch 0, gen_loss = 0.4527721975712066, disc_loss = 0.12635294336112254
Trained batch 188 in epoch 0, gen_loss = 0.45276571849666575, disc_loss = 0.12603964912828314
Trained batch 189 in epoch 0, gen_loss = 0.4526501685380936, disc_loss = 0.12587529856123422
Trained batch 190 in epoch 0, gen_loss = 0.4525917596841982, disc_loss = 0.12651979911545808
Trained batch 191 in epoch 0, gen_loss = 0.45298566451917094, disc_loss = 0.12701598279333362
Trained batch 192 in epoch 0, gen_loss = 0.45289719320949495, disc_loss = 0.12768362335127253
Trained batch 193 in epoch 0, gen_loss = 0.45312646062103745, disc_loss = 0.12758533983040102
Trained batch 194 in epoch 0, gen_loss = 0.45319551412875836, disc_loss = 0.12727952221265207
Trained batch 195 in epoch 0, gen_loss = 0.4527416071113275, disc_loss = 0.12703022778946527
Trained batch 196 in epoch 0, gen_loss = 0.452461599395965, disc_loss = 0.12670104141314018
Trained batch 197 in epoch 0, gen_loss = 0.45243480079101794, disc_loss = 0.12643247767530305
Trained batch 198 in epoch 0, gen_loss = 0.45238979737363266, disc_loss = 0.1261852977039227
Trained batch 199 in epoch 0, gen_loss = 0.4531947162747383, disc_loss = 0.1258020981028676
Trained batch 200 in epoch 0, gen_loss = 0.45300183026351737, disc_loss = 0.12549689734604821
Trained batch 201 in epoch 0, gen_loss = 0.4524765348080361, disc_loss = 0.12627086275727442
Trained batch 202 in epoch 0, gen_loss = 0.4529751503996074, disc_loss = 0.12733574963995975
Trained batch 203 in epoch 0, gen_loss = 0.45265885515540255, disc_loss = 0.12729952962813423
Trained batch 204 in epoch 0, gen_loss = 0.45212008691415556, disc_loss = 0.12764462025427237
Trained batch 205 in epoch 0, gen_loss = 0.45236914829143043, disc_loss = 0.12754722666537877
Trained batch 206 in epoch 0, gen_loss = 0.45217175285021466, disc_loss = 0.1272072162353186
Trained batch 207 in epoch 0, gen_loss = 0.4519903202756093, disc_loss = 0.12685073047088316
Trained batch 208 in epoch 0, gen_loss = 0.45216631176369043, disc_loss = 0.12647160158702062
Trained batch 209 in epoch 0, gen_loss = 0.45240658067521594, disc_loss = 0.1265172377760921
Trained batch 210 in epoch 0, gen_loss = 0.45246016513114856, disc_loss = 0.12779337575579708
Trained batch 211 in epoch 0, gen_loss = 0.4526015819524819, disc_loss = 0.12788430283302968
Trained batch 212 in epoch 0, gen_loss = 0.45228925767079203, disc_loss = 0.127586839711862
Trained batch 213 in epoch 0, gen_loss = 0.45208503459101523, disc_loss = 0.12772463312564053
Trained batch 214 in epoch 0, gen_loss = 0.4522449490635894, disc_loss = 0.1276739982844785
Trained batch 215 in epoch 0, gen_loss = 0.45233802483589564, disc_loss = 0.12733505492064137
Trained batch 216 in epoch 0, gen_loss = 0.4523817043974652, disc_loss = 0.12696831462226704
Trained batch 217 in epoch 0, gen_loss = 0.45221456625592815, disc_loss = 0.12681985183388267
Trained batch 218 in epoch 0, gen_loss = 0.45175952930428664, disc_loss = 0.12730091342438846
Trained batch 219 in epoch 0, gen_loss = 0.45172743228348816, disc_loss = 0.12800470422953367
Trained batch 220 in epoch 0, gen_loss = 0.4519031007365404, disc_loss = 0.12791503053917064
Trained batch 221 in epoch 0, gen_loss = 0.451634234270534, disc_loss = 0.1277940109002966
Trained batch 222 in epoch 0, gen_loss = 0.45157861789780346, disc_loss = 0.12761053698546684
Trained batch 223 in epoch 0, gen_loss = 0.4513403447344899, disc_loss = 0.12768244904665543
Trained batch 224 in epoch 0, gen_loss = 0.45162674519750806, disc_loss = 0.12764807841844028
Trained batch 225 in epoch 0, gen_loss = 0.4514810573474496, disc_loss = 0.12732132817659758
Trained batch 226 in epoch 0, gen_loss = 0.45112870377591, disc_loss = 0.12713384070322903
Trained batch 227 in epoch 0, gen_loss = 0.4511139043851903, disc_loss = 0.1272256811590571
Trained batch 228 in epoch 0, gen_loss = 0.4514348216712735, disc_loss = 0.12803795627891756
Trained batch 229 in epoch 0, gen_loss = 0.45130806111771127, disc_loss = 0.12805505906758102
Trained batch 230 in epoch 0, gen_loss = 0.4509306726775644, disc_loss = 0.12853371922845963
Trained batch 231 in epoch 0, gen_loss = 0.4512619022922269, disc_loss = 0.13000746052069911
Trained batch 232 in epoch 0, gen_loss = 0.4509784560090994, disc_loss = 0.1306692987936249
Trained batch 233 in epoch 0, gen_loss = 0.45140243124248636, disc_loss = 0.1310703937187154
Trained batch 234 in epoch 0, gen_loss = 0.45120899968958916, disc_loss = 0.13125606210941965
Trained batch 235 in epoch 0, gen_loss = 0.450633560070547, disc_loss = 0.1316532555778148
Trained batch 236 in epoch 0, gen_loss = 0.45033090049204444, disc_loss = 0.13171601704152827
Trained batch 237 in epoch 0, gen_loss = 0.44984139214042856, disc_loss = 0.13185969865372202
Trained batch 238 in epoch 0, gen_loss = 0.4494013292520116, disc_loss = 0.1320099221487923
Trained batch 239 in epoch 0, gen_loss = 0.4488919877757629, disc_loss = 0.13204282435278097
Trained batch 240 in epoch 0, gen_loss = 0.44883916165324167, disc_loss = 0.1320072317890112
Trained batch 241 in epoch 0, gen_loss = 0.4485827775533534, disc_loss = 0.13196682853023867
Trained batch 242 in epoch 0, gen_loss = 0.4480891620180734, disc_loss = 0.13224711765845618
Trained batch 243 in epoch 0, gen_loss = 0.4476347406868075, disc_loss = 0.13350954294571135
Trained batch 244 in epoch 0, gen_loss = 0.44745787686231187, disc_loss = 0.1339525579493873
Trained batch 245 in epoch 0, gen_loss = 0.4470842354665927, disc_loss = 0.13431626888431183
Trained batch 246 in epoch 0, gen_loss = 0.44663744127219507, disc_loss = 0.13456725105944917
Trained batch 247 in epoch 0, gen_loss = 0.4464483674495451, disc_loss = 0.13467605835607938
Trained batch 248 in epoch 0, gen_loss = 0.4463703577298237, disc_loss = 0.13483710805455365
Trained batch 249 in epoch 0, gen_loss = 0.4463493486642838, disc_loss = 0.13484337010979652
Trained batch 250 in epoch 0, gen_loss = 0.4459510838605493, disc_loss = 0.13517156151305157
Trained batch 251 in epoch 0, gen_loss = 0.4455920332480991, disc_loss = 0.1353241124500831
Trained batch 252 in epoch 0, gen_loss = 0.4452762983062051, disc_loss = 0.13537752743177264
Trained batch 253 in epoch 0, gen_loss = 0.44531868081393206, disc_loss = 0.13525258306795218
Trained batch 254 in epoch 0, gen_loss = 0.44540541230463515, disc_loss = 0.13517488591811236
Trained batch 255 in epoch 0, gen_loss = 0.4450745696667582, disc_loss = 0.1356542867142707
Trained batch 256 in epoch 0, gen_loss = 0.44505133517521367, disc_loss = 0.13649729787143752
Trained batch 257 in epoch 0, gen_loss = 0.4447317527708157, disc_loss = 0.1367764410584472
Trained batch 258 in epoch 0, gen_loss = 0.44448588909329595, disc_loss = 0.137551569225245
Trained batch 259 in epoch 0, gen_loss = 0.4443906370263833, disc_loss = 0.13800355287698599
Trained batch 260 in epoch 0, gen_loss = 0.44429601529092166, disc_loss = 0.13827825568873306
Trained batch 261 in epoch 0, gen_loss = 0.4438032635295664, disc_loss = 0.1384528284423224
Trained batch 262 in epoch 0, gen_loss = 0.44337750773012863, disc_loss = 0.13866782375388273
Trained batch 263 in epoch 0, gen_loss = 0.4430743131899472, disc_loss = 0.1387596820114237
Trained batch 264 in epoch 0, gen_loss = 0.4428333149766022, disc_loss = 0.13898236802164113
Trained batch 265 in epoch 0, gen_loss = 0.4426619139380921, disc_loss = 0.13904553276479692
Trained batch 266 in epoch 0, gen_loss = 0.4423975366331665, disc_loss = 0.139063307464346
Trained batch 267 in epoch 0, gen_loss = 0.44210714112911653, disc_loss = 0.13913318314659062
Trained batch 268 in epoch 0, gen_loss = 0.44208331987760324, disc_loss = 0.13932325427860132
Trained batch 269 in epoch 0, gen_loss = 0.44193405277199216, disc_loss = 0.14020474067440739
Trained batch 270 in epoch 0, gen_loss = 0.44155272302592374, disc_loss = 0.14041949715121646
Trained batch 271 in epoch 0, gen_loss = 0.4413925534223809, disc_loss = 0.14096633191494382
Trained batch 272 in epoch 0, gen_loss = 0.4410448040499355, disc_loss = 0.14162052125284524
Trained batch 273 in epoch 0, gen_loss = 0.4410189279239543, disc_loss = 0.1418139589746503
Trained batch 274 in epoch 0, gen_loss = 0.4405467100576921, disc_loss = 0.14207357921383598
Trained batch 275 in epoch 0, gen_loss = 0.44002340928367945, disc_loss = 0.14229097066150195
Trained batch 276 in epoch 0, gen_loss = 0.4396536308290296, disc_loss = 0.14237928820861376
Trained batch 277 in epoch 0, gen_loss = 0.43948799661166377, disc_loss = 0.14239982574534932
Trained batch 278 in epoch 0, gen_loss = 0.4392437074987692, disc_loss = 0.14257683351262068
Trained batch 279 in epoch 0, gen_loss = 0.43902706908328193, disc_loss = 0.14273138700851373
Trained batch 280 in epoch 0, gen_loss = 0.43870132387320765, disc_loss = 0.14312692930477794
Trained batch 281 in epoch 0, gen_loss = 0.4385353885855235, disc_loss = 0.14314931451428867
Trained batch 282 in epoch 0, gen_loss = 0.4384242709028426, disc_loss = 0.14302395589570696
Trained batch 283 in epoch 0, gen_loss = 0.43803918802402386, disc_loss = 0.14309844143793615
Trained batch 284 in epoch 0, gen_loss = 0.4376395685630932, disc_loss = 0.1433268193613019
Trained batch 285 in epoch 0, gen_loss = 0.43751628134217296, disc_loss = 0.14342890226549201
Trained batch 286 in epoch 0, gen_loss = 0.43750057060544084, disc_loss = 0.14333517249764466
Trained batch 287 in epoch 0, gen_loss = 0.43739903666492963, disc_loss = 0.14332883854189682
Trained batch 288 in epoch 0, gen_loss = 0.43717213815471295, disc_loss = 0.1436446371736411
Trained batch 289 in epoch 0, gen_loss = 0.43688345304850873, disc_loss = 0.14434426948428153
Trained batch 290 in epoch 0, gen_loss = 0.4365824911602584, disc_loss = 0.14444992179211064
Trained batch 291 in epoch 0, gen_loss = 0.43623383057444065, disc_loss = 0.14469241144212142
Trained batch 292 in epoch 0, gen_loss = 0.4360363958435254, disc_loss = 0.1448164980210135
Trained batch 293 in epoch 0, gen_loss = 0.4357568453363821, disc_loss = 0.1447664273484629
Trained batch 294 in epoch 0, gen_loss = 0.4356528741828466, disc_loss = 0.14467256283861096
Trained batch 295 in epoch 0, gen_loss = 0.4354967968286695, disc_loss = 0.14454079512506723
Trained batch 296 in epoch 0, gen_loss = 0.43518145708524014, disc_loss = 0.14447788961909033
Trained batch 297 in epoch 0, gen_loss = 0.4349168068010535, disc_loss = 0.1443049561907381
Trained batch 298 in epoch 0, gen_loss = 0.43463235545317863, disc_loss = 0.14435772455755286
Trained batch 299 in epoch 0, gen_loss = 0.4345044944683711, disc_loss = 0.14424106419086458
Trained batch 300 in epoch 0, gen_loss = 0.4341136016124903, disc_loss = 0.14456434320175768
Trained batch 301 in epoch 0, gen_loss = 0.434115130676339, disc_loss = 0.1447877831115628
Trained batch 302 in epoch 0, gen_loss = 0.4336278180871466, disc_loss = 0.14485266524376256
Trained batch 303 in epoch 0, gen_loss = 0.43327103859107746, disc_loss = 0.14491866671137119
Trained batch 304 in epoch 0, gen_loss = 0.43298214996447326, disc_loss = 0.14496699723063922
Trained batch 305 in epoch 0, gen_loss = 0.43278413709082636, disc_loss = 0.1453867977838111
Trained batch 306 in epoch 0, gen_loss = 0.43263077027246305, disc_loss = 0.14587918365622965
Trained batch 307 in epoch 0, gen_loss = 0.4324567338282412, disc_loss = 0.14592014190244984
Trained batch 308 in epoch 0, gen_loss = 0.43238924921137617, disc_loss = 0.14592495531711763
Trained batch 309 in epoch 0, gen_loss = 0.43221999897110847, disc_loss = 0.1460495243149419
Trained batch 310 in epoch 0, gen_loss = 0.4318602640912464, disc_loss = 0.14616974043117842
Trained batch 311 in epoch 0, gen_loss = 0.4317866620153953, disc_loss = 0.14613260887563229
Trained batch 312 in epoch 0, gen_loss = 0.4317961855056568, disc_loss = 0.14593366673960093
Trained batch 313 in epoch 0, gen_loss = 0.4314785784786674, disc_loss = 0.14601652305217305
Trained batch 314 in epoch 0, gen_loss = 0.4312031802676973, disc_loss = 0.14659081063573323
Trained batch 315 in epoch 0, gen_loss = 0.4312120088482205, disc_loss = 0.14708551189190225
Trained batch 316 in epoch 0, gen_loss = 0.4309785179911352, disc_loss = 0.1472864109634977
Trained batch 317 in epoch 0, gen_loss = 0.4306752401515373, disc_loss = 0.14754293652825384
Trained batch 318 in epoch 0, gen_loss = 0.43039049801407936, disc_loss = 0.14776319405501911
Trained batch 319 in epoch 0, gen_loss = 0.43033324433490633, disc_loss = 0.14787727151997387
Trained batch 320 in epoch 0, gen_loss = 0.43010780308105495, disc_loss = 0.14799416840447815
Trained batch 321 in epoch 0, gen_loss = 0.4298710249225545, disc_loss = 0.14802304585898143
Trained batch 322 in epoch 0, gen_loss = 0.4295995897921984, disc_loss = 0.14801639055504517
Trained batch 323 in epoch 0, gen_loss = 0.4295271465807785, disc_loss = 0.1480786905704457
Trained batch 324 in epoch 0, gen_loss = 0.42949012976426343, disc_loss = 0.14814804787819202
Trained batch 325 in epoch 0, gen_loss = 0.4295007822338057, disc_loss = 0.1480686137098476
Trained batch 326 in epoch 0, gen_loss = 0.4291992864659802, disc_loss = 0.14807916794895032
Trained batch 327 in epoch 0, gen_loss = 0.4289200692096861, disc_loss = 0.1487384359011563
Trained batch 328 in epoch 0, gen_loss = 0.42898818062431543, disc_loss = 0.14871236940104185
Trained batch 329 in epoch 0, gen_loss = 0.4288063642653552, disc_loss = 0.1488190723639546
Trained batch 330 in epoch 0, gen_loss = 0.42850914147325153, disc_loss = 0.14893008192320245
Trained batch 331 in epoch 0, gen_loss = 0.4282008764075946, disc_loss = 0.14913804142410497
Trained batch 332 in epoch 0, gen_loss = 0.4282284103356324, disc_loss = 0.1491230299343934
Trained batch 333 in epoch 0, gen_loss = 0.4281683784580516, disc_loss = 0.1490529505257121
Trained batch 334 in epoch 0, gen_loss = 0.42808476819920893, disc_loss = 0.14903338200120783
Trained batch 335 in epoch 0, gen_loss = 0.42794427470791907, disc_loss = 0.14900351728179625
Trained batch 336 in epoch 0, gen_loss = 0.4278475544926674, disc_loss = 0.14910600504641716
Trained batch 337 in epoch 0, gen_loss = 0.4275931110219843, disc_loss = 0.1494319449955895
Trained batch 338 in epoch 0, gen_loss = 0.4271922267995401, disc_loss = 0.14989325593178954
Trained batch 339 in epoch 0, gen_loss = 0.4271034084698733, disc_loss = 0.1498605551526827
Trained batch 340 in epoch 0, gen_loss = 0.4269329044651076, disc_loss = 0.1501483153824932
Trained batch 341 in epoch 0, gen_loss = 0.42679249342770603, disc_loss = 0.1502742099831676
Trained batch 342 in epoch 0, gen_loss = 0.4268079194139809, disc_loss = 0.15034602187117752
Trained batch 343 in epoch 0, gen_loss = 0.42671756134476774, disc_loss = 0.15042193779765173
Trained batch 344 in epoch 0, gen_loss = 0.4263977719389874, disc_loss = 0.15046640055767005
Trained batch 345 in epoch 0, gen_loss = 0.4261370892986397, disc_loss = 0.15045895987335658
Trained batch 346 in epoch 0, gen_loss = 0.42593151734610457, disc_loss = 0.15051050316703424
Trained batch 347 in epoch 0, gen_loss = 0.425953251448856, disc_loss = 0.15062006532974626
Trained batch 348 in epoch 0, gen_loss = 0.4258339491307223, disc_loss = 0.1506800123391657
Trained batch 349 in epoch 0, gen_loss = 0.425759083543505, disc_loss = 0.15078330542360033
Trained batch 350 in epoch 0, gen_loss = 0.4254917245984417, disc_loss = 0.15079512720943516
Trained batch 351 in epoch 0, gen_loss = 0.42526089179922233, disc_loss = 0.15071229509670625
Trained batch 352 in epoch 0, gen_loss = 0.4250589883530106, disc_loss = 0.15088209780012243
Trained batch 353 in epoch 0, gen_loss = 0.4248139565273867, disc_loss = 0.1510956092069378
Trained batch 354 in epoch 0, gen_loss = 0.4248770069908088, disc_loss = 0.15109676248590712
Trained batch 355 in epoch 0, gen_loss = 0.4247740087716767, disc_loss = 0.15106503887290365
Trained batch 356 in epoch 0, gen_loss = 0.4246604889213872, disc_loss = 0.15116453417042056
Trained batch 357 in epoch 0, gen_loss = 0.42473496080443846, disc_loss = 0.1511437562840611
Trained batch 358 in epoch 0, gen_loss = 0.4245529784963656, disc_loss = 0.1511973060854298
Trained batch 359 in epoch 0, gen_loss = 0.4245670167108377, disc_loss = 0.15120714844928848
Trained batch 360 in epoch 0, gen_loss = 0.42461575935091667, disc_loss = 0.15168821093448312
Trained batch 361 in epoch 0, gen_loss = 0.4242896925843223, disc_loss = 0.15181689828798917
Trained batch 362 in epoch 0, gen_loss = 0.42413608101773853, disc_loss = 0.15227736487533106
Trained batch 363 in epoch 0, gen_loss = 0.4240440312813927, disc_loss = 0.15238717853367983
Trained batch 364 in epoch 0, gen_loss = 0.4239781576476685, disc_loss = 0.15240121663433231
Trained batch 365 in epoch 0, gen_loss = 0.4236719626220849, disc_loss = 0.15236630758952574
Trained batch 366 in epoch 0, gen_loss = 0.4234680555334533, disc_loss = 0.15230673015604876
Trained batch 367 in epoch 0, gen_loss = 0.42341396601303766, disc_loss = 0.15219184254174647
Trained batch 368 in epoch 0, gen_loss = 0.4235719286490908, disc_loss = 0.15206101861830326
Trained batch 369 in epoch 0, gen_loss = 0.4233805277863064, disc_loss = 0.15205984919055088
Trained batch 370 in epoch 0, gen_loss = 0.4234962444099776, disc_loss = 0.15192825941624988
Trained batch 371 in epoch 0, gen_loss = 0.4232521017873159, disc_loss = 0.15183409635898887
Trained batch 372 in epoch 0, gen_loss = 0.4228837107365636, disc_loss = 0.152060730527617
Trained batch 373 in epoch 0, gen_loss = 0.42265902642897746, disc_loss = 0.15231698400834026
Trained batch 374 in epoch 0, gen_loss = 0.4225433626969655, disc_loss = 0.1524482541879018
Trained batch 375 in epoch 0, gen_loss = 0.42245423278593003, disc_loss = 0.1524236333021458
Trained batch 376 in epoch 0, gen_loss = 0.42218979046894956, disc_loss = 0.1524169819740781
Trained batch 377 in epoch 0, gen_loss = 0.42216514366329033, disc_loss = 0.15242187166340138
Trained batch 378 in epoch 0, gen_loss = 0.42198581667248364, disc_loss = 0.1523590461402581
Trained batch 379 in epoch 0, gen_loss = 0.421857251226902, disc_loss = 0.15229955362646203
Trained batch 380 in epoch 0, gen_loss = 0.4217405725964724, disc_loss = 0.1521879941459716
Trained batch 381 in epoch 0, gen_loss = 0.42169407766838973, disc_loss = 0.15203929678853895
Trained batch 382 in epoch 0, gen_loss = 0.4217790837543129, disc_loss = 0.15188283364315258
Trained batch 383 in epoch 0, gen_loss = 0.4215683330160876, disc_loss = 0.15194051299476996
Trained batch 384 in epoch 0, gen_loss = 0.42154462020118516, disc_loss = 0.15218910990984408
Trained batch 385 in epoch 0, gen_loss = 0.42140451853448246, disc_loss = 0.1525930120498714
Trained batch 386 in epoch 0, gen_loss = 0.421410691830539, disc_loss = 0.15257714197848193
Trained batch 387 in epoch 0, gen_loss = 0.4212187000924779, disc_loss = 0.15257917672933377
Trained batch 388 in epoch 0, gen_loss = 0.42107682339942853, disc_loss = 0.15264855698708704
Trained batch 389 in epoch 0, gen_loss = 0.420897809893657, disc_loss = 0.15264051352173855
Trained batch 390 in epoch 0, gen_loss = 0.42074131256784014, disc_loss = 0.15253653857485414
Trained batch 391 in epoch 0, gen_loss = 0.42059731247777843, disc_loss = 0.15262667817652834
Trained batch 392 in epoch 0, gen_loss = 0.4206360130364658, disc_loss = 0.15284329643307146
Trained batch 393 in epoch 0, gen_loss = 0.42046090158714255, disc_loss = 0.15282054334349437
Trained batch 394 in epoch 0, gen_loss = 0.42043096958836423, disc_loss = 0.15273056360362453
Trained batch 395 in epoch 0, gen_loss = 0.4205425513362644, disc_loss = 0.15251128057563546
Trained batch 396 in epoch 0, gen_loss = 0.4205817626015065, disc_loss = 0.15239834928092189
Trained batch 397 in epoch 0, gen_loss = 0.4205923276630478, disc_loss = 0.15237018065386682
Trained batch 398 in epoch 0, gen_loss = 0.4203927227130211, disc_loss = 0.15231319839942425
Trained batch 399 in epoch 0, gen_loss = 0.4203108262270689, disc_loss = 0.15216297326609493
Trained batch 400 in epoch 0, gen_loss = 0.42013991964130926, disc_loss = 0.152097911738844
Trained batch 401 in epoch 0, gen_loss = 0.42007489858278585, disc_loss = 0.15219406737246324
Trained batch 402 in epoch 0, gen_loss = 0.4198403421317969, disc_loss = 0.1526922567865393
Trained batch 403 in epoch 0, gen_loss = 0.4199567478482086, disc_loss = 0.152998571699061
Trained batch 404 in epoch 0, gen_loss = 0.4198582241564621, disc_loss = 0.15304161540152114
Trained batch 405 in epoch 0, gen_loss = 0.41965634350118963, disc_loss = 0.15312933626359906
Trained batch 406 in epoch 0, gen_loss = 0.4195648789112925, disc_loss = 0.15313299280346465
Trained batch 407 in epoch 0, gen_loss = 0.41940894123970296, disc_loss = 0.15325250726777548
Trained batch 408 in epoch 0, gen_loss = 0.41910142318543714, disc_loss = 0.15349891222557988
Trained batch 409 in epoch 0, gen_loss = 0.41918797180420014, disc_loss = 0.1534335571273071
Trained batch 410 in epoch 0, gen_loss = 0.4191361373503423, disc_loss = 0.1537301535480214
Trained batch 411 in epoch 0, gen_loss = 0.4190575873967513, disc_loss = 0.15370217126622363
Trained batch 412 in epoch 0, gen_loss = 0.4189246685106587, disc_loss = 0.1535946493179111
Trained batch 413 in epoch 0, gen_loss = 0.41891544596584523, disc_loss = 0.15349541311174775
Trained batch 414 in epoch 0, gen_loss = 0.41890842383166393, disc_loss = 0.15340020180825728
Trained batch 415 in epoch 0, gen_loss = 0.41883102833078456, disc_loss = 0.1532978140928138
Trained batch 416 in epoch 0, gen_loss = 0.4187501142207953, disc_loss = 0.15330466486924557
Trained batch 417 in epoch 0, gen_loss = 0.41866567559789813, disc_loss = 0.15333420243203355
Trained batch 418 in epoch 0, gen_loss = 0.4184203483608856, disc_loss = 0.15318836067271974
Trained batch 419 in epoch 0, gen_loss = 0.4183468908071518, disc_loss = 0.1530905670708134
Trained batch 420 in epoch 0, gen_loss = 0.4184444284778876, disc_loss = 0.1530237811088845
Trained batch 421 in epoch 0, gen_loss = 0.41835642086951086, disc_loss = 0.15282916049892303
Trained batch 422 in epoch 0, gen_loss = 0.4181179138644649, disc_loss = 0.1527161643648824
Trained batch 423 in epoch 0, gen_loss = 0.4179774084181156, disc_loss = 0.15263361244831444
Trained batch 424 in epoch 0, gen_loss = 0.4179182201273301, disc_loss = 0.15339734820758597
Trained batch 425 in epoch 0, gen_loss = 0.4177005088105448, disc_loss = 0.15349351083029045
Trained batch 426 in epoch 0, gen_loss = 0.4175672998054245, disc_loss = 0.15349431733755653
Trained batch 427 in epoch 0, gen_loss = 0.41760683902234674, disc_loss = 0.15326349226601213
Trained batch 428 in epoch 0, gen_loss = 0.4176529543105261, disc_loss = 0.15303543554770918
Trained batch 429 in epoch 0, gen_loss = 0.4173877381308134, disc_loss = 0.15302070342004298
Trained batch 430 in epoch 0, gen_loss = 0.4172251595836781, disc_loss = 0.15289181814012562
Trained batch 431 in epoch 0, gen_loss = 0.4172406460813902, disc_loss = 0.15282744032123852
Trained batch 432 in epoch 0, gen_loss = 0.41707098704287415, disc_loss = 0.15264570380090015
Trained batch 433 in epoch 0, gen_loss = 0.4170514918554763, disc_loss = 0.15258118335998827
Trained batch 434 in epoch 0, gen_loss = 0.4170546696788963, disc_loss = 0.1524678709435052
Trained batch 435 in epoch 0, gen_loss = 0.41678302365978925, disc_loss = 0.1524068977974287
Trained batch 436 in epoch 0, gen_loss = 0.4168033826951304, disc_loss = 0.1522316419236038
Trained batch 437 in epoch 0, gen_loss = 0.416863569453971, disc_loss = 0.15215571785184073
Trained batch 438 in epoch 0, gen_loss = 0.41714055248979554, disc_loss = 0.1523572260042937
Trained batch 439 in epoch 0, gen_loss = 0.4171538851477883, disc_loss = 0.15204864361916076
Trained batch 440 in epoch 0, gen_loss = 0.4170630817510644, disc_loss = 0.1518071508985393
Trained batch 441 in epoch 0, gen_loss = 0.41707154562300686, disc_loss = 0.15153444067014557
Trained batch 442 in epoch 0, gen_loss = 0.4170497870472161, disc_loss = 0.1512249188758349
Trained batch 443 in epoch 0, gen_loss = 0.4170985511831335, disc_loss = 0.15095054844671205
Trained batch 444 in epoch 0, gen_loss = 0.4171487076228924, disc_loss = 0.1507234361378497
Trained batch 445 in epoch 0, gen_loss = 0.4169187437525779, disc_loss = 0.15065536641144098
Trained batch 446 in epoch 0, gen_loss = 0.41706605932323193, disc_loss = 0.15037824743754444
Trained batch 447 in epoch 0, gen_loss = 0.417089563727911, disc_loss = 0.15019027646173658
Trained batch 448 in epoch 0, gen_loss = 0.4170949900468898, disc_loss = 0.1508774690699239
Trained batch 449 in epoch 0, gen_loss = 0.41709158572885724, disc_loss = 0.15133708401065735
Trained batch 450 in epoch 0, gen_loss = 0.41680459265169706, disc_loss = 0.15135464392924586
Trained batch 451 in epoch 0, gen_loss = 0.4167831594173887, disc_loss = 0.15121202057318153
Trained batch 452 in epoch 0, gen_loss = 0.41673085955331396, disc_loss = 0.15115004161343998
Trained batch 453 in epoch 0, gen_loss = 0.41683058683567636, disc_loss = 0.15089785375135914
Trained batch 454 in epoch 0, gen_loss = 0.41672911604682167, disc_loss = 0.1506266806417933
Trained batch 455 in epoch 0, gen_loss = 0.4164561163307282, disc_loss = 0.1505445663249447
Trained batch 456 in epoch 0, gen_loss = 0.41660922915721615, disc_loss = 0.1503015391108798
Trained batch 457 in epoch 0, gen_loss = 0.416662456817502, disc_loss = 0.15014388170052628
Trained batch 458 in epoch 0, gen_loss = 0.41665284267438, disc_loss = 0.151077895660627
Testing Epoch 0
Training Epoch 1
Trained batch 0 in epoch 1, gen_loss = 0.3622073829174042, disc_loss = 0.07607199996709824
Trained batch 1 in epoch 1, gen_loss = 0.3785010278224945, disc_loss = 0.08418431133031845
Trained batch 2 in epoch 1, gen_loss = 0.38522525628407794, disc_loss = 0.06926185513536136
Trained batch 3 in epoch 1, gen_loss = 0.35577234625816345, disc_loss = 0.08325757179409266
Trained batch 4 in epoch 1, gen_loss = 0.35221686363220217, disc_loss = 0.09321076348423958
Trained batch 5 in epoch 1, gen_loss = 0.36195620397726697, disc_loss = 0.0822881485025088
Trained batch 6 in epoch 1, gen_loss = 0.36683139204978943, disc_loss = 0.08899000712803432
Trained batch 7 in epoch 1, gen_loss = 0.37544136866927147, disc_loss = 0.08204561332240701
Trained batch 8 in epoch 1, gen_loss = 0.36554087532891166, disc_loss = 0.0903319770263301
Trained batch 9 in epoch 1, gen_loss = 0.3684001237154007, disc_loss = 0.08499221615493298
Trained batch 10 in epoch 1, gen_loss = 0.36292326992208307, disc_loss = 0.09781135720285503
Trained batch 11 in epoch 1, gen_loss = 0.37164480487505597, disc_loss = 0.11365468272318442
Trained batch 12 in epoch 1, gen_loss = 0.3713723444021665, disc_loss = 0.11824547069577071
Trained batch 13 in epoch 1, gen_loss = 0.37645114745412556, disc_loss = 0.11950891651213169
Trained batch 14 in epoch 1, gen_loss = 0.3754803895950317, disc_loss = 0.12043703570961953
Trained batch 15 in epoch 1, gen_loss = 0.3773832209408283, disc_loss = 0.11879637162201107
Trained batch 16 in epoch 1, gen_loss = 0.3822901091154884, disc_loss = 0.12032887931255733
Trained batch 17 in epoch 1, gen_loss = 0.379231345322397, disc_loss = 0.1193810703439845
Trained batch 18 in epoch 1, gen_loss = 0.37704826342432124, disc_loss = 0.12531448998733571
Trained batch 19 in epoch 1, gen_loss = 0.3796806588768959, disc_loss = 0.13363794554024935
Trained batch 20 in epoch 1, gen_loss = 0.3839296301205953, disc_loss = 0.1413375779631592
Trained batch 21 in epoch 1, gen_loss = 0.38265846398743714, disc_loss = 0.14277103966609997
Trained batch 22 in epoch 1, gen_loss = 0.3797470849493276, disc_loss = 0.14475636070837145
Trained batch 23 in epoch 1, gen_loss = 0.3796035833656788, disc_loss = 0.14240969639892379
Trained batch 24 in epoch 1, gen_loss = 0.37921619296073916, disc_loss = 0.14139940425753594
Trained batch 25 in epoch 1, gen_loss = 0.37816711916373325, disc_loss = 0.1426418783286443
Trained batch 26 in epoch 1, gen_loss = 0.3778732231369725, disc_loss = 0.1433991004747373
Trained batch 27 in epoch 1, gen_loss = 0.37857809237071444, disc_loss = 0.1468591092686568
Trained batch 28 in epoch 1, gen_loss = 0.3777381017290313, disc_loss = 0.14551232177121887
Trained batch 29 in epoch 1, gen_loss = 0.37766928871472677, disc_loss = 0.14493775703012943
Trained batch 30 in epoch 1, gen_loss = 0.37848725530409044, disc_loss = 0.1436781564787511
Trained batch 31 in epoch 1, gen_loss = 0.3777242200449109, disc_loss = 0.1423919223016128
Trained batch 32 in epoch 1, gen_loss = 0.37738665035276703, disc_loss = 0.14274335889653725
Trained batch 33 in epoch 1, gen_loss = 0.3788571892415776, disc_loss = 0.144911157186417
Trained batch 34 in epoch 1, gen_loss = 0.38312543886048456, disc_loss = 0.14296832201736315
Trained batch 35 in epoch 1, gen_loss = 0.3811257986558808, disc_loss = 0.14257679579572546
Trained batch 36 in epoch 1, gen_loss = 0.3785738953062006, disc_loss = 0.14195381457338463
Trained batch 37 in epoch 1, gen_loss = 0.378800829774455, disc_loss = 0.14306488976274667
Trained batch 38 in epoch 1, gen_loss = 0.379638549609062, disc_loss = 0.14308464288329467
Trained batch 39 in epoch 1, gen_loss = 0.37965054661035535, disc_loss = 0.1424883550964296
Trained batch 40 in epoch 1, gen_loss = 0.37938624765814805, disc_loss = 0.1421819662720692
Trained batch 41 in epoch 1, gen_loss = 0.37860063853717985, disc_loss = 0.141355410484331
Trained batch 42 in epoch 1, gen_loss = 0.3778127445731052, disc_loss = 0.14150403881835383
Trained batch 43 in epoch 1, gen_loss = 0.3776605860753493, disc_loss = 0.14086044452745805
Trained batch 44 in epoch 1, gen_loss = 0.3777776996294657, disc_loss = 0.1406348182923264
Trained batch 45 in epoch 1, gen_loss = 0.3765472173690796, disc_loss = 0.1445380048421414
Trained batch 46 in epoch 1, gen_loss = 0.3769167141711458, disc_loss = 0.14672893103449902
Trained batch 47 in epoch 1, gen_loss = 0.37797662739952403, disc_loss = 0.14627875395429632
Trained batch 48 in epoch 1, gen_loss = 0.3766090213036051, disc_loss = 0.1466150135562128
Trained batch 49 in epoch 1, gen_loss = 0.37632298946380616, disc_loss = 0.14689734168350696
Trained batch 50 in epoch 1, gen_loss = 0.3769247818226908, disc_loss = 0.14897002608460538
Trained batch 51 in epoch 1, gen_loss = 0.3771931758293739, disc_loss = 0.1486144966374223
Trained batch 52 in epoch 1, gen_loss = 0.37738775813354636, disc_loss = 0.1476509154264657
Trained batch 53 in epoch 1, gen_loss = 0.3773252390049122, disc_loss = 0.14675667612916893
Trained batch 54 in epoch 1, gen_loss = 0.376994467865337, disc_loss = 0.14568226452578198
Trained batch 55 in epoch 1, gen_loss = 0.37947186614785877, disc_loss = 0.14484263843457615
Trained batch 56 in epoch 1, gen_loss = 0.37966090388465346, disc_loss = 0.1451080759758489
Trained batch 57 in epoch 1, gen_loss = 0.37918298408902923, disc_loss = 0.1451739213461506
Trained batch 58 in epoch 1, gen_loss = 0.3797251294224949, disc_loss = 0.1443452887489634
Trained batch 59 in epoch 1, gen_loss = 0.38041341404120127, disc_loss = 0.14387554135173558
Trained batch 60 in epoch 1, gen_loss = 0.38021031950340894, disc_loss = 0.14292186907813198
Trained batch 61 in epoch 1, gen_loss = 0.37938323665049767, disc_loss = 0.14246090471504197
Trained batch 62 in epoch 1, gen_loss = 0.38075144896431573, disc_loss = 0.14109939277645142
Trained batch 63 in epoch 1, gen_loss = 0.38262731581926346, disc_loss = 0.1400296688079834
Trained batch 64 in epoch 1, gen_loss = 0.3819748273262611, disc_loss = 0.13841301856132654
Trained batch 65 in epoch 1, gen_loss = 0.3802447666724523, disc_loss = 0.1376496052200144
Trained batch 66 in epoch 1, gen_loss = 0.38118135973588746, disc_loss = 0.13614893131958905
Trained batch 67 in epoch 1, gen_loss = 0.38217227292411465, disc_loss = 0.13432530879371746
Trained batch 68 in epoch 1, gen_loss = 0.38162975121235504, disc_loss = 0.13432213746389185
Trained batch 69 in epoch 1, gen_loss = 0.38071468727929253, disc_loss = 0.13839843482045192
Trained batch 70 in epoch 1, gen_loss = 0.3805266173792557, disc_loss = 0.13837015037228104
Trained batch 71 in epoch 1, gen_loss = 0.3824647300773197, disc_loss = 0.13766788604617533
Trained batch 72 in epoch 1, gen_loss = 0.3840931221230389, disc_loss = 0.13615857509972706
Trained batch 73 in epoch 1, gen_loss = 0.3842832289032034, disc_loss = 0.13876480726223137
Trained batch 74 in epoch 1, gen_loss = 0.3852028799057007, disc_loss = 0.14369681970526774
Trained batch 75 in epoch 1, gen_loss = 0.3856376785981028, disc_loss = 0.14259080722388862
Trained batch 76 in epoch 1, gen_loss = 0.38560377119423506, disc_loss = 0.1413880835904123
Trained batch 77 in epoch 1, gen_loss = 0.38598008912343246, disc_loss = 0.14022873481735587
Trained batch 78 in epoch 1, gen_loss = 0.386461250012434, disc_loss = 0.14090882549416037
Trained batch 79 in epoch 1, gen_loss = 0.38761801086366177, disc_loss = 0.1429720869869925
Trained batch 80 in epoch 1, gen_loss = 0.3880689427440549, disc_loss = 0.1423045386341803
Trained batch 81 in epoch 1, gen_loss = 0.38851366501028944, disc_loss = 0.14209827077688603
Trained batch 82 in epoch 1, gen_loss = 0.3885227800851845, disc_loss = 0.1414539255314024
Trained batch 83 in epoch 1, gen_loss = 0.38887720626024974, disc_loss = 0.1419015929125072
Trained batch 84 in epoch 1, gen_loss = 0.38984913370188545, disc_loss = 0.14141698905869443
Trained batch 85 in epoch 1, gen_loss = 0.38969853797624276, disc_loss = 0.1413797617153546
Trained batch 86 in epoch 1, gen_loss = 0.3892431807243961, disc_loss = 0.14257317958078508
Trained batch 87 in epoch 1, gen_loss = 0.389683606272394, disc_loss = 0.14255843401505527
Trained batch 88 in epoch 1, gen_loss = 0.3894207209683536, disc_loss = 0.14258856674802772
Trained batch 89 in epoch 1, gen_loss = 0.3891202800803714, disc_loss = 0.14316644988333185
Trained batch 90 in epoch 1, gen_loss = 0.3891361905978276, disc_loss = 0.14333384366358046
Trained batch 91 in epoch 1, gen_loss = 0.38941849962524744, disc_loss = 0.14391554670367876
Trained batch 92 in epoch 1, gen_loss = 0.38898875732575694, disc_loss = 0.14401561042834674
Trained batch 93 in epoch 1, gen_loss = 0.38873814775588666, disc_loss = 0.14488483035065075
Trained batch 94 in epoch 1, gen_loss = 0.38816286827388563, disc_loss = 0.1453856360461367
Trained batch 95 in epoch 1, gen_loss = 0.3876168712352713, disc_loss = 0.1468570625584107
Trained batch 96 in epoch 1, gen_loss = 0.3876732968792473, disc_loss = 0.1471444692981151
Trained batch 97 in epoch 1, gen_loss = 0.38766326131869333, disc_loss = 0.14807020603888194
Trained batch 98 in epoch 1, gen_loss = 0.38696739077568054, disc_loss = 0.15242645796388388
Trained batch 99 in epoch 1, gen_loss = 0.3870530664920807, disc_loss = 0.15249016691930592
Trained batch 100 in epoch 1, gen_loss = 0.38719748801524095, disc_loss = 0.15228317077686587
Trained batch 101 in epoch 1, gen_loss = 0.3875238062704311, disc_loss = 0.15246882937008552
Trained batch 102 in epoch 1, gen_loss = 0.3869957478301039, disc_loss = 0.15203346142961274
Trained batch 103 in epoch 1, gen_loss = 0.3870029953809885, disc_loss = 0.15272525630783862
Trained batch 104 in epoch 1, gen_loss = 0.3876715952441806, disc_loss = 0.1527357090530651
Trained batch 105 in epoch 1, gen_loss = 0.3876868925004635, disc_loss = 0.1523758652092854
Trained batch 106 in epoch 1, gen_loss = 0.38765559268889027, disc_loss = 0.1535031615591077
Trained batch 107 in epoch 1, gen_loss = 0.3881596870444439, disc_loss = 0.15365114239803343
Trained batch 108 in epoch 1, gen_loss = 0.38826304017950636, disc_loss = 0.15365359840760812
Trained batch 109 in epoch 1, gen_loss = 0.3873860375447707, disc_loss = 0.15451640010049397
Trained batch 110 in epoch 1, gen_loss = 0.387785728450294, disc_loss = 0.1540942693901089
Trained batch 111 in epoch 1, gen_loss = 0.387372264372451, disc_loss = 0.15402575779340363
Trained batch 112 in epoch 1, gen_loss = 0.3874049782752991, disc_loss = 0.15352531704656056
Trained batch 113 in epoch 1, gen_loss = 0.3866405664828786, disc_loss = 0.15325037681644685
Trained batch 114 in epoch 1, gen_loss = 0.3862125743990359, disc_loss = 0.152712349569344
Trained batch 115 in epoch 1, gen_loss = 0.3863355101182543, disc_loss = 0.15218445155287869
Trained batch 116 in epoch 1, gen_loss = 0.3867887852028904, disc_loss = 0.15163434294458383
Trained batch 117 in epoch 1, gen_loss = 0.3866827624329066, disc_loss = 0.15163108432602326
Trained batch 118 in epoch 1, gen_loss = 0.38695076433550407, disc_loss = 0.15080713375056742
Trained batch 119 in epoch 1, gen_loss = 0.38712766716877617, disc_loss = 0.15020476332089552
Trained batch 120 in epoch 1, gen_loss = 0.38688147831554254, disc_loss = 0.14935223743596598
Trained batch 121 in epoch 1, gen_loss = 0.3867029503720706, disc_loss = 0.14837493119211714
Trained batch 122 in epoch 1, gen_loss = 0.386795686027868, disc_loss = 0.14769372126708427
Trained batch 123 in epoch 1, gen_loss = 0.38713502883911133, disc_loss = 0.14693546199780558
Trained batch 124 in epoch 1, gen_loss = 0.38743027782440187, disc_loss = 0.14613390333205462
Trained batch 125 in epoch 1, gen_loss = 0.3876317034638117, disc_loss = 0.14628860597602195
Trained batch 126 in epoch 1, gen_loss = 0.38846711849603127, disc_loss = 0.1469030480641197
Trained batch 127 in epoch 1, gen_loss = 0.38827249547466636, disc_loss = 0.1462291967254714
Trained batch 128 in epoch 1, gen_loss = 0.38823328877604285, disc_loss = 0.14551590233608042
Trained batch 129 in epoch 1, gen_loss = 0.3886649904342798, disc_loss = 0.14495235384226993
Trained batch 130 in epoch 1, gen_loss = 0.3883768210884269, disc_loss = 0.14495223272193708
Trained batch 131 in epoch 1, gen_loss = 0.3886340328238227, disc_loss = 0.1463696327921229
Trained batch 132 in epoch 1, gen_loss = 0.3890099971366108, disc_loss = 0.1461552941779557
Trained batch 133 in epoch 1, gen_loss = 0.3884350508451462, disc_loss = 0.14602536975698016
Trained batch 134 in epoch 1, gen_loss = 0.3879846767142967, disc_loss = 0.14547931243562037
Trained batch 135 in epoch 1, gen_loss = 0.3879757790881045, disc_loss = 0.14504466146258088
Trained batch 136 in epoch 1, gen_loss = 0.38831767722637983, disc_loss = 0.1446539454610787
Trained batch 137 in epoch 1, gen_loss = 0.38830791608147, disc_loss = 0.14461362098033229
Trained batch 138 in epoch 1, gen_loss = 0.3880028668925059, disc_loss = 0.14598253407522285
Trained batch 139 in epoch 1, gen_loss = 0.3870665401220322, disc_loss = 0.14655651956397509
Trained batch 140 in epoch 1, gen_loss = 0.3869351476219529, disc_loss = 0.1466311480096997
Trained batch 141 in epoch 1, gen_loss = 0.38734039055629516, disc_loss = 0.14660868033583105
Trained batch 142 in epoch 1, gen_loss = 0.3871289877207963, disc_loss = 0.14624964212021835
Trained batch 143 in epoch 1, gen_loss = 0.38703679893579745, disc_loss = 0.14561700055815485
Trained batch 144 in epoch 1, gen_loss = 0.38733792695505864, disc_loss = 0.14496535831612758
Trained batch 145 in epoch 1, gen_loss = 0.38722913987832525, disc_loss = 0.14467622444977704
Trained batch 146 in epoch 1, gen_loss = 0.38763966487378493, disc_loss = 0.14419014248236708
Trained batch 147 in epoch 1, gen_loss = 0.3875672110431903, disc_loss = 0.14352368435671403
Trained batch 148 in epoch 1, gen_loss = 0.38728599940370395, disc_loss = 0.14293174903789824
Trained batch 149 in epoch 1, gen_loss = 0.3876961706082026, disc_loss = 0.14216374666119616
Trained batch 150 in epoch 1, gen_loss = 0.38777641705329846, disc_loss = 0.1422096033031676
Trained batch 151 in epoch 1, gen_loss = 0.3879361331070724, disc_loss = 0.14290951712571673
Trained batch 152 in epoch 1, gen_loss = 0.3881205908613267, disc_loss = 0.1426487414141983
Trained batch 153 in epoch 1, gen_loss = 0.38862416612637507, disc_loss = 0.14308040686459703
Trained batch 154 in epoch 1, gen_loss = 0.38935081035860125, disc_loss = 0.14237854159286906
Trained batch 155 in epoch 1, gen_loss = 0.3894021683014356, disc_loss = 0.14153867124770889
Trained batch 156 in epoch 1, gen_loss = 0.38950449114392516, disc_loss = 0.1409591187776369
Trained batch 157 in epoch 1, gen_loss = 0.38903046823755094, disc_loss = 0.14133594232858926
Trained batch 158 in epoch 1, gen_loss = 0.3891634077021161, disc_loss = 0.14145223412709604
Trained batch 159 in epoch 1, gen_loss = 0.3895294161513448, disc_loss = 0.1413938568031881
Trained batch 160 in epoch 1, gen_loss = 0.3888670133877985, disc_loss = 0.14171546938834909
Trained batch 161 in epoch 1, gen_loss = 0.3890531477000978, disc_loss = 0.1414350562866915
Trained batch 162 in epoch 1, gen_loss = 0.3891592971020681, disc_loss = 0.1417823466843714
Trained batch 163 in epoch 1, gen_loss = 0.38904613038388697, disc_loss = 0.14109962785094068
Trained batch 164 in epoch 1, gen_loss = 0.38863437627301073, disc_loss = 0.14175180329404996
Trained batch 165 in epoch 1, gen_loss = 0.38882121012871523, disc_loss = 0.1416080265687442
Trained batch 166 in epoch 1, gen_loss = 0.3889829873324868, disc_loss = 0.1419390175145811
Trained batch 167 in epoch 1, gen_loss = 0.3886457899851458, disc_loss = 0.1422951132934984
Trained batch 168 in epoch 1, gen_loss = 0.38863838247998933, disc_loss = 0.14211549624778638
Trained batch 169 in epoch 1, gen_loss = 0.3889188282630023, disc_loss = 0.14242816209683523
Trained batch 170 in epoch 1, gen_loss = 0.3889744360195963, disc_loss = 0.14288550704085862
Trained batch 171 in epoch 1, gen_loss = 0.38954785899367445, disc_loss = 0.14237014422474734
Trained batch 172 in epoch 1, gen_loss = 0.38912500897583935, disc_loss = 0.14275327007786903
Trained batch 173 in epoch 1, gen_loss = 0.3895420951062235, disc_loss = 0.14262241357937455
Trained batch 174 in epoch 1, gen_loss = 0.3898871523993356, disc_loss = 0.14305660368608578
Trained batch 175 in epoch 1, gen_loss = 0.3896848809990016, disc_loss = 0.1432911778366278
Trained batch 176 in epoch 1, gen_loss = 0.38986538897799905, disc_loss = 0.14319144662385438
Trained batch 177 in epoch 1, gen_loss = 0.39002393453978423, disc_loss = 0.144009505696804
Trained batch 178 in epoch 1, gen_loss = 0.39031806554874227, disc_loss = 0.14369525021077367
Trained batch 179 in epoch 1, gen_loss = 0.3902034146918191, disc_loss = 0.14479307728405627
Trained batch 180 in epoch 1, gen_loss = 0.38969978163255514, disc_loss = 0.14537656633955173
Trained batch 181 in epoch 1, gen_loss = 0.38989579726706497, disc_loss = 0.1455436924237062
Trained batch 182 in epoch 1, gen_loss = 0.39012904701337137, disc_loss = 0.1455175208660667
Trained batch 183 in epoch 1, gen_loss = 0.3898076900969381, disc_loss = 0.14575683015256957
Trained batch 184 in epoch 1, gen_loss = 0.38973103922766605, disc_loss = 0.14567447559958374
Trained batch 185 in epoch 1, gen_loss = 0.3896318066825149, disc_loss = 0.14547216673431698
Trained batch 186 in epoch 1, gen_loss = 0.38996532129093925, disc_loss = 0.14509944009649403
Trained batch 187 in epoch 1, gen_loss = 0.3894589478348164, disc_loss = 0.14498876983874498
Trained batch 188 in epoch 1, gen_loss = 0.38898666967790596, disc_loss = 0.14522414403676828
Trained batch 189 in epoch 1, gen_loss = 0.3888389377217544, disc_loss = 0.14583037242195324
Trained batch 190 in epoch 1, gen_loss = 0.38873739766824933, disc_loss = 0.1465023872808246
Trained batch 191 in epoch 1, gen_loss = 0.38871118100360036, disc_loss = 0.14666235203912947
Trained batch 192 in epoch 1, gen_loss = 0.3887109671540829, disc_loss = 0.14725583565416578
Trained batch 193 in epoch 1, gen_loss = 0.38838512473499653, disc_loss = 0.1477813540727438
Trained batch 194 in epoch 1, gen_loss = 0.3881586314776005, disc_loss = 0.14804319416005643
Trained batch 195 in epoch 1, gen_loss = 0.3884761041524459, disc_loss = 0.14810813390839922
Trained batch 196 in epoch 1, gen_loss = 0.3887558060551658, disc_loss = 0.14793106533000766
Trained batch 197 in epoch 1, gen_loss = 0.3887651648485299, disc_loss = 0.1479739088969625
Trained batch 198 in epoch 1, gen_loss = 0.3886398553249225, disc_loss = 0.1478113332650994
Trained batch 199 in epoch 1, gen_loss = 0.38830190360546113, disc_loss = 0.14756159951444714
Trained batch 200 in epoch 1, gen_loss = 0.38819803230798067, disc_loss = 0.14734896555524413
Trained batch 201 in epoch 1, gen_loss = 0.38820974012412646, disc_loss = 0.14720495935474145
Trained batch 202 in epoch 1, gen_loss = 0.3883588814676689, disc_loss = 0.14721581946801524
Trained batch 203 in epoch 1, gen_loss = 0.3881339426426327, disc_loss = 0.14729721651996905
Trained batch 204 in epoch 1, gen_loss = 0.3884330431135689, disc_loss = 0.14692082061182435
Trained batch 205 in epoch 1, gen_loss = 0.3887219249623493, disc_loss = 0.14700355602753828
Trained batch 206 in epoch 1, gen_loss = 0.38875901411121017, disc_loss = 0.1467850510759846
Trained batch 207 in epoch 1, gen_loss = 0.3885228940500663, disc_loss = 0.14658508759188968
Trained batch 208 in epoch 1, gen_loss = 0.38872643036135074, disc_loss = 0.1463955692260673
Trained batch 209 in epoch 1, gen_loss = 0.3887780358393987, disc_loss = 0.14627634408839402
Trained batch 210 in epoch 1, gen_loss = 0.38898219740221285, disc_loss = 0.14658058898620555
Trained batch 211 in epoch 1, gen_loss = 0.38887754883968606, disc_loss = 0.1461548046604291
Trained batch 212 in epoch 1, gen_loss = 0.38904044507814683, disc_loss = 0.14658905899353292
Trained batch 213 in epoch 1, gen_loss = 0.3890200006627591, disc_loss = 0.14686981015447004
Trained batch 214 in epoch 1, gen_loss = 0.3890807916951734, disc_loss = 0.14675274554986592
Trained batch 215 in epoch 1, gen_loss = 0.388893309428736, disc_loss = 0.14668019110319652
Trained batch 216 in epoch 1, gen_loss = 0.38915176202075275, disc_loss = 0.14655672193586414
Trained batch 217 in epoch 1, gen_loss = 0.3890486184610139, disc_loss = 0.14615717740011736
Trained batch 218 in epoch 1, gen_loss = 0.388735327954706, disc_loss = 0.14622356009044468
Trained batch 219 in epoch 1, gen_loss = 0.3892542461102659, disc_loss = 0.14625293136235665
Trained batch 220 in epoch 1, gen_loss = 0.3896333045279818, disc_loss = 0.14582577517584844
Trained batch 221 in epoch 1, gen_loss = 0.38950819918164264, disc_loss = 0.14620825535458354
Trained batch 222 in epoch 1, gen_loss = 0.3894084381950276, disc_loss = 0.14693605600367612
Trained batch 223 in epoch 1, gen_loss = 0.3897083956482155, disc_loss = 0.14673626417477084
Trained batch 224 in epoch 1, gen_loss = 0.3895255353715685, disc_loss = 0.14691281273547147
Trained batch 225 in epoch 1, gen_loss = 0.3894253522157669, disc_loss = 0.146930434415529
Trained batch 226 in epoch 1, gen_loss = 0.3894105717736719, disc_loss = 0.14643767838354022
Trained batch 227 in epoch 1, gen_loss = 0.38965291987385664, disc_loss = 0.1466806837594496
Trained batch 228 in epoch 1, gen_loss = 0.3895550555016797, disc_loss = 0.14642647938095196
Trained batch 229 in epoch 1, gen_loss = 0.3897708539081656, disc_loss = 0.14620156182462107
Trained batch 230 in epoch 1, gen_loss = 0.3895474076271057, disc_loss = 0.14656167349564436
Trained batch 231 in epoch 1, gen_loss = 0.3900809660553932, disc_loss = 0.14657072007961186
Trained batch 232 in epoch 1, gen_loss = 0.3901682297815069, disc_loss = 0.14599406486976685
Trained batch 233 in epoch 1, gen_loss = 0.3902810354772796, disc_loss = 0.14545793407477248
Trained batch 234 in epoch 1, gen_loss = 0.3897861289217117, disc_loss = 0.14626773097651435
Trained batch 235 in epoch 1, gen_loss = 0.3900310264553054, disc_loss = 0.14721560790361363
Trained batch 236 in epoch 1, gen_loss = 0.39036776596986794, disc_loss = 0.14711775319092762
Trained batch 237 in epoch 1, gen_loss = 0.3902058716581649, disc_loss = 0.14705325236950978
Trained batch 238 in epoch 1, gen_loss = 0.39002348513782775, disc_loss = 0.14683843035812033
Trained batch 239 in epoch 1, gen_loss = 0.3899274945259094, disc_loss = 0.14700289694204305
Trained batch 240 in epoch 1, gen_loss = 0.3899068918960223, disc_loss = 0.1468073704948502
Trained batch 241 in epoch 1, gen_loss = 0.3898480022249143, disc_loss = 0.14681904266919354
Trained batch 242 in epoch 1, gen_loss = 0.38996482520927617, disc_loss = 0.1472702482868553
Trained batch 243 in epoch 1, gen_loss = 0.38985172304950777, disc_loss = 0.1473666146420492
Trained batch 244 in epoch 1, gen_loss = 0.38993421099623854, disc_loss = 0.14751663350557187
Trained batch 245 in epoch 1, gen_loss = 0.38962670736681154, disc_loss = 0.1473813429134103
Trained batch 246 in epoch 1, gen_loss = 0.3897592636496432, disc_loss = 0.1472506987926388
Trained batch 247 in epoch 1, gen_loss = 0.3900354013087288, disc_loss = 0.14718935731422877
Trained batch 248 in epoch 1, gen_loss = 0.3899713801332267, disc_loss = 0.14735440002851577
Trained batch 249 in epoch 1, gen_loss = 0.38991854155063627, disc_loss = 0.14772656836733222
Trained batch 250 in epoch 1, gen_loss = 0.38984139281440067, disc_loss = 0.14776077026137674
Trained batch 251 in epoch 1, gen_loss = 0.3901105225086212, disc_loss = 0.1477368261982938
Trained batch 252 in epoch 1, gen_loss = 0.3901845603121128, disc_loss = 0.14825977576094065
Trained batch 253 in epoch 1, gen_loss = 0.3899147226585178, disc_loss = 0.1482911922118267
Trained batch 254 in epoch 1, gen_loss = 0.3895672825037264, disc_loss = 0.14913790602529164
Trained batch 255 in epoch 1, gen_loss = 0.3896943711442873, disc_loss = 0.14929448716793559
Trained batch 256 in epoch 1, gen_loss = 0.3896889661072757, disc_loss = 0.14916126925411274
Trained batch 257 in epoch 1, gen_loss = 0.38966408060040586, disc_loss = 0.1491345087708833
Trained batch 258 in epoch 1, gen_loss = 0.3893539222050818, disc_loss = 0.148934963612339
Trained batch 259 in epoch 1, gen_loss = 0.389228794666437, disc_loss = 0.14879554515489593
Trained batch 260 in epoch 1, gen_loss = 0.38885483511106267, disc_loss = 0.14888891702967472
Trained batch 261 in epoch 1, gen_loss = 0.3888282218507228, disc_loss = 0.14907078018042308
Trained batch 262 in epoch 1, gen_loss = 0.3890583452842988, disc_loss = 0.14922823566773433
Trained batch 263 in epoch 1, gen_loss = 0.38901550537257484, disc_loss = 0.1493822498719744
Trained batch 264 in epoch 1, gen_loss = 0.38866253585185645, disc_loss = 0.14911533456014575
Trained batch 265 in epoch 1, gen_loss = 0.38836726759161266, disc_loss = 0.14960486500320913
Trained batch 266 in epoch 1, gen_loss = 0.3882995449871606, disc_loss = 0.1495650043111113
Trained batch 267 in epoch 1, gen_loss = 0.3882366637907811, disc_loss = 0.14957733237907403
Trained batch 268 in epoch 1, gen_loss = 0.388372797172752, disc_loss = 0.14936116763968782
Trained batch 269 in epoch 1, gen_loss = 0.38837330219922245, disc_loss = 0.1489819014755388
Trained batch 270 in epoch 1, gen_loss = 0.38819244152065574, disc_loss = 0.14889439458982862
Trained batch 271 in epoch 1, gen_loss = 0.3884687920046203, disc_loss = 0.148796507044394
Trained batch 272 in epoch 1, gen_loss = 0.388501532021023, disc_loss = 0.1487002701024378
Trained batch 273 in epoch 1, gen_loss = 0.38842923025580217, disc_loss = 0.1488613629557301
Trained batch 274 in epoch 1, gen_loss = 0.3886487416787581, disc_loss = 0.14867372802374038
Trained batch 275 in epoch 1, gen_loss = 0.3887512047869572, disc_loss = 0.1486068558777966
Trained batch 276 in epoch 1, gen_loss = 0.3886300991373372, disc_loss = 0.14912395095553532
Trained batch 277 in epoch 1, gen_loss = 0.3886989182491097, disc_loss = 0.14910802483330848
Trained batch 278 in epoch 1, gen_loss = 0.38864494641194636, disc_loss = 0.14912711492135428
Trained batch 279 in epoch 1, gen_loss = 0.3884841380374772, disc_loss = 0.1491085887188092
Trained batch 280 in epoch 1, gen_loss = 0.388022571483965, disc_loss = 0.14969783037357376
Trained batch 281 in epoch 1, gen_loss = 0.38797427851257593, disc_loss = 0.14988701718905612
Trained batch 282 in epoch 1, gen_loss = 0.38793286249410136, disc_loss = 0.14964603563908868
Trained batch 283 in epoch 1, gen_loss = 0.3876873865513734, disc_loss = 0.1495698341725945
Trained batch 284 in epoch 1, gen_loss = 0.38785222235478856, disc_loss = 0.14984124733886697
Trained batch 285 in epoch 1, gen_loss = 0.38789008828726684, disc_loss = 0.1499516286340158
Trained batch 286 in epoch 1, gen_loss = 0.38791630212022865, disc_loss = 0.1499090224523941
Trained batch 287 in epoch 1, gen_loss = 0.38802904314878917, disc_loss = 0.1497637250221386
Trained batch 288 in epoch 1, gen_loss = 0.38824623410677, disc_loss = 0.14948770921728913
Trained batch 289 in epoch 1, gen_loss = 0.3880012785566264, disc_loss = 0.14981248673886574
Trained batch 290 in epoch 1, gen_loss = 0.3881414776405518, disc_loss = 0.14984781545654094
Trained batch 291 in epoch 1, gen_loss = 0.38787781232840396, disc_loss = 0.1497189250730029
Trained batch 292 in epoch 1, gen_loss = 0.38819390138668414, disc_loss = 0.14969379301961677
Trained batch 293 in epoch 1, gen_loss = 0.38774221882122717, disc_loss = 0.1498622254367132
Trained batch 294 in epoch 1, gen_loss = 0.38752066169754934, disc_loss = 0.15006476829807133
Trained batch 295 in epoch 1, gen_loss = 0.38756941168292147, disc_loss = 0.15127130262742475
Trained batch 296 in epoch 1, gen_loss = 0.3876280792634495, disc_loss = 0.15131834853967333
Trained batch 297 in epoch 1, gen_loss = 0.38747680727267425, disc_loss = 0.15146535812195816
Trained batch 298 in epoch 1, gen_loss = 0.38732079708057904, disc_loss = 0.15134361846976754
Trained batch 299 in epoch 1, gen_loss = 0.3872381446758906, disc_loss = 0.15106511778819065
Trained batch 300 in epoch 1, gen_loss = 0.38723898339905216, disc_loss = 0.15074480063532575
Trained batch 301 in epoch 1, gen_loss = 0.3872725414914011, disc_loss = 0.15061545099088589
Trained batch 302 in epoch 1, gen_loss = 0.38724098475065954, disc_loss = 0.15073852190323692
Trained batch 303 in epoch 1, gen_loss = 0.3871484318454015, disc_loss = 0.1508091786036905
Trained batch 304 in epoch 1, gen_loss = 0.3871851993388817, disc_loss = 0.1512141552952225
Trained batch 305 in epoch 1, gen_loss = 0.3872092385697209, disc_loss = 0.15102178998766283
Trained batch 306 in epoch 1, gen_loss = 0.3871727191664109, disc_loss = 0.1509175949642004
Trained batch 307 in epoch 1, gen_loss = 0.3870494676294265, disc_loss = 0.15099421584700512
Trained batch 308 in epoch 1, gen_loss = 0.3871263070785498, disc_loss = 0.15170018819483255
Trained batch 309 in epoch 1, gen_loss = 0.3871167662643617, disc_loss = 0.15161367665315348
Trained batch 310 in epoch 1, gen_loss = 0.3869422524688328, disc_loss = 0.15189363810733872
Trained batch 311 in epoch 1, gen_loss = 0.3866637038687865, disc_loss = 0.1517993043958902
Trained batch 312 in epoch 1, gen_loss = 0.3866246491194533, disc_loss = 0.1517537754511062
Trained batch 313 in epoch 1, gen_loss = 0.386481707737704, disc_loss = 0.151698473138011
Trained batch 314 in epoch 1, gen_loss = 0.38629857386861527, disc_loss = 0.15180216165229915
Trained batch 315 in epoch 1, gen_loss = 0.3861256725614584, disc_loss = 0.1518062674116249
Trained batch 316 in epoch 1, gen_loss = 0.38584081081185806, disc_loss = 0.1517906238175106
Trained batch 317 in epoch 1, gen_loss = 0.38586268634916104, disc_loss = 0.15179511893880349
Trained batch 318 in epoch 1, gen_loss = 0.385951008542578, disc_loss = 0.15157367871507862
Trained batch 319 in epoch 1, gen_loss = 0.3858130777254701, disc_loss = 0.15136455868778284
Trained batch 320 in epoch 1, gen_loss = 0.385774394897657, disc_loss = 0.15131705306249893
Trained batch 321 in epoch 1, gen_loss = 0.38605253879698165, disc_loss = 0.15125949924626614
Trained batch 322 in epoch 1, gen_loss = 0.3860509229518312, disc_loss = 0.15130085623520353
Trained batch 323 in epoch 1, gen_loss = 0.38564322309361565, disc_loss = 0.1513534753819077
Trained batch 324 in epoch 1, gen_loss = 0.3858759292272421, disc_loss = 0.15129093929838675
Trained batch 325 in epoch 1, gen_loss = 0.386278450946135, disc_loss = 0.1510198618959567
Trained batch 326 in epoch 1, gen_loss = 0.3862343631024025, disc_loss = 0.15095121104452497
Trained batch 327 in epoch 1, gen_loss = 0.38615324420899877, disc_loss = 0.15081659250994917
Trained batch 328 in epoch 1, gen_loss = 0.38628285335190027, disc_loss = 0.1508551107798802
Trained batch 329 in epoch 1, gen_loss = 0.38604639660228385, disc_loss = 0.15104511195906636
Trained batch 330 in epoch 1, gen_loss = 0.3861510398884914, disc_loss = 0.15077635849294255
Trained batch 331 in epoch 1, gen_loss = 0.3864570758249386, disc_loss = 0.15108135671085532
Trained batch 332 in epoch 1, gen_loss = 0.38633567703378807, disc_loss = 0.15139286104567326
Trained batch 333 in epoch 1, gen_loss = 0.38631846224833394, disc_loss = 0.15173352983484636
Trained batch 334 in epoch 1, gen_loss = 0.38633818759847044, disc_loss = 0.15154926713222444
Trained batch 335 in epoch 1, gen_loss = 0.38656800896638915, disc_loss = 0.15149257051303894
Trained batch 336 in epoch 1, gen_loss = 0.3864539725490423, disc_loss = 0.15157234057153987
Trained batch 337 in epoch 1, gen_loss = 0.38639625148660334, disc_loss = 0.15144891956181833
Trained batch 338 in epoch 1, gen_loss = 0.3863493955768315, disc_loss = 0.15164758786723942
Trained batch 339 in epoch 1, gen_loss = 0.3864827958976521, disc_loss = 0.15158819502274343
Trained batch 340 in epoch 1, gen_loss = 0.38635162760085723, disc_loss = 0.1516231103852129
Trained batch 341 in epoch 1, gen_loss = 0.3861734085438544, disc_loss = 0.15219609668935863
Trained batch 342 in epoch 1, gen_loss = 0.38618284159777116, disc_loss = 0.152058769666397
Trained batch 343 in epoch 1, gen_loss = 0.38645358539597935, disc_loss = 0.15209711588605113
Trained batch 344 in epoch 1, gen_loss = 0.3864565512408381, disc_loss = 0.15190249831294236
Trained batch 345 in epoch 1, gen_loss = 0.3862209334711119, disc_loss = 0.15197849466137028
Trained batch 346 in epoch 1, gen_loss = 0.3861131138176327, disc_loss = 0.15206330137257532
Trained batch 347 in epoch 1, gen_loss = 0.38603629634298126, disc_loss = 0.15181750663684618
Trained batch 348 in epoch 1, gen_loss = 0.385979090515727, disc_loss = 0.15208917173869205
Trained batch 349 in epoch 1, gen_loss = 0.3858477644409452, disc_loss = 0.15257431916626438
Trained batch 350 in epoch 1, gen_loss = 0.3859613845151374, disc_loss = 0.15250807203235706
Trained batch 351 in epoch 1, gen_loss = 0.38605503196066077, disc_loss = 0.15233318447082472
Trained batch 352 in epoch 1, gen_loss = 0.38597071584493514, disc_loss = 0.1525812995285007
Trained batch 353 in epoch 1, gen_loss = 0.38624712648028037, disc_loss = 0.15329878666506563
Trained batch 354 in epoch 1, gen_loss = 0.38621420977820814, disc_loss = 0.15346267356366758
Trained batch 355 in epoch 1, gen_loss = 0.3862925208686443, disc_loss = 0.15351874128852583
Trained batch 356 in epoch 1, gen_loss = 0.38632017975093935, disc_loss = 0.15361334653492986
Trained batch 357 in epoch 1, gen_loss = 0.3860302695681929, disc_loss = 0.15374375761918432
Trained batch 358 in epoch 1, gen_loss = 0.38599840860844986, disc_loss = 0.15433814265300885
Trained batch 359 in epoch 1, gen_loss = 0.3859143897891045, disc_loss = 0.15435236579376377
Trained batch 360 in epoch 1, gen_loss = 0.3862328991665404, disc_loss = 0.15429353811765228
Trained batch 361 in epoch 1, gen_loss = 0.3863465838669413, disc_loss = 0.15417781565595645
Trained batch 362 in epoch 1, gen_loss = 0.3862256501331802, disc_loss = 0.15420689245752642
Trained batch 363 in epoch 1, gen_loss = 0.38637943140098024, disc_loss = 0.15413625201384362
Trained batch 364 in epoch 1, gen_loss = 0.38637638606437263, disc_loss = 0.15403103351541986
Trained batch 365 in epoch 1, gen_loss = 0.3863569223652772, disc_loss = 0.15382554124318104
Trained batch 366 in epoch 1, gen_loss = 0.3862502226550183, disc_loss = 0.1538724536989747
Trained batch 367 in epoch 1, gen_loss = 0.3861251430504996, disc_loss = 0.15412454803869047
Trained batch 368 in epoch 1, gen_loss = 0.3862009666314939, disc_loss = 0.15469520535764253
Trained batch 369 in epoch 1, gen_loss = 0.3860556298011058, disc_loss = 0.15451225977441346
Trained batch 370 in epoch 1, gen_loss = 0.38602970793562114, disc_loss = 0.15454828988941452
Trained batch 371 in epoch 1, gen_loss = 0.38601688303614173, disc_loss = 0.15454072325730756
Trained batch 372 in epoch 1, gen_loss = 0.3860611700660102, disc_loss = 0.1545155013289712
Trained batch 373 in epoch 1, gen_loss = 0.3860069076645183, disc_loss = 0.15448060584687853
Trained batch 374 in epoch 1, gen_loss = 0.3861189272403717, disc_loss = 0.15450088815639415
Trained batch 375 in epoch 1, gen_loss = 0.38589769910941735, disc_loss = 0.15456206704975364
Trained batch 376 in epoch 1, gen_loss = 0.38582964261267483, disc_loss = 0.15464505862286537
Trained batch 377 in epoch 1, gen_loss = 0.38589306569919385, disc_loss = 0.15461294219715807
Trained batch 378 in epoch 1, gen_loss = 0.3860457290288326, disc_loss = 0.15447835709486835
Trained batch 379 in epoch 1, gen_loss = 0.3858410211770158, disc_loss = 0.15461643533045916
Trained batch 380 in epoch 1, gen_loss = 0.38582864779187, disc_loss = 0.15472249055814163
Trained batch 381 in epoch 1, gen_loss = 0.385712668299675, disc_loss = 0.1547084090943541
Trained batch 382 in epoch 1, gen_loss = 0.3856171845767268, disc_loss = 0.15473029483109713
Trained batch 383 in epoch 1, gen_loss = 0.38548328580024344, disc_loss = 0.15478223440732108
Trained batch 384 in epoch 1, gen_loss = 0.3852413460031732, disc_loss = 0.15486254029024343
Trained batch 385 in epoch 1, gen_loss = 0.3851223530855821, disc_loss = 0.15522127635921762
Trained batch 386 in epoch 1, gen_loss = 0.38530224561691284, disc_loss = 0.15561222193343927
Trained batch 387 in epoch 1, gen_loss = 0.38522037863731384, disc_loss = 0.15552539212062724
Trained batch 388 in epoch 1, gen_loss = 0.38502905332030857, disc_loss = 0.15546003683855647
Trained batch 389 in epoch 1, gen_loss = 0.38515318830808004, disc_loss = 0.15529545637993858
Trained batch 390 in epoch 1, gen_loss = 0.3850597883276927, disc_loss = 0.15514724723318274
Trained batch 391 in epoch 1, gen_loss = 0.38488244523807447, disc_loss = 0.15501512745537852
Trained batch 392 in epoch 1, gen_loss = 0.38486659996988815, disc_loss = 0.1549999227311282
Trained batch 393 in epoch 1, gen_loss = 0.38484990831256516, disc_loss = 0.15570269157013236
Trained batch 394 in epoch 1, gen_loss = 0.38489427883413774, disc_loss = 0.15553572323833462
Trained batch 395 in epoch 1, gen_loss = 0.3846912919872939, disc_loss = 0.15562882194192046
Trained batch 396 in epoch 1, gen_loss = 0.38457678149569247, disc_loss = 0.15556407863185073
Trained batch 397 in epoch 1, gen_loss = 0.38460463150661794, disc_loss = 0.155452143220727
Trained batch 398 in epoch 1, gen_loss = 0.3846392563560553, disc_loss = 0.1553919442572204
Trained batch 399 in epoch 1, gen_loss = 0.3846639259904623, disc_loss = 0.15536448652623222
Trained batch 400 in epoch 1, gen_loss = 0.38477796710042883, disc_loss = 0.15564865225744887
Trained batch 401 in epoch 1, gen_loss = 0.3847107191139193, disc_loss = 0.15545777979061304
Trained batch 402 in epoch 1, gen_loss = 0.3846668305970895, disc_loss = 0.15531539568266192
Trained batch 403 in epoch 1, gen_loss = 0.38466947009362795, disc_loss = 0.15524569683763575
Trained batch 404 in epoch 1, gen_loss = 0.3846171304031655, disc_loss = 0.15506750373514713
Trained batch 405 in epoch 1, gen_loss = 0.3844597468088413, disc_loss = 0.15500276402473964
Trained batch 406 in epoch 1, gen_loss = 0.3842930569695606, disc_loss = 0.15490268823217043
Trained batch 407 in epoch 1, gen_loss = 0.38411200937687184, disc_loss = 0.15476786627151146
Trained batch 408 in epoch 1, gen_loss = 0.3840045539848962, disc_loss = 0.155129145336745
Trained batch 409 in epoch 1, gen_loss = 0.3840573044084921, disc_loss = 0.15537266226757954
Trained batch 410 in epoch 1, gen_loss = 0.3841449706078736, disc_loss = 0.1553636306824294
Trained batch 411 in epoch 1, gen_loss = 0.38388699372705903, disc_loss = 0.15553552878667934
Trained batch 412 in epoch 1, gen_loss = 0.38385244641119287, disc_loss = 0.15538307675104093
Trained batch 413 in epoch 1, gen_loss = 0.38382071566178605, disc_loss = 0.15535072133547945
Trained batch 414 in epoch 1, gen_loss = 0.383820904952934, disc_loss = 0.15529212937970838
Trained batch 415 in epoch 1, gen_loss = 0.3836689977548443, disc_loss = 0.1553373039552333
Trained batch 416 in epoch 1, gen_loss = 0.383514549735067, disc_loss = 0.15572391647613235
Trained batch 417 in epoch 1, gen_loss = 0.3834195096384395, disc_loss = 0.1557053119438794
Trained batch 418 in epoch 1, gen_loss = 0.3835659768956942, disc_loss = 0.15568614981152776
Trained batch 419 in epoch 1, gen_loss = 0.38348977438041143, disc_loss = 0.1555689888585004
Trained batch 420 in epoch 1, gen_loss = 0.3834280920283528, disc_loss = 0.15559267823201672
Trained batch 421 in epoch 1, gen_loss = 0.38322461767219257, disc_loss = 0.15632095667025983
Trained batch 422 in epoch 1, gen_loss = 0.38323967528681385, disc_loss = 0.15645380560132557
Trained batch 423 in epoch 1, gen_loss = 0.3831597106214964, disc_loss = 0.15646452012796938
Trained batch 424 in epoch 1, gen_loss = 0.38302780572105855, disc_loss = 0.15636741286472364
Trained batch 425 in epoch 1, gen_loss = 0.38310859404819114, disc_loss = 0.15615632674250174
Trained batch 426 in epoch 1, gen_loss = 0.3831721822048518, disc_loss = 0.15602160231875523
Trained batch 427 in epoch 1, gen_loss = 0.38311205289074196, disc_loss = 0.15602520751227217
Trained batch 428 in epoch 1, gen_loss = 0.3831364542315334, disc_loss = 0.1559591140741339
Trained batch 429 in epoch 1, gen_loss = 0.3831567658241405, disc_loss = 0.15583987389149706
Trained batch 430 in epoch 1, gen_loss = 0.38340255956915303, disc_loss = 0.15567692260964494
Trained batch 431 in epoch 1, gen_loss = 0.38325502778644915, disc_loss = 0.15563445311272517
Trained batch 432 in epoch 1, gen_loss = 0.3832606167358284, disc_loss = 0.15547867479581412
Trained batch 433 in epoch 1, gen_loss = 0.38330026561488756, disc_loss = 0.1557966980134665
Trained batch 434 in epoch 1, gen_loss = 0.38318819992843717, disc_loss = 0.15599400530215995
Trained batch 435 in epoch 1, gen_loss = 0.3832562971142454, disc_loss = 0.15596991427746867
Trained batch 436 in epoch 1, gen_loss = 0.38342856535649683, disc_loss = 0.15584246560854484
Trained batch 437 in epoch 1, gen_loss = 0.38328167136129176, disc_loss = 0.15585430291987376
Trained batch 438 in epoch 1, gen_loss = 0.3832219479295822, disc_loss = 0.15576185459792954
Trained batch 439 in epoch 1, gen_loss = 0.3831984966993332, disc_loss = 0.15575640713584354
Trained batch 440 in epoch 1, gen_loss = 0.38335251449998003, disc_loss = 0.1559011287830956
Trained batch 441 in epoch 1, gen_loss = 0.38358663905799656, disc_loss = 0.15573338996323996
Trained batch 442 in epoch 1, gen_loss = 0.3835582049651824, disc_loss = 0.15570285092854272
Trained batch 443 in epoch 1, gen_loss = 0.3835724416348311, disc_loss = 0.15554773140287548
Trained batch 444 in epoch 1, gen_loss = 0.38356908794199485, disc_loss = 0.1554312364501732
Trained batch 445 in epoch 1, gen_loss = 0.38356678428404, disc_loss = 0.15528368345783364
Trained batch 446 in epoch 1, gen_loss = 0.3834100319635148, disc_loss = 0.15516971864047932
Trained batch 447 in epoch 1, gen_loss = 0.38330881843077286, disc_loss = 0.1552314978388105
Trained batch 448 in epoch 1, gen_loss = 0.3832936339362427, disc_loss = 0.1557167076748404
Trained batch 449 in epoch 1, gen_loss = 0.3832071431477865, disc_loss = 0.15566100298323565
Trained batch 450 in epoch 1, gen_loss = 0.38324435369138443, disc_loss = 0.15554706594326478
Trained batch 451 in epoch 1, gen_loss = 0.38321296330046867, disc_loss = 0.15549515590557944
Trained batch 452 in epoch 1, gen_loss = 0.3830830788375526, disc_loss = 0.15547862988392971
Trained batch 453 in epoch 1, gen_loss = 0.3829829740104171, disc_loss = 0.1554993237491845
Trained batch 454 in epoch 1, gen_loss = 0.38299868002042664, disc_loss = 0.15542335293081763
Trained batch 455 in epoch 1, gen_loss = 0.38285034104136, disc_loss = 0.15532198403512634
Trained batch 456 in epoch 1, gen_loss = 0.38268228361069245, disc_loss = 0.15529848389629136
Trained batch 457 in epoch 1, gen_loss = 0.3827694355790792, disc_loss = 0.15524340800607503
Trained batch 458 in epoch 1, gen_loss = 0.38325543529587375, disc_loss = 0.15566373279435897
Testing Epoch 1
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 13:16:58,421
------------------------------------------------------------
Training Epoch 2
Trained batch 0 in epoch 2, gen_loss = 0.39697709679603577, disc_loss = 0.12579113245010376
Trained batch 1 in epoch 2, gen_loss = 0.39712493121623993, disc_loss = 0.17662756890058517
Trained batch 2 in epoch 2, gen_loss = 0.3917945325374603, disc_loss = 0.21342597901821136
Trained batch 3 in epoch 2, gen_loss = 0.3979451060295105, disc_loss = 0.3321708180010319
Trained batch 4 in epoch 2, gen_loss = 0.39304051995277406, disc_loss = 0.313677516579628
Trained batch 5 in epoch 2, gen_loss = 0.39209112028280896, disc_loss = 0.3076745296518008
Trained batch 6 in epoch 2, gen_loss = 0.38736043657575336, disc_loss = 0.31473208538123537
Trained batch 7 in epoch 2, gen_loss = 0.3726763650774956, disc_loss = 0.343724736943841
Trained batch 8 in epoch 2, gen_loss = 0.36907031801011825, disc_loss = 0.3613903803957833
Trained batch 9 in epoch 2, gen_loss = 0.3634516566991806, disc_loss = 0.35308419317007067
Trained batch 10 in epoch 2, gen_loss = 0.37294694781303406, disc_loss = 0.3450859554789283
Trained batch 11 in epoch 2, gen_loss = 0.371233897904555, disc_loss = 0.33934053406119347
Trained batch 12 in epoch 2, gen_loss = 0.3642909091252547, disc_loss = 0.32814013155607075
Trained batch 13 in epoch 2, gen_loss = 0.363784311073167, disc_loss = 0.3254631129758699
Trained batch 14 in epoch 2, gen_loss = 0.3631725112597148, disc_loss = 0.31964045763015747
Trained batch 15 in epoch 2, gen_loss = 0.3605186939239502, disc_loss = 0.31409562565386295
Trained batch 16 in epoch 2, gen_loss = 0.3572866671225604, disc_loss = 0.30945775263449726
Trained batch 17 in epoch 2, gen_loss = 0.3559933321343528, disc_loss = 0.3044372515545951
Trained batch 18 in epoch 2, gen_loss = 0.3519494110032132, disc_loss = 0.3016849269992427
Trained batch 19 in epoch 2, gen_loss = 0.35274135023355485, disc_loss = 0.2985878728330135
Trained batch 20 in epoch 2, gen_loss = 0.35091873435747056, disc_loss = 0.29464629221530186
Trained batch 21 in epoch 2, gen_loss = 0.3536354520104148, disc_loss = 0.2903065803376111
Trained batch 22 in epoch 2, gen_loss = 0.3540418368318807, disc_loss = 0.28631779033204785
Trained batch 23 in epoch 2, gen_loss = 0.35690195485949516, disc_loss = 0.2821770614633958
Trained batch 24 in epoch 2, gen_loss = 0.35808669924736025, disc_loss = 0.2775642961263657
Trained batch 25 in epoch 2, gen_loss = 0.3569269890968616, disc_loss = 0.2739619377713937
Trained batch 26 in epoch 2, gen_loss = 0.356240372966837, disc_loss = 0.2727657385446407
Trained batch 27 in epoch 2, gen_loss = 0.3565540185996464, disc_loss = 0.2716774716973305
Trained batch 28 in epoch 2, gen_loss = 0.35600062382632286, disc_loss = 0.2705794156625353
Trained batch 29 in epoch 2, gen_loss = 0.3560918837785721, disc_loss = 0.2686672156055768
Trained batch 30 in epoch 2, gen_loss = 0.3538939404872156, disc_loss = 0.26660668994149855
Trained batch 31 in epoch 2, gen_loss = 0.35475732292979956, disc_loss = 0.2636745707131922
Trained batch 32 in epoch 2, gen_loss = 0.3532541755473975, disc_loss = 0.2613934517809839
Trained batch 33 in epoch 2, gen_loss = 0.35347049727159385, disc_loss = 0.2578893474796239
Trained batch 34 in epoch 2, gen_loss = 0.3562259878431048, disc_loss = 0.25643020442553927
Trained batch 35 in epoch 2, gen_loss = 0.3546021365457111, disc_loss = 0.25467818561527467
Trained batch 36 in epoch 2, gen_loss = 0.3554667741865725, disc_loss = 0.253515731241252
Trained batch 37 in epoch 2, gen_loss = 0.35729825104537766, disc_loss = 0.25357100093051005
Trained batch 38 in epoch 2, gen_loss = 0.3553551129805736, disc_loss = 0.2515963862339656
Trained batch 39 in epoch 2, gen_loss = 0.35551458448171613, disc_loss = 0.253035094961524
Trained batch 40 in epoch 2, gen_loss = 0.3554127398060589, disc_loss = 0.2511263827725155
Trained batch 41 in epoch 2, gen_loss = 0.3549598114831107, disc_loss = 0.2502486074254626
Trained batch 42 in epoch 2, gen_loss = 0.3540252460989841, disc_loss = 0.24980999425400136
Trained batch 43 in epoch 2, gen_loss = 0.35366286540573294, disc_loss = 0.24793670123273676
Trained batch 44 in epoch 2, gen_loss = 0.35332554777463276, disc_loss = 0.24666021333800422
Trained batch 45 in epoch 2, gen_loss = 0.3527323039977447, disc_loss = 0.2445609848136487
Trained batch 46 in epoch 2, gen_loss = 0.35451625699692585, disc_loss = 0.24253863603510756
Trained batch 47 in epoch 2, gen_loss = 0.35472608047227067, disc_loss = 0.24051624163985252
Trained batch 48 in epoch 2, gen_loss = 0.35481293590701357, disc_loss = 0.2381116468079236
Trained batch 49 in epoch 2, gen_loss = 0.35490758895874025, disc_loss = 0.2362066251039505
Trained batch 50 in epoch 2, gen_loss = 0.3552638543587105, disc_loss = 0.23498051365216574
Trained batch 51 in epoch 2, gen_loss = 0.35553701451191533, disc_loss = 0.23490937455342367
Trained batch 52 in epoch 2, gen_loss = 0.35361459401418577, disc_loss = 0.23611364443347138
Trained batch 53 in epoch 2, gen_loss = 0.3534579928274508, disc_loss = 0.2349257750643624
Trained batch 54 in epoch 2, gen_loss = 0.35388532335107975, disc_loss = 0.23509158194065094
Trained batch 55 in epoch 2, gen_loss = 0.3543187193572521, disc_loss = 0.23471510357090405
Trained batch 56 in epoch 2, gen_loss = 0.3540844363078736, disc_loss = 0.23366793937850416
Trained batch 57 in epoch 2, gen_loss = 0.3544502931422201, disc_loss = 0.2322041929281991
Trained batch 58 in epoch 2, gen_loss = 0.3543274594565569, disc_loss = 0.2308228760957718
Trained batch 59 in epoch 2, gen_loss = 0.35389341513315836, disc_loss = 0.22939373726646106
Trained batch 60 in epoch 2, gen_loss = 0.35307369808681677, disc_loss = 0.22848249727585276
Trained batch 61 in epoch 2, gen_loss = 0.3525322305579339, disc_loss = 0.2279747847107149
Trained batch 62 in epoch 2, gen_loss = 0.3519761954981183, disc_loss = 0.22844736467278193
Trained batch 63 in epoch 2, gen_loss = 0.3526660059578717, disc_loss = 0.22761867218650877
Trained batch 64 in epoch 2, gen_loss = 0.35336299401063187, disc_loss = 0.22671618736707247
Trained batch 65 in epoch 2, gen_loss = 0.35272536675135296, disc_loss = 0.22569633094650327
Trained batch 66 in epoch 2, gen_loss = 0.35301784748461706, disc_loss = 0.22411305435113052
Trained batch 67 in epoch 2, gen_loss = 0.3534555286169052, disc_loss = 0.22266195944565184
Trained batch 68 in epoch 2, gen_loss = 0.3527956993683525, disc_loss = 0.22218102681032126
Trained batch 69 in epoch 2, gen_loss = 0.35325183016913275, disc_loss = 0.22148683592677115
Trained batch 70 in epoch 2, gen_loss = 0.3532108379081941, disc_loss = 0.221744539767084
Trained batch 71 in epoch 2, gen_loss = 0.3537973024778896, disc_loss = 0.22406361697034705
Trained batch 72 in epoch 2, gen_loss = 0.3535037587766778, disc_loss = 0.2238643299022766
Trained batch 73 in epoch 2, gen_loss = 0.3538859470470532, disc_loss = 0.2230073365609388
Trained batch 74 in epoch 2, gen_loss = 0.3536328423023224, disc_loss = 0.22190924515326818
Trained batch 75 in epoch 2, gen_loss = 0.35305433877204595, disc_loss = 0.22069264742496766
Trained batch 76 in epoch 2, gen_loss = 0.35271198331535636, disc_loss = 0.21972785628848263
Trained batch 77 in epoch 2, gen_loss = 0.3528829916165425, disc_loss = 0.21859629901173788
Trained batch 78 in epoch 2, gen_loss = 0.352908235184754, disc_loss = 0.2175156499577474
Trained batch 79 in epoch 2, gen_loss = 0.352995016425848, disc_loss = 0.21635382054373622
Trained batch 80 in epoch 2, gen_loss = 0.35333626468976337, disc_loss = 0.21608271449804306
Trained batch 81 in epoch 2, gen_loss = 0.35316750080120274, disc_loss = 0.21743412633858075
Trained batch 82 in epoch 2, gen_loss = 0.3534478613411088, disc_loss = 0.2177693993750825
Trained batch 83 in epoch 2, gen_loss = 0.35311638315518695, disc_loss = 0.21718669815787248
Trained batch 84 in epoch 2, gen_loss = 0.3524407695321476, disc_loss = 0.21649058925754883
Trained batch 85 in epoch 2, gen_loss = 0.353163038575372, disc_loss = 0.2158719937988492
Trained batch 86 in epoch 2, gen_loss = 0.3529108087906892, disc_loss = 0.21492785378091636
Trained batch 87 in epoch 2, gen_loss = 0.35263165255839174, disc_loss = 0.21538989474488932
Trained batch 88 in epoch 2, gen_loss = 0.35292082924521373, disc_loss = 0.2147294707345159
Trained batch 89 in epoch 2, gen_loss = 0.3533295217487547, disc_loss = 0.2145820616847939
Trained batch 90 in epoch 2, gen_loss = 0.3530724998358842, disc_loss = 0.21524505456397822
Trained batch 91 in epoch 2, gen_loss = 0.35377877756305365, disc_loss = 0.21450801266600256
Trained batch 92 in epoch 2, gen_loss = 0.3539398786842182, disc_loss = 0.21362966515364185
Trained batch 93 in epoch 2, gen_loss = 0.35370794731251737, disc_loss = 0.2138357898814881
Trained batch 94 in epoch 2, gen_loss = 0.3537572559557463, disc_loss = 0.21306804661688053
Trained batch 95 in epoch 2, gen_loss = 0.3538189396883051, disc_loss = 0.21216244553215802
Trained batch 96 in epoch 2, gen_loss = 0.35388200829938515, disc_loss = 0.21180700295671975
Trained batch 97 in epoch 2, gen_loss = 0.35377743870628126, disc_loss = 0.21142931092454462
Trained batch 98 in epoch 2, gen_loss = 0.3538112860135358, disc_loss = 0.21063912449160008
Trained batch 99 in epoch 2, gen_loss = 0.35318819880485536, disc_loss = 0.20984399430453776
Trained batch 100 in epoch 2, gen_loss = 0.35378925900648134, disc_loss = 0.20889574931104585
Trained batch 101 in epoch 2, gen_loss = 0.3538089099467969, disc_loss = 0.20787303259267526
Trained batch 102 in epoch 2, gen_loss = 0.35384043617155947, disc_loss = 0.20721817125105163
Trained batch 103 in epoch 2, gen_loss = 0.35439391520160896, disc_loss = 0.2071890877559781
Trained batch 104 in epoch 2, gen_loss = 0.35445975689660936, disc_loss = 0.20825806664569038
Trained batch 105 in epoch 2, gen_loss = 0.3545583930780303, disc_loss = 0.21005571823356287
Trained batch 106 in epoch 2, gen_loss = 0.3549571293536748, disc_loss = 0.20958790036840974
Trained batch 107 in epoch 2, gen_loss = 0.35560060540835065, disc_loss = 0.20927831164940638
Trained batch 108 in epoch 2, gen_loss = 0.3558268000226502, disc_loss = 0.2088659663402706
Trained batch 109 in epoch 2, gen_loss = 0.35509303943677384, disc_loss = 0.20861519622531804
Trained batch 110 in epoch 2, gen_loss = 0.35580475883440926, disc_loss = 0.20823632012884896
Trained batch 111 in epoch 2, gen_loss = 0.35526736160474165, disc_loss = 0.2076695487568421
Trained batch 112 in epoch 2, gen_loss = 0.3547772282520227, disc_loss = 0.20755723441860316
Trained batch 113 in epoch 2, gen_loss = 0.35485492123846424, disc_loss = 0.2072369653012669
Trained batch 114 in epoch 2, gen_loss = 0.354796432412189, disc_loss = 0.20657132598369018
Trained batch 115 in epoch 2, gen_loss = 0.35402391825256674, disc_loss = 0.20633806667194285
Trained batch 116 in epoch 2, gen_loss = 0.35392872237751627, disc_loss = 0.20612073447714505
Trained batch 117 in epoch 2, gen_loss = 0.35443418662426834, disc_loss = 0.20524812363466974
Trained batch 118 in epoch 2, gen_loss = 0.3547308036760122, disc_loss = 0.20459093328784494
Trained batch 119 in epoch 2, gen_loss = 0.35463277573386826, disc_loss = 0.20416698728998503
Trained batch 120 in epoch 2, gen_loss = 0.3548514128716524, disc_loss = 0.20365279617388388
Trained batch 121 in epoch 2, gen_loss = 0.35441684063340795, disc_loss = 0.20276904264923
Trained batch 122 in epoch 2, gen_loss = 0.35428263065291615, disc_loss = 0.2034986148762509
Trained batch 123 in epoch 2, gen_loss = 0.354985085706557, disc_loss = 0.20395838337079172
Trained batch 124 in epoch 2, gen_loss = 0.3548505663871765, disc_loss = 0.20352499449253084
Trained batch 125 in epoch 2, gen_loss = 0.35490510364373523, disc_loss = 0.2029695121778382
Trained batch 126 in epoch 2, gen_loss = 0.35540419136445356, disc_loss = 0.2022971251583475
Trained batch 127 in epoch 2, gen_loss = 0.35533601068891585, disc_loss = 0.20180126558989286
Trained batch 128 in epoch 2, gen_loss = 0.35545142191325046, disc_loss = 0.20177393943764443
Trained batch 129 in epoch 2, gen_loss = 0.35538802307385664, disc_loss = 0.20170559963354698
Trained batch 130 in epoch 2, gen_loss = 0.3552442290855728, disc_loss = 0.20243612580171977
Trained batch 131 in epoch 2, gen_loss = 0.3556774996898391, disc_loss = 0.20182149067069544
Trained batch 132 in epoch 2, gen_loss = 0.3563367607898282, disc_loss = 0.20101953258639887
Trained batch 133 in epoch 2, gen_loss = 0.35622854241684304, disc_loss = 0.20080181967411467
Trained batch 134 in epoch 2, gen_loss = 0.3567707609247278, disc_loss = 0.20057268628367672
Trained batch 135 in epoch 2, gen_loss = 0.35685129332191806, disc_loss = 0.20063901013311217
Trained batch 136 in epoch 2, gen_loss = 0.35696990929380823, disc_loss = 0.20165938160715313
Trained batch 137 in epoch 2, gen_loss = 0.3569984820441923, disc_loss = 0.20166299384141315
Trained batch 138 in epoch 2, gen_loss = 0.3575334810524536, disc_loss = 0.20116793626932788
Trained batch 139 in epoch 2, gen_loss = 0.35762156482253754, disc_loss = 0.20037739888897965
Trained batch 140 in epoch 2, gen_loss = 0.35811286847642126, disc_loss = 0.19950129075887355
Trained batch 141 in epoch 2, gen_loss = 0.3588799385117813, disc_loss = 0.19886618039347756
Trained batch 142 in epoch 2, gen_loss = 0.35961209581448483, disc_loss = 0.19814120816600905
Trained batch 143 in epoch 2, gen_loss = 0.3603245974000957, disc_loss = 0.19743061557205188
Trained batch 144 in epoch 2, gen_loss = 0.36052062943063934, disc_loss = 0.19721344231531537
Trained batch 145 in epoch 2, gen_loss = 0.36039267357898086, disc_loss = 0.19804135021077443
Trained batch 146 in epoch 2, gen_loss = 0.36096823762874214, disc_loss = 0.19916555462848573
Trained batch 147 in epoch 2, gen_loss = 0.36083464747345123, disc_loss = 0.19897943367627827
Trained batch 148 in epoch 2, gen_loss = 0.36040411039486825, disc_loss = 0.1986180809420227
Trained batch 149 in epoch 2, gen_loss = 0.3601769208908081, disc_loss = 0.19811596219738326
Trained batch 150 in epoch 2, gen_loss = 0.3598178585633537, disc_loss = 0.19815346228563233
Trained batch 151 in epoch 2, gen_loss = 0.3598869413529572, disc_loss = 0.1979299748904611
Trained batch 152 in epoch 2, gen_loss = 0.35966987372223846, disc_loss = 0.1975362499067986
Trained batch 153 in epoch 2, gen_loss = 0.359911026892724, disc_loss = 0.19734073270644462
Trained batch 154 in epoch 2, gen_loss = 0.3598441283549032, disc_loss = 0.19734951310580776
Trained batch 155 in epoch 2, gen_loss = 0.359896291524936, disc_loss = 0.19710984162222117
Trained batch 156 in epoch 2, gen_loss = 0.3603778714966622, disc_loss = 0.19643247331593447
Trained batch 157 in epoch 2, gen_loss = 0.3603811230086073, disc_loss = 0.1957560183032404
Trained batch 158 in epoch 2, gen_loss = 0.36037365239371294, disc_loss = 0.1954447536629701
Trained batch 159 in epoch 2, gen_loss = 0.36068357080221175, disc_loss = 0.19537246259860694
Trained batch 160 in epoch 2, gen_loss = 0.361305792879614, disc_loss = 0.19476748961284293
Trained batch 161 in epoch 2, gen_loss = 0.36135587408954717, disc_loss = 0.19434754352694678
Trained batch 162 in epoch 2, gen_loss = 0.3617158435239382, disc_loss = 0.19417231511667463
Trained batch 163 in epoch 2, gen_loss = 0.36187606741015504, disc_loss = 0.19397696221201885
Trained batch 164 in epoch 2, gen_loss = 0.36201186884533276, disc_loss = 0.19348884084911058
Trained batch 165 in epoch 2, gen_loss = 0.36244967472122375, disc_loss = 0.19297741510602365
Trained batch 166 in epoch 2, gen_loss = 0.36200969661781174, disc_loss = 0.19292896535403714
Trained batch 167 in epoch 2, gen_loss = 0.36214135782349677, disc_loss = 0.19354778665694453
Trained batch 168 in epoch 2, gen_loss = 0.36209299754814284, disc_loss = 0.19335794312185084
Trained batch 169 in epoch 2, gen_loss = 0.3626758566674064, disc_loss = 0.19305290733190145
Trained batch 170 in epoch 2, gen_loss = 0.36296388506889343, disc_loss = 0.19249672041824686
Trained batch 171 in epoch 2, gen_loss = 0.3635746803741122, disc_loss = 0.19229666329920292
Trained batch 172 in epoch 2, gen_loss = 0.3631475457566322, disc_loss = 0.1924141131642926
Trained batch 173 in epoch 2, gen_loss = 0.36334535873484336, disc_loss = 0.19246080316517544
Trained batch 174 in epoch 2, gen_loss = 0.36338546105793545, disc_loss = 0.19206387034484318
Trained batch 175 in epoch 2, gen_loss = 0.363471224734729, disc_loss = 0.19160075384107503
Trained batch 176 in epoch 2, gen_loss = 0.3636701876497538, disc_loss = 0.19089527015632154
Trained batch 177 in epoch 2, gen_loss = 0.3633995243672575, disc_loss = 0.1903794247112917
Trained batch 178 in epoch 2, gen_loss = 0.36333525996634414, disc_loss = 0.19005534119446185
Trained batch 179 in epoch 2, gen_loss = 0.36340072088771397, disc_loss = 0.19128546350532108
Trained batch 180 in epoch 2, gen_loss = 0.3635883696830075, disc_loss = 0.19127464022754964
Trained batch 181 in epoch 2, gen_loss = 0.3637408861419657, disc_loss = 0.1907475008578091
Trained batch 182 in epoch 2, gen_loss = 0.36396126294396614, disc_loss = 0.19050471224094348
Trained batch 183 in epoch 2, gen_loss = 0.364118124641802, disc_loss = 0.18993109748091386
Trained batch 184 in epoch 2, gen_loss = 0.3640442007296794, disc_loss = 0.1895292411784868
Trained batch 185 in epoch 2, gen_loss = 0.3644787819795711, disc_loss = 0.1897862844409481
Trained batch 186 in epoch 2, gen_loss = 0.36443069656902455, disc_loss = 0.18934240801767868
Trained batch 187 in epoch 2, gen_loss = 0.36453543270521976, disc_loss = 0.18891877455121658
Trained batch 188 in epoch 2, gen_loss = 0.3644285810687555, disc_loss = 0.18904198449913157
Trained batch 189 in epoch 2, gen_loss = 0.3644413979429948, disc_loss = 0.18840909376740456
Trained batch 190 in epoch 2, gen_loss = 0.36404137789266894, disc_loss = 0.18807885460360513
Trained batch 191 in epoch 2, gen_loss = 0.3642896297387779, disc_loss = 0.18753738324933997
Trained batch 192 in epoch 2, gen_loss = 0.3643694694486924, disc_loss = 0.1871227515098962
Trained batch 193 in epoch 2, gen_loss = 0.3642527470269154, disc_loss = 0.18710047786229664
Trained batch 194 in epoch 2, gen_loss = 0.3643677026797564, disc_loss = 0.18689724371219293
Trained batch 195 in epoch 2, gen_loss = 0.3642704651063802, disc_loss = 0.18729006616892863
Trained batch 196 in epoch 2, gen_loss = 0.36404442000510123, disc_loss = 0.18771811877259142
Trained batch 197 in epoch 2, gen_loss = 0.3638418059457432, disc_loss = 0.18761479278857057
Trained batch 198 in epoch 2, gen_loss = 0.3634618273632011, disc_loss = 0.18740323361889202
Trained batch 199 in epoch 2, gen_loss = 0.3633918648958206, disc_loss = 0.18716151375323534
Trained batch 200 in epoch 2, gen_loss = 0.36355756942312517, disc_loss = 0.1878661113369524
Trained batch 201 in epoch 2, gen_loss = 0.36349803887971555, disc_loss = 0.18827727499722255
Trained batch 202 in epoch 2, gen_loss = 0.3634082619192565, disc_loss = 0.18781638582204951
Trained batch 203 in epoch 2, gen_loss = 0.36362381513212244, disc_loss = 0.1874453502835012
Trained batch 204 in epoch 2, gen_loss = 0.3636734625188316, disc_loss = 0.18730412867011093
Trained batch 205 in epoch 2, gen_loss = 0.3640380171896185, disc_loss = 0.18703880949506482
Trained batch 206 in epoch 2, gen_loss = 0.3637043839491508, disc_loss = 0.18720625808849428
Trained batch 207 in epoch 2, gen_loss = 0.3639305695318259, disc_loss = 0.18779935931357053
Trained batch 208 in epoch 2, gen_loss = 0.36369621226091703, disc_loss = 0.18762247891802536
Trained batch 209 in epoch 2, gen_loss = 0.363976640360696, disc_loss = 0.18735159997429165
Trained batch 210 in epoch 2, gen_loss = 0.36422206101259347, disc_loss = 0.18770752112729855
Trained batch 211 in epoch 2, gen_loss = 0.3641548931317509, disc_loss = 0.18762444852376883
Trained batch 212 in epoch 2, gen_loss = 0.3643788044721308, disc_loss = 0.1874059646482199
Trained batch 213 in epoch 2, gen_loss = 0.36438022902078715, disc_loss = 0.1872998854128
Trained batch 214 in epoch 2, gen_loss = 0.3644873632941135, disc_loss = 0.1870788296987844
Trained batch 215 in epoch 2, gen_loss = 0.3644112308544141, disc_loss = 0.18682580593007583
Trained batch 216 in epoch 2, gen_loss = 0.3641386376822599, disc_loss = 0.18685470033900528
Trained batch 217 in epoch 2, gen_loss = 0.3640536313210059, disc_loss = 0.1867127511479439
Trained batch 218 in epoch 2, gen_loss = 0.3645559677250309, disc_loss = 0.1866121539786526
Trained batch 219 in epoch 2, gen_loss = 0.3648862318559126, disc_loss = 0.1861601061103019
Trained batch 220 in epoch 2, gen_loss = 0.36506298939566806, disc_loss = 0.18558018034265053
Trained batch 221 in epoch 2, gen_loss = 0.36503049597009884, disc_loss = 0.18525870241694622
Trained batch 222 in epoch 2, gen_loss = 0.3648616078188601, disc_loss = 0.18640638643984303
Trained batch 223 in epoch 2, gen_loss = 0.3651838345187051, disc_loss = 0.1866799943215613
Trained batch 224 in epoch 2, gen_loss = 0.3656592367755042, disc_loss = 0.18625086526075998
Trained batch 225 in epoch 2, gen_loss = 0.36510403447710305, disc_loss = 0.18691217971850285
Trained batch 226 in epoch 2, gen_loss = 0.3651187567590092, disc_loss = 0.1867767772616794
Trained batch 227 in epoch 2, gen_loss = 0.3653328208939025, disc_loss = 0.1869839752713839
Trained batch 228 in epoch 2, gen_loss = 0.36545562138984294, disc_loss = 0.1867235979659068
Trained batch 229 in epoch 2, gen_loss = 0.36546896352716113, disc_loss = 0.18650872798069665
Trained batch 230 in epoch 2, gen_loss = 0.3653215891742087, disc_loss = 0.1863130507789133
Trained batch 231 in epoch 2, gen_loss = 0.3654652228257779, disc_loss = 0.18605296718406267
Trained batch 232 in epoch 2, gen_loss = 0.3655326702180339, disc_loss = 0.18622031353829757
Trained batch 233 in epoch 2, gen_loss = 0.3657740627725919, disc_loss = 0.18574895779801232
Trained batch 234 in epoch 2, gen_loss = 0.36592720182652166, disc_loss = 0.18530404272865741
Trained batch 235 in epoch 2, gen_loss = 0.36620375697137947, disc_loss = 0.18555843498620947
Trained batch 236 in epoch 2, gen_loss = 0.36598206603828864, disc_loss = 0.1851264224210872
Trained batch 237 in epoch 2, gen_loss = 0.365874140390328, disc_loss = 0.1848439443699953
Trained batch 238 in epoch 2, gen_loss = 0.36592587710175056, disc_loss = 0.18447929006615443
Trained batch 239 in epoch 2, gen_loss = 0.36619607228785755, disc_loss = 0.183950630761683
Trained batch 240 in epoch 2, gen_loss = 0.36685618442865825, disc_loss = 0.18352434085488814
Trained batch 241 in epoch 2, gen_loss = 0.36712586762737637, disc_loss = 0.1831638868128465
Trained batch 242 in epoch 2, gen_loss = 0.36741196404023424, disc_loss = 0.18379030634223678
Trained batch 243 in epoch 2, gen_loss = 0.3671760592670714, disc_loss = 0.18417659130130634
Trained batch 244 in epoch 2, gen_loss = 0.3672233943428312, disc_loss = 0.18384257868236425
Trained batch 245 in epoch 2, gen_loss = 0.3672206605958745, disc_loss = 0.18367363588233304
Trained batch 246 in epoch 2, gen_loss = 0.367264117487529, disc_loss = 0.18352157598444324
Trained batch 247 in epoch 2, gen_loss = 0.36741924400050796, disc_loss = 0.18319540347663626
Trained batch 248 in epoch 2, gen_loss = 0.3677355476531638, disc_loss = 0.18293494656382794
Trained batch 249 in epoch 2, gen_loss = 0.3679952475428581, disc_loss = 0.18243267801404
Trained batch 250 in epoch 2, gen_loss = 0.36814057559843555, disc_loss = 0.18187776285101218
Trained batch 251 in epoch 2, gen_loss = 0.36821019572634545, disc_loss = 0.18134945166844224
Trained batch 252 in epoch 2, gen_loss = 0.36820951416322834, disc_loss = 0.1809631956836923
Trained batch 253 in epoch 2, gen_loss = 0.36826797645157716, disc_loss = 0.1811472432995875
Trained batch 254 in epoch 2, gen_loss = 0.36818377989179946, disc_loss = 0.18133065019752465
Trained batch 255 in epoch 2, gen_loss = 0.3682263913215138, disc_loss = 0.18120626572635956
Trained batch 256 in epoch 2, gen_loss = 0.3686872461542545, disc_loss = 0.18072369432344976
Trained batch 257 in epoch 2, gen_loss = 0.3684058365549228, disc_loss = 0.1805947094780299
Trained batch 258 in epoch 2, gen_loss = 0.36855925803709216, disc_loss = 0.18007806359168185
Trained batch 259 in epoch 2, gen_loss = 0.3686125612602784, disc_loss = 0.17978814131078813
Trained batch 260 in epoch 2, gen_loss = 0.3690783181067171, disc_loss = 0.17955371119453076
Trained batch 261 in epoch 2, gen_loss = 0.36897037565025664, disc_loss = 0.17906890378710422
Trained batch 262 in epoch 2, gen_loss = 0.3691815071572822, disc_loss = 0.1784667601815988
Trained batch 263 in epoch 2, gen_loss = 0.3692474018105052, disc_loss = 0.17793526364292836
Trained batch 264 in epoch 2, gen_loss = 0.3692589746893577, disc_loss = 0.17740112698443655
Trained batch 265 in epoch 2, gen_loss = 0.3691448297603686, disc_loss = 0.17685480807256654
Trained batch 266 in epoch 2, gen_loss = 0.3692107828480474, disc_loss = 0.1762642895154069
Trained batch 267 in epoch 2, gen_loss = 0.36932991773112495, disc_loss = 0.17588317565230735
Trained batch 268 in epoch 2, gen_loss = 0.36953806361965974, disc_loss = 0.17574884162239426
Trained batch 269 in epoch 2, gen_loss = 0.3697861866266639, disc_loss = 0.17529831201665932
Trained batch 270 in epoch 2, gen_loss = 0.36993707848431, disc_loss = 0.17494455308436907
Trained batch 271 in epoch 2, gen_loss = 0.3701649019494653, disc_loss = 0.17445334215538905
Trained batch 272 in epoch 2, gen_loss = 0.37065922346088914, disc_loss = 0.1740255870143354
Trained batch 273 in epoch 2, gen_loss = 0.37038809621203556, disc_loss = 0.1735103344340829
Trained batch 274 in epoch 2, gen_loss = 0.37045725470239466, disc_loss = 0.1730816257677295
Trained batch 275 in epoch 2, gen_loss = 0.37099451080396556, disc_loss = 0.17249778215435968
Trained batch 276 in epoch 2, gen_loss = 0.37086922753373636, disc_loss = 0.17205887433101125
Trained batch 277 in epoch 2, gen_loss = 0.37105236620568544, disc_loss = 0.1716360270226602
Trained batch 278 in epoch 2, gen_loss = 0.3710120554786429, disc_loss = 0.1712658636565704
Trained batch 279 in epoch 2, gen_loss = 0.37155861615070274, disc_loss = 0.17204303650983743
Trained batch 280 in epoch 2, gen_loss = 0.3715900551275851, disc_loss = 0.1722456271962339
Trained batch 281 in epoch 2, gen_loss = 0.3716632294210982, disc_loss = 0.17188009532525184
Trained batch 282 in epoch 2, gen_loss = 0.37163215596557925, disc_loss = 0.17138675558166874
Trained batch 283 in epoch 2, gen_loss = 0.37177466774280643, disc_loss = 0.17089304085296225
Trained batch 284 in epoch 2, gen_loss = 0.371736216074542, disc_loss = 0.17047238887140626
Trained batch 285 in epoch 2, gen_loss = 0.3719533840780492, disc_loss = 0.16996485945749115
Trained batch 286 in epoch 2, gen_loss = 0.371983169730532, disc_loss = 0.169993608800584
Trained batch 287 in epoch 2, gen_loss = 0.3719045815265013, disc_loss = 0.17096834301224184
Trained batch 288 in epoch 2, gen_loss = 0.3722648993392304, disc_loss = 0.17064638111005606
Trained batch 289 in epoch 2, gen_loss = 0.3721004902802665, disc_loss = 0.1705386704412
Trained batch 290 in epoch 2, gen_loss = 0.3719774231161039, disc_loss = 0.17077932094585446
Trained batch 291 in epoch 2, gen_loss = 0.371980710541957, disc_loss = 0.17040274819129542
Trained batch 292 in epoch 2, gen_loss = 0.37231802864082847, disc_loss = 0.17020497446936958
Trained batch 293 in epoch 2, gen_loss = 0.37203092756522754, disc_loss = 0.17019682214120213
Trained batch 294 in epoch 2, gen_loss = 0.3719883009033688, disc_loss = 0.16989394331635055
Trained batch 295 in epoch 2, gen_loss = 0.3721741561249301, disc_loss = 0.16950850992941777
Trained batch 296 in epoch 2, gen_loss = 0.37229749876441376, disc_loss = 0.1691154082014103
Trained batch 297 in epoch 2, gen_loss = 0.3721132619968997, disc_loss = 0.16880119631954488
Trained batch 298 in epoch 2, gen_loss = 0.3719413967734595, disc_loss = 0.16843845654141942
Trained batch 299 in epoch 2, gen_loss = 0.37219645246863364, disc_loss = 0.16863429055859644
Trained batch 300 in epoch 2, gen_loss = 0.37207557736243124, disc_loss = 0.1685258970035865
Trained batch 301 in epoch 2, gen_loss = 0.37196214965834523, disc_loss = 0.16810148020601826
Trained batch 302 in epoch 2, gen_loss = 0.37193510728110574, disc_loss = 0.1676956811557115
Trained batch 303 in epoch 2, gen_loss = 0.3721320793326748, disc_loss = 0.16724044922739267
Trained batch 304 in epoch 2, gen_loss = 0.37197275020059994, disc_loss = 0.1670800556413463
Trained batch 305 in epoch 2, gen_loss = 0.3721759694756246, disc_loss = 0.1670292448861147
Trained batch 306 in epoch 2, gen_loss = 0.37204259172907095, disc_loss = 0.16675253639586196
Trained batch 307 in epoch 2, gen_loss = 0.37221222578898655, disc_loss = 0.166358384352129
Trained batch 308 in epoch 2, gen_loss = 0.3721958989560797, disc_loss = 0.16608521512266503
Trained batch 309 in epoch 2, gen_loss = 0.37242364474842626, disc_loss = 0.16585652264616182
Trained batch 310 in epoch 2, gen_loss = 0.3723664673290835, disc_loss = 0.16550871369300166
Trained batch 311 in epoch 2, gen_loss = 0.3725593052326869, disc_loss = 0.1650852530191724
Trained batch 312 in epoch 2, gen_loss = 0.37288667252078983, disc_loss = 0.16466260666902455
Trained batch 313 in epoch 2, gen_loss = 0.372982494533062, disc_loss = 0.16426129219163754
Trained batch 314 in epoch 2, gen_loss = 0.37302326507984646, disc_loss = 0.16390917001972122
Trained batch 315 in epoch 2, gen_loss = 0.3729694785102259, disc_loss = 0.1635080613431674
Trained batch 316 in epoch 2, gen_loss = 0.37292336096710965, disc_loss = 0.16308710161796316
Trained batch 317 in epoch 2, gen_loss = 0.37282075601741205, disc_loss = 0.16270848155701123
Trained batch 318 in epoch 2, gen_loss = 0.3732327615672892, disc_loss = 0.16302315169670925
Trained batch 319 in epoch 2, gen_loss = 0.3732383218128234, disc_loss = 0.16339264235575685
Trained batch 320 in epoch 2, gen_loss = 0.3734189014289981, disc_loss = 0.16292761474546058
Trained batch 321 in epoch 2, gen_loss = 0.37365626978763145, disc_loss = 0.16271326604721523
Trained batch 322 in epoch 2, gen_loss = 0.37346248550127165, disc_loss = 0.16262257234669136
Trained batch 323 in epoch 2, gen_loss = 0.3735427198310693, disc_loss = 0.16237985326069188
Trained batch 324 in epoch 2, gen_loss = 0.373474360200075, disc_loss = 0.16210035564234623
Trained batch 325 in epoch 2, gen_loss = 0.37339344058482926, disc_loss = 0.16177747242632637
Trained batch 326 in epoch 2, gen_loss = 0.37364380061626434, disc_loss = 0.16154240681832538
Trained batch 327 in epoch 2, gen_loss = 0.3739831410802719, disc_loss = 0.16111456622119721
Trained batch 328 in epoch 2, gen_loss = 0.37398607204569145, disc_loss = 0.16067521138212965
Trained batch 329 in epoch 2, gen_loss = 0.37401354452877333, disc_loss = 0.1602206853923924
Trained batch 330 in epoch 2, gen_loss = 0.37412860913038976, disc_loss = 0.15976686612773247
Trained batch 331 in epoch 2, gen_loss = 0.37420663116387576, disc_loss = 0.1593306838080332
Trained batch 332 in epoch 2, gen_loss = 0.37446542424303636, disc_loss = 0.15894183062587505
Trained batch 333 in epoch 2, gen_loss = 0.37463513485150424, disc_loss = 0.15849262635463368
Trained batch 334 in epoch 2, gen_loss = 0.3748413287436784, disc_loss = 0.15807416651453546
Trained batch 335 in epoch 2, gen_loss = 0.37491057808732703, disc_loss = 0.15819910185278527
Trained batch 336 in epoch 2, gen_loss = 0.37546135211026277, disc_loss = 0.15827339506246568
Trained batch 337 in epoch 2, gen_loss = 0.375295068870282, disc_loss = 0.15811990209188334
Trained batch 338 in epoch 2, gen_loss = 0.3753753927341253, disc_loss = 0.1578548654672143
Trained batch 339 in epoch 2, gen_loss = 0.3754875954897965, disc_loss = 0.15768154168172793
Trained batch 340 in epoch 2, gen_loss = 0.3757858350217517, disc_loss = 0.15742137911251564
Trained batch 341 in epoch 2, gen_loss = 0.37595135779582967, disc_loss = 0.15706945682347517
Trained batch 342 in epoch 2, gen_loss = 0.37617344771981587, disc_loss = 0.15679618699948572
Trained batch 343 in epoch 2, gen_loss = 0.3764270230867835, disc_loss = 0.15672814855785216
Trained batch 344 in epoch 2, gen_loss = 0.37648641721925874, disc_loss = 0.1563535187015499
Trained batch 345 in epoch 2, gen_loss = 0.37645323018979476, disc_loss = 0.15594294304674158
Trained batch 346 in epoch 2, gen_loss = 0.3766814310973247, disc_loss = 0.1555192945605568
Trained batch 347 in epoch 2, gen_loss = 0.3768548991573953, disc_loss = 0.15509636838246008
Trained batch 348 in epoch 2, gen_loss = 0.3768911186210747, disc_loss = 0.15466555594106374
Trained batch 349 in epoch 2, gen_loss = 0.3770045874374253, disc_loss = 0.1542431914806366
Trained batch 350 in epoch 2, gen_loss = 0.37684154438327183, disc_loss = 0.15385122721393904
Trained batch 351 in epoch 2, gen_loss = 0.376855362333696, disc_loss = 0.1534312341563319
Trained batch 352 in epoch 2, gen_loss = 0.3772230703415344, disc_loss = 0.15302605471618622
Trained batch 353 in epoch 2, gen_loss = 0.37724151066635964, disc_loss = 0.1526275085085361
Trained batch 354 in epoch 2, gen_loss = 0.3770993648700311, disc_loss = 0.15242579099787792
Trained batch 355 in epoch 2, gen_loss = 0.3774761043154122, disc_loss = 0.15226062687553382
Trained batch 356 in epoch 2, gen_loss = 0.37754715803791494, disc_loss = 0.15199729250300498
Trained batch 357 in epoch 2, gen_loss = 0.3775248368941872, disc_loss = 0.1521175458465375
Trained batch 358 in epoch 2, gen_loss = 0.3777549010714449, disc_loss = 0.15189242438727102
Trained batch 359 in epoch 2, gen_loss = 0.3778315213405424, disc_loss = 0.1517685267970794
Trained batch 360 in epoch 2, gen_loss = 0.37771862196294886, disc_loss = 0.15150134371712268
Trained batch 361 in epoch 2, gen_loss = 0.37784794413417744, disc_loss = 0.1512478454172282
Trained batch 362 in epoch 2, gen_loss = 0.3778232359442829, disc_loss = 0.15126528814640255
Trained batch 363 in epoch 2, gen_loss = 0.3779761148104956, disc_loss = 0.15162040223623371
Trained batch 364 in epoch 2, gen_loss = 0.37791268437692566, disc_loss = 0.1518457879758861
Trained batch 365 in epoch 2, gen_loss = 0.3780081796108699, disc_loss = 0.1516905595126048
Trained batch 366 in epoch 2, gen_loss = 0.37802524523611614, disc_loss = 0.15160614101860764
Trained batch 367 in epoch 2, gen_loss = 0.3782196451059502, disc_loss = 0.15154912383498056
Trained batch 368 in epoch 2, gen_loss = 0.3783135731934209, disc_loss = 0.1513750906478422
Trained batch 369 in epoch 2, gen_loss = 0.37874517468987284, disc_loss = 0.15172218724682524
Trained batch 370 in epoch 2, gen_loss = 0.3786348974046039, disc_loss = 0.15156863914988433
Trained batch 371 in epoch 2, gen_loss = 0.37854693529586636, disc_loss = 0.1514419969772139
Trained batch 372 in epoch 2, gen_loss = 0.3784016716336437, disc_loss = 0.15143209923528156
Trained batch 373 in epoch 2, gen_loss = 0.3784068472643587, disc_loss = 0.15142659054082983
Trained batch 374 in epoch 2, gen_loss = 0.37854575741291047, disc_loss = 0.15123770914475124
Trained batch 375 in epoch 2, gen_loss = 0.3785597722026262, disc_loss = 0.15094612223750098
Trained batch 376 in epoch 2, gen_loss = 0.3784086934688553, disc_loss = 0.1507477928298854
Trained batch 377 in epoch 2, gen_loss = 0.37874940569911686, disc_loss = 0.15050595664670544
Trained batch 378 in epoch 2, gen_loss = 0.37863388354828614, disc_loss = 0.15023864751637453
Trained batch 379 in epoch 2, gen_loss = 0.3789387247672206, disc_loss = 0.1500566498719548
Trained batch 380 in epoch 2, gen_loss = 0.37922204585056607, disc_loss = 0.14969047582573855
Trained batch 381 in epoch 2, gen_loss = 0.3792892997567566, disc_loss = 0.14944837303071512
Trained batch 382 in epoch 2, gen_loss = 0.3790047590866413, disc_loss = 0.15013978883439272
Trained batch 383 in epoch 2, gen_loss = 0.37919909378979355, disc_loss = 0.1499604780522835
Trained batch 384 in epoch 2, gen_loss = 0.37930555277830597, disc_loss = 0.1496355927730729
Trained batch 385 in epoch 2, gen_loss = 0.37927529327764414, disc_loss = 0.1495013017463136
Trained batch 386 in epoch 2, gen_loss = 0.3795566466042546, disc_loss = 0.1493038981503179
Trained batch 387 in epoch 2, gen_loss = 0.37962303514179496, disc_loss = 0.14900732988290027
Trained batch 388 in epoch 2, gen_loss = 0.3795448829321751, disc_loss = 0.1489494854660949
Trained batch 389 in epoch 2, gen_loss = 0.37954920304891393, disc_loss = 0.1491193719709722
Trained batch 390 in epoch 2, gen_loss = 0.3795271912575378, disc_loss = 0.14902827085788978
Trained batch 391 in epoch 2, gen_loss = 0.3795620820732141, disc_loss = 0.14888564228526868
Trained batch 392 in epoch 2, gen_loss = 0.37958407572662556, disc_loss = 0.14874440819527432
Trained batch 393 in epoch 2, gen_loss = 0.3798378319834089, disc_loss = 0.148801839756803
Trained batch 394 in epoch 2, gen_loss = 0.3799793536527247, disc_loss = 0.14888195389103664
Trained batch 395 in epoch 2, gen_loss = 0.38006815047125625, disc_loss = 0.14862538863095748
Trained batch 396 in epoch 2, gen_loss = 0.3801636162497835, disc_loss = 0.148509031112402
Trained batch 397 in epoch 2, gen_loss = 0.38010706160985047, disc_loss = 0.14830361447301715
Trained batch 398 in epoch 2, gen_loss = 0.3802747758184758, disc_loss = 0.1483865377136079
Trained batch 399 in epoch 2, gen_loss = 0.38042433399707076, disc_loss = 0.14828199574956671
Trained batch 400 in epoch 2, gen_loss = 0.38060507137430577, disc_loss = 0.14806144156184353
Trained batch 401 in epoch 2, gen_loss = 0.38056282613852727, disc_loss = 0.1479671821299366
Trained batch 402 in epoch 2, gen_loss = 0.38063052463028624, disc_loss = 0.14777179538658253
Trained batch 403 in epoch 2, gen_loss = 0.3808205776506721, disc_loss = 0.14747047312972644
Trained batch 404 in epoch 2, gen_loss = 0.38066877432075547, disc_loss = 0.14756985765962322
Trained batch 405 in epoch 2, gen_loss = 0.3809332630684223, disc_loss = 0.1474734670207308
Trained batch 406 in epoch 2, gen_loss = 0.3811296930111011, disc_loss = 0.14723340895356432
Trained batch 407 in epoch 2, gen_loss = 0.38099816386752267, disc_loss = 0.14710398366464777
Trained batch 408 in epoch 2, gen_loss = 0.3809779660553104, disc_loss = 0.14691445777251916
Trained batch 409 in epoch 2, gen_loss = 0.38102826298010056, disc_loss = 0.14664332124563614
Trained batch 410 in epoch 2, gen_loss = 0.3810173973187333, disc_loss = 0.14637849033286754
Trained batch 411 in epoch 2, gen_loss = 0.3811604710096873, disc_loss = 0.14608628171478008
Trained batch 412 in epoch 2, gen_loss = 0.3811525071432169, disc_loss = 0.14577247518324463
Trained batch 413 in epoch 2, gen_loss = 0.3814797062732747, disc_loss = 0.14545417274235958
Trained batch 414 in epoch 2, gen_loss = 0.3815064085176192, disc_loss = 0.14522173099937927
Trained batch 415 in epoch 2, gen_loss = 0.3814100415016023, disc_loss = 0.14505406071951327
Trained batch 416 in epoch 2, gen_loss = 0.3814089677388148, disc_loss = 0.144754177464141
Trained batch 417 in epoch 2, gen_loss = 0.3814192513743656, disc_loss = 0.14445134393122208
Trained batch 418 in epoch 2, gen_loss = 0.3816884513899933, disc_loss = 0.14413719389338694
Trained batch 419 in epoch 2, gen_loss = 0.38171442942250344, disc_loss = 0.14404391330400748
Trained batch 420 in epoch 2, gen_loss = 0.3817097705715909, disc_loss = 0.14381032462526033
Trained batch 421 in epoch 2, gen_loss = 0.38158723503633696, disc_loss = 0.1437799704826097
Trained batch 422 in epoch 2, gen_loss = 0.3816487979733916, disc_loss = 0.14367376640218862
Trained batch 423 in epoch 2, gen_loss = 0.38184421309182104, disc_loss = 0.1433590843807906
Trained batch 424 in epoch 2, gen_loss = 0.3818820714599946, disc_loss = 0.14310898160671487
Trained batch 425 in epoch 2, gen_loss = 0.3818542279058219, disc_loss = 0.14288262721640824
Trained batch 426 in epoch 2, gen_loss = 0.3820308475150995, disc_loss = 0.14258423525255515
Trained batch 427 in epoch 2, gen_loss = 0.3822883416628726, disc_loss = 0.1422940889486573
Trained batch 428 in epoch 2, gen_loss = 0.38225170000866576, disc_loss = 0.14198041824181076
Trained batch 429 in epoch 2, gen_loss = 0.38217712727396985, disc_loss = 0.14169099447100836
Trained batch 430 in epoch 2, gen_loss = 0.3822512842732073, disc_loss = 0.14139821907297953
Trained batch 431 in epoch 2, gen_loss = 0.3823016000635646, disc_loss = 0.14112864242526013
Trained batch 432 in epoch 2, gen_loss = 0.38229528726799106, disc_loss = 0.14094215333913443
Trained batch 433 in epoch 2, gen_loss = 0.3826792723915544, disc_loss = 0.14091823863032948
Trained batch 434 in epoch 2, gen_loss = 0.3826878685718295, disc_loss = 0.14094710786901843
Trained batch 435 in epoch 2, gen_loss = 0.38289713172600903, disc_loss = 0.14071013165078203
Trained batch 436 in epoch 2, gen_loss = 0.38318917513302864, disc_loss = 0.14043608562833282
Trained batch 437 in epoch 2, gen_loss = 0.38309484260947735, disc_loss = 0.14028456311388002
Trained batch 438 in epoch 2, gen_loss = 0.3832964818067594, disc_loss = 0.1400721045157921
Trained batch 439 in epoch 2, gen_loss = 0.3832906188951297, disc_loss = 0.13983873342354358
Trained batch 440 in epoch 2, gen_loss = 0.38356293352688253, disc_loss = 0.13957995684530222
Trained batch 441 in epoch 2, gen_loss = 0.38368401170720884, disc_loss = 0.13930798594721874
Trained batch 442 in epoch 2, gen_loss = 0.3837268676432207, disc_loss = 0.13905472014179246
Trained batch 443 in epoch 2, gen_loss = 0.3836054129039382, disc_loss = 0.1388513547387226
Trained batch 444 in epoch 2, gen_loss = 0.3836500050981393, disc_loss = 0.13858042258162345
Trained batch 445 in epoch 2, gen_loss = 0.38370616416626446, disc_loss = 0.13829633945311032
Trained batch 446 in epoch 2, gen_loss = 0.383867245092488, disc_loss = 0.1380198966738845
Trained batch 447 in epoch 2, gen_loss = 0.38404215682697085, disc_loss = 0.13785812755668303
Trained batch 448 in epoch 2, gen_loss = 0.383894259089351, disc_loss = 0.1380275649657444
Trained batch 449 in epoch 2, gen_loss = 0.38410432792372173, disc_loss = 0.1380253465111471
Trained batch 450 in epoch 2, gen_loss = 0.38406171083053836, disc_loss = 0.13775837953468814
Trained batch 451 in epoch 2, gen_loss = 0.38402457545157026, disc_loss = 0.13769514311570674
Trained batch 452 in epoch 2, gen_loss = 0.3841672835431615, disc_loss = 0.13747677013841325
Trained batch 453 in epoch 2, gen_loss = 0.3842810537780959, disc_loss = 0.13727032669844508
Trained batch 454 in epoch 2, gen_loss = 0.3842695495257011, disc_loss = 0.1373091005454106
Trained batch 455 in epoch 2, gen_loss = 0.3844396091278708, disc_loss = 0.1371251200581084
Trained batch 456 in epoch 2, gen_loss = 0.3845064873181495, disc_loss = 0.136869309287665
Trained batch 457 in epoch 2, gen_loss = 0.3846731706803022, disc_loss = 0.13698505868171404
Trained batch 458 in epoch 2, gen_loss = 0.3849311154457479, disc_loss = 0.13775118900674005
Testing Epoch 2
  0%|          | 0/25 [00:00<?, ?it/s]
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 13:19:34,997
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 13:19:35,280

Training Epoch 3
Trained batch 0 in epoch 3, gen_loss = 0.3060230314731598, disc_loss = 0.10973473638296127
Trained batch 1 in epoch 3, gen_loss = 0.35803787410259247, disc_loss = 0.11749491468071938
Trained batch 2 in epoch 3, gen_loss = 0.3778184950351715, disc_loss = 0.10899734993775685
Trained batch 3 in epoch 3, gen_loss = 0.38684385269880295, disc_loss = 0.13080358505249023
Trained batch 4 in epoch 3, gen_loss = 0.3823798596858978, disc_loss = 0.11754876971244813
Trained batch 5 in epoch 3, gen_loss = 0.3831881235043208, disc_loss = 0.10797464847564697
Trained batch 6 in epoch 3, gen_loss = 0.38727045910699026, disc_loss = 0.11263589348111834
Trained batch 7 in epoch 3, gen_loss = 0.388895932585001, disc_loss = 0.10890813358128071
Trained batch 8 in epoch 3, gen_loss = 0.38295260734028286, disc_loss = 0.1042412453227573
Trained batch 9 in epoch 3, gen_loss = 0.38731366991996763, disc_loss = 0.09931880235671997
Trained batch 10 in epoch 3, gen_loss = 0.38752650672739203, disc_loss = 0.09239762564274398
Trained batch 11 in epoch 3, gen_loss = 0.39512965083122253, disc_loss = 0.08590497146360576
Trained batch 12 in epoch 3, gen_loss = 0.39674888207362247, disc_loss = 0.08207876786876184
Trained batch 13 in epoch 3, gen_loss = 0.3927507059914725, disc_loss = 0.09557350971070784
Trained batch 14 in epoch 3, gen_loss = 0.39452201724052427, disc_loss = 0.10818860661238432
Trained batch 15 in epoch 3, gen_loss = 0.39974107034504414, disc_loss = 0.1072553054546006
Trained batch 16 in epoch 3, gen_loss = 0.39872812523561363, disc_loss = 0.10462193349924158
Trained batch 17 in epoch 3, gen_loss = 0.40163060691621566, disc_loss = 0.09956183600135976
Trained batch 18 in epoch 3, gen_loss = 0.40296970856817144, disc_loss = 0.09502151637877289
Trained batch 19 in epoch 3, gen_loss = 0.403907784819603, disc_loss = 0.09093412403017283
Trained batch 20 in epoch 3, gen_loss = 0.3992340380237216, disc_loss = 0.08992453043659528
Trained batch 21 in epoch 3, gen_loss = 0.3961911973628131, disc_loss = 0.08901781944388693
Trained batch 22 in epoch 3, gen_loss = 0.39794123950211896, disc_loss = 0.08882708539781363
Trained batch 23 in epoch 3, gen_loss = 0.39459140226244926, disc_loss = 0.09805535168076555
Trained batch 24 in epoch 3, gen_loss = 0.39421785712242124, disc_loss = 0.09774806037545204
Trained batch 25 in epoch 3, gen_loss = 0.3941020163205954, disc_loss = 0.09913622086437848
Trained batch 26 in epoch 3, gen_loss = 0.3923763621736456, disc_loss = 0.09815166600876385
Trained batch 27 in epoch 3, gen_loss = 0.39044381571667536, disc_loss = 0.09785095961498362
Trained batch 28 in epoch 3, gen_loss = 0.38915171397143394, disc_loss = 0.0968903296723448
Trained batch 29 in epoch 3, gen_loss = 0.3919074257214864, disc_loss = 0.09404298060884078
Trained batch 30 in epoch 3, gen_loss = 0.3961569359225611, disc_loss = 0.09211465085466061
Trained batch 31 in epoch 3, gen_loss = 0.39517905563116074, disc_loss = 0.09262617368949577
Trained batch 32 in epoch 3, gen_loss = 0.3978802733349078, disc_loss = 0.09242471076096549
Trained batch 33 in epoch 3, gen_loss = 0.3987133222467759, disc_loss = 0.09142463648801341
Trained batch 34 in epoch 3, gen_loss = 0.3977613704545157, disc_loss = 0.09188101754656859
Trained batch 35 in epoch 3, gen_loss = 0.3985486701130867, disc_loss = 0.09082298120483756
Trained batch 36 in epoch 3, gen_loss = 0.39851627478728424, disc_loss = 0.08932985461040123
Trained batch 37 in epoch 3, gen_loss = 0.40166657221944707, disc_loss = 0.08865280464095504
Trained batch 38 in epoch 3, gen_loss = 0.40194204984567106, disc_loss = 0.08685385717604405
Trained batch 39 in epoch 3, gen_loss = 0.4032902680337429, disc_loss = 0.08493138996418566
Trained batch 40 in epoch 3, gen_loss = 0.40580179705852415, disc_loss = 0.08325422125891214
Trained batch 41 in epoch 3, gen_loss = 0.4057796271074386, disc_loss = 0.08149749539526445
Trained batch 42 in epoch 3, gen_loss = 0.40514657109282737, disc_loss = 0.0799598308756601
Trained batch 43 in epoch 3, gen_loss = 0.40651552785526623, disc_loss = 0.07843746699985456
Trained batch 44 in epoch 3, gen_loss = 0.4060912913746304, disc_loss = 0.07750908821407292
Trained batch 45 in epoch 3, gen_loss = 0.40446961314781854, disc_loss = 0.0774883536176513
Trained batch 46 in epoch 3, gen_loss = 0.4072768320428564, disc_loss = 0.0769709515722191
Trained batch 47 in epoch 3, gen_loss = 0.40721594107647735, disc_loss = 0.0756740047945641
Trained batch 48 in epoch 3, gen_loss = 0.40732195608469907, disc_loss = 0.07454242467956275
Trained batch 49 in epoch 3, gen_loss = 0.4075539326667786, disc_loss = 0.0733414500951767
Trained batch 50 in epoch 3, gen_loss = 0.4083290690300511, disc_loss = 0.07291520036318723
Trained batch 51 in epoch 3, gen_loss = 0.4082218918662805, disc_loss = 0.07455401566739266
Trained batch 52 in epoch 3, gen_loss = 0.4084050492295679, disc_loss = 0.07609071076478598
Trained batch 53 in epoch 3, gen_loss = 0.40812954472170937, disc_loss = 0.07606609220857974
Trained batch 54 in epoch 3, gen_loss = 0.4076888658783653, disc_loss = 0.07636362707073038
Trained batch 55 in epoch 3, gen_loss = 0.4081451254231589, disc_loss = 0.07700127961912326
Trained batch 56 in epoch 3, gen_loss = 0.4079341449235615, disc_loss = 0.07627334779030398
Trained batch 57 in epoch 3, gen_loss = 0.40734378325528114, disc_loss = 0.07568711119479146
Trained batch 58 in epoch 3, gen_loss = 0.40669632665181565, disc_loss = 0.07466369229605642
Trained batch 59 in epoch 3, gen_loss = 0.4080510293443998, disc_loss = 0.07421430703252554
Trained batch 60 in epoch 3, gen_loss = 0.40878821298724316, disc_loss = 0.07326337261522403
Trained batch 61 in epoch 3, gen_loss = 0.4081806968296728, disc_loss = 0.07383895106613636
Trained batch 62 in epoch 3, gen_loss = 0.4114271340862153, disc_loss = 0.07573945743460504
Trained batch 63 in epoch 3, gen_loss = 0.4111374099738896, disc_loss = 0.07494822578155436
Trained batch 64 in epoch 3, gen_loss = 0.4099145077742063, disc_loss = 0.07729847445510901
Trained batch 65 in epoch 3, gen_loss = 0.4110270770210208, disc_loss = 0.07989475461231037
Trained batch 66 in epoch 3, gen_loss = 0.4104215951997842, disc_loss = 0.08022507116087337
Trained batch 67 in epoch 3, gen_loss = 0.4101528534117867, disc_loss = 0.08135326056028991
Trained batch 68 in epoch 3, gen_loss = 0.40936392113782355, disc_loss = 0.08209620764398057
Trained batch 69 in epoch 3, gen_loss = 0.41048712602683474, disc_loss = 0.08132271859794855
Trained batch 70 in epoch 3, gen_loss = 0.4112192434324345, disc_loss = 0.08064944273464277
Trained batch 71 in epoch 3, gen_loss = 0.41150011080834603, disc_loss = 0.0796388003250791
Trained batch 72 in epoch 3, gen_loss = 0.411376173365606, disc_loss = 0.07901115894113502
Trained batch 73 in epoch 3, gen_loss = 0.4108759221192953, disc_loss = 0.07924066700444028
Trained batch 74 in epoch 3, gen_loss = 0.41161320368448895, disc_loss = 0.08037314588824908
Trained batch 75 in epoch 3, gen_loss = 0.411396313654749, disc_loss = 0.08007072922038405
Trained batch 76 in epoch 3, gen_loss = 0.409960043507737, disc_loss = 0.08029637524446884
Trained batch 77 in epoch 3, gen_loss = 0.4088876270330869, disc_loss = 0.08046369875470798
Trained batch 78 in epoch 3, gen_loss = 0.40949140092994596, disc_loss = 0.07982585150041158
Trained batch 79 in epoch 3, gen_loss = 0.40975314378738403, disc_loss = 0.07904845904558896
Trained batch 80 in epoch 3, gen_loss = 0.409010249523469, disc_loss = 0.07953596391059735
Trained batch 81 in epoch 3, gen_loss = 0.408751302739469, disc_loss = 0.08578673931883603
Trained batch 82 in epoch 3, gen_loss = 0.40825947293316023, disc_loss = 0.08668110025934427
Trained batch 83 in epoch 3, gen_loss = 0.4084240045575869, disc_loss = 0.08710744418203831
Trained batch 84 in epoch 3, gen_loss = 0.40776746588594776, disc_loss = 0.08771262370488223
Trained batch 85 in epoch 3, gen_loss = 0.4066443041313526, disc_loss = 0.08822443864719812
Trained batch 86 in epoch 3, gen_loss = 0.40709601668105727, disc_loss = 0.08832002807965224
Trained batch 87 in epoch 3, gen_loss = 0.40714302455837076, disc_loss = 0.08782637521455233
Trained batch 88 in epoch 3, gen_loss = 0.40751981802201004, disc_loss = 0.08771898409121492
Trained batch 89 in epoch 3, gen_loss = 0.4073036359416114, disc_loss = 0.08830649740993976
Trained batch 90 in epoch 3, gen_loss = 0.4075431974379571, disc_loss = 0.08764221879479649
Trained batch 91 in epoch 3, gen_loss = 0.40720338018044183, disc_loss = 0.08699582820839208
Trained batch 92 in epoch 3, gen_loss = 0.4070820471932811, disc_loss = 0.0864282925362869
Trained batch 93 in epoch 3, gen_loss = 0.4076729473915506, disc_loss = 0.08592173881194692
Trained batch 94 in epoch 3, gen_loss = 0.4071657808203446, disc_loss = 0.08528692702713765
Trained batch 95 in epoch 3, gen_loss = 0.40751523803919554, disc_loss = 0.08501311073390146
Trained batch 96 in epoch 3, gen_loss = 0.40737684147874104, disc_loss = 0.08429380159671467
Trained batch 97 in epoch 3, gen_loss = 0.40721643518428413, disc_loss = 0.08354809482068735
Trained batch 98 in epoch 3, gen_loss = 0.4075744389885604, disc_loss = 0.08276563366367058
Trained batch 99 in epoch 3, gen_loss = 0.4073968631029129, disc_loss = 0.08234378992579877
Trained batch 100 in epoch 3, gen_loss = 0.4068413182060317, disc_loss = 0.08289840373920628
Trained batch 101 in epoch 3, gen_loss = 0.40661026216020774, disc_loss = 0.08262310417222918
Trained batch 102 in epoch 3, gen_loss = 0.408043055279741, disc_loss = 0.0820428721733319
Trained batch 103 in epoch 3, gen_loss = 0.40819493795816714, disc_loss = 0.081335806610206
Trained batch 104 in epoch 3, gen_loss = 0.4086175881680988, disc_loss = 0.08065240935732922
Trained batch 105 in epoch 3, gen_loss = 0.40836497044788217, disc_loss = 0.08108999593323975
Trained batch 106 in epoch 3, gen_loss = 0.40958942069071475, disc_loss = 0.0817509328284971
Trained batch 107 in epoch 3, gen_loss = 0.40913383607511167, disc_loss = 0.08116613313797172
Trained batch 108 in epoch 3, gen_loss = 0.40836928470419087, disc_loss = 0.08200300190119295
Trained batch 109 in epoch 3, gen_loss = 0.40860842032866046, disc_loss = 0.0814053983766247
Trained batch 110 in epoch 3, gen_loss = 0.4097163559080244, disc_loss = 0.08117728209676775
Trained batch 111 in epoch 3, gen_loss = 0.4100228279296841, disc_loss = 0.0805501444847323
Trained batch 112 in epoch 3, gen_loss = 0.4089047188779949, disc_loss = 0.08043268045196228
Trained batch 113 in epoch 3, gen_loss = 0.4080237231233664, disc_loss = 0.08124906268264902
Trained batch 114 in epoch 3, gen_loss = 0.40871195274850597, disc_loss = 0.08121949290937704
Trained batch 115 in epoch 3, gen_loss = 0.40860521844748793, disc_loss = 0.08121886977058804
Trained batch 116 in epoch 3, gen_loss = 0.40818345775971043, disc_loss = 0.08089770777071388
Trained batch 117 in epoch 3, gen_loss = 0.408372630507259, disc_loss = 0.08039182070169155
Trained batch 118 in epoch 3, gen_loss = 0.4084781353213206, disc_loss = 0.07981340830535197
Trained batch 119 in epoch 3, gen_loss = 0.4083419591188431, disc_loss = 0.07928306074657789
Trained batch 120 in epoch 3, gen_loss = 0.40817478077470765, disc_loss = 0.07875555384257608
Trained batch 121 in epoch 3, gen_loss = 0.40779176354408264, disc_loss = 0.07841560668999055
Trained batch 122 in epoch 3, gen_loss = 0.4086026699562383, disc_loss = 0.07790215560272942
Trained batch 123 in epoch 3, gen_loss = 0.4092040821429222, disc_loss = 0.07736789305964785
Trained batch 124 in epoch 3, gen_loss = 0.4092091190814972, disc_loss = 0.0768540817797184
Trained batch 125 in epoch 3, gen_loss = 0.40920056213462164, disc_loss = 0.0763236216624223
Trained batch 126 in epoch 3, gen_loss = 0.40949530981657073, disc_loss = 0.07583589047398859
Trained batch 127 in epoch 3, gen_loss = 0.40907048946246505, disc_loss = 0.07532637647818774
Trained batch 128 in epoch 3, gen_loss = 0.40898446773373803, disc_loss = 0.07478756012842637
Trained batch 129 in epoch 3, gen_loss = 0.40903898638028363, disc_loss = 0.07429639275830525
Trained batch 130 in epoch 3, gen_loss = 0.409577141053804, disc_loss = 0.0737671875465974
Trained batch 131 in epoch 3, gen_loss = 0.4100640612569722, disc_loss = 0.0732383216681862
Trained batch 132 in epoch 3, gen_loss = 0.41033461286609335, disc_loss = 0.07278691441927077
Trained batch 133 in epoch 3, gen_loss = 0.41042217478823306, disc_loss = 0.0722836644784895
Trained batch 134 in epoch 3, gen_loss = 0.41111210187276204, disc_loss = 0.07182437319791428
Trained batch 135 in epoch 3, gen_loss = 0.4113815637195812, disc_loss = 0.07132669598863953
Trained batch 136 in epoch 3, gen_loss = 0.41189567951390343, disc_loss = 0.07083999283312664
Trained batch 137 in epoch 3, gen_loss = 0.4121389877105105, disc_loss = 0.07038688848631969
Trained batch 138 in epoch 3, gen_loss = 0.4116748715047356, disc_loss = 0.06992881621817033
Trained batch 139 in epoch 3, gen_loss = 0.41222430020570755, disc_loss = 0.06947759791676487
Trained batch 140 in epoch 3, gen_loss = 0.4120033444665002, disc_loss = 0.06903205894541445
Trained batch 141 in epoch 3, gen_loss = 0.4121210577202515, disc_loss = 0.06859149829104123
Trained batch 142 in epoch 3, gen_loss = 0.41212874338343425, disc_loss = 0.06814986471920371
Trained batch 143 in epoch 3, gen_loss = 0.4123291131108999, disc_loss = 0.06771977662962551
Trained batch 144 in epoch 3, gen_loss = 0.41232393219553193, disc_loss = 0.06730763992487357
Trained batch 145 in epoch 3, gen_loss = 0.41245390433971196, disc_loss = 0.06688107845807219
Trained batch 146 in epoch 3, gen_loss = 0.4117880688638103, disc_loss = 0.06654942952742686
Trained batch 147 in epoch 3, gen_loss = 0.41180223025180196, disc_loss = 0.0661340511334758
Trained batch 148 in epoch 3, gen_loss = 0.41204738116904394, disc_loss = 0.06572583928116715
Trained batch 149 in epoch 3, gen_loss = 0.41208074311415355, disc_loss = 0.0653203597633789
Trained batch 150 in epoch 3, gen_loss = 0.41173862187278193, disc_loss = 0.06492501910812906
Trained batch 151 in epoch 3, gen_loss = 0.411990387267188, disc_loss = 0.06453737700480576
Trained batch 152 in epoch 3, gen_loss = 0.41185615927565333, disc_loss = 0.06413988010604786
Trained batch 153 in epoch 3, gen_loss = 0.4118437378050445, disc_loss = 0.06376215286988329
Trained batch 154 in epoch 3, gen_loss = 0.4123554418163915, disc_loss = 0.06339024478990224
Trained batch 155 in epoch 3, gen_loss = 0.41228625923395157, disc_loss = 0.06309424079835224
Trained batch 156 in epoch 3, gen_loss = 0.412446314362204, disc_loss = 0.06277552213828275
Trained batch 157 in epoch 3, gen_loss = 0.4122519264870052, disc_loss = 0.06248665084661562
Trained batch 158 in epoch 3, gen_loss = 0.4116830269120774, disc_loss = 0.0622864120973731
Trained batch 159 in epoch 3, gen_loss = 0.41150281485170126, disc_loss = 0.061961622931994496
Trained batch 160 in epoch 3, gen_loss = 0.41173109949005315, disc_loss = 0.06164245670719176
Trained batch 161 in epoch 3, gen_loss = 0.41203870707088047, disc_loss = 0.06129582434961641
Trained batch 162 in epoch 3, gen_loss = 0.4116741981974409, disc_loss = 0.061009489794038925
Trained batch 163 in epoch 3, gen_loss = 0.4117227411124764, disc_loss = 0.06094334994033888
Trained batch 164 in epoch 3, gen_loss = 0.41224325714689314, disc_loss = 0.06064398003121217
Trained batch 165 in epoch 3, gen_loss = 0.4124938626605344, disc_loss = 0.06042770043868257
Trained batch 166 in epoch 3, gen_loss = 0.4123107972973121, disc_loss = 0.060116066775859116
Trained batch 167 in epoch 3, gen_loss = 0.4120344723619166, disc_loss = 0.05992448066605166
Trained batch 168 in epoch 3, gen_loss = 0.41254753015450474, disc_loss = 0.05960697880753222
Trained batch 169 in epoch 3, gen_loss = 0.41274658090928024, disc_loss = 0.05932427058544229
Trained batch 170 in epoch 3, gen_loss = 0.41316349168269956, disc_loss = 0.059029316720253196
Trained batch 171 in epoch 3, gen_loss = 0.4135747467016065, disc_loss = 0.05871770336552588
Trained batch 172 in epoch 3, gen_loss = 0.41395156404186534, disc_loss = 0.05846540823664968
Trained batch 173 in epoch 3, gen_loss = 0.4141948253944002, disc_loss = 0.058169231525269045
Trained batch 174 in epoch 3, gen_loss = 0.414105373280389, disc_loss = 0.05791235938136067
Trained batch 175 in epoch 3, gen_loss = 0.4148155882615935, disc_loss = 0.05772586189612577
Trained batch 176 in epoch 3, gen_loss = 0.41489978816549655, disc_loss = 0.058257922756427764
Trained batch 177 in epoch 3, gen_loss = 0.4140593448046888, disc_loss = 0.05977045281612304
Trained batch 178 in epoch 3, gen_loss = 0.4140991463674513, disc_loss = 0.05996156298144403
Trained batch 179 in epoch 3, gen_loss = 0.4141206137008137, disc_loss = 0.06007309147777657
Trained batch 180 in epoch 3, gen_loss = 0.41421084723419904, disc_loss = 0.05989012467412494
Trained batch 181 in epoch 3, gen_loss = 0.4142760613134929, disc_loss = 0.059640057860863405
Trained batch 182 in epoch 3, gen_loss = 0.4140966111193589, disc_loss = 0.05945838073299068
Trained batch 183 in epoch 3, gen_loss = 0.41382984185348387, disc_loss = 0.059239594847895205
Trained batch 184 in epoch 3, gen_loss = 0.4142168749023128, disc_loss = 0.05903171787692888
Trained batch 185 in epoch 3, gen_loss = 0.4143326385046846, disc_loss = 0.058772017072726
Trained batch 186 in epoch 3, gen_loss = 0.4145535074453303, disc_loss = 0.05850295614411327
Trained batch 187 in epoch 3, gen_loss = 0.4143470500377899, disc_loss = 0.058248126715857614
Trained batch 188 in epoch 3, gen_loss = 0.4148256917479177, disc_loss = 0.05800905684748339
Trained batch 189 in epoch 3, gen_loss = 0.41423326793469883, disc_loss = 0.057764860046537296
Trained batch 190 in epoch 3, gen_loss = 0.4146893957522527, disc_loss = 0.05750557496968208
Trained batch 191 in epoch 3, gen_loss = 0.4148468803614378, disc_loss = 0.05723041723103961
Trained batch 192 in epoch 3, gen_loss = 0.4150578995751593, disc_loss = 0.05695652944841688
Trained batch 193 in epoch 3, gen_loss = 0.41498648398315785, disc_loss = 0.05668125928562019
Trained batch 194 in epoch 3, gen_loss = 0.4149022409549126, disc_loss = 0.05641097872494123
Trained batch 195 in epoch 3, gen_loss = 0.4151817169420573, disc_loss = 0.05617553564928928
Trained batch 196 in epoch 3, gen_loss = 0.4153634377845048, disc_loss = 0.05593921220506811
Trained batch 197 in epoch 3, gen_loss = 0.4152167573420688, disc_loss = 0.05573277016913499
Trained batch 198 in epoch 3, gen_loss = 0.4153321232627984, disc_loss = 0.05585853908510514
Trained batch 199 in epoch 3, gen_loss = 0.41515742614865303, disc_loss = 0.055605233556125316
Trained batch 200 in epoch 3, gen_loss = 0.4151853656590874, disc_loss = 0.055432607148732264
Trained batch 201 in epoch 3, gen_loss = 0.41537359165083065, disc_loss = 0.055186487257130226
Trained batch 202 in epoch 3, gen_loss = 0.4156125014638666, disc_loss = 0.05494355682852527
Trained batch 203 in epoch 3, gen_loss = 0.415461777910298, disc_loss = 0.05471123285436382
Trained batch 204 in epoch 3, gen_loss = 0.41561904549598694, disc_loss = 0.0546368141885756
Trained batch 205 in epoch 3, gen_loss = 0.4157883870659523, disc_loss = 0.054465068095065294
Trained batch 206 in epoch 3, gen_loss = 0.4159678763525497, disc_loss = 0.0543159915804683
Trained batch 207 in epoch 3, gen_loss = 0.4158495508420926, disc_loss = 0.05448390936362557
Trained batch 208 in epoch 3, gen_loss = 0.4163544863890233, disc_loss = 0.05523475967837792
Trained batch 209 in epoch 3, gen_loss = 0.41643706531751723, disc_loss = 0.05518384422175586
Trained batch 210 in epoch 3, gen_loss = 0.4161190598214407, disc_loss = 0.05502575560653874
Trained batch 211 in epoch 3, gen_loss = 0.41587165729054865, disc_loss = 0.05484518325088089
Trained batch 212 in epoch 3, gen_loss = 0.4157443658007143, disc_loss = 0.05477049494459525
Trained batch 213 in epoch 3, gen_loss = 0.4158862032622935, disc_loss = 0.05516697266835406
Trained batch 214 in epoch 3, gen_loss = 0.41623525148214296, disc_loss = 0.057628330889396194
Trained batch 215 in epoch 3, gen_loss = 0.41593382935281153, disc_loss = 0.05797176865679729
Trained batch 216 in epoch 3, gen_loss = 0.41569158462335437, disc_loss = 0.058044356776804834
Trained batch 217 in epoch 3, gen_loss = 0.4156992711605282, disc_loss = 0.05830688469342614
Trained batch 218 in epoch 3, gen_loss = 0.4157088420706797, disc_loss = 0.05838169142833515
Trained batch 219 in epoch 3, gen_loss = 0.4159570344469764, disc_loss = 0.0589454602682963
Trained batch 220 in epoch 3, gen_loss = 0.41568330779873947, disc_loss = 0.05888277479991047
Trained batch 221 in epoch 3, gen_loss = 0.4156275631876679, disc_loss = 0.058981710245732115
Trained batch 222 in epoch 3, gen_loss = 0.41597631493491444, disc_loss = 0.05885066283081612
Trained batch 223 in epoch 3, gen_loss = 0.4162558764219284, disc_loss = 0.05911062964462742
Trained batch 224 in epoch 3, gen_loss = 0.4161923458841112, disc_loss = 0.059784302055421804
Trained batch 225 in epoch 3, gen_loss = 0.4160839691098812, disc_loss = 0.05998480201913126
Trained batch 226 in epoch 3, gen_loss = 0.41610273797606584, disc_loss = 0.05986172952668717
Trained batch 227 in epoch 3, gen_loss = 0.4155335030273387, disc_loss = 0.05980116890931273
Trained batch 228 in epoch 3, gen_loss = 0.41560301236710695, disc_loss = 0.059977815146903674
Trained batch 229 in epoch 3, gen_loss = 0.4155518956806349, disc_loss = 0.06041877568375481
Trained batch 230 in epoch 3, gen_loss = 0.4158627736620057, disc_loss = 0.06042484636519314
Trained batch 231 in epoch 3, gen_loss = 0.41524298078027266, disc_loss = 0.060554928120209614
Trained batch 232 in epoch 3, gen_loss = 0.4154639701986518, disc_loss = 0.06042447258306611
Trained batch 233 in epoch 3, gen_loss = 0.415421230925454, disc_loss = 0.06032098413238095
Trained batch 234 in epoch 3, gen_loss = 0.4156146082472294, disc_loss = 0.0601979120991173
Trained batch 235 in epoch 3, gen_loss = 0.4156810426611011, disc_loss = 0.05996201054579815
Trained batch 236 in epoch 3, gen_loss = 0.41600198358423096, disc_loss = 0.05978764884197448
Trained batch 237 in epoch 3, gen_loss = 0.41612478351893545, disc_loss = 0.05966011073025523
Trained batch 238 in epoch 3, gen_loss = 0.41576314134577824, disc_loss = 0.05953130343243106
Trained batch 239 in epoch 3, gen_loss = 0.4160841508458058, disc_loss = 0.05938660884082007
Trained batch 240 in epoch 3, gen_loss = 0.4158728741016625, disc_loss = 0.059860983297337016
Trained batch 241 in epoch 3, gen_loss = 0.41612758124170224, disc_loss = 0.060070212343553746
Trained batch 242 in epoch 3, gen_loss = 0.4159224050525775, disc_loss = 0.05989921436963196
Trained batch 243 in epoch 3, gen_loss = 0.4157920886502891, disc_loss = 0.05973212871906638
Trained batch 244 in epoch 3, gen_loss = 0.4156678232611442, disc_loss = 0.05954308359104456
Trained batch 245 in epoch 3, gen_loss = 0.41569549111815973, disc_loss = 0.059459079024798384
Trained batch 246 in epoch 3, gen_loss = 0.4156925960590965, disc_loss = 0.05930698064046531
Trained batch 247 in epoch 3, gen_loss = 0.41560503275644395, disc_loss = 0.05911684114553575
Trained batch 248 in epoch 3, gen_loss = 0.4155653012564862, disc_loss = 0.058908793188811065
Trained batch 249 in epoch 3, gen_loss = 0.4156617720127106, disc_loss = 0.05872112860530615
Trained batch 250 in epoch 3, gen_loss = 0.41559974843287373, disc_loss = 0.05850777060787873
Trained batch 251 in epoch 3, gen_loss = 0.41549909777111477, disc_loss = 0.05844027893100348
Trained batch 252 in epoch 3, gen_loss = 0.4152185044034196, disc_loss = 0.058630525487891064
Trained batch 253 in epoch 3, gen_loss = 0.41556051502546926, disc_loss = 0.058668413335149446
Trained batch 254 in epoch 3, gen_loss = 0.41574572523434955, disc_loss = 0.05851671498853202
Trained batch 255 in epoch 3, gen_loss = 0.4157555568963289, disc_loss = 0.05856119953750749
Trained batch 256 in epoch 3, gen_loss = 0.41601969562615865, disc_loss = 0.058444061345540366
Trained batch 257 in epoch 3, gen_loss = 0.41618631318096044, disc_loss = 0.05825249662680566
Trained batch 258 in epoch 3, gen_loss = 0.4162917402950493, disc_loss = 0.05805596927698687
Trained batch 259 in epoch 3, gen_loss = 0.4161812920983021, disc_loss = 0.0579076193828279
Trained batch 260 in epoch 3, gen_loss = 0.416566187280348, disc_loss = 0.05771211044634496
Trained batch 261 in epoch 3, gen_loss = 0.41676075756549835, disc_loss = 0.05772856123325991
Trained batch 262 in epoch 3, gen_loss = 0.41633904490180795, disc_loss = 0.05778323270614213
Trained batch 263 in epoch 3, gen_loss = 0.4163168292831291, disc_loss = 0.05809044361883549
Trained batch 264 in epoch 3, gen_loss = 0.41597922680512917, disc_loss = 0.05878658748214256
Trained batch 265 in epoch 3, gen_loss = 0.4160999491026527, disc_loss = 0.05896515579354998
Trained batch 266 in epoch 3, gen_loss = 0.4158238818806209, disc_loss = 0.059027163062439984
Trained batch 267 in epoch 3, gen_loss = 0.41585590846058146, disc_loss = 0.05909871032857684
Trained batch 268 in epoch 3, gen_loss = 0.4153883843838504, disc_loss = 0.059416472200359664
Trained batch 269 in epoch 3, gen_loss = 0.41570342701894264, disc_loss = 0.05946940810902527
Trained batch 270 in epoch 3, gen_loss = 0.41575105284852737, disc_loss = 0.059531545350706115
Trained batch 271 in epoch 3, gen_loss = 0.4152933233143652, disc_loss = 0.05979323722182445
Trained batch 272 in epoch 3, gen_loss = 0.4155998891526526, disc_loss = 0.05962148980977826
Trained batch 273 in epoch 3, gen_loss = 0.4154183267459382, disc_loss = 0.0606143765617162
Trained batch 274 in epoch 3, gen_loss = 0.41490260861136696, disc_loss = 0.06126562818376855
Trained batch 275 in epoch 3, gen_loss = 0.4148313512188801, disc_loss = 0.061242935823047184
Trained batch 276 in epoch 3, gen_loss = 0.4146839727778727, disc_loss = 0.061359289073677804
Trained batch 277 in epoch 3, gen_loss = 0.4142348053429624, disc_loss = 0.061882972685459385
Trained batch 278 in epoch 3, gen_loss = 0.41414899670095, disc_loss = 0.06179422078200192
Trained batch 279 in epoch 3, gen_loss = 0.41414163538387844, disc_loss = 0.06232522802726765
Trained batch 280 in epoch 3, gen_loss = 0.413936206348426, disc_loss = 0.06231427076852672
Trained batch 281 in epoch 3, gen_loss = 0.41363501284562104, disc_loss = 0.062264138880575484
Trained batch 282 in epoch 3, gen_loss = 0.41367720262321905, disc_loss = 0.0621156002947725
Trained batch 283 in epoch 3, gen_loss = 0.4135659781979843, disc_loss = 0.06211547631750697
Trained batch 284 in epoch 3, gen_loss = 0.4137229537754728, disc_loss = 0.06211330347710796
Trained batch 285 in epoch 3, gen_loss = 0.4138529345497385, disc_loss = 0.06201272331002344
Trained batch 286 in epoch 3, gen_loss = 0.4137855949925213, disc_loss = 0.06193321690982279
Trained batch 287 in epoch 3, gen_loss = 0.41346745120568407, disc_loss = 0.062040054544922896
Trained batch 288 in epoch 3, gen_loss = 0.4134492414220394, disc_loss = 0.06217093123316404
Trained batch 289 in epoch 3, gen_loss = 0.41332421672755276, disc_loss = 0.0622940238645493
Trained batch 290 in epoch 3, gen_loss = 0.41335165961501524, disc_loss = 0.06215245401665978
Trained batch 291 in epoch 3, gen_loss = 0.4135517184048483, disc_loss = 0.06198621342398788
Trained batch 292 in epoch 3, gen_loss = 0.41360842479780674, disc_loss = 0.061834998481268055
Trained batch 293 in epoch 3, gen_loss = 0.4136179889343223, disc_loss = 0.0616448995337321
Trained batch 294 in epoch 3, gen_loss = 0.41341793789701947, disc_loss = 0.06148767124829908
Trained batch 295 in epoch 3, gen_loss = 0.4132611058853768, disc_loss = 0.061368935302566936
Trained batch 296 in epoch 3, gen_loss = 0.4134103414988277, disc_loss = 0.061205341290958504
Trained batch 297 in epoch 3, gen_loss = 0.4137199661075669, disc_loss = 0.06104471641217652
Trained batch 298 in epoch 3, gen_loss = 0.41369508261664656, disc_loss = 0.060915755548741804
Trained batch 299 in epoch 3, gen_loss = 0.4135640702644984, disc_loss = 0.060761682519999645
Trained batch 300 in epoch 3, gen_loss = 0.41330239335167845, disc_loss = 0.06066778681374022
Trained batch 301 in epoch 3, gen_loss = 0.4133718618691362, disc_loss = 0.06069388011599959
Trained batch 302 in epoch 3, gen_loss = 0.41332231702977673, disc_loss = 0.06093768468556969
Trained batch 303 in epoch 3, gen_loss = 0.41346800003788975, disc_loss = 0.06160031918797789
Trained batch 304 in epoch 3, gen_loss = 0.4131298354414643, disc_loss = 0.061646294696103845
Trained batch 305 in epoch 3, gen_loss = 0.4131530527195899, disc_loss = 0.06148025021413524
Trained batch 306 in epoch 3, gen_loss = 0.41313356918310107, disc_loss = 0.061320473538584254
Trained batch 307 in epoch 3, gen_loss = 0.41317559972211915, disc_loss = 0.061156287297981414
Trained batch 308 in epoch 3, gen_loss = 0.4129897120701071, disc_loss = 0.06102241090917809
Trained batch 309 in epoch 3, gen_loss = 0.41280772955186906, disc_loss = 0.06088063722746747
Trained batch 310 in epoch 3, gen_loss = 0.4126473665237427, disc_loss = 0.06071386394507201
Trained batch 311 in epoch 3, gen_loss = 0.4124322361671008, disc_loss = 0.060546935215078965
Trained batch 312 in epoch 3, gen_loss = 0.41227921776878185, disc_loss = 0.06041007120751392
Trained batch 313 in epoch 3, gen_loss = 0.41220615576406955, disc_loss = 0.06029850099929816
Trained batch 314 in epoch 3, gen_loss = 0.41196096274587846, disc_loss = 0.06032689675126993
Trained batch 315 in epoch 3, gen_loss = 0.4118264045896409, disc_loss = 0.06069834466840883
Trained batch 316 in epoch 3, gen_loss = 0.41207492614770164, disc_loss = 0.061637735824256384
Trained batch 317 in epoch 3, gen_loss = 0.41218439288109354, disc_loss = 0.061788427849950374
Trained batch 318 in epoch 3, gen_loss = 0.412307945538464, disc_loss = 0.06169871061158638
Trained batch 319 in epoch 3, gen_loss = 0.412115989997983, disc_loss = 0.061809551996702794
Trained batch 320 in epoch 3, gen_loss = 0.41258344360601124, disc_loss = 0.062279553893907144
Trained batch 321 in epoch 3, gen_loss = 0.41259329613321316, disc_loss = 0.062206004927027395
Trained batch 322 in epoch 3, gen_loss = 0.41246242078465206, disc_loss = 0.06215021965863766
Trained batch 323 in epoch 3, gen_loss = 0.4123047789857711, disc_loss = 0.062007031703862237
Trained batch 324 in epoch 3, gen_loss = 0.4123646287734692, disc_loss = 0.06212349604098843
Trained batch 325 in epoch 3, gen_loss = 0.4125886891334335, disc_loss = 0.0627266177407643
Trained batch 326 in epoch 3, gen_loss = 0.4123357332080876, disc_loss = 0.06309506070546646
Trained batch 327 in epoch 3, gen_loss = 0.41235677788897257, disc_loss = 0.0632199193138016
Trained batch 328 in epoch 3, gen_loss = 0.4121341189896082, disc_loss = 0.06363535309097189
Trained batch 329 in epoch 3, gen_loss = 0.41220225755012396, disc_loss = 0.06362927006416474
Trained batch 330 in epoch 3, gen_loss = 0.4121792736010249, disc_loss = 0.06361193058089412
Trained batch 331 in epoch 3, gen_loss = 0.4120205816734268, disc_loss = 0.06368378250360354
Trained batch 332 in epoch 3, gen_loss = 0.4120817469046997, disc_loss = 0.06352355456617367
Trained batch 333 in epoch 3, gen_loss = 0.4121914450636881, disc_loss = 0.06365543374273101
Trained batch 334 in epoch 3, gen_loss = 0.4118049862669475, disc_loss = 0.06359453470543472
Trained batch 335 in epoch 3, gen_loss = 0.4115786136438449, disc_loss = 0.06358380910768617
Trained batch 336 in epoch 3, gen_loss = 0.4117220442974249, disc_loss = 0.0634501807029616
Trained batch 337 in epoch 3, gen_loss = 0.411664310291674, disc_loss = 0.06341615936597644
Trained batch 338 in epoch 3, gen_loss = 0.4115806662403377, disc_loss = 0.06336090799591403
Trained batch 339 in epoch 3, gen_loss = 0.4114549913827111, disc_loss = 0.06357895977493813
Trained batch 340 in epoch 3, gen_loss = 0.4119071390621823, disc_loss = 0.06354382351352192
Trained batch 341 in epoch 3, gen_loss = 0.41211635527903573, disc_loss = 0.06357846026886145
Trained batch 342 in epoch 3, gen_loss = 0.4120316654878177, disc_loss = 0.0634181294821029
Trained batch 343 in epoch 3, gen_loss = 0.4118560885274133, disc_loss = 0.06342059323634562
Trained batch 344 in epoch 3, gen_loss = 0.4118005809576615, disc_loss = 0.06326475535802867
Trained batch 345 in epoch 3, gen_loss = 0.41187817116693265, disc_loss = 0.06310397874553166
Trained batch 346 in epoch 3, gen_loss = 0.41177330649208266, disc_loss = 0.06293969483970951
Trained batch 347 in epoch 3, gen_loss = 0.4118411125636649, disc_loss = 0.06278721949797467
Trained batch 348 in epoch 3, gen_loss = 0.4118519996674491, disc_loss = 0.06267232848277961
Trained batch 349 in epoch 3, gen_loss = 0.4118355052811759, disc_loss = 0.06260813316197268
Trained batch 350 in epoch 3, gen_loss = 0.4115454116438189, disc_loss = 0.062481078636325744
Trained batch 351 in epoch 3, gen_loss = 0.4114285923371261, disc_loss = 0.06251837536613246
Trained batch 352 in epoch 3, gen_loss = 0.411538119103348, disc_loss = 0.06240347097561861
Trained batch 353 in epoch 3, gen_loss = 0.4115926257129443, disc_loss = 0.06250955095109503
Trained batch 354 in epoch 3, gen_loss = 0.4114227540895972, disc_loss = 0.06285923293490016
Trained batch 355 in epoch 3, gen_loss = 0.4116225265217631, disc_loss = 0.06271090609508075
Trained batch 356 in epoch 3, gen_loss = 0.4114405954418396, disc_loss = 0.0631632255559855
Trained batch 357 in epoch 3, gen_loss = 0.411195243537093, disc_loss = 0.0631482251308463
Trained batch 358 in epoch 3, gen_loss = 0.4111383359744356, disc_loss = 0.06301397468744256
Trained batch 359 in epoch 3, gen_loss = 0.41125518414709306, disc_loss = 0.06287276053206167
Trained batch 360 in epoch 3, gen_loss = 0.41111123916845244, disc_loss = 0.06272049257634955
Trained batch 361 in epoch 3, gen_loss = 0.4110999699290945, disc_loss = 0.06269664092128324
Trained batch 362 in epoch 3, gen_loss = 0.4111712874624026, disc_loss = 0.06271615701524885
Trained batch 363 in epoch 3, gen_loss = 0.4111166191133824, disc_loss = 0.06270830950489943
Trained batch 364 in epoch 3, gen_loss = 0.4110939287976043, disc_loss = 0.06258144926866643
Trained batch 365 in epoch 3, gen_loss = 0.41106089770468207, disc_loss = 0.062466984636358955
Trained batch 366 in epoch 3, gen_loss = 0.41094714102693086, disc_loss = 0.06238345305590157
Trained batch 367 in epoch 3, gen_loss = 0.4109640404905962, disc_loss = 0.06230743188011136
Trained batch 368 in epoch 3, gen_loss = 0.41061341318334665, disc_loss = 0.06255400175895028
Trained batch 369 in epoch 3, gen_loss = 0.41076727783357775, disc_loss = 0.06296381820622529
Trained batch 370 in epoch 3, gen_loss = 0.410596472474764, disc_loss = 0.06290033850392121
Trained batch 371 in epoch 3, gen_loss = 0.41068419245302035, disc_loss = 0.0628554906848798
Trained batch 372 in epoch 3, gen_loss = 0.4106859920331684, disc_loss = 0.06273250153098485
Trained batch 373 in epoch 3, gen_loss = 0.41076573992476745, disc_loss = 0.06259302969618556
Trained batch 374 in epoch 3, gen_loss = 0.41083770179748536, disc_loss = 0.06251166878516476
Trained batch 375 in epoch 3, gen_loss = 0.4108706791191659, disc_loss = 0.06241704355504245
Trained batch 376 in epoch 3, gen_loss = 0.411005365832731, disc_loss = 0.062320569963676145
Trained batch 377 in epoch 3, gen_loss = 0.4111583756391334, disc_loss = 0.062190307559268104
Trained batch 378 in epoch 3, gen_loss = 0.4109699620735048, disc_loss = 0.06235859129150302
Trained batch 379 in epoch 3, gen_loss = 0.4108879060337418, disc_loss = 0.06327488674218522
Trained batch 380 in epoch 3, gen_loss = 0.4110392101324136, disc_loss = 0.06331754691796157
Trained batch 381 in epoch 3, gen_loss = 0.411028371353424, disc_loss = 0.06320431330046221
Trained batch 382 in epoch 3, gen_loss = 0.41090548077389094, disc_loss = 0.06325232238428516
Trained batch 383 in epoch 3, gen_loss = 0.4109227124135941, disc_loss = 0.0631519673903919
Trained batch 384 in epoch 3, gen_loss = 0.4108987788875382, disc_loss = 0.06302152681829674
Trained batch 385 in epoch 3, gen_loss = 0.4110221492966222, disc_loss = 0.06291650872981572
Trained batch 386 in epoch 3, gen_loss = 0.4108060144792848, disc_loss = 0.06281585317437155
Trained batch 387 in epoch 3, gen_loss = 0.4108262220301579, disc_loss = 0.06271917557166218
Trained batch 388 in epoch 3, gen_loss = 0.41081635964253876, disc_loss = 0.06259187659641349
Trained batch 389 in epoch 3, gen_loss = 0.41076339804209194, disc_loss = 0.062496409079251
Trained batch 390 in epoch 3, gen_loss = 0.4107089855939226, disc_loss = 0.062424397435458495
Trained batch 391 in epoch 3, gen_loss = 0.41066595395000616, disc_loss = 0.062374740098935684
Trained batch 392 in epoch 3, gen_loss = 0.4106012899002046, disc_loss = 0.0622877226846231
Trained batch 393 in epoch 3, gen_loss = 0.41054334812963067, disc_loss = 0.06222161638484275
Trained batch 394 in epoch 3, gen_loss = 0.4107969115052042, disc_loss = 0.06217426737959061
Trained batch 395 in epoch 3, gen_loss = 0.41061864447112034, disc_loss = 0.0620426889732386
Trained batch 396 in epoch 3, gen_loss = 0.4105384192178472, disc_loss = 0.061913810359543985
Trained batch 397 in epoch 3, gen_loss = 0.4106519893186176, disc_loss = 0.061775182453381955
Trained batch 398 in epoch 3, gen_loss = 0.4107724670927626, disc_loss = 0.0616590387974504
Trained batch 399 in epoch 3, gen_loss = 0.4107033986598253, disc_loss = 0.061519223481882365
Trained batch 400 in epoch 3, gen_loss = 0.4106953001379075, disc_loss = 0.06141320884720123
Trained batch 401 in epoch 3, gen_loss = 0.41043031682719044, disc_loss = 0.06136125136417017
Trained batch 402 in epoch 3, gen_loss = 0.4105425692225804, disc_loss = 0.06122610751174335
Trained batch 403 in epoch 3, gen_loss = 0.41075735340023983, disc_loss = 0.061328195993290605
Trained batch 404 in epoch 3, gen_loss = 0.41083415415551927, disc_loss = 0.061278761085122826
Trained batch 405 in epoch 3, gen_loss = 0.4107980291391241, disc_loss = 0.06114858502792791
Trained batch 406 in epoch 3, gen_loss = 0.4107838059965457, disc_loss = 0.06105138684670997
Trained batch 407 in epoch 3, gen_loss = 0.41086366334382224, disc_loss = 0.060927828738475034
Trained batch 408 in epoch 3, gen_loss = 0.4108872571026492, disc_loss = 0.06079492388716683
Trained batch 409 in epoch 3, gen_loss = 0.41087158111537375, disc_loss = 0.060679729882536865
Trained batch 410 in epoch 3, gen_loss = 0.4107602671550138, disc_loss = 0.06056942739308678
Trained batch 411 in epoch 3, gen_loss = 0.4108308160189286, disc_loss = 0.06043298422919532
Trained batch 412 in epoch 3, gen_loss = 0.41090037819836966, disc_loss = 0.06030802017632538
Trained batch 413 in epoch 3, gen_loss = 0.4110368070539069, disc_loss = 0.06018524021945066
Trained batch 414 in epoch 3, gen_loss = 0.4110787492200553, disc_loss = 0.060053030565291286
Trained batch 415 in epoch 3, gen_loss = 0.41087051982489914, disc_loss = 0.059937563682279475
Trained batch 416 in epoch 3, gen_loss = 0.41079622914465214, disc_loss = 0.059864087800810234
Trained batch 417 in epoch 3, gen_loss = 0.4107539123325257, disc_loss = 0.05983186604758128
Trained batch 418 in epoch 3, gen_loss = 0.4105542287194928, disc_loss = 0.059820594828406924
Trained batch 419 in epoch 3, gen_loss = 0.4107364384900956, disc_loss = 0.05973952995125382
Trained batch 420 in epoch 3, gen_loss = 0.41087079062314613, disc_loss = 0.059623068952910835
Trained batch 421 in epoch 3, gen_loss = 0.41088010413104326, disc_loss = 0.059510757394082035
Trained batch 422 in epoch 3, gen_loss = 0.41082684234242633, disc_loss = 0.05938531976439781
Trained batch 423 in epoch 3, gen_loss = 0.4107182894675237, disc_loss = 0.059269085170630856
Trained batch 424 in epoch 3, gen_loss = 0.4108139918130987, disc_loss = 0.05914366335772416
Trained batch 425 in epoch 3, gen_loss = 0.4107768425079579, disc_loss = 0.05902637262553186
Trained batch 426 in epoch 3, gen_loss = 0.4106933032042528, disc_loss = 0.05893787880596079
Trained batch 427 in epoch 3, gen_loss = 0.4106698930959835, disc_loss = 0.05881654481386122
Trained batch 428 in epoch 3, gen_loss = 0.41077000604364977, disc_loss = 0.058707278547482894
Trained batch 429 in epoch 3, gen_loss = 0.41083713804566585, disc_loss = 0.05860420407640726
Trained batch 430 in epoch 3, gen_loss = 0.4107640374564239, disc_loss = 0.058509588987067374
Trained batch 431 in epoch 3, gen_loss = 0.41111371638598265, disc_loss = 0.05842812244426804
Trained batch 432 in epoch 3, gen_loss = 0.41108685910839404, disc_loss = 0.05831784361168983
Trained batch 433 in epoch 3, gen_loss = 0.41108682016897863, disc_loss = 0.058275108498173515
Trained batch 434 in epoch 3, gen_loss = 0.41112206180890404, disc_loss = 0.05816840057357632
Trained batch 435 in epoch 3, gen_loss = 0.4111543093389327, disc_loss = 0.05806554685594565
Trained batch 436 in epoch 3, gen_loss = 0.41141976665031993, disc_loss = 0.057947948487641746
Trained batch 437 in epoch 3, gen_loss = 0.41138552068031, disc_loss = 0.057856455247543036
Trained batch 438 in epoch 3, gen_loss = 0.41140114242775294, disc_loss = 0.05774077723345853
Trained batch 439 in epoch 3, gen_loss = 0.41143121407790617, disc_loss = 0.05763652658788487
Trained batch 440 in epoch 3, gen_loss = 0.411639928817749, disc_loss = 0.05752050732906545
Trained batch 441 in epoch 3, gen_loss = 0.41161387133921973, disc_loss = 0.05745060030029606
Trained batch 442 in epoch 3, gen_loss = 0.41160968739884163, disc_loss = 0.05735168110633912
Trained batch 443 in epoch 3, gen_loss = 0.41144234646816513, disc_loss = 0.05724804515233012
Trained batch 444 in epoch 3, gen_loss = 0.41164384243193636, disc_loss = 0.05727652901406871
Trained batch 445 in epoch 3, gen_loss = 0.4117142883517817, disc_loss = 0.057170031263363535
Trained batch 446 in epoch 3, gen_loss = 0.41165975829632223, disc_loss = 0.057300940819576346
Trained batch 447 in epoch 3, gen_loss = 0.4117859532125294, disc_loss = 0.05749409129930427
Trained batch 448 in epoch 3, gen_loss = 0.4119202655912242, disc_loss = 0.05740201665826955
Trained batch 449 in epoch 3, gen_loss = 0.41192271126641167, disc_loss = 0.057340131792136366
Trained batch 450 in epoch 3, gen_loss = 0.4119232072269837, disc_loss = 0.05722706755540621
Trained batch 451 in epoch 3, gen_loss = 0.412032319051502, disc_loss = 0.0571262734927715
Trained batch 452 in epoch 3, gen_loss = 0.4119712793932319, disc_loss = 0.05702162069467947
Trained batch 453 in epoch 3, gen_loss = 0.41203810839138366, disc_loss = 0.05697055551682964
Trained batch 454 in epoch 3, gen_loss = 0.4121695462818984, disc_loss = 0.0569116095807608
Trained batch 455 in epoch 3, gen_loss = 0.41226951915182564, disc_loss = 0.05680479480692986
Trained batch 456 in epoch 3, gen_loss = 0.41230627463996017, disc_loss = 0.05687772863008555
Trained batch 457 in epoch 3, gen_loss = 0.4123934789776281, disc_loss = 0.05743596186011411
Trained batch 458 in epoch 3, gen_loss = 0.4121126511777408, disc_loss = 0.05760502205423053
Testing Epoch 3
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 13:22:11,963
------------------------------------------------------------
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 13:22:12,007
------------------------------------------------------------
Training Epoch 4
Trained batch 0 in epoch 4, gen_loss = 0.4446570873260498, disc_loss = 0.13436907529830933
Trained batch 1 in epoch 4, gen_loss = 0.44933345913887024, disc_loss = 0.12021182477474213
Trained batch 2 in epoch 4, gen_loss = 0.4182361563046773, disc_loss = 0.10917113969723384
Trained batch 3 in epoch 4, gen_loss = 0.42553626000881195, disc_loss = 0.13814942352473736
Trained batch 4 in epoch 4, gen_loss = 0.4176840424537659, disc_loss = 0.12384791821241378
Trained batch 5 in epoch 4, gen_loss = 0.40745383004347485, disc_loss = 0.11061262836058934
Trained batch 6 in epoch 4, gen_loss = 0.41963087235178265, disc_loss = 0.09705224234078612
Trained batch 7 in epoch 4, gen_loss = 0.4246324524283409, disc_loss = 0.08727080095559359
Trained batch 8 in epoch 4, gen_loss = 0.4245004587703281, disc_loss = 0.07932971438599958
Trained batch 9 in epoch 4, gen_loss = 0.4247161984443665, disc_loss = 0.07356723155826331
Trained batch 10 in epoch 4, gen_loss = 0.4304731650785966, disc_loss = 0.06963555548678745
Trained batch 11 in epoch 4, gen_loss = 0.4246773471434911, disc_loss = 0.0654889897753795
Trained batch 12 in epoch 4, gen_loss = 0.42814147701630223, disc_loss = 0.0616709624345486
Trained batch 13 in epoch 4, gen_loss = 0.43538292603833334, disc_loss = 0.058226115203329494
Trained batch 14 in epoch 4, gen_loss = 0.43989787697792054, disc_loss = 0.055498209223151206
Trained batch 15 in epoch 4, gen_loss = 0.4378155879676342, disc_loss = 0.052288859616965055
Trained batch 16 in epoch 4, gen_loss = 0.43958597498781543, disc_loss = 0.04990629731293987
Trained batch 17 in epoch 4, gen_loss = 0.4351237118244171, disc_loss = 0.05003966318650378
Trained batch 18 in epoch 4, gen_loss = 0.42984096000069066, disc_loss = 0.04842815479557765
Trained batch 19 in epoch 4, gen_loss = 0.42717577815055846, disc_loss = 0.05268723713234067
Trained batch 20 in epoch 4, gen_loss = 0.42643247899555026, disc_loss = 0.0518646306757416
Trained batch 21 in epoch 4, gen_loss = 0.42602085931734607, disc_loss = 0.0524308934638446
Trained batch 22 in epoch 4, gen_loss = 0.42277110529982526, disc_loss = 0.05362404486083466
Trained batch 23 in epoch 4, gen_loss = 0.42620288704832393, disc_loss = 0.0529938618807743
Trained batch 24 in epoch 4, gen_loss = 0.426417396068573, disc_loss = 0.05132256664335728
Trained batch 25 in epoch 4, gen_loss = 0.42459011651002443, disc_loss = 0.05106897229472032
Trained batch 26 in epoch 4, gen_loss = 0.42785039102589645, disc_loss = 0.05178876007320704
Trained batch 27 in epoch 4, gen_loss = 0.4279003696782248, disc_loss = 0.05017410529710885
Trained batch 28 in epoch 4, gen_loss = 0.42562539618590783, disc_loss = 0.04975130066982117
Trained batch 29 in epoch 4, gen_loss = 0.4231009175380071, disc_loss = 0.04862575038957099
Trained batch 30 in epoch 4, gen_loss = 0.4240154287507457, disc_loss = 0.04719918718441359
Trained batch 31 in epoch 4, gen_loss = 0.42445580288767815, disc_loss = 0.04619100860145409
Trained batch 32 in epoch 4, gen_loss = 0.42328128850821295, disc_loss = 0.045243377783194635
Trained batch 33 in epoch 4, gen_loss = 0.4228232792195152, disc_loss = 0.04439106552094659
Trained batch 34 in epoch 4, gen_loss = 0.42192533952849254, disc_loss = 0.04369675060734153
Trained batch 35 in epoch 4, gen_loss = 0.42024585356314975, disc_loss = 0.04363292788103637
Trained batch 36 in epoch 4, gen_loss = 0.41937778608219045, disc_loss = 0.042785147016213554
Trained batch 37 in epoch 4, gen_loss = 0.41656884786329773, disc_loss = 0.04422807268259164
Trained batch 38 in epoch 4, gen_loss = 0.4183906813462575, disc_loss = 0.04366375645622611
Trained batch 39 in epoch 4, gen_loss = 0.4196008786559105, disc_loss = 0.04272501863306388
Trained batch 40 in epoch 4, gen_loss = 0.41849772813843517, disc_loss = 0.041949598357172276
Trained batch 41 in epoch 4, gen_loss = 0.4179809426977521, disc_loss = 0.04143438329698429
Trained batch 42 in epoch 4, gen_loss = 0.4181823078976121, disc_loss = 0.041050205581150086
Trained batch 43 in epoch 4, gen_loss = 0.41849193518812006, disc_loss = 0.040439697056585414
Trained batch 44 in epoch 4, gen_loss = 0.41740882992744444, disc_loss = 0.04005707774518265
Trained batch 45 in epoch 4, gen_loss = 0.41808775585630664, disc_loss = 0.03984185234319581
Trained batch 46 in epoch 4, gen_loss = 0.41766077660499734, disc_loss = 0.03916405150270526
Trained batch 47 in epoch 4, gen_loss = 0.4175250269472599, disc_loss = 0.0385071992156251
Trained batch 48 in epoch 4, gen_loss = 0.41764315841149313, disc_loss = 0.03851882451004824
Trained batch 49 in epoch 4, gen_loss = 0.4182510882616043, disc_loss = 0.037911897068843244
Trained batch 50 in epoch 4, gen_loss = 0.41937999047485053, disc_loss = 0.037815830935084935
Trained batch 51 in epoch 4, gen_loss = 0.41971814747040087, disc_loss = 0.03719580664227788
Trained batch 52 in epoch 4, gen_loss = 0.4212760509185071, disc_loss = 0.03686209743455896
Trained batch 53 in epoch 4, gen_loss = 0.4208596177675106, disc_loss = 0.03626826089047999
Trained batch 54 in epoch 4, gen_loss = 0.41958020600405604, disc_loss = 0.036602696649391545
Trained batch 55 in epoch 4, gen_loss = 0.42165873093264444, disc_loss = 0.03643697750521824
Trained batch 56 in epoch 4, gen_loss = 0.4214064149480117, disc_loss = 0.036073785185356415
Trained batch 57 in epoch 4, gen_loss = 0.41942855458835077, disc_loss = 0.03595484472843337
Trained batch 58 in epoch 4, gen_loss = 0.4186760874117835, disc_loss = 0.03641951653190841
Trained batch 59 in epoch 4, gen_loss = 0.41613929718732834, disc_loss = 0.03680514396013071
Trained batch 60 in epoch 4, gen_loss = 0.4161445014789456, disc_loss = 0.04116689084769517
Trained batch 61 in epoch 4, gen_loss = 0.4147561000239465, disc_loss = 0.04239105277754847
Trained batch 62 in epoch 4, gen_loss = 0.4152853342275771, disc_loss = 0.042036617270833444
Trained batch 63 in epoch 4, gen_loss = 0.41512876795604825, disc_loss = 0.045125410142645705
Trained batch 64 in epoch 4, gen_loss = 0.41462086851780233, disc_loss = 0.04643296502673855
Trained batch 65 in epoch 4, gen_loss = 0.4150564042907773, disc_loss = 0.04661678049402932
Trained batch 66 in epoch 4, gen_loss = 0.4160967833960234, disc_loss = 0.046700477495845126
Trained batch 67 in epoch 4, gen_loss = 0.41516884241034, disc_loss = 0.04643343921120772
Trained batch 68 in epoch 4, gen_loss = 0.4147898032181505, disc_loss = 0.04601352665222425
Trained batch 69 in epoch 4, gen_loss = 0.4144335367849895, disc_loss = 0.04687573317039226
Trained batch 70 in epoch 4, gen_loss = 0.41595157141416844, disc_loss = 0.050716747313370586
Trained batch 71 in epoch 4, gen_loss = 0.41566097860534984, disc_loss = 0.05375637158673877
Trained batch 72 in epoch 4, gen_loss = 0.4161476333663888, disc_loss = 0.05403502921458997
Trained batch 73 in epoch 4, gen_loss = 0.41589811404009125, disc_loss = 0.05418506056397549
Trained batch 74 in epoch 4, gen_loss = 0.4146586294968923, disc_loss = 0.05384845627471804
Trained batch 75 in epoch 4, gen_loss = 0.41361015564516973, disc_loss = 0.05429949143925976
Trained batch 76 in epoch 4, gen_loss = 0.41331401157688785, disc_loss = 0.0541125129388234
Trained batch 77 in epoch 4, gen_loss = 0.4129057022241446, disc_loss = 0.05375592418325444
Trained batch 78 in epoch 4, gen_loss = 0.4121364562571803, disc_loss = 0.05455772576947944
Trained batch 79 in epoch 4, gen_loss = 0.41202929727733134, disc_loss = 0.054734435287537055
Trained batch 80 in epoch 4, gen_loss = 0.4128173468289552, disc_loss = 0.054149791667306865
Trained batch 81 in epoch 4, gen_loss = 0.4136000442795637, disc_loss = 0.053832651184099474
Trained batch 82 in epoch 4, gen_loss = 0.41297632455825806, disc_loss = 0.05328727780605655
Trained batch 83 in epoch 4, gen_loss = 0.4134477266953105, disc_loss = 0.052944142260544357
Trained batch 84 in epoch 4, gen_loss = 0.4138017920886769, disc_loss = 0.05251024387338582
Trained batch 85 in epoch 4, gen_loss = 0.41300855784915214, disc_loss = 0.05266598503776761
Trained batch 86 in epoch 4, gen_loss = 0.413652121678166, disc_loss = 0.05385583172413124
Trained batch 87 in epoch 4, gen_loss = 0.41415977308695967, disc_loss = 0.053424737162210724
Trained batch 88 in epoch 4, gen_loss = 0.41359581003028356, disc_loss = 0.05318657107902377
Trained batch 89 in epoch 4, gen_loss = 0.413817102710406, disc_loss = 0.052646933982355724
Trained batch 90 in epoch 4, gen_loss = 0.4137468727735373, disc_loss = 0.0525953472377016
Trained batch 91 in epoch 4, gen_loss = 0.4139795225599538, disc_loss = 0.052593426566328046
Trained batch 92 in epoch 4, gen_loss = 0.4130809707667238, disc_loss = 0.05237824112297066
Trained batch 93 in epoch 4, gen_loss = 0.413179208940648, disc_loss = 0.05207847085523796
Trained batch 94 in epoch 4, gen_loss = 0.41378561603395564, disc_loss = 0.051755056638074545
Trained batch 95 in epoch 4, gen_loss = 0.41319736496855813, disc_loss = 0.05137607980092677
Trained batch 96 in epoch 4, gen_loss = 0.41301752980222406, disc_loss = 0.05090192020342676
Trained batch 97 in epoch 4, gen_loss = 0.41261098640305655, disc_loss = 0.050437335566408475
Trained batch 98 in epoch 4, gen_loss = 0.41256438120447025, disc_loss = 0.04999607289209962
Trained batch 99 in epoch 4, gen_loss = 0.4126141449809074, disc_loss = 0.049633612628094854
Trained batch 100 in epoch 4, gen_loss = 0.41154215211915496, disc_loss = 0.04925533746931665
Trained batch 101 in epoch 4, gen_loss = 0.4114932350668253, disc_loss = 0.04882516488250272
Trained batch 102 in epoch 4, gen_loss = 0.4108533390517374, disc_loss = 0.04855300714849558
Trained batch 103 in epoch 4, gen_loss = 0.41055749700619626, disc_loss = 0.04815943066765053
Trained batch 104 in epoch 4, gen_loss = 0.4104550625596728, disc_loss = 0.0477451010607183
Trained batch 105 in epoch 4, gen_loss = 0.4112191782245096, disc_loss = 0.04742695768539495
Trained batch 106 in epoch 4, gen_loss = 0.4117612883309338, disc_loss = 0.047524866321620264
Trained batch 107 in epoch 4, gen_loss = 0.41085760212606853, disc_loss = 0.04905926127038482
Trained batch 108 in epoch 4, gen_loss = 0.4110264398089243, disc_loss = 0.049422020566812074
Trained batch 109 in epoch 4, gen_loss = 0.4109964541413567, disc_loss = 0.049069714440371504
Trained batch 110 in epoch 4, gen_loss = 0.4106798969410561, disc_loss = 0.048708128981997036
Trained batch 111 in epoch 4, gen_loss = 0.41103614148284706, disc_loss = 0.04849723295358542
Trained batch 112 in epoch 4, gen_loss = 0.41093419927411373, disc_loss = 0.04811176831166433
Trained batch 113 in epoch 4, gen_loss = 0.41051574443515976, disc_loss = 0.04776769004386376
Trained batch 114 in epoch 4, gen_loss = 0.4107559901216756, disc_loss = 0.0474316803616998
Trained batch 115 in epoch 4, gen_loss = 0.41117135024276275, disc_loss = 0.04708336713193948
Trained batch 116 in epoch 4, gen_loss = 0.4106695206246824, disc_loss = 0.04695014358283235
Trained batch 117 in epoch 4, gen_loss = 0.4099361719721455, disc_loss = 0.048743155252156875
Trained batch 118 in epoch 4, gen_loss = 0.41002386507867766, disc_loss = 0.051079502082703745
Trained batch 119 in epoch 4, gen_loss = 0.40970104237397514, disc_loss = 0.05102776508235062
Trained batch 120 in epoch 4, gen_loss = 0.40898531823118855, disc_loss = 0.0509638259425944
Trained batch 121 in epoch 4, gen_loss = 0.40892464117925675, disc_loss = 0.05070034204218842
Trained batch 122 in epoch 4, gen_loss = 0.4082479556886161, disc_loss = 0.05036084997899285
Trained batch 123 in epoch 4, gen_loss = 0.4082885906100273, disc_loss = 0.050012014881377256
Trained batch 124 in epoch 4, gen_loss = 0.40877953767776487, disc_loss = 0.049798257619142534
Trained batch 125 in epoch 4, gen_loss = 0.40833883862646797, disc_loss = 0.04962064432246344
Trained batch 126 in epoch 4, gen_loss = 0.40861767671239657, disc_loss = 0.04928288939152294
Trained batch 127 in epoch 4, gen_loss = 0.40841525979340076, disc_loss = 0.04894906105619157
Trained batch 128 in epoch 4, gen_loss = 0.40788696047871614, disc_loss = 0.048610282527614936
Trained batch 129 in epoch 4, gen_loss = 0.4077318764649905, disc_loss = 0.04828536895891795
Trained batch 130 in epoch 4, gen_loss = 0.40807364778664273, disc_loss = 0.04811661448756247
Trained batch 131 in epoch 4, gen_loss = 0.4081368168646639, disc_loss = 0.04781393366019157
Trained batch 132 in epoch 4, gen_loss = 0.4082289734729251, disc_loss = 0.047489983337770277
Trained batch 133 in epoch 4, gen_loss = 0.40761310040061155, disc_loss = 0.04722112281692784
Trained batch 134 in epoch 4, gen_loss = 0.4070589972866906, disc_loss = 0.046919658024691877
Trained batch 135 in epoch 4, gen_loss = 0.4071449854356401, disc_loss = 0.046645867313011825
Trained batch 136 in epoch 4, gen_loss = 0.4072252827404189, disc_loss = 0.04634573270165681
Trained batch 137 in epoch 4, gen_loss = 0.407286263462426, disc_loss = 0.04633456836049647
Trained batch 138 in epoch 4, gen_loss = 0.40755183233631603, disc_loss = 0.04638169733003425
Trained batch 139 in epoch 4, gen_loss = 0.40788183105843406, disc_loss = 0.0461038552923128
Trained batch 140 in epoch 4, gen_loss = 0.40740004815953845, disc_loss = 0.045901264760854606
Trained batch 141 in epoch 4, gen_loss = 0.4072637828722806, disc_loss = 0.0456854268600246
Trained batch 142 in epoch 4, gen_loss = 0.40692832524126227, disc_loss = 0.04565735340079332
Trained batch 143 in epoch 4, gen_loss = 0.40703354879385895, disc_loss = 0.045415903729412496
Trained batch 144 in epoch 4, gen_loss = 0.40689958642269003, disc_loss = 0.0452062269255262
Trained batch 145 in epoch 4, gen_loss = 0.40719255702952817, disc_loss = 0.045165531876280085
Trained batch 146 in epoch 4, gen_loss = 0.40725192103256175, disc_loss = 0.04504129132509333
Trained batch 147 in epoch 4, gen_loss = 0.4076104379586271, disc_loss = 0.044812966707615635
Trained batch 148 in epoch 4, gen_loss = 0.4080367130321144, disc_loss = 0.04471073178699453
Trained batch 149 in epoch 4, gen_loss = 0.4080729017655055, disc_loss = 0.044540520623947186
Trained batch 150 in epoch 4, gen_loss = 0.40798224242317754, disc_loss = 0.0444982577491527
Trained batch 151 in epoch 4, gen_loss = 0.407868101604675, disc_loss = 0.0442309924707699
Trained batch 152 in epoch 4, gen_loss = 0.4076274588606716, disc_loss = 0.04398471107584686
Trained batch 153 in epoch 4, gen_loss = 0.407710449649142, disc_loss = 0.04377720593595756
Trained batch 154 in epoch 4, gen_loss = 0.4076074323346538, disc_loss = 0.04367576863075937
Trained batch 155 in epoch 4, gen_loss = 0.40747508597679627, disc_loss = 0.04356882966254862
Trained batch 156 in epoch 4, gen_loss = 0.40787331674508986, disc_loss = 0.043371878638507645
Trained batch 157 in epoch 4, gen_loss = 0.40811043242110484, disc_loss = 0.043137093693536674
Trained batch 158 in epoch 4, gen_loss = 0.40783759857873497, disc_loss = 0.042890795020374864
Trained batch 159 in epoch 4, gen_loss = 0.4082851253449917, disc_loss = 0.04267099761927966
Trained batch 160 in epoch 4, gen_loss = 0.40843006302110896, disc_loss = 0.04246364639470388
Trained batch 161 in epoch 4, gen_loss = 0.4077747517529829, disc_loss = 0.0422806924490695
Trained batch 162 in epoch 4, gen_loss = 0.4080553223018997, disc_loss = 0.04208397281647551
Trained batch 163 in epoch 4, gen_loss = 0.40869646137807425, disc_loss = 0.04187808030500736
Trained batch 164 in epoch 4, gen_loss = 0.40897568211410984, disc_loss = 0.04167343242884134
Trained batch 165 in epoch 4, gen_loss = 0.40907948167927294, disc_loss = 0.041485698015642274
Trained batch 166 in epoch 4, gen_loss = 0.4094278983727187, disc_loss = 0.041312410119742515
Trained batch 167 in epoch 4, gen_loss = 0.40973519604830516, disc_loss = 0.04114712440752469
Trained batch 168 in epoch 4, gen_loss = 0.4096245991407767, disc_loss = 0.04095697854562889
Trained batch 169 in epoch 4, gen_loss = 0.4099230524371652, disc_loss = 0.04083639469600337
Trained batch 170 in epoch 4, gen_loss = 0.40980085068278843, disc_loss = 0.04061841304490223
Trained batch 171 in epoch 4, gen_loss = 0.41039337581673335, disc_loss = 0.04041052856455492
Trained batch 172 in epoch 4, gen_loss = 0.410604196132263, disc_loss = 0.04020727221111126
Trained batch 173 in epoch 4, gen_loss = 0.41073231262037124, disc_loss = 0.04003508429540771
Trained batch 174 in epoch 4, gen_loss = 0.41064830149923054, disc_loss = 0.039888085056362405
Trained batch 175 in epoch 4, gen_loss = 0.41109277426519175, disc_loss = 0.03970922709479716
Trained batch 176 in epoch 4, gen_loss = 0.41106742839355254, disc_loss = 0.039562089925126755
Trained batch 177 in epoch 4, gen_loss = 0.41112675777312074, disc_loss = 0.03956049680579035
Trained batch 178 in epoch 4, gen_loss = 0.41098670203592524, disc_loss = 0.03942683717761418
Trained batch 179 in epoch 4, gen_loss = 0.4110734225975143, disc_loss = 0.03929450355547791
Trained batch 180 in epoch 4, gen_loss = 0.4106892378620021, disc_loss = 0.03914311776601437
Trained batch 181 in epoch 4, gen_loss = 0.4106202225436221, disc_loss = 0.03895509465479875
Trained batch 182 in epoch 4, gen_loss = 0.4106045075453044, disc_loss = 0.038775425077329485
Trained batch 183 in epoch 4, gen_loss = 0.4107165598998899, disc_loss = 0.03859200864478581
Trained batch 184 in epoch 4, gen_loss = 0.4104368573910481, disc_loss = 0.038431618290928164
Trained batch 185 in epoch 4, gen_loss = 0.4105879867910057, disc_loss = 0.03825460861171646
Trained batch 186 in epoch 4, gen_loss = 0.4110894721140836, disc_loss = 0.03808900114412813
Trained batch 187 in epoch 4, gen_loss = 0.4110565778422863, disc_loss = 0.03801107497890777
Trained batch 188 in epoch 4, gen_loss = 0.410411147371171, disc_loss = 0.03802041441483039
Trained batch 189 in epoch 4, gen_loss = 0.41034777305628123, disc_loss = 0.03877404834217343
Trained batch 190 in epoch 4, gen_loss = 0.4101652303291241, disc_loss = 0.03892921203996069
Trained batch 191 in epoch 4, gen_loss = 0.41002086984614533, disc_loss = 0.03886257466244084
Trained batch 192 in epoch 4, gen_loss = 0.4102945096134522, disc_loss = 0.03883294797010257
Trained batch 193 in epoch 4, gen_loss = 0.41041416728619445, disc_loss = 0.03893672345691005
Trained batch 194 in epoch 4, gen_loss = 0.4099740303479708, disc_loss = 0.03886702399915801
Trained batch 195 in epoch 4, gen_loss = 0.4096228481859577, disc_loss = 0.038986352701167744
Trained batch 196 in epoch 4, gen_loss = 0.40988192900183235, disc_loss = 0.03887632378698492
Trained batch 197 in epoch 4, gen_loss = 0.4100117654812456, disc_loss = 0.03881392690160246
Trained batch 198 in epoch 4, gen_loss = 0.40977219391108755, disc_loss = 0.03897793525619311
Trained batch 199 in epoch 4, gen_loss = 0.4100306236743927, disc_loss = 0.04059287430834956
Trained batch 200 in epoch 4, gen_loss = 0.4097434973242271, disc_loss = 0.04053056950041496
Trained batch 201 in epoch 4, gen_loss = 0.4096056056199687, disc_loss = 0.04084860760428122
Trained batch 202 in epoch 4, gen_loss = 0.4098003707789435, disc_loss = 0.04103465971142384
Trained batch 203 in epoch 4, gen_loss = 0.40961502974524217, disc_loss = 0.04090236809090985
Trained batch 204 in epoch 4, gen_loss = 0.4092537091999519, disc_loss = 0.040822773159867744
Trained batch 205 in epoch 4, gen_loss = 0.409256878263742, disc_loss = 0.04071788351137408
Trained batch 206 in epoch 4, gen_loss = 0.40926276327331285, disc_loss = 0.040582221488418856
Trained batch 207 in epoch 4, gen_loss = 0.40936852576067817, disc_loss = 0.04056443087868571
Trained batch 208 in epoch 4, gen_loss = 0.40981203816724165, disc_loss = 0.0407933252362276
Trained batch 209 in epoch 4, gen_loss = 0.4097896083479836, disc_loss = 0.04098098242677571
Trained batch 210 in epoch 4, gen_loss = 0.41002982515859376, disc_loss = 0.041866461460597776
Trained batch 211 in epoch 4, gen_loss = 0.4097597790214251, disc_loss = 0.04258643076777072
Trained batch 212 in epoch 4, gen_loss = 0.4100734879713103, disc_loss = 0.043114279218656425
Trained batch 213 in epoch 4, gen_loss = 0.4099061282995705, disc_loss = 0.04325679839462494
Trained batch 214 in epoch 4, gen_loss = 0.4097371016823968, disc_loss = 0.0433987813644371
Trained batch 215 in epoch 4, gen_loss = 0.4099010666487394, disc_loss = 0.04327869868979582
Trained batch 216 in epoch 4, gen_loss = 0.4097339394180456, disc_loss = 0.04400313791630077
Trained batch 217 in epoch 4, gen_loss = 0.4092859889662594, disc_loss = 0.04433146787384405
Trained batch 218 in epoch 4, gen_loss = 0.4088634214444792, disc_loss = 0.044216427851051565
Trained batch 219 in epoch 4, gen_loss = 0.4087460108778693, disc_loss = 0.04410035381707447
Trained batch 220 in epoch 4, gen_loss = 0.40855901381548715, disc_loss = 0.04400794921185804
Trained batch 221 in epoch 4, gen_loss = 0.40844539975797806, disc_loss = 0.04385982777793296
Trained batch 222 in epoch 4, gen_loss = 0.40833233998495366, disc_loss = 0.04384875458022037
Trained batch 223 in epoch 4, gen_loss = 0.4077714141458273, disc_loss = 0.04398213233902685
Trained batch 224 in epoch 4, gen_loss = 0.4076601049635145, disc_loss = 0.04402467312187784
Trained batch 225 in epoch 4, gen_loss = 0.4080818517018208, disc_loss = 0.04420649413682883
Trained batch 226 in epoch 4, gen_loss = 0.4078459143638611, disc_loss = 0.044176523020852045
Trained batch 227 in epoch 4, gen_loss = 0.40762403528941304, disc_loss = 0.044302894718528385
Trained batch 228 in epoch 4, gen_loss = 0.40745378828985723, disc_loss = 0.04471384109339502
Trained batch 229 in epoch 4, gen_loss = 0.4075397207685139, disc_loss = 0.04611698904216451
Trained batch 230 in epoch 4, gen_loss = 0.40747271562035464, disc_loss = 0.04647759825608076
Trained batch 231 in epoch 4, gen_loss = 0.40773128923671, disc_loss = 0.04714077335465218
Trained batch 232 in epoch 4, gen_loss = 0.4074565704288401, disc_loss = 0.047521178143962325
Trained batch 233 in epoch 4, gen_loss = 0.407144958137447, disc_loss = 0.04788998466753202
Trained batch 234 in epoch 4, gen_loss = 0.40738998562731643, disc_loss = 0.04797049757747098
Trained batch 235 in epoch 4, gen_loss = 0.4072000345183631, disc_loss = 0.04816193787195578
Trained batch 236 in epoch 4, gen_loss = 0.40750869693635383, disc_loss = 0.048345621220398115
Trained batch 237 in epoch 4, gen_loss = 0.4076726948764144, disc_loss = 0.04865578020543267
Trained batch 238 in epoch 4, gen_loss = 0.4075168468463371, disc_loss = 0.04918654927122699
Trained batch 239 in epoch 4, gen_loss = 0.4077287989358107, disc_loss = 0.04930785422620829
Trained batch 240 in epoch 4, gen_loss = 0.4075180546871359, disc_loss = 0.04930458054104936
Trained batch 241 in epoch 4, gen_loss = 0.4076810405274068, disc_loss = 0.04942346490584776
Trained batch 242 in epoch 4, gen_loss = 0.4074629342850344, disc_loss = 0.04942385223885776
Trained batch 243 in epoch 4, gen_loss = 0.40735864639282227, disc_loss = 0.04931378895206927
Trained batch 244 in epoch 4, gen_loss = 0.40706357323393527, disc_loss = 0.04985015896453085
Trained batch 245 in epoch 4, gen_loss = 0.4071213149927496, disc_loss = 0.05117090693883204
Trained batch 246 in epoch 4, gen_loss = 0.4074657521991112, disc_loss = 0.05103300902558875
Trained batch 247 in epoch 4, gen_loss = 0.40744033780309463, disc_loss = 0.0516049999963387
Trained batch 248 in epoch 4, gen_loss = 0.4075400159062152, disc_loss = 0.05202617665404925
Trained batch 249 in epoch 4, gen_loss = 0.4070824602842331, disc_loss = 0.05281470583472401
Trained batch 250 in epoch 4, gen_loss = 0.4075197298450774, disc_loss = 0.05337369286240008
Trained batch 251 in epoch 4, gen_loss = 0.40748455765701475, disc_loss = 0.05358354527122593
Trained batch 252 in epoch 4, gen_loss = 0.4072347526022568, disc_loss = 0.053622104184289754
Trained batch 253 in epoch 4, gen_loss = 0.4070639102243063, disc_loss = 0.05348160831481365
Trained batch 254 in epoch 4, gen_loss = 0.40728085134543623, disc_loss = 0.053309050619638726
Trained batch 255 in epoch 4, gen_loss = 0.40696744655724615, disc_loss = 0.05339663031281816
Trained batch 256 in epoch 4, gen_loss = 0.4065234145069864, disc_loss = 0.053466851994257554
Trained batch 257 in epoch 4, gen_loss = 0.4063836194055025, disc_loss = 0.05328411385579424
Trained batch 258 in epoch 4, gen_loss = 0.4064384668950409, disc_loss = 0.05311469479579061
Trained batch 259 in epoch 4, gen_loss = 0.4064055537948242, disc_loss = 0.05295673686599072
Trained batch 260 in epoch 4, gen_loss = 0.4065176011045317, disc_loss = 0.05281955129788097
Trained batch 261 in epoch 4, gen_loss = 0.4064105835579734, disc_loss = 0.05268456997040602
Trained batch 262 in epoch 4, gen_loss = 0.4064817030846846, disc_loss = 0.05262254594697727
Trained batch 263 in epoch 4, gen_loss = 0.4061694358560172, disc_loss = 0.052477302055304986
Trained batch 264 in epoch 4, gen_loss = 0.4061902968388683, disc_loss = 0.05310388052537334
Trained batch 265 in epoch 4, gen_loss = 0.40643739610686336, disc_loss = 0.05480416995539729
Trained batch 266 in epoch 4, gen_loss = 0.4065198956357406, disc_loss = 0.05501395006043216
Trained batch 267 in epoch 4, gen_loss = 0.4062969924798652, disc_loss = 0.055808424947039685
Trained batch 268 in epoch 4, gen_loss = 0.4060856274512621, disc_loss = 0.055841963167811245
Trained batch 269 in epoch 4, gen_loss = 0.40593185071591975, disc_loss = 0.055692109600985765
Trained batch 270 in epoch 4, gen_loss = 0.4059737053084637, disc_loss = 0.0555248983054872
Trained batch 271 in epoch 4, gen_loss = 0.4055230671211201, disc_loss = 0.05544541412296787
Trained batch 272 in epoch 4, gen_loss = 0.4055135768630129, disc_loss = 0.05530530493109463
Trained batch 273 in epoch 4, gen_loss = 0.40585880916919154, disc_loss = 0.05522695203213171
Trained batch 274 in epoch 4, gen_loss = 0.4060553939775987, disc_loss = 0.05517307119359347
Trained batch 275 in epoch 4, gen_loss = 0.40630509963502054, disc_loss = 0.0550239860878218
Trained batch 276 in epoch 4, gen_loss = 0.40621137436116217, disc_loss = 0.05485833629659824
Trained batch 277 in epoch 4, gen_loss = 0.4061757787097272, disc_loss = 0.05470580946764634
Trained batch 278 in epoch 4, gen_loss = 0.4058568861108527, disc_loss = 0.05470524498722165
Trained batch 279 in epoch 4, gen_loss = 0.40610909749354634, disc_loss = 0.05495094622435447
Trained batch 280 in epoch 4, gen_loss = 0.4060748774173845, disc_loss = 0.054957171750430585
Trained batch 281 in epoch 4, gen_loss = 0.40619994530863796, disc_loss = 0.054811744195250596
Trained batch 282 in epoch 4, gen_loss = 0.40631927018030795, disc_loss = 0.05463871673200372
Trained batch 283 in epoch 4, gen_loss = 0.4067302523574359, disc_loss = 0.054532278775939275
Trained batch 284 in epoch 4, gen_loss = 0.4067664141194862, disc_loss = 0.054369000986773976
Trained batch 285 in epoch 4, gen_loss = 0.4067130445183574, disc_loss = 0.05419984220452216
Trained batch 286 in epoch 4, gen_loss = 0.40690862987099624, disc_loss = 0.05403576402451181
Trained batch 287 in epoch 4, gen_loss = 0.40696646128263736, disc_loss = 0.05388384978464779
Trained batch 288 in epoch 4, gen_loss = 0.4069075117267952, disc_loss = 0.0537798728876035
Trained batch 289 in epoch 4, gen_loss = 0.4066887620194205, disc_loss = 0.053644737780318946
Trained batch 290 in epoch 4, gen_loss = 0.4065460881211913, disc_loss = 0.05348463876483341
Trained batch 291 in epoch 4, gen_loss = 0.40665816485065304, disc_loss = 0.053356971466524704
Trained batch 292 in epoch 4, gen_loss = 0.4070829702318732, disc_loss = 0.053198416413001895
Trained batch 293 in epoch 4, gen_loss = 0.40719403002132365, disc_loss = 0.053042537389405474
Trained batch 294 in epoch 4, gen_loss = 0.4073696843648361, disc_loss = 0.052894181564797534
Trained batch 295 in epoch 4, gen_loss = 0.4074845338189924, disc_loss = 0.05272876650230279
Trained batch 296 in epoch 4, gen_loss = 0.40764619244469535, disc_loss = 0.05257496940401643
Trained batch 297 in epoch 4, gen_loss = 0.4076582725416094, disc_loss = 0.05243887645020556
Trained batch 298 in epoch 4, gen_loss = 0.40788543842309294, disc_loss = 0.05235561753006459
Trained batch 299 in epoch 4, gen_loss = 0.40784781793753305, disc_loss = 0.05226854201018189
Trained batch 300 in epoch 4, gen_loss = 0.4077257270432786, disc_loss = 0.05210455670253532
Trained batch 301 in epoch 4, gen_loss = 0.4079978737412699, disc_loss = 0.051952964563033735
Trained batch 302 in epoch 4, gen_loss = 0.40805912558788515, disc_loss = 0.051831827451330505
Trained batch 303 in epoch 4, gen_loss = 0.4079944453153171, disc_loss = 0.0517673009231466
Trained batch 304 in epoch 4, gen_loss = 0.4080417639896518, disc_loss = 0.051633885614268606
Trained batch 305 in epoch 4, gen_loss = 0.4079085437495724, disc_loss = 0.051510555686404794
Trained batch 306 in epoch 4, gen_loss = 0.4079894752572336, disc_loss = 0.051370672309765116
Trained batch 307 in epoch 4, gen_loss = 0.4082175297783567, disc_loss = 0.051222478485569455
Trained batch 308 in epoch 4, gen_loss = 0.40862186074642687, disc_loss = 0.05107327082125066
Trained batch 309 in epoch 4, gen_loss = 0.40863653440629283, disc_loss = 0.0509243211168195
Trained batch 310 in epoch 4, gen_loss = 0.40861024139778407, disc_loss = 0.05078168852116997
Trained batch 311 in epoch 4, gen_loss = 0.4084337613521478, disc_loss = 0.05063409843326857
Trained batch 312 in epoch 4, gen_loss = 0.40853788039554806, disc_loss = 0.05048329860400468
Trained batch 313 in epoch 4, gen_loss = 0.40860592236944066, disc_loss = 0.050337874819969486
Trained batch 314 in epoch 4, gen_loss = 0.4087910218844338, disc_loss = 0.050226680955125225
Trained batch 315 in epoch 4, gen_loss = 0.40891798142390917, disc_loss = 0.050103564690680634
Trained batch 316 in epoch 4, gen_loss = 0.40900262297139933, disc_loss = 0.04996163613671196
Trained batch 317 in epoch 4, gen_loss = 0.4089352029299586, disc_loss = 0.04982381887769081
Trained batch 318 in epoch 4, gen_loss = 0.40917945674220596, disc_loss = 0.049686067498239415
Trained batch 319 in epoch 4, gen_loss = 0.40939241647720337, disc_loss = 0.0495522023018566
Trained batch 320 in epoch 4, gen_loss = 0.40950342919967625, disc_loss = 0.04944032859608438
Trained batch 321 in epoch 4, gen_loss = 0.40937922228567347, disc_loss = 0.049312770052853484
Trained batch 322 in epoch 4, gen_loss = 0.4093294035724073, disc_loss = 0.049204527384575585
Trained batch 323 in epoch 4, gen_loss = 0.4093686879417043, disc_loss = 0.04908534896381797
Trained batch 324 in epoch 4, gen_loss = 0.40937892336111803, disc_loss = 0.04895409513121614
Trained batch 325 in epoch 4, gen_loss = 0.4096388591030624, disc_loss = 0.04883421449122116
Trained batch 326 in epoch 4, gen_loss = 0.4096553452335731, disc_loss = 0.048701008139548405
Trained batch 327 in epoch 4, gen_loss = 0.40987488600175553, disc_loss = 0.04858615844107301
Trained batch 328 in epoch 4, gen_loss = 0.40979919670925313, disc_loss = 0.048452329864346146
Trained batch 329 in epoch 4, gen_loss = 0.4096936105778723, disc_loss = 0.048431904128555095
Trained batch 330 in epoch 4, gen_loss = 0.4099781930086476, disc_loss = 0.0483068102714676
Trained batch 331 in epoch 4, gen_loss = 0.409950172416417, disc_loss = 0.048270309308869205
Trained batch 332 in epoch 4, gen_loss = 0.4101085190300469, disc_loss = 0.04814017161743732
Trained batch 333 in epoch 4, gen_loss = 0.41001178440219627, disc_loss = 0.048018029005640374
Trained batch 334 in epoch 4, gen_loss = 0.410083474863821, disc_loss = 0.04792704627946464
Trained batch 335 in epoch 4, gen_loss = 0.4102599678472394, disc_loss = 0.04801814769355891
Trained batch 336 in epoch 4, gen_loss = 0.4100878289085467, disc_loss = 0.04833993511495543
Trained batch 337 in epoch 4, gen_loss = 0.4101687562183516, disc_loss = 0.04871160022434971
Trained batch 338 in epoch 4, gen_loss = 0.40998433314945143, disc_loss = 0.048621813842208074
Trained batch 339 in epoch 4, gen_loss = 0.41008512903662286, disc_loss = 0.04855273519505692
Trained batch 340 in epoch 4, gen_loss = 0.40993888960206265, disc_loss = 0.04842361007595866
Trained batch 341 in epoch 4, gen_loss = 0.41009264042851523, disc_loss = 0.04836453537712669
Trained batch 342 in epoch 4, gen_loss = 0.41019026226969574, disc_loss = 0.048346061867718795
Trained batch 343 in epoch 4, gen_loss = 0.4102543802975222, disc_loss = 0.048234741003144274
Trained batch 344 in epoch 4, gen_loss = 0.41043430471765824, disc_loss = 0.04832812583856824
Trained batch 345 in epoch 4, gen_loss = 0.41023983870972097, disc_loss = 0.048730619698547556
Trained batch 346 in epoch 4, gen_loss = 0.4103194700194367, disc_loss = 0.0489054408718856
Trained batch 347 in epoch 4, gen_loss = 0.4103879947429416, disc_loss = 0.04886478815634532
Trained batch 348 in epoch 4, gen_loss = 0.41042728564117564, disc_loss = 0.04876784709172809
Trained batch 349 in epoch 4, gen_loss = 0.4106446411779949, disc_loss = 0.04871129390916654
Trained batch 350 in epoch 4, gen_loss = 0.4104340695417844, disc_loss = 0.048835256877235875
Trained batch 351 in epoch 4, gen_loss = 0.41069079452956264, disc_loss = 0.049462729340038175
Trained batch 352 in epoch 4, gen_loss = 0.41072180436623335, disc_loss = 0.0494111084218319
Trained batch 353 in epoch 4, gen_loss = 0.4104080480539193, disc_loss = 0.049326242347600434
Trained batch 354 in epoch 4, gen_loss = 0.4104025703080943, disc_loss = 0.04924885070239994
Trained batch 355 in epoch 4, gen_loss = 0.41037488854333254, disc_loss = 0.04912467440459459
Trained batch 356 in epoch 4, gen_loss = 0.41047451876792584, disc_loss = 0.049024490857397726
Trained batch 357 in epoch 4, gen_loss = 0.41036484427958225, disc_loss = 0.048907966052530616
Trained batch 358 in epoch 4, gen_loss = 0.41054547007369463, disc_loss = 0.04891339367421598
Trained batch 359 in epoch 4, gen_loss = 0.41077505639857714, disc_loss = 0.048926123745170316
Trained batch 360 in epoch 4, gen_loss = 0.41077682483229283, disc_loss = 0.04886422559768581
Trained batch 361 in epoch 4, gen_loss = 0.41086701093786987, disc_loss = 0.048842063231537766
Trained batch 362 in epoch 4, gen_loss = 0.41097323575952494, disc_loss = 0.05005852952625182
Trained batch 363 in epoch 4, gen_loss = 0.41076764243317176, disc_loss = 0.05011445390966281
Trained batch 364 in epoch 4, gen_loss = 0.4107505593397846, disc_loss = 0.05031877691436508
Trained batch 365 in epoch 4, gen_loss = 0.41080871338401337, disc_loss = 0.05020728006149779
Trained batch 366 in epoch 4, gen_loss = 0.4110692023256494, disc_loss = 0.0501047511387119
Trained batch 367 in epoch 4, gen_loss = 0.4110924800776917, disc_loss = 0.05001301763442588
Trained batch 368 in epoch 4, gen_loss = 0.41086745892113785, disc_loss = 0.05000172556077602
Trained batch 369 in epoch 4, gen_loss = 0.410694048775209, disc_loss = 0.04999338643801575
Trained batch 370 in epoch 4, gen_loss = 0.41048175875710025, disc_loss = 0.05029529704262987
Trained batch 371 in epoch 4, gen_loss = 0.41032061629718347, disc_loss = 0.050947463656875795
Trained batch 372 in epoch 4, gen_loss = 0.41025107116226217, disc_loss = 0.05089939207502768
Trained batch 373 in epoch 4, gen_loss = 0.41022219560681816, disc_loss = 0.05080942255395021
Trained batch 374 in epoch 4, gen_loss = 0.41012647541364033, disc_loss = 0.050748827597747244
Trained batch 375 in epoch 4, gen_loss = 0.4099124388650377, disc_loss = 0.05080886298240697
Trained batch 376 in epoch 4, gen_loss = 0.4098602992628234, disc_loss = 0.05084675959674567
Trained batch 377 in epoch 4, gen_loss = 0.41003834641484355, disc_loss = 0.050768983625516136
Trained batch 378 in epoch 4, gen_loss = 0.4102751946858177, disc_loss = 0.0508911324023591
Trained batch 379 in epoch 4, gen_loss = 0.41004515384372914, disc_loss = 0.051216802178685995
Trained batch 380 in epoch 4, gen_loss = 0.4102022015829412, disc_loss = 0.05110501625215796
Trained batch 381 in epoch 4, gen_loss = 0.410291394014009, disc_loss = 0.051073136238420275
Trained batch 382 in epoch 4, gen_loss = 0.41012170996429403, disc_loss = 0.05101410973714981
Trained batch 383 in epoch 4, gen_loss = 0.4098995743940274, disc_loss = 0.050961973869561916
Trained batch 384 in epoch 4, gen_loss = 0.4100229611644497, disc_loss = 0.0509236304464375
Trained batch 385 in epoch 4, gen_loss = 0.41020941317390286, disc_loss = 0.05090855780646321
Trained batch 386 in epoch 4, gen_loss = 0.4102865569197238, disc_loss = 0.05079594014323189
Trained batch 387 in epoch 4, gen_loss = 0.41019683592405515, disc_loss = 0.0507509511722655
Trained batch 388 in epoch 4, gen_loss = 0.4101392733253979, disc_loss = 0.051145834216230326
Trained batch 389 in epoch 4, gen_loss = 0.4101491112739612, disc_loss = 0.05194362959323021
Trained batch 390 in epoch 4, gen_loss = 0.41017845097710104, disc_loss = 0.05185786131150125
Trained batch 391 in epoch 4, gen_loss = 0.4100903419359606, disc_loss = 0.05188623121559468
Trained batch 392 in epoch 4, gen_loss = 0.41006243031746864, disc_loss = 0.051779818465179615
Trained batch 393 in epoch 4, gen_loss = 0.41013104389161625, disc_loss = 0.051767230206429204
Trained batch 394 in epoch 4, gen_loss = 0.4100459448898895, disc_loss = 0.05189237336427728
Trained batch 395 in epoch 4, gen_loss = 0.4099814723988976, disc_loss = 0.05185377805945322
Trained batch 396 in epoch 4, gen_loss = 0.4099040642493318, disc_loss = 0.051791559902467865
Trained batch 397 in epoch 4, gen_loss = 0.40987882025577316, disc_loss = 0.051831428642529785
Trained batch 398 in epoch 4, gen_loss = 0.410315584942213, disc_loss = 0.05211434121894881
Trained batch 399 in epoch 4, gen_loss = 0.4100450650602579, disc_loss = 0.05211321710376069
Trained batch 400 in epoch 4, gen_loss = 0.409961923176511, disc_loss = 0.052049170276080435
Trained batch 401 in epoch 4, gen_loss = 0.40998422536090834, disc_loss = 0.05202253746443349
Trained batch 402 in epoch 4, gen_loss = 0.40985583881882226, disc_loss = 0.051937054170217024
Trained batch 403 in epoch 4, gen_loss = 0.4099474268236963, disc_loss = 0.05186350871163356
Trained batch 404 in epoch 4, gen_loss = 0.4100829670458664, disc_loss = 0.05179364485551178
Trained batch 405 in epoch 4, gen_loss = 0.41026620133757, disc_loss = 0.05171441625152242
Trained batch 406 in epoch 4, gen_loss = 0.41024378066566713, disc_loss = 0.051641526458103035
Trained batch 407 in epoch 4, gen_loss = 0.4101773130104822, disc_loss = 0.05163273085867438
Trained batch 408 in epoch 4, gen_loss = 0.41041013525575765, disc_loss = 0.051517588664802626
Trained batch 409 in epoch 4, gen_loss = 0.41044511889539115, disc_loss = 0.05142594427097498
Trained batch 410 in epoch 4, gen_loss = 0.41064612056217054, disc_loss = 0.05133172815071913
Trained batch 411 in epoch 4, gen_loss = 0.410793511178887, disc_loss = 0.05125960620183462
Trained batch 412 in epoch 4, gen_loss = 0.4108343546529082, disc_loss = 0.05114398568363513
Trained batch 413 in epoch 4, gen_loss = 0.4109988171553266, disc_loss = 0.05117994176160886
Trained batch 414 in epoch 4, gen_loss = 0.41077043507472577, disc_loss = 0.051530363868518045
Trained batch 415 in epoch 4, gen_loss = 0.4109537534129161, disc_loss = 0.051941632794646114
Trained batch 416 in epoch 4, gen_loss = 0.41100339623663923, disc_loss = 0.05189167623289769
Trained batch 417 in epoch 4, gen_loss = 0.41108599333671864, disc_loss = 0.0519104382406439
Trained batch 418 in epoch 4, gen_loss = 0.41110600100781297, disc_loss = 0.05180075493149975
Trained batch 419 in epoch 4, gen_loss = 0.4110904039371581, disc_loss = 0.05171820672694594
Trained batch 420 in epoch 4, gen_loss = 0.4108772950330993, disc_loss = 0.0516138778183158
Trained batch 421 in epoch 4, gen_loss = 0.41080850920688483, disc_loss = 0.051555962528000585
Trained batch 422 in epoch 4, gen_loss = 0.4109290485968263, disc_loss = 0.0515911640878987
Trained batch 423 in epoch 4, gen_loss = 0.4109207623690929, disc_loss = 0.05155396033715422
Trained batch 424 in epoch 4, gen_loss = 0.4109334480061251, disc_loss = 0.05151814115507638
Trained batch 425 in epoch 4, gen_loss = 0.41110239447282515, disc_loss = 0.051465097951436056
Trained batch 426 in epoch 4, gen_loss = 0.4112502934642363, disc_loss = 0.05155692683681148
Trained batch 427 in epoch 4, gen_loss = 0.41106483890352963, disc_loss = 0.05168876887155505
Trained batch 428 in epoch 4, gen_loss = 0.41099844945894254, disc_loss = 0.05164444757113125
Trained batch 429 in epoch 4, gen_loss = 0.41087085646252297, disc_loss = 0.051557036693922656
Trained batch 430 in epoch 4, gen_loss = 0.41088158811881204, disc_loss = 0.05145521971381976
Trained batch 431 in epoch 4, gen_loss = 0.4109934524943431, disc_loss = 0.051362869311425904
Trained batch 432 in epoch 4, gen_loss = 0.41114083200899615, disc_loss = 0.051258442270640484
Trained batch 433 in epoch 4, gen_loss = 0.41124122510857297, disc_loss = 0.05115461043910497
Trained batch 434 in epoch 4, gen_loss = 0.4112126083209597, disc_loss = 0.051073918748518514
Trained batch 435 in epoch 4, gen_loss = 0.41119896155705143, disc_loss = 0.05096865790776498
Trained batch 436 in epoch 4, gen_loss = 0.41118620591796506, disc_loss = 0.05089268088980111
Trained batch 437 in epoch 4, gen_loss = 0.41128802986722013, disc_loss = 0.05102042669056145
Trained batch 438 in epoch 4, gen_loss = 0.41141654187834614, disc_loss = 0.05136614833196842
Trained batch 439 in epoch 4, gen_loss = 0.41130002974109214, disc_loss = 0.05127119654577903
Trained batch 440 in epoch 4, gen_loss = 0.4112210362946906, disc_loss = 0.05119659345968713
Trained batch 441 in epoch 4, gen_loss = 0.41108320815261135, disc_loss = 0.05111112529243347
Trained batch 442 in epoch 4, gen_loss = 0.4112039788985629, disc_loss = 0.05101731978987531
Trained batch 443 in epoch 4, gen_loss = 0.41117978666548255, disc_loss = 0.05092265716384727
Trained batch 444 in epoch 4, gen_loss = 0.41114342788631997, disc_loss = 0.050846429958186126
Trained batch 445 in epoch 4, gen_loss = 0.4111169160347883, disc_loss = 0.05076044694533062
Trained batch 446 in epoch 4, gen_loss = 0.4110910838482364, disc_loss = 0.050859179541518626
Trained batch 447 in epoch 4, gen_loss = 0.4108774356677064, disc_loss = 0.051034685658773275
Trained batch 448 in epoch 4, gen_loss = 0.41103499218456463, disc_loss = 0.05106682615989367
Trained batch 449 in epoch 4, gen_loss = 0.41112193094359506, disc_loss = 0.050974917016509504
Trained batch 450 in epoch 4, gen_loss = 0.4111930118696124, disc_loss = 0.05087950375724064
Trained batch 451 in epoch 4, gen_loss = 0.4111313314828198, disc_loss = 0.05077643672198024
Trained batch 452 in epoch 4, gen_loss = 0.41116267554544195, disc_loss = 0.05067988223895825
Trained batch 453 in epoch 4, gen_loss = 0.41112011152479616, disc_loss = 0.05057493975029085
Trained batch 454 in epoch 4, gen_loss = 0.41098571354216273, disc_loss = 0.05047146636214885
Trained batch 455 in epoch 4, gen_loss = 0.4110091596580388, disc_loss = 0.050374006948499174
Trained batch 456 in epoch 4, gen_loss = 0.41120668521856063, disc_loss = 0.050274376349861954
Trained batch 457 in epoch 4, gen_loss = 0.41117404674598745, disc_loss = 0.050174963304683504
Trained batch 458 in epoch 4, gen_loss = 0.4111402377583622, disc_loss = 0.05010294226608959
Testing Epoch 4
Training Epoch 5
Trained batch 0 in epoch 5, gen_loss = 0.3628470003604889, disc_loss = 0.010821607895195484
Trained batch 1 in epoch 5, gen_loss = 0.42583687603473663, disc_loss = 0.011708998586982489
Trained batch 2 in epoch 5, gen_loss = 0.4287269314130147, disc_loss = 0.009390966035425663
Trained batch 3 in epoch 5, gen_loss = 0.43310077488422394, disc_loss = 0.01041369722224772
Trained batch 4 in epoch 5, gen_loss = 0.4288709282875061, disc_loss = 0.009553608018904924
Trained batch 5 in epoch 5, gen_loss = 0.41367052495479584, disc_loss = 0.009886847110465169
Trained batch 6 in epoch 5, gen_loss = 0.41519560132707867, disc_loss = 0.009524610226175614
Trained batch 7 in epoch 5, gen_loss = 0.4199877381324768, disc_loss = 0.009468609292525798
Trained batch 8 in epoch 5, gen_loss = 0.42126137349340653, disc_loss = 0.010991192784988217
Trained batch 9 in epoch 5, gen_loss = 0.4109379470348358, disc_loss = 0.015500423172488809
Trained batch 10 in epoch 5, gen_loss = 0.41322163018313324, disc_loss = 0.014439556874673475
Trained batch 11 in epoch 5, gen_loss = 0.4158754274249077, disc_loss = 0.015404468363461396
Trained batch 12 in epoch 5, gen_loss = 0.419771474141341, disc_loss = 0.018252288457006216
Trained batch 13 in epoch 5, gen_loss = 0.4155933601515634, disc_loss = 0.028472007884244834
Trained batch 14 in epoch 5, gen_loss = 0.4134870767593384, disc_loss = 0.034648327995091675
Trained batch 15 in epoch 5, gen_loss = 0.4165327828377485, disc_loss = 0.03679446593741886
Trained batch 16 in epoch 5, gen_loss = 0.4249345011570874, disc_loss = 0.03676448211840847
Trained batch 17 in epoch 5, gen_loss = 0.4291950116554896, disc_loss = 0.03578381931098799
Trained batch 18 in epoch 5, gen_loss = 0.4275577005587126, disc_loss = 0.03431640180612081
Trained batch 19 in epoch 5, gen_loss = 0.4257033199071884, disc_loss = 0.03373083777260035
Trained batch 20 in epoch 5, gen_loss = 0.4288657108942668, disc_loss = 0.032591144931280895
Trained batch 21 in epoch 5, gen_loss = 0.42694322764873505, disc_loss = 0.032880346015603704
Trained batch 22 in epoch 5, gen_loss = 0.42694631996362103, disc_loss = 0.03279478611100627
Trained batch 23 in epoch 5, gen_loss = 0.4282360759874185, disc_loss = 0.03843933365230138
Trained batch 24 in epoch 5, gen_loss = 0.4236339771747589, disc_loss = 0.037283001821488145
Trained batch 25 in epoch 5, gen_loss = 0.4261661091676125, disc_loss = 0.05650809032914157
Trained batch 26 in epoch 5, gen_loss = 0.4236340268894478, disc_loss = 0.05923073681899243
Trained batch 27 in epoch 5, gen_loss = 0.4202356551374708, disc_loss = 0.06370692884749067
Trained batch 28 in epoch 5, gen_loss = 0.41889717661101245, disc_loss = 0.06248835639642744
Trained batch 29 in epoch 5, gen_loss = 0.41752105951309204, disc_loss = 0.06136672172384958
Trained batch 30 in epoch 5, gen_loss = 0.41381024545238865, disc_loss = 0.059929334213055914
Trained batch 31 in epoch 5, gen_loss = 0.41387810558080673, disc_loss = 0.0587998218688881
Trained batch 32 in epoch 5, gen_loss = 0.41694221352085925, disc_loss = 0.058695107007004095
Trained batch 33 in epoch 5, gen_loss = 0.41499995133456064, disc_loss = 0.05758418541346841
Trained batch 34 in epoch 5, gen_loss = 0.41631820031574795, disc_loss = 0.05665640191041998
Trained batch 35 in epoch 5, gen_loss = 0.41686128576596576, disc_loss = 0.05541272475642876
Trained batch 36 in epoch 5, gen_loss = 0.4168838810276341, disc_loss = 0.05457700208785969
Trained batch 37 in epoch 5, gen_loss = 0.4158717378189689, disc_loss = 0.05344774175778424
Trained batch 38 in epoch 5, gen_loss = 0.4161454668411842, disc_loss = 0.05235088782576032
Trained batch 39 in epoch 5, gen_loss = 0.41566269993782046, disc_loss = 0.0513889929628931
Trained batch 40 in epoch 5, gen_loss = 0.41519469749636767, disc_loss = 0.05064284559566437
Trained batch 41 in epoch 5, gen_loss = 0.4159201830625534, disc_loss = 0.04984671324269757
Trained batch 42 in epoch 5, gen_loss = 0.4147073058194892, disc_loss = 0.048815819857165564
Trained batch 43 in epoch 5, gen_loss = 0.416142112152143, disc_loss = 0.04788830119650811
Trained batch 44 in epoch 5, gen_loss = 0.41523883210288154, disc_loss = 0.04717680953650011
Trained batch 45 in epoch 5, gen_loss = 0.4157177611537602, disc_loss = 0.04623461273782279
Trained batch 46 in epoch 5, gen_loss = 0.4160982002603247, disc_loss = 0.04626087965245577
Trained batch 47 in epoch 5, gen_loss = 0.4162059761583805, disc_loss = 0.04561887012096122
Trained batch 48 in epoch 5, gen_loss = 0.4173731061877037, disc_loss = 0.04518911521881819
Trained batch 49 in epoch 5, gen_loss = 0.4174554938077927, disc_loss = 0.04458316214382649
Trained batch 50 in epoch 5, gen_loss = 0.4166800064199111, disc_loss = 0.04462912496106297
Trained batch 51 in epoch 5, gen_loss = 0.4171293102777921, disc_loss = 0.044192223594738886
Trained batch 52 in epoch 5, gen_loss = 0.41742076401440603, disc_loss = 0.043536274641189934
Trained batch 53 in epoch 5, gen_loss = 0.41670456142337237, disc_loss = 0.04295223899599579
Trained batch 54 in epoch 5, gen_loss = 0.41595933545719493, disc_loss = 0.04233826962722973
Trained batch 55 in epoch 5, gen_loss = 0.41535011891807827, disc_loss = 0.04182568573326405
Trained batch 56 in epoch 5, gen_loss = 0.41488879239350035, disc_loss = 0.04118584042513057
Trained batch 57 in epoch 5, gen_loss = 0.4145637647858981, disc_loss = 0.04069568287452747
Trained batch 58 in epoch 5, gen_loss = 0.4146548681339975, disc_loss = 0.04009103959710416
Trained batch 59 in epoch 5, gen_loss = 0.41450727929671605, disc_loss = 0.03953065761985878
Trained batch 60 in epoch 5, gen_loss = 0.415879983882435, disc_loss = 0.039294359213138216
Trained batch 61 in epoch 5, gen_loss = 0.41581004473470873, disc_loss = 0.03916942744305538
Trained batch 62 in epoch 5, gen_loss = 0.4179750945832994, disc_loss = 0.03927092220161169
Trained batch 63 in epoch 5, gen_loss = 0.41730655264109373, disc_loss = 0.038851876990520395
Trained batch 64 in epoch 5, gen_loss = 0.41928761097101064, disc_loss = 0.038347996577907065
Trained batch 65 in epoch 5, gen_loss = 0.4187301794687907, disc_loss = 0.03788703133239213
Trained batch 66 in epoch 5, gen_loss = 0.4178430811682744, disc_loss = 0.038227411855790594
Trained batch 67 in epoch 5, gen_loss = 0.4201233693782021, disc_loss = 0.03982606843141291
Trained batch 68 in epoch 5, gen_loss = 0.42133587685184204, disc_loss = 0.03946853638964071
Trained batch 69 in epoch 5, gen_loss = 0.42087860320295606, disc_loss = 0.03908303197074149
Trained batch 70 in epoch 5, gen_loss = 0.4206030868308645, disc_loss = 0.03916312626261317
Trained batch 71 in epoch 5, gen_loss = 0.4219605637093385, disc_loss = 0.03884340065350342
Trained batch 72 in epoch 5, gen_loss = 0.4227589495377998, disc_loss = 0.03859814953645819
Trained batch 73 in epoch 5, gen_loss = 0.4221448833877976, disc_loss = 0.038283961076239076
Trained batch 74 in epoch 5, gen_loss = 0.42239264567693074, disc_loss = 0.038183069409181675
Trained batch 75 in epoch 5, gen_loss = 0.42200681371124166, disc_loss = 0.03789414257717956
Trained batch 76 in epoch 5, gen_loss = 0.4217189411064247, disc_loss = 0.037537484157636955
Trained batch 77 in epoch 5, gen_loss = 0.42321151877060914, disc_loss = 0.03720911882984906
Trained batch 78 in epoch 5, gen_loss = 0.4228743578814253, disc_loss = 0.0371042079928838
Trained batch 79 in epoch 5, gen_loss = 0.422076615691185, disc_loss = 0.03716610909323208
Trained batch 80 in epoch 5, gen_loss = 0.4228911145969673, disc_loss = 0.038213564077231255
Trained batch 81 in epoch 5, gen_loss = 0.4225165934824362, disc_loss = 0.03893892800367278
Trained batch 82 in epoch 5, gen_loss = 0.4231157428528889, disc_loss = 0.038563729353608134
Trained batch 83 in epoch 5, gen_loss = 0.4240145544920649, disc_loss = 0.0382834703639327
Trained batch 84 in epoch 5, gen_loss = 0.4238212420659907, disc_loss = 0.03791379706167123
Trained batch 85 in epoch 5, gen_loss = 0.4236673695403476, disc_loss = 0.03797569521161359
Trained batch 86 in epoch 5, gen_loss = 0.4240601436160077, disc_loss = 0.037789133313144076
Trained batch 87 in epoch 5, gen_loss = 0.4248122349381447, disc_loss = 0.03751896940891377
Trained batch 88 in epoch 5, gen_loss = 0.4253647163342894, disc_loss = 0.03716196226521155
Trained batch 89 in epoch 5, gen_loss = 0.4249919656250212, disc_loss = 0.037328062682516046
Trained batch 90 in epoch 5, gen_loss = 0.42420842457603625, disc_loss = 0.03869668670653642
Trained batch 91 in epoch 5, gen_loss = 0.42348628912283026, disc_loss = 0.04023338018147194
Trained batch 92 in epoch 5, gen_loss = 0.4241376628157913, disc_loss = 0.0399826880223969
Trained batch 93 in epoch 5, gen_loss = 0.424050842510893, disc_loss = 0.03986792032547454
Trained batch 94 in epoch 5, gen_loss = 0.4240515702649167, disc_loss = 0.03998845549006211
Trained batch 95 in epoch 5, gen_loss = 0.42407983634620905, disc_loss = 0.040076347921664514
Trained batch 96 in epoch 5, gen_loss = 0.42337233473345176, disc_loss = 0.04048971155869592
Trained batch 97 in epoch 5, gen_loss = 0.42430010711660193, disc_loss = 0.042843938329998325
Trained batch 98 in epoch 5, gen_loss = 0.4230929905115956, disc_loss = 0.043050075871775846
Trained batch 99 in epoch 5, gen_loss = 0.42222683370113373, disc_loss = 0.043014939576387405
Trained batch 100 in epoch 5, gen_loss = 0.4219149067850396, disc_loss = 0.04309677303132444
Trained batch 101 in epoch 5, gen_loss = 0.42207330027047324, disc_loss = 0.04307304180282004
Trained batch 102 in epoch 5, gen_loss = 0.42220077873433676, disc_loss = 0.042768313459039316
Trained batch 103 in epoch 5, gen_loss = 0.42208209920388, disc_loss = 0.042760624684608325
Trained batch 104 in epoch 5, gen_loss = 0.42203764149120876, disc_loss = 0.04248333437634366
Trained batch 105 in epoch 5, gen_loss = 0.4216772998278996, disc_loss = 0.042262000743440296
Trained batch 106 in epoch 5, gen_loss = 0.4214024791650683, disc_loss = 0.0425655991100123
Trained batch 107 in epoch 5, gen_loss = 0.42090709866197024, disc_loss = 0.044338467384309126
Trained batch 108 in epoch 5, gen_loss = 0.4210190491391978, disc_loss = 0.0460178514669111
Trained batch 109 in epoch 5, gen_loss = 0.4210637545043772, disc_loss = 0.04576126558028839
Trained batch 110 in epoch 5, gen_loss = 0.4209576412901148, disc_loss = 0.045699927695766765
Trained batch 111 in epoch 5, gen_loss = 0.419622467564685, disc_loss = 0.0456866636356738
Trained batch 112 in epoch 5, gen_loss = 0.41993599602606446, disc_loss = 0.04539619922736841
Trained batch 113 in epoch 5, gen_loss = 0.4196268848159857, disc_loss = 0.04531371939045034
Trained batch 114 in epoch 5, gen_loss = 0.4195645739202914, disc_loss = 0.045455385412534945
Trained batch 115 in epoch 5, gen_loss = 0.42037405767317476, disc_loss = 0.047977581997562586
Trained batch 116 in epoch 5, gen_loss = 0.41984434209318244, disc_loss = 0.04788423577148435
Trained batch 117 in epoch 5, gen_loss = 0.4198719556048765, disc_loss = 0.04772554869147933
Trained batch 118 in epoch 5, gen_loss = 0.4203055483453414, disc_loss = 0.04737762911166964
Trained batch 119 in epoch 5, gen_loss = 0.42013439734776814, disc_loss = 0.047114003511766596
Trained batch 120 in epoch 5, gen_loss = 0.41990356159604286, disc_loss = 0.046910996140896784
Trained batch 121 in epoch 5, gen_loss = 0.4193517897949844, disc_loss = 0.04732583156313564
Trained batch 122 in epoch 5, gen_loss = 0.41870230048652585, disc_loss = 0.04911591498771819
Trained batch 123 in epoch 5, gen_loss = 0.4191256831249883, disc_loss = 0.0495130738033162
Trained batch 124 in epoch 5, gen_loss = 0.41901575469970703, disc_loss = 0.049456358954310414
Trained batch 125 in epoch 5, gen_loss = 0.4188795778013411, disc_loss = 0.04939012023960314
Trained batch 126 in epoch 5, gen_loss = 0.41906677714483004, disc_loss = 0.04916735184122258
Trained batch 127 in epoch 5, gen_loss = 0.418171331519261, disc_loss = 0.049043668317608535
Trained batch 128 in epoch 5, gen_loss = 0.4177744062834008, disc_loss = 0.04876759353043266
Trained batch 129 in epoch 5, gen_loss = 0.41770079204669364, disc_loss = 0.048447401900417526
Trained batch 130 in epoch 5, gen_loss = 0.41750673528845983, disc_loss = 0.04810953589924078
Trained batch 131 in epoch 5, gen_loss = 0.4179437341112079, disc_loss = 0.04778516576907626
Trained batch 132 in epoch 5, gen_loss = 0.4178531302097149, disc_loss = 0.047465425877502763
Trained batch 133 in epoch 5, gen_loss = 0.4175996368945534, disc_loss = 0.047150236436290974
Trained batch 134 in epoch 5, gen_loss = 0.41743768475673815, disc_loss = 0.04684843059146294
Trained batch 135 in epoch 5, gen_loss = 0.4167048576123574, disc_loss = 0.04672626638442606
Trained batch 136 in epoch 5, gen_loss = 0.4164966118596766, disc_loss = 0.04663720131124349
Trained batch 137 in epoch 5, gen_loss = 0.4166213168182235, disc_loss = 0.04653787180659887
Trained batch 138 in epoch 5, gen_loss = 0.41713024279196487, disc_loss = 0.046435551031110744
Trained batch 139 in epoch 5, gen_loss = 0.4173299027340753, disc_loss = 0.0461338710738346
Trained batch 140 in epoch 5, gen_loss = 0.4173729301344418, disc_loss = 0.04585279829483083
Trained batch 141 in epoch 5, gen_loss = 0.4172579056360352, disc_loss = 0.04568356657269555
Trained batch 142 in epoch 5, gen_loss = 0.41722944608101475, disc_loss = 0.04544483937349145
Trained batch 143 in epoch 5, gen_loss = 0.41769842244684696, disc_loss = 0.045217059500929385
Trained batch 144 in epoch 5, gen_loss = 0.4173559371767373, disc_loss = 0.04523643820450224
Trained batch 145 in epoch 5, gen_loss = 0.41710188903220713, disc_loss = 0.04626649761036651
Trained batch 146 in epoch 5, gen_loss = 0.41736675606292933, disc_loss = 0.046839860426325375
Trained batch 147 in epoch 5, gen_loss = 0.41756256468392705, disc_loss = 0.04659559015134299
Trained batch 148 in epoch 5, gen_loss = 0.41748399962514837, disc_loss = 0.04638722996483713
Trained batch 149 in epoch 5, gen_loss = 0.41755929092566174, disc_loss = 0.04618343121061722
Trained batch 150 in epoch 5, gen_loss = 0.41778889910274786, disc_loss = 0.04599086631903585
Trained batch 151 in epoch 5, gen_loss = 0.4177037883353861, disc_loss = 0.0458162506601136
Trained batch 152 in epoch 5, gen_loss = 0.41804616318808663, disc_loss = 0.045554876869264384
Trained batch 153 in epoch 5, gen_loss = 0.4177672816561414, disc_loss = 0.0454131396330119
Trained batch 154 in epoch 5, gen_loss = 0.4180261311992522, disc_loss = 0.04589430719253517
Trained batch 155 in epoch 5, gen_loss = 0.41833366663792193, disc_loss = 0.046390983783520565
Trained batch 156 in epoch 5, gen_loss = 0.4185288322579329, disc_loss = 0.04628357947893014
Trained batch 157 in epoch 5, gen_loss = 0.4190115674009806, disc_loss = 0.046309850420331276
Trained batch 158 in epoch 5, gen_loss = 0.41872007685637325, disc_loss = 0.04607376500776729
Trained batch 159 in epoch 5, gen_loss = 0.4179606853052974, disc_loss = 0.04592444754671306
Trained batch 160 in epoch 5, gen_loss = 0.41740966046819034, disc_loss = 0.04576476376434291
Trained batch 161 in epoch 5, gen_loss = 0.41729447300787326, disc_loss = 0.04552452207002559
Trained batch 162 in epoch 5, gen_loss = 0.41726874518979545, disc_loss = 0.045271158918304126
Trained batch 163 in epoch 5, gen_loss = 0.41784391697587037, disc_loss = 0.04502167352532014
Trained batch 164 in epoch 5, gen_loss = 0.4178916105718324, disc_loss = 0.044814376942248955
Trained batch 165 in epoch 5, gen_loss = 0.4179025606577655, disc_loss = 0.04461028668973371
Trained batch 166 in epoch 5, gen_loss = 0.41751793919209235, disc_loss = 0.04444893142543064
Trained batch 167 in epoch 5, gen_loss = 0.4175539832739603, disc_loss = 0.04420996142185426
Trained batch 168 in epoch 5, gen_loss = 0.41780168294201236, disc_loss = 0.043970805752647696
Trained batch 169 in epoch 5, gen_loss = 0.41768048861447504, disc_loss = 0.04375617490971789
Trained batch 170 in epoch 5, gen_loss = 0.4181874708125466, disc_loss = 0.04355708090316134
Trained batch 171 in epoch 5, gen_loss = 0.4183106706585995, disc_loss = 0.0433477000847762
Trained batch 172 in epoch 5, gen_loss = 0.418154507530907, disc_loss = 0.043274828903054056
Trained batch 173 in epoch 5, gen_loss = 0.41824652151814823, disc_loss = 0.043070158249452366
Trained batch 174 in epoch 5, gen_loss = 0.4184528885568891, disc_loss = 0.04284334459741201
Trained batch 175 in epoch 5, gen_loss = 0.4185695741325617, disc_loss = 0.04262762742688541
Trained batch 176 in epoch 5, gen_loss = 0.4188072683110749, disc_loss = 0.042409147191161324
Trained batch 177 in epoch 5, gen_loss = 0.4184708178378223, disc_loss = 0.042245642112023876
Trained batch 178 in epoch 5, gen_loss = 0.4186025494969757, disc_loss = 0.04207836003328918
Trained batch 179 in epoch 5, gen_loss = 0.41885206550359727, disc_loss = 0.0419001453788951
Trained batch 180 in epoch 5, gen_loss = 0.418973949403394, disc_loss = 0.04176433299261644
Trained batch 181 in epoch 5, gen_loss = 0.41922397174678006, disc_loss = 0.04156879210527372
Trained batch 182 in epoch 5, gen_loss = 0.41961501367756576, disc_loss = 0.04137445701530478
Trained batch 183 in epoch 5, gen_loss = 0.4196656417587529, disc_loss = 0.04118364628748563
Trained batch 184 in epoch 5, gen_loss = 0.41967477234634193, disc_loss = 0.040989022274073715
Trained batch 185 in epoch 5, gen_loss = 0.419645837237758, disc_loss = 0.04084992902954259
Trained batch 186 in epoch 5, gen_loss = 0.41959497428195364, disc_loss = 0.040707425214350224
Trained batch 187 in epoch 5, gen_loss = 0.4195739048275542, disc_loss = 0.04051900776895754
Trained batch 188 in epoch 5, gen_loss = 0.4194449944786294, disc_loss = 0.04033181867586873
Trained batch 189 in epoch 5, gen_loss = 0.41967757375616777, disc_loss = 0.04014209547129117
Trained batch 190 in epoch 5, gen_loss = 0.4195225252843028, disc_loss = 0.03995569564733674
Trained batch 191 in epoch 5, gen_loss = 0.4192322491047283, disc_loss = 0.0398141201051961
Trained batch 192 in epoch 5, gen_loss = 0.4193535084242648, disc_loss = 0.03963218435374875
Trained batch 193 in epoch 5, gen_loss = 0.4195618486588763, disc_loss = 0.03946266490870069
Trained batch 194 in epoch 5, gen_loss = 0.4200774992123628, disc_loss = 0.03992254381091931
Trained batch 195 in epoch 5, gen_loss = 0.4198174312406657, disc_loss = 0.04178977041619317
Trained batch 196 in epoch 5, gen_loss = 0.42048077413878465, disc_loss = 0.0417575587939263
Trained batch 197 in epoch 5, gen_loss = 0.42045404423366894, disc_loss = 0.04187467312816568
Trained batch 198 in epoch 5, gen_loss = 0.42052315961775466, disc_loss = 0.04176170929760939
Trained batch 199 in epoch 5, gen_loss = 0.42041758105158805, disc_loss = 0.04164994987193495
Trained batch 200 in epoch 5, gen_loss = 0.42040838427211513, disc_loss = 0.04149784790398321
Trained batch 201 in epoch 5, gen_loss = 0.42017285643827795, disc_loss = 0.04133741988680593
Trained batch 202 in epoch 5, gen_loss = 0.42000089681207253, disc_loss = 0.04139877950745116
Trained batch 203 in epoch 5, gen_loss = 0.419919475766958, disc_loss = 0.042232221316582726
Trained batch 204 in epoch 5, gen_loss = 0.41966544447875603, disc_loss = 0.043693401532747395
Trained batch 205 in epoch 5, gen_loss = 0.4201955335232818, disc_loss = 0.044296749872019855
Trained batch 206 in epoch 5, gen_loss = 0.42062349135173116, disc_loss = 0.04413793119039512
Trained batch 207 in epoch 5, gen_loss = 0.4210986506480437, disc_loss = 0.043972562394069076
Trained batch 208 in epoch 5, gen_loss = 0.42081705006686126, disc_loss = 0.04390756682933945
Trained batch 209 in epoch 5, gen_loss = 0.4206235694033759, disc_loss = 0.043744621013424224
Trained batch 210 in epoch 5, gen_loss = 0.4207605229452323, disc_loss = 0.043596782964340886
Trained batch 211 in epoch 5, gen_loss = 0.4203043962424656, disc_loss = 0.04393698929650885
Trained batch 212 in epoch 5, gen_loss = 0.42009745461280357, disc_loss = 0.044345624788616186
Trained batch 213 in epoch 5, gen_loss = 0.4202431500236565, disc_loss = 0.04420321705429075
Trained batch 214 in epoch 5, gen_loss = 0.42061132067857787, disc_loss = 0.04422959298068701
Trained batch 215 in epoch 5, gen_loss = 0.41986258258974113, disc_loss = 0.044272376853903686
Trained batch 216 in epoch 5, gen_loss = 0.4200931393331097, disc_loss = 0.04414432834027
Trained batch 217 in epoch 5, gen_loss = 0.42003775763949125, disc_loss = 0.044415419852925006
Trained batch 218 in epoch 5, gen_loss = 0.4198998834716675, disc_loss = 0.044577930530864895
Trained batch 219 in epoch 5, gen_loss = 0.41980016272176396, disc_loss = 0.04483036441220479
Trained batch 220 in epoch 5, gen_loss = 0.41988861803555383, disc_loss = 0.04616488686581543
Trained batch 221 in epoch 5, gen_loss = 0.4196621762202667, disc_loss = 0.046009013722944365
Trained batch 222 in epoch 5, gen_loss = 0.41945195532165835, disc_loss = 0.04592218782101244
Trained batch 223 in epoch 5, gen_loss = 0.41922280471771955, disc_loss = 0.04575058956730312
Trained batch 224 in epoch 5, gen_loss = 0.4192347268263499, disc_loss = 0.04562638076643149
Trained batch 225 in epoch 5, gen_loss = 0.41928238995307315, disc_loss = 0.04547613217140985
Trained batch 226 in epoch 5, gen_loss = 0.41889508613405774, disc_loss = 0.045353391687775496
Trained batch 227 in epoch 5, gen_loss = 0.4191335796525604, disc_loss = 0.04533214939006588
Trained batch 228 in epoch 5, gen_loss = 0.4190655135952229, disc_loss = 0.04517423090683581
Trained batch 229 in epoch 5, gen_loss = 0.4190962563390317, disc_loss = 0.045000787804146174
Trained batch 230 in epoch 5, gen_loss = 0.41885617672106923, disc_loss = 0.04489761566364275
Trained batch 231 in epoch 5, gen_loss = 0.41887555438382873, disc_loss = 0.044764954897832
Trained batch 232 in epoch 5, gen_loss = 0.41928276496383765, disc_loss = 0.04476121022833647
Trained batch 233 in epoch 5, gen_loss = 0.41933794064908964, disc_loss = 0.044907445386529736
Trained batch 234 in epoch 5, gen_loss = 0.41960480555574947, disc_loss = 0.045002435619368196
Trained batch 235 in epoch 5, gen_loss = 0.4194982972438053, disc_loss = 0.04483307555112672
Trained batch 236 in epoch 5, gen_loss = 0.4196088647289115, disc_loss = 0.04466641199173806
Trained batch 237 in epoch 5, gen_loss = 0.41933708343686177, disc_loss = 0.0446098390810129
Trained batch 238 in epoch 5, gen_loss = 0.4195460233229474, disc_loss = 0.04445218336943802
Trained batch 239 in epoch 5, gen_loss = 0.41968831742803253, disc_loss = 0.044327502317416174
Trained batch 240 in epoch 5, gen_loss = 0.41973928952612816, disc_loss = 0.04418290989991293
Trained batch 241 in epoch 5, gen_loss = 0.4197609297746469, disc_loss = 0.044093205501163794
Trained batch 242 in epoch 5, gen_loss = 0.41995835831626455, disc_loss = 0.044081947218182156
Trained batch 243 in epoch 5, gen_loss = 0.4200966976216582, disc_loss = 0.04398078205766248
Trained batch 244 in epoch 5, gen_loss = 0.4200547119792627, disc_loss = 0.043858790359630875
Trained batch 245 in epoch 5, gen_loss = 0.41971446246635624, disc_loss = 0.043702463081818285
Trained batch 246 in epoch 5, gen_loss = 0.41967198976620973, disc_loss = 0.044001440845641046
Trained batch 247 in epoch 5, gen_loss = 0.41980501132146003, disc_loss = 0.045559768429807114
Trained batch 248 in epoch 5, gen_loss = 0.42014173822230605, disc_loss = 0.04551153796085392
Trained batch 249 in epoch 5, gen_loss = 0.4199517184495926, disc_loss = 0.04547959132492542
Trained batch 250 in epoch 5, gen_loss = 0.419922411441803, disc_loss = 0.0454234118866493
Trained batch 251 in epoch 5, gen_loss = 0.4195827190128584, disc_loss = 0.04529809198224
Trained batch 252 in epoch 5, gen_loss = 0.419673000046387, disc_loss = 0.045168081611365436
Trained batch 253 in epoch 5, gen_loss = 0.4194852363640868, disc_loss = 0.045007378697087326
Trained batch 254 in epoch 5, gen_loss = 0.41968257801205505, disc_loss = 0.04486933002686676
Trained batch 255 in epoch 5, gen_loss = 0.41962596285156906, disc_loss = 0.044729683935656794
Trained batch 256 in epoch 5, gen_loss = 0.4196032708952863, disc_loss = 0.04458349285799473
Trained batch 257 in epoch 5, gen_loss = 0.4194393189147461, disc_loss = 0.04457793633865063
Trained batch 258 in epoch 5, gen_loss = 0.4196778362091904, disc_loss = 0.044483984399831436
Trained batch 259 in epoch 5, gen_loss = 0.4199057650107604, disc_loss = 0.044327561285060185
Trained batch 260 in epoch 5, gen_loss = 0.41961770598915804, disc_loss = 0.04418268599244141
Trained batch 261 in epoch 5, gen_loss = 0.4194906624673887, disc_loss = 0.044115161807596226
Trained batch 262 in epoch 5, gen_loss = 0.4197818428391286, disc_loss = 0.04430218886569879
Trained batch 263 in epoch 5, gen_loss = 0.41951486073208577, disc_loss = 0.044556240565284636
Trained batch 264 in epoch 5, gen_loss = 0.4192959448076644, disc_loss = 0.04519234871808088
Trained batch 265 in epoch 5, gen_loss = 0.4190657390911776, disc_loss = 0.045045869515970685
Trained batch 266 in epoch 5, gen_loss = 0.41885374090198274, disc_loss = 0.045063670452558595
Trained batch 267 in epoch 5, gen_loss = 0.4190283105222147, disc_loss = 0.044946264190627125
Trained batch 268 in epoch 5, gen_loss = 0.4190392166265325, disc_loss = 0.04480331862989301
Trained batch 269 in epoch 5, gen_loss = 0.41905966952995016, disc_loss = 0.044676041841093035
Trained batch 270 in epoch 5, gen_loss = 0.4192334218878588, disc_loss = 0.044524399215712926
Trained batch 271 in epoch 5, gen_loss = 0.41929751820862293, disc_loss = 0.04439605834726107
Trained batch 272 in epoch 5, gen_loss = 0.4193175230925773, disc_loss = 0.04425605058912256
Trained batch 273 in epoch 5, gen_loss = 0.4191027950413906, disc_loss = 0.044319375478458614
Trained batch 274 in epoch 5, gen_loss = 0.41942333449016916, disc_loss = 0.044894934458319435
Trained batch 275 in epoch 5, gen_loss = 0.4191439435749814, disc_loss = 0.04531862683833806
Trained batch 276 in epoch 5, gen_loss = 0.41935002481033656, disc_loss = 0.04535787544441863
Trained batch 277 in epoch 5, gen_loss = 0.41958511057946324, disc_loss = 0.0452588140259316
Trained batch 278 in epoch 5, gen_loss = 0.41924505314946603, disc_loss = 0.045138485982553454
Trained batch 279 in epoch 5, gen_loss = 0.419259587675333, disc_loss = 0.04507733635255136
Trained batch 280 in epoch 5, gen_loss = 0.4194286684124495, disc_loss = 0.044942322255897726
Trained batch 281 in epoch 5, gen_loss = 0.4194961496701477, disc_loss = 0.044798712773704306
Trained batch 282 in epoch 5, gen_loss = 0.4195433730792662, disc_loss = 0.04466899754166893
Trained batch 283 in epoch 5, gen_loss = 0.4193986730886177, disc_loss = 0.044607679280091704
Trained batch 284 in epoch 5, gen_loss = 0.41967713634173076, disc_loss = 0.045012826393276716
Trained batch 285 in epoch 5, gen_loss = 0.4192400435050884, disc_loss = 0.046102042419842434
Trained batch 286 in epoch 5, gen_loss = 0.4192877683905359, disc_loss = 0.04719742305677397
Trained batch 287 in epoch 5, gen_loss = 0.4191587370716863, disc_loss = 0.0474266024272462
Trained batch 288 in epoch 5, gen_loss = 0.4189958277458138, disc_loss = 0.047632742904378
Trained batch 289 in epoch 5, gen_loss = 0.41898977972310164, disc_loss = 0.047500923907801765
Trained batch 290 in epoch 5, gen_loss = 0.41909918332427637, disc_loss = 0.047368563605229216
Trained batch 291 in epoch 5, gen_loss = 0.41883904925764426, disc_loss = 0.04726087147838832
Trained batch 292 in epoch 5, gen_loss = 0.41873286913686236, disc_loss = 0.047135604512893656
Trained batch 293 in epoch 5, gen_loss = 0.4184667677903662, disc_loss = 0.04702248638036477
Trained batch 294 in epoch 5, gen_loss = 0.4182382447234655, disc_loss = 0.046887213837008106
Trained batch 295 in epoch 5, gen_loss = 0.4182341344453193, disc_loss = 0.04674354751477949
Trained batch 296 in epoch 5, gen_loss = 0.41836408422852206, disc_loss = 0.04659738687105377
Trained batch 297 in epoch 5, gen_loss = 0.4182181449344494, disc_loss = 0.046453291871397434
Trained batch 298 in epoch 5, gen_loss = 0.41818811712057696, disc_loss = 0.046310924692079425
Trained batch 299 in epoch 5, gen_loss = 0.41834045201539993, disc_loss = 0.04618558880019312
Trained batch 300 in epoch 5, gen_loss = 0.41818978471613405, disc_loss = 0.04604338190171781
Trained batch 301 in epoch 5, gen_loss = 0.41794719196707997, disc_loss = 0.04591206937260457
Trained batch 302 in epoch 5, gen_loss = 0.4176874539442975, disc_loss = 0.045784667760545614
Trained batch 303 in epoch 5, gen_loss = 0.41749840719919457, disc_loss = 0.04568749517861043
Trained batch 304 in epoch 5, gen_loss = 0.417303593432317, disc_loss = 0.045933493445856406
Trained batch 305 in epoch 5, gen_loss = 0.4174302551481459, disc_loss = 0.04680514628953282
Trained batch 306 in epoch 5, gen_loss = 0.417310741611723, disc_loss = 0.046777202659028704
Trained batch 307 in epoch 5, gen_loss = 0.4171537037019606, disc_loss = 0.04683892404609179
Trained batch 308 in epoch 5, gen_loss = 0.41713637190729286, disc_loss = 0.046802656260141226
Trained batch 309 in epoch 5, gen_loss = 0.4170913090628962, disc_loss = 0.04670868616235713
Trained batch 310 in epoch 5, gen_loss = 0.417068316622179, disc_loss = 0.04664762785218033
Trained batch 311 in epoch 5, gen_loss = 0.4170376954552455, disc_loss = 0.04655177596260984
Trained batch 312 in epoch 5, gen_loss = 0.417191846111712, disc_loss = 0.046420867149435434
Trained batch 313 in epoch 5, gen_loss = 0.4173212671166013, disc_loss = 0.04633385601088666
Trained batch 314 in epoch 5, gen_loss = 0.4170699055232699, disc_loss = 0.046426673241639654
Trained batch 315 in epoch 5, gen_loss = 0.4174373627086229, disc_loss = 0.0463529266733853
Trained batch 316 in epoch 5, gen_loss = 0.4176882062612648, disc_loss = 0.04628879084745392
Trained batch 317 in epoch 5, gen_loss = 0.4176604557524687, disc_loss = 0.046297778746657914
Trained batch 318 in epoch 5, gen_loss = 0.41776563203820616, disc_loss = 0.04621582756440818
Trained batch 319 in epoch 5, gen_loss = 0.41769437538459897, disc_loss = 0.046095520667586244
Trained batch 320 in epoch 5, gen_loss = 0.4175970332459126, disc_loss = 0.046028281369818104
Trained batch 321 in epoch 5, gen_loss = 0.4175434735435877, disc_loss = 0.0459649743684365
Trained batch 322 in epoch 5, gen_loss = 0.41757850519643847, disc_loss = 0.04589246480074068
Trained batch 323 in epoch 5, gen_loss = 0.41760467268802504, disc_loss = 0.04626459342263708
Trained batch 324 in epoch 5, gen_loss = 0.4179262610582205, disc_loss = 0.047073771027275
Trained batch 325 in epoch 5, gen_loss = 0.4180689830721522, disc_loss = 0.04697108825174463
Trained batch 326 in epoch 5, gen_loss = 0.41779620585456173, disc_loss = 0.04687537380995439
Trained batch 327 in epoch 5, gen_loss = 0.4174521551808206, disc_loss = 0.04677611565509834
Trained batch 328 in epoch 5, gen_loss = 0.4172288360566716, disc_loss = 0.04665808473277758
Trained batch 329 in epoch 5, gen_loss = 0.4169688194087057, disc_loss = 0.046537415175980916
Trained batch 330 in epoch 5, gen_loss = 0.41674560641594166, disc_loss = 0.046505666752219246
Trained batch 331 in epoch 5, gen_loss = 0.4169376520327775, disc_loss = 0.046458320345039515
Trained batch 332 in epoch 5, gen_loss = 0.416922852978692, disc_loss = 0.04636351649604693
Trained batch 333 in epoch 5, gen_loss = 0.41676999967612194, disc_loss = 0.046306162286956914
Trained batch 334 in epoch 5, gen_loss = 0.4167248773041056, disc_loss = 0.046180847746584174
Trained batch 335 in epoch 5, gen_loss = 0.41666397053216186, disc_loss = 0.046075797546239174
Trained batch 336 in epoch 5, gen_loss = 0.4165265872322841, disc_loss = 0.04597849888624817
Trained batch 337 in epoch 5, gen_loss = 0.4164662363790196, disc_loss = 0.04585666787885019
Trained batch 338 in epoch 5, gen_loss = 0.41646439302987404, disc_loss = 0.045785229321387885
Trained batch 339 in epoch 5, gen_loss = 0.4163571495343657, disc_loss = 0.04567179833059473
Trained batch 340 in epoch 5, gen_loss = 0.4164260746446872, disc_loss = 0.04576815336825233
Trained batch 341 in epoch 5, gen_loss = 0.4166127091262773, disc_loss = 0.045868694584146795
Trained batch 342 in epoch 5, gen_loss = 0.4164909796012734, disc_loss = 0.04582823012309263
Trained batch 343 in epoch 5, gen_loss = 0.41641362262673154, disc_loss = 0.04571928239365238
Trained batch 344 in epoch 5, gen_loss = 0.41632632639097134, disc_loss = 0.04565959224085985
Trained batch 345 in epoch 5, gen_loss = 0.416214794609588, disc_loss = 0.04554028735654913
Trained batch 346 in epoch 5, gen_loss = 0.4161777785772549, disc_loss = 0.04545698318998155
Trained batch 347 in epoch 5, gen_loss = 0.4161973685540002, disc_loss = 0.04551172187757924
Trained batch 348 in epoch 5, gen_loss = 0.416545777488233, disc_loss = 0.04541333866796662
Trained batch 349 in epoch 5, gen_loss = 0.4167185070684978, disc_loss = 0.04534741045175386
Trained batch 350 in epoch 5, gen_loss = 0.4167625894743493, disc_loss = 0.04526763420586509
Trained batch 351 in epoch 5, gen_loss = 0.4166759112003175, disc_loss = 0.04523968400859634
Trained batch 352 in epoch 5, gen_loss = 0.4167107908482592, disc_loss = 0.04512719219621725
Trained batch 353 in epoch 5, gen_loss = 0.4166214833993696, disc_loss = 0.045016434986149566
Trained batch 354 in epoch 5, gen_loss = 0.41656177681936346, disc_loss = 0.04490532748807799
Trained batch 355 in epoch 5, gen_loss = 0.4164166800426633, disc_loss = 0.04481179584955713
Trained batch 356 in epoch 5, gen_loss = 0.41656259061241685, disc_loss = 0.044697279049897516
Trained batch 357 in epoch 5, gen_loss = 0.41645394099158284, disc_loss = 0.04464778131558222
Trained batch 358 in epoch 5, gen_loss = 0.4163738788004373, disc_loss = 0.04460499512646503
Trained batch 359 in epoch 5, gen_loss = 0.4164466954767704, disc_loss = 0.04451386302179243
Trained batch 360 in epoch 5, gen_loss = 0.41649170248792444, disc_loss = 0.04444286264053487
Trained batch 361 in epoch 5, gen_loss = 0.4164108927901937, disc_loss = 0.044361260243002014
Trained batch 362 in epoch 5, gen_loss = 0.41635867230819934, disc_loss = 0.0442539276882298
Trained batch 363 in epoch 5, gen_loss = 0.41615694491090355, disc_loss = 0.04415269889728074
Trained batch 364 in epoch 5, gen_loss = 0.41602500472983267, disc_loss = 0.04404424127663346
Trained batch 365 in epoch 5, gen_loss = 0.41615571065352913, disc_loss = 0.04399487797407525
Trained batch 366 in epoch 5, gen_loss = 0.4159426713509521, disc_loss = 0.043905821789375805
Trained batch 367 in epoch 5, gen_loss = 0.41602616036391776, disc_loss = 0.043850729581722786
Trained batch 368 in epoch 5, gen_loss = 0.41613408252798767, disc_loss = 0.04375448502501761
Trained batch 369 in epoch 5, gen_loss = 0.41609627443390923, disc_loss = 0.043644474319660585
Trained batch 370 in epoch 5, gen_loss = 0.4160328433520068, disc_loss = 0.04359809152475706
Trained batch 371 in epoch 5, gen_loss = 0.4161064490996381, disc_loss = 0.04363781244679284
Trained batch 372 in epoch 5, gen_loss = 0.41608669842535945, disc_loss = 0.04353595497436202
Trained batch 373 in epoch 5, gen_loss = 0.4161154854903247, disc_loss = 0.04344810268662392
Trained batch 374 in epoch 5, gen_loss = 0.41588424785931905, disc_loss = 0.04339039094373584
Trained batch 375 in epoch 5, gen_loss = 0.4160105503619985, disc_loss = 0.043297317955256535
Trained batch 376 in epoch 5, gen_loss = 0.41613672140106284, disc_loss = 0.04320068036969405
Trained batch 377 in epoch 5, gen_loss = 0.41618359703866264, disc_loss = 0.04311747680832115
Trained batch 378 in epoch 5, gen_loss = 0.4160531128616635, disc_loss = 0.04301349591159097
Trained batch 379 in epoch 5, gen_loss = 0.41611430307752206, disc_loss = 0.04294377985949579
Trained batch 380 in epoch 5, gen_loss = 0.4160895050354204, disc_loss = 0.04284763356836958
Trained batch 381 in epoch 5, gen_loss = 0.41616014855382333, disc_loss = 0.0427640033093481
Trained batch 382 in epoch 5, gen_loss = 0.4159810443459852, disc_loss = 0.04266497958573092
Trained batch 383 in epoch 5, gen_loss = 0.4159178592575093, disc_loss = 0.04256216073190444
Trained batch 384 in epoch 5, gen_loss = 0.41588486626550747, disc_loss = 0.04246861394373821
Trained batch 385 in epoch 5, gen_loss = 0.4157168527804508, disc_loss = 0.04239478483771992
Trained batch 386 in epoch 5, gen_loss = 0.41578039804170297, disc_loss = 0.042413374667780265
Trained batch 387 in epoch 5, gen_loss = 0.41570495460758505, disc_loss = 0.04237419186212776
Trained batch 388 in epoch 5, gen_loss = 0.4157638657062403, disc_loss = 0.04235715706231776
Trained batch 389 in epoch 5, gen_loss = 0.4156114790684138, disc_loss = 0.042275274006458814
Trained batch 390 in epoch 5, gen_loss = 0.41550398048232584, disc_loss = 0.04225013747720805
Trained batch 391 in epoch 5, gen_loss = 0.4156043948415591, disc_loss = 0.042159744109530765
Trained batch 392 in epoch 5, gen_loss = 0.41546270296773835, disc_loss = 0.042106341360890455
Trained batch 393 in epoch 5, gen_loss = 0.4154230270742765, disc_loss = 0.042030013855404884
Trained batch 394 in epoch 5, gen_loss = 0.4155028515978704, disc_loss = 0.04196537292055503
Trained batch 395 in epoch 5, gen_loss = 0.415380775100655, disc_loss = 0.04188811649554268
Trained batch 396 in epoch 5, gen_loss = 0.4153915787824155, disc_loss = 0.041806225792765245
Trained batch 397 in epoch 5, gen_loss = 0.41524403575976293, disc_loss = 0.04179947315855654
Trained batch 398 in epoch 5, gen_loss = 0.41536065622379903, disc_loss = 0.042342390238370435
Trained batch 399 in epoch 5, gen_loss = 0.4153544943779707, disc_loss = 0.042284716627327724
Trained batch 400 in epoch 5, gen_loss = 0.41523410993026677, disc_loss = 0.042279063799462634
Trained batch 401 in epoch 5, gen_loss = 0.4152857376568353, disc_loss = 0.0422111398283281
Trained batch 402 in epoch 5, gen_loss = 0.415450041554406, disc_loss = 0.04216693463173716
Trained batch 403 in epoch 5, gen_loss = 0.4153650844893833, disc_loss = 0.042073523971519554
Trained batch 404 in epoch 5, gen_loss = 0.4153561489081677, disc_loss = 0.04198120062319953
Trained batch 405 in epoch 5, gen_loss = 0.4152832052537373, disc_loss = 0.04188856805716022
Trained batch 406 in epoch 5, gen_loss = 0.41520095655021855, disc_loss = 0.04180168985510451
Trained batch 407 in epoch 5, gen_loss = 0.415138320084296, disc_loss = 0.041708180888021806
Trained batch 408 in epoch 5, gen_loss = 0.41514424567992064, disc_loss = 0.0416206232366587
Trained batch 409 in epoch 5, gen_loss = 0.4153812243444164, disc_loss = 0.04152863812121767
Trained batch 410 in epoch 5, gen_loss = 0.4152491812723397, disc_loss = 0.04143403218481282
Trained batch 411 in epoch 5, gen_loss = 0.41518621103277487, disc_loss = 0.041340902872107815
Trained batch 412 in epoch 5, gen_loss = 0.4149207182715649, disc_loss = 0.04126715298784901
Trained batch 413 in epoch 5, gen_loss = 0.4147233365526522, disc_loss = 0.04119685103223718
Trained batch 414 in epoch 5, gen_loss = 0.41451632581561443, disc_loss = 0.041126856014289594
Trained batch 415 in epoch 5, gen_loss = 0.41441494269439805, disc_loss = 0.04105037003878701
Trained batch 416 in epoch 5, gen_loss = 0.4141727874604918, disc_loss = 0.0410550589750273
Trained batch 417 in epoch 5, gen_loss = 0.4138087963230872, disc_loss = 0.04141813751842613
Trained batch 418 in epoch 5, gen_loss = 0.41387088749744444, disc_loss = 0.04271003433174247
Trained batch 419 in epoch 5, gen_loss = 0.41381169373080845, disc_loss = 0.04323433999448926
Trained batch 420 in epoch 5, gen_loss = 0.41370886755386044, disc_loss = 0.04366289192396979
Trained batch 421 in epoch 5, gen_loss = 0.4136909557179817, disc_loss = 0.043736624261651244
Trained batch 422 in epoch 5, gen_loss = 0.4136034931555989, disc_loss = 0.04378244574908299
Trained batch 423 in epoch 5, gen_loss = 0.4134425534954611, disc_loss = 0.04381403738999616
Trained batch 424 in epoch 5, gen_loss = 0.4132825038012336, disc_loss = 0.043835226025103646
Trained batch 425 in epoch 5, gen_loss = 0.41327664430992145, disc_loss = 0.04385246385376411
Trained batch 426 in epoch 5, gen_loss = 0.41309224993897825, disc_loss = 0.04417179531823469
Trained batch 427 in epoch 5, gen_loss = 0.412979976805014, disc_loss = 0.04448277329118644
Trained batch 428 in epoch 5, gen_loss = 0.4129353177436304, disc_loss = 0.04469489228004255
Trained batch 429 in epoch 5, gen_loss = 0.4126722771067952, disc_loss = 0.04478994732625176
Trained batch 430 in epoch 5, gen_loss = 0.41283502455653837, disc_loss = 0.044823093957261216
Trained batch 431 in epoch 5, gen_loss = 0.4126258538690982, disc_loss = 0.04494105834735954
Trained batch 432 in epoch 5, gen_loss = 0.4125876507913268, disc_loss = 0.04528725233227961
Trained batch 433 in epoch 5, gen_loss = 0.41228534885540535, disc_loss = 0.04543750310769468
Trained batch 434 in epoch 5, gen_loss = 0.4120865386107872, disc_loss = 0.045396097646169795
Trained batch 435 in epoch 5, gen_loss = 0.41196445279985394, disc_loss = 0.04555806767893955
Trained batch 436 in epoch 5, gen_loss = 0.4118124123159753, disc_loss = 0.04581856946631396
Trained batch 437 in epoch 5, gen_loss = 0.4118512621889376, disc_loss = 0.045807913413003394
Trained batch 438 in epoch 5, gen_loss = 0.41208324067141855, disc_loss = 0.045766856211103955
Trained batch 439 in epoch 5, gen_loss = 0.41200937344269317, disc_loss = 0.045691573035120114
Trained batch 440 in epoch 5, gen_loss = 0.41195051274061745, disc_loss = 0.04562436920155659
Trained batch 441 in epoch 5, gen_loss = 0.41173775419929987, disc_loss = 0.045732158855155816
Trained batch 442 in epoch 5, gen_loss = 0.41153430676352626, disc_loss = 0.04574405519621821
Trained batch 443 in epoch 5, gen_loss = 0.4113747684268264, disc_loss = 0.045739837225237105
Trained batch 444 in epoch 5, gen_loss = 0.4112542077396693, disc_loss = 0.045903841782298484
Trained batch 445 in epoch 5, gen_loss = 0.4108456472778534, disc_loss = 0.04656518269027479
Trained batch 446 in epoch 5, gen_loss = 0.4107600455182777, disc_loss = 0.047200122685119576
Trained batch 447 in epoch 5, gen_loss = 0.41060531245810644, disc_loss = 0.047271174943619244
Trained batch 448 in epoch 5, gen_loss = 0.4105566919248194, disc_loss = 0.04734093719058336
Trained batch 449 in epoch 5, gen_loss = 0.4106527266237471, disc_loss = 0.04782922948348439
Trained batch 450 in epoch 5, gen_loss = 0.41054271297021344, disc_loss = 0.047751582605029125
Trained batch 451 in epoch 5, gen_loss = 0.41032816594944593, disc_loss = 0.0478538779734502
Trained batch 452 in epoch 5, gen_loss = 0.41042110692323175, disc_loss = 0.04784644040624481
Trained batch 453 in epoch 5, gen_loss = 0.4103853106498718, disc_loss = 0.04786323898703697
Trained batch 454 in epoch 5, gen_loss = 0.4101022441308577, disc_loss = 0.047784781152546245
Trained batch 455 in epoch 5, gen_loss = 0.40985047947942166, disc_loss = 0.048083078630346186
Trained batch 456 in epoch 5, gen_loss = 0.40992877682919576, disc_loss = 0.04842985409140766
Trained batch 457 in epoch 5, gen_loss = 0.41002879978267387, disc_loss = 0.048384542767605114
Trained batch 458 in epoch 5, gen_loss = 0.4101952567599178, disc_loss = 0.0483126162316991
Testing Epoch 5
Training Epoch 6
Trained batch 0 in epoch 6, gen_loss = 0.3136809170246124, disc_loss = 0.1009059026837349
Trained batch 1 in epoch 6, gen_loss = 0.3696721941232681, disc_loss = 0.0898442417383194
Trained batch 2 in epoch 6, gen_loss = 0.3844791154066722, disc_loss = 0.07463815932472546
Trained batch 3 in epoch 6, gen_loss = 0.3914650157094002, disc_loss = 0.08426017221063375
Trained batch 4 in epoch 6, gen_loss = 0.3963187873363495, disc_loss = 0.11216192170977593
Trained batch 5 in epoch 6, gen_loss = 0.41248656809329987, disc_loss = 0.09571486633891861
Trained batch 6 in epoch 6, gen_loss = 0.42024565594536917, disc_loss = 0.08399671116577727
Trained batch 7 in epoch 6, gen_loss = 0.4224371314048767, disc_loss = 0.07484449807088822
Trained batch 8 in epoch 6, gen_loss = 0.41379617320166695, disc_loss = 0.07050230260938406
Trained batch 9 in epoch 6, gen_loss = 0.40602492094039916, disc_loss = 0.06438479954376816
Trained batch 10 in epoch 6, gen_loss = 0.40955098650672217, disc_loss = 0.05903103820640932
Trained batch 11 in epoch 6, gen_loss = 0.4007079402605693, disc_loss = 0.056750804263477526
Trained batch 12 in epoch 6, gen_loss = 0.3978985043672415, disc_loss = 0.06769674221197
Trained batch 13 in epoch 6, gen_loss = 0.399307553257261, disc_loss = 0.07332746478329812
Trained batch 14 in epoch 6, gen_loss = 0.39837730924288434, disc_loss = 0.06913373408218225
Trained batch 15 in epoch 6, gen_loss = 0.393495861440897, disc_loss = 0.07048363925423473
Trained batch 16 in epoch 6, gen_loss = 0.3968477529637954, disc_loss = 0.06661227367380086
Trained batch 17 in epoch 6, gen_loss = 0.3970056821902593, disc_loss = 0.06457106272379558
Trained batch 18 in epoch 6, gen_loss = 0.39247527875398336, disc_loss = 0.06397808382385656
Trained batch 19 in epoch 6, gen_loss = 0.39416523873806, disc_loss = 0.06336888503283263
Trained batch 20 in epoch 6, gen_loss = 0.3931039046673548, disc_loss = 0.061523906531788054
Trained batch 21 in epoch 6, gen_loss = 0.3896207254041325, disc_loss = 0.059957878325473175
Trained batch 22 in epoch 6, gen_loss = 0.39196184018383856, disc_loss = 0.058030253478690334
Trained batch 23 in epoch 6, gen_loss = 0.3950917162001133, disc_loss = 0.05656685334785531
Trained batch 24 in epoch 6, gen_loss = 0.395940500497818, disc_loss = 0.056383853368461134
Trained batch 25 in epoch 6, gen_loss = 0.3933005860218635, disc_loss = 0.058530890418646425
Trained batch 26 in epoch 6, gen_loss = 0.3942238379407812, disc_loss = 0.05682268331724184
Trained batch 27 in epoch 6, gen_loss = 0.39662843304021017, disc_loss = 0.05506765386754913
Trained batch 28 in epoch 6, gen_loss = 0.3998871445655823, disc_loss = 0.053367835919147934
Trained batch 29 in epoch 6, gen_loss = 0.40173437297344206, disc_loss = 0.0518738419127961
Trained batch 30 in epoch 6, gen_loss = 0.40287922082408784, disc_loss = 0.05094156080796834
Trained batch 31 in epoch 6, gen_loss = 0.40234203077852726, disc_loss = 0.050443596235709265
Trained batch 32 in epoch 6, gen_loss = 0.4001398574222218, disc_loss = 0.051505546706418194
Trained batch 33 in epoch 6, gen_loss = 0.40007316014345956, disc_loss = 0.0510564332773142
Trained batch 34 in epoch 6, gen_loss = 0.400330707856587, disc_loss = 0.05023636128753424
Trained batch 35 in epoch 6, gen_loss = 0.3978651447428597, disc_loss = 0.05021791452438467
Trained batch 36 in epoch 6, gen_loss = 0.3996260456136755, disc_loss = 0.049547812750412
Trained batch 37 in epoch 6, gen_loss = 0.400652781913155, disc_loss = 0.048610239828887736
Trained batch 38 in epoch 6, gen_loss = 0.4012048084002275, disc_loss = 0.049180461428104304
Trained batch 39 in epoch 6, gen_loss = 0.4014601565897465, disc_loss = 0.051358454301953314
Trained batch 40 in epoch 6, gen_loss = 0.4029211147529323, disc_loss = 0.051313195650170486
Trained batch 41 in epoch 6, gen_loss = 0.4017308418239866, disc_loss = 0.0504975380996863
Trained batch 42 in epoch 6, gen_loss = 0.39950281173683877, disc_loss = 0.050088218998077305
Trained batch 43 in epoch 6, gen_loss = 0.40255027128891513, disc_loss = 0.04908130997368558
Trained batch 44 in epoch 6, gen_loss = 0.4043946140342288, disc_loss = 0.048245831144352755
Trained batch 45 in epoch 6, gen_loss = 0.4032096862792969, disc_loss = 0.04738577675965169
Trained batch 46 in epoch 6, gen_loss = 0.40340934281653545, disc_loss = 0.04654544736555916
Trained batch 47 in epoch 6, gen_loss = 0.402600205813845, disc_loss = 0.04564506694441661
Trained batch 48 in epoch 6, gen_loss = 0.4032332495767243, disc_loss = 0.04488837730367573
Trained batch 49 in epoch 6, gen_loss = 0.4037023317813873, disc_loss = 0.04418727181851864
Trained batch 50 in epoch 6, gen_loss = 0.4026884331422694, disc_loss = 0.043548129225040186
Trained batch 51 in epoch 6, gen_loss = 0.40163817829810655, disc_loss = 0.042929797970618196
Trained batch 52 in epoch 6, gen_loss = 0.4024891139201398, disc_loss = 0.042195582692072076
Trained batch 53 in epoch 6, gen_loss = 0.4024652546202695, disc_loss = 0.04148675980805247
Trained batch 54 in epoch 6, gen_loss = 0.40287576697089456, disc_loss = 0.041080231456594035
Trained batch 55 in epoch 6, gen_loss = 0.4021333046257496, disc_loss = 0.04091224297215896
Trained batch 56 in epoch 6, gen_loss = 0.40181073964687813, disc_loss = 0.04038338948106557
Trained batch 57 in epoch 6, gen_loss = 0.402570448558906, disc_loss = 0.04096088632298955
Trained batch 58 in epoch 6, gen_loss = 0.4014632131083537, disc_loss = 0.04307134294787706
Trained batch 59 in epoch 6, gen_loss = 0.40365472386280693, disc_loss = 0.043551426474004985
Trained batch 60 in epoch 6, gen_loss = 0.4046619050815457, disc_loss = 0.04317264839029703
Trained batch 61 in epoch 6, gen_loss = 0.4043669710236211, disc_loss = 0.04261026588538962
Trained batch 62 in epoch 6, gen_loss = 0.40420542586417424, disc_loss = 0.04211563427769949
Trained batch 63 in epoch 6, gen_loss = 0.40401769429445267, disc_loss = 0.04157582169136731
Trained batch 64 in epoch 6, gen_loss = 0.40353895058998696, disc_loss = 0.04099092755036859
Trained batch 65 in epoch 6, gen_loss = 0.4025265502207207, disc_loss = 0.04042931981243645
Trained batch 66 in epoch 6, gen_loss = 0.402411811387361, disc_loss = 0.03989363765455226
Trained batch 67 in epoch 6, gen_loss = 0.40263452862992005, disc_loss = 0.039370921002153086
Trained batch 68 in epoch 6, gen_loss = 0.40177070144293964, disc_loss = 0.03896270422399908
Trained batch 69 in epoch 6, gen_loss = 0.4018444095339094, disc_loss = 0.038461926552866184
Trained batch 70 in epoch 6, gen_loss = 0.4015693345540006, disc_loss = 0.037995786432334235
Trained batch 71 in epoch 6, gen_loss = 0.40167221137219006, disc_loss = 0.0375126428100177
Trained batch 72 in epoch 6, gen_loss = 0.4018460308035759, disc_loss = 0.03706925288353064
Trained batch 73 in epoch 6, gen_loss = 0.4027673916236774, disc_loss = 0.03667841247610144
Trained batch 74 in epoch 6, gen_loss = 0.4031579053401947, disc_loss = 0.03629004788274566
Trained batch 75 in epoch 6, gen_loss = 0.4031670375874168, disc_loss = 0.03586791740656879
Trained batch 76 in epoch 6, gen_loss = 0.40249116583303973, disc_loss = 0.03546711943995256
Trained batch 77 in epoch 6, gen_loss = 0.4017880501655432, disc_loss = 0.03504678989963558
Trained batch 78 in epoch 6, gen_loss = 0.40069641493543795, disc_loss = 0.034755341811812945
Trained batch 79 in epoch 6, gen_loss = 0.4013214841485023, disc_loss = 0.0344529679248808
Trained batch 80 in epoch 6, gen_loss = 0.40035439788559335, disc_loss = 0.03407208084266771
Trained batch 81 in epoch 6, gen_loss = 0.4002630179975091, disc_loss = 0.03383425920463463
Trained batch 82 in epoch 6, gen_loss = 0.3990657954330904, disc_loss = 0.03389682259174984
Trained batch 83 in epoch 6, gen_loss = 0.39950093768891837, disc_loss = 0.034855091298509035
Trained batch 84 in epoch 6, gen_loss = 0.3991302588406731, disc_loss = 0.034681160723352256
Trained batch 85 in epoch 6, gen_loss = 0.39941518944363263, disc_loss = 0.03522569033977857
Trained batch 86 in epoch 6, gen_loss = 0.39919894488378505, disc_loss = 0.035133581605857646
Trained batch 87 in epoch 6, gen_loss = 0.3989476700398055, disc_loss = 0.03489802572188306
Trained batch 88 in epoch 6, gen_loss = 0.39923767259951387, disc_loss = 0.03488762100917821
Trained batch 89 in epoch 6, gen_loss = 0.400743540459209, disc_loss = 0.03611282650122626
Trained batch 90 in epoch 6, gen_loss = 0.4016867384805784, disc_loss = 0.03686398343224037
Trained batch 91 in epoch 6, gen_loss = 0.4029883671066035, disc_loss = 0.03667721852569072
Trained batch 92 in epoch 6, gen_loss = 0.40368624335976055, disc_loss = 0.03654965043057918
Trained batch 93 in epoch 6, gen_loss = 0.40275984939108506, disc_loss = 0.03690519625509277
Trained batch 94 in epoch 6, gen_loss = 0.40321155692401683, disc_loss = 0.03715567786589657
Trained batch 95 in epoch 6, gen_loss = 0.40294091651837033, disc_loss = 0.0370656628292636
Trained batch 96 in epoch 6, gen_loss = 0.40335624795599084, disc_loss = 0.03678638963076795
Trained batch 97 in epoch 6, gen_loss = 0.40377766410915217, disc_loss = 0.036694149531861196
Trained batch 98 in epoch 6, gen_loss = 0.40351225902335813, disc_loss = 0.03643423679868004
Trained batch 99 in epoch 6, gen_loss = 0.4032122790813446, disc_loss = 0.036610861679073424
Trained batch 100 in epoch 6, gen_loss = 0.40361296835512217, disc_loss = 0.03683583530376085
Trained batch 101 in epoch 6, gen_loss = 0.40386397873654084, disc_loss = 0.03655907816445345
Trained batch 102 in epoch 6, gen_loss = 0.40476213381128406, disc_loss = 0.036296900621732894
Trained batch 103 in epoch 6, gen_loss = 0.40398758821762526, disc_loss = 0.036825661482558086
Trained batch 104 in epoch 6, gen_loss = 0.403916810523896, disc_loss = 0.037368186818258396
Trained batch 105 in epoch 6, gen_loss = 0.4037302071755787, disc_loss = 0.03708534316766023
Trained batch 106 in epoch 6, gen_loss = 0.40318302935528977, disc_loss = 0.03692584792717804
Trained batch 107 in epoch 6, gen_loss = 0.4025438990857866, disc_loss = 0.03746704813912166
Trained batch 108 in epoch 6, gen_loss = 0.402915905921831, disc_loss = 0.04087898656170508
Trained batch 109 in epoch 6, gen_loss = 0.40255978595126757, disc_loss = 0.04059474693230269
Trained batch 110 in epoch 6, gen_loss = 0.4023705063102482, disc_loss = 0.04037922551763152
Trained batch 111 in epoch 6, gen_loss = 0.4017849961029632, disc_loss = 0.0402182618833779
Trained batch 112 in epoch 6, gen_loss = 0.4025472402572632, disc_loss = 0.03991369414143264
Trained batch 113 in epoch 6, gen_loss = 0.40257899175610456, disc_loss = 0.03963439392636677
Trained batch 114 in epoch 6, gen_loss = 0.40225115262943767, disc_loss = 0.03938060557348249
Trained batch 115 in epoch 6, gen_loss = 0.4018675954691295, disc_loss = 0.03920019378460109
Trained batch 116 in epoch 6, gen_loss = 0.40115683048199385, disc_loss = 0.0393263397909478
Trained batch 117 in epoch 6, gen_loss = 0.4009280250234119, disc_loss = 0.040920789170047364
Trained batch 118 in epoch 6, gen_loss = 0.40090581674535736, disc_loss = 0.04377470142599352
Trained batch 119 in epoch 6, gen_loss = 0.4013002246618271, disc_loss = 0.04421734172501601
Trained batch 120 in epoch 6, gen_loss = 0.40135670200852325, disc_loss = 0.0446559591199587
Trained batch 121 in epoch 6, gen_loss = 0.401365587701563, disc_loss = 0.044817907909374136
Trained batch 122 in epoch 6, gen_loss = 0.4006754634826164, disc_loss = 0.04522572096429644
Trained batch 123 in epoch 6, gen_loss = 0.4012864926649678, disc_loss = 0.04528338785636269
Trained batch 124 in epoch 6, gen_loss = 0.40155180597305296, disc_loss = 0.045060644721612336
Trained batch 125 in epoch 6, gen_loss = 0.4016994143289233, disc_loss = 0.044788313244232936
Trained batch 126 in epoch 6, gen_loss = 0.40146656557330934, disc_loss = 0.04447438470161278
Trained batch 127 in epoch 6, gen_loss = 0.4014874573331326, disc_loss = 0.04421571024249715
Trained batch 128 in epoch 6, gen_loss = 0.40152411289917406, disc_loss = 0.04392668165721346
Trained batch 129 in epoch 6, gen_loss = 0.4014694796158717, disc_loss = 0.04374427391180339
Trained batch 130 in epoch 6, gen_loss = 0.40149655460401346, disc_loss = 0.04357735168380762
Trained batch 131 in epoch 6, gen_loss = 0.40151643911094376, disc_loss = 0.04563694654533527
Trained batch 132 in epoch 6, gen_loss = 0.40089109629616704, disc_loss = 0.04853292183313323
Trained batch 133 in epoch 6, gen_loss = 0.40199476858573174, disc_loss = 0.04876366940000331
Trained batch 134 in epoch 6, gen_loss = 0.40191911591423884, disc_loss = 0.04942618093660308
Trained batch 135 in epoch 6, gen_loss = 0.40121114736094193, disc_loss = 0.049309006356291804
Trained batch 136 in epoch 6, gen_loss = 0.40133874216218934, disc_loss = 0.049460226940127076
Trained batch 137 in epoch 6, gen_loss = 0.401846495659455, disc_loss = 0.049233836822036275
Trained batch 138 in epoch 6, gen_loss = 0.4020064970572218, disc_loss = 0.04893692968607539
Trained batch 139 in epoch 6, gen_loss = 0.40180164447852545, disc_loss = 0.04873339753165575
Trained batch 140 in epoch 6, gen_loss = 0.4019671082496643, disc_loss = 0.04844589796122031
Trained batch 141 in epoch 6, gen_loss = 0.4026931583041876, disc_loss = 0.048247083646087895
Trained batch 142 in epoch 6, gen_loss = 0.4021311271023917, disc_loss = 0.04811471514892276
Trained batch 143 in epoch 6, gen_loss = 0.40180467896991306, disc_loss = 0.04796883704936287
Trained batch 144 in epoch 6, gen_loss = 0.4023450884325751, disc_loss = 0.048006472381731044
Trained batch 145 in epoch 6, gen_loss = 0.40179731360037035, disc_loss = 0.04851363556402136
Trained batch 146 in epoch 6, gen_loss = 0.4022241342229908, disc_loss = 0.04844774420335129
Trained batch 147 in epoch 6, gen_loss = 0.40229367162730245, disc_loss = 0.04831752395477599
Trained batch 148 in epoch 6, gen_loss = 0.4023012878910807, disc_loss = 0.04801458870717043
Trained batch 149 in epoch 6, gen_loss = 0.4021105029185613, disc_loss = 0.0477866557892412
Trained batch 150 in epoch 6, gen_loss = 0.40246266402945613, disc_loss = 0.04754186173999645
Trained batch 151 in epoch 6, gen_loss = 0.4021211054764296, disc_loss = 0.047277197502185835
Trained batch 152 in epoch 6, gen_loss = 0.4024007480128918, disc_loss = 0.046997578781146826
Trained batch 153 in epoch 6, gen_loss = 0.40235652687487666, disc_loss = 0.0467779940302641
Trained batch 154 in epoch 6, gen_loss = 0.40325756784408323, disc_loss = 0.04660744599457229
Trained batch 155 in epoch 6, gen_loss = 0.40357376883427304, disc_loss = 0.04639695595221546
Trained batch 156 in epoch 6, gen_loss = 0.4038523830425967, disc_loss = 0.046131119639227156
Trained batch 157 in epoch 6, gen_loss = 0.4035379922465433, disc_loss = 0.04590387141060886
Trained batch 158 in epoch 6, gen_loss = 0.40364838639895123, disc_loss = 0.04573678868125726
Trained batch 159 in epoch 6, gen_loss = 0.40387645456939936, disc_loss = 0.0454939776158426
Trained batch 160 in epoch 6, gen_loss = 0.4038120297171314, disc_loss = 0.04526489805892943
Trained batch 161 in epoch 6, gen_loss = 0.40405658733697586, disc_loss = 0.045102110161319556
Trained batch 162 in epoch 6, gen_loss = 0.40423556302954083, disc_loss = 0.04512164863454966
Trained batch 163 in epoch 6, gen_loss = 0.4038407611774235, disc_loss = 0.04566869110709465
Trained batch 164 in epoch 6, gen_loss = 0.4041562116507328, disc_loss = 0.04598117288427823
Trained batch 165 in epoch 6, gen_loss = 0.4042806519442294, disc_loss = 0.04591773818976369
Trained batch 166 in epoch 6, gen_loss = 0.4045517285783848, disc_loss = 0.04568436714223848
Trained batch 167 in epoch 6, gen_loss = 0.4047838616229239, disc_loss = 0.04547569853353447
Trained batch 168 in epoch 6, gen_loss = 0.4046323847841229, disc_loss = 0.0452819507508456
Trained batch 169 in epoch 6, gen_loss = 0.40434645203983083, disc_loss = 0.045132285622222455
Trained batch 170 in epoch 6, gen_loss = 0.4046907327328509, disc_loss = 0.044952744914883234
Trained batch 171 in epoch 6, gen_loss = 0.40462811429833256, disc_loss = 0.04517443610496039
Trained batch 172 in epoch 6, gen_loss = 0.4044793320529034, disc_loss = 0.045575109200089135
Trained batch 173 in epoch 6, gen_loss = 0.4049319624900818, disc_loss = 0.04572850810738559
Trained batch 174 in epoch 6, gen_loss = 0.40523209146090916, disc_loss = 0.045534696459238015
Trained batch 175 in epoch 6, gen_loss = 0.4050779026001692, disc_loss = 0.04533904067780399
Trained batch 176 in epoch 6, gen_loss = 0.4051939605993066, disc_loss = 0.04514132813934637
Trained batch 177 in epoch 6, gen_loss = 0.405355239014947, disc_loss = 0.04492207645344433
Trained batch 178 in epoch 6, gen_loss = 0.40510755577566904, disc_loss = 0.04470635755716006
Trained batch 179 in epoch 6, gen_loss = 0.404952499932713, disc_loss = 0.04448389115795079
Trained batch 180 in epoch 6, gen_loss = 0.40527976283710965, disc_loss = 0.04425375738042247
Trained batch 181 in epoch 6, gen_loss = 0.4051780255286248, disc_loss = 0.04402959835715592
Trained batch 182 in epoch 6, gen_loss = 0.4052124085322104, disc_loss = 0.04380195818159505
Trained batch 183 in epoch 6, gen_loss = 0.4052597394456034, disc_loss = 0.043589855377238404
Trained batch 184 in epoch 6, gen_loss = 0.40495260696153385, disc_loss = 0.043368205994468285
Trained batch 185 in epoch 6, gen_loss = 0.4050027282648189, disc_loss = 0.04316472124698902
Trained batch 186 in epoch 6, gen_loss = 0.405239370098726, disc_loss = 0.04295069303732106
Trained batch 187 in epoch 6, gen_loss = 0.40500051227021727, disc_loss = 0.042739307569795625
Trained batch 188 in epoch 6, gen_loss = 0.40509553387682273, disc_loss = 0.04254047764790437
Trained batch 189 in epoch 6, gen_loss = 0.40494686506296457, disc_loss = 0.04238558070440041
Trained batch 190 in epoch 6, gen_loss = 0.4054278892060225, disc_loss = 0.04225802628313684
Trained batch 191 in epoch 6, gen_loss = 0.40552442396680516, disc_loss = 0.042068633537079826
Trained batch 192 in epoch 6, gen_loss = 0.40562944168253884, disc_loss = 0.04205743792355832
Trained batch 193 in epoch 6, gen_loss = 0.4060016976496608, disc_loss = 0.04213565562554088
Trained batch 194 in epoch 6, gen_loss = 0.4064520293321365, disc_loss = 0.04198132738566551
Trained batch 195 in epoch 6, gen_loss = 0.406461698516291, disc_loss = 0.041790700011544536
Trained batch 196 in epoch 6, gen_loss = 0.4064537282219998, disc_loss = 0.04177015275472236
Trained batch 197 in epoch 6, gen_loss = 0.406592416793409, disc_loss = 0.04174470463814684
Trained batch 198 in epoch 6, gen_loss = 0.4064915885577849, disc_loss = 0.04159664629663729
Trained batch 199 in epoch 6, gen_loss = 0.40665498867630956, disc_loss = 0.04155890244292095
Trained batch 200 in epoch 6, gen_loss = 0.4067900547044194, disc_loss = 0.04143233990426458
Trained batch 201 in epoch 6, gen_loss = 0.4069082975977718, disc_loss = 0.041334544264683776
Trained batch 202 in epoch 6, gen_loss = 0.4070301572677537, disc_loss = 0.04114784923923463
Trained batch 203 in epoch 6, gen_loss = 0.4073106124997139, disc_loss = 0.04099884154115274
Trained batch 204 in epoch 6, gen_loss = 0.4071127326023288, disc_loss = 0.040950374728886456
Trained batch 205 in epoch 6, gen_loss = 0.4073934738786475, disc_loss = 0.04120642039585786
Trained batch 206 in epoch 6, gen_loss = 0.4070072895374851, disc_loss = 0.04110928839589986
Trained batch 207 in epoch 6, gen_loss = 0.40685926979550946, disc_loss = 0.04093871257702211
Trained batch 208 in epoch 6, gen_loss = 0.4064963777955069, disc_loss = 0.04077131735076281
Trained batch 209 in epoch 6, gen_loss = 0.40656840049085163, disc_loss = 0.04059705922624007
Trained batch 210 in epoch 6, gen_loss = 0.4065509482300112, disc_loss = 0.040494662540704364
Trained batch 211 in epoch 6, gen_loss = 0.40666401442491784, disc_loss = 0.040637755840094235
Trained batch 212 in epoch 6, gen_loss = 0.40640970462924436, disc_loss = 0.04114267527685444
Trained batch 213 in epoch 6, gen_loss = 0.40653134339323665, disc_loss = 0.04189433787936327
Trained batch 214 in epoch 6, gen_loss = 0.40694513196168947, disc_loss = 0.04172822889048866
Trained batch 215 in epoch 6, gen_loss = 0.40688569471240044, disc_loss = 0.04160941522934957
Trained batch 216 in epoch 6, gen_loss = 0.4068528376691352, disc_loss = 0.041613333662199326
Trained batch 217 in epoch 6, gen_loss = 0.4067738337801137, disc_loss = 0.04170674298902751
Trained batch 218 in epoch 6, gen_loss = 0.4069342764273082, disc_loss = 0.0427278330066926
Trained batch 219 in epoch 6, gen_loss = 0.40721353333104743, disc_loss = 0.04343456654407253
Trained batch 220 in epoch 6, gen_loss = 0.40739926790220166, disc_loss = 0.0436018051135004
Trained batch 221 in epoch 6, gen_loss = 0.4071396001287409, disc_loss = 0.043687892201994254
Trained batch 222 in epoch 6, gen_loss = 0.4069170235518383, disc_loss = 0.043757309540980935
Trained batch 223 in epoch 6, gen_loss = 0.40692395876560894, disc_loss = 0.04370226566035334
Trained batch 224 in epoch 6, gen_loss = 0.407000449763404, disc_loss = 0.04357720910364555
Trained batch 225 in epoch 6, gen_loss = 0.40744380771586325, disc_loss = 0.04349084622618141
Trained batch 226 in epoch 6, gen_loss = 0.4077825144524091, disc_loss = 0.043361706048914844
Trained batch 227 in epoch 6, gen_loss = 0.40720271593646, disc_loss = 0.043538781133145424
Trained batch 228 in epoch 6, gen_loss = 0.40729755891983166, disc_loss = 0.04484311490132591
Trained batch 229 in epoch 6, gen_loss = 0.4074621301630269, disc_loss = 0.04467880455473357
Trained batch 230 in epoch 6, gen_loss = 0.40757047794598006, disc_loss = 0.044705207408224416
Trained batch 231 in epoch 6, gen_loss = 0.40734057398191814, disc_loss = 0.04463987717312632
Trained batch 232 in epoch 6, gen_loss = 0.4070995379671007, disc_loss = 0.04449446668124921
Trained batch 233 in epoch 6, gen_loss = 0.4072158432159668, disc_loss = 0.04438713582284334
Trained batch 234 in epoch 6, gen_loss = 0.40715033982662446, disc_loss = 0.04433383755484953
Trained batch 235 in epoch 6, gen_loss = 0.406974103364904, disc_loss = 0.04435233659035984
Trained batch 236 in epoch 6, gen_loss = 0.4070022699702138, disc_loss = 0.0443612526451878
Trained batch 237 in epoch 6, gen_loss = 0.40743114016637083, disc_loss = 0.04515322937313154
Trained batch 238 in epoch 6, gen_loss = 0.4070401898737233, disc_loss = 0.04598747069994182
Trained batch 239 in epoch 6, gen_loss = 0.4074034865945578, disc_loss = 0.046594409653334876
Trained batch 240 in epoch 6, gen_loss = 0.4076036536347322, disc_loss = 0.04645780401393246
Trained batch 241 in epoch 6, gen_loss = 0.407899808908297, disc_loss = 0.04630557173759146
Trained batch 242 in epoch 6, gen_loss = 0.4079294147069562, disc_loss = 0.04616633688919859
Trained batch 243 in epoch 6, gen_loss = 0.40793084023428744, disc_loss = 0.0460014864659227
Trained batch 244 in epoch 6, gen_loss = 0.4081448248454503, disc_loss = 0.04583509660668063
Trained batch 245 in epoch 6, gen_loss = 0.4079922374671068, disc_loss = 0.045671220811091484
Trained batch 246 in epoch 6, gen_loss = 0.40793724255523217, disc_loss = 0.04554064035215811
Trained batch 247 in epoch 6, gen_loss = 0.40755426390997823, disc_loss = 0.045433091468200265
Trained batch 248 in epoch 6, gen_loss = 0.407282952802727, disc_loss = 0.045699395137431334
Trained batch 249 in epoch 6, gen_loss = 0.40772109603881834, disc_loss = 0.04588995404820889
Trained batch 250 in epoch 6, gen_loss = 0.4076208735842154, disc_loss = 0.046346955582967024
Trained batch 251 in epoch 6, gen_loss = 0.4071785021159384, disc_loss = 0.047524865083802964
Trained batch 252 in epoch 6, gen_loss = 0.40729049460690014, disc_loss = 0.04918013520726544
Trained batch 253 in epoch 6, gen_loss = 0.4070542487572497, disc_loss = 0.049773716568528845
Trained batch 254 in epoch 6, gen_loss = 0.40672353342467665, disc_loss = 0.05017214080264025
Trained batch 255 in epoch 6, gen_loss = 0.40647669474128634, disc_loss = 0.05037930103117105
Trained batch 256 in epoch 6, gen_loss = 0.4060737539358176, disc_loss = 0.05061784837710225
Trained batch 257 in epoch 6, gen_loss = 0.4059222143056781, disc_loss = 0.050949189424796336
Trained batch 258 in epoch 6, gen_loss = 0.4057833823918376, disc_loss = 0.05143790595992163
Trained batch 259 in epoch 6, gen_loss = 0.4060940751662621, disc_loss = 0.05134667199946796
Trained batch 260 in epoch 6, gen_loss = 0.4061027721883693, disc_loss = 0.05124577898014751
Trained batch 261 in epoch 6, gen_loss = 0.40586836465442455, disc_loss = 0.051212599852037057
Trained batch 262 in epoch 6, gen_loss = 0.40583638671233174, disc_loss = 0.05111713734625382
Trained batch 263 in epoch 6, gen_loss = 0.40552755614573305, disc_loss = 0.05115549776008155
Trained batch 264 in epoch 6, gen_loss = 0.4056356171392045, disc_loss = 0.05156922611970244
Trained batch 265 in epoch 6, gen_loss = 0.4057322959030481, disc_loss = 0.051608336251754226
Trained batch 266 in epoch 6, gen_loss = 0.40586529755860234, disc_loss = 0.05146246088393144
Trained batch 267 in epoch 6, gen_loss = 0.40573222957440275, disc_loss = 0.05135323971409156
Trained batch 268 in epoch 6, gen_loss = 0.4054465098895105, disc_loss = 0.05127339570810776
Trained batch 269 in epoch 6, gen_loss = 0.4053203733982863, disc_loss = 0.05139491890850304
Trained batch 270 in epoch 6, gen_loss = 0.40523821731335125, disc_loss = 0.05181272923379339
Trained batch 271 in epoch 6, gen_loss = 0.40538282254162955, disc_loss = 0.05221657763382502
Trained batch 272 in epoch 6, gen_loss = 0.4051833899466546, disc_loss = 0.052188450834737755
Trained batch 273 in epoch 6, gen_loss = 0.4052483202332128, disc_loss = 0.05203292065684133
Trained batch 274 in epoch 6, gen_loss = 0.4054289010438052, disc_loss = 0.051989959176121786
Trained batch 275 in epoch 6, gen_loss = 0.40530112374951877, disc_loss = 0.0519443957254871
Trained batch 276 in epoch 6, gen_loss = 0.4053760729326668, disc_loss = 0.05178190015394254
Trained batch 277 in epoch 6, gen_loss = 0.40504007909795364, disc_loss = 0.0518026209558635
Trained batch 278 in epoch 6, gen_loss = 0.40535386478174545, disc_loss = 0.05190651524080945
Trained batch 279 in epoch 6, gen_loss = 0.40519461993660244, disc_loss = 0.051746405490640815
Trained batch 280 in epoch 6, gen_loss = 0.4051049138515445, disc_loss = 0.051672390462446205
Trained batch 281 in epoch 6, gen_loss = 0.40539568609802434, disc_loss = 0.05150597706248865
Trained batch 282 in epoch 6, gen_loss = 0.4055543033267921, disc_loss = 0.051478757492559486
Trained batch 283 in epoch 6, gen_loss = 0.4051281063699386, disc_loss = 0.05174485408999419
Trained batch 284 in epoch 6, gen_loss = 0.40511479900594344, disc_loss = 0.05168053633206638
Trained batch 285 in epoch 6, gen_loss = 0.40525282596374723, disc_loss = 0.051614926046027534
Trained batch 286 in epoch 6, gen_loss = 0.4051689572035228, disc_loss = 0.051486585580481005
Trained batch 287 in epoch 6, gen_loss = 0.4052783580910828, disc_loss = 0.05138436127243848
Trained batch 288 in epoch 6, gen_loss = 0.40541849829333876, disc_loss = 0.05132540385561083
Trained batch 289 in epoch 6, gen_loss = 0.4056493040816537, disc_loss = 0.05162337700402814
Trained batch 290 in epoch 6, gen_loss = 0.405427900069358, disc_loss = 0.05182108380895786
Trained batch 291 in epoch 6, gen_loss = 0.4057369118888084, disc_loss = 0.05167093966076508
Trained batch 292 in epoch 6, gen_loss = 0.40565018920361384, disc_loss = 0.05192786064745903
Trained batch 293 in epoch 6, gen_loss = 0.4052662461185131, disc_loss = 0.0519760425517741
Trained batch 294 in epoch 6, gen_loss = 0.40527866927243894, disc_loss = 0.05189937849339666
Trained batch 295 in epoch 6, gen_loss = 0.4054169270235139, disc_loss = 0.05174168908883616
Trained batch 296 in epoch 6, gen_loss = 0.40542361270699034, disc_loss = 0.05159884327254337
Trained batch 297 in epoch 6, gen_loss = 0.4055682248717186, disc_loss = 0.05147593887600948
Trained batch 298 in epoch 6, gen_loss = 0.4054776645424374, disc_loss = 0.051396644618954
Trained batch 299 in epoch 6, gen_loss = 0.40536432902018227, disc_loss = 0.052279397532499085
Trained batch 300 in epoch 6, gen_loss = 0.405193009942869, disc_loss = 0.053213596428308224
Trained batch 301 in epoch 6, gen_loss = 0.40529566667727285, disc_loss = 0.05361255321001005
Trained batch 302 in epoch 6, gen_loss = 0.4051865564517849, disc_loss = 0.05389465385258026
Trained batch 303 in epoch 6, gen_loss = 0.40522171253044353, disc_loss = 0.054211883693106325
Trained batch 304 in epoch 6, gen_loss = 0.4051743872830125, disc_loss = 0.05413775407159548
Trained batch 305 in epoch 6, gen_loss = 0.40510816677333483, disc_loss = 0.05400688482183671
Trained batch 306 in epoch 6, gen_loss = 0.40496692216745805, disc_loss = 0.05395600264998159
Trained batch 307 in epoch 6, gen_loss = 0.4047900533134287, disc_loss = 0.053949579715202624
Trained batch 308 in epoch 6, gen_loss = 0.4046966931194935, disc_loss = 0.054242421867639355
Trained batch 309 in epoch 6, gen_loss = 0.40433780416365595, disc_loss = 0.05505089651447751
Trained batch 310 in epoch 6, gen_loss = 0.4043703806553623, disc_loss = 0.05522285346495784
Trained batch 311 in epoch 6, gen_loss = 0.40446828506313837, disc_loss = 0.055608845743476056
Trained batch 312 in epoch 6, gen_loss = 0.40447130951637655, disc_loss = 0.05676542462694783
Trained batch 313 in epoch 6, gen_loss = 0.4043156818789282, disc_loss = 0.057165638298229286
Trained batch 314 in epoch 6, gen_loss = 0.4042760717490363, disc_loss = 0.05745386511811779
Trained batch 315 in epoch 6, gen_loss = 0.4040725049150141, disc_loss = 0.057776745194362926
Trained batch 316 in epoch 6, gen_loss = 0.4038562191773664, disc_loss = 0.05804328674271303
Trained batch 317 in epoch 6, gen_loss = 0.40358917349539464, disc_loss = 0.05809377210943977
Trained batch 318 in epoch 6, gen_loss = 0.4037868728084624, disc_loss = 0.0583735206215511
Trained batch 319 in epoch 6, gen_loss = 0.4035794572904706, disc_loss = 0.05835412201486179
Trained batch 320 in epoch 6, gen_loss = 0.40343289768955787, disc_loss = 0.05851494681998229
Trained batch 321 in epoch 6, gen_loss = 0.4035350457296608, disc_loss = 0.058440463036813585
Trained batch 322 in epoch 6, gen_loss = 0.40340495266412435, disc_loss = 0.05830122399916613
Trained batch 323 in epoch 6, gen_loss = 0.40316979467500874, disc_loss = 0.05827242140385127
Trained batch 324 in epoch 6, gen_loss = 0.4030643554834219, disc_loss = 0.05850458135756736
Trained batch 325 in epoch 6, gen_loss = 0.40306760517000423, disc_loss = 0.05914611876527979
Trained batch 326 in epoch 6, gen_loss = 0.40301944903277476, disc_loss = 0.05908005543135744
Trained batch 327 in epoch 6, gen_loss = 0.40286498644003055, disc_loss = 0.05897436884200632
Trained batch 328 in epoch 6, gen_loss = 0.40305944969226526, disc_loss = 0.05886702500864025
Trained batch 329 in epoch 6, gen_loss = 0.40317685215762167, disc_loss = 0.05888567831945803
Trained batch 330 in epoch 6, gen_loss = 0.4031613964328593, disc_loss = 0.0590920728185352
Trained batch 331 in epoch 6, gen_loss = 0.40307873801653643, disc_loss = 0.059258135134516936
Trained batch 332 in epoch 6, gen_loss = 0.4030995759162101, disc_loss = 0.05946119034357995
Trained batch 333 in epoch 6, gen_loss = 0.4031356683748211, disc_loss = 0.05938236382831736
Trained batch 334 in epoch 6, gen_loss = 0.40331280356022847, disc_loss = 0.05939508715241369
Trained batch 335 in epoch 6, gen_loss = 0.4030300078115293, disc_loss = 0.06021895794921355
Trained batch 336 in epoch 6, gen_loss = 0.4032644782469605, disc_loss = 0.061054575898842084
Trained batch 337 in epoch 6, gen_loss = 0.40336424041781904, disc_loss = 0.061064834280088326
Trained batch 338 in epoch 6, gen_loss = 0.403072043418181, disc_loss = 0.06113813919493253
Trained batch 339 in epoch 6, gen_loss = 0.4030251794878174, disc_loss = 0.06112244526704992
Trained batch 340 in epoch 6, gen_loss = 0.40293506294751097, disc_loss = 0.06114213892717537
Trained batch 341 in epoch 6, gen_loss = 0.402593376517993, disc_loss = 0.061177734969788344
Trained batch 342 in epoch 6, gen_loss = 0.4028170694415145, disc_loss = 0.061103579273946995
Trained batch 343 in epoch 6, gen_loss = 0.4028729485391184, disc_loss = 0.06101284103351645
Trained batch 344 in epoch 6, gen_loss = 0.40286457737286885, disc_loss = 0.06103568810065264
Trained batch 345 in epoch 6, gen_loss = 0.4026457152270168, disc_loss = 0.06092594645586338
Trained batch 346 in epoch 6, gen_loss = 0.40249238277031296, disc_loss = 0.06095640822743154
Trained batch 347 in epoch 6, gen_loss = 0.402553356156267, disc_loss = 0.06081497249924096
Trained batch 348 in epoch 6, gen_loss = 0.40249536209939885, disc_loss = 0.060668433096425285
Trained batch 349 in epoch 6, gen_loss = 0.40262816974094934, disc_loss = 0.06052101948764175
Trained batch 350 in epoch 6, gen_loss = 0.4026499642775609, disc_loss = 0.06038426677165739
Trained batch 351 in epoch 6, gen_loss = 0.40270300912247464, disc_loss = 0.060231113207754046
Trained batch 352 in epoch 6, gen_loss = 0.4025311059722144, disc_loss = 0.06010079984790606
Trained batch 353 in epoch 6, gen_loss = 0.4025363401841309, disc_loss = 0.059983031986686426
Trained batch 354 in epoch 6, gen_loss = 0.4025836751494609, disc_loss = 0.05983547987744317
Trained batch 355 in epoch 6, gen_loss = 0.4024838914027375, disc_loss = 0.05976073815045209
Trained batch 356 in epoch 6, gen_loss = 0.40255737388167395, disc_loss = 0.05968906735304837
Trained batch 357 in epoch 6, gen_loss = 0.40271271124232416, disc_loss = 0.059696305009234674
Trained batch 358 in epoch 6, gen_loss = 0.40299824253762334, disc_loss = 0.05988040203967944
Trained batch 359 in epoch 6, gen_loss = 0.4030370079808765, disc_loss = 0.05976611232682545
Trained batch 360 in epoch 6, gen_loss = 0.4031457116729335, disc_loss = 0.05962928701282435
Trained batch 361 in epoch 6, gen_loss = 0.40332736972287214, disc_loss = 0.0594954061166265
Trained batch 362 in epoch 6, gen_loss = 0.40322691161113666, disc_loss = 0.05937938212504298
Trained batch 363 in epoch 6, gen_loss = 0.4031505375118046, disc_loss = 0.059249770448282155
Trained batch 364 in epoch 6, gen_loss = 0.4031617719833165, disc_loss = 0.05912899524675146
Trained batch 365 in epoch 6, gen_loss = 0.4030669344578936, disc_loss = 0.05905760744970821
Trained batch 366 in epoch 6, gen_loss = 0.40316612990090894, disc_loss = 0.05893831302625018
Trained batch 367 in epoch 6, gen_loss = 0.4031907703889453, disc_loss = 0.05879603197694371
Trained batch 368 in epoch 6, gen_loss = 0.40299621264785934, disc_loss = 0.05870290488688664
Trained batch 369 in epoch 6, gen_loss = 0.4027693112154265, disc_loss = 0.05911644870805478
Trained batch 370 in epoch 6, gen_loss = 0.4030675385197539, disc_loss = 0.05988712247769848
Trained batch 371 in epoch 6, gen_loss = 0.40291854138335875, disc_loss = 0.0601537542521543
Trained batch 372 in epoch 6, gen_loss = 0.40265240194650503, disc_loss = 0.06078353556604611
Trained batch 373 in epoch 6, gen_loss = 0.4026756486631332, disc_loss = 0.06100968331693706
Trained batch 374 in epoch 6, gen_loss = 0.40265125219027204, disc_loss = 0.061227706039324405
Trained batch 375 in epoch 6, gen_loss = 0.40265605273715993, disc_loss = 0.06123795485597084
Trained batch 376 in epoch 6, gen_loss = 0.4027939225381502, disc_loss = 0.06119863486809246
Trained batch 377 in epoch 6, gen_loss = 0.40283049682460764, disc_loss = 0.06117920082237414
Trained batch 378 in epoch 6, gen_loss = 0.4027386935216456, disc_loss = 0.06107204890500331
Trained batch 379 in epoch 6, gen_loss = 0.4029579499834462, disc_loss = 0.06104503832206032
Trained batch 380 in epoch 6, gen_loss = 0.4028583544445789, disc_loss = 0.06098475687027349
Trained batch 381 in epoch 6, gen_loss = 0.402707353078258, disc_loss = 0.061081384629844956
Trained batch 382 in epoch 6, gen_loss = 0.40280784398083896, disc_loss = 0.06147996624554787
Trained batch 383 in epoch 6, gen_loss = 0.402670370026802, disc_loss = 0.061558550518990764
Trained batch 384 in epoch 6, gen_loss = 0.40254856843452946, disc_loss = 0.06144844149360312
Trained batch 385 in epoch 6, gen_loss = 0.4024814200524839, disc_loss = 0.06133411725720034
Trained batch 386 in epoch 6, gen_loss = 0.4026657340600509, disc_loss = 0.06119632822442174
Trained batch 387 in epoch 6, gen_loss = 0.4027434414655892, disc_loss = 0.06107835800893432
Trained batch 388 in epoch 6, gen_loss = 0.4028501840054529, disc_loss = 0.060986327605350735
Trained batch 389 in epoch 6, gen_loss = 0.4027006435088622, disc_loss = 0.06088451696261286
Trained batch 390 in epoch 6, gen_loss = 0.4026545687862065, disc_loss = 0.060991178530499415
Trained batch 391 in epoch 6, gen_loss = 0.4026434343232184, disc_loss = 0.06106943942128909
Trained batch 392 in epoch 6, gen_loss = 0.40287141884859584, disc_loss = 0.06096437684279267
Trained batch 393 in epoch 6, gen_loss = 0.4028807263537712, disc_loss = 0.0608560943185366
Trained batch 394 in epoch 6, gen_loss = 0.40299646809131284, disc_loss = 0.0607337296474725
Trained batch 395 in epoch 6, gen_loss = 0.4029962158564365, disc_loss = 0.060686718455558133
Trained batch 396 in epoch 6, gen_loss = 0.4031133186306701, disc_loss = 0.06106803647796119
Trained batch 397 in epoch 6, gen_loss = 0.40286884939850276, disc_loss = 0.061209217621242845
Trained batch 398 in epoch 6, gen_loss = 0.40296256183681634, disc_loss = 0.06119440974875407
Trained batch 399 in epoch 6, gen_loss = 0.40307554230093956, disc_loss = 0.06110241897345986
Trained batch 400 in epoch 6, gen_loss = 0.4030719067241783, disc_loss = 0.0609698563975577
Trained batch 401 in epoch 6, gen_loss = 0.40316670851327885, disc_loss = 0.06084327040812399
Trained batch 402 in epoch 6, gen_loss = 0.4032926793873458, disc_loss = 0.06071707132739239
Trained batch 403 in epoch 6, gen_loss = 0.40328646613524693, disc_loss = 0.06057844552416631
Trained batch 404 in epoch 6, gen_loss = 0.40319083678869555, disc_loss = 0.06043773925069858
Trained batch 405 in epoch 6, gen_loss = 0.40314964869339476, disc_loss = 0.06029854280635568
Trained batch 406 in epoch 6, gen_loss = 0.40299407006481647, disc_loss = 0.06016408308370254
Trained batch 407 in epoch 6, gen_loss = 0.40306657793767314, disc_loss = 0.06006006403899222
Trained batch 408 in epoch 6, gen_loss = 0.40301672309127007, disc_loss = 0.0599226143955729
Trained batch 409 in epoch 6, gen_loss = 0.40277097399641826, disc_loss = 0.059894367051878714
Trained batch 410 in epoch 6, gen_loss = 0.4027262030581778, disc_loss = 0.05982171375997854
Trained batch 411 in epoch 6, gen_loss = 0.4026460204888316, disc_loss = 0.060044081681588826
Trained batch 412 in epoch 6, gen_loss = 0.4026425321367693, disc_loss = 0.060153492641822404
Trained batch 413 in epoch 6, gen_loss = 0.40243398013034304, disc_loss = 0.06041319603392863
Trained batch 414 in epoch 6, gen_loss = 0.4025708347199911, disc_loss = 0.06053162576092115
Trained batch 415 in epoch 6, gen_loss = 0.40240881491739017, disc_loss = 0.060423215458285995
Trained batch 416 in epoch 6, gen_loss = 0.4023921276739747, disc_loss = 0.0603099282020234
Trained batch 417 in epoch 6, gen_loss = 0.4023054359061866, disc_loss = 0.06031094576704481
Trained batch 418 in epoch 6, gen_loss = 0.40254133897066685, disc_loss = 0.06037257383810912
Trained batch 419 in epoch 6, gen_loss = 0.40283657369159515, disc_loss = 0.06025123147050007
Trained batch 420 in epoch 6, gen_loss = 0.4027570114424563, disc_loss = 0.0602712275652821
Trained batch 421 in epoch 6, gen_loss = 0.402689965768448, disc_loss = 0.060779279209364434
Trained batch 422 in epoch 6, gen_loss = 0.40267448264656336, disc_loss = 0.06081215476828581
Trained batch 423 in epoch 6, gen_loss = 0.40261040086734967, disc_loss = 0.0607010015332632
Trained batch 424 in epoch 6, gen_loss = 0.40273145465289845, disc_loss = 0.060567425442311695
Trained batch 425 in epoch 6, gen_loss = 0.4029556006333078, disc_loss = 0.060457198531913434
Trained batch 426 in epoch 6, gen_loss = 0.40284904635203805, disc_loss = 0.060331095669819895
Trained batch 427 in epoch 6, gen_loss = 0.4029825990584409, disc_loss = 0.06020526387989869
Trained batch 428 in epoch 6, gen_loss = 0.4028938937159407, disc_loss = 0.06009238814861277
Trained batch 429 in epoch 6, gen_loss = 0.40327795293442037, disc_loss = 0.06001594623897311
Trained batch 430 in epoch 6, gen_loss = 0.4034306092356308, disc_loss = 0.05992386275967216
Trained batch 431 in epoch 6, gen_loss = 0.40350848091421304, disc_loss = 0.05979769818346809
Trained batch 432 in epoch 6, gen_loss = 0.403538355513478, disc_loss = 0.059672149720948024
Trained batch 433 in epoch 6, gen_loss = 0.4035972926061824, disc_loss = 0.05954669473139131
Trained batch 434 in epoch 6, gen_loss = 0.40353396452706436, disc_loss = 0.059424138284320464
Trained batch 435 in epoch 6, gen_loss = 0.4035456806011156, disc_loss = 0.05930106730067915
Trained batch 436 in epoch 6, gen_loss = 0.40356659909680453, disc_loss = 0.05918506260223908
Trained batch 437 in epoch 6, gen_loss = 0.4034785484750521, disc_loss = 0.05906973923471454
Trained batch 438 in epoch 6, gen_loss = 0.40337463778895505, disc_loss = 0.058970650149920874
Trained batch 439 in epoch 6, gen_loss = 0.4034813163632696, disc_loss = 0.0588843623271466
Trained batch 440 in epoch 6, gen_loss = 0.4033746881549861, disc_loss = 0.058874557872858245
Trained batch 441 in epoch 6, gen_loss = 0.4036002965534435, disc_loss = 0.05940450793785376
Trained batch 442 in epoch 6, gen_loss = 0.40370842895174136, disc_loss = 0.05933179924239323
Trained batch 443 in epoch 6, gen_loss = 0.4035897428119505, disc_loss = 0.05956954677769629
Trained batch 444 in epoch 6, gen_loss = 0.40376714240299183, disc_loss = 0.05952551323983274
Trained batch 445 in epoch 6, gen_loss = 0.40380312602616214, disc_loss = 0.05946709868088866
Trained batch 446 in epoch 6, gen_loss = 0.403948392910712, disc_loss = 0.0593534655216873
Trained batch 447 in epoch 6, gen_loss = 0.40383657620155383, disc_loss = 0.05926383861619148
Trained batch 448 in epoch 6, gen_loss = 0.4039682807662174, disc_loss = 0.059172775280062435
Trained batch 449 in epoch 6, gen_loss = 0.40384196062882743, disc_loss = 0.059091309531488355
Trained batch 450 in epoch 6, gen_loss = 0.4037263344502502, disc_loss = 0.05959376695146681
Trained batch 451 in epoch 6, gen_loss = 0.40400635971959714, disc_loss = 0.060130698185010226
Trained batch 452 in epoch 6, gen_loss = 0.4040675144190293, disc_loss = 0.06025968000979449
Trained batch 453 in epoch 6, gen_loss = 0.40391349746529753, disc_loss = 0.06026990151151785
Trained batch 454 in epoch 6, gen_loss = 0.4038633813569834, disc_loss = 0.06020607142146309
Trained batch 455 in epoch 6, gen_loss = 0.40381813055852, disc_loss = 0.06010868102455054
Trained batch 456 in epoch 6, gen_loss = 0.4036475440866316, disc_loss = 0.060060168931329996
Trained batch 457 in epoch 6, gen_loss = 0.4036442371304899, disc_loss = 0.060141899678896805
Trained batch 458 in epoch 6, gen_loss = 0.4039652241730742, disc_loss = 0.060849669625808143
Testing Epoch 6
Training Epoch 7
Trained batch 0 in epoch 7, gen_loss = 0.45898520946502686, disc_loss = 0.06039425730705261
Trained batch 1 in epoch 7, gen_loss = 0.40280501544475555, disc_loss = 0.054826440289616585
Trained batch 2 in epoch 7, gen_loss = 0.3814774552981059, disc_loss = 0.052218822141488395
Trained batch 3 in epoch 7, gen_loss = 0.3908770680427551, disc_loss = 0.046022660098969936
Trained batch 4 in epoch 7, gen_loss = 0.396307909488678, disc_loss = 0.04324208348989487
Trained batch 5 in epoch 7, gen_loss = 0.38732896248499554, disc_loss = 0.038287027894208826
Trained batch 6 in epoch 7, gen_loss = 0.38280741231782095, disc_loss = 0.03712842334061861
Trained batch 7 in epoch 7, gen_loss = 0.3823408894240856, disc_loss = 0.039847037638537586
Trained batch 8 in epoch 7, gen_loss = 0.38888412051730686, disc_loss = 0.03893773661305507
Trained batch 9 in epoch 7, gen_loss = 0.3974944084882736, disc_loss = 0.03819267069920897
Trained batch 10 in epoch 7, gen_loss = 0.4025899713689631, disc_loss = 0.06514632083814252
Trained batch 11 in epoch 7, gen_loss = 0.3960205763578415, disc_loss = 0.0742838412988931
Trained batch 12 in epoch 7, gen_loss = 0.3999788165092468, disc_loss = 0.06920562834980395
Trained batch 13 in epoch 7, gen_loss = 0.4044586590358189, disc_loss = 0.06655590375885367
Trained batch 14 in epoch 7, gen_loss = 0.4073679586251577, disc_loss = 0.06302046813070775
Trained batch 15 in epoch 7, gen_loss = 0.40790778771042824, disc_loss = 0.06075044209137559
Trained batch 16 in epoch 7, gen_loss = 0.4009172197650461, disc_loss = 0.05854232927017352
Trained batch 17 in epoch 7, gen_loss = 0.4029369155565898, disc_loss = 0.0575487097311351
Trained batch 18 in epoch 7, gen_loss = 0.39851438685467366, disc_loss = 0.05750355349951669
Trained batch 19 in epoch 7, gen_loss = 0.40062825828790666, disc_loss = 0.0605332869105041
Trained batch 20 in epoch 7, gen_loss = 0.39978007901282536, disc_loss = 0.05981126702612355
Trained batch 21 in epoch 7, gen_loss = 0.398694937879389, disc_loss = 0.06043669810010628
Trained batch 22 in epoch 7, gen_loss = 0.39657430674718774, disc_loss = 0.058271126821637154
Trained batch 23 in epoch 7, gen_loss = 0.3983263559639454, disc_loss = 0.05667059115755061
Trained batch 24 in epoch 7, gen_loss = 0.396147882938385, disc_loss = 0.05498058386147022
Trained batch 25 in epoch 7, gen_loss = 0.39855303443395174, disc_loss = 0.05381531146569894
Trained batch 26 in epoch 7, gen_loss = 0.39698507609190764, disc_loss = 0.052262307386155483
Trained batch 27 in epoch 7, gen_loss = 0.3961153190050806, disc_loss = 0.05054979872823294
Trained batch 28 in epoch 7, gen_loss = 0.4000085438119954, disc_loss = 0.04958964198635056
Trained batch 29 in epoch 7, gen_loss = 0.4002226630846659, disc_loss = 0.04820243804715574
Trained batch 30 in epoch 7, gen_loss = 0.39894959522831824, disc_loss = 0.04763136841657181
Trained batch 31 in epoch 7, gen_loss = 0.400293106213212, disc_loss = 0.04699368013825733
Trained batch 32 in epoch 7, gen_loss = 0.4001887458743471, disc_loss = 0.047731764007811296
Trained batch 33 in epoch 7, gen_loss = 0.39882411413332997, disc_loss = 0.04805426339290159
Trained batch 34 in epoch 7, gen_loss = 0.4002723208495549, disc_loss = 0.04756656668281981
Trained batch 35 in epoch 7, gen_loss = 0.4014505586690373, disc_loss = 0.04661198287633144
Trained batch 36 in epoch 7, gen_loss = 0.402724904788507, disc_loss = 0.04553813843459294
Trained batch 37 in epoch 7, gen_loss = 0.40265840684112747, disc_loss = 0.04444189742207527
Trained batch 38 in epoch 7, gen_loss = 0.40282361324016863, disc_loss = 0.0438852398059307
Trained batch 39 in epoch 7, gen_loss = 0.40203591138124467, disc_loss = 0.04335820209234953
Trained batch 40 in epoch 7, gen_loss = 0.4051327400091218, disc_loss = 0.04242912055243079
Trained batch 41 in epoch 7, gen_loss = 0.40660025605133604, disc_loss = 0.04163381632506138
Trained batch 42 in epoch 7, gen_loss = 0.40454555528108466, disc_loss = 0.042155337519943714
Trained batch 43 in epoch 7, gen_loss = 0.4069688333706422, disc_loss = 0.04534108596007255
Trained batch 44 in epoch 7, gen_loss = 0.4078055262565613, disc_loss = 0.044516151481204566
Trained batch 45 in epoch 7, gen_loss = 0.40632812354875647, disc_loss = 0.04405917381138905
Trained batch 46 in epoch 7, gen_loss = 0.4066569278848932, disc_loss = 0.043341806217869545
Trained batch 47 in epoch 7, gen_loss = 0.4078993896643321, disc_loss = 0.042632151453290135
Trained batch 48 in epoch 7, gen_loss = 0.4077821276625808, disc_loss = 0.04190284151545897
Trained batch 49 in epoch 7, gen_loss = 0.4081370437145233, disc_loss = 0.04121811886318028
Trained batch 50 in epoch 7, gen_loss = 0.40638506821557585, disc_loss = 0.0409392472447864
Trained batch 51 in epoch 7, gen_loss = 0.4072721629188611, disc_loss = 0.0449725025996136
Trained batch 52 in epoch 7, gen_loss = 0.40681147069301243, disc_loss = 0.05652932321020174
Trained batch 53 in epoch 7, gen_loss = 0.4062826837654467, disc_loss = 0.05894092171176992
Trained batch 54 in epoch 7, gen_loss = 0.4046968481757424, disc_loss = 0.05980848430401899
Trained batch 55 in epoch 7, gen_loss = 0.4030058378619807, disc_loss = 0.0612742297234945
Trained batch 56 in epoch 7, gen_loss = 0.4034826206533532, disc_loss = 0.06201751168261756
Trained batch 57 in epoch 7, gen_loss = 0.40151649353833035, disc_loss = 0.06185266064833207
Trained batch 58 in epoch 7, gen_loss = 0.4013150864738529, disc_loss = 0.06116989299939093
Trained batch 59 in epoch 7, gen_loss = 0.401336429019769, disc_loss = 0.06051978894975037
Trained batch 60 in epoch 7, gen_loss = 0.4001322115053896, disc_loss = 0.06020361579740878
Trained batch 61 in epoch 7, gen_loss = 0.40028605105415466, disc_loss = 0.05937388491997075
Trained batch 62 in epoch 7, gen_loss = 0.39877294406058295, disc_loss = 0.05874295752229435
Trained batch 63 in epoch 7, gen_loss = 0.39872670406475663, disc_loss = 0.058599923802830745
Trained batch 64 in epoch 7, gen_loss = 0.396733453640571, disc_loss = 0.059467856879704274
Trained batch 65 in epoch 7, gen_loss = 0.3974083165327708, disc_loss = 0.06023770938345203
Trained batch 66 in epoch 7, gen_loss = 0.3979979130759168, disc_loss = 0.05955835896780464
Trained batch 67 in epoch 7, gen_loss = 0.3968864324338296, disc_loss = 0.058793915339800364
Trained batch 68 in epoch 7, gen_loss = 0.3966843135978865, disc_loss = 0.05811398437219686
Trained batch 69 in epoch 7, gen_loss = 0.3968787465776716, disc_loss = 0.057763165115777934
Trained batch 70 in epoch 7, gen_loss = 0.3975897271868209, disc_loss = 0.05744908533623101
Trained batch 71 in epoch 7, gen_loss = 0.397719575299157, disc_loss = 0.0567501120062338
Trained batch 72 in epoch 7, gen_loss = 0.3979132346910973, disc_loss = 0.056207287648361026
Trained batch 73 in epoch 7, gen_loss = 0.39747072474376577, disc_loss = 0.055536599074666564
Trained batch 74 in epoch 7, gen_loss = 0.39821930686632795, disc_loss = 0.05495387248694897
Trained batch 75 in epoch 7, gen_loss = 0.39899035151067536, disc_loss = 0.05437616228224024
Trained batch 76 in epoch 7, gen_loss = 0.39936969264761196, disc_loss = 0.053977708235479795
Trained batch 77 in epoch 7, gen_loss = 0.39958341266864383, disc_loss = 0.0536095143104784
Trained batch 78 in epoch 7, gen_loss = 0.39936675112458725, disc_loss = 0.05310214776545763
Trained batch 79 in epoch 7, gen_loss = 0.40055589862167834, disc_loss = 0.05256253381958231
Trained batch 80 in epoch 7, gen_loss = 0.4006442317256221, disc_loss = 0.05201032397877655
Trained batch 81 in epoch 7, gen_loss = 0.40064284241781, disc_loss = 0.0516606882191831
Trained batch 82 in epoch 7, gen_loss = 0.4018925762320139, disc_loss = 0.05129997790173953
Trained batch 83 in epoch 7, gen_loss = 0.40257134572381065, disc_loss = 0.050965729114111694
Trained batch 84 in epoch 7, gen_loss = 0.4023661806302912, disc_loss = 0.05089044810875374
Trained batch 85 in epoch 7, gen_loss = 0.40209029614925385, disc_loss = 0.05037814648930243
Trained batch 86 in epoch 7, gen_loss = 0.402051975329717, disc_loss = 0.05046685962220547
Trained batch 87 in epoch 7, gen_loss = 0.4016335698013956, disc_loss = 0.0517374803470871
Trained batch 88 in epoch 7, gen_loss = 0.40271077732021887, disc_loss = 0.05496766641631388
Trained batch 89 in epoch 7, gen_loss = 0.40248304671711393, disc_loss = 0.054814396234643126
Trained batch 90 in epoch 7, gen_loss = 0.40185137993686804, disc_loss = 0.054658181161957455
Trained batch 91 in epoch 7, gen_loss = 0.40277215773644653, disc_loss = 0.05423981009516865
Trained batch 92 in epoch 7, gen_loss = 0.402747098476656, disc_loss = 0.053820948842512345
Trained batch 93 in epoch 7, gen_loss = 0.4030976333516709, disc_loss = 0.05388459499350729
Trained batch 94 in epoch 7, gen_loss = 0.4044251617632414, disc_loss = 0.05351635119142501
Trained batch 95 in epoch 7, gen_loss = 0.4039276350910465, disc_loss = 0.053134963862248696
Trained batch 96 in epoch 7, gen_loss = 0.40330215428293364, disc_loss = 0.05350035768405525
Trained batch 97 in epoch 7, gen_loss = 0.4035733187076997, disc_loss = 0.05634748237682696
Trained batch 98 in epoch 7, gen_loss = 0.4036925991978308, disc_loss = 0.05588393233660044
Trained batch 99 in epoch 7, gen_loss = 0.4037535563111305, disc_loss = 0.055585154187865554
Trained batch 100 in epoch 7, gen_loss = 0.4041596465181596, disc_loss = 0.0551881236669672
Trained batch 101 in epoch 7, gen_loss = 0.40439986539822, disc_loss = 0.05511046556628072
Trained batch 102 in epoch 7, gen_loss = 0.404070888908164, disc_loss = 0.05501047320645845
Trained batch 103 in epoch 7, gen_loss = 0.403819879087118, disc_loss = 0.054558925702272415
Trained batch 104 in epoch 7, gen_loss = 0.4039353404726301, disc_loss = 0.054792271638732584
Trained batch 105 in epoch 7, gen_loss = 0.40377902506657365, disc_loss = 0.054778176460872
Trained batch 106 in epoch 7, gen_loss = 0.4035879092238774, disc_loss = 0.05432820551219248
Trained batch 107 in epoch 7, gen_loss = 0.40395732748287694, disc_loss = 0.05394643921560297
Trained batch 108 in epoch 7, gen_loss = 0.403606438035265, disc_loss = 0.0535595520963431
Trained batch 109 in epoch 7, gen_loss = 0.40436852005395024, disc_loss = 0.05317681910554794
Trained batch 110 in epoch 7, gen_loss = 0.4034530332496574, disc_loss = 0.053110938867436605
Trained batch 111 in epoch 7, gen_loss = 0.4034966020179646, disc_loss = 0.053597782318580096
Trained batch 112 in epoch 7, gen_loss = 0.4035950028790837, disc_loss = 0.05642459875763913
Trained batch 113 in epoch 7, gen_loss = 0.4037066977797893, disc_loss = 0.058953400223368875
Trained batch 114 in epoch 7, gen_loss = 0.40436358011287193, disc_loss = 0.05866552744789616
Trained batch 115 in epoch 7, gen_loss = 0.4042648611397579, disc_loss = 0.05834973055532138
Trained batch 116 in epoch 7, gen_loss = 0.40378335958872086, disc_loss = 0.058259495251422
Trained batch 117 in epoch 7, gen_loss = 0.4037049301600052, disc_loss = 0.05820016665147396
Trained batch 118 in epoch 7, gen_loss = 0.4038060174769714, disc_loss = 0.05795352941598086
Trained batch 119 in epoch 7, gen_loss = 0.40301406333843864, disc_loss = 0.05856344989733771
Trained batch 120 in epoch 7, gen_loss = 0.4030544179037583, disc_loss = 0.058309371309924474
Trained batch 121 in epoch 7, gen_loss = 0.40356696409280185, disc_loss = 0.058584311087692124
Trained batch 122 in epoch 7, gen_loss = 0.40413226320491574, disc_loss = 0.058825810625392
Trained batch 123 in epoch 7, gen_loss = 0.4046776138486401, disc_loss = 0.0584590942110686
Trained batch 124 in epoch 7, gen_loss = 0.4047815170288086, disc_loss = 0.05804956951364875
Trained batch 125 in epoch 7, gen_loss = 0.40436056611083804, disc_loss = 0.057667154903774935
Trained batch 126 in epoch 7, gen_loss = 0.40425477065439297, disc_loss = 0.05783357902056002
Trained batch 127 in epoch 7, gen_loss = 0.40369459986686707, disc_loss = 0.06013433370026178
Trained batch 128 in epoch 7, gen_loss = 0.40285738932993986, disc_loss = 0.0607609284731249
Trained batch 129 in epoch 7, gen_loss = 0.40304019978413214, disc_loss = 0.061169689861484446
Trained batch 130 in epoch 7, gen_loss = 0.4027129661945896, disc_loss = 0.06083462984151854
Trained batch 131 in epoch 7, gen_loss = 0.40180640916029614, disc_loss = 0.060714587311711955
Trained batch 132 in epoch 7, gen_loss = 0.4014818168672404, disc_loss = 0.06043909394525384
Trained batch 133 in epoch 7, gen_loss = 0.40119164070086694, disc_loss = 0.06084510439019928
Trained batch 134 in epoch 7, gen_loss = 0.4015155754707478, disc_loss = 0.0613009561508618
Trained batch 135 in epoch 7, gen_loss = 0.40153105666532235, disc_loss = 0.06132189918186187
Trained batch 136 in epoch 7, gen_loss = 0.40119844870845767, disc_loss = 0.06204586861872651
Trained batch 137 in epoch 7, gen_loss = 0.4012971833564233, disc_loss = 0.06271513788690926
Trained batch 138 in epoch 7, gen_loss = 0.4018697097575922, disc_loss = 0.06245622842525728
Trained batch 139 in epoch 7, gen_loss = 0.40200039190905434, disc_loss = 0.06258266796690545
Trained batch 140 in epoch 7, gen_loss = 0.4023611562471863, disc_loss = 0.062308278235322825
Trained batch 141 in epoch 7, gen_loss = 0.40241124638369385, disc_loss = 0.06197591693612786
Trained batch 142 in epoch 7, gen_loss = 0.4019660374501368, disc_loss = 0.06210214239252093
Trained batch 143 in epoch 7, gen_loss = 0.4021190119286378, disc_loss = 0.06239995873571994
Trained batch 144 in epoch 7, gen_loss = 0.4019596817164586, disc_loss = 0.06211657255309923
Trained batch 145 in epoch 7, gen_loss = 0.4018091302211971, disc_loss = 0.062317094558288585
Trained batch 146 in epoch 7, gen_loss = 0.40132484367104615, disc_loss = 0.06212868732495271
Trained batch 147 in epoch 7, gen_loss = 0.4016721478185138, disc_loss = 0.06228438979706954
Trained batch 148 in epoch 7, gen_loss = 0.4007988884144981, disc_loss = 0.06501527374060262
Trained batch 149 in epoch 7, gen_loss = 0.40128014246622723, disc_loss = 0.0657077748918285
Trained batch 150 in epoch 7, gen_loss = 0.40156654845799833, disc_loss = 0.06544685030405391
Trained batch 151 in epoch 7, gen_loss = 0.4007962634296794, disc_loss = 0.06539818524125669
Trained batch 152 in epoch 7, gen_loss = 0.40032487425928803, disc_loss = 0.06546640227810523
Trained batch 153 in epoch 7, gen_loss = 0.4004311640928318, disc_loss = 0.06522434521406018
Trained batch 154 in epoch 7, gen_loss = 0.40101557835455864, disc_loss = 0.06483908796743039
Trained batch 155 in epoch 7, gen_loss = 0.4012233928228036, disc_loss = 0.06453869180180706
Trained batch 156 in epoch 7, gen_loss = 0.4017914594358699, disc_loss = 0.06443199514156314
Trained batch 157 in epoch 7, gen_loss = 0.40156424932087526, disc_loss = 0.06430135232313902
Trained batch 158 in epoch 7, gen_loss = 0.4018262307973778, disc_loss = 0.06415434264864936
Trained batch 159 in epoch 7, gen_loss = 0.40146364327520134, disc_loss = 0.06402965734014288
Trained batch 160 in epoch 7, gen_loss = 0.4019492440712378, disc_loss = 0.06389792442830823
Trained batch 161 in epoch 7, gen_loss = 0.4019754221777857, disc_loss = 0.06367088135699799
Trained batch 162 in epoch 7, gen_loss = 0.40157522032597315, disc_loss = 0.06336578194829036
Trained batch 163 in epoch 7, gen_loss = 0.40193160968582803, disc_loss = 0.06303507984025268
Trained batch 164 in epoch 7, gen_loss = 0.40199611512097444, disc_loss = 0.06310142463242466
Trained batch 165 in epoch 7, gen_loss = 0.40248959861606, disc_loss = 0.06376805384811687
Trained batch 166 in epoch 7, gen_loss = 0.4022652567503695, disc_loss = 0.06345546292977597
Trained batch 167 in epoch 7, gen_loss = 0.40241971079792294, disc_loss = 0.06348160293418914
Trained batch 168 in epoch 7, gen_loss = 0.40213408272647294, disc_loss = 0.06317930707719023
Trained batch 169 in epoch 7, gen_loss = 0.40230753264006447, disc_loss = 0.06290337977492634
Trained batch 170 in epoch 7, gen_loss = 0.4026778993899362, disc_loss = 0.06331106793266117
Trained batch 171 in epoch 7, gen_loss = 0.4025271534919739, disc_loss = 0.06507844927850677
Trained batch 172 in epoch 7, gen_loss = 0.401853490599318, disc_loss = 0.06566014859523904
Trained batch 173 in epoch 7, gen_loss = 0.4020990528937044, disc_loss = 0.06599126610069952
Trained batch 174 in epoch 7, gen_loss = 0.40201853615897043, disc_loss = 0.0668623144232801
Trained batch 175 in epoch 7, gen_loss = 0.4025002159178257, disc_loss = 0.06737912835193459
Trained batch 176 in epoch 7, gen_loss = 0.40242376906723626, disc_loss = 0.06732396583078103
Trained batch 177 in epoch 7, gen_loss = 0.40295715763997497, disc_loss = 0.06711846539290266
Trained batch 178 in epoch 7, gen_loss = 0.40307384945826824, disc_loss = 0.06680065180648471
Trained batch 179 in epoch 7, gen_loss = 0.40280944655338924, disc_loss = 0.06651528304339283
Trained batch 180 in epoch 7, gen_loss = 0.40260687338713125, disc_loss = 0.06640414268457594
Trained batch 181 in epoch 7, gen_loss = 0.4025501045551929, disc_loss = 0.0662289432986834
Trained batch 182 in epoch 7, gen_loss = 0.40301588715099895, disc_loss = 0.06713189836591482
Trained batch 183 in epoch 7, gen_loss = 0.4028755458800689, disc_loss = 0.0674726508770381
Trained batch 184 in epoch 7, gen_loss = 0.4032816559881777, disc_loss = 0.06717639008184542
Trained batch 185 in epoch 7, gen_loss = 0.40358205492137583, disc_loss = 0.06684486870153217
Trained batch 186 in epoch 7, gen_loss = 0.4035402018437411, disc_loss = 0.06687655038683411
Trained batch 187 in epoch 7, gen_loss = 0.40328901213534335, disc_loss = 0.06704174998424392
Trained batch 188 in epoch 7, gen_loss = 0.4032944879203877, disc_loss = 0.06673447724934371
Trained batch 189 in epoch 7, gen_loss = 0.4031916166606702, disc_loss = 0.06645039285925267
Trained batch 190 in epoch 7, gen_loss = 0.4033395050395846, disc_loss = 0.06627684702160548
Trained batch 191 in epoch 7, gen_loss = 0.4035745745835205, disc_loss = 0.06611785342344471
Trained batch 192 in epoch 7, gen_loss = 0.40330629012127617, disc_loss = 0.06632093447525961
Trained batch 193 in epoch 7, gen_loss = 0.403559212985727, disc_loss = 0.0661915045005951
Trained batch 194 in epoch 7, gen_loss = 0.4033903617125291, disc_loss = 0.06654001448828822
Trained batch 195 in epoch 7, gen_loss = 0.403808950769658, disc_loss = 0.06712335436747466
Trained batch 196 in epoch 7, gen_loss = 0.40371756187550306, disc_loss = 0.066957518432365
Trained batch 197 in epoch 7, gen_loss = 0.4038190036410033, disc_loss = 0.06683446579104797
Trained batch 198 in epoch 7, gen_loss = 0.4039495094637176, disc_loss = 0.06652043032782835
Trained batch 199 in epoch 7, gen_loss = 0.4035348148643971, disc_loss = 0.06633404407883063
Trained batch 200 in epoch 7, gen_loss = 0.40388049904386797, disc_loss = 0.06631823914792778
Trained batch 201 in epoch 7, gen_loss = 0.40369247800052754, disc_loss = 0.06701263180694146
Trained batch 202 in epoch 7, gen_loss = 0.40390577104878544, disc_loss = 0.06830237475751436
Trained batch 203 in epoch 7, gen_loss = 0.4039583675125066, disc_loss = 0.06813900757297947
Trained batch 204 in epoch 7, gen_loss = 0.4036837912187344, disc_loss = 0.06808961775471888
Trained batch 205 in epoch 7, gen_loss = 0.4037943320366943, disc_loss = 0.06791642702690967
Trained batch 206 in epoch 7, gen_loss = 0.4043046192846436, disc_loss = 0.06776782402606762
Trained batch 207 in epoch 7, gen_loss = 0.40386990199868494, disc_loss = 0.06837172827978905
Trained batch 208 in epoch 7, gen_loss = 0.4034791500374461, disc_loss = 0.06979045707010553
Trained batch 209 in epoch 7, gen_loss = 0.40364929976917446, disc_loss = 0.07028260834382048
Trained batch 210 in epoch 7, gen_loss = 0.40344273422566634, disc_loss = 0.07023812398111438
Trained batch 211 in epoch 7, gen_loss = 0.4033058871919254, disc_loss = 0.07034764426786734
Trained batch 212 in epoch 7, gen_loss = 0.4031459515643232, disc_loss = 0.0701225897747621
Trained batch 213 in epoch 7, gen_loss = 0.40318258232045395, disc_loss = 0.06988237982955282
Trained batch 214 in epoch 7, gen_loss = 0.40306602175845657, disc_loss = 0.06965487609119263
Trained batch 215 in epoch 7, gen_loss = 0.4028371558697135, disc_loss = 0.06949798727658128
Trained batch 216 in epoch 7, gen_loss = 0.40316123566869216, disc_loss = 0.06931479496898534
Trained batch 217 in epoch 7, gen_loss = 0.4038354724372199, disc_loss = 0.06922075357672614
Trained batch 218 in epoch 7, gen_loss = 0.40359335879212643, disc_loss = 0.06902602048097475
Trained batch 219 in epoch 7, gen_loss = 0.40346008688211443, disc_loss = 0.0689549178414216
Trained batch 220 in epoch 7, gen_loss = 0.4036595287366151, disc_loss = 0.06940687759842605
Trained batch 221 in epoch 7, gen_loss = 0.40306459488095464, disc_loss = 0.07079933052001572
Trained batch 222 in epoch 7, gen_loss = 0.40350755394306953, disc_loss = 0.07067679542204523
Trained batch 223 in epoch 7, gen_loss = 0.40324181211846216, disc_loss = 0.07148637155478355
Trained batch 224 in epoch 7, gen_loss = 0.4026869022846222, disc_loss = 0.07218026259086198
Trained batch 225 in epoch 7, gen_loss = 0.4027076910818573, disc_loss = 0.07197556251750649
Trained batch 226 in epoch 7, gen_loss = 0.40276615735192656, disc_loss = 0.07171632894540476
Trained batch 227 in epoch 7, gen_loss = 0.4026377103046367, disc_loss = 0.07145532198748633
Trained batch 228 in epoch 7, gen_loss = 0.40221733492534756, disc_loss = 0.07125612342827771
Trained batch 229 in epoch 7, gen_loss = 0.4021508740342182, disc_loss = 0.07108853283824156
Trained batch 230 in epoch 7, gen_loss = 0.4019014696022133, disc_loss = 0.07094426376712851
Trained batch 231 in epoch 7, gen_loss = 0.40176176344012393, disc_loss = 0.07097513065874127
Trained batch 232 in epoch 7, gen_loss = 0.4017301278564551, disc_loss = 0.07153683092820862
Trained batch 233 in epoch 7, gen_loss = 0.4017040464613173, disc_loss = 0.07170667809147674
Trained batch 234 in epoch 7, gen_loss = 0.4013466436812218, disc_loss = 0.07211029895165182
Trained batch 235 in epoch 7, gen_loss = 0.40154667173401787, disc_loss = 0.07245724557670054
Trained batch 236 in epoch 7, gen_loss = 0.401651695936541, disc_loss = 0.07223523191455358
Trained batch 237 in epoch 7, gen_loss = 0.401107609397223, disc_loss = 0.07318892799701322
Trained batch 238 in epoch 7, gen_loss = 0.40113388506937225, disc_loss = 0.07370922917297508
Trained batch 239 in epoch 7, gen_loss = 0.401112491513292, disc_loss = 0.07362225698501182
Trained batch 240 in epoch 7, gen_loss = 0.4011068988390483, disc_loss = 0.07352797149321165
Trained batch 241 in epoch 7, gen_loss = 0.40131545103778526, disc_loss = 0.07340606126726475
Trained batch 242 in epoch 7, gen_loss = 0.401244672114957, disc_loss = 0.07318743549233662
Trained batch 243 in epoch 7, gen_loss = 0.40137411287573516, disc_loss = 0.0729835174737315
Trained batch 244 in epoch 7, gen_loss = 0.4013296868119921, disc_loss = 0.07276602964658214
Trained batch 245 in epoch 7, gen_loss = 0.4009177420682054, disc_loss = 0.07352988609127943
Trained batch 246 in epoch 7, gen_loss = 0.4010648179633415, disc_loss = 0.0757529202807197
Trained batch 247 in epoch 7, gen_loss = 0.40086767558128605, disc_loss = 0.0766742137474789
Trained batch 248 in epoch 7, gen_loss = 0.40081940549444484, disc_loss = 0.0769323771800771
Trained batch 249 in epoch 7, gen_loss = 0.4001878932714462, disc_loss = 0.07749040382541716
Trained batch 250 in epoch 7, gen_loss = 0.3997341269753369, disc_loss = 0.07778782862984386
Trained batch 251 in epoch 7, gen_loss = 0.39976542135552756, disc_loss = 0.07774694275207049
Trained batch 252 in epoch 7, gen_loss = 0.39961309383509186, disc_loss = 0.07762935179885727
Trained batch 253 in epoch 7, gen_loss = 0.39954752563022256, disc_loss = 0.07739132460331412
Trained batch 254 in epoch 7, gen_loss = 0.39923805255515904, disc_loss = 0.07713888023669521
Trained batch 255 in epoch 7, gen_loss = 0.39906362700276077, disc_loss = 0.07688228170263756
Trained batch 256 in epoch 7, gen_loss = 0.39932041513780675, disc_loss = 0.07661615589865509
Trained batch 257 in epoch 7, gen_loss = 0.3995199454154155, disc_loss = 0.07636880554266043
Trained batch 258 in epoch 7, gen_loss = 0.39920849954299487, disc_loss = 0.07617617388611882
Trained batch 259 in epoch 7, gen_loss = 0.39919660377960936, disc_loss = 0.07601302713334847
Trained batch 260 in epoch 7, gen_loss = 0.3992550622001005, disc_loss = 0.07582080893225654
Trained batch 261 in epoch 7, gen_loss = 0.3992824254145149, disc_loss = 0.07570677122122516
Trained batch 262 in epoch 7, gen_loss = 0.3988511585010775, disc_loss = 0.07612733516891702
Trained batch 263 in epoch 7, gen_loss = 0.3986297571523623, disc_loss = 0.07693587889309239
Trained batch 264 in epoch 7, gen_loss = 0.39870873251051275, disc_loss = 0.07671731663516389
Trained batch 265 in epoch 7, gen_loss = 0.39848846040273966, disc_loss = 0.07667029266161635
Trained batch 266 in epoch 7, gen_loss = 0.3985361580768328, disc_loss = 0.07659868126707187
Trained batch 267 in epoch 7, gen_loss = 0.398876963933902, disc_loss = 0.07647396726429519
Trained batch 268 in epoch 7, gen_loss = 0.39874849033621607, disc_loss = 0.07686072966900956
Trained batch 269 in epoch 7, gen_loss = 0.3989693660427023, disc_loss = 0.0776612276504575
Trained batch 270 in epoch 7, gen_loss = 0.3989426992916093, disc_loss = 0.07740810438406369
Trained batch 271 in epoch 7, gen_loss = 0.399109047563637, disc_loss = 0.0772130574863267
Trained batch 272 in epoch 7, gen_loss = 0.39916137723259, disc_loss = 0.07702371424691745
Trained batch 273 in epoch 7, gen_loss = 0.3994102237650948, disc_loss = 0.07686038207718218
Trained batch 274 in epoch 7, gen_loss = 0.3989311182498932, disc_loss = 0.07668207475238226
Trained batch 275 in epoch 7, gen_loss = 0.3990084051653959, disc_loss = 0.07646280638299936
Trained batch 276 in epoch 7, gen_loss = 0.3989516177117179, disc_loss = 0.0762232107560853
Trained batch 277 in epoch 7, gen_loss = 0.39904579391582407, disc_loss = 0.07598936258105012
Trained batch 278 in epoch 7, gen_loss = 0.39894704718316326, disc_loss = 0.07576383459865779
Trained batch 279 in epoch 7, gen_loss = 0.39927242951733727, disc_loss = 0.07554785752768761
Trained batch 280 in epoch 7, gen_loss = 0.39928864170648026, disc_loss = 0.0756197184360722
Trained batch 281 in epoch 7, gen_loss = 0.39961018756771766, disc_loss = 0.07713278417198106
Trained batch 282 in epoch 7, gen_loss = 0.39974594863901713, disc_loss = 0.07719468364702677
Trained batch 283 in epoch 7, gen_loss = 0.39952008531127176, disc_loss = 0.07751035726871866
Trained batch 284 in epoch 7, gen_loss = 0.39945268766921865, disc_loss = 0.07744661599495693
Trained batch 285 in epoch 7, gen_loss = 0.3992866920632916, disc_loss = 0.07785809309534415
Trained batch 286 in epoch 7, gen_loss = 0.39917022747860553, disc_loss = 0.0778025271750675
Trained batch 287 in epoch 7, gen_loss = 0.39885268743253416, disc_loss = 0.07784999605468733
Trained batch 288 in epoch 7, gen_loss = 0.3986258413964902, disc_loss = 0.07799175344117527
Trained batch 289 in epoch 7, gen_loss = 0.39875962138175963, disc_loss = 0.0781369622009967
Trained batch 290 in epoch 7, gen_loss = 0.39870801455376487, disc_loss = 0.07817512372815885
Trained batch 291 in epoch 7, gen_loss = 0.39835299326948925, disc_loss = 0.0787092429531534
Trained batch 292 in epoch 7, gen_loss = 0.39843082519521483, disc_loss = 0.07863862030430611
Trained batch 293 in epoch 7, gen_loss = 0.3984303678176841, disc_loss = 0.07853629277721301
Trained batch 294 in epoch 7, gen_loss = 0.3982803539704468, disc_loss = 0.0783366689537415
Trained batch 295 in epoch 7, gen_loss = 0.3982600431788612, disc_loss = 0.07812466516593672
Trained batch 296 in epoch 7, gen_loss = 0.3982612975318022, disc_loss = 0.07792525018035412
Trained batch 297 in epoch 7, gen_loss = 0.39835911839200344, disc_loss = 0.07772135062787007
Trained batch 298 in epoch 7, gen_loss = 0.39847269943326613, disc_loss = 0.07747734289298637
Trained batch 299 in epoch 7, gen_loss = 0.3981560613711675, disc_loss = 0.07731988932782163
Trained batch 300 in epoch 7, gen_loss = 0.3979190290964323, disc_loss = 0.07708524855200288
Trained batch 301 in epoch 7, gen_loss = 0.39788146840026045, disc_loss = 0.07686093953647805
Trained batch 302 in epoch 7, gen_loss = 0.39785634251711, disc_loss = 0.07663720095431795
Trained batch 303 in epoch 7, gen_loss = 0.39795585574680253, disc_loss = 0.07642720566639725
Trained batch 304 in epoch 7, gen_loss = 0.39768675897942213, disc_loss = 0.0763863175908928
Trained batch 305 in epoch 7, gen_loss = 0.3977532989643758, disc_loss = 0.07647509622582374
Trained batch 306 in epoch 7, gen_loss = 0.3979025793774508, disc_loss = 0.07630526131103937
Trained batch 307 in epoch 7, gen_loss = 0.39780637399329766, disc_loss = 0.07613687241274573
Trained batch 308 in epoch 7, gen_loss = 0.3979501261294467, disc_loss = 0.07591316778013862
Trained batch 309 in epoch 7, gen_loss = 0.398126926537483, disc_loss = 0.07569160144325465
Trained batch 310 in epoch 7, gen_loss = 0.39834532410002216, disc_loss = 0.07547462367904867
Trained batch 311 in epoch 7, gen_loss = 0.3984296426941187, disc_loss = 0.07535528749054393
Trained batch 312 in epoch 7, gen_loss = 0.39855759326642315, disc_loss = 0.07534528753836267
Trained batch 313 in epoch 7, gen_loss = 0.39835368666299587, disc_loss = 0.07514069889743284
Trained batch 314 in epoch 7, gen_loss = 0.39848615309548757, disc_loss = 0.07497423698770858
Trained batch 315 in epoch 7, gen_loss = 0.3985188028103189, disc_loss = 0.07478069579022453
Trained batch 316 in epoch 7, gen_loss = 0.39850362035378295, disc_loss = 0.07475257191472108
Trained batch 317 in epoch 7, gen_loss = 0.3984006745447903, disc_loss = 0.0747653490193071
Trained batch 318 in epoch 7, gen_loss = 0.3984705369487452, disc_loss = 0.07457869288695503
Trained batch 319 in epoch 7, gen_loss = 0.39834626195952294, disc_loss = 0.07486635634122649
Trained batch 320 in epoch 7, gen_loss = 0.3979780149422702, disc_loss = 0.07513410044613518
Trained batch 321 in epoch 7, gen_loss = 0.39804226298880135, disc_loss = 0.07500482613353857
Trained batch 322 in epoch 7, gen_loss = 0.39845043171670047, disc_loss = 0.07487446175968915
Trained batch 323 in epoch 7, gen_loss = 0.39848349031842784, disc_loss = 0.07471521504160109
Trained batch 324 in epoch 7, gen_loss = 0.3983447397672213, disc_loss = 0.07462771011803013
Trained batch 325 in epoch 7, gen_loss = 0.3983289565593918, disc_loss = 0.07450779154468214
Trained batch 326 in epoch 7, gen_loss = 0.3982742066047972, disc_loss = 0.07432468829744864
Trained batch 327 in epoch 7, gen_loss = 0.39839832802734726, disc_loss = 0.07421209804696689
Trained batch 328 in epoch 7, gen_loss = 0.3981798804820852, disc_loss = 0.07413478180522659
Trained batch 329 in epoch 7, gen_loss = 0.3983558208653421, disc_loss = 0.07396238378644215
Trained batch 330 in epoch 7, gen_loss = 0.39833922571646124, disc_loss = 0.07375861360519854
Trained batch 331 in epoch 7, gen_loss = 0.3982717042048293, disc_loss = 0.07356364845511425
Trained batch 332 in epoch 7, gen_loss = 0.39845981048392104, disc_loss = 0.07342229658799307
Trained batch 333 in epoch 7, gen_loss = 0.39885110599909, disc_loss = 0.07359008339908488
Trained batch 334 in epoch 7, gen_loss = 0.3986994899030942, disc_loss = 0.07372621896662819
Trained batch 335 in epoch 7, gen_loss = 0.39884227682792006, disc_loss = 0.07356665320583575
Trained batch 336 in epoch 7, gen_loss = 0.39898806438955425, disc_loss = 0.073892305281776
Trained batch 337 in epoch 7, gen_loss = 0.3990232132419327, disc_loss = 0.07433193496059208
Trained batch 338 in epoch 7, gen_loss = 0.3989242040126373, disc_loss = 0.07419461368481493
Trained batch 339 in epoch 7, gen_loss = 0.3990956841146245, disc_loss = 0.0739932588657693
Trained batch 340 in epoch 7, gen_loss = 0.39926690632297146, disc_loss = 0.07379703372553034
Trained batch 341 in epoch 7, gen_loss = 0.39922166123376257, disc_loss = 0.07366998453640886
Trained batch 342 in epoch 7, gen_loss = 0.399337633618808, disc_loss = 0.07347448424601781
Trained batch 343 in epoch 7, gen_loss = 0.39920199523831523, disc_loss = 0.0734589441468246
Trained batch 344 in epoch 7, gen_loss = 0.39901088303413945, disc_loss = 0.07389565017614244
Trained batch 345 in epoch 7, gen_loss = 0.39903619067172785, disc_loss = 0.07449389695098375
Trained batch 346 in epoch 7, gen_loss = 0.39914885343667067, disc_loss = 0.0746999594922411
Trained batch 347 in epoch 7, gen_loss = 0.3989222263810278, disc_loss = 0.07473770184602974
Trained batch 348 in epoch 7, gen_loss = 0.3988449991090933, disc_loss = 0.07459779257984848
Trained batch 349 in epoch 7, gen_loss = 0.3989713993242809, disc_loss = 0.0745724933195327
Trained batch 350 in epoch 7, gen_loss = 0.3988558554071986, disc_loss = 0.07515082566964405
Trained batch 351 in epoch 7, gen_loss = 0.39911740959029307, disc_loss = 0.07522588281691159
Trained batch 352 in epoch 7, gen_loss = 0.3993064492687625, disc_loss = 0.0752820816582264
Trained batch 353 in epoch 7, gen_loss = 0.3993639770874196, disc_loss = 0.07510824922451191
Trained batch 354 in epoch 7, gen_loss = 0.39930191778800855, disc_loss = 0.07508950655309247
Trained batch 355 in epoch 7, gen_loss = 0.3991665426599845, disc_loss = 0.07490632306585569
Trained batch 356 in epoch 7, gen_loss = 0.39933338836461557, disc_loss = 0.07471398514609377
Trained batch 357 in epoch 7, gen_loss = 0.39928820229775414, disc_loss = 0.07459974604237346
Trained batch 358 in epoch 7, gen_loss = 0.39909492495332255, disc_loss = 0.07458225169678252
Trained batch 359 in epoch 7, gen_loss = 0.39913015415271125, disc_loss = 0.07490853782122334
Trained batch 360 in epoch 7, gen_loss = 0.39900276551946706, disc_loss = 0.07551378918775561
Trained batch 361 in epoch 7, gen_loss = 0.3990051377544087, disc_loss = 0.07570160059927247
Trained batch 362 in epoch 7, gen_loss = 0.39907667623735327, disc_loss = 0.07560226344824166
Trained batch 363 in epoch 7, gen_loss = 0.3989589288012012, disc_loss = 0.07547145401854273
Trained batch 364 in epoch 7, gen_loss = 0.39874497880674387, disc_loss = 0.07530041739905942
Trained batch 365 in epoch 7, gen_loss = 0.3989289862210633, disc_loss = 0.07511567997064217
Trained batch 366 in epoch 7, gen_loss = 0.39910587205549025, disc_loss = 0.07498868057321585
Trained batch 367 in epoch 7, gen_loss = 0.39933756576931995, disc_loss = 0.07485996229123608
Trained batch 368 in epoch 7, gen_loss = 0.39906721459171635, disc_loss = 0.07490598470815596
Trained batch 369 in epoch 7, gen_loss = 0.3989487147814519, disc_loss = 0.07535650538708512
Trained batch 370 in epoch 7, gen_loss = 0.3990371936575743, disc_loss = 0.07519088872404633
Trained batch 371 in epoch 7, gen_loss = 0.3989852638815039, disc_loss = 0.07525201017783094
Trained batch 372 in epoch 7, gen_loss = 0.3990879084405567, disc_loss = 0.07512750148138995
Trained batch 373 in epoch 7, gen_loss = 0.39903985234824096, disc_loss = 0.07494714613480961
Trained batch 374 in epoch 7, gen_loss = 0.3990637683868408, disc_loss = 0.07476050746565063
Trained batch 375 in epoch 7, gen_loss = 0.39899336839927, disc_loss = 0.07459276026743959
Trained batch 376 in epoch 7, gen_loss = 0.39889156810484766, disc_loss = 0.07443537905846849
Trained batch 377 in epoch 7, gen_loss = 0.39884909419786363, disc_loss = 0.07430224746303071
Trained batch 378 in epoch 7, gen_loss = 0.39878666400909424, disc_loss = 0.07429848995556107
Trained batch 379 in epoch 7, gen_loss = 0.39874783472010966, disc_loss = 0.0741535146953538
Trained batch 380 in epoch 7, gen_loss = 0.39887743492138983, disc_loss = 0.07422399876658803
Trained batch 381 in epoch 7, gen_loss = 0.398839779237178, disc_loss = 0.0743432394289826
Trained batch 382 in epoch 7, gen_loss = 0.3990406434467505, disc_loss = 0.07448382268954
Trained batch 383 in epoch 7, gen_loss = 0.39898494840599597, disc_loss = 0.07432557817931713
Trained batch 384 in epoch 7, gen_loss = 0.3990557857148059, disc_loss = 0.07416603826349238
Trained batch 385 in epoch 7, gen_loss = 0.3989879287431895, disc_loss = 0.07399210117400233
Trained batch 386 in epoch 7, gen_loss = 0.3988560714616948, disc_loss = 0.07383162253692707
Trained batch 387 in epoch 7, gen_loss = 0.39885965888340447, disc_loss = 0.0739641614407109
Trained batch 388 in epoch 7, gen_loss = 0.3985501231295284, disc_loss = 0.07463501666488179
Trained batch 389 in epoch 7, gen_loss = 0.39861742708927544, disc_loss = 0.07546970707436021
Trained batch 390 in epoch 7, gen_loss = 0.39843134738295277, disc_loss = 0.07542742079700274
Trained batch 391 in epoch 7, gen_loss = 0.3983457841891415, disc_loss = 0.07542462234280775
Trained batch 392 in epoch 7, gen_loss = 0.39858851534416356, disc_loss = 0.07538915141876645
Trained batch 393 in epoch 7, gen_loss = 0.39852894434166436, disc_loss = 0.07528797314658307
Trained batch 394 in epoch 7, gen_loss = 0.3985933045043221, disc_loss = 0.07520240974152767
Trained batch 395 in epoch 7, gen_loss = 0.39860880969449725, disc_loss = 0.07505830754337814
Trained batch 396 in epoch 7, gen_loss = 0.3986730221987371, disc_loss = 0.07494107899150484
Trained batch 397 in epoch 7, gen_loss = 0.39845552703543524, disc_loss = 0.0751228657944231
Trained batch 398 in epoch 7, gen_loss = 0.3984448050795342, disc_loss = 0.07540316704922077
Trained batch 399 in epoch 7, gen_loss = 0.39846918247640134, disc_loss = 0.0752975398930721
Trained batch 400 in epoch 7, gen_loss = 0.398428476213517, disc_loss = 0.07529339356640553
Trained batch 401 in epoch 7, gen_loss = 0.39851868945864305, disc_loss = 0.0753968612948868
Trained batch 402 in epoch 7, gen_loss = 0.39855020417469017, disc_loss = 0.07535762889611144
Trained batch 403 in epoch 7, gen_loss = 0.39836471763872866, disc_loss = 0.07530000585242
Trained batch 404 in epoch 7, gen_loss = 0.39853555228975085, disc_loss = 0.07556250923899589
Trained batch 405 in epoch 7, gen_loss = 0.3985174753395795, disc_loss = 0.07545855675085351
Trained batch 406 in epoch 7, gen_loss = 0.39826325299698834, disc_loss = 0.07615775350224986
Trained batch 407 in epoch 7, gen_loss = 0.39845222914043593, disc_loss = 0.07645722833580758
Trained batch 408 in epoch 7, gen_loss = 0.3984591096712499, disc_loss = 0.07643673897545539
Trained batch 409 in epoch 7, gen_loss = 0.3982787252199359, disc_loss = 0.07638522481727528
Trained batch 410 in epoch 7, gen_loss = 0.3980411164226903, disc_loss = 0.07646622212145958
Trained batch 411 in epoch 7, gen_loss = 0.39796742456919937, disc_loss = 0.0764391400638823
Trained batch 412 in epoch 7, gen_loss = 0.39797147531197663, disc_loss = 0.07630461672451753
Trained batch 413 in epoch 7, gen_loss = 0.39802398125906496, disc_loss = 0.07614178533985275
Trained batch 414 in epoch 7, gen_loss = 0.39799269782491475, disc_loss = 0.07602987530450504
Trained batch 415 in epoch 7, gen_loss = 0.39800401576436484, disc_loss = 0.0758822289107439
Trained batch 416 in epoch 7, gen_loss = 0.3980431924763915, disc_loss = 0.07577232184330765
Trained batch 417 in epoch 7, gen_loss = 0.3981433624143235, disc_loss = 0.075652020885364
Trained batch 418 in epoch 7, gen_loss = 0.39811215459020155, disc_loss = 0.07560938495813663
Trained batch 419 in epoch 7, gen_loss = 0.39790994773308436, disc_loss = 0.07581789712199853
Trained batch 420 in epoch 7, gen_loss = 0.39801100278693535, disc_loss = 0.07592060144840256
Trained batch 421 in epoch 7, gen_loss = 0.3979393543225329, disc_loss = 0.07576865098169912
Trained batch 422 in epoch 7, gen_loss = 0.39805991239581545, disc_loss = 0.07560351779728458
Trained batch 423 in epoch 7, gen_loss = 0.39811968669857617, disc_loss = 0.07552237548527115
Trained batch 424 in epoch 7, gen_loss = 0.3983498003903557, disc_loss = 0.07537748988608227
Trained batch 425 in epoch 7, gen_loss = 0.3984562201259282, disc_loss = 0.0752527799310836
Trained batch 426 in epoch 7, gen_loss = 0.3983081921202237, disc_loss = 0.07528310504783407
Trained batch 427 in epoch 7, gen_loss = 0.39837171562085644, disc_loss = 0.07562392796977276
Trained batch 428 in epoch 7, gen_loss = 0.39827667999934485, disc_loss = 0.07553957487046198
Trained batch 429 in epoch 7, gen_loss = 0.39833403007928714, disc_loss = 0.07543589386677499
Trained batch 430 in epoch 7, gen_loss = 0.39838473516107986, disc_loss = 0.07527266193198563
Trained batch 431 in epoch 7, gen_loss = 0.3985151116632753, disc_loss = 0.07511902238345808
Trained batch 432 in epoch 7, gen_loss = 0.39855584385213344, disc_loss = 0.07495977091506192
Trained batch 433 in epoch 7, gen_loss = 0.3985536855898695, disc_loss = 0.07485185370754777
Trained batch 434 in epoch 7, gen_loss = 0.39879587004924644, disc_loss = 0.07473216298646454
Trained batch 435 in epoch 7, gen_loss = 0.3988269261947466, disc_loss = 0.0749375436897176
Trained batch 436 in epoch 7, gen_loss = 0.39887861890432763, disc_loss = 0.07570933465668996
Trained batch 437 in epoch 7, gen_loss = 0.398979598256551, disc_loss = 0.075636212925584
Trained batch 438 in epoch 7, gen_loss = 0.3989749558965818, disc_loss = 0.07554586582492553
Trained batch 439 in epoch 7, gen_loss = 0.3987875807691704, disc_loss = 0.07564294403736395
Trained batch 440 in epoch 7, gen_loss = 0.3988000165983663, disc_loss = 0.07573001432526105
Trained batch 441 in epoch 7, gen_loss = 0.39867142874460954, disc_loss = 0.07572072676416672
Trained batch 442 in epoch 7, gen_loss = 0.3986896032942606, disc_loss = 0.07564787649387666
Trained batch 443 in epoch 7, gen_loss = 0.39870815663724335, disc_loss = 0.07557097125508999
Trained batch 444 in epoch 7, gen_loss = 0.3988652684715357, disc_loss = 0.07542019758394428
Trained batch 445 in epoch 7, gen_loss = 0.3990299386293899, disc_loss = 0.07542530182360634
Trained batch 446 in epoch 7, gen_loss = 0.39892093487233926, disc_loss = 0.07540966999473288
Trained batch 447 in epoch 7, gen_loss = 0.3988506001021181, disc_loss = 0.07526544679941642
Trained batch 448 in epoch 7, gen_loss = 0.3988850221602051, disc_loss = 0.0751552230218023
Trained batch 449 in epoch 7, gen_loss = 0.39894248611397215, disc_loss = 0.07515256536193192
Trained batch 450 in epoch 7, gen_loss = 0.39909943039560003, disc_loss = 0.07517502617665014
Trained batch 451 in epoch 7, gen_loss = 0.39925613768596563, disc_loss = 0.07509460401272121
Trained batch 452 in epoch 7, gen_loss = 0.3993546080510348, disc_loss = 0.07496213619484182
Trained batch 453 in epoch 7, gen_loss = 0.3992149478013295, disc_loss = 0.07486035466493653
Trained batch 454 in epoch 7, gen_loss = 0.3992972720455337, disc_loss = 0.07473004204988644
Trained batch 455 in epoch 7, gen_loss = 0.39931686385943177, disc_loss = 0.07474370480600842
Trained batch 456 in epoch 7, gen_loss = 0.39926081302390315, disc_loss = 0.07485212656390125
Trained batch 457 in epoch 7, gen_loss = 0.3995648597135294, disc_loss = 0.07560463672743777
Trained batch 458 in epoch 7, gen_loss = 0.39970596196344993, disc_loss = 0.07547593661857878
Testing Epoch 7
Training Epoch 8
Trained batch 0 in epoch 8, gen_loss = 0.433281272649765, disc_loss = 0.023474231362342834
Trained batch 1 in epoch 8, gen_loss = 0.42631950974464417, disc_loss = 0.021907195448875427
Trained batch 2 in epoch 8, gen_loss = 0.424239714940389, disc_loss = 0.017354565983017285
Trained batch 3 in epoch 8, gen_loss = 0.4188346639275551, disc_loss = 0.014659903477877378
Trained batch 4 in epoch 8, gen_loss = 0.4143598020076752, disc_loss = 0.013118874095380307
Trained batch 5 in epoch 8, gen_loss = 0.41518395642439526, disc_loss = 0.012115280299137035
Trained batch 6 in epoch 8, gen_loss = 0.408342855317252, disc_loss = 0.01157978576208864
Trained batch 7 in epoch 8, gen_loss = 0.4077010527253151, disc_loss = 0.013113792287185788
Trained batch 8 in epoch 8, gen_loss = 0.3978479239675734, disc_loss = 0.014799878001213074
Trained batch 9 in epoch 8, gen_loss = 0.3954341322183609, disc_loss = 0.01592886745929718
Trained batch 10 in epoch 8, gen_loss = 0.3985002772374587, disc_loss = 0.01579967513680458
Trained batch 11 in epoch 8, gen_loss = 0.3998695934812228, disc_loss = 0.02172392016897599
Trained batch 12 in epoch 8, gen_loss = 0.4059584209552178, disc_loss = 0.02588297684605305
Trained batch 13 in epoch 8, gen_loss = 0.4087895154953003, disc_loss = 0.025661029320742403
Trained batch 14 in epoch 8, gen_loss = 0.4104691008726756, disc_loss = 0.024832500765721004
Trained batch 15 in epoch 8, gen_loss = 0.4077117722481489, disc_loss = 0.02488799043931067
Trained batch 16 in epoch 8, gen_loss = 0.405519764213001, disc_loss = 0.023720823940547073
Trained batch 17 in epoch 8, gen_loss = 0.4053187684880363, disc_loss = 0.022653990864960685
Trained batch 18 in epoch 8, gen_loss = 0.405947407609538, disc_loss = 0.021735015888943485
Trained batch 19 in epoch 8, gen_loss = 0.40406039357185364, disc_loss = 0.021537090302444994
Trained batch 20 in epoch 8, gen_loss = 0.40858155488967896, disc_loss = 0.0211769876159018
Trained batch 21 in epoch 8, gen_loss = 0.4061922620643269, disc_loss = 0.02101219274018976
Trained batch 22 in epoch 8, gen_loss = 0.4060189257497373, disc_loss = 0.022195232283000067
Trained batch 23 in epoch 8, gen_loss = 0.4017636912564437, disc_loss = 0.02924567583249882
Trained batch 24 in epoch 8, gen_loss = 0.404490247964859, disc_loss = 0.03189810810610652
Trained batch 25 in epoch 8, gen_loss = 0.40394097337355983, disc_loss = 0.03894481175722411
Trained batch 26 in epoch 8, gen_loss = 0.40039295730767427, disc_loss = 0.04298063283096309
Trained batch 27 in epoch 8, gen_loss = 0.4004529650722231, disc_loss = 0.04173162424870368
Trained batch 28 in epoch 8, gen_loss = 0.4009970447112774, disc_loss = 0.04053703746918974
Trained batch 29 in epoch 8, gen_loss = 0.3977100153764089, disc_loss = 0.039343095508714516
Trained batch 30 in epoch 8, gen_loss = 0.39765011206749945, disc_loss = 0.03966281484932669
Trained batch 31 in epoch 8, gen_loss = 0.399696234613657, disc_loss = 0.039033980981912464
Trained batch 32 in epoch 8, gen_loss = 0.4015906976931023, disc_loss = 0.040100026706402954
Trained batch 33 in epoch 8, gen_loss = 0.39885831580442543, disc_loss = 0.04094356555929955
Trained batch 34 in epoch 8, gen_loss = 0.39856094632829936, disc_loss = 0.04079228953591415
Trained batch 35 in epoch 8, gen_loss = 0.40140001310242546, disc_loss = 0.04162325270266996
Trained batch 36 in epoch 8, gen_loss = 0.40067101410917333, disc_loss = 0.04249337693122593
Trained batch 37 in epoch 8, gen_loss = 0.40075302516159256, disc_loss = 0.0457044970734339
Trained batch 38 in epoch 8, gen_loss = 0.39978790512451756, disc_loss = 0.0450973162570825
Trained batch 39 in epoch 8, gen_loss = 0.39872891530394555, disc_loss = 0.044867469323799015
Trained batch 40 in epoch 8, gen_loss = 0.39930248842006777, disc_loss = 0.044224052848975834
Trained batch 41 in epoch 8, gen_loss = 0.39719570250738234, disc_loss = 0.04366010795569136
Trained batch 42 in epoch 8, gen_loss = 0.39722708214161007, disc_loss = 0.04277093268844277
Trained batch 43 in epoch 8, gen_loss = 0.3972451165318489, disc_loss = 0.04232623337090693
Trained batch 44 in epoch 8, gen_loss = 0.3971801459789276, disc_loss = 0.041940750202371015
Trained batch 45 in epoch 8, gen_loss = 0.3971563247234925, disc_loss = 0.041382296031098005
Trained batch 46 in epoch 8, gen_loss = 0.3973643094935316, disc_loss = 0.040638281785427256
Trained batch 47 in epoch 8, gen_loss = 0.3987852428108454, disc_loss = 0.04059406851107875
Trained batch 48 in epoch 8, gen_loss = 0.3986044209830615, disc_loss = 0.04023883955515161
Trained batch 49 in epoch 8, gen_loss = 0.40144763350486756, disc_loss = 0.04031815208494663
Trained batch 50 in epoch 8, gen_loss = 0.40102365087060365, disc_loss = 0.03974219561353618
Trained batch 51 in epoch 8, gen_loss = 0.4018820845163785, disc_loss = 0.03935778065799521
Trained batch 52 in epoch 8, gen_loss = 0.4040823522603737, disc_loss = 0.04228820873178401
Trained batch 53 in epoch 8, gen_loss = 0.40336992453645776, disc_loss = 0.043076386847705754
Trained batch 54 in epoch 8, gen_loss = 0.4033327433195981, disc_loss = 0.04359413896771994
Trained batch 55 in epoch 8, gen_loss = 0.40394147112965584, disc_loss = 0.04486347784820412
Trained batch 56 in epoch 8, gen_loss = 0.4031903665316732, disc_loss = 0.04443762582122234
Trained batch 57 in epoch 8, gen_loss = 0.40190794087689496, disc_loss = 0.04479658423826612
Trained batch 58 in epoch 8, gen_loss = 0.40303733490281185, disc_loss = 0.04555027666738478
Trained batch 59 in epoch 8, gen_loss = 0.4026515205701192, disc_loss = 0.04487160394589106
Trained batch 60 in epoch 8, gen_loss = 0.4012258111453447, disc_loss = 0.04533715460632668
Trained batch 61 in epoch 8, gen_loss = 0.4010962055575463, disc_loss = 0.046495339923327966
Trained batch 62 in epoch 8, gen_loss = 0.4009878408341181, disc_loss = 0.04795227625540325
Trained batch 63 in epoch 8, gen_loss = 0.4000832485035062, disc_loss = 0.04940780869219452
Trained batch 64 in epoch 8, gen_loss = 0.39934529478733355, disc_loss = 0.04996801878397281
Trained batch 65 in epoch 8, gen_loss = 0.39981268301154627, disc_loss = 0.04953909637124249
Trained batch 66 in epoch 8, gen_loss = 0.39967429326541387, disc_loss = 0.048985210733849614
Trained batch 67 in epoch 8, gen_loss = 0.3998832439675051, disc_loss = 0.04853391795254806
Trained batch 68 in epoch 8, gen_loss = 0.40067648282949475, disc_loss = 0.04810062485436598
Trained batch 69 in epoch 8, gen_loss = 0.4002475368125098, disc_loss = 0.049096766673028466
Trained batch 70 in epoch 8, gen_loss = 0.39924003246804357, disc_loss = 0.05268677662480885
Trained batch 71 in epoch 8, gen_loss = 0.40031466840042007, disc_loss = 0.05352267315093842
Trained batch 72 in epoch 8, gen_loss = 0.4005948823608764, disc_loss = 0.054314033753455504
Trained batch 73 in epoch 8, gen_loss = 0.40058194584137685, disc_loss = 0.053708605216564356
Trained batch 74 in epoch 8, gen_loss = 0.4003590138753255, disc_loss = 0.053428753813107806
Trained batch 75 in epoch 8, gen_loss = 0.3999264561816266, disc_loss = 0.052844792837277055
Trained batch 76 in epoch 8, gen_loss = 0.39996220500438245, disc_loss = 0.05226552167109081
Trained batch 77 in epoch 8, gen_loss = 0.3996677841895666, disc_loss = 0.05197066859079477
Trained batch 78 in epoch 8, gen_loss = 0.39966017535970183, disc_loss = 0.05146873570224152
Trained batch 79 in epoch 8, gen_loss = 0.39927041791379453, disc_loss = 0.051430356898345055
Trained batch 80 in epoch 8, gen_loss = 0.3984327765158665, disc_loss = 0.05225669309772827
Trained batch 81 in epoch 8, gen_loss = 0.39827469463755444, disc_loss = 0.058842071695480405
Trained batch 82 in epoch 8, gen_loss = 0.39773269015622426, disc_loss = 0.060544257085905016
Trained batch 83 in epoch 8, gen_loss = 0.39691066387153806, disc_loss = 0.06146398082464224
Trained batch 84 in epoch 8, gen_loss = 0.39715450546320746, disc_loss = 0.061605123408577024
Trained batch 85 in epoch 8, gen_loss = 0.3972030718659246, disc_loss = 0.0618562885711706
Trained batch 86 in epoch 8, gen_loss = 0.39682715720143813, disc_loss = 0.06138689274332304
Trained batch 87 in epoch 8, gen_loss = 0.3969736895100637, disc_loss = 0.060932591409337794
Trained batch 88 in epoch 8, gen_loss = 0.39649911643414015, disc_loss = 0.060420906181666956
Trained batch 89 in epoch 8, gen_loss = 0.39658266372150847, disc_loss = 0.06003933690695299
Trained batch 90 in epoch 8, gen_loss = 0.3969909905732333, disc_loss = 0.059437992660185464
Trained batch 91 in epoch 8, gen_loss = 0.3969416864540266, disc_loss = 0.05889351027714008
Trained batch 92 in epoch 8, gen_loss = 0.39613467839456373, disc_loss = 0.05874790485087101
Trained batch 93 in epoch 8, gen_loss = 0.39633491920663955, disc_loss = 0.05893453949210333
Trained batch 94 in epoch 8, gen_loss = 0.39635261422709417, disc_loss = 0.05932513547473048
Trained batch 95 in epoch 8, gen_loss = 0.3970651937027772, disc_loss = 0.059013837924188316
Trained batch 96 in epoch 8, gen_loss = 0.3968011245285113, disc_loss = 0.05846094256074926
Trained batch 97 in epoch 8, gen_loss = 0.39714688366773176, disc_loss = 0.05793782773579718
Trained batch 98 in epoch 8, gen_loss = 0.39755349779369853, disc_loss = 0.05748000578729041
Trained batch 99 in epoch 8, gen_loss = 0.398105009496212, disc_loss = 0.05697677148040384
Trained batch 100 in epoch 8, gen_loss = 0.39803198156970565, disc_loss = 0.05654819990683457
Trained batch 101 in epoch 8, gen_loss = 0.39768676664315017, disc_loss = 0.05613567751795784
Trained batch 102 in epoch 8, gen_loss = 0.3977616845982746, disc_loss = 0.055969056777330564
Trained batch 103 in epoch 8, gen_loss = 0.3985041041786854, disc_loss = 0.05571052072515998
Trained batch 104 in epoch 8, gen_loss = 0.3979937859943935, disc_loss = 0.055498195036003985
Trained batch 105 in epoch 8, gen_loss = 0.398464616177217, disc_loss = 0.0551982924983538
Trained batch 106 in epoch 8, gen_loss = 0.39877356240682515, disc_loss = 0.0550770256363691
Trained batch 107 in epoch 8, gen_loss = 0.3989603665691835, disc_loss = 0.05482360093285226
Trained batch 108 in epoch 8, gen_loss = 0.3982766049170713, disc_loss = 0.05463928979214862
Trained batch 109 in epoch 8, gen_loss = 0.39815807044506074, disc_loss = 0.05533958128653467
Trained batch 110 in epoch 8, gen_loss = 0.39867581413672853, disc_loss = 0.05491948467133953
Trained batch 111 in epoch 8, gen_loss = 0.39863964303263594, disc_loss = 0.05459546091982962
Trained batch 112 in epoch 8, gen_loss = 0.39804319048349834, disc_loss = 0.05606025398453384
Trained batch 113 in epoch 8, gen_loss = 0.3990618356487207, disc_loss = 0.05807017489630533
Trained batch 114 in epoch 8, gen_loss = 0.3991111141184102, disc_loss = 0.057667507996539705
Trained batch 115 in epoch 8, gen_loss = 0.39850597057876913, disc_loss = 0.05763617147097428
Trained batch 116 in epoch 8, gen_loss = 0.39853639531339335, disc_loss = 0.05738078559645348
Trained batch 117 in epoch 8, gen_loss = 0.3989337480674356, disc_loss = 0.05697814725197346
Trained batch 118 in epoch 8, gen_loss = 0.39842437044913026, disc_loss = 0.056652541104078045
Trained batch 119 in epoch 8, gen_loss = 0.3986544226606687, disc_loss = 0.05659437151237701
Trained batch 120 in epoch 8, gen_loss = 0.3980858966338733, disc_loss = 0.05658430100826562
Trained batch 121 in epoch 8, gen_loss = 0.39746569097042084, disc_loss = 0.056798067306488995
Trained batch 122 in epoch 8, gen_loss = 0.397765876558738, disc_loss = 0.05811457159906262
Trained batch 123 in epoch 8, gen_loss = 0.3971767661071593, disc_loss = 0.059171179185561355
Trained batch 124 in epoch 8, gen_loss = 0.3979967324733734, disc_loss = 0.05978383844718337
Trained batch 125 in epoch 8, gen_loss = 0.39786498792587766, disc_loss = 0.0593845239463484
Trained batch 126 in epoch 8, gen_loss = 0.39786312077927777, disc_loss = 0.05908443307592057
Trained batch 127 in epoch 8, gen_loss = 0.3979371169116348, disc_loss = 0.05874911129285465
Trained batch 128 in epoch 8, gen_loss = 0.3978715476601623, disc_loss = 0.05837605860762934
Trained batch 129 in epoch 8, gen_loss = 0.397636904166295, disc_loss = 0.058197114233357404
Trained batch 130 in epoch 8, gen_loss = 0.39711578292701083, disc_loss = 0.05811196510530724
Trained batch 131 in epoch 8, gen_loss = 0.39704336632381787, disc_loss = 0.05773020201983551
Trained batch 132 in epoch 8, gen_loss = 0.39756754399242256, disc_loss = 0.05750993309416493
Trained batch 133 in epoch 8, gen_loss = 0.3978896485780602, disc_loss = 0.05744251503901028
Trained batch 134 in epoch 8, gen_loss = 0.3978844753018132, disc_loss = 0.05860858135339286
Trained batch 135 in epoch 8, gen_loss = 0.39711475591449175, disc_loss = 0.06091802584363476
Trained batch 136 in epoch 8, gen_loss = 0.39715063006338414, disc_loss = 0.06067225696641381
Trained batch 137 in epoch 8, gen_loss = 0.3976328511168991, disc_loss = 0.060624688708533846
Trained batch 138 in epoch 8, gen_loss = 0.39753197230023446, disc_loss = 0.060740101847985235
Trained batch 139 in epoch 8, gen_loss = 0.3977530298488481, disc_loss = 0.06090734202547797
Trained batch 140 in epoch 8, gen_loss = 0.3976792445842256, disc_loss = 0.06205336840043888
Trained batch 141 in epoch 8, gen_loss = 0.3980804889554709, disc_loss = 0.06239207189294024
Trained batch 142 in epoch 8, gen_loss = 0.3975886285721839, disc_loss = 0.06216743978561013
Trained batch 143 in epoch 8, gen_loss = 0.398093796438641, disc_loss = 0.061801169306919396
Trained batch 144 in epoch 8, gen_loss = 0.39835666726375446, disc_loss = 0.061468407820011006
Trained batch 145 in epoch 8, gen_loss = 0.39776628270541153, disc_loss = 0.06136510738056816
Trained batch 146 in epoch 8, gen_loss = 0.3981035440957465, disc_loss = 0.06105607263997299
Trained batch 147 in epoch 8, gen_loss = 0.3983677863269239, disc_loss = 0.06068567379151244
Trained batch 148 in epoch 8, gen_loss = 0.39803056368891826, disc_loss = 0.06058224089343676
Trained batch 149 in epoch 8, gen_loss = 0.39906738539536796, disc_loss = 0.06033208828419447
Trained batch 150 in epoch 8, gen_loss = 0.3996624695938944, disc_loss = 0.060133572038731826
Trained batch 151 in epoch 8, gen_loss = 0.39973570680931997, disc_loss = 0.05984363363026396
Trained batch 152 in epoch 8, gen_loss = 0.39918485770817674, disc_loss = 0.060482086418987877
Trained batch 153 in epoch 8, gen_loss = 0.3996950885305157, disc_loss = 0.06152896090809788
Trained batch 154 in epoch 8, gen_loss = 0.4001181690923629, disc_loss = 0.06116430390806448
Trained batch 155 in epoch 8, gen_loss = 0.400226717767043, disc_loss = 0.0608566401209921
Trained batch 156 in epoch 8, gen_loss = 0.4002128776850974, disc_loss = 0.060583854470829104
Trained batch 157 in epoch 8, gen_loss = 0.3999653773594506, disc_loss = 0.06031365726508577
Trained batch 158 in epoch 8, gen_loss = 0.40013119672079506, disc_loss = 0.059968081302940845
Trained batch 159 in epoch 8, gen_loss = 0.3999249855056405, disc_loss = 0.05972694171941839
Trained batch 160 in epoch 8, gen_loss = 0.39976082251679085, disc_loss = 0.05940275208920426
Trained batch 161 in epoch 8, gen_loss = 0.3996873516359447, disc_loss = 0.05931675719258226
Trained batch 162 in epoch 8, gen_loss = 0.3993619833987183, disc_loss = 0.06040334015901835
Trained batch 163 in epoch 8, gen_loss = 0.3991355363552163, disc_loss = 0.0606168645729379
Trained batch 164 in epoch 8, gen_loss = 0.3991639559919184, disc_loss = 0.060892656129418
Trained batch 165 in epoch 8, gen_loss = 0.39919246499796945, disc_loss = 0.060621933764721976
Trained batch 166 in epoch 8, gen_loss = 0.39896179084292427, disc_loss = 0.060599349082230095
Trained batch 167 in epoch 8, gen_loss = 0.39945447711007936, disc_loss = 0.06052357903016465
Trained batch 168 in epoch 8, gen_loss = 0.3993221732991687, disc_loss = 0.06026061115092075
Trained batch 169 in epoch 8, gen_loss = 0.3989496085573645, disc_loss = 0.06020729964708581
Trained batch 170 in epoch 8, gen_loss = 0.3997434888318268, disc_loss = 0.06025801165497791
Trained batch 171 in epoch 8, gen_loss = 0.39969145125427913, disc_loss = 0.06023013758538074
Trained batch 172 in epoch 8, gen_loss = 0.3991257208964728, disc_loss = 0.061740298082546004
Trained batch 173 in epoch 8, gen_loss = 0.39932798448650314, disc_loss = 0.06148192997293911
Trained batch 174 in epoch 8, gen_loss = 0.39938609991754803, disc_loss = 0.06278340024607522
Trained batch 175 in epoch 8, gen_loss = 0.39880450594831596, disc_loss = 0.06357958337122743
Trained batch 176 in epoch 8, gen_loss = 0.3991321515565538, disc_loss = 0.06331374553048004
Trained batch 177 in epoch 8, gen_loss = 0.3988090457206362, disc_loss = 0.06330387212670921
Trained batch 178 in epoch 8, gen_loss = 0.3985689270762758, disc_loss = 0.06312880200963447
Trained batch 179 in epoch 8, gen_loss = 0.39821151246627173, disc_loss = 0.06306566463576423
Trained batch 180 in epoch 8, gen_loss = 0.39801285774009665, disc_loss = 0.06279335768883071
Trained batch 181 in epoch 8, gen_loss = 0.39813883406120343, disc_loss = 0.06271108451739445
Trained batch 182 in epoch 8, gen_loss = 0.3976278555849211, disc_loss = 0.06397002258546691
Trained batch 183 in epoch 8, gen_loss = 0.3979837534868199, disc_loss = 0.06610606374907428
Trained batch 184 in epoch 8, gen_loss = 0.3980727234402218, disc_loss = 0.06580038656656806
Trained batch 185 in epoch 8, gen_loss = 0.3976123179158857, disc_loss = 0.06582554980551683
Trained batch 186 in epoch 8, gen_loss = 0.3974089244788981, disc_loss = 0.06573742044402316
Trained batch 187 in epoch 8, gen_loss = 0.3973263199342058, disc_loss = 0.06560636438587879
Trained batch 188 in epoch 8, gen_loss = 0.39741401476834814, disc_loss = 0.06587178327103771
Trained batch 189 in epoch 8, gen_loss = 0.39741654317629965, disc_loss = 0.0661030091737446
Trained batch 190 in epoch 8, gen_loss = 0.39710330697878493, disc_loss = 0.06741658383639071
Trained batch 191 in epoch 8, gen_loss = 0.3972340594045818, disc_loss = 0.06818859015281002
Trained batch 192 in epoch 8, gen_loss = 0.39712372746492297, disc_loss = 0.06794715169913719
Trained batch 193 in epoch 8, gen_loss = 0.3969904396337332, disc_loss = 0.06832218987233553
Trained batch 194 in epoch 8, gen_loss = 0.3971888890633216, disc_loss = 0.06802824104252533
Trained batch 195 in epoch 8, gen_loss = 0.39776797714282053, disc_loss = 0.06803769970844899
Trained batch 196 in epoch 8, gen_loss = 0.3981720687169109, disc_loss = 0.06782531054681025
Trained batch 197 in epoch 8, gen_loss = 0.3981011347337203, disc_loss = 0.06769061209916165
Trained batch 198 in epoch 8, gen_loss = 0.39807714828893764, disc_loss = 0.0677880772188231
Trained batch 199 in epoch 8, gen_loss = 0.39799189642071725, disc_loss = 0.06759311052970589
Trained batch 200 in epoch 8, gen_loss = 0.3979508480918941, disc_loss = 0.06743779759020058
Trained batch 201 in epoch 8, gen_loss = 0.3981990275701674, disc_loss = 0.06734026713057024
Trained batch 202 in epoch 8, gen_loss = 0.3976340007605811, disc_loss = 0.0672376556918392
Trained batch 203 in epoch 8, gen_loss = 0.397882609390745, disc_loss = 0.06706269446066489
Trained batch 204 in epoch 8, gen_loss = 0.3979811217726731, disc_loss = 0.06691293501090713
Trained batch 205 in epoch 8, gen_loss = 0.3979138798505357, disc_loss = 0.0671598628362261
Trained batch 206 in epoch 8, gen_loss = 0.39831377227525205, disc_loss = 0.06795343964536121
Trained batch 207 in epoch 8, gen_loss = 0.39871366837849986, disc_loss = 0.06765009945509239
Trained batch 208 in epoch 8, gen_loss = 0.39871896425502723, disc_loss = 0.06743450868322233
Trained batch 209 in epoch 8, gen_loss = 0.3986034972327096, disc_loss = 0.06720954886681976
Trained batch 210 in epoch 8, gen_loss = 0.3984114824313123, disc_loss = 0.0669318296862722
Trained batch 211 in epoch 8, gen_loss = 0.3985903673576859, disc_loss = 0.06670418969478528
Trained batch 212 in epoch 8, gen_loss = 0.398503603649811, disc_loss = 0.06649438177231053
Trained batch 213 in epoch 8, gen_loss = 0.3981708907913939, disc_loss = 0.06678959122362817
Trained batch 214 in epoch 8, gen_loss = 0.3980238059232401, disc_loss = 0.06735615349959495
Trained batch 215 in epoch 8, gen_loss = 0.39784608560579793, disc_loss = 0.06712596495290873
Trained batch 216 in epoch 8, gen_loss = 0.39783592199400275, disc_loss = 0.0669460184700478
Trained batch 217 in epoch 8, gen_loss = 0.3977020611183359, disc_loss = 0.06672957032030329
Trained batch 218 in epoch 8, gen_loss = 0.3976528784727941, disc_loss = 0.06648346992660331
Trained batch 219 in epoch 8, gen_loss = 0.39779445840553807, disc_loss = 0.06628227362578565
Trained batch 220 in epoch 8, gen_loss = 0.3976049266789294, disc_loss = 0.06620572544465778
Trained batch 221 in epoch 8, gen_loss = 0.39788774904367086, disc_loss = 0.06597285682067007
Trained batch 222 in epoch 8, gen_loss = 0.39812851660454757, disc_loss = 0.06579649199067611
Trained batch 223 in epoch 8, gen_loss = 0.39812038612685036, disc_loss = 0.06553525247727521
Trained batch 224 in epoch 8, gen_loss = 0.39790281309021847, disc_loss = 0.06533670202311542
Trained batch 225 in epoch 8, gen_loss = 0.3982538317157104, disc_loss = 0.0652531893157392
Trained batch 226 in epoch 8, gen_loss = 0.39828493652889907, disc_loss = 0.06516297974332445
Trained batch 227 in epoch 8, gen_loss = 0.3982546444524798, disc_loss = 0.06495369385454085
Trained batch 228 in epoch 8, gen_loss = 0.39845126620026133, disc_loss = 0.06475464997642295
Trained batch 229 in epoch 8, gen_loss = 0.39873220376346424, disc_loss = 0.06477756848072876
Trained batch 230 in epoch 8, gen_loss = 0.39913154886914537, disc_loss = 0.06490699554595983
Trained batch 231 in epoch 8, gen_loss = 0.3986576372950241, disc_loss = 0.06634293022517372
Trained batch 232 in epoch 8, gen_loss = 0.39876579279040064, disc_loss = 0.06655003403437368
Trained batch 233 in epoch 8, gen_loss = 0.3989985026100762, disc_loss = 0.06648019590996142
Trained batch 234 in epoch 8, gen_loss = 0.39914541764462247, disc_loss = 0.06624234432473462
Trained batch 235 in epoch 8, gen_loss = 0.39904887456510024, disc_loss = 0.06625574302733324
Trained batch 236 in epoch 8, gen_loss = 0.39909117068419475, disc_loss = 0.06600473514258988
Trained batch 237 in epoch 8, gen_loss = 0.3989904004485667, disc_loss = 0.06595555503124825
Trained batch 238 in epoch 8, gen_loss = 0.39872642728075325, disc_loss = 0.06631465671997065
Trained batch 239 in epoch 8, gen_loss = 0.39877000836034615, disc_loss = 0.0666992564802058
Trained batch 240 in epoch 8, gen_loss = 0.3986108018649564, disc_loss = 0.06691771595356252
Trained batch 241 in epoch 8, gen_loss = 0.3984057165620741, disc_loss = 0.06672072048445256
Trained batch 242 in epoch 8, gen_loss = 0.39871203654096943, disc_loss = 0.0669814636547563
Trained batch 243 in epoch 8, gen_loss = 0.3987947859969295, disc_loss = 0.06799463550254825
Trained batch 244 in epoch 8, gen_loss = 0.3989999407408189, disc_loss = 0.06789553735253154
Trained batch 245 in epoch 8, gen_loss = 0.39891079310479205, disc_loss = 0.06791398193823492
Trained batch 246 in epoch 8, gen_loss = 0.39889585827043667, disc_loss = 0.06768493156367347
Trained batch 247 in epoch 8, gen_loss = 0.39880262050897847, disc_loss = 0.06752616510681447
Trained batch 248 in epoch 8, gen_loss = 0.3985455167820176, disc_loss = 0.06785821012150212
Trained batch 249 in epoch 8, gen_loss = 0.39871280860900876, disc_loss = 0.06857082272693515
Trained batch 250 in epoch 8, gen_loss = 0.39879199909973906, disc_loss = 0.06837526419797385
Trained batch 251 in epoch 8, gen_loss = 0.39898379974895054, disc_loss = 0.06877189672492917
Trained batch 252 in epoch 8, gen_loss = 0.3989700308665928, disc_loss = 0.06947895736164844
Trained batch 253 in epoch 8, gen_loss = 0.39870335525415074, disc_loss = 0.06933171837773966
Trained batch 254 in epoch 8, gen_loss = 0.3986831220926023, disc_loss = 0.06935670143906392
Trained batch 255 in epoch 8, gen_loss = 0.398433527443558, disc_loss = 0.0691769634904631
Trained batch 256 in epoch 8, gen_loss = 0.39835511745181995, disc_loss = 0.06899558354517017
Trained batch 257 in epoch 8, gen_loss = 0.39839257542477097, disc_loss = 0.06887358209378151
Trained batch 258 in epoch 8, gen_loss = 0.3985460045024695, disc_loss = 0.06884191299224107
Trained batch 259 in epoch 8, gen_loss = 0.3984841757095777, disc_loss = 0.06929388718607907
Trained batch 260 in epoch 8, gen_loss = 0.39852592885722604, disc_loss = 0.07038452498029589
Trained batch 261 in epoch 8, gen_loss = 0.3982473145459444, disc_loss = 0.0701843916779768
Trained batch 262 in epoch 8, gen_loss = 0.39797012048982394, disc_loss = 0.07024865031256536
Trained batch 263 in epoch 8, gen_loss = 0.3979746349381678, disc_loss = 0.0704328956287072
Trained batch 264 in epoch 8, gen_loss = 0.39779637219770897, disc_loss = 0.07058392007185041
Trained batch 265 in epoch 8, gen_loss = 0.39777468290544093, disc_loss = 0.07052786535184298
Trained batch 266 in epoch 8, gen_loss = 0.3977401460824388, disc_loss = 0.07031453223306029
Trained batch 267 in epoch 8, gen_loss = 0.39770200448249704, disc_loss = 0.07013550996710893
Trained batch 268 in epoch 8, gen_loss = 0.39779619457110155, disc_loss = 0.06992079446708513
Trained batch 269 in epoch 8, gen_loss = 0.3979157402559563, disc_loss = 0.06979252993025714
Trained batch 270 in epoch 8, gen_loss = 0.3975323522222878, disc_loss = 0.07081292838036904
Trained batch 271 in epoch 8, gen_loss = 0.3979422191486639, disc_loss = 0.0722068634658011
Trained batch 272 in epoch 8, gen_loss = 0.3978891651054005, disc_loss = 0.07202399830118968
Trained batch 273 in epoch 8, gen_loss = 0.39744393668905664, disc_loss = 0.07203733594408326
Trained batch 274 in epoch 8, gen_loss = 0.39727103374221107, disc_loss = 0.07188771851022135
Trained batch 275 in epoch 8, gen_loss = 0.3972812683685966, disc_loss = 0.07172018821702163
Trained batch 276 in epoch 8, gen_loss = 0.3973613096273333, disc_loss = 0.0714851834404447
Trained batch 277 in epoch 8, gen_loss = 0.3974021178998535, disc_loss = 0.07126399559444553
Trained batch 278 in epoch 8, gen_loss = 0.3975643779428202, disc_loss = 0.07108278919385219
Trained batch 279 in epoch 8, gen_loss = 0.39769658584679873, disc_loss = 0.07087983222611781
Trained batch 280 in epoch 8, gen_loss = 0.39774785474526075, disc_loss = 0.07077494093624616
Trained batch 281 in epoch 8, gen_loss = 0.3976028465421487, disc_loss = 0.07071328679337463
Trained batch 282 in epoch 8, gen_loss = 0.3972169908533669, disc_loss = 0.07111161645475525
Trained batch 283 in epoch 8, gen_loss = 0.3973556667776175, disc_loss = 0.07141223910238437
Trained batch 284 in epoch 8, gen_loss = 0.39740094584331176, disc_loss = 0.07119062503374983
Trained batch 285 in epoch 8, gen_loss = 0.39714784305412454, disc_loss = 0.07102758626590346
Trained batch 286 in epoch 8, gen_loss = 0.39719044663764874, disc_loss = 0.07097744888817496
Trained batch 287 in epoch 8, gen_loss = 0.397164989883701, disc_loss = 0.07149313534157248
Trained batch 288 in epoch 8, gen_loss = 0.39705043917708743, disc_loss = 0.07216913888881879
Trained batch 289 in epoch 8, gen_loss = 0.39703390053633986, disc_loss = 0.07206693611846401
Trained batch 290 in epoch 8, gen_loss = 0.39744035105934666, disc_loss = 0.07189986695090622
Trained batch 291 in epoch 8, gen_loss = 0.3973468533933979, disc_loss = 0.07185327258177918
Trained batch 292 in epoch 8, gen_loss = 0.3979288123980317, disc_loss = 0.07210420831440353
Trained batch 293 in epoch 8, gen_loss = 0.39789275155991927, disc_loss = 0.07219391414059365
Trained batch 294 in epoch 8, gen_loss = 0.3978771806773493, disc_loss = 0.0720505011631018
Trained batch 295 in epoch 8, gen_loss = 0.39784524307863134, disc_loss = 0.07195986774309564
Trained batch 296 in epoch 8, gen_loss = 0.39789532360805807, disc_loss = 0.07186249743595167
Trained batch 297 in epoch 8, gen_loss = 0.39801887397798114, disc_loss = 0.07166001280994723
Trained batch 298 in epoch 8, gen_loss = 0.3979258665871062, disc_loss = 0.07143883722177068
Trained batch 299 in epoch 8, gen_loss = 0.3979520210623741, disc_loss = 0.07138951697542022
Trained batch 300 in epoch 8, gen_loss = 0.39802845470929066, disc_loss = 0.07141829805411522
Trained batch 301 in epoch 8, gen_loss = 0.3979711066808132, disc_loss = 0.07158522259610527
Trained batch 302 in epoch 8, gen_loss = 0.3982141435933192, disc_loss = 0.07154003030193275
Trained batch 303 in epoch 8, gen_loss = 0.39850370487884473, disc_loss = 0.0713604150667762
Trained batch 304 in epoch 8, gen_loss = 0.3987338213646998, disc_loss = 0.07130644079450457
Trained batch 305 in epoch 8, gen_loss = 0.3987219054130168, disc_loss = 0.07111560755251037
Trained batch 306 in epoch 8, gen_loss = 0.39897291978718014, disc_loss = 0.0709312927411681
Trained batch 307 in epoch 8, gen_loss = 0.3991401018453883, disc_loss = 0.07074434220542913
Trained batch 308 in epoch 8, gen_loss = 0.3991091656453401, disc_loss = 0.07068935624839177
Trained batch 309 in epoch 8, gen_loss = 0.3991613582257302, disc_loss = 0.07055705637190371
Trained batch 310 in epoch 8, gen_loss = 0.3994237034075513, disc_loss = 0.07064377790065392
Trained batch 311 in epoch 8, gen_loss = 0.39928325628622985, disc_loss = 0.07122919152532585
Trained batch 312 in epoch 8, gen_loss = 0.39961861497677936, disc_loss = 0.07153975761706789
Trained batch 313 in epoch 8, gen_loss = 0.39992159652482173, disc_loss = 0.07148975300436519
Trained batch 314 in epoch 8, gen_loss = 0.4000715722167303, disc_loss = 0.07131722781600223
Trained batch 315 in epoch 8, gen_loss = 0.40009221462886546, disc_loss = 0.07112973159963053
Trained batch 316 in epoch 8, gen_loss = 0.40017427884817874, disc_loss = 0.07093114171570832
Trained batch 317 in epoch 8, gen_loss = 0.4004638907294603, disc_loss = 0.07075476757859893
Trained batch 318 in epoch 8, gen_loss = 0.4004356772361504, disc_loss = 0.0705543641208271
Trained batch 319 in epoch 8, gen_loss = 0.4004529255442321, disc_loss = 0.07035196073411498
Trained batch 320 in epoch 8, gen_loss = 0.40022194394812777, disc_loss = 0.07015467296003414
Trained batch 321 in epoch 8, gen_loss = 0.400351276031192, disc_loss = 0.06995356124420853
Trained batch 322 in epoch 8, gen_loss = 0.40009470104064, disc_loss = 0.06979365572304502
Trained batch 323 in epoch 8, gen_loss = 0.3998557677791442, disc_loss = 0.06972242993400375
Trained batch 324 in epoch 8, gen_loss = 0.3997602869914128, disc_loss = 0.0698170388246385
Trained batch 325 in epoch 8, gen_loss = 0.39984173569942544, disc_loss = 0.06971787044669907
Trained batch 326 in epoch 8, gen_loss = 0.39983572197981204, disc_loss = 0.06984459260615324
Trained batch 327 in epoch 8, gen_loss = 0.39961586638194757, disc_loss = 0.07071574904995676
Trained batch 328 in epoch 8, gen_loss = 0.3999053718108899, disc_loss = 0.07106003310604977
Trained batch 329 in epoch 8, gen_loss = 0.39998016529011005, disc_loss = 0.07093583608864609
Trained batch 330 in epoch 8, gen_loss = 0.39966071579391504, disc_loss = 0.07092135126513972
Trained batch 331 in epoch 8, gen_loss = 0.3995720547545387, disc_loss = 0.0708485446037186
Trained batch 332 in epoch 8, gen_loss = 0.399799865197849, disc_loss = 0.07087448343785631
Trained batch 333 in epoch 8, gen_loss = 0.39972921733013883, disc_loss = 0.07071607187808586
Trained batch 334 in epoch 8, gen_loss = 0.3994865277809883, disc_loss = 0.07074406234158287
Trained batch 335 in epoch 8, gen_loss = 0.39929939132361186, disc_loss = 0.07104317469583336
Trained batch 336 in epoch 8, gen_loss = 0.39909660232526967, disc_loss = 0.07125757557674359
Trained batch 337 in epoch 8, gen_loss = 0.399249457925029, disc_loss = 0.07116721081547439
Trained batch 338 in epoch 8, gen_loss = 0.39929850456637267, disc_loss = 0.07123986515559938
Trained batch 339 in epoch 8, gen_loss = 0.39917052186587276, disc_loss = 0.07128251515301492
Trained batch 340 in epoch 8, gen_loss = 0.39940036793957706, disc_loss = 0.07119791544400308
Trained batch 341 in epoch 8, gen_loss = 0.39923566614675243, disc_loss = 0.07101882135152425
Trained batch 342 in epoch 8, gen_loss = 0.39948252938231643, disc_loss = 0.0709024284173444
Trained batch 343 in epoch 8, gen_loss = 0.3994180120874283, disc_loss = 0.07075379155765743
Trained batch 344 in epoch 8, gen_loss = 0.3994737215664076, disc_loss = 0.07065824093567072
Trained batch 345 in epoch 8, gen_loss = 0.39970835431807306, disc_loss = 0.07076050944470214
Trained batch 346 in epoch 8, gen_loss = 0.3996242361213013, disc_loss = 0.07093272442320195
Trained batch 347 in epoch 8, gen_loss = 0.3995270816416576, disc_loss = 0.07081839766476475
Trained batch 348 in epoch 8, gen_loss = 0.39959356137538027, disc_loss = 0.07067956210095382
Trained batch 349 in epoch 8, gen_loss = 0.39955671199730464, disc_loss = 0.07054750897921622
Trained batch 350 in epoch 8, gen_loss = 0.39970925127678786, disc_loss = 0.07042596685405597
Trained batch 351 in epoch 8, gen_loss = 0.39984074675224046, disc_loss = 0.07029071164354471
Trained batch 352 in epoch 8, gen_loss = 0.39990895404018695, disc_loss = 0.07018887853017737
Trained batch 353 in epoch 8, gen_loss = 0.39984182314684164, disc_loss = 0.07004004007463191
Trained batch 354 in epoch 8, gen_loss = 0.4001405072883821, disc_loss = 0.07020158962753247
Trained batch 355 in epoch 8, gen_loss = 0.39994102322988295, disc_loss = 0.07048596514865045
Trained batch 356 in epoch 8, gen_loss = 0.4001759455985382, disc_loss = 0.07058276048097081
Trained batch 357 in epoch 8, gen_loss = 0.4000056131259023, disc_loss = 0.07069929349808511
Trained batch 358 in epoch 8, gen_loss = 0.4002625615151812, disc_loss = 0.07064071328646418
Trained batch 359 in epoch 8, gen_loss = 0.40039290438095726, disc_loss = 0.07056060444641238
Trained batch 360 in epoch 8, gen_loss = 0.4004098449387379, disc_loss = 0.07047375225413002
Trained batch 361 in epoch 8, gen_loss = 0.4003659648954539, disc_loss = 0.07033515915413546
Trained batch 362 in epoch 8, gen_loss = 0.4004694282515975, disc_loss = 0.07022706484781276
Trained batch 363 in epoch 8, gen_loss = 0.40044916707735795, disc_loss = 0.0702338975606036
Trained batch 364 in epoch 8, gen_loss = 0.4003013091544582, disc_loss = 0.07075192801628823
Trained batch 365 in epoch 8, gen_loss = 0.40029722427735565, disc_loss = 0.07190124100058905
Trained batch 366 in epoch 8, gen_loss = 0.4002452616957943, disc_loss = 0.07198252579532259
Trained batch 367 in epoch 8, gen_loss = 0.40007663720651815, disc_loss = 0.07234052054295519
Trained batch 368 in epoch 8, gen_loss = 0.3998805951619859, disc_loss = 0.07237108857282576
Trained batch 369 in epoch 8, gen_loss = 0.3998145440945754, disc_loss = 0.07225580904506952
Trained batch 370 in epoch 8, gen_loss = 0.39972165194804454, disc_loss = 0.07212616951453356
Trained batch 371 in epoch 8, gen_loss = 0.39952494756829354, disc_loss = 0.07204934372191107
Trained batch 372 in epoch 8, gen_loss = 0.3995993945138384, disc_loss = 0.07208963919396015
Trained batch 373 in epoch 8, gen_loss = 0.39948080822745746, disc_loss = 0.0719630314263809
Trained batch 374 in epoch 8, gen_loss = 0.39961961841583254, disc_loss = 0.07194887781515717
Trained batch 375 in epoch 8, gen_loss = 0.3993640293941853, disc_loss = 0.07202424200504344
Trained batch 376 in epoch 8, gen_loss = 0.3995126611516077, disc_loss = 0.07221766290889771
Trained batch 377 in epoch 8, gen_loss = 0.3996263575301599, disc_loss = 0.0721244143861686
Trained batch 378 in epoch 8, gen_loss = 0.3997568899377355, disc_loss = 0.0719614554538163
Trained batch 379 in epoch 8, gen_loss = 0.39975942820310595, disc_loss = 0.07187711992913759
Trained batch 380 in epoch 8, gen_loss = 0.39999297042218407, disc_loss = 0.07213835109616788
Trained batch 381 in epoch 8, gen_loss = 0.40020162304034407, disc_loss = 0.07240209966795567
Trained batch 382 in epoch 8, gen_loss = 0.4002260967272069, disc_loss = 0.072342658832465
Trained batch 383 in epoch 8, gen_loss = 0.40032047933588427, disc_loss = 0.07222693470612285
Trained batch 384 in epoch 8, gen_loss = 0.4002783710306341, disc_loss = 0.07213181323891917
Trained batch 385 in epoch 8, gen_loss = 0.40055598449830565, disc_loss = 0.07217834510483388
Trained batch 386 in epoch 8, gen_loss = 0.40059596746774917, disc_loss = 0.07204724910719566
Trained batch 387 in epoch 8, gen_loss = 0.40035444267631803, disc_loss = 0.07218086612818897
Trained batch 388 in epoch 8, gen_loss = 0.40036057123488206, disc_loss = 0.07300635644505256
Trained batch 389 in epoch 8, gen_loss = 0.4003551094959944, disc_loss = 0.07315849834599365
Trained batch 390 in epoch 8, gen_loss = 0.40010433634528725, disc_loss = 0.07336608822459874
Trained batch 391 in epoch 8, gen_loss = 0.400126823737305, disc_loss = 0.07329989396563104
Trained batch 392 in epoch 8, gen_loss = 0.4001732759803306, disc_loss = 0.0731440301138538
Trained batch 393 in epoch 8, gen_loss = 0.4003246741246451, disc_loss = 0.07299536136499024
Trained batch 394 in epoch 8, gen_loss = 0.40038488356372975, disc_loss = 0.07284034952827835
Trained batch 395 in epoch 8, gen_loss = 0.40025044751889777, disc_loss = 0.0728271942635095
Trained batch 396 in epoch 8, gen_loss = 0.40027444706455584, disc_loss = 0.07312653910120015
Trained batch 397 in epoch 8, gen_loss = 0.4001852605660357, disc_loss = 0.07361355693613053
Trained batch 398 in epoch 8, gen_loss = 0.4004567040686022, disc_loss = 0.07380357713445573
Trained batch 399 in epoch 8, gen_loss = 0.4005575064569712, disc_loss = 0.07371375967864878
Trained batch 400 in epoch 8, gen_loss = 0.4004713348171063, disc_loss = 0.07366236350487482
Trained batch 401 in epoch 8, gen_loss = 0.4003142413511798, disc_loss = 0.0735115131226586
Trained batch 402 in epoch 8, gen_loss = 0.40032789074161806, disc_loss = 0.07339387646906319
Trained batch 403 in epoch 8, gen_loss = 0.40048238701454486, disc_loss = 0.07323878084765839
Trained batch 404 in epoch 8, gen_loss = 0.4004259818865929, disc_loss = 0.07308468675286865
Trained batch 405 in epoch 8, gen_loss = 0.40046775928271816, disc_loss = 0.07297239894061143
Trained batch 406 in epoch 8, gen_loss = 0.40029195463628087, disc_loss = 0.07292369867649835
Trained batch 407 in epoch 8, gen_loss = 0.40010038040140095, disc_loss = 0.07361656897724149
Trained batch 408 in epoch 8, gen_loss = 0.40037584064350734, disc_loss = 0.0738528524161132
Trained batch 409 in epoch 8, gen_loss = 0.40042366000210367, disc_loss = 0.07369363348499486
Trained batch 410 in epoch 8, gen_loss = 0.40027818700112855, disc_loss = 0.07363865034736312
Trained batch 411 in epoch 8, gen_loss = 0.4003389747542085, disc_loss = 0.0735058946483
Trained batch 412 in epoch 8, gen_loss = 0.4003535304895036, disc_loss = 0.0734187212465985
Trained batch 413 in epoch 8, gen_loss = 0.40037299447877395, disc_loss = 0.07327934625054651
Trained batch 414 in epoch 8, gen_loss = 0.40050959888711035, disc_loss = 0.07335174874211829
Trained batch 415 in epoch 8, gen_loss = 0.40073669615846413, disc_loss = 0.07401024343002624
Trained batch 416 in epoch 8, gen_loss = 0.40066919981432764, disc_loss = 0.07392357931778336
Trained batch 417 in epoch 8, gen_loss = 0.4005873569746337, disc_loss = 0.07382467232809434
Trained batch 418 in epoch 8, gen_loss = 0.4006105455834427, disc_loss = 0.073775451129129
Trained batch 419 in epoch 8, gen_loss = 0.40077423403660456, disc_loss = 0.0736574500987661
Trained batch 420 in epoch 8, gen_loss = 0.4007469313727988, disc_loss = 0.07353472277066381
Trained batch 421 in epoch 8, gen_loss = 0.40086225614446036, disc_loss = 0.07339457458798813
Trained batch 422 in epoch 8, gen_loss = 0.40110740840575937, disc_loss = 0.07325691530419333
Trained batch 423 in epoch 8, gen_loss = 0.40112829194316324, disc_loss = 0.07311755298518242
Trained batch 424 in epoch 8, gen_loss = 0.4011295229547164, disc_loss = 0.07306626541759162
Trained batch 425 in epoch 8, gen_loss = 0.40109107604888683, disc_loss = 0.07361858038279827
Trained batch 426 in epoch 8, gen_loss = 0.40092423565214635, disc_loss = 0.07430209736917735
Trained batch 427 in epoch 8, gen_loss = 0.4010116839520285, disc_loss = 0.07487484545634067
Trained batch 428 in epoch 8, gen_loss = 0.40095365325331966, disc_loss = 0.07474764652380889
Trained batch 429 in epoch 8, gen_loss = 0.4009478652893111, disc_loss = 0.07460164475298031
Trained batch 430 in epoch 8, gen_loss = 0.40078183407020124, disc_loss = 0.07452514509102136
Trained batch 431 in epoch 8, gen_loss = 0.4008124513482606, disc_loss = 0.0743708281456579
Trained batch 432 in epoch 8, gen_loss = 0.4007523723342402, disc_loss = 0.07423759254306452
Trained batch 433 in epoch 8, gen_loss = 0.4006944587153773, disc_loss = 0.07416640249432885
Trained batch 434 in epoch 8, gen_loss = 0.4004594069102715, disc_loss = 0.07421946063016852
Trained batch 435 in epoch 8, gen_loss = 0.40032222121953964, disc_loss = 0.07413068207711357
Trained batch 436 in epoch 8, gen_loss = 0.40033054174493055, disc_loss = 0.07417129458288409
Trained batch 437 in epoch 8, gen_loss = 0.40017999103080193, disc_loss = 0.07442791774320377
Trained batch 438 in epoch 8, gen_loss = 0.40027885848405964, disc_loss = 0.07455042908222739
Trained batch 439 in epoch 8, gen_loss = 0.40037258849902585, disc_loss = 0.07446708135539666
Trained batch 440 in epoch 8, gen_loss = 0.4001526941382696, disc_loss = 0.07485389967856595
Trained batch 441 in epoch 8, gen_loss = 0.4002144120262759, disc_loss = 0.07487848921830668
Trained batch 442 in epoch 8, gen_loss = 0.4002614433017326, disc_loss = 0.07474114084153796
Trained batch 443 in epoch 8, gen_loss = 0.40020050128569473, disc_loss = 0.07460886378550215
Trained batch 444 in epoch 8, gen_loss = 0.40012663930989384, disc_loss = 0.07448371339149856
Trained batch 445 in epoch 8, gen_loss = 0.39989558530495306, disc_loss = 0.07439499454585326
Trained batch 446 in epoch 8, gen_loss = 0.3999567251210778, disc_loss = 0.07427478235910837
Trained batch 447 in epoch 8, gen_loss = 0.3998853932134807, disc_loss = 0.07418755986665408
Trained batch 448 in epoch 8, gen_loss = 0.39995931430755055, disc_loss = 0.0742253426116018
Trained batch 449 in epoch 8, gen_loss = 0.39990702211856843, disc_loss = 0.07421388057474461
Trained batch 450 in epoch 8, gen_loss = 0.3998277354531172, disc_loss = 0.0742060373363781
Trained batch 451 in epoch 8, gen_loss = 0.39965639553502597, disc_loss = 0.07446258845718462
Trained batch 452 in epoch 8, gen_loss = 0.3997866954761362, disc_loss = 0.07510165269147383
Trained batch 453 in epoch 8, gen_loss = 0.399853486387215, disc_loss = 0.0751659365930894
Trained batch 454 in epoch 8, gen_loss = 0.3997452369103065, disc_loss = 0.07507712009291236
Trained batch 455 in epoch 8, gen_loss = 0.3995742788048167, disc_loss = 0.07503066874587123
Trained batch 456 in epoch 8, gen_loss = 0.3994836280982395, disc_loss = 0.07491819466886068
Trained batch 457 in epoch 8, gen_loss = 0.3995590043380271, disc_loss = 0.07492498032785301
Trained batch 458 in epoch 8, gen_loss = 0.39994387286421, disc_loss = 0.0749361700345894
Testing Epoch 8
Training Epoch 9
Trained batch 0 in epoch 9, gen_loss = 0.3310506343841553, disc_loss = 0.1290748566389084
Trained batch 1 in epoch 9, gen_loss = 0.36180171370506287, disc_loss = 0.1793489009141922
Trained batch 2 in epoch 9, gen_loss = 0.35836337010065716, disc_loss = 0.1438909520705541
Trained batch 3 in epoch 9, gen_loss = 0.37190697342157364, disc_loss = 0.12576971389353275
Trained batch 4 in epoch 9, gen_loss = 0.38473832607269287, disc_loss = 0.1369256004691124
Trained batch 5 in epoch 9, gen_loss = 0.38241487244764966, disc_loss = 0.1197121540705363
Trained batch 6 in epoch 9, gen_loss = 0.38393726093428476, disc_loss = 0.10652488682951246
Trained batch 7 in epoch 9, gen_loss = 0.3793816938996315, disc_loss = 0.09377075405791402
Trained batch 8 in epoch 9, gen_loss = 0.3828246096769969, disc_loss = 0.08534413224293126
Trained batch 9 in epoch 9, gen_loss = 0.38888882398605346, disc_loss = 0.0846107391640544
Trained batch 10 in epoch 9, gen_loss = 0.3862806883725253, disc_loss = 0.10328462432053956
Trained batch 11 in epoch 9, gen_loss = 0.39076409488916397, disc_loss = 0.10985202699278791
Trained batch 12 in epoch 9, gen_loss = 0.38895658117074233, disc_loss = 0.11291102362939945
Trained batch 13 in epoch 9, gen_loss = 0.3852699590580804, disc_loss = 0.1074586786063654
Trained batch 14 in epoch 9, gen_loss = 0.3850574235121409, disc_loss = 0.10158751209576924
Trained batch 15 in epoch 9, gen_loss = 0.38624841161072254, disc_loss = 0.0958929731277749
Trained batch 16 in epoch 9, gen_loss = 0.38439150768167835, disc_loss = 0.09076246422003298
Trained batch 17 in epoch 9, gen_loss = 0.3862859871652391, disc_loss = 0.08694745703703827
Trained batch 18 in epoch 9, gen_loss = 0.3838364325071636, disc_loss = 0.08497478597258266
Trained batch 19 in epoch 9, gen_loss = 0.3839027419686317, disc_loss = 0.09027596171945333
Trained batch 20 in epoch 9, gen_loss = 0.3879510604199909, disc_loss = 0.1097621341191587
Trained batch 21 in epoch 9, gen_loss = 0.38931111855940387, disc_loss = 0.10907902924174612
Trained batch 22 in epoch 9, gen_loss = 0.38751998155013373, disc_loss = 0.11383142046954321
Trained batch 23 in epoch 9, gen_loss = 0.3865269136925538, disc_loss = 0.11041387123987079
Trained batch 24 in epoch 9, gen_loss = 0.3848666572570801, disc_loss = 0.1084164734184742
Trained batch 25 in epoch 9, gen_loss = 0.3861609869278394, disc_loss = 0.10518517903983593
Trained batch 26 in epoch 9, gen_loss = 0.3859757792066645, disc_loss = 0.10255707662414622
Trained batch 27 in epoch 9, gen_loss = 0.38496687688997816, disc_loss = 0.1011566479823419
Trained batch 28 in epoch 9, gen_loss = 0.38451628746657535, disc_loss = 0.09997852609075349
Trained batch 29 in epoch 9, gen_loss = 0.38426931003729503, disc_loss = 0.10110826989014944
Trained batch 30 in epoch 9, gen_loss = 0.3876210768376627, disc_loss = 0.10649880574595544
Trained batch 31 in epoch 9, gen_loss = 0.39019422605633736, disc_loss = 0.10332965463749133
Trained batch 32 in epoch 9, gen_loss = 0.39157436110756616, disc_loss = 0.10103653487043851
Trained batch 33 in epoch 9, gen_loss = 0.3901398707838619, disc_loss = 0.09857655439854544
Trained batch 34 in epoch 9, gen_loss = 0.38962296758379256, disc_loss = 0.09623117971100978
Trained batch 35 in epoch 9, gen_loss = 0.38799238867229885, disc_loss = 0.09505330473701987
Trained batch 36 in epoch 9, gen_loss = 0.38630402249258916, disc_loss = 0.0938926167232362
Trained batch 37 in epoch 9, gen_loss = 0.3866590794764067, disc_loss = 0.09775940576372177
Trained batch 38 in epoch 9, gen_loss = 0.3837280212304531, disc_loss = 0.0965646352762213
Trained batch 39 in epoch 9, gen_loss = 0.38367279022932055, disc_loss = 0.09818814622703939
Trained batch 40 in epoch 9, gen_loss = 0.3849974449087934, disc_loss = 0.09732343404122241
Trained batch 41 in epoch 9, gen_loss = 0.38664356157893226, disc_loss = 0.09694751762297182
Trained batch 42 in epoch 9, gen_loss = 0.38861849696137185, disc_loss = 0.0948362777681025
Trained batch 43 in epoch 9, gen_loss = 0.3876342536373572, disc_loss = 0.0928734530250288
Trained batch 44 in epoch 9, gen_loss = 0.38730757501390245, disc_loss = 0.09110995074734092
Trained batch 45 in epoch 9, gen_loss = 0.3864313998947973, disc_loss = 0.09009607791212267
Trained batch 46 in epoch 9, gen_loss = 0.38681344973280074, disc_loss = 0.08875699058928072
Trained batch 47 in epoch 9, gen_loss = 0.3870204910635948, disc_loss = 0.08761194428855863
Trained batch 48 in epoch 9, gen_loss = 0.388629816624583, disc_loss = 0.08979947548549698
Trained batch 49 in epoch 9, gen_loss = 0.38735810995101927, disc_loss = 0.09594434636645019
Trained batch 50 in epoch 9, gen_loss = 0.3866189870179868, disc_loss = 0.09654931945945411
Trained batch 51 in epoch 9, gen_loss = 0.38745434696857745, disc_loss = 0.09632804175803009
Trained batch 52 in epoch 9, gen_loss = 0.3884266935429483, disc_loss = 0.09577990705498828
Trained batch 53 in epoch 9, gen_loss = 0.3877947352550648, disc_loss = 0.09674235187574393
Trained batch 54 in epoch 9, gen_loss = 0.38848877549171446, disc_loss = 0.09765623837540095
Trained batch 55 in epoch 9, gen_loss = 0.38877139719469206, disc_loss = 0.09729660757251882
Trained batch 56 in epoch 9, gen_loss = 0.3896902208788353, disc_loss = 0.09820442322412865
Trained batch 57 in epoch 9, gen_loss = 0.38964947235995323, disc_loss = 0.10065889951837217
Trained batch 58 in epoch 9, gen_loss = 0.39010288099111134, disc_loss = 0.09945092387339574
Trained batch 59 in epoch 9, gen_loss = 0.3907190745075544, disc_loss = 0.09827223695659389
Trained batch 60 in epoch 9, gen_loss = 0.39062779115848856, disc_loss = 0.09796418508392621
Trained batch 61 in epoch 9, gen_loss = 0.3904271063304717, disc_loss = 0.09720417667150257
Trained batch 62 in epoch 9, gen_loss = 0.3907609146738809, disc_loss = 0.09609399956931906
Trained batch 63 in epoch 9, gen_loss = 0.39229081431403756, disc_loss = 0.09632755032362184
Trained batch 64 in epoch 9, gen_loss = 0.3922056211875035, disc_loss = 0.09806762437264506
Trained batch 65 in epoch 9, gen_loss = 0.3941618578903603, disc_loss = 0.09827425011264329
Trained batch 66 in epoch 9, gen_loss = 0.3948679535246607, disc_loss = 0.09706803986024279
Trained batch 67 in epoch 9, gen_loss = 0.3951759960721521, disc_loss = 0.09603832790162414
Trained batch 68 in epoch 9, gen_loss = 0.39520498721495917, disc_loss = 0.09507150866388195
Trained batch 69 in epoch 9, gen_loss = 0.3956383790288653, disc_loss = 0.09439525906927884
Trained batch 70 in epoch 9, gen_loss = 0.3950234072309145, disc_loss = 0.09333975318635643
Trained batch 71 in epoch 9, gen_loss = 0.3951288556887044, disc_loss = 0.09223734059034744
Trained batch 72 in epoch 9, gen_loss = 0.3947211932646085, disc_loss = 0.09128068070475982
Trained batch 73 in epoch 9, gen_loss = 0.3949420206450127, disc_loss = 0.09155887988949749
Trained batch 74 in epoch 9, gen_loss = 0.3942640920480092, disc_loss = 0.0936280564405024
Trained batch 75 in epoch 9, gen_loss = 0.39502982991306407, disc_loss = 0.09263034041750391
Trained batch 76 in epoch 9, gen_loss = 0.3958332267674533, disc_loss = 0.09206081181159848
Trained batch 77 in epoch 9, gen_loss = 0.39513026368923676, disc_loss = 0.0910898681718092
Trained batch 78 in epoch 9, gen_loss = 0.3952838997297649, disc_loss = 0.09005234237831039
Trained batch 79 in epoch 9, gen_loss = 0.39477979615330694, disc_loss = 0.08925758232944644
Trained batch 80 in epoch 9, gen_loss = 0.39294257336928523, disc_loss = 0.08955496968701482
Trained batch 81 in epoch 9, gen_loss = 0.394625141671518, disc_loss = 0.0913369458952419
Trained batch 82 in epoch 9, gen_loss = 0.3948669884219227, disc_loss = 0.09110697965328414
Trained batch 83 in epoch 9, gen_loss = 0.393486922872918, disc_loss = 0.0905890061708522
Trained batch 84 in epoch 9, gen_loss = 0.3928871643893859, disc_loss = 0.09122868351747884
Trained batch 85 in epoch 9, gen_loss = 0.3942475642922313, disc_loss = 0.09025639339978266
Trained batch 86 in epoch 9, gen_loss = 0.3944654418476697, disc_loss = 0.09003629442304373
Trained batch 87 in epoch 9, gen_loss = 0.3946130785413764, disc_loss = 0.08910739962646569
Trained batch 88 in epoch 9, gen_loss = 0.3940655995955628, disc_loss = 0.08831721501362123
Trained batch 89 in epoch 9, gen_loss = 0.39302707496616573, disc_loss = 0.0883202969096601
Trained batch 90 in epoch 9, gen_loss = 0.3939164465927816, disc_loss = 0.0878893838949747
Trained batch 91 in epoch 9, gen_loss = 0.3945708532372247, disc_loss = 0.08723069487504014
Trained batch 92 in epoch 9, gen_loss = 0.39476076457449183, disc_loss = 0.08717897329078887
Trained batch 93 in epoch 9, gen_loss = 0.39351362037531873, disc_loss = 0.08836306048002332
Trained batch 94 in epoch 9, gen_loss = 0.3942479621422918, disc_loss = 0.08789634789879384
Trained batch 95 in epoch 9, gen_loss = 0.39453886371726793, disc_loss = 0.0872363033995498
Trained batch 96 in epoch 9, gen_loss = 0.39427578618231507, disc_loss = 0.08682378726176072
Trained batch 97 in epoch 9, gen_loss = 0.39490757593695, disc_loss = 0.08621169437597297
Trained batch 98 in epoch 9, gen_loss = 0.39587915982260846, disc_loss = 0.0857251960915899
Trained batch 99 in epoch 9, gen_loss = 0.39602850332856177, disc_loss = 0.08495615459047258
Trained batch 100 in epoch 9, gen_loss = 0.39557686610387105, disc_loss = 0.0849306959529767
Trained batch 101 in epoch 9, gen_loss = 0.3960425525027163, disc_loss = 0.0842594956047833
Trained batch 102 in epoch 9, gen_loss = 0.39647201354642514, disc_loss = 0.083704128400287
Trained batch 103 in epoch 9, gen_loss = 0.3963350336998701, disc_loss = 0.08310252830135421
Trained batch 104 in epoch 9, gen_loss = 0.3959510875599725, disc_loss = 0.08632733169943094
Trained batch 105 in epoch 9, gen_loss = 0.39690138582351076, disc_loss = 0.08598676960880183
Trained batch 106 in epoch 9, gen_loss = 0.3977711021064598, disc_loss = 0.08637896323768056
Trained batch 107 in epoch 9, gen_loss = 0.3973177176106859, disc_loss = 0.08592956427795191
Trained batch 108 in epoch 9, gen_loss = 0.3968573618646062, disc_loss = 0.08650494193436083
Trained batch 109 in epoch 9, gen_loss = 0.3966392315246842, disc_loss = 0.08586264023218643
Trained batch 110 in epoch 9, gen_loss = 0.39789377663049613, disc_loss = 0.08526503027055983
Trained batch 111 in epoch 9, gen_loss = 0.39827519322612454, disc_loss = 0.08463885439726125
Trained batch 112 in epoch 9, gen_loss = 0.3992594030842317, disc_loss = 0.08396473812944857
Trained batch 113 in epoch 9, gen_loss = 0.39876703826481835, disc_loss = 0.08333005824763524
Trained batch 114 in epoch 9, gen_loss = 0.3986294537782669, disc_loss = 0.082923507820005
Trained batch 115 in epoch 9, gen_loss = 0.3981678024705114, disc_loss = 0.08256028823811433
Trained batch 116 in epoch 9, gen_loss = 0.39807217561791086, disc_loss = 0.08258499491673249
Trained batch 117 in epoch 9, gen_loss = 0.3979286052665468, disc_loss = 0.08333156491487713
Trained batch 118 in epoch 9, gen_loss = 0.39789002094449116, disc_loss = 0.08360851468408809
Trained batch 119 in epoch 9, gen_loss = 0.3968119860937198, disc_loss = 0.08302590021242698
Trained batch 120 in epoch 9, gen_loss = 0.3966750459483832, disc_loss = 0.08242601578023807
Trained batch 121 in epoch 9, gen_loss = 0.3973000334178815, disc_loss = 0.08181425473332161
Trained batch 122 in epoch 9, gen_loss = 0.39778662563824074, disc_loss = 0.08123389948008021
Trained batch 123 in epoch 9, gen_loss = 0.39831778515250454, disc_loss = 0.08076624268846165
Trained batch 124 in epoch 9, gen_loss = 0.39975776064395907, disc_loss = 0.08078380677103997
Trained batch 125 in epoch 9, gen_loss = 0.39884779696899747, disc_loss = 0.0822766176942322
Trained batch 126 in epoch 9, gen_loss = 0.3989628465391519, disc_loss = 0.08383107299762448
Trained batch 127 in epoch 9, gen_loss = 0.399345051147975, disc_loss = 0.08329233772383304
Trained batch 128 in epoch 9, gen_loss = 0.3989130569289821, disc_loss = 0.08364351683606704
Trained batch 129 in epoch 9, gen_loss = 0.39938251295915017, disc_loss = 0.08313980720793972
Trained batch 130 in epoch 9, gen_loss = 0.3995712744143173, disc_loss = 0.08275347006087767
Trained batch 131 in epoch 9, gen_loss = 0.3992326572311647, disc_loss = 0.08231900332523792
Trained batch 132 in epoch 9, gen_loss = 0.3990707878107415, disc_loss = 0.08200949975954634
Trained batch 133 in epoch 9, gen_loss = 0.3994167615006219, disc_loss = 0.08163907717385177
Trained batch 134 in epoch 9, gen_loss = 0.39925520188278624, disc_loss = 0.08150605795973981
Trained batch 135 in epoch 9, gen_loss = 0.3991034200743717, disc_loss = 0.08478311443126157
Trained batch 136 in epoch 9, gen_loss = 0.3996354346945338, disc_loss = 0.0844945333231866
Trained batch 137 in epoch 9, gen_loss = 0.39935128552758176, disc_loss = 0.08644597490817524
Trained batch 138 in epoch 9, gen_loss = 0.3988597919400647, disc_loss = 0.08808835118124597
Trained batch 139 in epoch 9, gen_loss = 0.3984895032431398, disc_loss = 0.0891456260146307
Trained batch 140 in epoch 9, gen_loss = 0.3981783946989276, disc_loss = 0.08984332504609586
Trained batch 141 in epoch 9, gen_loss = 0.39835530571954353, disc_loss = 0.09025362322211895
Trained batch 142 in epoch 9, gen_loss = 0.3976935980828492, disc_loss = 0.09055350532664078
Trained batch 143 in epoch 9, gen_loss = 0.3977055149152875, disc_loss = 0.09100517164269048
Trained batch 144 in epoch 9, gen_loss = 0.39774404013979026, disc_loss = 0.09110936110775018
Trained batch 145 in epoch 9, gen_loss = 0.39713253683015093, disc_loss = 0.09159743213668874
Trained batch 146 in epoch 9, gen_loss = 0.39734149333976565, disc_loss = 0.09172447993210991
Trained batch 147 in epoch 9, gen_loss = 0.39764071910365206, disc_loss = 0.09199427636466115
Trained batch 148 in epoch 9, gen_loss = 0.39782488116081927, disc_loss = 0.09195084474205771
Trained batch 149 in epoch 9, gen_loss = 0.3977809426188469, disc_loss = 0.09153784920151035
Trained batch 150 in epoch 9, gen_loss = 0.3980917898037576, disc_loss = 0.09131853197954151
Trained batch 151 in epoch 9, gen_loss = 0.39797050594107103, disc_loss = 0.09100310403338976
Trained batch 152 in epoch 9, gen_loss = 0.3979170689590616, disc_loss = 0.09065011885698909
Trained batch 153 in epoch 9, gen_loss = 0.39805976533657544, disc_loss = 0.09013562290868782
Trained batch 154 in epoch 9, gen_loss = 0.3977952838905396, disc_loss = 0.08967369824287391
Trained batch 155 in epoch 9, gen_loss = 0.3976720415819914, disc_loss = 0.08955263394790773
Trained batch 156 in epoch 9, gen_loss = 0.3980495084053392, disc_loss = 0.09059297384184067
Trained batch 157 in epoch 9, gen_loss = 0.39808664885880074, disc_loss = 0.09032823127116772
Trained batch 158 in epoch 9, gen_loss = 0.39777819043810264, disc_loss = 0.08997423523369263
Trained batch 159 in epoch 9, gen_loss = 0.398140003811568, disc_loss = 0.08973296892945655
Trained batch 160 in epoch 9, gen_loss = 0.3971641123850153, disc_loss = 0.08957084303617663
Trained batch 161 in epoch 9, gen_loss = 0.39749826923196696, disc_loss = 0.08926511388616981
Trained batch 162 in epoch 9, gen_loss = 0.3977120287396425, disc_loss = 0.08928511285457326
Trained batch 163 in epoch 9, gen_loss = 0.3974162788107628, disc_loss = 0.09006570432357854
Trained batch 164 in epoch 9, gen_loss = 0.3983330583030527, disc_loss = 0.09036079038386093
Trained batch 165 in epoch 9, gen_loss = 0.39825872313904476, disc_loss = 0.09003572635554585
Trained batch 166 in epoch 9, gen_loss = 0.39791850014004165, disc_loss = 0.09084584053695023
Trained batch 167 in epoch 9, gen_loss = 0.398286984523847, disc_loss = 0.09151981507671908
Trained batch 168 in epoch 9, gen_loss = 0.39819186969974335, disc_loss = 0.09106110684441392
Trained batch 169 in epoch 9, gen_loss = 0.39787363541476867, disc_loss = 0.0908651026951916
Trained batch 170 in epoch 9, gen_loss = 0.3976394353728545, disc_loss = 0.09038025516559157
Trained batch 171 in epoch 9, gen_loss = 0.39833505876189057, disc_loss = 0.08991428092122078
Trained batch 172 in epoch 9, gen_loss = 0.3985081150524878, disc_loss = 0.08956821715039325
Trained batch 173 in epoch 9, gen_loss = 0.398269213907335, disc_loss = 0.08927090555943291
Trained batch 174 in epoch 9, gen_loss = 0.39858795617307935, disc_loss = 0.0889798111149243
Trained batch 175 in epoch 9, gen_loss = 0.3985246586698023, disc_loss = 0.08870294980112124
Trained batch 176 in epoch 9, gen_loss = 0.3984563533364043, disc_loss = 0.08846064168686248
Trained batch 177 in epoch 9, gen_loss = 0.39873906325423314, disc_loss = 0.08802317120030187
Trained batch 178 in epoch 9, gen_loss = 0.39867085692935816, disc_loss = 0.08773307468450768
Trained batch 179 in epoch 9, gen_loss = 0.39853012735644977, disc_loss = 0.08767372584487829
Trained batch 180 in epoch 9, gen_loss = 0.39881674336135714, disc_loss = 0.08744866342813765
Trained batch 181 in epoch 9, gen_loss = 0.39934552149785746, disc_loss = 0.08753706895040123
Trained batch 182 in epoch 9, gen_loss = 0.3996061574403054, disc_loss = 0.087345870094669
Trained batch 183 in epoch 9, gen_loss = 0.39976018302790495, disc_loss = 0.08690420546285484
Trained batch 184 in epoch 9, gen_loss = 0.3999944647421708, disc_loss = 0.08647037415286979
Trained batch 185 in epoch 9, gen_loss = 0.4002345333336502, disc_loss = 0.0863112643741632
Trained batch 186 in epoch 9, gen_loss = 0.4000718388806052, disc_loss = 0.0879255150629078
Trained batch 187 in epoch 9, gen_loss = 0.4006540413074037, disc_loss = 0.08898008391855562
Trained batch 188 in epoch 9, gen_loss = 0.4006123575110915, disc_loss = 0.08858718487025095
Trained batch 189 in epoch 9, gen_loss = 0.40049385483327665, disc_loss = 0.08837984051849497
Trained batch 190 in epoch 9, gen_loss = 0.40053846893822337, disc_loss = 0.08814782288939697
Trained batch 191 in epoch 9, gen_loss = 0.4007920029107481, disc_loss = 0.08820791238395032
Trained batch 192 in epoch 9, gen_loss = 0.40055782120153693, disc_loss = 0.08916794765895049
Trained batch 193 in epoch 9, gen_loss = 0.40105222603402185, disc_loss = 0.08917680619399726
Trained batch 194 in epoch 9, gen_loss = 0.401092037711388, disc_loss = 0.08892567125746073
Trained batch 195 in epoch 9, gen_loss = 0.40090400885258404, disc_loss = 0.08868975935940993
Trained batch 196 in epoch 9, gen_loss = 0.40093017010216786, disc_loss = 0.08860546575982105
Trained batch 197 in epoch 9, gen_loss = 0.4011843202240539, disc_loss = 0.08932307835273219
Trained batch 198 in epoch 9, gen_loss = 0.4014166287291589, disc_loss = 0.08905548074905148
Trained batch 199 in epoch 9, gen_loss = 0.4012412893027067, disc_loss = 0.08869744159746915
Trained batch 200 in epoch 9, gen_loss = 0.40108617732477425, disc_loss = 0.0883031032923887
Trained batch 201 in epoch 9, gen_loss = 0.40127222999782847, disc_loss = 0.08801350387569407
Trained batch 202 in epoch 9, gen_loss = 0.40131512555876386, disc_loss = 0.08770854720671482
Trained batch 203 in epoch 9, gen_loss = 0.4012283552072796, disc_loss = 0.08736989629801874
Trained batch 204 in epoch 9, gen_loss = 0.40151117000637987, disc_loss = 0.08714578483344579
Trained batch 205 in epoch 9, gen_loss = 0.4015196093801156, disc_loss = 0.0868331629565908
Trained batch 206 in epoch 9, gen_loss = 0.4015138619331922, disc_loss = 0.08654020836459841
Trained batch 207 in epoch 9, gen_loss = 0.4016262531423798, disc_loss = 0.08622489494379036
Trained batch 208 in epoch 9, gen_loss = 0.40126899219871137, disc_loss = 0.08637623044185376
Trained batch 209 in epoch 9, gen_loss = 0.4012616691844804, disc_loss = 0.0873451048863076
Trained batch 210 in epoch 9, gen_loss = 0.40102154094178527, disc_loss = 0.08703991178405511
Trained batch 211 in epoch 9, gen_loss = 0.4009013294751914, disc_loss = 0.08785016849672175
Trained batch 212 in epoch 9, gen_loss = 0.40091420752061924, disc_loss = 0.08896956044498464
Trained batch 213 in epoch 9, gen_loss = 0.40084325731079157, disc_loss = 0.08898236290073004
Trained batch 214 in epoch 9, gen_loss = 0.40094451218150384, disc_loss = 0.08872503375764502
Trained batch 215 in epoch 9, gen_loss = 0.40059414057543985, disc_loss = 0.08903658101162701
Trained batch 216 in epoch 9, gen_loss = 0.40084610082861466, disc_loss = 0.08872313847258893
Trained batch 217 in epoch 9, gen_loss = 0.40071186662540526, disc_loss = 0.08860577730068919
Trained batch 218 in epoch 9, gen_loss = 0.4005958645447204, disc_loss = 0.08832286650391474
Trained batch 219 in epoch 9, gen_loss = 0.4004421929744157, disc_loss = 0.08864819277077914
Trained batch 220 in epoch 9, gen_loss = 0.4004532196537941, disc_loss = 0.08915781548322596
Trained batch 221 in epoch 9, gen_loss = 0.40060252293541626, disc_loss = 0.08903732134012489
Trained batch 222 in epoch 9, gen_loss = 0.4004523172105909, disc_loss = 0.08919894097230895
Trained batch 223 in epoch 9, gen_loss = 0.40070531204608933, disc_loss = 0.08915311616978475
Trained batch 224 in epoch 9, gen_loss = 0.40067168666256797, disc_loss = 0.08888899990253979
Trained batch 225 in epoch 9, gen_loss = 0.40039928686038584, disc_loss = 0.08864245209348413
Trained batch 226 in epoch 9, gen_loss = 0.40039047999266486, disc_loss = 0.08873048058756122
Trained batch 227 in epoch 9, gen_loss = 0.40074979219781726, disc_loss = 0.08902839749332583
Trained batch 228 in epoch 9, gen_loss = 0.4008952680503437, disc_loss = 0.08870788193490828
Trained batch 229 in epoch 9, gen_loss = 0.4007869660206463, disc_loss = 0.08865067587922448
Trained batch 230 in epoch 9, gen_loss = 0.40086245194916087, disc_loss = 0.08864172798021015
Trained batch 231 in epoch 9, gen_loss = 0.4008692791364316, disc_loss = 0.08829427042430074
Trained batch 232 in epoch 9, gen_loss = 0.40062278924837647, disc_loss = 0.08828260692819762
Trained batch 233 in epoch 9, gen_loss = 0.40099770945106816, disc_loss = 0.08793419870571831
Trained batch 234 in epoch 9, gen_loss = 0.4010482282714641, disc_loss = 0.08783766171161798
Trained batch 235 in epoch 9, gen_loss = 0.4009208759387671, disc_loss = 0.08754970867707694
Trained batch 236 in epoch 9, gen_loss = 0.4002863140423087, disc_loss = 0.08776005362612412
Trained batch 237 in epoch 9, gen_loss = 0.4003428952658878, disc_loss = 0.08745309764112369
Trained batch 238 in epoch 9, gen_loss = 0.40050892831141977, disc_loss = 0.08777910817383348
Trained batch 239 in epoch 9, gen_loss = 0.4003332855179906, disc_loss = 0.0881942301716966
Trained batch 240 in epoch 9, gen_loss = 0.4004221691506532, disc_loss = 0.0889739686994199
Trained batch 241 in epoch 9, gen_loss = 0.40031193018205896, disc_loss = 0.08878165192917482
Trained batch 242 in epoch 9, gen_loss = 0.39999904879081394, disc_loss = 0.08852706227543546
Trained batch 243 in epoch 9, gen_loss = 0.3999354537026804, disc_loss = 0.08829496453180298
Trained batch 244 in epoch 9, gen_loss = 0.4001266675944231, disc_loss = 0.08836813502545868
Trained batch 245 in epoch 9, gen_loss = 0.40031769792965755, disc_loss = 0.0890724211363349
Trained batch 246 in epoch 9, gen_loss = 0.40032846236277203, disc_loss = 0.09033087710755677
Trained batch 247 in epoch 9, gen_loss = 0.4003892116128437, disc_loss = 0.09026451817818827
Trained batch 248 in epoch 9, gen_loss = 0.4000869240746441, disc_loss = 0.09011603841356125
Trained batch 249 in epoch 9, gen_loss = 0.39959986609220505, disc_loss = 0.09013375682011247
Trained batch 250 in epoch 9, gen_loss = 0.3993826747771753, disc_loss = 0.08982305410151106
Trained batch 251 in epoch 9, gen_loss = 0.3992282311239886, disc_loss = 0.08959737364276653
Trained batch 252 in epoch 9, gen_loss = 0.3989996896548705, disc_loss = 0.08928743136582874
Trained batch 253 in epoch 9, gen_loss = 0.3988786630156472, disc_loss = 0.08902148856216763
Trained batch 254 in epoch 9, gen_loss = 0.39876761640988145, disc_loss = 0.08881880374369668
Trained batch 255 in epoch 9, gen_loss = 0.3990065038087778, disc_loss = 0.08875733482273063
Trained batch 256 in epoch 9, gen_loss = 0.3988065345625933, disc_loss = 0.08889694209663553
Trained batch 257 in epoch 9, gen_loss = 0.39892486194076465, disc_loss = 0.08949536841016176
Trained batch 258 in epoch 9, gen_loss = 0.3988031076993721, disc_loss = 0.08930594131034084
Trained batch 259 in epoch 9, gen_loss = 0.39907239750027657, disc_loss = 0.08909103939882838
Trained batch 260 in epoch 9, gen_loss = 0.3992384943354632, disc_loss = 0.08881646937109045
Trained batch 261 in epoch 9, gen_loss = 0.3995731577049685, disc_loss = 0.08856911858444223
Trained batch 262 in epoch 9, gen_loss = 0.39989665144976555, disc_loss = 0.08838999272101053
Trained batch 263 in epoch 9, gen_loss = 0.40015885487876157, disc_loss = 0.08813506042387223
Trained batch 264 in epoch 9, gen_loss = 0.4000928060626084, disc_loss = 0.08809013205738563
Trained batch 265 in epoch 9, gen_loss = 0.4001074049593811, disc_loss = 0.08823638534719559
Trained batch 266 in epoch 9, gen_loss = 0.3996821730659249, disc_loss = 0.08836570548849383
Trained batch 267 in epoch 9, gen_loss = 0.3999529981902286, disc_loss = 0.0881136795575383
Trained batch 268 in epoch 9, gen_loss = 0.40035283460271404, disc_loss = 0.08788524030060352
Trained batch 269 in epoch 9, gen_loss = 0.4003213852092072, disc_loss = 0.08758891998203816
Trained batch 270 in epoch 9, gen_loss = 0.40018642394085213, disc_loss = 0.08734088735414387
Trained batch 271 in epoch 9, gen_loss = 0.4004927315365742, disc_loss = 0.08704719431047767
Trained batch 272 in epoch 9, gen_loss = 0.4004010301042389, disc_loss = 0.08679163571440311
Trained batch 273 in epoch 9, gen_loss = 0.40028585466372707, disc_loss = 0.08657113135873891
Trained batch 274 in epoch 9, gen_loss = 0.40024437378753314, disc_loss = 0.0866273736902936
Trained batch 275 in epoch 9, gen_loss = 0.3999493061092453, disc_loss = 0.08713669059426943
Trained batch 276 in epoch 9, gen_loss = 0.4002031864134413, disc_loss = 0.08699041363759645
Trained batch 277 in epoch 9, gen_loss = 0.4003902095363294, disc_loss = 0.08682804625220061
Trained batch 278 in epoch 9, gen_loss = 0.4002178856655688, disc_loss = 0.0866353117466961
Trained batch 279 in epoch 9, gen_loss = 0.40030907717134273, disc_loss = 0.08648345451303092
Trained batch 280 in epoch 9, gen_loss = 0.4003525886989573, disc_loss = 0.08633377743235315
Trained batch 281 in epoch 9, gen_loss = 0.4004432240382154, disc_loss = 0.0860540143260402
Trained batch 282 in epoch 9, gen_loss = 0.40062916894894185, disc_loss = 0.08582733474777149
Trained batch 283 in epoch 9, gen_loss = 0.40053572395527864, disc_loss = 0.08580362797439309
Trained batch 284 in epoch 9, gen_loss = 0.400503131224398, disc_loss = 0.08613457303951706
Trained batch 285 in epoch 9, gen_loss = 0.40007812967458806, disc_loss = 0.08634403515346609
Trained batch 286 in epoch 9, gen_loss = 0.4003581817453331, disc_loss = 0.08695634016410192
Trained batch 287 in epoch 9, gen_loss = 0.4002770270841817, disc_loss = 0.08684434307765009
Trained batch 288 in epoch 9, gen_loss = 0.3999537619855577, disc_loss = 0.08668897751473845
Trained batch 289 in epoch 9, gen_loss = 0.3998465092531566, disc_loss = 0.08679039770544603
Trained batch 290 in epoch 9, gen_loss = 0.3999276312253729, disc_loss = 0.08678218073938106
Trained batch 291 in epoch 9, gen_loss = 0.3996335062364193, disc_loss = 0.08672036046213279
Trained batch 292 in epoch 9, gen_loss = 0.3993674738923844, disc_loss = 0.08656821564577342
Trained batch 293 in epoch 9, gen_loss = 0.39948906891402747, disc_loss = 0.08648285139858926
Trained batch 294 in epoch 9, gen_loss = 0.3993158278323836, disc_loss = 0.0867952527320486
Trained batch 295 in epoch 9, gen_loss = 0.39964926519708055, disc_loss = 0.0870139511943971
Trained batch 296 in epoch 9, gen_loss = 0.3997266764692987, disc_loss = 0.08690397967568753
Trained batch 297 in epoch 9, gen_loss = 0.3997745364404365, disc_loss = 0.08693025965593605
Trained batch 298 in epoch 9, gen_loss = 0.3997064994828757, disc_loss = 0.08679721366776072
Trained batch 299 in epoch 9, gen_loss = 0.4001343209048112, disc_loss = 0.08669186821207404
Trained batch 300 in epoch 9, gen_loss = 0.4002170610764494, disc_loss = 0.08667020044874313
Trained batch 301 in epoch 9, gen_loss = 0.40034774345475316, disc_loss = 0.08648564606066177
Trained batch 302 in epoch 9, gen_loss = 0.400577251421343, disc_loss = 0.08625302171771086
Trained batch 303 in epoch 9, gen_loss = 0.4006363027484009, disc_loss = 0.0862982568490368
Trained batch 304 in epoch 9, gen_loss = 0.4009885361448663, disc_loss = 0.08702053714116088
Trained batch 305 in epoch 9, gen_loss = 0.4009765250717892, disc_loss = 0.08700084596799285
Trained batch 306 in epoch 9, gen_loss = 0.4009792956641909, disc_loss = 0.08685664550464976
Trained batch 307 in epoch 9, gen_loss = 0.4011946700319841, disc_loss = 0.0866537989455868
Trained batch 308 in epoch 9, gen_loss = 0.401111497317703, disc_loss = 0.08651000187162636
Trained batch 309 in epoch 9, gen_loss = 0.40072794878675094, disc_loss = 0.08684709954766497
Trained batch 310 in epoch 9, gen_loss = 0.40096542665621093, disc_loss = 0.08689132295069779
Trained batch 311 in epoch 9, gen_loss = 0.40115222511574244, disc_loss = 0.08682523360356498
Trained batch 312 in epoch 9, gen_loss = 0.40097845110078206, disc_loss = 0.0865965772616549
Trained batch 313 in epoch 9, gen_loss = 0.4009110405092027, disc_loss = 0.08641706861757265
Trained batch 314 in epoch 9, gen_loss = 0.4007963065590177, disc_loss = 0.08617626000491399
Trained batch 315 in epoch 9, gen_loss = 0.4006375233300879, disc_loss = 0.08597876714495352
Trained batch 316 in epoch 9, gen_loss = 0.4007111956550496, disc_loss = 0.08599682413746694
Trained batch 317 in epoch 9, gen_loss = 0.40085954912616023, disc_loss = 0.08657063228084044
Trained batch 318 in epoch 9, gen_loss = 0.4005410177487191, disc_loss = 0.08657688218341165
Trained batch 319 in epoch 9, gen_loss = 0.4005332390312105, disc_loss = 0.08639838864910417
Trained batch 320 in epoch 9, gen_loss = 0.4001109773217703, disc_loss = 0.08654494603915935
Trained batch 321 in epoch 9, gen_loss = 0.40005349904668996, disc_loss = 0.08643706799455866
Trained batch 322 in epoch 9, gen_loss = 0.400122609070211, disc_loss = 0.0870812038830467
Trained batch 323 in epoch 9, gen_loss = 0.4001288278327312, disc_loss = 0.08689859574430703
Trained batch 324 in epoch 9, gen_loss = 0.3999081418605951, disc_loss = 0.08696506056074912
Trained batch 325 in epoch 9, gen_loss = 0.40004744974930595, disc_loss = 0.08693840080997878
Trained batch 326 in epoch 9, gen_loss = 0.3999829288196126, disc_loss = 0.08675902736706471
Trained batch 327 in epoch 9, gen_loss = 0.3999036137559792, disc_loss = 0.08666911120412917
Trained batch 328 in epoch 9, gen_loss = 0.40006612123508223, disc_loss = 0.08652989142843293
Trained batch 329 in epoch 9, gen_loss = 0.40007401772520756, disc_loss = 0.08673293750846024
Trained batch 330 in epoch 9, gen_loss = 0.3999203474590065, disc_loss = 0.08720961003775322
Trained batch 331 in epoch 9, gen_loss = 0.399917492171727, disc_loss = 0.08746691328664143
Trained batch 332 in epoch 9, gen_loss = 0.3999226983334567, disc_loss = 0.08730372686957096
Trained batch 333 in epoch 9, gen_loss = 0.3995549383009979, disc_loss = 0.08710780517828322
Trained batch 334 in epoch 9, gen_loss = 0.399553693008067, disc_loss = 0.08688455852888413
Trained batch 335 in epoch 9, gen_loss = 0.3995518481713675, disc_loss = 0.08666651616139072
Trained batch 336 in epoch 9, gen_loss = 0.3994875361463083, disc_loss = 0.08645810629033901
Trained batch 337 in epoch 9, gen_loss = 0.3994381892875101, disc_loss = 0.08628936373138216
Trained batch 338 in epoch 9, gen_loss = 0.39924873060005606, disc_loss = 0.08619525287970681
Trained batch 339 in epoch 9, gen_loss = 0.3992383847780087, disc_loss = 0.08605673905900296
Trained batch 340 in epoch 9, gen_loss = 0.39926841684625297, disc_loss = 0.0860566538253313
Trained batch 341 in epoch 9, gen_loss = 0.3988871451968338, disc_loss = 0.08702933835138006
Trained batch 342 in epoch 9, gen_loss = 0.39908566197744266, disc_loss = 0.08689680099270086
Trained batch 343 in epoch 9, gen_loss = 0.39933490384976533, disc_loss = 0.08680601479745535
Trained batch 344 in epoch 9, gen_loss = 0.39915698503238567, disc_loss = 0.08677044403941735
Trained batch 345 in epoch 9, gen_loss = 0.3991141500586719, disc_loss = 0.08672419925774798
Trained batch 346 in epoch 9, gen_loss = 0.3991488684237175, disc_loss = 0.08663780973306306
Trained batch 347 in epoch 9, gen_loss = 0.39932960224733954, disc_loss = 0.08645860330019703
Trained batch 348 in epoch 9, gen_loss = 0.39933556117608415, disc_loss = 0.0863308817692592
Trained batch 349 in epoch 9, gen_loss = 0.39913260583366666, disc_loss = 0.0864674495320235
Trained batch 350 in epoch 9, gen_loss = 0.39942880051258284, disc_loss = 0.08708312508366217
Trained batch 351 in epoch 9, gen_loss = 0.3995300844227048, disc_loss = 0.08689311665313487
Trained batch 352 in epoch 9, gen_loss = 0.39938801261081913, disc_loss = 0.08673299919739999
Trained batch 353 in epoch 9, gen_loss = 0.3993425125540313, disc_loss = 0.08653347936621998
Trained batch 354 in epoch 9, gen_loss = 0.399542724204735, disc_loss = 0.08631084358162233
Trained batch 355 in epoch 9, gen_loss = 0.39966265986977, disc_loss = 0.08612827804290135
Trained batch 356 in epoch 9, gen_loss = 0.3995638458418245, disc_loss = 0.08598939165947776
Trained batch 357 in epoch 9, gen_loss = 0.3993924016642837, disc_loss = 0.08599732819731301
Trained batch 358 in epoch 9, gen_loss = 0.3996206238492286, disc_loss = 0.08602008314201386
Trained batch 359 in epoch 9, gen_loss = 0.39975245623952815, disc_loss = 0.08602533888252865
Trained batch 360 in epoch 9, gen_loss = 0.39972526763779964, disc_loss = 0.08631200602773442
Trained batch 361 in epoch 9, gen_loss = 0.39952154173541465, disc_loss = 0.08611234905357724
Trained batch 362 in epoch 9, gen_loss = 0.3994221094143949, disc_loss = 0.08650254417267261
Trained batch 363 in epoch 9, gen_loss = 0.399572119730842, disc_loss = 0.08644581664031228
Trained batch 364 in epoch 9, gen_loss = 0.3996613454737075, disc_loss = 0.08623628662899137
Trained batch 365 in epoch 9, gen_loss = 0.399485600654219, disc_loss = 0.08607230319824742
Trained batch 366 in epoch 9, gen_loss = 0.3993656258898145, disc_loss = 0.08590252280910309
Trained batch 367 in epoch 9, gen_loss = 0.3993317014740213, disc_loss = 0.08584582084491242
Trained batch 368 in epoch 9, gen_loss = 0.39933802340896474, disc_loss = 0.08570677812935577
Trained batch 369 in epoch 9, gen_loss = 0.3993496431289492, disc_loss = 0.08564136545425532
Trained batch 370 in epoch 9, gen_loss = 0.3993576260991495, disc_loss = 0.08563025217036392
Trained batch 371 in epoch 9, gen_loss = 0.3993204169135581, disc_loss = 0.08545665689919305
Trained batch 372 in epoch 9, gen_loss = 0.3993064988474424, disc_loss = 0.08562071428287166
Trained batch 373 in epoch 9, gen_loss = 0.39927801270695296, disc_loss = 0.08628379815148518
Trained batch 374 in epoch 9, gen_loss = 0.39926046391328174, disc_loss = 0.0863862825098137
Trained batch 375 in epoch 9, gen_loss = 0.39921344567011013, disc_loss = 0.08618273890819995
Trained batch 376 in epoch 9, gen_loss = 0.399161280426802, disc_loss = 0.08598879915575648
Trained batch 377 in epoch 9, gen_loss = 0.3988232259791364, disc_loss = 0.0864335416320948
Trained batch 378 in epoch 9, gen_loss = 0.39902673850430664, disc_loss = 0.08705537397743726
Trained batch 379 in epoch 9, gen_loss = 0.3990145609959176, disc_loss = 0.0869195256590549
Trained batch 380 in epoch 9, gen_loss = 0.3990686952363788, disc_loss = 0.08675307334764931
Trained batch 381 in epoch 9, gen_loss = 0.3989691504555223, disc_loss = 0.08671617566568884
Trained batch 382 in epoch 9, gen_loss = 0.3989371031367125, disc_loss = 0.08656768043775977
Trained batch 383 in epoch 9, gen_loss = 0.39903344528283924, disc_loss = 0.0866697821196188
Trained batch 384 in epoch 9, gen_loss = 0.39894815122152305, disc_loss = 0.08683671984313564
Trained batch 385 in epoch 9, gen_loss = 0.39893183038796787, disc_loss = 0.08681464824618028
Trained batch 386 in epoch 9, gen_loss = 0.39881476902376467, disc_loss = 0.08711120813666273
Trained batch 387 in epoch 9, gen_loss = 0.39867761834841414, disc_loss = 0.08722290623400207
Trained batch 388 in epoch 9, gen_loss = 0.39916947579782236, disc_loss = 0.0882969076893649
Trained batch 389 in epoch 9, gen_loss = 0.3991011704771947, disc_loss = 0.08830757431614285
Trained batch 390 in epoch 9, gen_loss = 0.3991823153346396, disc_loss = 0.08813533809183695
Trained batch 391 in epoch 9, gen_loss = 0.3990100035633968, disc_loss = 0.08817078778639018
Trained batch 392 in epoch 9, gen_loss = 0.3988562725654995, disc_loss = 0.08801233369985041
Trained batch 393 in epoch 9, gen_loss = 0.398679376291442, disc_loss = 0.08789944105668154
Trained batch 394 in epoch 9, gen_loss = 0.3987303470131717, disc_loss = 0.08773197951031071
Trained batch 395 in epoch 9, gen_loss = 0.398809258195788, disc_loss = 0.08755553194975499
Trained batch 396 in epoch 9, gen_loss = 0.39879512099985515, disc_loss = 0.08758070471084275
Trained batch 397 in epoch 9, gen_loss = 0.39884357779619084, disc_loss = 0.08786454672419733
Trained batch 398 in epoch 9, gen_loss = 0.3988542182926546, disc_loss = 0.08775851476055227
Trained batch 399 in epoch 9, gen_loss = 0.3986835986748338, disc_loss = 0.08824588792514987
Trained batch 400 in epoch 9, gen_loss = 0.39897998078654234, disc_loss = 0.08894575090075557
Trained batch 401 in epoch 9, gen_loss = 0.3989403992520636, disc_loss = 0.08911902377896233
Trained batch 402 in epoch 9, gen_loss = 0.39852273216466455, disc_loss = 0.09026711718953462
Trained batch 403 in epoch 9, gen_loss = 0.39851360801275415, disc_loss = 0.09036881253607387
Trained batch 404 in epoch 9, gen_loss = 0.3986469399413945, disc_loss = 0.0903814238726081
Trained batch 405 in epoch 9, gen_loss = 0.39858491817865466, disc_loss = 0.09029900533229737
Trained batch 406 in epoch 9, gen_loss = 0.39840681543367795, disc_loss = 0.09017875716570738
Trained batch 407 in epoch 9, gen_loss = 0.3983264354002826, disc_loss = 0.09012308169964373
Trained batch 408 in epoch 9, gen_loss = 0.39817361322329503, disc_loss = 0.08999629130286409
Trained batch 409 in epoch 9, gen_loss = 0.3980473006280457, disc_loss = 0.09009164918055076
Trained batch 410 in epoch 9, gen_loss = 0.3979293584751097, disc_loss = 0.09012056338893128
Trained batch 411 in epoch 9, gen_loss = 0.39808584196330277, disc_loss = 0.09005087955054619
Trained batch 412 in epoch 9, gen_loss = 0.39787740060116994, disc_loss = 0.0899554554014478
Trained batch 413 in epoch 9, gen_loss = 0.39777836797461996, disc_loss = 0.08984919601560971
Trained batch 414 in epoch 9, gen_loss = 0.39757737492222384, disc_loss = 0.08973699117932155
Trained batch 415 in epoch 9, gen_loss = 0.3976584642480772, disc_loss = 0.08967096306710468
Trained batch 416 in epoch 9, gen_loss = 0.39772220563402566, disc_loss = 0.08963933714042358
Trained batch 417 in epoch 9, gen_loss = 0.3976700018253623, disc_loss = 0.08946163151702848
Trained batch 418 in epoch 9, gen_loss = 0.3978459188150051, disc_loss = 0.08938232850759048
Trained batch 419 in epoch 9, gen_loss = 0.39766418965799466, disc_loss = 0.09001786989669892
Trained batch 420 in epoch 9, gen_loss = 0.3977624782119964, disc_loss = 0.08990853628134819
Trained batch 421 in epoch 9, gen_loss = 0.39776192481907624, disc_loss = 0.09000637194790581
Trained batch 422 in epoch 9, gen_loss = 0.3976377524594043, disc_loss = 0.09002938852194106
Trained batch 423 in epoch 9, gen_loss = 0.3977208938449621, disc_loss = 0.08986356315523703
Trained batch 424 in epoch 9, gen_loss = 0.397759240900769, disc_loss = 0.08995733564938692
Trained batch 425 in epoch 9, gen_loss = 0.39759209524717687, disc_loss = 0.09059178677579921
Trained batch 426 in epoch 9, gen_loss = 0.3975445136462777, disc_loss = 0.09045402523876109
Trained batch 427 in epoch 9, gen_loss = 0.3976119277981397, disc_loss = 0.09038681383397013
Trained batch 428 in epoch 9, gen_loss = 0.39751754082860924, disc_loss = 0.0903351019279888
Trained batch 429 in epoch 9, gen_loss = 0.3976156951036564, disc_loss = 0.09019917627081794
Trained batch 430 in epoch 9, gen_loss = 0.3976082064366949, disc_loss = 0.09006276821475606
Trained batch 431 in epoch 9, gen_loss = 0.39759715850016586, disc_loss = 0.09005576761598975
Trained batch 432 in epoch 9, gen_loss = 0.3978814760408005, disc_loss = 0.08995967115411066
Trained batch 433 in epoch 9, gen_loss = 0.3979601073443615, disc_loss = 0.0898923274131775
Trained batch 434 in epoch 9, gen_loss = 0.39792331022092664, disc_loss = 0.08986550302876309
Trained batch 435 in epoch 9, gen_loss = 0.39778538694212195, disc_loss = 0.08984378512218219
Trained batch 436 in epoch 9, gen_loss = 0.3977385445303993, disc_loss = 0.09008236112311756
Trained batch 437 in epoch 9, gen_loss = 0.3978747056295338, disc_loss = 0.09070818148846801
Trained batch 438 in epoch 9, gen_loss = 0.3977419368430531, disc_loss = 0.09067226184854509
Trained batch 439 in epoch 9, gen_loss = 0.39780033383179797, disc_loss = 0.09053024562943557
Trained batch 440 in epoch 9, gen_loss = 0.3976520505689439, disc_loss = 0.09051667413697526
Trained batch 441 in epoch 9, gen_loss = 0.39754728942570106, disc_loss = 0.09042765116382272
Trained batch 442 in epoch 9, gen_loss = 0.39760234787151993, disc_loss = 0.09035346110963155
Trained batch 443 in epoch 9, gen_loss = 0.39757731566960747, disc_loss = 0.09024437184357462
Trained batch 444 in epoch 9, gen_loss = 0.39755279291211887, disc_loss = 0.09028052531622266
Trained batch 445 in epoch 9, gen_loss = 0.39768038573152814, disc_loss = 0.09089497117338192
Trained batch 446 in epoch 9, gen_loss = 0.39753701606186176, disc_loss = 0.09074971917912497
Trained batch 447 in epoch 9, gen_loss = 0.39756863521012875, disc_loss = 0.09074295120600644
Trained batch 448 in epoch 9, gen_loss = 0.39765479838795015, disc_loss = 0.09073193789146558
Trained batch 449 in epoch 9, gen_loss = 0.39759602828158275, disc_loss = 0.09060330988321867
Trained batch 450 in epoch 9, gen_loss = 0.3975639114953462, disc_loss = 0.09045841818378036
Trained batch 451 in epoch 9, gen_loss = 0.39742693459961265, disc_loss = 0.09034419326066344
Trained batch 452 in epoch 9, gen_loss = 0.3975394492841451, disc_loss = 0.09024414762332378
Trained batch 453 in epoch 9, gen_loss = 0.3975436782981331, disc_loss = 0.09007179449796512
Trained batch 454 in epoch 9, gen_loss = 0.3975375908744204, disc_loss = 0.09000807597639633
Trained batch 455 in epoch 9, gen_loss = 0.39763880524326833, disc_loss = 0.09004909084321473
Trained batch 456 in epoch 9, gen_loss = 0.39759479065301384, disc_loss = 0.09002454921142636
Trained batch 457 in epoch 9, gen_loss = 0.3976759763849354, disc_loss = 0.0899138558141513
Trained batch 458 in epoch 9, gen_loss = 0.39849407224224026, disc_loss = 0.09044975017893386
Testing Epoch 9
Training Epoch 10
Trained batch 0 in epoch 10, gen_loss = 0.36553528904914856, disc_loss = 0.08552701026201248
Trained batch 1 in epoch 10, gen_loss = 0.39938415586948395, disc_loss = 0.06776926480233669
Trained batch 2 in epoch 10, gen_loss = 0.401872843503952, disc_loss = 0.13813271497686705
Trained batch 3 in epoch 10, gen_loss = 0.4009755849838257, disc_loss = 0.13821888249367476
Trained batch 4 in epoch 10, gen_loss = 0.40455934405326843, disc_loss = 0.11959039196372032
Trained batch 5 in epoch 10, gen_loss = 0.4049692104260127, disc_loss = 0.10322395401696365
Trained batch 6 in epoch 10, gen_loss = 0.4052916467189789, disc_loss = 0.09021956766290325
Trained batch 7 in epoch 10, gen_loss = 0.4065464697778225, disc_loss = 0.08654683805070817
Trained batch 8 in epoch 10, gen_loss = 0.4099855091836717, disc_loss = 0.0972040541883972
Trained batch 9 in epoch 10, gen_loss = 0.4045298308134079, disc_loss = 0.10046251248568297
Trained batch 10 in epoch 10, gen_loss = 0.40778130292892456, disc_loss = 0.09574813175607812
Trained batch 11 in epoch 10, gen_loss = 0.4109629765152931, disc_loss = 0.08963380878170331
Trained batch 12 in epoch 10, gen_loss = 0.4088353652220506, disc_loss = 0.0868597523524211
Trained batch 13 in epoch 10, gen_loss = 0.4042334918464933, disc_loss = 0.0841149634548596
Trained batch 14 in epoch 10, gen_loss = 0.39759142994880675, disc_loss = 0.09864628612995148
Trained batch 15 in epoch 10, gen_loss = 0.3997692931443453, disc_loss = 0.11039799358695745
Trained batch 16 in epoch 10, gen_loss = 0.3971603951033424, disc_loss = 0.11591101569287918
Trained batch 17 in epoch 10, gen_loss = 0.39239929450882804, disc_loss = 0.12444999648465051
Trained batch 18 in epoch 10, gen_loss = 0.39413684920260783, disc_loss = 0.11856311143032815
Trained batch 19 in epoch 10, gen_loss = 0.398349741101265, disc_loss = 0.1133051855955273
Trained batch 20 in epoch 10, gen_loss = 0.4015170875049773, disc_loss = 0.10818521155133135
Trained batch 21 in epoch 10, gen_loss = 0.40221361951394513, disc_loss = 0.10365993990986185
Trained batch 22 in epoch 10, gen_loss = 0.4037986799426701, disc_loss = 0.09961623617488405
Trained batch 23 in epoch 10, gen_loss = 0.4024095671872298, disc_loss = 0.09636269765906036
Trained batch 24 in epoch 10, gen_loss = 0.4031050908565521, disc_loss = 0.09455990619957447
Trained batch 25 in epoch 10, gen_loss = 0.4013164857259163, disc_loss = 0.09251877658355695
Trained batch 26 in epoch 10, gen_loss = 0.39959957754170455, disc_loss = 0.09060977019921497
Trained batch 27 in epoch 10, gen_loss = 0.39583464924778256, disc_loss = 0.09015850676223636
Trained batch 28 in epoch 10, gen_loss = 0.3975324887653877, disc_loss = 0.09182634390890598
Trained batch 29 in epoch 10, gen_loss = 0.39572861790657043, disc_loss = 0.08900510560100278
Trained batch 30 in epoch 10, gen_loss = 0.3938346024482481, disc_loss = 0.08979881401624411
Trained batch 31 in epoch 10, gen_loss = 0.3955120025202632, disc_loss = 0.08986795708187856
Trained batch 32 in epoch 10, gen_loss = 0.39465728311827686, disc_loss = 0.08773887973052985
Trained batch 33 in epoch 10, gen_loss = 0.3922986765118206, disc_loss = 0.08856897562851801
Trained batch 34 in epoch 10, gen_loss = 0.39355179071426394, disc_loss = 0.0888742193845766
Trained batch 35 in epoch 10, gen_loss = 0.394859228697088, disc_loss = 0.08756858444151779
Trained batch 36 in epoch 10, gen_loss = 0.3927469366305583, disc_loss = 0.08579193038010113
Trained batch 37 in epoch 10, gen_loss = 0.39149411336371776, disc_loss = 0.08874511387885402
Trained batch 38 in epoch 10, gen_loss = 0.3941318186429831, disc_loss = 0.09657297362215243
Trained batch 39 in epoch 10, gen_loss = 0.3964861765503883, disc_loss = 0.09874393625650554
Trained batch 40 in epoch 10, gen_loss = 0.3947385178833473, disc_loss = 0.0988890676100443
Trained batch 41 in epoch 10, gen_loss = 0.39354613707179115, disc_loss = 0.09765604406683928
Trained batch 42 in epoch 10, gen_loss = 0.394187179415725, disc_loss = 0.09631682094186544
Trained batch 43 in epoch 10, gen_loss = 0.3951313820752231, disc_loss = 0.09835463315671818
Trained batch 44 in epoch 10, gen_loss = 0.3938757141431173, disc_loss = 0.09759670092413823
Trained batch 45 in epoch 10, gen_loss = 0.39371747620727704, disc_loss = 0.09671192634445817
Trained batch 46 in epoch 10, gen_loss = 0.39434307940462804, disc_loss = 0.09564934672906678
Trained batch 47 in epoch 10, gen_loss = 0.3945557661354542, disc_loss = 0.09401011410712574
Trained batch 48 in epoch 10, gen_loss = 0.39430207074904927, disc_loss = 0.09366606455296278
Trained batch 49 in epoch 10, gen_loss = 0.39696233451366425, disc_loss = 0.09313760017976165
Trained batch 50 in epoch 10, gen_loss = 0.3980690638224284, disc_loss = 0.09223116004803017
Trained batch 51 in epoch 10, gen_loss = 0.395796822813841, disc_loss = 0.09071175150501613
Trained batch 52 in epoch 10, gen_loss = 0.3960253028374798, disc_loss = 0.09879931833876192
Trained batch 53 in epoch 10, gen_loss = 0.3965257720814811, disc_loss = 0.09744258057671012
Trained batch 54 in epoch 10, gen_loss = 0.39873182827776127, disc_loss = 0.09678557567637075
Trained batch 55 in epoch 10, gen_loss = 0.39805752092174124, disc_loss = 0.0963499596442229
Trained batch 56 in epoch 10, gen_loss = 0.398101423393216, disc_loss = 0.09658159013314728
Trained batch 57 in epoch 10, gen_loss = 0.3973546577938672, disc_loss = 0.09525448127232235
Trained batch 58 in epoch 10, gen_loss = 0.39799171585147664, disc_loss = 0.0939285160215982
Trained batch 59 in epoch 10, gen_loss = 0.3986344282825788, disc_loss = 0.09295431255983809
Trained batch 60 in epoch 10, gen_loss = 0.39867330379173405, disc_loss = 0.09261242524705461
Trained batch 61 in epoch 10, gen_loss = 0.39922657224439806, disc_loss = 0.09158566784894755
Trained batch 62 in epoch 10, gen_loss = 0.3996174609850323, disc_loss = 0.09121614728596002
Trained batch 63 in epoch 10, gen_loss = 0.39898199029266834, disc_loss = 0.09719448709802236
Trained batch 64 in epoch 10, gen_loss = 0.4000077976630284, disc_loss = 0.09663332137637413
Trained batch 65 in epoch 10, gen_loss = 0.4009155184030533, disc_loss = 0.09659824891467438
Trained batch 66 in epoch 10, gen_loss = 0.39999874937000557, disc_loss = 0.09717115769579784
Trained batch 67 in epoch 10, gen_loss = 0.40012550748446407, disc_loss = 0.09637342123588656
Trained batch 68 in epoch 10, gen_loss = 0.40144038718679675, disc_loss = 0.09551136037739723
Trained batch 69 in epoch 10, gen_loss = 0.40238746447222573, disc_loss = 0.0955677740674998
Trained batch 70 in epoch 10, gen_loss = 0.4028149738278187, disc_loss = 0.09642327245010036
Trained batch 71 in epoch 10, gen_loss = 0.4024062284992801, disc_loss = 0.09734682732313457
Trained batch 72 in epoch 10, gen_loss = 0.40310109723104187, disc_loss = 0.09626389778385015
Trained batch 73 in epoch 10, gen_loss = 0.40307548440791463, disc_loss = 0.09601332613493542
Trained batch 74 in epoch 10, gen_loss = 0.4018501909573873, disc_loss = 0.09567955875148376
Trained batch 75 in epoch 10, gen_loss = 0.4020315651830874, disc_loss = 0.09469624607529688
Trained batch 76 in epoch 10, gen_loss = 0.402276632847724, disc_loss = 0.09371316901033187
Trained batch 77 in epoch 10, gen_loss = 0.4021266645345932, disc_loss = 0.09281708891145311
Trained batch 78 in epoch 10, gen_loss = 0.40254996169971513, disc_loss = 0.09330011337193884
Trained batch 79 in epoch 10, gen_loss = 0.4027941633015871, disc_loss = 0.09563698599813505
Trained batch 80 in epoch 10, gen_loss = 0.4036403986406915, disc_loss = 0.09755970094996838
Trained batch 81 in epoch 10, gen_loss = 0.40314418877043373, disc_loss = 0.09748871577903628
Trained batch 82 in epoch 10, gen_loss = 0.40281522633081457, disc_loss = 0.09667837246130388
Trained batch 83 in epoch 10, gen_loss = 0.4032849644621213, disc_loss = 0.09598071002844899
Trained batch 84 in epoch 10, gen_loss = 0.40289628786199233, disc_loss = 0.09567622532520224
Trained batch 85 in epoch 10, gen_loss = 0.4026400242433992, disc_loss = 0.0950504659978283
Trained batch 86 in epoch 10, gen_loss = 0.40270224145089073, disc_loss = 0.09623326882505896
Trained batch 87 in epoch 10, gen_loss = 0.4020685604350133, disc_loss = 0.09624269290361553
Trained batch 88 in epoch 10, gen_loss = 0.4022144779060664, disc_loss = 0.09541009398951625
Trained batch 89 in epoch 10, gen_loss = 0.4016527156035105, disc_loss = 0.09583306410867307
Trained batch 90 in epoch 10, gen_loss = 0.4013477256009867, disc_loss = 0.09506414330226708
Trained batch 91 in epoch 10, gen_loss = 0.40070594717626984, disc_loss = 0.09604681500881586
Trained batch 92 in epoch 10, gen_loss = 0.40073482708264424, disc_loss = 0.09761354125915997
Trained batch 93 in epoch 10, gen_loss = 0.3999612106287733, disc_loss = 0.09673937903519006
Trained batch 94 in epoch 10, gen_loss = 0.39937466571205543, disc_loss = 0.09613401264344391
Trained batch 95 in epoch 10, gen_loss = 0.39978219910214347, disc_loss = 0.09520070552631903
Trained batch 96 in epoch 10, gen_loss = 0.40040057621051356, disc_loss = 0.09442871402872284
Trained batch 97 in epoch 10, gen_loss = 0.4000903720758399, disc_loss = 0.09453420881752153
Trained batch 98 in epoch 10, gen_loss = 0.4006795780827301, disc_loss = 0.09482716401154646
Trained batch 99 in epoch 10, gen_loss = 0.40055549919605254, disc_loss = 0.0953625422809273
Trained batch 100 in epoch 10, gen_loss = 0.40126277786670345, disc_loss = 0.09522089163892634
Trained batch 101 in epoch 10, gen_loss = 0.4018080085515976, disc_loss = 0.0945159344130433
Trained batch 102 in epoch 10, gen_loss = 0.4012951888505695, disc_loss = 0.09409364708021138
Trained batch 103 in epoch 10, gen_loss = 0.4006057143784486, disc_loss = 0.09375774793219395
Trained batch 104 in epoch 10, gen_loss = 0.39989143780299596, disc_loss = 0.09405107786435457
Trained batch 105 in epoch 10, gen_loss = 0.40045598430453605, disc_loss = 0.0941668285390819
Trained batch 106 in epoch 10, gen_loss = 0.399786232787872, disc_loss = 0.09339864159472913
Trained batch 107 in epoch 10, gen_loss = 0.3995789695117209, disc_loss = 0.0933999436200355
Trained batch 108 in epoch 10, gen_loss = 0.3997909284512931, disc_loss = 0.09391492048979079
Trained batch 109 in epoch 10, gen_loss = 0.3995307077061046, disc_loss = 0.09319257721812887
Trained batch 110 in epoch 10, gen_loss = 0.3999994633434055, disc_loss = 0.09550042959718823
Trained batch 111 in epoch 10, gen_loss = 0.40040129316704615, disc_loss = 0.09523343566771862
Trained batch 112 in epoch 10, gen_loss = 0.40109921978638235, disc_loss = 0.09585608521361003
Trained batch 113 in epoch 10, gen_loss = 0.40097390507396896, disc_loss = 0.09540707996245801
Trained batch 114 in epoch 10, gen_loss = 0.39987731601880944, disc_loss = 0.09716525517566049
Trained batch 115 in epoch 10, gen_loss = 0.3997143414513818, disc_loss = 0.09669049215053432
Trained batch 116 in epoch 10, gen_loss = 0.39972281557881933, disc_loss = 0.09652965702912492
Trained batch 117 in epoch 10, gen_loss = 0.39960654155682707, disc_loss = 0.09594603349312635
Trained batch 118 in epoch 10, gen_loss = 0.3990651639569707, disc_loss = 0.09620858577839217
Trained batch 119 in epoch 10, gen_loss = 0.3988782758514086, disc_loss = 0.09563286732106159
Trained batch 120 in epoch 10, gen_loss = 0.3989754649233227, disc_loss = 0.09514764166044548
Trained batch 121 in epoch 10, gen_loss = 0.39860354290633904, disc_loss = 0.09596785822822178
Trained batch 122 in epoch 10, gen_loss = 0.39911618538019134, disc_loss = 0.0971862335076056
Trained batch 123 in epoch 10, gen_loss = 0.3986859569145787, disc_loss = 0.09707518431898807
Trained batch 124 in epoch 10, gen_loss = 0.39841911506652833, disc_loss = 0.0967226494178176
Trained batch 125 in epoch 10, gen_loss = 0.39847341936732095, disc_loss = 0.09731462121098525
Trained batch 126 in epoch 10, gen_loss = 0.39887946515571415, disc_loss = 0.09688430404891883
Trained batch 127 in epoch 10, gen_loss = 0.3987284379545599, disc_loss = 0.09645399863802595
Trained batch 128 in epoch 10, gen_loss = 0.39874386718106825, disc_loss = 0.09593064163977555
Trained batch 129 in epoch 10, gen_loss = 0.39850963675058804, disc_loss = 0.09534956221826947
Trained batch 130 in epoch 10, gen_loss = 0.3979923370230289, disc_loss = 0.09530283015164483
Trained batch 131 in epoch 10, gen_loss = 0.39870056464816583, disc_loss = 0.09501746990435729
Trained batch 132 in epoch 10, gen_loss = 0.3986192524881291, disc_loss = 0.09437405193378602
Trained batch 133 in epoch 10, gen_loss = 0.39865643987015115, disc_loss = 0.09381980330808394
Trained batch 134 in epoch 10, gen_loss = 0.3986039327250587, disc_loss = 0.09341068398897294
Trained batch 135 in epoch 10, gen_loss = 0.39884039036491337, disc_loss = 0.09282651579911437
Trained batch 136 in epoch 10, gen_loss = 0.39846456485943205, disc_loss = 0.09236086187816232
Trained batch 137 in epoch 10, gen_loss = 0.39882800803668256, disc_loss = 0.09184924335610392
Trained batch 138 in epoch 10, gen_loss = 0.3989637153182956, disc_loss = 0.09124314671100901
Trained batch 139 in epoch 10, gen_loss = 0.39848809369972776, disc_loss = 0.09076685797689217
Trained batch 140 in epoch 10, gen_loss = 0.39856952640181736, disc_loss = 0.09040779127666713
Trained batch 141 in epoch 10, gen_loss = 0.39870825766677587, disc_loss = 0.09040850069059032
Trained batch 142 in epoch 10, gen_loss = 0.39946499967074894, disc_loss = 0.09398477981713685
Trained batch 143 in epoch 10, gen_loss = 0.3993602010111014, disc_loss = 0.09496469602971855
Trained batch 144 in epoch 10, gen_loss = 0.3994053300084739, disc_loss = 0.09486180198346747
Trained batch 145 in epoch 10, gen_loss = 0.39915989604714797, disc_loss = 0.09462304570240108
Trained batch 146 in epoch 10, gen_loss = 0.3990996550946009, disc_loss = 0.09418274199932206
Trained batch 147 in epoch 10, gen_loss = 0.3984337519552257, disc_loss = 0.09391567520042127
Trained batch 148 in epoch 10, gen_loss = 0.3986393255275368, disc_loss = 0.09334681101218366
Trained batch 149 in epoch 10, gen_loss = 0.39882707635561626, disc_loss = 0.09277948963145415
Trained batch 150 in epoch 10, gen_loss = 0.3992692549891819, disc_loss = 0.09224387215117351
Trained batch 151 in epoch 10, gen_loss = 0.3994482349800436, disc_loss = 0.09179254893311545
Trained batch 152 in epoch 10, gen_loss = 0.3993469932500054, disc_loss = 0.09141489785481123
Trained batch 153 in epoch 10, gen_loss = 0.3993135386860216, disc_loss = 0.09096709941211459
Trained batch 154 in epoch 10, gen_loss = 0.39916062816496817, disc_loss = 0.09065122750978316
Trained batch 155 in epoch 10, gen_loss = 0.399642003652377, disc_loss = 0.0906457361072684
Trained batch 156 in epoch 10, gen_loss = 0.39968614365644517, disc_loss = 0.09030144495569217
Trained batch 157 in epoch 10, gen_loss = 0.3994472977481311, disc_loss = 0.09167480053780955
Trained batch 158 in epoch 10, gen_loss = 0.39974887715945456, disc_loss = 0.09191536603483765
Trained batch 159 in epoch 10, gen_loss = 0.3997412556782365, disc_loss = 0.09138048551103566
Trained batch 160 in epoch 10, gen_loss = 0.3999614993237561, disc_loss = 0.09095437748658454
Trained batch 161 in epoch 10, gen_loss = 0.3995191112712578, disc_loss = 0.09092838963620181
Trained batch 162 in epoch 10, gen_loss = 0.39940693590538634, disc_loss = 0.09134599057089057
Trained batch 163 in epoch 10, gen_loss = 0.3992711142068956, disc_loss = 0.09090133009353517
Trained batch 164 in epoch 10, gen_loss = 0.3987576927199508, disc_loss = 0.09102752111908613
Trained batch 165 in epoch 10, gen_loss = 0.3989174154149481, disc_loss = 0.09095329219329519
Trained batch 166 in epoch 10, gen_loss = 0.39952136531561433, disc_loss = 0.0908184015180938
Trained batch 167 in epoch 10, gen_loss = 0.3989563240181832, disc_loss = 0.09228228859969281
Trained batch 168 in epoch 10, gen_loss = 0.39950955337321264, disc_loss = 0.09193878535170262
Trained batch 169 in epoch 10, gen_loss = 0.39991172832601213, disc_loss = 0.0925872243310818
Trained batch 170 in epoch 10, gen_loss = 0.39977055735755385, disc_loss = 0.09232450353134183
Trained batch 171 in epoch 10, gen_loss = 0.39925653331501537, disc_loss = 0.0919901149937623
Trained batch 172 in epoch 10, gen_loss = 0.39946663724204706, disc_loss = 0.09163722928042788
Trained batch 173 in epoch 10, gen_loss = 0.39946717794599207, disc_loss = 0.09184221801583538
Trained batch 174 in epoch 10, gen_loss = 0.398738420350211, disc_loss = 0.09186323559976049
Trained batch 175 in epoch 10, gen_loss = 0.39855702983384783, disc_loss = 0.09200180883106607
Trained batch 176 in epoch 10, gen_loss = 0.39893618899550143, disc_loss = 0.09294597057646699
Trained batch 177 in epoch 10, gen_loss = 0.39892786456627793, disc_loss = 0.09253274500003775
Trained batch 178 in epoch 10, gen_loss = 0.39898492004618297, disc_loss = 0.09299880667074516
Trained batch 179 in epoch 10, gen_loss = 0.3989598093761338, disc_loss = 0.0926731769538795
Trained batch 180 in epoch 10, gen_loss = 0.3990721177330333, disc_loss = 0.09226883051772886
Trained batch 181 in epoch 10, gen_loss = 0.3985046857333445, disc_loss = 0.09243132445480225
Trained batch 182 in epoch 10, gen_loss = 0.39771852141521014, disc_loss = 0.09300879044254702
Trained batch 183 in epoch 10, gen_loss = 0.39755265285139496, disc_loss = 0.09310257715507127
Trained batch 184 in epoch 10, gen_loss = 0.39731255544198524, disc_loss = 0.09292077153568735
Trained batch 185 in epoch 10, gen_loss = 0.39721882134996433, disc_loss = 0.09295931936401913
Trained batch 186 in epoch 10, gen_loss = 0.39688473876147345, disc_loss = 0.09305013028187628
Trained batch 187 in epoch 10, gen_loss = 0.39664661472148083, disc_loss = 0.09326650825715525
Trained batch 188 in epoch 10, gen_loss = 0.39664715418109187, disc_loss = 0.0931899528383775
Trained batch 189 in epoch 10, gen_loss = 0.39690210772188084, disc_loss = 0.09287496155471002
Trained batch 190 in epoch 10, gen_loss = 0.3967231150072907, disc_loss = 0.09269033201984789
Trained batch 191 in epoch 10, gen_loss = 0.39714924556513626, disc_loss = 0.09297303833348754
Trained batch 192 in epoch 10, gen_loss = 0.3961186648341658, disc_loss = 0.09333461416171082
Trained batch 193 in epoch 10, gen_loss = 0.396080311887043, disc_loss = 0.09308703216128819
Trained batch 194 in epoch 10, gen_loss = 0.3961516042550405, disc_loss = 0.0939870279879333
Trained batch 195 in epoch 10, gen_loss = 0.39607202140044195, disc_loss = 0.09437428159420663
Trained batch 196 in epoch 10, gen_loss = 0.395980831935321, disc_loss = 0.09450236007542855
Trained batch 197 in epoch 10, gen_loss = 0.3960568990671273, disc_loss = 0.09411400629235714
Trained batch 198 in epoch 10, gen_loss = 0.3961321055589609, disc_loss = 0.09382770002009956
Trained batch 199 in epoch 10, gen_loss = 0.39575390666723254, disc_loss = 0.0935770517704077
Trained batch 200 in epoch 10, gen_loss = 0.39555215138701066, disc_loss = 0.09342683267209735
Trained batch 201 in epoch 10, gen_loss = 0.3952916074212235, disc_loss = 0.09345422435487334
Trained batch 202 in epoch 10, gen_loss = 0.3952096954648718, disc_loss = 0.0936794772198231
Trained batch 203 in epoch 10, gen_loss = 0.39467234646572785, disc_loss = 0.09389164088083905
Trained batch 204 in epoch 10, gen_loss = 0.3950246764392388, disc_loss = 0.09352331871348547
Trained batch 205 in epoch 10, gen_loss = 0.39522080658708963, disc_loss = 0.0932968537825006
Trained batch 206 in epoch 10, gen_loss = 0.3950636965641077, disc_loss = 0.09373736422248005
Trained batch 207 in epoch 10, gen_loss = 0.3955931460055021, disc_loss = 0.0936978136014659
Trained batch 208 in epoch 10, gen_loss = 0.3952664573226819, disc_loss = 0.09353289437039118
Trained batch 209 in epoch 10, gen_loss = 0.39545841472489496, disc_loss = 0.09354631007826399
Trained batch 210 in epoch 10, gen_loss = 0.39566745308903156, disc_loss = 0.0944942125887279
Trained batch 211 in epoch 10, gen_loss = 0.3953867533578063, disc_loss = 0.09477362895322929
Trained batch 212 in epoch 10, gen_loss = 0.39520272416687907, disc_loss = 0.09488936777099827
Trained batch 213 in epoch 10, gen_loss = 0.39546922810166796, disc_loss = 0.0948325184012859
Trained batch 214 in epoch 10, gen_loss = 0.39520434861959414, disc_loss = 0.09467651685699821
Trained batch 215 in epoch 10, gen_loss = 0.3951060511171818, disc_loss = 0.09446883068152669
Trained batch 216 in epoch 10, gen_loss = 0.39537077098398166, disc_loss = 0.09419452430989404
Trained batch 217 in epoch 10, gen_loss = 0.3954444636992358, disc_loss = 0.09385201013903346
Trained batch 218 in epoch 10, gen_loss = 0.39498721600667525, disc_loss = 0.09370622397974541
Trained batch 219 in epoch 10, gen_loss = 0.39471541087735784, disc_loss = 0.093629421278919
Trained batch 220 in epoch 10, gen_loss = 0.3947341954546277, disc_loss = 0.09340296409459473
Trained batch 221 in epoch 10, gen_loss = 0.39481807748476666, disc_loss = 0.09318060183117317
Trained batch 222 in epoch 10, gen_loss = 0.3943104520774208, disc_loss = 0.09330424355894261
Trained batch 223 in epoch 10, gen_loss = 0.3946098777066384, disc_loss = 0.09363883763892643
Trained batch 224 in epoch 10, gen_loss = 0.39437378724416094, disc_loss = 0.09350905666955643
Trained batch 225 in epoch 10, gen_loss = 0.39419516538624216, disc_loss = 0.0933078016315183
Trained batch 226 in epoch 10, gen_loss = 0.39461880856673626, disc_loss = 0.0930628637405777
Trained batch 227 in epoch 10, gen_loss = 0.3947631076239703, disc_loss = 0.09300181142405786
Trained batch 228 in epoch 10, gen_loss = 0.3948369063925014, disc_loss = 0.09291098852678482
Trained batch 229 in epoch 10, gen_loss = 0.3944885761841484, disc_loss = 0.09327711064732917
Trained batch 230 in epoch 10, gen_loss = 0.3947678019990137, disc_loss = 0.09473426753122892
Trained batch 231 in epoch 10, gen_loss = 0.3947492879012535, disc_loss = 0.09440583536794794
Trained batch 232 in epoch 10, gen_loss = 0.39475059227882026, disc_loss = 0.0943251556612935
Trained batch 233 in epoch 10, gen_loss = 0.3950808220184766, disc_loss = 0.09415557496767077
Trained batch 234 in epoch 10, gen_loss = 0.39517201337408514, disc_loss = 0.09392301727363721
Trained batch 235 in epoch 10, gen_loss = 0.39551267406698, disc_loss = 0.09357256583782639
Trained batch 236 in epoch 10, gen_loss = 0.3955411426880189, disc_loss = 0.09331605395789451
Trained batch 237 in epoch 10, gen_loss = 0.3956210372828636, disc_loss = 0.09310070146070872
Trained batch 238 in epoch 10, gen_loss = 0.3952300567257853, disc_loss = 0.09314286318572558
Trained batch 239 in epoch 10, gen_loss = 0.39533756437400974, disc_loss = 0.09396391221671366
Trained batch 240 in epoch 10, gen_loss = 0.3956392059929638, disc_loss = 0.09387639655897788
Trained batch 241 in epoch 10, gen_loss = 0.3959469201643605, disc_loss = 0.09356432944759419
Trained batch 242 in epoch 10, gen_loss = 0.3961672291098308, disc_loss = 0.09367626796020463
Trained batch 243 in epoch 10, gen_loss = 0.39605734937015125, disc_loss = 0.09392139799015016
Trained batch 244 in epoch 10, gen_loss = 0.39611394989247223, disc_loss = 0.0936157711249377
Trained batch 245 in epoch 10, gen_loss = 0.3960557197167621, disc_loss = 0.09342486065494396
Trained batch 246 in epoch 10, gen_loss = 0.3958556276825275, disc_loss = 0.09316405676765299
Trained batch 247 in epoch 10, gen_loss = 0.39563612051067815, disc_loss = 0.09360549681737358
Trained batch 248 in epoch 10, gen_loss = 0.39547641318007165, disc_loss = 0.09453779146501637
Trained batch 249 in epoch 10, gen_loss = 0.39591065132617953, disc_loss = 0.09446402679570019
Trained batch 250 in epoch 10, gen_loss = 0.39572588155469096, disc_loss = 0.09477199114065069
Trained batch 251 in epoch 10, gen_loss = 0.3957976092185293, disc_loss = 0.0945361100658331
Trained batch 252 in epoch 10, gen_loss = 0.39607959066926257, disc_loss = 0.0941919574657595
Trained batch 253 in epoch 10, gen_loss = 0.39625594770814493, disc_loss = 0.09386692934038895
Trained batch 254 in epoch 10, gen_loss = 0.3959028838896284, disc_loss = 0.0937504799506974
Trained batch 255 in epoch 10, gen_loss = 0.3957065996946767, disc_loss = 0.09359047049838409
Trained batch 256 in epoch 10, gen_loss = 0.39588445784516835, disc_loss = 0.09343915263277837
Trained batch 257 in epoch 10, gen_loss = 0.3960110408853191, disc_loss = 0.09326497924716262
Trained batch 258 in epoch 10, gen_loss = 0.3960925080601313, disc_loss = 0.09300059658514774
Trained batch 259 in epoch 10, gen_loss = 0.39610488334527383, disc_loss = 0.09372710221841071
Trained batch 260 in epoch 10, gen_loss = 0.39612577495903806, disc_loss = 0.09457391606272694
Trained batch 261 in epoch 10, gen_loss = 0.39649588233641997, disc_loss = 0.09433680391898876
Trained batch 262 in epoch 10, gen_loss = 0.3969122760649416, disc_loss = 0.09414941207204765
Trained batch 263 in epoch 10, gen_loss = 0.3970451473512433, disc_loss = 0.09386423750336027
Trained batch 264 in epoch 10, gen_loss = 0.3972782091149744, disc_loss = 0.09354874670400092
Trained batch 265 in epoch 10, gen_loss = 0.39759138663460436, disc_loss = 0.09330389348446931
Trained batch 266 in epoch 10, gen_loss = 0.3977545964137445, disc_loss = 0.09303991908333108
Trained batch 267 in epoch 10, gen_loss = 0.39787377105720007, disc_loss = 0.09273724290090543
Trained batch 268 in epoch 10, gen_loss = 0.3975921594520484, disc_loss = 0.09246247820036839
Trained batch 269 in epoch 10, gen_loss = 0.39750339620643194, disc_loss = 0.09222921920353892
Trained batch 270 in epoch 10, gen_loss = 0.39742161987892377, disc_loss = 0.09213839804863633
Trained batch 271 in epoch 10, gen_loss = 0.3971489871687749, disc_loss = 0.0922718981421306
Trained batch 272 in epoch 10, gen_loss = 0.3970793476908198, disc_loss = 0.09210425007562989
Trained batch 273 in epoch 10, gen_loss = 0.3972617931609606, disc_loss = 0.09198423201238641
Trained batch 274 in epoch 10, gen_loss = 0.3973995091698386, disc_loss = 0.09203500843352892
Trained batch 275 in epoch 10, gen_loss = 0.3974179542367009, disc_loss = 0.09243932353717316
Trained batch 276 in epoch 10, gen_loss = 0.39751754555891566, disc_loss = 0.09261919782137236
Trained batch 277 in epoch 10, gen_loss = 0.39745811003146414, disc_loss = 0.09256268674072227
Trained batch 278 in epoch 10, gen_loss = 0.39761968645998225, disc_loss = 0.09225831948567889
Trained batch 279 in epoch 10, gen_loss = 0.39783475335155216, disc_loss = 0.09219510551275951
Trained batch 280 in epoch 10, gen_loss = 0.39777522462542797, disc_loss = 0.09235186685287655
Trained batch 281 in epoch 10, gen_loss = 0.39798495205158885, disc_loss = 0.09216751917826792
Trained batch 282 in epoch 10, gen_loss = 0.39827207604903636, disc_loss = 0.0921945344038018
Trained batch 283 in epoch 10, gen_loss = 0.3979451892451501, disc_loss = 0.0933768825448105
Trained batch 284 in epoch 10, gen_loss = 0.39796831816957706, disc_loss = 0.0931764963426088
Trained batch 285 in epoch 10, gen_loss = 0.3977486201516398, disc_loss = 0.09318974444811995
Trained batch 286 in epoch 10, gen_loss = 0.39760600534050305, disc_loss = 0.09302187234630568
Trained batch 287 in epoch 10, gen_loss = 0.397201809928649, disc_loss = 0.0932487132312316
Trained batch 288 in epoch 10, gen_loss = 0.39751174695351543, disc_loss = 0.09468991460220624
Trained batch 289 in epoch 10, gen_loss = 0.3973446906640612, disc_loss = 0.0945319809661857
Trained batch 290 in epoch 10, gen_loss = 0.3970590589177568, disc_loss = 0.09482165196865695
Trained batch 291 in epoch 10, gen_loss = 0.3970126532120247, disc_loss = 0.0951573125482218
Trained batch 292 in epoch 10, gen_loss = 0.3969587163917034, disc_loss = 0.09504166564589474
Trained batch 293 in epoch 10, gen_loss = 0.39682338047189775, disc_loss = 0.0950083075610756
Trained batch 294 in epoch 10, gen_loss = 0.3964903344542293, disc_loss = 0.09511379133594239
Trained batch 295 in epoch 10, gen_loss = 0.3963098692128787, disc_loss = 0.09534802221114168
Trained batch 296 in epoch 10, gen_loss = 0.39648082591467837, disc_loss = 0.09520540065335906
Trained batch 297 in epoch 10, gen_loss = 0.3966192406095914, disc_loss = 0.095114648617154
Trained batch 298 in epoch 10, gen_loss = 0.39644189622489906, disc_loss = 0.09524400529753803
Trained batch 299 in epoch 10, gen_loss = 0.3965028382341067, disc_loss = 0.09500559516871969
Trained batch 300 in epoch 10, gen_loss = 0.396338091637209, disc_loss = 0.09498563506006204
Trained batch 301 in epoch 10, gen_loss = 0.39613278012796743, disc_loss = 0.09585610849301744
Trained batch 302 in epoch 10, gen_loss = 0.3959877585420514, disc_loss = 0.09622335323922508
Trained batch 303 in epoch 10, gen_loss = 0.3961826570724186, disc_loss = 0.09599893071419119
Trained batch 304 in epoch 10, gen_loss = 0.3963149938427034, disc_loss = 0.09593490024448419
Trained batch 305 in epoch 10, gen_loss = 0.39649871244929197, disc_loss = 0.09576419183947876
Trained batch 306 in epoch 10, gen_loss = 0.3965691093124862, disc_loss = 0.09554914750935395
Trained batch 307 in epoch 10, gen_loss = 0.3966934606432915, disc_loss = 0.09537735029256769
Trained batch 308 in epoch 10, gen_loss = 0.3964823801733529, disc_loss = 0.09551901825399267
Trained batch 309 in epoch 10, gen_loss = 0.39665301567123784, disc_loss = 0.09527557075864845
Trained batch 310 in epoch 10, gen_loss = 0.39671783594839827, disc_loss = 0.09550833651179094
Trained batch 311 in epoch 10, gen_loss = 0.3963175439872803, disc_loss = 0.0960773160525908
Trained batch 312 in epoch 10, gen_loss = 0.3963022018773868, disc_loss = 0.09589727592473023
Trained batch 313 in epoch 10, gen_loss = 0.39618398581340813, disc_loss = 0.09666200839338979
Trained batch 314 in epoch 10, gen_loss = 0.39597196560057385, disc_loss = 0.09718501845167743
Trained batch 315 in epoch 10, gen_loss = 0.39627044412154183, disc_loss = 0.09698220189731521
Trained batch 316 in epoch 10, gen_loss = 0.3963588675489937, disc_loss = 0.09698886391985867
Trained batch 317 in epoch 10, gen_loss = 0.3961854376508005, disc_loss = 0.09728509734191422
Trained batch 318 in epoch 10, gen_loss = 0.39628250098153717, disc_loss = 0.097384367879702
Trained batch 319 in epoch 10, gen_loss = 0.3961601100862026, disc_loss = 0.09738014152389951
Trained batch 320 in epoch 10, gen_loss = 0.39599388568572164, disc_loss = 0.09739684390710708
Trained batch 321 in epoch 10, gen_loss = 0.39604665005799405, disc_loss = 0.09805949069906651
Trained batch 322 in epoch 10, gen_loss = 0.39587773664078846, disc_loss = 0.09847288350963924
Trained batch 323 in epoch 10, gen_loss = 0.39591908427300276, disc_loss = 0.09842664450062094
Trained batch 324 in epoch 10, gen_loss = 0.3956398931833414, disc_loss = 0.09829638394598778
Trained batch 325 in epoch 10, gen_loss = 0.3955845101479372, disc_loss = 0.0981061306090717
Trained batch 326 in epoch 10, gen_loss = 0.3954803266474231, disc_loss = 0.09794369256209343
Trained batch 327 in epoch 10, gen_loss = 0.39508925787195925, disc_loss = 0.09810107849288459
Trained batch 328 in epoch 10, gen_loss = 0.39525659078884995, disc_loss = 0.09833349168051521
Trained batch 329 in epoch 10, gen_loss = 0.39529810683293776, disc_loss = 0.09809636169988098
Trained batch 330 in epoch 10, gen_loss = 0.39524453014045324, disc_loss = 0.09793154065837673
Trained batch 331 in epoch 10, gen_loss = 0.3952078865055578, disc_loss = 0.09787125074226095
Trained batch 332 in epoch 10, gen_loss = 0.3952523661447359, disc_loss = 0.09781657455785496
Trained batch 333 in epoch 10, gen_loss = 0.3951478074053804, disc_loss = 0.09768503042172172
Trained batch 334 in epoch 10, gen_loss = 0.3952100771576611, disc_loss = 0.09763332070476974
Trained batch 335 in epoch 10, gen_loss = 0.39513889762262505, disc_loss = 0.09788644906976038
Trained batch 336 in epoch 10, gen_loss = 0.39539447161493385, disc_loss = 0.09809431768622172
Trained batch 337 in epoch 10, gen_loss = 0.39513832815652766, disc_loss = 0.09800069158643308
Trained batch 338 in epoch 10, gen_loss = 0.3951988688788231, disc_loss = 0.09793699597582704
Trained batch 339 in epoch 10, gen_loss = 0.3951820845113081, disc_loss = 0.09780841567279662
Trained batch 340 in epoch 10, gen_loss = 0.39475266080448007, disc_loss = 0.09800496576162727
Trained batch 341 in epoch 10, gen_loss = 0.3948030752396723, disc_loss = 0.09806928449250453
Trained batch 342 in epoch 10, gen_loss = 0.3946546060698373, disc_loss = 0.0983894535234475
Trained batch 343 in epoch 10, gen_loss = 0.3947625034597031, disc_loss = 0.09836235210342809
Trained batch 344 in epoch 10, gen_loss = 0.394654387322025, disc_loss = 0.09832439665561137
Trained batch 345 in epoch 10, gen_loss = 0.39494223737647766, disc_loss = 0.09825139418459697
Trained batch 346 in epoch 10, gen_loss = 0.395147764974781, disc_loss = 0.09819505261713558
Trained batch 347 in epoch 10, gen_loss = 0.39512585523142213, disc_loss = 0.09845368276168218
Trained batch 348 in epoch 10, gen_loss = 0.3950887009031793, disc_loss = 0.09841093257667342
Trained batch 349 in epoch 10, gen_loss = 0.3952971865449633, disc_loss = 0.09818682886127915
Trained batch 350 in epoch 10, gen_loss = 0.39523562007819824, disc_loss = 0.0979800396399875
Trained batch 351 in epoch 10, gen_loss = 0.395161913792518, disc_loss = 0.098322065689982
Trained batch 352 in epoch 10, gen_loss = 0.39554657468377025, disc_loss = 0.09919071811180108
Trained batch 353 in epoch 10, gen_loss = 0.3954449612542061, disc_loss = 0.09908977979636294
Trained batch 354 in epoch 10, gen_loss = 0.39541571400534936, disc_loss = 0.09895086386568949
Trained batch 355 in epoch 10, gen_loss = 0.395384260777677, disc_loss = 0.09912777103462748
Trained batch 356 in epoch 10, gen_loss = 0.3953362342690219, disc_loss = 0.09889645797803122
Trained batch 357 in epoch 10, gen_loss = 0.3955331506342861, disc_loss = 0.0987541968544019
Trained batch 358 in epoch 10, gen_loss = 0.3958107789246817, disc_loss = 0.09853879796097205
Trained batch 359 in epoch 10, gen_loss = 0.39571232257617844, disc_loss = 0.09833744056005445
Trained batch 360 in epoch 10, gen_loss = 0.39549936705018673, disc_loss = 0.09817779364987919
Trained batch 361 in epoch 10, gen_loss = 0.3954185830295415, disc_loss = 0.0981861912074257
Trained batch 362 in epoch 10, gen_loss = 0.3954050522041058, disc_loss = 0.09891211528320779
Trained batch 363 in epoch 10, gen_loss = 0.39575520100501865, disc_loss = 0.0987484517077414
Trained batch 364 in epoch 10, gen_loss = 0.3955049118767046, disc_loss = 0.09856815243726724
Trained batch 365 in epoch 10, gen_loss = 0.395470408061163, disc_loss = 0.09847538191010881
Trained batch 366 in epoch 10, gen_loss = 0.395556528090781, disc_loss = 0.0983555767563367
Trained batch 367 in epoch 10, gen_loss = 0.3954754369738309, disc_loss = 0.09823718731311838
Trained batch 368 in epoch 10, gen_loss = 0.39516375494520195, disc_loss = 0.0984213875914573
Trained batch 369 in epoch 10, gen_loss = 0.3951079122923516, disc_loss = 0.09836393737209004
Trained batch 370 in epoch 10, gen_loss = 0.3949339846073778, disc_loss = 0.09829200618973158
Trained batch 371 in epoch 10, gen_loss = 0.39457207125040794, disc_loss = 0.09851251862522575
Trained batch 372 in epoch 10, gen_loss = 0.394513423017778, disc_loss = 0.09846737181353345
Trained batch 373 in epoch 10, gen_loss = 0.39462991895522664, disc_loss = 0.09858276794121705
Trained batch 374 in epoch 10, gen_loss = 0.3945715294679006, disc_loss = 0.0990905417551597
Trained batch 375 in epoch 10, gen_loss = 0.39441234697686867, disc_loss = 0.09895975266068065
Trained batch 376 in epoch 10, gen_loss = 0.3946190468512416, disc_loss = 0.09929085106388802
Trained batch 377 in epoch 10, gen_loss = 0.3947262055974789, disc_loss = 0.09905798022669775
Trained batch 378 in epoch 10, gen_loss = 0.39462793596816254, disc_loss = 0.09912404796418225
Trained batch 379 in epoch 10, gen_loss = 0.3947122838936354, disc_loss = 0.09890855150787455
Trained batch 380 in epoch 10, gen_loss = 0.3947937396254752, disc_loss = 0.09893951770358199
Trained batch 381 in epoch 10, gen_loss = 0.39440458763332265, disc_loss = 0.09913617204777234
Trained batch 382 in epoch 10, gen_loss = 0.39435550344830705, disc_loss = 0.09911276281424665
Trained batch 383 in epoch 10, gen_loss = 0.39440573131044704, disc_loss = 0.09897323622135445
Trained batch 384 in epoch 10, gen_loss = 0.3944165542528227, disc_loss = 0.09888725600072316
Trained batch 385 in epoch 10, gen_loss = 0.3945014506115197, disc_loss = 0.09902571626200578
Trained batch 386 in epoch 10, gen_loss = 0.3947074461044883, disc_loss = 0.09951688543693656
Trained batch 387 in epoch 10, gen_loss = 0.3946938485521631, disc_loss = 0.09942170923825391
Trained batch 388 in epoch 10, gen_loss = 0.3944747976594842, disc_loss = 0.09941805690373737
Trained batch 389 in epoch 10, gen_loss = 0.39447275086855277, disc_loss = 0.09940110722031349
Trained batch 390 in epoch 10, gen_loss = 0.39438211323355166, disc_loss = 0.09928254703121722
Trained batch 391 in epoch 10, gen_loss = 0.39440552510169086, disc_loss = 0.09912943854281793
Trained batch 392 in epoch 10, gen_loss = 0.3944921610312911, disc_loss = 0.09891442031511899
Trained batch 393 in epoch 10, gen_loss = 0.39462861259879195, disc_loss = 0.09876485582355995
Trained batch 394 in epoch 10, gen_loss = 0.3948067342178731, disc_loss = 0.09891094709923373
Trained batch 395 in epoch 10, gen_loss = 0.394642219022669, disc_loss = 0.09932955370679723
Trained batch 396 in epoch 10, gen_loss = 0.39489721418628165, disc_loss = 0.09967426183664004
Trained batch 397 in epoch 10, gen_loss = 0.39494349751340685, disc_loss = 0.09949331225396775
Trained batch 398 in epoch 10, gen_loss = 0.3950145736075284, disc_loss = 0.09925892688147257
Trained batch 399 in epoch 10, gen_loss = 0.39516148895025255, disc_loss = 0.09904807405546308
Trained batch 400 in epoch 10, gen_loss = 0.3949831416482045, disc_loss = 0.09883842637479082
Trained batch 401 in epoch 10, gen_loss = 0.39498254723513304, disc_loss = 0.09866015650378308
Trained batch 402 in epoch 10, gen_loss = 0.39503655192573967, disc_loss = 0.09843118120419328
Trained batch 403 in epoch 10, gen_loss = 0.3949568335815231, disc_loss = 0.09820523940137413
Trained batch 404 in epoch 10, gen_loss = 0.3949700615288299, disc_loss = 0.09804943857921494
Trained batch 405 in epoch 10, gen_loss = 0.3949368770046187, disc_loss = 0.09811659222422855
Trained batch 406 in epoch 10, gen_loss = 0.3951978323939977, disc_loss = 0.09821154992725398
Trained batch 407 in epoch 10, gen_loss = 0.3953062565449406, disc_loss = 0.0980202548078024
Trained batch 408 in epoch 10, gen_loss = 0.39533560491715786, disc_loss = 0.09787266365364011
Trained batch 409 in epoch 10, gen_loss = 0.39547825237599815, disc_loss = 0.09769435976518363
Trained batch 410 in epoch 10, gen_loss = 0.3953491220219002, disc_loss = 0.097663438731664
Trained batch 411 in epoch 10, gen_loss = 0.3953362113787133, disc_loss = 0.09783276212989415
Trained batch 412 in epoch 10, gen_loss = 0.39543341681108635, disc_loss = 0.0978448295257715
Trained batch 413 in epoch 10, gen_loss = 0.39571435065661076, disc_loss = 0.0976710809295736
Trained batch 414 in epoch 10, gen_loss = 0.3957949178764619, disc_loss = 0.09757714101887612
Trained batch 415 in epoch 10, gen_loss = 0.39565613192434496, disc_loss = 0.09777598497636902
Trained batch 416 in epoch 10, gen_loss = 0.39554531461329195, disc_loss = 0.09842636808753014
Trained batch 417 in epoch 10, gen_loss = 0.3954546566357453, disc_loss = 0.09861303800850679
Trained batch 418 in epoch 10, gen_loss = 0.3954024016857147, disc_loss = 0.09880808894666965
Trained batch 419 in epoch 10, gen_loss = 0.3953757725301243, disc_loss = 0.0987089014656487
Trained batch 420 in epoch 10, gen_loss = 0.3953078731788309, disc_loss = 0.09884715138662456
Trained batch 421 in epoch 10, gen_loss = 0.39535246987195943, disc_loss = 0.09904647178912615
Trained batch 422 in epoch 10, gen_loss = 0.3953417831278862, disc_loss = 0.0989534237353796
Trained batch 423 in epoch 10, gen_loss = 0.3951089884031494, disc_loss = 0.09906961993788774
Trained batch 424 in epoch 10, gen_loss = 0.3952175847221823, disc_loss = 0.09911444506224464
Trained batch 425 in epoch 10, gen_loss = 0.39524874650816405, disc_loss = 0.09901283605312797
Trained batch 426 in epoch 10, gen_loss = 0.3951139863257665, disc_loss = 0.09964967919491773
Trained batch 427 in epoch 10, gen_loss = 0.39518338316511886, disc_loss = 0.09950682979564522
Trained batch 428 in epoch 10, gen_loss = 0.3952162897948063, disc_loss = 0.0994114437789628
Trained batch 429 in epoch 10, gen_loss = 0.39509537566539854, disc_loss = 0.09931370991953584
Trained batch 430 in epoch 10, gen_loss = 0.395233973964461, disc_loss = 0.09921231540892352
Trained batch 431 in epoch 10, gen_loss = 0.39523853237430256, disc_loss = 0.09908815683728014
Trained batch 432 in epoch 10, gen_loss = 0.3952350064458252, disc_loss = 0.09913285004349283
Trained batch 433 in epoch 10, gen_loss = 0.3950897039081644, disc_loss = 0.09905052816812893
Trained batch 434 in epoch 10, gen_loss = 0.3950966127987566, disc_loss = 0.09947627741715004
Trained batch 435 in epoch 10, gen_loss = 0.394864623973129, disc_loss = 0.09996520003320974
Trained batch 436 in epoch 10, gen_loss = 0.39502605523070156, disc_loss = 0.09989611004869234
Trained batch 437 in epoch 10, gen_loss = 0.3948388475941741, disc_loss = 0.1000619483899036
Trained batch 438 in epoch 10, gen_loss = 0.39464026506234956, disc_loss = 0.10002833491102167
Trained batch 439 in epoch 10, gen_loss = 0.39455526450818235, disc_loss = 0.10000951383262872
Trained batch 440 in epoch 10, gen_loss = 0.3947480141846231, disc_loss = 0.10009401713977326
Trained batch 441 in epoch 10, gen_loss = 0.39466903395782227, disc_loss = 0.10008797258543213
Trained batch 442 in epoch 10, gen_loss = 0.39480628412948504, disc_loss = 0.0999760580318507
Trained batch 443 in epoch 10, gen_loss = 0.39473194078550683, disc_loss = 0.09992604679218284
Trained batch 444 in epoch 10, gen_loss = 0.3947550331608633, disc_loss = 0.09992119033684892
Trained batch 445 in epoch 10, gen_loss = 0.3947143803931138, disc_loss = 0.09992171890799775
Trained batch 446 in epoch 10, gen_loss = 0.39454190949732293, disc_loss = 0.10003325043108639
Trained batch 447 in epoch 10, gen_loss = 0.39453983047444907, disc_loss = 0.10007753632297474
Trained batch 448 in epoch 10, gen_loss = 0.39448005047301143, disc_loss = 0.09992904413516378
Trained batch 449 in epoch 10, gen_loss = 0.39437235037485757, disc_loss = 0.09993705385261112
Trained batch 450 in epoch 10, gen_loss = 0.3944321423438594, disc_loss = 0.09973964191758447
Trained batch 451 in epoch 10, gen_loss = 0.39429563250953115, disc_loss = 0.09968652825934433
Trained batch 452 in epoch 10, gen_loss = 0.3942216655144892, disc_loss = 0.09974650962167228
Trained batch 453 in epoch 10, gen_loss = 0.39431734035193655, disc_loss = 0.1000123637346838
Trained batch 454 in epoch 10, gen_loss = 0.39439755049380626, disc_loss = 0.09991441685911064
Trained batch 455 in epoch 10, gen_loss = 0.39442026785068346, disc_loss = 0.09989373834411565
Trained batch 456 in epoch 10, gen_loss = 0.3945460224308122, disc_loss = 0.09975056707272123
Trained batch 457 in epoch 10, gen_loss = 0.3946438395950992, disc_loss = 0.09986280807696575
Trained batch 458 in epoch 10, gen_loss = 0.3949850056815511, disc_loss = 0.1001505034778892
Testing Epoch 10
Training Epoch 11
Trained batch 0 in epoch 11, gen_loss = 0.23984463512897491, disc_loss = 0.6298835873603821
Trained batch 1 in epoch 11, gen_loss = 0.2723490670323372, disc_loss = 0.34905651211738586
Trained batch 2 in epoch 11, gen_loss = 0.3310366024573644, disc_loss = 0.2621379966537158
Trained batch 3 in epoch 11, gen_loss = 0.3631954602897167, disc_loss = 0.26962600462138653
Trained batch 4 in epoch 11, gen_loss = 0.3624388128519058, disc_loss = 0.23173149526119233
Trained batch 5 in epoch 11, gen_loss = 0.35920926680167514, disc_loss = 0.19737988586227098
Trained batch 6 in epoch 11, gen_loss = 0.35049330975328175, disc_loss = 0.1807945966720581
Trained batch 7 in epoch 11, gen_loss = 0.3537334594875574, disc_loss = 0.167942238971591
Trained batch 8 in epoch 11, gen_loss = 0.35825358000066543, disc_loss = 0.16011314425203535
Trained batch 9 in epoch 11, gen_loss = 0.35657098442316054, disc_loss = 0.1571756973862648
Trained batch 10 in epoch 11, gen_loss = 0.35675637423992157, disc_loss = 0.18036264316602188
Trained batch 11 in epoch 11, gen_loss = 0.35789655273159343, disc_loss = 0.17057897709310055
Trained batch 12 in epoch 11, gen_loss = 0.35915041772218853, disc_loss = 0.16196484978382403
Trained batch 13 in epoch 11, gen_loss = 0.3651688428861754, disc_loss = 0.15557500187839782
Trained batch 14 in epoch 11, gen_loss = 0.36083888908227285, disc_loss = 0.14981035888195038
Trained batch 15 in epoch 11, gen_loss = 0.3632482038810849, disc_loss = 0.14542460767552257
Trained batch 16 in epoch 11, gen_loss = 0.36898596935412464, disc_loss = 0.13841306966017275
Trained batch 17 in epoch 11, gen_loss = 0.37006109373437035, disc_loss = 0.135483895531959
Trained batch 18 in epoch 11, gen_loss = 0.37149680366641596, disc_loss = 0.13332461193203926
Trained batch 19 in epoch 11, gen_loss = 0.3757329933345318, disc_loss = 0.12786655398085714
Trained batch 20 in epoch 11, gen_loss = 0.3757322011958985, disc_loss = 0.1224608537075775
Trained batch 21 in epoch 11, gen_loss = 0.37578174810517917, disc_loss = 0.11958447509360584
Trained batch 22 in epoch 11, gen_loss = 0.37781955560912256, disc_loss = 0.11896768345942964
Trained batch 23 in epoch 11, gen_loss = 0.3782689527918895, disc_loss = 0.11614564608316869
Trained batch 24 in epoch 11, gen_loss = 0.37855874359607694, disc_loss = 0.11390660423785448
Trained batch 25 in epoch 11, gen_loss = 0.3814636245369911, disc_loss = 0.11911209289414379
Trained batch 26 in epoch 11, gen_loss = 0.3831458075178994, disc_loss = 0.11541776776451755
Trained batch 27 in epoch 11, gen_loss = 0.382498424500227, disc_loss = 0.1146555663019951
Trained batch 28 in epoch 11, gen_loss = 0.38481931182844886, disc_loss = 0.1117324061242157
Trained batch 29 in epoch 11, gen_loss = 0.3859075322747231, disc_loss = 0.10944444354002675
Trained batch 30 in epoch 11, gen_loss = 0.38674842590285885, disc_loss = 0.11162564894484897
Trained batch 31 in epoch 11, gen_loss = 0.38792234053835273, disc_loss = 0.11875382313155569
Trained batch 32 in epoch 11, gen_loss = 0.38575900368618243, disc_loss = 0.1237163341914614
Trained batch 33 in epoch 11, gen_loss = 0.3910656312809271, disc_loss = 0.12241600336068693
Trained batch 34 in epoch 11, gen_loss = 0.39128496178558897, disc_loss = 0.11919035408645869
Trained batch 35 in epoch 11, gen_loss = 0.39126141824656063, disc_loss = 0.11701037432067096
Trained batch 36 in epoch 11, gen_loss = 0.39025422165522705, disc_loss = 0.12031492336678344
Trained batch 37 in epoch 11, gen_loss = 0.391354549480112, disc_loss = 0.11990762862229817
Trained batch 38 in epoch 11, gen_loss = 0.39087822842292297, disc_loss = 0.11793645239697817
Trained batch 39 in epoch 11, gen_loss = 0.3900404516607523, disc_loss = 0.11727032845374197
Trained batch 40 in epoch 11, gen_loss = 0.39194237786095315, disc_loss = 0.11939423583538794
Trained batch 41 in epoch 11, gen_loss = 0.3908138867645037, disc_loss = 0.12259991713134306
Trained batch 42 in epoch 11, gen_loss = 0.38968556530253834, disc_loss = 0.12101186697133058
Trained batch 43 in epoch 11, gen_loss = 0.39161691238934343, disc_loss = 0.11899263536642221
Trained batch 44 in epoch 11, gen_loss = 0.39340522521071963, disc_loss = 0.11650735912844538
Trained batch 45 in epoch 11, gen_loss = 0.39236397037039633, disc_loss = 0.11459694821994913
Trained batch 46 in epoch 11, gen_loss = 0.391451210734692, disc_loss = 0.11393218014904476
Trained batch 47 in epoch 11, gen_loss = 0.3904762811337908, disc_loss = 0.11220544238070336
Trained batch 48 in epoch 11, gen_loss = 0.39143708378684766, disc_loss = 0.11166889816332533
Trained batch 49 in epoch 11, gen_loss = 0.3888197776675224, disc_loss = 0.11281871709041297
Trained batch 50 in epoch 11, gen_loss = 0.38841699472829405, disc_loss = 0.11252973509002842
Trained batch 51 in epoch 11, gen_loss = 0.3890598298838505, disc_loss = 0.1117752262015039
Trained batch 52 in epoch 11, gen_loss = 0.3893140973347538, disc_loss = 0.11188107113055182
Trained batch 53 in epoch 11, gen_loss = 0.3925037199148425, disc_loss = 0.11448467221904408
Trained batch 54 in epoch 11, gen_loss = 0.3932122590866956, disc_loss = 0.1127750653011555
Trained batch 55 in epoch 11, gen_loss = 0.39184281256582054, disc_loss = 0.11176030579788078
Trained batch 56 in epoch 11, gen_loss = 0.39125380625850276, disc_loss = 0.1102784118092243
Trained batch 57 in epoch 11, gen_loss = 0.3909736756106903, disc_loss = 0.10943499698046723
Trained batch 58 in epoch 11, gen_loss = 0.39129359009912457, disc_loss = 0.11038375484078365
Trained batch 59 in epoch 11, gen_loss = 0.39257915193835896, disc_loss = 0.1160573490196839
Trained batch 60 in epoch 11, gen_loss = 0.39164423038724994, disc_loss = 0.1183334767558902
Trained batch 61 in epoch 11, gen_loss = 0.3908267105298658, disc_loss = 0.1184235623992619
Trained batch 62 in epoch 11, gen_loss = 0.3901864637931188, disc_loss = 0.11754826624094257
Trained batch 63 in epoch 11, gen_loss = 0.39040909870527685, disc_loss = 0.11591666563617764
Trained batch 64 in epoch 11, gen_loss = 0.3909605610829133, disc_loss = 0.11423385397602732
Trained batch 65 in epoch 11, gen_loss = 0.3917146720217936, disc_loss = 0.11262183315402856
Trained batch 66 in epoch 11, gen_loss = 0.3931699499710282, disc_loss = 0.11104673997207141
Trained batch 67 in epoch 11, gen_loss = 0.39306965579881387, disc_loss = 0.10978017883676597
Trained batch 68 in epoch 11, gen_loss = 0.3919091801280561, disc_loss = 0.10842631165397124
Trained batch 69 in epoch 11, gen_loss = 0.39194206744432447, disc_loss = 0.1072559815099729
Trained batch 70 in epoch 11, gen_loss = 0.390948483851594, disc_loss = 0.106874696562775
Trained batch 71 in epoch 11, gen_loss = 0.3921854349060191, disc_loss = 0.10796936970695646
Trained batch 72 in epoch 11, gen_loss = 0.3910259206409324, disc_loss = 0.10931337835930593
Trained batch 73 in epoch 11, gen_loss = 0.39165773967633377, disc_loss = 0.1089156943285284
Trained batch 74 in epoch 11, gen_loss = 0.391652194460233, disc_loss = 0.11181369867796699
Trained batch 75 in epoch 11, gen_loss = 0.3922332668382871, disc_loss = 0.11084373949071098
Trained batch 76 in epoch 11, gen_loss = 0.39217295526684104, disc_loss = 0.11031545792379743
Trained batch 77 in epoch 11, gen_loss = 0.3924672127916263, disc_loss = 0.10953385523186089
Trained batch 78 in epoch 11, gen_loss = 0.3921648718511002, disc_loss = 0.11042628641817955
Trained batch 79 in epoch 11, gen_loss = 0.3914499880746007, disc_loss = 0.11028608518536202
Trained batch 80 in epoch 11, gen_loss = 0.39033071549586307, disc_loss = 0.10980035922846493
Trained batch 81 in epoch 11, gen_loss = 0.39019680150398395, disc_loss = 0.11077848846297257
Trained batch 82 in epoch 11, gen_loss = 0.38964207542229845, disc_loss = 0.11147528857060046
Trained batch 83 in epoch 11, gen_loss = 0.3910613434300536, disc_loss = 0.11091953779326841
Trained batch 84 in epoch 11, gen_loss = 0.3909970190595178, disc_loss = 0.10988015897900742
Trained batch 85 in epoch 11, gen_loss = 0.39065655979306196, disc_loss = 0.10928533938280198
Trained batch 86 in epoch 11, gen_loss = 0.39005798632386085, disc_loss = 0.10950012352510259
Trained batch 87 in epoch 11, gen_loss = 0.38969713500277564, disc_loss = 0.10951884304152125
Trained batch 88 in epoch 11, gen_loss = 0.3898071989919362, disc_loss = 0.10938561047961036
Trained batch 89 in epoch 11, gen_loss = 0.3906957455807262, disc_loss = 0.10901631697908871
Trained batch 90 in epoch 11, gen_loss = 0.3903327084832139, disc_loss = 0.1082316431687674
Trained batch 91 in epoch 11, gen_loss = 0.390773452008548, disc_loss = 0.10799276870776615
Trained batch 92 in epoch 11, gen_loss = 0.39059809026538683, disc_loss = 0.10929043087807874
Trained batch 93 in epoch 11, gen_loss = 0.3909735709745833, disc_loss = 0.10866211720821546
Trained batch 94 in epoch 11, gen_loss = 0.3908400104234093, disc_loss = 0.108169684377744
Trained batch 95 in epoch 11, gen_loss = 0.3913129917345941, disc_loss = 0.10746703449694905
Trained batch 96 in epoch 11, gen_loss = 0.39085244011018694, disc_loss = 0.10720196264056661
Trained batch 97 in epoch 11, gen_loss = 0.39153187630736097, disc_loss = 0.10627360637679849
Trained batch 98 in epoch 11, gen_loss = 0.3910739700300525, disc_loss = 0.10631215876683292
Trained batch 99 in epoch 11, gen_loss = 0.3922720272839069, disc_loss = 0.10856924507301301
Trained batch 100 in epoch 11, gen_loss = 0.39147505060871046, disc_loss = 0.10872673150613019
Trained batch 101 in epoch 11, gen_loss = 0.3908839872946926, disc_loss = 0.10848256532449786
Trained batch 102 in epoch 11, gen_loss = 0.3909911216752043, disc_loss = 0.10812078296541444
Trained batch 103 in epoch 11, gen_loss = 0.39130659960210323, disc_loss = 0.10738750235088027
Trained batch 104 in epoch 11, gen_loss = 0.39034928324676693, disc_loss = 0.10683829776854033
Trained batch 105 in epoch 11, gen_loss = 0.3907322589800043, disc_loss = 0.11091025700388511
Trained batch 106 in epoch 11, gen_loss = 0.3905022268261865, disc_loss = 0.11203929231388965
Trained batch 107 in epoch 11, gen_loss = 0.39203696904910934, disc_loss = 0.11313555037378575
Trained batch 108 in epoch 11, gen_loss = 0.3914427952755482, disc_loss = 0.11296914223530287
Trained batch 109 in epoch 11, gen_loss = 0.3921308445659551, disc_loss = 0.11223483525470576
Trained batch 110 in epoch 11, gen_loss = 0.3913894587003433, disc_loss = 0.11274290171678404
Trained batch 111 in epoch 11, gen_loss = 0.39171303449464695, disc_loss = 0.11324903481623291
Trained batch 112 in epoch 11, gen_loss = 0.39215270858422846, disc_loss = 0.11300798465571968
Trained batch 113 in epoch 11, gen_loss = 0.3925085202382322, disc_loss = 0.11238341650664153
Trained batch 114 in epoch 11, gen_loss = 0.39309575233770455, disc_loss = 0.11179956832252767
Trained batch 115 in epoch 11, gen_loss = 0.39337191101292085, disc_loss = 0.11116481902768258
Trained batch 116 in epoch 11, gen_loss = 0.39386803306575513, disc_loss = 0.11150067735415621
Trained batch 117 in epoch 11, gen_loss = 0.39381512709088246, disc_loss = 0.11170910333156965
Trained batch 118 in epoch 11, gen_loss = 0.3937802298479721, disc_loss = 0.11125912435524979
Trained batch 119 in epoch 11, gen_loss = 0.3943726528435946, disc_loss = 0.11153178562332565
Trained batch 120 in epoch 11, gen_loss = 0.39433879214377443, disc_loss = 0.1123930543376333
Trained batch 121 in epoch 11, gen_loss = 0.3936059075545092, disc_loss = 0.11299166937938845
Trained batch 122 in epoch 11, gen_loss = 0.39356695236713907, disc_loss = 0.11302776676716238
Trained batch 123 in epoch 11, gen_loss = 0.39292678369149087, disc_loss = 0.11459377029114554
Trained batch 124 in epoch 11, gen_loss = 0.39304871690273285, disc_loss = 0.11427423691377044
Trained batch 125 in epoch 11, gen_loss = 0.39366396019856137, disc_loss = 0.11498156544338498
Trained batch 126 in epoch 11, gen_loss = 0.39344200785235156, disc_loss = 0.11443153434015048
Trained batch 127 in epoch 11, gen_loss = 0.3931350725470111, disc_loss = 0.11424703977172612
Trained batch 128 in epoch 11, gen_loss = 0.3927048686169839, disc_loss = 0.11358836370830734
Trained batch 129 in epoch 11, gen_loss = 0.3932170195075182, disc_loss = 0.11300414711451874
Trained batch 130 in epoch 11, gen_loss = 0.39279915961145445, disc_loss = 0.11320052258599236
Trained batch 131 in epoch 11, gen_loss = 0.3929090941268386, disc_loss = 0.11394590661141345
Trained batch 132 in epoch 11, gen_loss = 0.39303214108585416, disc_loss = 0.11341993989338889
Trained batch 133 in epoch 11, gen_loss = 0.3928410565452789, disc_loss = 0.11317765798572618
Trained batch 134 in epoch 11, gen_loss = 0.39310511185063257, disc_loss = 0.11353145768452022
Trained batch 135 in epoch 11, gen_loss = 0.393274075954276, disc_loss = 0.11294446170316352
Trained batch 136 in epoch 11, gen_loss = 0.39247515329914373, disc_loss = 0.11258603352033635
Trained batch 137 in epoch 11, gen_loss = 0.3926239027709201, disc_loss = 0.11244931641250741
Trained batch 138 in epoch 11, gen_loss = 0.39210017690126847, disc_loss = 0.11263634164971735
Trained batch 139 in epoch 11, gen_loss = 0.3927223613219602, disc_loss = 0.1121163578670738
Trained batch 140 in epoch 11, gen_loss = 0.39291572687050974, disc_loss = 0.1115501294975955
Trained batch 141 in epoch 11, gen_loss = 0.3921306705181028, disc_loss = 0.11151907096853034
Trained batch 142 in epoch 11, gen_loss = 0.3927247218943976, disc_loss = 0.11115416938803725
Trained batch 143 in epoch 11, gen_loss = 0.39272585045546293, disc_loss = 0.1112522129195794
Trained batch 144 in epoch 11, gen_loss = 0.3925377269243372, disc_loss = 0.11262622210678869
Trained batch 145 in epoch 11, gen_loss = 0.3930123390196121, disc_loss = 0.11225809184642993
Trained batch 146 in epoch 11, gen_loss = 0.39296067034711646, disc_loss = 0.11251336434653321
Trained batch 147 in epoch 11, gen_loss = 0.3924275251055086, disc_loss = 0.11258417531231267
Trained batch 148 in epoch 11, gen_loss = 0.39246545792026005, disc_loss = 0.11197534459486803
Trained batch 149 in epoch 11, gen_loss = 0.3924782008926074, disc_loss = 0.11135067630248766
Trained batch 150 in epoch 11, gen_loss = 0.39285586300669917, disc_loss = 0.11067527917133557
Trained batch 151 in epoch 11, gen_loss = 0.39303767690925223, disc_loss = 0.11011964347103219
Trained batch 152 in epoch 11, gen_loss = 0.39305811039372984, disc_loss = 0.10995235279190287
Trained batch 153 in epoch 11, gen_loss = 0.393789862754283, disc_loss = 0.10975263872208049
Trained batch 154 in epoch 11, gen_loss = 0.3937005820774263, disc_loss = 0.10937506616295826
Trained batch 155 in epoch 11, gen_loss = 0.3933525806627212, disc_loss = 0.10890916094649583
Trained batch 156 in epoch 11, gen_loss = 0.3931242061458575, disc_loss = 0.10993871576550185
Trained batch 157 in epoch 11, gen_loss = 0.39336234548046617, disc_loss = 0.11209456499701342
Trained batch 158 in epoch 11, gen_loss = 0.39361004737563104, disc_loss = 0.11179611231815421
Trained batch 159 in epoch 11, gen_loss = 0.39314237153157594, disc_loss = 0.11131710780027788
Trained batch 160 in epoch 11, gen_loss = 0.3926903349087105, disc_loss = 0.11112929336576266
Trained batch 161 in epoch 11, gen_loss = 0.3926112978362743, disc_loss = 0.11060709702598367
Trained batch 162 in epoch 11, gen_loss = 0.39244932530482124, disc_loss = 0.11029727175043313
Trained batch 163 in epoch 11, gen_loss = 0.3922995887696743, disc_loss = 0.11036598699156014
Trained batch 164 in epoch 11, gen_loss = 0.3925494834329143, disc_loss = 0.11030299178973743
Trained batch 165 in epoch 11, gen_loss = 0.39263104019035777, disc_loss = 0.11024523538492441
Trained batch 166 in epoch 11, gen_loss = 0.3922320648046311, disc_loss = 0.11043099027048953
Trained batch 167 in epoch 11, gen_loss = 0.3918187124211164, disc_loss = 0.11047122936551682
Trained batch 168 in epoch 11, gen_loss = 0.39209910759911737, disc_loss = 0.11034454584683805
Trained batch 169 in epoch 11, gen_loss = 0.3919140122392598, disc_loss = 0.11023610890295138
Trained batch 170 in epoch 11, gen_loss = 0.3921464720838948, disc_loss = 0.10990262056335981
Trained batch 171 in epoch 11, gen_loss = 0.39186696266365606, disc_loss = 0.10948977548748168
Trained batch 172 in epoch 11, gen_loss = 0.39216705527953327, disc_loss = 0.10909505996777746
Trained batch 173 in epoch 11, gen_loss = 0.3924830834242119, disc_loss = 0.10912817916511719
Trained batch 174 in epoch 11, gen_loss = 0.39215846598148346, disc_loss = 0.10856606326731189
Trained batch 175 in epoch 11, gen_loss = 0.3916697362437844, disc_loss = 0.10867553260124457
Trained batch 176 in epoch 11, gen_loss = 0.39204302017634873, disc_loss = 0.10814489459745207
Trained batch 177 in epoch 11, gen_loss = 0.3921438476510262, disc_loss = 0.10808971551184156
Trained batch 178 in epoch 11, gen_loss = 0.39190498951760083, disc_loss = 0.10842823959085778
Trained batch 179 in epoch 11, gen_loss = 0.39284084911147754, disc_loss = 0.10825183534115139
Trained batch 180 in epoch 11, gen_loss = 0.392914064928313, disc_loss = 0.10857048303207886
Trained batch 181 in epoch 11, gen_loss = 0.392753463606913, disc_loss = 0.10939480333363863
Trained batch 182 in epoch 11, gen_loss = 0.3927353546430504, disc_loss = 0.1090123136731404
Trained batch 183 in epoch 11, gen_loss = 0.3932759237840124, disc_loss = 0.10845804789721075
Trained batch 184 in epoch 11, gen_loss = 0.39341333017155933, disc_loss = 0.1079253050146272
Trained batch 185 in epoch 11, gen_loss = 0.39340272970417495, disc_loss = 0.10744324645217788
Trained batch 186 in epoch 11, gen_loss = 0.39354720384998115, disc_loss = 0.10693531021983786
Trained batch 187 in epoch 11, gen_loss = 0.3932360237107632, disc_loss = 0.10653566886878948
Trained batch 188 in epoch 11, gen_loss = 0.3931872426044373, disc_loss = 0.10604775044327927
Trained batch 189 in epoch 11, gen_loss = 0.3932684811322313, disc_loss = 0.10559696595086471
Trained batch 190 in epoch 11, gen_loss = 0.39342431021922547, disc_loss = 0.10558110257825225
Trained batch 191 in epoch 11, gen_loss = 0.3939085412615289, disc_loss = 0.10580743066141925
Trained batch 192 in epoch 11, gen_loss = 0.39367236166111547, disc_loss = 0.10574910130322829
Trained batch 193 in epoch 11, gen_loss = 0.39382844725527716, disc_loss = 0.10584101108498103
Trained batch 194 in epoch 11, gen_loss = 0.3942074854404498, disc_loss = 0.10642879777946151
Trained batch 195 in epoch 11, gen_loss = 0.3940176219508356, disc_loss = 0.1063554267641347
Trained batch 196 in epoch 11, gen_loss = 0.3937871399415931, disc_loss = 0.10687673383813143
Trained batch 197 in epoch 11, gen_loss = 0.39378405377419307, disc_loss = 0.10799241898289759
Trained batch 198 in epoch 11, gen_loss = 0.39347763584187284, disc_loss = 0.10852009025004566
Trained batch 199 in epoch 11, gen_loss = 0.39323062904179096, disc_loss = 0.1082461858796887
Trained batch 200 in epoch 11, gen_loss = 0.39291871935870515, disc_loss = 0.1081167915673806
Trained batch 201 in epoch 11, gen_loss = 0.39280537117530806, disc_loss = 0.10777905882834134
Trained batch 202 in epoch 11, gen_loss = 0.3927593719342659, disc_loss = 0.10740171972744791
Trained batch 203 in epoch 11, gen_loss = 0.3923737465897027, disc_loss = 0.10709498106620695
Trained batch 204 in epoch 11, gen_loss = 0.39259989050830285, disc_loss = 0.10666039887497701
Trained batch 205 in epoch 11, gen_loss = 0.39254898737067156, disc_loss = 0.10634495075385186
Trained batch 206 in epoch 11, gen_loss = 0.3925404019545818, disc_loss = 0.10603765957732347
Trained batch 207 in epoch 11, gen_loss = 0.3926701308586277, disc_loss = 0.10597161713835354
Trained batch 208 in epoch 11, gen_loss = 0.3925132906180249, disc_loss = 0.10720618256104834
Trained batch 209 in epoch 11, gen_loss = 0.3927367177037966, disc_loss = 0.1069453775505757
Trained batch 210 in epoch 11, gen_loss = 0.39303029890026525, disc_loss = 0.10678924831795679
Trained batch 211 in epoch 11, gen_loss = 0.39276158071632655, disc_loss = 0.10673439730934026
Trained batch 212 in epoch 11, gen_loss = 0.3925102668608858, disc_loss = 0.1072905131117244
Trained batch 213 in epoch 11, gen_loss = 0.3927104789937768, disc_loss = 0.10689098121398172
Trained batch 214 in epoch 11, gen_loss = 0.3932177163140718, disc_loss = 0.10656519026040684
Trained batch 215 in epoch 11, gen_loss = 0.3935385325026733, disc_loss = 0.1061789484897249
Trained batch 216 in epoch 11, gen_loss = 0.39332610032250803, disc_loss = 0.10583145671614236
Trained batch 217 in epoch 11, gen_loss = 0.39311937721224005, disc_loss = 0.10557835199442957
Trained batch 218 in epoch 11, gen_loss = 0.3932695707910137, disc_loss = 0.10548548011500473
Trained batch 219 in epoch 11, gen_loss = 0.3933556890623136, disc_loss = 0.10518790692387318
Trained batch 220 in epoch 11, gen_loss = 0.3931596521203874, disc_loss = 0.10643877222822196
Trained batch 221 in epoch 11, gen_loss = 0.39332458397021164, disc_loss = 0.1060455606826623
Trained batch 222 in epoch 11, gen_loss = 0.3936367749232348, disc_loss = 0.10592267637855202
Trained batch 223 in epoch 11, gen_loss = 0.3936353053764573, disc_loss = 0.10561000935558695
Trained batch 224 in epoch 11, gen_loss = 0.39334976957903967, disc_loss = 0.1064838265772495
Trained batch 225 in epoch 11, gen_loss = 0.3933575587858141, disc_loss = 0.10712207043419832
Trained batch 226 in epoch 11, gen_loss = 0.39298702067478114, disc_loss = 0.10690167829156381
Trained batch 227 in epoch 11, gen_loss = 0.3928914771398954, disc_loss = 0.10725717881098062
Trained batch 228 in epoch 11, gen_loss = 0.39337511620927584, disc_loss = 0.10745978570750642
Trained batch 229 in epoch 11, gen_loss = 0.39346812296172845, disc_loss = 0.10710891672086133
Trained batch 230 in epoch 11, gen_loss = 0.3932877178445007, disc_loss = 0.1073234861704533
Trained batch 231 in epoch 11, gen_loss = 0.39338236796701775, disc_loss = 0.10733455312558739
Trained batch 232 in epoch 11, gen_loss = 0.39360947472087304, disc_loss = 0.10696231659158041
Trained batch 233 in epoch 11, gen_loss = 0.3938008407369638, disc_loss = 0.10679072783822115
Trained batch 234 in epoch 11, gen_loss = 0.3937464898571055, disc_loss = 0.10672820108011365
Trained batch 235 in epoch 11, gen_loss = 0.3937696275948468, disc_loss = 0.10665680738600065
Trained batch 236 in epoch 11, gen_loss = 0.3938443966932941, disc_loss = 0.10656649187670919
Trained batch 237 in epoch 11, gen_loss = 0.39406086435588467, disc_loss = 0.106728132898301
Trained batch 238 in epoch 11, gen_loss = 0.39355115729645207, disc_loss = 0.10710219264802012
Trained batch 239 in epoch 11, gen_loss = 0.3937580827002724, disc_loss = 0.1071038774428113
Trained batch 240 in epoch 11, gen_loss = 0.39368375029059366, disc_loss = 0.10690300728298754
Trained batch 241 in epoch 11, gen_loss = 0.39351152567085157, disc_loss = 0.10680496571624021
Trained batch 242 in epoch 11, gen_loss = 0.39336702981848776, disc_loss = 0.10656257788363246
Trained batch 243 in epoch 11, gen_loss = 0.39357659190160327, disc_loss = 0.10624216376903055
Trained batch 244 in epoch 11, gen_loss = 0.3937171548604965, disc_loss = 0.10594132520372466
Trained batch 245 in epoch 11, gen_loss = 0.3936504085010629, disc_loss = 0.10580505263173907
Trained batch 246 in epoch 11, gen_loss = 0.39338318134850336, disc_loss = 0.10621050297874611
Trained batch 247 in epoch 11, gen_loss = 0.39309019457188343, disc_loss = 0.10695091342636114
Trained batch 248 in epoch 11, gen_loss = 0.3933684094004842, disc_loss = 0.1066883939812072
Trained batch 249 in epoch 11, gen_loss = 0.39357877749204634, disc_loss = 0.10659525535069406
Trained batch 250 in epoch 11, gen_loss = 0.393352119155614, disc_loss = 0.10644537825471317
Trained batch 251 in epoch 11, gen_loss = 0.3930199041607834, disc_loss = 0.10641683280904082
Trained batch 252 in epoch 11, gen_loss = 0.39270429183607514, disc_loss = 0.10625079366021419
Trained batch 253 in epoch 11, gen_loss = 0.39267446352975577, disc_loss = 0.10596598094277905
Trained batch 254 in epoch 11, gen_loss = 0.3923805658139434, disc_loss = 0.10597069242092616
Trained batch 255 in epoch 11, gen_loss = 0.3923435360775329, disc_loss = 0.10613787321744894
Trained batch 256 in epoch 11, gen_loss = 0.3928114111437408, disc_loss = 0.10668437411022963
Trained batch 257 in epoch 11, gen_loss = 0.3929033028178437, disc_loss = 0.10631447389194842
Trained batch 258 in epoch 11, gen_loss = 0.39282693302539323, disc_loss = 0.10609680071696063
Trained batch 259 in epoch 11, gen_loss = 0.39275582106067586, disc_loss = 0.10577736064039457
Trained batch 260 in epoch 11, gen_loss = 0.3926413707235307, disc_loss = 0.10544927500124121
Trained batch 261 in epoch 11, gen_loss = 0.3923627061357025, disc_loss = 0.10572624657807858
Trained batch 262 in epoch 11, gen_loss = 0.3926822564107837, disc_loss = 0.1058839783550527
Trained batch 263 in epoch 11, gen_loss = 0.39286727170375263, disc_loss = 0.10550903274049757
Trained batch 264 in epoch 11, gen_loss = 0.3926639958934964, disc_loss = 0.10531437754595899
Trained batch 265 in epoch 11, gen_loss = 0.3924533330968448, disc_loss = 0.10514883869817775
Trained batch 266 in epoch 11, gen_loss = 0.3919586617960019, disc_loss = 0.10503224237937103
Trained batch 267 in epoch 11, gen_loss = 0.39188975612841437, disc_loss = 0.10501320926131986
Trained batch 268 in epoch 11, gen_loss = 0.3922553701139294, disc_loss = 0.10498502002128826
Trained batch 269 in epoch 11, gen_loss = 0.3921965076415627, disc_loss = 0.10538541684789514
Trained batch 270 in epoch 11, gen_loss = 0.3923799746920702, disc_loss = 0.1052975658640073
Trained batch 271 in epoch 11, gen_loss = 0.3926083947915365, disc_loss = 0.10510704186162911
Trained batch 272 in epoch 11, gen_loss = 0.3926663728969874, disc_loss = 0.10479422233446123
Trained batch 273 in epoch 11, gen_loss = 0.39243550005837946, disc_loss = 0.10458206599340332
Trained batch 274 in epoch 11, gen_loss = 0.3924756753986532, disc_loss = 0.10443907176059755
Trained batch 275 in epoch 11, gen_loss = 0.39241594880603364, disc_loss = 0.104205225180983
Trained batch 276 in epoch 11, gen_loss = 0.3925303818409193, disc_loss = 0.10401951652591786
Trained batch 277 in epoch 11, gen_loss = 0.39234240958802136, disc_loss = 0.1045357376360502
Trained batch 278 in epoch 11, gen_loss = 0.3924045115709305, disc_loss = 0.10488098314178834
Trained batch 279 in epoch 11, gen_loss = 0.3921644605164017, disc_loss = 0.10512702176846297
Trained batch 280 in epoch 11, gen_loss = 0.39205536347054926, disc_loss = 0.10509954108376043
Trained batch 281 in epoch 11, gen_loss = 0.39223299629933445, disc_loss = 0.1052247683917245
Trained batch 282 in epoch 11, gen_loss = 0.3922848869444203, disc_loss = 0.10501608204313755
Trained batch 283 in epoch 11, gen_loss = 0.39216516056740786, disc_loss = 0.1050491232710274
Trained batch 284 in epoch 11, gen_loss = 0.3924090691302952, disc_loss = 0.10513070533378867
Trained batch 285 in epoch 11, gen_loss = 0.3921521451402377, disc_loss = 0.10500659295227509
Trained batch 286 in epoch 11, gen_loss = 0.39185706045777124, disc_loss = 0.10536305644494263
Trained batch 287 in epoch 11, gen_loss = 0.39194125128496027, disc_loss = 0.1064931536271211
Trained batch 288 in epoch 11, gen_loss = 0.39200158417224884, disc_loss = 0.10634777851396314
Trained batch 289 in epoch 11, gen_loss = 0.39194166850427103, disc_loss = 0.10625394589653046
Trained batch 290 in epoch 11, gen_loss = 0.39174251770440655, disc_loss = 0.10678229674767331
Trained batch 291 in epoch 11, gen_loss = 0.39188295260888256, disc_loss = 0.10693810193014829
Trained batch 292 in epoch 11, gen_loss = 0.39202898288139304, disc_loss = 0.10670385464434687
Trained batch 293 in epoch 11, gen_loss = 0.3919544719210287, disc_loss = 0.10641154972994764
Trained batch 294 in epoch 11, gen_loss = 0.392028754494958, disc_loss = 0.10613361987743085
Trained batch 295 in epoch 11, gen_loss = 0.39211525058222785, disc_loss = 0.1058966495345246
Trained batch 296 in epoch 11, gen_loss = 0.39226222976490305, disc_loss = 0.10559053610389431
Trained batch 297 in epoch 11, gen_loss = 0.3924282558712383, disc_loss = 0.10547689075156697
Trained batch 298 in epoch 11, gen_loss = 0.3923564045425243, disc_loss = 0.10555164442930283
Trained batch 299 in epoch 11, gen_loss = 0.39208740894993144, disc_loss = 0.10608236920554191
Trained batch 300 in epoch 11, gen_loss = 0.39222246254995413, disc_loss = 0.10634466898519286
Trained batch 301 in epoch 11, gen_loss = 0.392237857526896, disc_loss = 0.10620078132857895
Trained batch 302 in epoch 11, gen_loss = 0.39202650078255746, disc_loss = 0.1061225877168032
Trained batch 303 in epoch 11, gen_loss = 0.3917675089385164, disc_loss = 0.1059640086497989
Trained batch 304 in epoch 11, gen_loss = 0.3918902366376314, disc_loss = 0.10640440527502386
Trained batch 305 in epoch 11, gen_loss = 0.391624322368039, disc_loss = 0.10674435843019654
Trained batch 306 in epoch 11, gen_loss = 0.39187877035490465, disc_loss = 0.10655754936118807
Trained batch 307 in epoch 11, gen_loss = 0.39189293733858444, disc_loss = 0.10685847554954567
Trained batch 308 in epoch 11, gen_loss = 0.39151919606627, disc_loss = 0.10707919902852389
Trained batch 309 in epoch 11, gen_loss = 0.3915721153539996, disc_loss = 0.10682657563367919
Trained batch 310 in epoch 11, gen_loss = 0.39156853074621156, disc_loss = 0.10690063200262151
Trained batch 311 in epoch 11, gen_loss = 0.3912859983646717, disc_loss = 0.1067078296521989
Trained batch 312 in epoch 11, gen_loss = 0.39119746981146997, disc_loss = 0.10661083848301928
Trained batch 313 in epoch 11, gen_loss = 0.39104442151298946, disc_loss = 0.1063204445345268
Trained batch 314 in epoch 11, gen_loss = 0.3909380948259717, disc_loss = 0.10612126439070654
Trained batch 315 in epoch 11, gen_loss = 0.39069957969875274, disc_loss = 0.10629228405106247
Trained batch 316 in epoch 11, gen_loss = 0.39066810849525196, disc_loss = 0.10646885315438127
Trained batch 317 in epoch 11, gen_loss = 0.39068573061962547, disc_loss = 0.10634733829500868
Trained batch 318 in epoch 11, gen_loss = 0.3904542096636512, disc_loss = 0.10623936377740159
Trained batch 319 in epoch 11, gen_loss = 0.390553113585338, disc_loss = 0.10616905637289165
Trained batch 320 in epoch 11, gen_loss = 0.3902634405922667, disc_loss = 0.10626010883837428
Trained batch 321 in epoch 11, gen_loss = 0.3902219072539614, disc_loss = 0.105972821941391
Trained batch 322 in epoch 11, gen_loss = 0.39044566046527296, disc_loss = 0.10574257089655512
Trained batch 323 in epoch 11, gen_loss = 0.39041047603075885, disc_loss = 0.10558862620418501
Trained batch 324 in epoch 11, gen_loss = 0.39050566668693837, disc_loss = 0.10577457381698947
Trained batch 325 in epoch 11, gen_loss = 0.3908095282553895, disc_loss = 0.10660260001146035
Trained batch 326 in epoch 11, gen_loss = 0.39100349710439686, disc_loss = 0.10634514662815936
Trained batch 327 in epoch 11, gen_loss = 0.39093534144141323, disc_loss = 0.10646454191045472
Trained batch 328 in epoch 11, gen_loss = 0.39092575819840186, disc_loss = 0.10635007178059873
Trained batch 329 in epoch 11, gen_loss = 0.3911541104768262, disc_loss = 0.10614155809338571
Trained batch 330 in epoch 11, gen_loss = 0.39116025308647906, disc_loss = 0.1059463649180653
Trained batch 331 in epoch 11, gen_loss = 0.39133544306618623, disc_loss = 0.10585589986995805
Trained batch 332 in epoch 11, gen_loss = 0.39150935281683374, disc_loss = 0.10616269543929188
Trained batch 333 in epoch 11, gen_loss = 0.3913605525911211, disc_loss = 0.10601224251297821
Trained batch 334 in epoch 11, gen_loss = 0.39154386720550594, disc_loss = 0.1058302262895254
Trained batch 335 in epoch 11, gen_loss = 0.39164914798346306, disc_loss = 0.10581686080106356
Trained batch 336 in epoch 11, gen_loss = 0.3914542161480963, disc_loss = 0.10589336666474755
Trained batch 337 in epoch 11, gen_loss = 0.3916355028043132, disc_loss = 0.10591690617712689
Trained batch 338 in epoch 11, gen_loss = 0.3916372906054016, disc_loss = 0.10570322250353947
Trained batch 339 in epoch 11, gen_loss = 0.39148851909181653, disc_loss = 0.10552729292197481
Trained batch 340 in epoch 11, gen_loss = 0.39156348994575285, disc_loss = 0.10532986965505652
Trained batch 341 in epoch 11, gen_loss = 0.39142173088607735, disc_loss = 0.10526733083666809
Trained batch 342 in epoch 11, gen_loss = 0.3914183302193272, disc_loss = 0.10515402614358954
Trained batch 343 in epoch 11, gen_loss = 0.3914474664299294, disc_loss = 0.10514744423833394
Trained batch 344 in epoch 11, gen_loss = 0.3916786084572474, disc_loss = 0.10531733827125551
Trained batch 345 in epoch 11, gen_loss = 0.3915790699723828, disc_loss = 0.1050446017556474
Trained batch 346 in epoch 11, gen_loss = 0.3914845864522011, disc_loss = 0.10488010926966579
Trained batch 347 in epoch 11, gen_loss = 0.3912956401620103, disc_loss = 0.10475533760832516
Trained batch 348 in epoch 11, gen_loss = 0.3915015307487253, disc_loss = 0.10471951561368853
Trained batch 349 in epoch 11, gen_loss = 0.39154153002159936, disc_loss = 0.10448785812860088
Trained batch 350 in epoch 11, gen_loss = 0.3913981475976118, disc_loss = 0.10440036059195372
Trained batch 351 in epoch 11, gen_loss = 0.3912817020053891, disc_loss = 0.10438702908603856
Trained batch 352 in epoch 11, gen_loss = 0.39136879357163695, disc_loss = 0.10479707607640634
Trained batch 353 in epoch 11, gen_loss = 0.39138117007448175, disc_loss = 0.10454719277535497
Trained batch 354 in epoch 11, gen_loss = 0.3911170513277322, disc_loss = 0.10500841816152695
Trained batch 355 in epoch 11, gen_loss = 0.39129528993468604, disc_loss = 0.10542773827518012
Trained batch 356 in epoch 11, gen_loss = 0.39122132681498006, disc_loss = 0.10533824387327337
Trained batch 357 in epoch 11, gen_loss = 0.3912522243804106, disc_loss = 0.10514800625790806
Trained batch 358 in epoch 11, gen_loss = 0.3912838826521525, disc_loss = 0.10491796533776898
Trained batch 359 in epoch 11, gen_loss = 0.3913283134914107, disc_loss = 0.10473629886724262
Trained batch 360 in epoch 11, gen_loss = 0.3916006700401491, disc_loss = 0.10475072562513961
Trained batch 361 in epoch 11, gen_loss = 0.39149755844589096, disc_loss = 0.10462054517248759
Trained batch 362 in epoch 11, gen_loss = 0.3914329207222652, disc_loss = 0.10441090604392991
Trained batch 363 in epoch 11, gen_loss = 0.39136676330651554, disc_loss = 0.10426777612116024
Trained batch 364 in epoch 11, gen_loss = 0.3915178887239874, disc_loss = 0.1040860260760233
Trained batch 365 in epoch 11, gen_loss = 0.39170740312728725, disc_loss = 0.10409749355905083
Trained batch 366 in epoch 11, gen_loss = 0.39154340781535374, disc_loss = 0.10448858998233722
Trained batch 367 in epoch 11, gen_loss = 0.3918086639807924, disc_loss = 0.10437679496902527
Trained batch 368 in epoch 11, gen_loss = 0.3918908404383233, disc_loss = 0.10417643962882278
Trained batch 369 in epoch 11, gen_loss = 0.39177970696945447, disc_loss = 0.1041059549004343
Trained batch 370 in epoch 11, gen_loss = 0.39176330110936797, disc_loss = 0.10511063198079518
Trained batch 371 in epoch 11, gen_loss = 0.39146923253773364, disc_loss = 0.10573977170016376
Trained batch 372 in epoch 11, gen_loss = 0.39145154212339317, disc_loss = 0.10562627003640536
Trained batch 373 in epoch 11, gen_loss = 0.3915740896594078, disc_loss = 0.10561266878276147
Trained batch 374 in epoch 11, gen_loss = 0.39138569207986196, disc_loss = 0.10544577670221528
Trained batch 375 in epoch 11, gen_loss = 0.39118510758147595, disc_loss = 0.10574035310964199
Trained batch 376 in epoch 11, gen_loss = 0.3915135402341104, disc_loss = 0.10564907401212212
Trained batch 377 in epoch 11, gen_loss = 0.3916645562916836, disc_loss = 0.10543602487816421
Trained batch 378 in epoch 11, gen_loss = 0.39175170278643556, disc_loss = 0.10523763108914988
Trained batch 379 in epoch 11, gen_loss = 0.39182864815780993, disc_loss = 0.10523148805123607
Trained batch 380 in epoch 11, gen_loss = 0.39216960536369816, disc_loss = 0.1052140216367549
Trained batch 381 in epoch 11, gen_loss = 0.39227299123066256, disc_loss = 0.10512033844712868
Trained batch 382 in epoch 11, gen_loss = 0.39205242366610243, disc_loss = 0.10527611824054048
Trained batch 383 in epoch 11, gen_loss = 0.39197493899458397, disc_loss = 0.10535390522394057
Trained batch 384 in epoch 11, gen_loss = 0.3918534014519159, disc_loss = 0.10571754546352215
Trained batch 385 in epoch 11, gen_loss = 0.39215205343430526, disc_loss = 0.1055050851268105
Trained batch 386 in epoch 11, gen_loss = 0.3922128317353029, disc_loss = 0.10553850350631955
Trained batch 387 in epoch 11, gen_loss = 0.3923665762485303, disc_loss = 0.10540779556757435
Trained batch 388 in epoch 11, gen_loss = 0.3922932917553845, disc_loss = 0.10549550183275404
Trained batch 389 in epoch 11, gen_loss = 0.3926331300383959, disc_loss = 0.10547143818500142
Trained batch 390 in epoch 11, gen_loss = 0.3927143057975013, disc_loss = 0.10528454827287656
Trained batch 391 in epoch 11, gen_loss = 0.3925253928696014, disc_loss = 0.10554569745460068
Trained batch 392 in epoch 11, gen_loss = 0.3927070266797039, disc_loss = 0.10553312852016576
Trained batch 393 in epoch 11, gen_loss = 0.3926213079221963, disc_loss = 0.10536138254435269
Trained batch 394 in epoch 11, gen_loss = 0.39256961213637004, disc_loss = 0.10527750173159227
Trained batch 395 in epoch 11, gen_loss = 0.39250770764368953, disc_loss = 0.105164861133689
Trained batch 396 in epoch 11, gen_loss = 0.39247607235193854, disc_loss = 0.10569294370940747
Trained batch 397 in epoch 11, gen_loss = 0.39235340706517347, disc_loss = 0.10608822451413015
Trained batch 398 in epoch 11, gen_loss = 0.39258169100846263, disc_loss = 0.10600404435404598
Trained batch 399 in epoch 11, gen_loss = 0.39264456208795306, disc_loss = 0.10586399277322926
Trained batch 400 in epoch 11, gen_loss = 0.3926843264676686, disc_loss = 0.10574928458032205
Trained batch 401 in epoch 11, gen_loss = 0.39251728552342646, disc_loss = 0.1056903439136083
Trained batch 402 in epoch 11, gen_loss = 0.392307032315666, disc_loss = 0.10574437005482337
Trained batch 403 in epoch 11, gen_loss = 0.3924282189864333, disc_loss = 0.10553235569530821
Trained batch 404 in epoch 11, gen_loss = 0.39233688627496177, disc_loss = 0.10530246835500921
Trained batch 405 in epoch 11, gen_loss = 0.3924332771615442, disc_loss = 0.10509592455151157
Trained batch 406 in epoch 11, gen_loss = 0.39259994216720945, disc_loss = 0.1048567934529238
Trained batch 407 in epoch 11, gen_loss = 0.39279440691804185, disc_loss = 0.10476651479371403
Trained batch 408 in epoch 11, gen_loss = 0.3927199951666783, disc_loss = 0.1050283976450271
Trained batch 409 in epoch 11, gen_loss = 0.3928753956425481, disc_loss = 0.10499061635218379
Trained batch 410 in epoch 11, gen_loss = 0.39303148412791483, disc_loss = 0.10483960865559441
Trained batch 411 in epoch 11, gen_loss = 0.39300913584319136, disc_loss = 0.10476307146187908
Trained batch 412 in epoch 11, gen_loss = 0.39300604142952195, disc_loss = 0.10456884800079876
Trained batch 413 in epoch 11, gen_loss = 0.3929932227241244, disc_loss = 0.10446139627275763
Trained batch 414 in epoch 11, gen_loss = 0.392787643118077, disc_loss = 0.10437814597579011
Trained batch 415 in epoch 11, gen_loss = 0.392754923659735, disc_loss = 0.10426150340936147
Trained batch 416 in epoch 11, gen_loss = 0.3927898319433633, disc_loss = 0.10455894144810289
Trained batch 417 in epoch 11, gen_loss = 0.3927357172923225, disc_loss = 0.10516173114251506
Trained batch 418 in epoch 11, gen_loss = 0.3929393904946015, disc_loss = 0.10500107539110863
Trained batch 419 in epoch 11, gen_loss = 0.3930328018963337, disc_loss = 0.10520397169914629
Trained batch 420 in epoch 11, gen_loss = 0.3928956627633396, disc_loss = 0.10514989409224083
Trained batch 421 in epoch 11, gen_loss = 0.39283580227062037, disc_loss = 0.10506273882675439
Trained batch 422 in epoch 11, gen_loss = 0.3928479651257783, disc_loss = 0.10516491270542638
Trained batch 423 in epoch 11, gen_loss = 0.39273557991211144, disc_loss = 0.10502665090805166
Trained batch 424 in epoch 11, gen_loss = 0.3926718853852328, disc_loss = 0.10480933213716044
Trained batch 425 in epoch 11, gen_loss = 0.3927041497518759, disc_loss = 0.10464253176677045
Trained batch 426 in epoch 11, gen_loss = 0.392650268919574, disc_loss = 0.10447683581205595
Trained batch 427 in epoch 11, gen_loss = 0.39268170056916846, disc_loss = 0.10432399708177094
Trained batch 428 in epoch 11, gen_loss = 0.3926230665200796, disc_loss = 0.10468410274843166
Trained batch 429 in epoch 11, gen_loss = 0.3923590890543405, disc_loss = 0.10549560130118978
Trained batch 430 in epoch 11, gen_loss = 0.3923161045373731, disc_loss = 0.10554688985474632
Trained batch 431 in epoch 11, gen_loss = 0.39268013217520936, disc_loss = 0.1057257752637034
Trained batch 432 in epoch 11, gen_loss = 0.39262999793811426, disc_loss = 0.10562663062262687
Trained batch 433 in epoch 11, gen_loss = 0.39260227384243146, disc_loss = 0.10607028106862705
Trained batch 434 in epoch 11, gen_loss = 0.39275795539905284, disc_loss = 0.10615635925111756
Trained batch 435 in epoch 11, gen_loss = 0.39265582652403674, disc_loss = 0.1060904825101991
Trained batch 436 in epoch 11, gen_loss = 0.39274375543032414, disc_loss = 0.10623346069439803
Trained batch 437 in epoch 11, gen_loss = 0.3928590843190341, disc_loss = 0.10627409405623602
Trained batch 438 in epoch 11, gen_loss = 0.3928914743906273, disc_loss = 0.10624844770759752
Trained batch 439 in epoch 11, gen_loss = 0.39278450340709903, disc_loss = 0.10625041331884197
Trained batch 440 in epoch 11, gen_loss = 0.3928552980528397, disc_loss = 0.10630791519225792
Trained batch 441 in epoch 11, gen_loss = 0.3929517688187539, disc_loss = 0.10623744696302853
Trained batch 442 in epoch 11, gen_loss = 0.3930117651719272, disc_loss = 0.10608858742770103
Trained batch 443 in epoch 11, gen_loss = 0.39310782124196086, disc_loss = 0.10606509055900346
Trained batch 444 in epoch 11, gen_loss = 0.39305147739608637, disc_loss = 0.10616750889405441
Trained batch 445 in epoch 11, gen_loss = 0.3929078768387504, disc_loss = 0.10680423661724
Trained batch 446 in epoch 11, gen_loss = 0.3930595513491556, disc_loss = 0.1066540965843754
Trained batch 447 in epoch 11, gen_loss = 0.3931256752527718, disc_loss = 0.10658423620666976
Trained batch 448 in epoch 11, gen_loss = 0.3930365873007042, disc_loss = 0.10650936772793797
Trained batch 449 in epoch 11, gen_loss = 0.3929694636331664, disc_loss = 0.10640711451363233
Trained batch 450 in epoch 11, gen_loss = 0.3929363441903417, disc_loss = 0.10638879054327167
Trained batch 451 in epoch 11, gen_loss = 0.39296892704030056, disc_loss = 0.10648605345946167
Trained batch 452 in epoch 11, gen_loss = 0.39291647277262565, disc_loss = 0.10661895638722392
Trained batch 453 in epoch 11, gen_loss = 0.39306884423095223, disc_loss = 0.10644461969241893
Trained batch 454 in epoch 11, gen_loss = 0.3929749734781601, disc_loss = 0.10635759903957229
Trained batch 455 in epoch 11, gen_loss = 0.3929824052345857, disc_loss = 0.10621642870134101
Trained batch 456 in epoch 11, gen_loss = 0.39298946535952506, disc_loss = 0.10622377308692857
Trained batch 457 in epoch 11, gen_loss = 0.3927282907361547, disc_loss = 0.10645078688526453
Trained batch 458 in epoch 11, gen_loss = 0.3925633209398369, disc_loss = 0.10657822517454948
Testing Epoch 11
Training Epoch 12
Trained batch 0 in epoch 12, gen_loss = 0.46198418736457825, disc_loss = 0.016864296048879623
Trained batch 1 in epoch 12, gen_loss = 0.3851612061262131, disc_loss = 0.04691067896783352
Trained batch 2 in epoch 12, gen_loss = 0.37709381182988483, disc_loss = 0.04969670375188192
Trained batch 3 in epoch 12, gen_loss = 0.3797645717859268, disc_loss = 0.06392821669578552
Trained batch 4 in epoch 12, gen_loss = 0.37881978750228884, disc_loss = 0.0706171840429306
Trained batch 5 in epoch 12, gen_loss = 0.3754148830970128, disc_loss = 0.07741850366195042
Trained batch 6 in epoch 12, gen_loss = 0.3836407959461212, disc_loss = 0.0868183182818549
Trained batch 7 in epoch 12, gen_loss = 0.3761930614709854, disc_loss = 0.09681464917957783
Trained batch 8 in epoch 12, gen_loss = 0.3918562200334337, disc_loss = 0.10551485419273376
Trained batch 9 in epoch 12, gen_loss = 0.38896001875400543, disc_loss = 0.10009205415844917
Trained batch 10 in epoch 12, gen_loss = 0.38454258712855255, disc_loss = 0.0964992002330043
Trained batch 11 in epoch 12, gen_loss = 0.38151417672634125, disc_loss = 0.09474663902074099
Trained batch 12 in epoch 12, gen_loss = 0.382702683026974, disc_loss = 0.09140792660988294
Trained batch 13 in epoch 12, gen_loss = 0.3921069311244147, disc_loss = 0.09003596273916108
Trained batch 14 in epoch 12, gen_loss = 0.39517722129821775, disc_loss = 0.08683674857020378
Trained batch 15 in epoch 12, gen_loss = 0.3987227138131857, disc_loss = 0.08847039681859314
Trained batch 16 in epoch 12, gen_loss = 0.3968523407683653, disc_loss = 0.09239707733778392
Trained batch 17 in epoch 12, gen_loss = 0.40281127724382615, disc_loss = 0.0920430804706282
Trained batch 18 in epoch 12, gen_loss = 0.4072797439600292, disc_loss = 0.09009580412193348
Trained batch 19 in epoch 12, gen_loss = 0.4051224872469902, disc_loss = 0.08942202758044004
Trained batch 20 in epoch 12, gen_loss = 0.40334675851322355, disc_loss = 0.0870213813724972
Trained batch 21 in epoch 12, gen_loss = 0.40132392130114813, disc_loss = 0.08500818434086713
Trained batch 22 in epoch 12, gen_loss = 0.4046369609625443, disc_loss = 0.08482516621765883
Trained batch 23 in epoch 12, gen_loss = 0.40471700703104335, disc_loss = 0.09345646606137355
Trained batch 24 in epoch 12, gen_loss = 0.4087463343143463, disc_loss = 0.10555057555437088
Trained batch 25 in epoch 12, gen_loss = 0.4093407186178061, disc_loss = 0.1022004048841504
Trained batch 26 in epoch 12, gen_loss = 0.4074682416739287, disc_loss = 0.10442318953573704
Trained batch 27 in epoch 12, gen_loss = 0.40760610571929384, disc_loss = 0.10204262785347444
Trained batch 28 in epoch 12, gen_loss = 0.40623803077072934, disc_loss = 0.10074269456853127
Trained batch 29 in epoch 12, gen_loss = 0.40516236126422883, disc_loss = 0.10145007738222679
Trained batch 30 in epoch 12, gen_loss = 0.40535514200887374, disc_loss = 0.10168545831355356
Trained batch 31 in epoch 12, gen_loss = 0.40314517728984356, disc_loss = 0.09987543715396896
Trained batch 32 in epoch 12, gen_loss = 0.4011697769165039, disc_loss = 0.09767387406618307
Trained batch 33 in epoch 12, gen_loss = 0.40189169610247893, disc_loss = 0.0967553617870983
Trained batch 34 in epoch 12, gen_loss = 0.4000829747744969, disc_loss = 0.09605551069336278
Trained batch 35 in epoch 12, gen_loss = 0.4002632664309608, disc_loss = 0.09533155445630352
Trained batch 36 in epoch 12, gen_loss = 0.40219554143982966, disc_loss = 0.09740259221478088
Trained batch 37 in epoch 12, gen_loss = 0.4021966559322257, disc_loss = 0.0955061343449511
Trained batch 38 in epoch 12, gen_loss = 0.40150375473193634, disc_loss = 0.09386589067677657
Trained batch 39 in epoch 12, gen_loss = 0.40351119041442873, disc_loss = 0.0919966057408601
Trained batch 40 in epoch 12, gen_loss = 0.40359373281641703, disc_loss = 0.09046955247659509
Trained batch 41 in epoch 12, gen_loss = 0.4047289959021977, disc_loss = 0.09022843309988578
Trained batch 42 in epoch 12, gen_loss = 0.4049186644166015, disc_loss = 0.08949699863618196
Trained batch 43 in epoch 12, gen_loss = 0.4050611487843774, disc_loss = 0.08810087361119011
Trained batch 44 in epoch 12, gen_loss = 0.4046122352282206, disc_loss = 0.08827094982067744
Trained batch 45 in epoch 12, gen_loss = 0.40558735443198163, disc_loss = 0.08753873302560786
Trained batch 46 in epoch 12, gen_loss = 0.4049426818147619, disc_loss = 0.08665165059426998
Trained batch 47 in epoch 12, gen_loss = 0.40379570859173936, disc_loss = 0.08547587836316477
Trained batch 48 in epoch 12, gen_loss = 0.40379807839588244, disc_loss = 0.08431471439496595
Trained batch 49 in epoch 12, gen_loss = 0.4039110815525055, disc_loss = 0.08448942821472884
Trained batch 50 in epoch 12, gen_loss = 0.4040551729062024, disc_loss = 0.085059796149532
Trained batch 51 in epoch 12, gen_loss = 0.4058980425963035, disc_loss = 0.08465046460668628
Trained batch 52 in epoch 12, gen_loss = 0.40805566535805754, disc_loss = 0.08451241729253868
Trained batch 53 in epoch 12, gen_loss = 0.4077510072125329, disc_loss = 0.0870282227449395
Trained batch 54 in epoch 12, gen_loss = 0.4094539067961953, disc_loss = 0.08875398686663671
Trained batch 55 in epoch 12, gen_loss = 0.40935307794383596, disc_loss = 0.08771732875279017
Trained batch 56 in epoch 12, gen_loss = 0.41150064060562536, disc_loss = 0.08647651075009714
Trained batch 57 in epoch 12, gen_loss = 0.41135559873334293, disc_loss = 0.08539669241370826
Trained batch 58 in epoch 12, gen_loss = 0.41155845280420983, disc_loss = 0.08422991216687833
Trained batch 59 in epoch 12, gen_loss = 0.41144438534975053, disc_loss = 0.08297171141020954
Trained batch 60 in epoch 12, gen_loss = 0.4117559634271215, disc_loss = 0.0818098131414564
Trained batch 61 in epoch 12, gen_loss = 0.4104645780978664, disc_loss = 0.08060165799613442
Trained batch 62 in epoch 12, gen_loss = 0.4098916228801485, disc_loss = 0.07955642040109351
Trained batch 63 in epoch 12, gen_loss = 0.4093569219112396, disc_loss = 0.07867828353482764
Trained batch 64 in epoch 12, gen_loss = 0.4080714317468496, disc_loss = 0.07792785813888678
Trained batch 65 in epoch 12, gen_loss = 0.4070055268027566, disc_loss = 0.07729528622814652
Trained batch 66 in epoch 12, gen_loss = 0.4067648702592992, disc_loss = 0.07715117668649599
Trained batch 67 in epoch 12, gen_loss = 0.40579763142501607, disc_loss = 0.07711848204352838
Trained batch 68 in epoch 12, gen_loss = 0.4057048045206761, disc_loss = 0.07935442876718614
Trained batch 69 in epoch 12, gen_loss = 0.40499658031123026, disc_loss = 0.08219619950811778
Trained batch 70 in epoch 12, gen_loss = 0.40559709072113037, disc_loss = 0.08484374851145794
Trained batch 71 in epoch 12, gen_loss = 0.40518686837620205, disc_loss = 0.08400744216568354
Trained batch 72 in epoch 12, gen_loss = 0.40493877334137485, disc_loss = 0.08351262124280816
Trained batch 73 in epoch 12, gen_loss = 0.4057531332647478, disc_loss = 0.08290422321423083
Trained batch 74 in epoch 12, gen_loss = 0.4049943534533183, disc_loss = 0.08267097638299067
Trained batch 75 in epoch 12, gen_loss = 0.40515388862082835, disc_loss = 0.08308497930288707
Trained batch 76 in epoch 12, gen_loss = 0.4057108043850242, disc_loss = 0.08446541173359404
Trained batch 77 in epoch 12, gen_loss = 0.40597670315167844, disc_loss = 0.08359555726966415
Trained batch 78 in epoch 12, gen_loss = 0.4043546760384041, disc_loss = 0.08465211563802595
Trained batch 79 in epoch 12, gen_loss = 0.40499640814960003, disc_loss = 0.08791466838447377
Trained batch 80 in epoch 12, gen_loss = 0.40485298486403476, disc_loss = 0.08725330784318992
Trained batch 81 in epoch 12, gen_loss = 0.40401611458964465, disc_loss = 0.08740495425853424
Trained batch 82 in epoch 12, gen_loss = 0.40334581610668135, disc_loss = 0.08677331608417163
Trained batch 83 in epoch 12, gen_loss = 0.40403008177166894, disc_loss = 0.08686593590703394
Trained batch 84 in epoch 12, gen_loss = 0.40459773961235496, disc_loss = 0.08664637250716195
Trained batch 85 in epoch 12, gen_loss = 0.4039386049952618, disc_loss = 0.08587395238451832
Trained batch 86 in epoch 12, gen_loss = 0.4045510572948675, disc_loss = 0.085952111305776
Trained batch 87 in epoch 12, gen_loss = 0.40356244214556436, disc_loss = 0.08656475484498184
Trained batch 88 in epoch 12, gen_loss = 0.40415285176105714, disc_loss = 0.08571582489510936
Trained batch 89 in epoch 12, gen_loss = 0.4045125580496258, disc_loss = 0.08772100534083115
Trained batch 90 in epoch 12, gen_loss = 0.4031156972869412, disc_loss = 0.08914082924129216
Trained batch 91 in epoch 12, gen_loss = 0.4030977665730145, disc_loss = 0.08872413522887813
Trained batch 92 in epoch 12, gen_loss = 0.4026426983776913, disc_loss = 0.08852004797588434
Trained batch 93 in epoch 12, gen_loss = 0.40217439481552614, disc_loss = 0.08818348093909469
Trained batch 94 in epoch 12, gen_loss = 0.40149572962208796, disc_loss = 0.0878862670475715
Trained batch 95 in epoch 12, gen_loss = 0.4009160030012329, disc_loss = 0.08774218313434783
Trained batch 96 in epoch 12, gen_loss = 0.4010667929944304, disc_loss = 0.08705670955907746
Trained batch 97 in epoch 12, gen_loss = 0.40159142078185567, disc_loss = 0.08664804348265942
Trained batch 98 in epoch 12, gen_loss = 0.40103483651623584, disc_loss = 0.08661545753817666
Trained batch 99 in epoch 12, gen_loss = 0.4018154439330101, disc_loss = 0.08615243234671652
Trained batch 100 in epoch 12, gen_loss = 0.4017101009883503, disc_loss = 0.09074949429803851
Trained batch 101 in epoch 12, gen_loss = 0.4007587619856292, disc_loss = 0.09149110690672316
Trained batch 102 in epoch 12, gen_loss = 0.40033211436086485, disc_loss = 0.09122693763810744
Trained batch 103 in epoch 12, gen_loss = 0.3998713934650788, disc_loss = 0.09100924920326528
Trained batch 104 in epoch 12, gen_loss = 0.4001713630698976, disc_loss = 0.09053896542283751
Trained batch 105 in epoch 12, gen_loss = 0.3998077615814389, disc_loss = 0.09048722112410755
Trained batch 106 in epoch 12, gen_loss = 0.39954873947339636, disc_loss = 0.09013068568936297
Trained batch 107 in epoch 12, gen_loss = 0.3987822253946905, disc_loss = 0.08967010350035573
Trained batch 108 in epoch 12, gen_loss = 0.39936349944237176, disc_loss = 0.08893829923328184
Trained batch 109 in epoch 12, gen_loss = 0.39862876778299156, disc_loss = 0.08852241253480315
Trained batch 110 in epoch 12, gen_loss = 0.39851094930021613, disc_loss = 0.08835773939384264
Trained batch 111 in epoch 12, gen_loss = 0.3980132067309959, disc_loss = 0.08795746795866373
Trained batch 112 in epoch 12, gen_loss = 0.39751941203016095, disc_loss = 0.08818522300900875
Trained batch 113 in epoch 12, gen_loss = 0.39694475735488693, disc_loss = 0.0893972094595563
Trained batch 114 in epoch 12, gen_loss = 0.3973112124463786, disc_loss = 0.09027986844758625
Trained batch 115 in epoch 12, gen_loss = 0.39768631781997354, disc_loss = 0.0898949367491978
Trained batch 116 in epoch 12, gen_loss = 0.3976443185765519, disc_loss = 0.08970850410783647
Trained batch 117 in epoch 12, gen_loss = 0.3983525654016915, disc_loss = 0.08963002413669127
Trained batch 118 in epoch 12, gen_loss = 0.39860561214575246, disc_loss = 0.08901996476215725
Trained batch 119 in epoch 12, gen_loss = 0.3991425742705663, disc_loss = 0.08919807229346285
Trained batch 120 in epoch 12, gen_loss = 0.3999963466786156, disc_loss = 0.0894578526350708
Trained batch 121 in epoch 12, gen_loss = 0.4001649554635658, disc_loss = 0.08903235032940741
Trained batch 122 in epoch 12, gen_loss = 0.39977087625643104, disc_loss = 0.08863106067860271
Trained batch 123 in epoch 12, gen_loss = 0.39873477984820643, disc_loss = 0.08813237636950949
Trained batch 124 in epoch 12, gen_loss = 0.3989113893508911, disc_loss = 0.08770654083043337
Trained batch 125 in epoch 12, gen_loss = 0.39811000724633533, disc_loss = 0.08753797838405247
Trained batch 126 in epoch 12, gen_loss = 0.39814494163032593, disc_loss = 0.08716890427804604
Trained batch 127 in epoch 12, gen_loss = 0.3982831984758377, disc_loss = 0.08701300971006276
Trained batch 128 in epoch 12, gen_loss = 0.39798995505931767, disc_loss = 0.08732034694114628
Trained batch 129 in epoch 12, gen_loss = 0.39814710021018984, disc_loss = 0.08738828181790617
Trained batch 130 in epoch 12, gen_loss = 0.39837645005633815, disc_loss = 0.08692575839724932
Trained batch 131 in epoch 12, gen_loss = 0.3983223456324953, disc_loss = 0.08643040921059296
Trained batch 132 in epoch 12, gen_loss = 0.39782348409631196, disc_loss = 0.08653829691413426
Trained batch 133 in epoch 12, gen_loss = 0.3980470353098058, disc_loss = 0.086557303812466
Trained batch 134 in epoch 12, gen_loss = 0.39837704764472115, disc_loss = 0.0874456922420197
Trained batch 135 in epoch 12, gen_loss = 0.3986689584220157, disc_loss = 0.08717062879655071
Trained batch 136 in epoch 12, gen_loss = 0.39870009043791, disc_loss = 0.08709173096874118
Trained batch 137 in epoch 12, gen_loss = 0.39851217403791955, disc_loss = 0.08678203259014348
Trained batch 138 in epoch 12, gen_loss = 0.39839198799442044, disc_loss = 0.08662230536850879
Trained batch 139 in epoch 12, gen_loss = 0.3994588177118983, disc_loss = 0.08627370145571019
Trained batch 140 in epoch 12, gen_loss = 0.3993074424723361, disc_loss = 0.08589231251270002
Trained batch 141 in epoch 12, gen_loss = 0.3996687959617292, disc_loss = 0.08600177617848549
Trained batch 142 in epoch 12, gen_loss = 0.3998120154117371, disc_loss = 0.08591942470260225
Trained batch 143 in epoch 12, gen_loss = 0.4000868573784828, disc_loss = 0.08551666601690361
Trained batch 144 in epoch 12, gen_loss = 0.39981645921180986, disc_loss = 0.08585398973704413
Trained batch 145 in epoch 12, gen_loss = 0.39850109305283793, disc_loss = 0.08734535186691847
Trained batch 146 in epoch 12, gen_loss = 0.3984054243888985, disc_loss = 0.08719222445902573
Trained batch 147 in epoch 12, gen_loss = 0.39854526721142436, disc_loss = 0.08718081836185947
Trained batch 148 in epoch 12, gen_loss = 0.39902111727919354, disc_loss = 0.08709464067805733
Trained batch 149 in epoch 12, gen_loss = 0.39908247788747153, disc_loss = 0.08715186402822535
Trained batch 150 in epoch 12, gen_loss = 0.39915607346604204, disc_loss = 0.0877566168405461
Trained batch 151 in epoch 12, gen_loss = 0.3991096653044224, disc_loss = 0.08790022360871692
Trained batch 152 in epoch 12, gen_loss = 0.39875897550894546, disc_loss = 0.08753406707489607
Trained batch 153 in epoch 12, gen_loss = 0.398233465947114, disc_loss = 0.08756751928164007
Trained batch 154 in epoch 12, gen_loss = 0.39855955070064913, disc_loss = 0.08737451999538368
Trained batch 155 in epoch 12, gen_loss = 0.3980371401860164, disc_loss = 0.08775435854346515
Trained batch 156 in epoch 12, gen_loss = 0.39775882670833806, disc_loss = 0.08968261746203254
Trained batch 157 in epoch 12, gen_loss = 0.3978705734391756, disc_loss = 0.08922347155859388
Trained batch 158 in epoch 12, gen_loss = 0.39847458046187395, disc_loss = 0.08913065561638125
Trained batch 159 in epoch 12, gen_loss = 0.3978588193655014, disc_loss = 0.08953739388962276
Trained batch 160 in epoch 12, gen_loss = 0.39825978153240604, disc_loss = 0.08924894181213208
Trained batch 161 in epoch 12, gen_loss = 0.3988341275188658, disc_loss = 0.08935618417245554
Trained batch 162 in epoch 12, gen_loss = 0.3985455577358878, disc_loss = 0.08975103413514747
Trained batch 163 in epoch 12, gen_loss = 0.3988354435054267, disc_loss = 0.08964658345141244
Trained batch 164 in epoch 12, gen_loss = 0.3987030773451834, disc_loss = 0.089461104983859
Trained batch 165 in epoch 12, gen_loss = 0.398496076464653, disc_loss = 0.0898170910203403
Trained batch 166 in epoch 12, gen_loss = 0.3988264015691723, disc_loss = 0.08958635479769485
Trained batch 167 in epoch 12, gen_loss = 0.39912195698845954, disc_loss = 0.08925233480320978
Trained batch 168 in epoch 12, gen_loss = 0.39967441717548485, disc_loss = 0.08909022857120932
Trained batch 169 in epoch 12, gen_loss = 0.40009998731753404, disc_loss = 0.08906443566631744
Trained batch 170 in epoch 12, gen_loss = 0.40023206496796415, disc_loss = 0.08875961889845063
Trained batch 171 in epoch 12, gen_loss = 0.40021548853364103, disc_loss = 0.08869581587807557
Trained batch 172 in epoch 12, gen_loss = 0.3999090406591493, disc_loss = 0.08907278438201012
Trained batch 173 in epoch 12, gen_loss = 0.40047551348976707, disc_loss = 0.09011133079920178
Trained batch 174 in epoch 12, gen_loss = 0.4011098185607365, disc_loss = 0.08969452288001775
Trained batch 175 in epoch 12, gen_loss = 0.4007396657358516, disc_loss = 0.08959636350945485
Trained batch 176 in epoch 12, gen_loss = 0.40090820327990473, disc_loss = 0.08919578374463455
Trained batch 177 in epoch 12, gen_loss = 0.40115893975402533, disc_loss = 0.08882637000171824
Trained batch 178 in epoch 12, gen_loss = 0.4011694003083852, disc_loss = 0.0887500795291206
Trained batch 179 in epoch 12, gen_loss = 0.40093960579898624, disc_loss = 0.08902147992307113
Trained batch 180 in epoch 12, gen_loss = 0.40144314489311933, disc_loss = 0.0904694942201781
Trained batch 181 in epoch 12, gen_loss = 0.4012677757949619, disc_loss = 0.0909969826372197
Trained batch 182 in epoch 12, gen_loss = 0.40116671362861256, disc_loss = 0.09090605557799503
Trained batch 183 in epoch 12, gen_loss = 0.4007789578450763, disc_loss = 0.0906780773581451
Trained batch 184 in epoch 12, gen_loss = 0.4005250768081562, disc_loss = 0.09040157759209742
Trained batch 185 in epoch 12, gen_loss = 0.4008716804686413, disc_loss = 0.09000952935887761
Trained batch 186 in epoch 12, gen_loss = 0.40086809948166424, disc_loss = 0.09007117089959868
Trained batch 187 in epoch 12, gen_loss = 0.4005098873947529, disc_loss = 0.09021219077638964
Trained batch 188 in epoch 12, gen_loss = 0.40092556911801536, disc_loss = 0.08987321969239957
Trained batch 189 in epoch 12, gen_loss = 0.40127225079034506, disc_loss = 0.08967393792087311
Trained batch 190 in epoch 12, gen_loss = 0.4007990586508007, disc_loss = 0.0893952386473252
Trained batch 191 in epoch 12, gen_loss = 0.40070236831282574, disc_loss = 0.08978984887653496
Trained batch 192 in epoch 12, gen_loss = 0.4007266273461475, disc_loss = 0.09002851739699513
Trained batch 193 in epoch 12, gen_loss = 0.40044088323706206, disc_loss = 0.08973306878805928
Trained batch 194 in epoch 12, gen_loss = 0.40071389354192294, disc_loss = 0.08944023742985267
Trained batch 195 in epoch 12, gen_loss = 0.40050884138564674, disc_loss = 0.08940919076700751
Trained batch 196 in epoch 12, gen_loss = 0.40025149671559407, disc_loss = 0.08911473079475805
Trained batch 197 in epoch 12, gen_loss = 0.4002608623769548, disc_loss = 0.08918243795727389
Trained batch 198 in epoch 12, gen_loss = 0.39998498424213735, disc_loss = 0.08964407562404572
Trained batch 199 in epoch 12, gen_loss = 0.4007309901714325, disc_loss = 0.09012067882809788
Trained batch 200 in epoch 12, gen_loss = 0.40058237729380974, disc_loss = 0.08991211099058982
Trained batch 201 in epoch 12, gen_loss = 0.40027619514724994, disc_loss = 0.09052734971876339
Trained batch 202 in epoch 12, gen_loss = 0.4007627573506585, disc_loss = 0.09132370421103216
Trained batch 203 in epoch 12, gen_loss = 0.40088484158702925, disc_loss = 0.0909661930647916
Trained batch 204 in epoch 12, gen_loss = 0.4008054323312713, disc_loss = 0.09073951918995235
Trained batch 205 in epoch 12, gen_loss = 0.40027458922376913, disc_loss = 0.09165928815265448
Trained batch 206 in epoch 12, gen_loss = 0.40053641508166915, disc_loss = 0.09149649851294099
Trained batch 207 in epoch 12, gen_loss = 0.40090636307230365, disc_loss = 0.09132904359229052
Trained batch 208 in epoch 12, gen_loss = 0.4006228773502642, disc_loss = 0.09120114597282483
Trained batch 209 in epoch 12, gen_loss = 0.4005589658305759, disc_loss = 0.09147228911252958
Trained batch 210 in epoch 12, gen_loss = 0.40048128267600075, disc_loss = 0.0911319865337551
Trained batch 211 in epoch 12, gen_loss = 0.400857002667661, disc_loss = 0.09096068045880012
Trained batch 212 in epoch 12, gen_loss = 0.40059667070147015, disc_loss = 0.09094169033262792
Trained batch 213 in epoch 12, gen_loss = 0.4003888669415055, disc_loss = 0.09079147343062491
Trained batch 214 in epoch 12, gen_loss = 0.40000337195950886, disc_loss = 0.09097532211088163
Trained batch 215 in epoch 12, gen_loss = 0.40017753439369025, disc_loss = 0.09107797658847024
Trained batch 216 in epoch 12, gen_loss = 0.39999943985367703, disc_loss = 0.09166477734334595
Trained batch 217 in epoch 12, gen_loss = 0.399823699385748, disc_loss = 0.09381673529897945
Trained batch 218 in epoch 12, gen_loss = 0.3996961373988896, disc_loss = 0.09384356562014176
Trained batch 219 in epoch 12, gen_loss = 0.40004250271753833, disc_loss = 0.09441005825065077
Trained batch 220 in epoch 12, gen_loss = 0.40016953438115876, disc_loss = 0.09432021552502974
Trained batch 221 in epoch 12, gen_loss = 0.40005162304586117, disc_loss = 0.094252519917817
Trained batch 222 in epoch 12, gen_loss = 0.3995963838870215, disc_loss = 0.0939980758220425
Trained batch 223 in epoch 12, gen_loss = 0.3999248733744025, disc_loss = 0.09401877479311745
Trained batch 224 in epoch 12, gen_loss = 0.39961829556359185, disc_loss = 0.09408652267936203
Trained batch 225 in epoch 12, gen_loss = 0.3999066330426562, disc_loss = 0.09387370072453555
Trained batch 226 in epoch 12, gen_loss = 0.39970651268959045, disc_loss = 0.09358325126757312
Trained batch 227 in epoch 12, gen_loss = 0.3995918936112471, disc_loss = 0.09328651984156877
Trained batch 228 in epoch 12, gen_loss = 0.39979405733695716, disc_loss = 0.09318827060518957
Trained batch 229 in epoch 12, gen_loss = 0.39983998420445815, disc_loss = 0.09334179681685308
Trained batch 230 in epoch 12, gen_loss = 0.39942702728432494, disc_loss = 0.09366016303193131
Trained batch 231 in epoch 12, gen_loss = 0.3996319256979844, disc_loss = 0.09395782893989235
Trained batch 232 in epoch 12, gen_loss = 0.399665663810247, disc_loss = 0.09364908890870635
Trained batch 233 in epoch 12, gen_loss = 0.3994774393036834, disc_loss = 0.0937719486343364
Trained batch 234 in epoch 12, gen_loss = 0.3997701747620359, disc_loss = 0.09361753427681137
Trained batch 235 in epoch 12, gen_loss = 0.39981925790592776, disc_loss = 0.09342988227273069
Trained batch 236 in epoch 12, gen_loss = 0.3998985587293086, disc_loss = 0.09339745745518666
Trained batch 237 in epoch 12, gen_loss = 0.399900087914547, disc_loss = 0.09313192297195812
Trained batch 238 in epoch 12, gen_loss = 0.4001705314823773, disc_loss = 0.09298274663343215
Trained batch 239 in epoch 12, gen_loss = 0.399904532606403, disc_loss = 0.09270216000343984
Trained batch 240 in epoch 12, gen_loss = 0.399757390447672, disc_loss = 0.09297858089347721
Trained batch 241 in epoch 12, gen_loss = 0.4001415179780692, disc_loss = 0.09364952150470585
Trained batch 242 in epoch 12, gen_loss = 0.4001121636280798, disc_loss = 0.093489361861759
Trained batch 243 in epoch 12, gen_loss = 0.40018975722496625, disc_loss = 0.09414614990857414
Trained batch 244 in epoch 12, gen_loss = 0.40047331598340247, disc_loss = 0.09469780073862295
Trained batch 245 in epoch 12, gen_loss = 0.400490922898781, disc_loss = 0.0945077004872747
Trained batch 246 in epoch 12, gen_loss = 0.4004127728311639, disc_loss = 0.09426914735014742
Trained batch 247 in epoch 12, gen_loss = 0.40054061011441294, disc_loss = 0.09398322863759653
Trained batch 248 in epoch 12, gen_loss = 0.400471002940672, disc_loss = 0.09388631006635456
Trained batch 249 in epoch 12, gen_loss = 0.4006804370880127, disc_loss = 0.09381991197541356
Trained batch 250 in epoch 12, gen_loss = 0.400497208078544, disc_loss = 0.09355960793392473
Trained batch 251 in epoch 12, gen_loss = 0.40045051454078584, disc_loss = 0.09330510970072023
Trained batch 252 in epoch 12, gen_loss = 0.40037310936234216, disc_loss = 0.09316891659669607
Trained batch 253 in epoch 12, gen_loss = 0.40078740525902723, disc_loss = 0.0929563112784265
Trained batch 254 in epoch 12, gen_loss = 0.40091725354101143, disc_loss = 0.09275066279532278
Trained batch 255 in epoch 12, gen_loss = 0.4004729272564873, disc_loss = 0.09287052641957416
Trained batch 256 in epoch 12, gen_loss = 0.40052615100307687, disc_loss = 0.09276173643202518
Trained batch 257 in epoch 12, gen_loss = 0.4005807168030924, disc_loss = 0.09249485393466297
Trained batch 258 in epoch 12, gen_loss = 0.40039692318577563, disc_loss = 0.09244027474542728
Trained batch 259 in epoch 12, gen_loss = 0.4005289803330715, disc_loss = 0.0924726382148667
Trained batch 260 in epoch 12, gen_loss = 0.4004823638561585, disc_loss = 0.09270063370566144
Trained batch 261 in epoch 12, gen_loss = 0.40050451377875934, disc_loss = 0.09315693744934583
Trained batch 262 in epoch 12, gen_loss = 0.4003370865442907, disc_loss = 0.09296882596971758
Trained batch 263 in epoch 12, gen_loss = 0.40011680498719215, disc_loss = 0.09304874437988143
Trained batch 264 in epoch 12, gen_loss = 0.40007657633637483, disc_loss = 0.09276635273939596
Trained batch 265 in epoch 12, gen_loss = 0.4004019250098924, disc_loss = 0.09268558516580247
Trained batch 266 in epoch 12, gen_loss = 0.40039064531469165, disc_loss = 0.09279615438651391
Trained batch 267 in epoch 12, gen_loss = 0.4005100184412145, disc_loss = 0.09281964973657768
Trained batch 268 in epoch 12, gen_loss = 0.40033485322193585, disc_loss = 0.09256961726718566
Trained batch 269 in epoch 12, gen_loss = 0.4000662053072894, disc_loss = 0.09262702590268519
Trained batch 270 in epoch 12, gen_loss = 0.4001741803000334, disc_loss = 0.09341687033798311
Trained batch 271 in epoch 12, gen_loss = 0.40017053430133004, disc_loss = 0.09331234742764055
Trained batch 272 in epoch 12, gen_loss = 0.40017616333978956, disc_loss = 0.09312721513443704
Trained batch 273 in epoch 12, gen_loss = 0.4000727790985664, disc_loss = 0.09311994156684644
Trained batch 274 in epoch 12, gen_loss = 0.3999432642893358, disc_loss = 0.09309645950455557
Trained batch 275 in epoch 12, gen_loss = 0.39986091873783997, disc_loss = 0.09291078473873221
Trained batch 276 in epoch 12, gen_loss = 0.39989002850511873, disc_loss = 0.09277218612186637
Trained batch 277 in epoch 12, gen_loss = 0.3999231398748837, disc_loss = 0.09249767556237123
Trained batch 278 in epoch 12, gen_loss = 0.39980037601190654, disc_loss = 0.09243106459831572
Trained batch 279 in epoch 12, gen_loss = 0.3997450338942664, disc_loss = 0.09227877759175108
Trained batch 280 in epoch 12, gen_loss = 0.3996516629470201, disc_loss = 0.09224732458472146
Trained batch 281 in epoch 12, gen_loss = 0.399405244817125, disc_loss = 0.0932554939715522
Trained batch 282 in epoch 12, gen_loss = 0.39952276957751165, disc_loss = 0.09318966949983852
Trained batch 283 in epoch 12, gen_loss = 0.39985371874251835, disc_loss = 0.09308956376880302
Trained batch 284 in epoch 12, gen_loss = 0.40007613552244087, disc_loss = 0.09298663131173765
Trained batch 285 in epoch 12, gen_loss = 0.3999416151872048, disc_loss = 0.0929195249121037
Trained batch 286 in epoch 12, gen_loss = 0.3998137957543031, disc_loss = 0.09279136242546167
Trained batch 287 in epoch 12, gen_loss = 0.3995741442259815, disc_loss = 0.09274306763674961
Trained batch 288 in epoch 12, gen_loss = 0.39946258088709163, disc_loss = 0.0929703833084154
Trained batch 289 in epoch 12, gen_loss = 0.39945278434917847, disc_loss = 0.09354531908536266
Trained batch 290 in epoch 12, gen_loss = 0.3994604856083074, disc_loss = 0.09399114600046701
Trained batch 291 in epoch 12, gen_loss = 0.39964268387180485, disc_loss = 0.09387001680682273
Trained batch 292 in epoch 12, gen_loss = 0.3994481000070279, disc_loss = 0.09385235856506503
Trained batch 293 in epoch 12, gen_loss = 0.399362725668213, disc_loss = 0.09373967029901893
Trained batch 294 in epoch 12, gen_loss = 0.39951688111838646, disc_loss = 0.09355458528497966
Trained batch 295 in epoch 12, gen_loss = 0.3993527314348801, disc_loss = 0.09345541020691697
Trained batch 296 in epoch 12, gen_loss = 0.398955043317493, disc_loss = 0.09358082337599712
Trained batch 297 in epoch 12, gen_loss = 0.3990785601555101, disc_loss = 0.09476512672704639
Trained batch 298 in epoch 12, gen_loss = 0.39908751815457805, disc_loss = 0.09462012071162462
Trained batch 299 in epoch 12, gen_loss = 0.39899189889430997, disc_loss = 0.09453105310288569
Trained batch 300 in epoch 12, gen_loss = 0.39902265879798965, disc_loss = 0.0944792290629689
Trained batch 301 in epoch 12, gen_loss = 0.399087983547457, disc_loss = 0.09425331459423861
Trained batch 302 in epoch 12, gen_loss = 0.3990056883580614, disc_loss = 0.09415066372234338
Trained batch 303 in epoch 12, gen_loss = 0.39872991666197777, disc_loss = 0.09417012728150248
Trained batch 304 in epoch 12, gen_loss = 0.39863890350842085, disc_loss = 0.09395658170163143
Trained batch 305 in epoch 12, gen_loss = 0.3986099962315528, disc_loss = 0.09374909009480106
Trained batch 306 in epoch 12, gen_loss = 0.39846896309806, disc_loss = 0.09361716581004936
Trained batch 307 in epoch 12, gen_loss = 0.3986428416781611, disc_loss = 0.09376447096575874
Trained batch 308 in epoch 12, gen_loss = 0.3986900844234479, disc_loss = 0.09390622724908551
Trained batch 309 in epoch 12, gen_loss = 0.39862418376630354, disc_loss = 0.09380773565761985
Trained batch 310 in epoch 12, gen_loss = 0.3989470901979894, disc_loss = 0.0937834982445817
Trained batch 311 in epoch 12, gen_loss = 0.39900804616701907, disc_loss = 0.09366267818348625
Trained batch 312 in epoch 12, gen_loss = 0.39904239916572937, disc_loss = 0.09346011096831804
Trained batch 313 in epoch 12, gen_loss = 0.39923264247596646, disc_loss = 0.09330662031758838
Trained batch 314 in epoch 12, gen_loss = 0.39925728213219414, disc_loss = 0.09312510332240471
Trained batch 315 in epoch 12, gen_loss = 0.3989689314289938, disc_loss = 0.09361297828498992
Trained batch 316 in epoch 12, gen_loss = 0.39923581227143107, disc_loss = 0.09400763786001254
Trained batch 317 in epoch 12, gen_loss = 0.39923919512415834, disc_loss = 0.09380910470906012
Trained batch 318 in epoch 12, gen_loss = 0.39913534538872936, disc_loss = 0.09397646869156148
Trained batch 319 in epoch 12, gen_loss = 0.39900477789342403, disc_loss = 0.09429366095282603
Trained batch 320 in epoch 12, gen_loss = 0.39868279363136055, disc_loss = 0.09435347748798466
Trained batch 321 in epoch 12, gen_loss = 0.39889996077703394, disc_loss = 0.09423330797877463
Trained batch 322 in epoch 12, gen_loss = 0.3990577843167095, disc_loss = 0.09503052221328574
Trained batch 323 in epoch 12, gen_loss = 0.39916656101927345, disc_loss = 0.09482155058153525
Trained batch 324 in epoch 12, gen_loss = 0.399137679705253, disc_loss = 0.09488431603576128
Trained batch 325 in epoch 12, gen_loss = 0.3992694907941701, disc_loss = 0.09467307692736479
Trained batch 326 in epoch 12, gen_loss = 0.3994322619671486, disc_loss = 0.09490666244270149
Trained batch 327 in epoch 12, gen_loss = 0.3994108322190075, disc_loss = 0.0951322373882981
Trained batch 328 in epoch 12, gen_loss = 0.3991002883411106, disc_loss = 0.09507920848641624
Trained batch 329 in epoch 12, gen_loss = 0.39931472025134346, disc_loss = 0.09558370808478106
Trained batch 330 in epoch 12, gen_loss = 0.3990520093916406, disc_loss = 0.09580648737450291
Trained batch 331 in epoch 12, gen_loss = 0.39907927703426543, disc_loss = 0.09639649900764856
Trained batch 332 in epoch 12, gen_loss = 0.39904175389994373, disc_loss = 0.09621297490612434
Trained batch 333 in epoch 12, gen_loss = 0.3992688271278393, disc_loss = 0.09622307305508655
Trained batch 334 in epoch 12, gen_loss = 0.3994783638128594, disc_loss = 0.09599004931914717
Trained batch 335 in epoch 12, gen_loss = 0.3993567281535694, disc_loss = 0.09594409550551236
Trained batch 336 in epoch 12, gen_loss = 0.3993769706356773, disc_loss = 0.0957271964634694
Trained batch 337 in epoch 12, gen_loss = 0.3993128767380348, disc_loss = 0.09580595862704533
Trained batch 338 in epoch 12, gen_loss = 0.3990648785347784, disc_loss = 0.09570580668978196
Trained batch 339 in epoch 12, gen_loss = 0.39875384744475867, disc_loss = 0.09598605160272736
Trained batch 340 in epoch 12, gen_loss = 0.39872100031620594, disc_loss = 0.09608303837183196
Trained batch 341 in epoch 12, gen_loss = 0.3986238451206196, disc_loss = 0.09616728363101158
Trained batch 342 in epoch 12, gen_loss = 0.3984470976511174, disc_loss = 0.09639345731521053
Trained batch 343 in epoch 12, gen_loss = 0.3982537587194942, disc_loss = 0.09626211667552503
Trained batch 344 in epoch 12, gen_loss = 0.3982246362644693, disc_loss = 0.09617019118336231
Trained batch 345 in epoch 12, gen_loss = 0.39837999469627533, disc_loss = 0.096409083874304
Trained batch 346 in epoch 12, gen_loss = 0.39828417443748165, disc_loss = 0.09644900938436947
Trained batch 347 in epoch 12, gen_loss = 0.39802847383008605, disc_loss = 0.09646587283350527
Trained batch 348 in epoch 12, gen_loss = 0.3980033148325617, disc_loss = 0.09643768567997525
Trained batch 349 in epoch 12, gen_loss = 0.39809364531721386, disc_loss = 0.0962554208056203
Trained batch 350 in epoch 12, gen_loss = 0.3980288810369975, disc_loss = 0.09614995845521872
Trained batch 351 in epoch 12, gen_loss = 0.39789844753051345, disc_loss = 0.0961666167052251
Trained batch 352 in epoch 12, gen_loss = 0.39795778231647805, disc_loss = 0.09598891504330524
Trained batch 353 in epoch 12, gen_loss = 0.3981977515133087, disc_loss = 0.095769744953088
Trained batch 354 in epoch 12, gen_loss = 0.3985140418502646, disc_loss = 0.09559958224302866
Trained batch 355 in epoch 12, gen_loss = 0.3985768258571625, disc_loss = 0.09543227899055719
Trained batch 356 in epoch 12, gen_loss = 0.3985585960186496, disc_loss = 0.09527046958386313
Trained batch 357 in epoch 12, gen_loss = 0.3984840938498854, disc_loss = 0.09521670571616825
Trained batch 358 in epoch 12, gen_loss = 0.3985946797726878, disc_loss = 0.0951152063859497
Trained batch 359 in epoch 12, gen_loss = 0.39848973287476436, disc_loss = 0.09494180036450012
Trained batch 360 in epoch 12, gen_loss = 0.3984075515554222, disc_loss = 0.0948040392585202
Trained batch 361 in epoch 12, gen_loss = 0.3984610818696944, disc_loss = 0.09466412257742733
Trained batch 362 in epoch 12, gen_loss = 0.39872801369543576, disc_loss = 0.0945370070425891
Trained batch 363 in epoch 12, gen_loss = 0.3985658179927658, disc_loss = 0.09463666207259419
Trained batch 364 in epoch 12, gen_loss = 0.3985616685592965, disc_loss = 0.09457904289999645
Trained batch 365 in epoch 12, gen_loss = 0.3986167074715505, disc_loss = 0.09445603015511984
Trained batch 366 in epoch 12, gen_loss = 0.398359395340288, disc_loss = 0.09430114060833197
Trained batch 367 in epoch 12, gen_loss = 0.3983100147350975, disc_loss = 0.0941602666229617
Trained batch 368 in epoch 12, gen_loss = 0.3982271705539569, disc_loss = 0.09396293769189255
Trained batch 369 in epoch 12, gen_loss = 0.3980350744079899, disc_loss = 0.09394349695208508
Trained batch 370 in epoch 12, gen_loss = 0.39767648195320704, disc_loss = 0.09451649602843985
Trained batch 371 in epoch 12, gen_loss = 0.3975875347211797, disc_loss = 0.09450387329574153
Trained batch 372 in epoch 12, gen_loss = 0.3975950721601379, disc_loss = 0.09466765808745539
Trained batch 373 in epoch 12, gen_loss = 0.3977123838376234, disc_loss = 0.09480319737660933
Trained batch 374 in epoch 12, gen_loss = 0.3976847152709961, disc_loss = 0.09485016355663538
Trained batch 375 in epoch 12, gen_loss = 0.3977146124110577, disc_loss = 0.09498970101319967
Trained batch 376 in epoch 12, gen_loss = 0.39756532317763615, disc_loss = 0.09503373726757752
Trained batch 377 in epoch 12, gen_loss = 0.3977037243269108, disc_loss = 0.09506765774465979
Trained batch 378 in epoch 12, gen_loss = 0.3978418614273021, disc_loss = 0.09485748708297284
Trained batch 379 in epoch 12, gen_loss = 0.397658944208371, disc_loss = 0.09515540904953684
Trained batch 380 in epoch 12, gen_loss = 0.39800471654088476, disc_loss = 0.0950801083818078
Trained batch 381 in epoch 12, gen_loss = 0.39810507631426706, disc_loss = 0.09489115668187668
Trained batch 382 in epoch 12, gen_loss = 0.3981337365220172, disc_loss = 0.09468829202132577
Trained batch 383 in epoch 12, gen_loss = 0.3983507351949811, disc_loss = 0.09452444233708472
Trained batch 384 in epoch 12, gen_loss = 0.39844636468144207, disc_loss = 0.09429733888306595
Trained batch 385 in epoch 12, gen_loss = 0.3984409294289011, disc_loss = 0.09409651558465021
Trained batch 386 in epoch 12, gen_loss = 0.39840453693725036, disc_loss = 0.0939307693808366
Trained batch 387 in epoch 12, gen_loss = 0.39854827838152956, disc_loss = 0.09379873308233111
Trained batch 388 in epoch 12, gen_loss = 0.39859480814946036, disc_loss = 0.09369228737773541
Trained batch 389 in epoch 12, gen_loss = 0.39875969466490624, disc_loss = 0.09419959890178572
Trained batch 390 in epoch 12, gen_loss = 0.3987995604877277, disc_loss = 0.09417502473101325
Trained batch 391 in epoch 12, gen_loss = 0.3987034979675497, disc_loss = 0.09405063330884833
Trained batch 392 in epoch 12, gen_loss = 0.39879162507202787, disc_loss = 0.09391533718598442
Trained batch 393 in epoch 12, gen_loss = 0.3986607086537453, disc_loss = 0.09400079449104513
Trained batch 394 in epoch 12, gen_loss = 0.39865335980548133, disc_loss = 0.09416754849938841
Trained batch 395 in epoch 12, gen_loss = 0.39870977951119646, disc_loss = 0.09400854988912628
Trained batch 396 in epoch 12, gen_loss = 0.3986812994372034, disc_loss = 0.09379537523576346
Trained batch 397 in epoch 12, gen_loss = 0.39874814667893416, disc_loss = 0.09369827206854957
Trained batch 398 in epoch 12, gen_loss = 0.39855797555213585, disc_loss = 0.093728244107422
Trained batch 399 in epoch 12, gen_loss = 0.39845031552016735, disc_loss = 0.09370568788493984
Trained batch 400 in epoch 12, gen_loss = 0.39860859884882804, disc_loss = 0.09380776164681648
Trained batch 401 in epoch 12, gen_loss = 0.39859523131183133, disc_loss = 0.0937874043506306
Trained batch 402 in epoch 12, gen_loss = 0.3984941281100952, disc_loss = 0.0937979769587942
Trained batch 403 in epoch 12, gen_loss = 0.3986285581889719, disc_loss = 0.09381083250483775
Trained batch 404 in epoch 12, gen_loss = 0.39840918941262327, disc_loss = 0.09365550403218763
Trained batch 405 in epoch 12, gen_loss = 0.39816962784440646, disc_loss = 0.09361522201003662
Trained batch 406 in epoch 12, gen_loss = 0.3982885996891181, disc_loss = 0.09357872082112718
Trained batch 407 in epoch 12, gen_loss = 0.39811037100997626, disc_loss = 0.09349188887326997
Trained batch 408 in epoch 12, gen_loss = 0.3978544470733419, disc_loss = 0.0937018003485514
Trained batch 409 in epoch 12, gen_loss = 0.39799550553647484, disc_loss = 0.0935396254914472
Trained batch 410 in epoch 12, gen_loss = 0.39786654427973894, disc_loss = 0.09336242497923564
Trained batch 411 in epoch 12, gen_loss = 0.3978222608566284, disc_loss = 0.09330839281607853
Trained batch 412 in epoch 12, gen_loss = 0.39796114978143726, disc_loss = 0.09333373407199617
Trained batch 413 in epoch 12, gen_loss = 0.39822198774503625, disc_loss = 0.09322091540578159
Trained batch 414 in epoch 12, gen_loss = 0.39816946897162014, disc_loss = 0.09315224327034799
Trained batch 415 in epoch 12, gen_loss = 0.3981933364501366, disc_loss = 0.09334399409104102
Trained batch 416 in epoch 12, gen_loss = 0.3978989818970934, disc_loss = 0.09358032513521522
Trained batch 417 in epoch 12, gen_loss = 0.3980540071377914, disc_loss = 0.09347936432055559
Trained batch 418 in epoch 12, gen_loss = 0.3980764389607104, disc_loss = 0.093282406921843
Trained batch 419 in epoch 12, gen_loss = 0.3981369007201422, disc_loss = 0.09307811576540449
Trained batch 420 in epoch 12, gen_loss = 0.39802253635648877, disc_loss = 0.09291368332799887
Trained batch 421 in epoch 12, gen_loss = 0.3981191962957382, disc_loss = 0.09273033548406903
Trained batch 422 in epoch 12, gen_loss = 0.39805905475120457, disc_loss = 0.09255966748359742
Trained batch 423 in epoch 12, gen_loss = 0.39803328836020435, disc_loss = 0.09239307950351844
Trained batch 424 in epoch 12, gen_loss = 0.3980392529683955, disc_loss = 0.09222074103596456
Trained batch 425 in epoch 12, gen_loss = 0.39783565644087365, disc_loss = 0.09213035730229682
Trained batch 426 in epoch 12, gen_loss = 0.39768303997064364, disc_loss = 0.09199717676537482
Trained batch 427 in epoch 12, gen_loss = 0.39779270656197985, disc_loss = 0.09183373216813796
Trained batch 428 in epoch 12, gen_loss = 0.3977218726020315, disc_loss = 0.09190208584586884
Trained batch 429 in epoch 12, gen_loss = 0.397529661655426, disc_loss = 0.09216183410026133
Trained batch 430 in epoch 12, gen_loss = 0.397447616484215, disc_loss = 0.09198594546991372
Trained batch 431 in epoch 12, gen_loss = 0.3974089521086878, disc_loss = 0.0918485550112867
Trained batch 432 in epoch 12, gen_loss = 0.39761420643907774, disc_loss = 0.09172419871485364
Trained batch 433 in epoch 12, gen_loss = 0.39771936916261225, disc_loss = 0.09163614926314677
Trained batch 434 in epoch 12, gen_loss = 0.3975877090432178, disc_loss = 0.09156318210043955
Trained batch 435 in epoch 12, gen_loss = 0.39747749850017217, disc_loss = 0.09145705720490921
Trained batch 436 in epoch 12, gen_loss = 0.3975815084897135, disc_loss = 0.09127290025502614
Trained batch 437 in epoch 12, gen_loss = 0.39768988833035507, disc_loss = 0.09114262663555166
Trained batch 438 in epoch 12, gen_loss = 0.39773665222600274, disc_loss = 0.09109211973909602
Trained batch 439 in epoch 12, gen_loss = 0.39773484962907707, disc_loss = 0.09100010503739626
Trained batch 440 in epoch 12, gen_loss = 0.3975148354393014, disc_loss = 0.09095789629294454
Trained batch 441 in epoch 12, gen_loss = 0.39759372370275436, disc_loss = 0.09090367350959097
Trained batch 442 in epoch 12, gen_loss = 0.39761503757257227, disc_loss = 0.0910162716530028
Trained batch 443 in epoch 12, gen_loss = 0.39772131663184984, disc_loss = 0.0909065081190469
Trained batch 444 in epoch 12, gen_loss = 0.39786905626232705, disc_loss = 0.0907342949683328
Trained batch 445 in epoch 12, gen_loss = 0.39780520604330327, disc_loss = 0.09060384911033972
Trained batch 446 in epoch 12, gen_loss = 0.3977546355868346, disc_loss = 0.09089523330393354
Trained batch 447 in epoch 12, gen_loss = 0.3978022045588919, disc_loss = 0.09145140897245645
Trained batch 448 in epoch 12, gen_loss = 0.3977396231318901, disc_loss = 0.09148220434050618
Trained batch 449 in epoch 12, gen_loss = 0.39774436116218564, disc_loss = 0.09152197630765538
Trained batch 450 in epoch 12, gen_loss = 0.39780230136245426, disc_loss = 0.09138093155988403
Trained batch 451 in epoch 12, gen_loss = 0.3977617849554636, disc_loss = 0.09123473412015236
Trained batch 452 in epoch 12, gen_loss = 0.39797328132930443, disc_loss = 0.09112479077512295
Trained batch 453 in epoch 12, gen_loss = 0.39793704817736203, disc_loss = 0.09096726199041741
Trained batch 454 in epoch 12, gen_loss = 0.3980476137700972, disc_loss = 0.09079228761288655
Trained batch 455 in epoch 12, gen_loss = 0.397939478226921, disc_loss = 0.0907313682418725
Trained batch 456 in epoch 12, gen_loss = 0.3980549071758529, disc_loss = 0.0906353505212137
Trained batch 457 in epoch 12, gen_loss = 0.39805464889024544, disc_loss = 0.09046965608409886
Trained batch 458 in epoch 12, gen_loss = 0.39792563342580606, disc_loss = 0.09106988349750898
Testing Epoch 12
Training Epoch 13
Trained batch 0 in epoch 13, gen_loss = 0.387813001871109, disc_loss = 0.2553114891052246
Trained batch 1 in epoch 13, gen_loss = 0.40139828622341156, disc_loss = 0.20503660291433334
Trained batch 2 in epoch 13, gen_loss = 0.3898837665716807, disc_loss = 0.21893682579199472
Trained batch 3 in epoch 13, gen_loss = 0.4119161516427994, disc_loss = 0.34317492321133614
Trained batch 4 in epoch 13, gen_loss = 0.40819680094718935, disc_loss = 0.2986806780099869
Trained batch 5 in epoch 13, gen_loss = 0.4112144360939662, disc_loss = 0.29004595677057904
Trained batch 6 in epoch 13, gen_loss = 0.4078035184315273, disc_loss = 0.3051100713866098
Trained batch 7 in epoch 13, gen_loss = 0.4087069071829319, disc_loss = 0.2910658121109009
Trained batch 8 in epoch 13, gen_loss = 0.40177234676149154, disc_loss = 0.27645526826381683
Trained batch 9 in epoch 13, gen_loss = 0.4060154974460602, disc_loss = 0.2645071342587471
Trained batch 10 in epoch 13, gen_loss = 0.4050450162454085, disc_loss = 0.24921823834831064
Trained batch 11 in epoch 13, gen_loss = 0.399883896112442, disc_loss = 0.23980419524013996
Trained batch 12 in epoch 13, gen_loss = 0.40357067034794736, disc_loss = 0.2280410723044322
Trained batch 13 in epoch 13, gen_loss = 0.40280946663447786, disc_loss = 0.21802089842302458
Trained batch 14 in epoch 13, gen_loss = 0.4082049389680227, disc_loss = 0.21048602412144343
Trained batch 15 in epoch 13, gen_loss = 0.40605529956519604, disc_loss = 0.2099656336940825
Trained batch 16 in epoch 13, gen_loss = 0.4053022633580601, disc_loss = 0.2106030044310233
Trained batch 17 in epoch 13, gen_loss = 0.4005388567845027, disc_loss = 0.20539054026206335
Trained batch 18 in epoch 13, gen_loss = 0.3964763785663404, disc_loss = 0.19962393296392342
Trained batch 19 in epoch 13, gen_loss = 0.3933665230870247, disc_loss = 0.1945012103766203
Trained batch 20 in epoch 13, gen_loss = 0.3902782258533296, disc_loss = 0.18632351154727594
Trained batch 21 in epoch 13, gen_loss = 0.39052118496461347, disc_loss = 0.18156518016687848
Trained batch 22 in epoch 13, gen_loss = 0.3913950013077777, disc_loss = 0.17728241670714773
Trained batch 23 in epoch 13, gen_loss = 0.38960085560878116, disc_loss = 0.17335898033343256
Trained batch 24 in epoch 13, gen_loss = 0.38902263522148134, disc_loss = 0.1700084538012743
Trained batch 25 in epoch 13, gen_loss = 0.3865065849744357, disc_loss = 0.16572232193385178
Trained batch 26 in epoch 13, gen_loss = 0.38729426706278763, disc_loss = 0.16513032652437687
Trained batch 27 in epoch 13, gen_loss = 0.3887559675744602, disc_loss = 0.16323329049295612
Trained batch 28 in epoch 13, gen_loss = 0.3909279416347372, disc_loss = 0.15839707780757856
Trained batch 29 in epoch 13, gen_loss = 0.38770576218763986, disc_loss = 0.15799109817792972
Trained batch 30 in epoch 13, gen_loss = 0.3874880565750983, disc_loss = 0.15434907346723542
Trained batch 31 in epoch 13, gen_loss = 0.39248624350875616, disc_loss = 0.15496944513870403
Trained batch 32 in epoch 13, gen_loss = 0.391435649358865, disc_loss = 0.1564749643545259
Trained batch 33 in epoch 13, gen_loss = 0.3911352218950496, disc_loss = 0.15263941045850515
Trained batch 34 in epoch 13, gen_loss = 0.39087442925998145, disc_loss = 0.15099185636000975
Trained batch 35 in epoch 13, gen_loss = 0.38985227213965523, disc_loss = 0.1490100901056495
Trained batch 36 in epoch 13, gen_loss = 0.3875539882763012, disc_loss = 0.1474730831042335
Trained batch 37 in epoch 13, gen_loss = 0.3895951980038693, disc_loss = 0.14840573224386103
Trained batch 38 in epoch 13, gen_loss = 0.3872585587012462, disc_loss = 0.1466102599620055
Trained batch 39 in epoch 13, gen_loss = 0.38904984295368195, disc_loss = 0.14403204931877553
Trained batch 40 in epoch 13, gen_loss = 0.38693480229959254, disc_loss = 0.14357982553178217
Trained batch 41 in epoch 13, gen_loss = 0.3848070026863189, disc_loss = 0.1422563274612739
Trained batch 42 in epoch 13, gen_loss = 0.38559982249903124, disc_loss = 0.1420047537445329
Trained batch 43 in epoch 13, gen_loss = 0.38659781556237827, disc_loss = 0.143028295641257
Trained batch 44 in epoch 13, gen_loss = 0.3891398833857642, disc_loss = 0.14039591008590327
Trained batch 45 in epoch 13, gen_loss = 0.3887890071972557, disc_loss = 0.1443474939416932
Trained batch 46 in epoch 13, gen_loss = 0.3874997147854338, disc_loss = 0.14257793243419617
Trained batch 47 in epoch 13, gen_loss = 0.38930668123066425, disc_loss = 0.1412656174118941
Trained batch 48 in epoch 13, gen_loss = 0.39171319530934706, disc_loss = 0.1396870631724596
Trained batch 49 in epoch 13, gen_loss = 0.39144460678100584, disc_loss = 0.138125355578959
Trained batch 50 in epoch 13, gen_loss = 0.3929946960187426, disc_loss = 0.1360793380687634
Trained batch 51 in epoch 13, gen_loss = 0.3945964832718556, disc_loss = 0.13654401421976778
Trained batch 52 in epoch 13, gen_loss = 0.39468213409747716, disc_loss = 0.13929124187045502
Trained batch 53 in epoch 13, gen_loss = 0.395575068615101, disc_loss = 0.1374700661679661
Trained batch 54 in epoch 13, gen_loss = 0.39498694810000334, disc_loss = 0.136110046133399
Trained batch 55 in epoch 13, gen_loss = 0.3947314029293401, disc_loss = 0.13450340597358132
Trained batch 56 in epoch 13, gen_loss = 0.3960877761506198, disc_loss = 0.13259082303888964
Trained batch 57 in epoch 13, gen_loss = 0.3977368910764826, disc_loss = 0.13078395771826135
Trained batch 58 in epoch 13, gen_loss = 0.3971935323739456, disc_loss = 0.1294593454291255
Trained batch 59 in epoch 13, gen_loss = 0.39604168981313703, disc_loss = 0.12879842774321634
Trained batch 60 in epoch 13, gen_loss = 0.39638798500670763, disc_loss = 0.1289799526700231
Trained batch 61 in epoch 13, gen_loss = 0.3954728087109904, disc_loss = 0.12891591081936513
Trained batch 62 in epoch 13, gen_loss = 0.39627770866666523, disc_loss = 0.1270209622998086
Trained batch 63 in epoch 13, gen_loss = 0.39710799511522055, disc_loss = 0.12572728021768853
Trained batch 64 in epoch 13, gen_loss = 0.3964958223012777, disc_loss = 0.12457791853409547
Trained batch 65 in epoch 13, gen_loss = 0.3955926750645493, disc_loss = 0.12362731417471712
Trained batch 66 in epoch 13, gen_loss = 0.3949357315675536, disc_loss = 0.1237109553680491
Trained batch 67 in epoch 13, gen_loss = 0.39378978136707754, disc_loss = 0.12361646301167853
Trained batch 68 in epoch 13, gen_loss = 0.39561349844587024, disc_loss = 0.1257000832238059
Trained batch 69 in epoch 13, gen_loss = 0.3962055461747306, disc_loss = 0.12476090309875353
Trained batch 70 in epoch 13, gen_loss = 0.39664135726404864, disc_loss = 0.12372308240180284
Trained batch 71 in epoch 13, gen_loss = 0.396816020210584, disc_loss = 0.12294851672939128
Trained batch 72 in epoch 13, gen_loss = 0.39653137489540935, disc_loss = 0.12172321796621362
Trained batch 73 in epoch 13, gen_loss = 0.3961333608305132, disc_loss = 0.12019344375191911
Trained batch 74 in epoch 13, gen_loss = 0.3952873440583547, disc_loss = 0.11901875164359808
Trained batch 75 in epoch 13, gen_loss = 0.3951606158363192, disc_loss = 0.11774105682822042
Trained batch 76 in epoch 13, gen_loss = 0.394832327381357, disc_loss = 0.11680506045216477
Trained batch 77 in epoch 13, gen_loss = 0.39498898692620105, disc_loss = 0.11603688244492961
Trained batch 78 in epoch 13, gen_loss = 0.3947011519081985, disc_loss = 0.11484914675024868
Trained batch 79 in epoch 13, gen_loss = 0.39553918577730657, disc_loss = 0.11441600812831894
Trained batch 80 in epoch 13, gen_loss = 0.3940038633199386, disc_loss = 0.11494410227708242
Trained batch 81 in epoch 13, gen_loss = 0.39441828357010356, disc_loss = 0.11431025346831941
Trained batch 82 in epoch 13, gen_loss = 0.39492680617125636, disc_loss = 0.11335725845567074
Trained batch 83 in epoch 13, gen_loss = 0.39557340350889025, disc_loss = 0.11304438625284959
Trained batch 84 in epoch 13, gen_loss = 0.3952853181782891, disc_loss = 0.11209012143971289
Trained batch 85 in epoch 13, gen_loss = 0.39479102298270824, disc_loss = 0.11092346139945262
Trained batch 86 in epoch 13, gen_loss = 0.394717395648189, disc_loss = 0.1101437301813871
Trained batch 87 in epoch 13, gen_loss = 0.39578717337413266, disc_loss = 0.10932342081584713
Trained batch 88 in epoch 13, gen_loss = 0.39534610811244236, disc_loss = 0.10915178244703272
Trained batch 89 in epoch 13, gen_loss = 0.3961054672797521, disc_loss = 0.10855730921030045
Trained batch 90 in epoch 13, gen_loss = 0.39638972937405764, disc_loss = 0.1091736614049136
Trained batch 91 in epoch 13, gen_loss = 0.39647880358540494, disc_loss = 0.10840743982597538
Trained batch 92 in epoch 13, gen_loss = 0.3960429148007465, disc_loss = 0.1080125116052166
Trained batch 93 in epoch 13, gen_loss = 0.3967491175900114, disc_loss = 0.10762607639140272
Trained batch 94 in epoch 13, gen_loss = 0.39771025055333187, disc_loss = 0.10680830862961317
Trained batch 95 in epoch 13, gen_loss = 0.3981794457261761, disc_loss = 0.10609798994846642
Trained batch 96 in epoch 13, gen_loss = 0.3970875767702909, disc_loss = 0.10544431881652665
Trained batch 97 in epoch 13, gen_loss = 0.3980770482092488, disc_loss = 0.10452660030628345
Trained batch 98 in epoch 13, gen_loss = 0.3988272665124951, disc_loss = 0.10413725698611351
Trained batch 99 in epoch 13, gen_loss = 0.3981163322925568, disc_loss = 0.10555915692821145
Trained batch 100 in epoch 13, gen_loss = 0.39859757860108175, disc_loss = 0.1053413858840076
Trained batch 101 in epoch 13, gen_loss = 0.3990634440207014, disc_loss = 0.10453238383885108
Trained batch 102 in epoch 13, gen_loss = 0.39888464739021745, disc_loss = 0.10386726424749036
Trained batch 103 in epoch 13, gen_loss = 0.39863409474492073, disc_loss = 0.10321506576684232
Trained batch 104 in epoch 13, gen_loss = 0.39874429560842967, disc_loss = 0.10239199279319672
Trained batch 105 in epoch 13, gen_loss = 0.39873182098820525, disc_loss = 0.10158468491204505
Trained batch 106 in epoch 13, gen_loss = 0.3988606567694762, disc_loss = 0.10170347059023714
Trained batch 107 in epoch 13, gen_loss = 0.3984313579621138, disc_loss = 0.10182939921678216
Trained batch 108 in epoch 13, gen_loss = 0.3990380854234783, disc_loss = 0.10103264567228633
Trained batch 109 in epoch 13, gen_loss = 0.3994138376279311, disc_loss = 0.10020455202426423
Trained batch 110 in epoch 13, gen_loss = 0.39984913291157903, disc_loss = 0.09955669856454069
Trained batch 111 in epoch 13, gen_loss = 0.4006319224302258, disc_loss = 0.09879641363763117
Trained batch 112 in epoch 13, gen_loss = 0.40133869806222155, disc_loss = 0.09842418041080236
Trained batch 113 in epoch 13, gen_loss = 0.40134527076754656, disc_loss = 0.09931858588957734
Trained batch 114 in epoch 13, gen_loss = 0.4022462321364361, disc_loss = 0.10071954311721999
Trained batch 115 in epoch 13, gen_loss = 0.40216802060604095, disc_loss = 0.10047694513220982
Trained batch 116 in epoch 13, gen_loss = 0.40151505668958026, disc_loss = 0.10000581573694944
Trained batch 117 in epoch 13, gen_loss = 0.4014661655587665, disc_loss = 0.10097436839714646
Trained batch 118 in epoch 13, gen_loss = 0.40146950062583475, disc_loss = 0.10056025377560814
Trained batch 119 in epoch 13, gen_loss = 0.4015951432287693, disc_loss = 0.09981342537794262
Trained batch 120 in epoch 13, gen_loss = 0.40123164038027614, disc_loss = 0.09953805387851374
Trained batch 121 in epoch 13, gen_loss = 0.40136751361557693, disc_loss = 0.10103067684704896
Trained batch 122 in epoch 13, gen_loss = 0.4002569320240641, disc_loss = 0.10407628012230484
Trained batch 123 in epoch 13, gen_loss = 0.3997895534961454, disc_loss = 0.10493437179003752
Trained batch 124 in epoch 13, gen_loss = 0.4004590389728546, disc_loss = 0.10576050712913275
Trained batch 125 in epoch 13, gen_loss = 0.40056343305678593, disc_loss = 0.10596441574365137
Trained batch 126 in epoch 13, gen_loss = 0.4006437089030198, disc_loss = 0.10584832636243481
Trained batch 127 in epoch 13, gen_loss = 0.40034606610424817, disc_loss = 0.10630325998499757
Trained batch 128 in epoch 13, gen_loss = 0.40003417790398116, disc_loss = 0.10603466701455587
Trained batch 129 in epoch 13, gen_loss = 0.3997107526430717, disc_loss = 0.10680100564629985
Trained batch 130 in epoch 13, gen_loss = 0.40001134813286876, disc_loss = 0.1071742957543212
Trained batch 131 in epoch 13, gen_loss = 0.40044979999462765, disc_loss = 0.10698825964055052
Trained batch 132 in epoch 13, gen_loss = 0.40009349674210515, disc_loss = 0.10652810488512418
Trained batch 133 in epoch 13, gen_loss = 0.4001968527462945, disc_loss = 0.10617641022484471
Trained batch 134 in epoch 13, gen_loss = 0.4003214827290288, disc_loss = 0.10619437006750593
Trained batch 135 in epoch 13, gen_loss = 0.4004482510773575, disc_loss = 0.10572877144851886
Trained batch 136 in epoch 13, gen_loss = 0.399692152755974, disc_loss = 0.1058563165516205
Trained batch 137 in epoch 13, gen_loss = 0.40028102091257123, disc_loss = 0.10591211225972444
Trained batch 138 in epoch 13, gen_loss = 0.4004471653656994, disc_loss = 0.10543991428994232
Trained batch 139 in epoch 13, gen_loss = 0.3999839995588575, disc_loss = 0.1049422649600144
Trained batch 140 in epoch 13, gen_loss = 0.3997666180556548, disc_loss = 0.10443378537761193
Trained batch 141 in epoch 13, gen_loss = 0.39973792097937894, disc_loss = 0.10404837789328795
Trained batch 142 in epoch 13, gen_loss = 0.4001937098019607, disc_loss = 0.10378925905439194
Trained batch 143 in epoch 13, gen_loss = 0.40029449346992707, disc_loss = 0.10324668192899683
Trained batch 144 in epoch 13, gen_loss = 0.3997587604769345, disc_loss = 0.10323678164518085
Trained batch 145 in epoch 13, gen_loss = 0.39931716820965074, disc_loss = 0.10342540430568464
Trained batch 146 in epoch 13, gen_loss = 0.399350056437408, disc_loss = 0.1031446239157092
Trained batch 147 in epoch 13, gen_loss = 0.3990679143651112, disc_loss = 0.10283795225031271
Trained batch 148 in epoch 13, gen_loss = 0.39928797207422706, disc_loss = 0.10344541377244179
Trained batch 149 in epoch 13, gen_loss = 0.3990178213516871, disc_loss = 0.10390114589904745
Trained batch 150 in epoch 13, gen_loss = 0.39936530728213837, disc_loss = 0.10336244907476846
Trained batch 151 in epoch 13, gen_loss = 0.3991331554165012, disc_loss = 0.10317399756566278
Trained batch 152 in epoch 13, gen_loss = 0.39887143233243155, disc_loss = 0.10310390822321566
Trained batch 153 in epoch 13, gen_loss = 0.3988145249230521, disc_loss = 0.10268267299133269
Trained batch 154 in epoch 13, gen_loss = 0.39852825826214205, disc_loss = 0.10233734451354512
Trained batch 155 in epoch 13, gen_loss = 0.3984798137576152, disc_loss = 0.10206203228937319
Trained batch 156 in epoch 13, gen_loss = 0.3982762980992627, disc_loss = 0.10255354936501593
Trained batch 157 in epoch 13, gen_loss = 0.398837091990664, disc_loss = 0.10327431445799862
Trained batch 158 in epoch 13, gen_loss = 0.3980792076707636, disc_loss = 0.10326284052417525
Trained batch 159 in epoch 13, gen_loss = 0.39791632499545815, disc_loss = 0.10277679972932674
Trained batch 160 in epoch 13, gen_loss = 0.3979723690459447, disc_loss = 0.10233223453881393
Trained batch 161 in epoch 13, gen_loss = 0.39754860158319827, disc_loss = 0.10235133975813235
Trained batch 162 in epoch 13, gen_loss = 0.39733157000658703, disc_loss = 0.10260320310280915
Trained batch 163 in epoch 13, gen_loss = 0.39722410226013605, disc_loss = 0.10233601300250285
Trained batch 164 in epoch 13, gen_loss = 0.3978734563697468, disc_loss = 0.10192089351176313
Trained batch 165 in epoch 13, gen_loss = 0.3973854692226433, disc_loss = 0.1027240212726216
Trained batch 166 in epoch 13, gen_loss = 0.3976727474235489, disc_loss = 0.10275041494340062
Trained batch 167 in epoch 13, gen_loss = 0.3975551413993041, disc_loss = 0.1024168909560623
Trained batch 168 in epoch 13, gen_loss = 0.3972500292859839, disc_loss = 0.10215453569330936
Trained batch 169 in epoch 13, gen_loss = 0.39759638432194205, disc_loss = 0.10163034379810972
Trained batch 170 in epoch 13, gen_loss = 0.3973828883547532, disc_loss = 0.10146189794183998
Trained batch 171 in epoch 13, gen_loss = 0.39712383320858313, disc_loss = 0.10138034677067988
Trained batch 172 in epoch 13, gen_loss = 0.39722837326843613, disc_loss = 0.10150901051076679
Trained batch 173 in epoch 13, gen_loss = 0.3969914673388689, disc_loss = 0.10109761189776419
Trained batch 174 in epoch 13, gen_loss = 0.39683339187077116, disc_loss = 0.10139008142586266
Trained batch 175 in epoch 13, gen_loss = 0.3972392962737517, disc_loss = 0.1011353741262362
Trained batch 176 in epoch 13, gen_loss = 0.3977778883977125, disc_loss = 0.10114926722237451
Trained batch 177 in epoch 13, gen_loss = 0.39727529364355496, disc_loss = 0.1018801020050233
Trained batch 178 in epoch 13, gen_loss = 0.396850217487559, disc_loss = 0.10210866551305162
Trained batch 179 in epoch 13, gen_loss = 0.3968418616387579, disc_loss = 0.10190181545395818
Trained batch 180 in epoch 13, gen_loss = 0.3968669296298896, disc_loss = 0.10205995323887682
Trained batch 181 in epoch 13, gen_loss = 0.397362022118254, disc_loss = 0.1017618777363428
Trained batch 182 in epoch 13, gen_loss = 0.39768807695863023, disc_loss = 0.1014553983670359
Trained batch 183 in epoch 13, gen_loss = 0.397644125411044, disc_loss = 0.1011358833335259
Trained batch 184 in epoch 13, gen_loss = 0.3977853106485831, disc_loss = 0.10119534426343602
Trained batch 185 in epoch 13, gen_loss = 0.39815903495075883, disc_loss = 0.10111357369309952
Trained batch 186 in epoch 13, gen_loss = 0.39830068295652216, disc_loss = 0.10067151376808231
Trained batch 187 in epoch 13, gen_loss = 0.39833893135507054, disc_loss = 0.1003135312100912
Trained batch 188 in epoch 13, gen_loss = 0.3986124609197889, disc_loss = 0.09990444907021744
Trained batch 189 in epoch 13, gen_loss = 0.39835397648183923, disc_loss = 0.09974552527756284
Trained batch 190 in epoch 13, gen_loss = 0.3984522933423207, disc_loss = 0.09971564034419378
Trained batch 191 in epoch 13, gen_loss = 0.39784627547487617, disc_loss = 0.09955758051849746
Trained batch 192 in epoch 13, gen_loss = 0.3984433296739746, disc_loss = 0.0991762118954501
Trained batch 193 in epoch 13, gen_loss = 0.3985456487874395, disc_loss = 0.09874485506071258
Trained batch 194 in epoch 13, gen_loss = 0.3980842385536585, disc_loss = 0.09848466150653667
Trained batch 195 in epoch 13, gen_loss = 0.39811661079221844, disc_loss = 0.09816527319121726
Trained batch 196 in epoch 13, gen_loss = 0.3983149372684169, disc_loss = 0.09776723711056455
Trained batch 197 in epoch 13, gen_loss = 0.3978828474728748, disc_loss = 0.09744877101985192
Trained batch 198 in epoch 13, gen_loss = 0.3975813989363723, disc_loss = 0.09715119007057581
Trained batch 199 in epoch 13, gen_loss = 0.39770574018359184, disc_loss = 0.09698565135709941
Trained batch 200 in epoch 13, gen_loss = 0.39734936338752064, disc_loss = 0.09676972190057163
Trained batch 201 in epoch 13, gen_loss = 0.39715428517596557, disc_loss = 0.09646598709802522
Trained batch 202 in epoch 13, gen_loss = 0.39758249618149744, disc_loss = 0.0960690317299272
Trained batch 203 in epoch 13, gen_loss = 0.3975829929113388, disc_loss = 0.09619590262060657
Trained batch 204 in epoch 13, gen_loss = 0.39736628634173693, disc_loss = 0.09669868751633458
Trained batch 205 in epoch 13, gen_loss = 0.3975208203480082, disc_loss = 0.09834782831660173
Trained batch 206 in epoch 13, gen_loss = 0.3977303025515183, disc_loss = 0.09800113848262075
Trained batch 207 in epoch 13, gen_loss = 0.39827383381242937, disc_loss = 0.09785654681484
Trained batch 208 in epoch 13, gen_loss = 0.3982653997161172, disc_loss = 0.0975906993373872
Trained batch 209 in epoch 13, gen_loss = 0.39786556306339443, disc_loss = 0.09733060077719745
Trained batch 210 in epoch 13, gen_loss = 0.39830730113937957, disc_loss = 0.09722727760496015
Trained batch 211 in epoch 13, gen_loss = 0.39839297968823956, disc_loss = 0.09696173132836537
Trained batch 212 in epoch 13, gen_loss = 0.3980368442938361, disc_loss = 0.09688709731358038
Trained batch 213 in epoch 13, gen_loss = 0.3980503004288005, disc_loss = 0.09705588352979622
Trained batch 214 in epoch 13, gen_loss = 0.39805051518041035, disc_loss = 0.09727629380690497
Trained batch 215 in epoch 13, gen_loss = 0.39819350921445423, disc_loss = 0.0981756861200901
Trained batch 216 in epoch 13, gen_loss = 0.3978409706722207, disc_loss = 0.09914385955694908
Trained batch 217 in epoch 13, gen_loss = 0.3975884851512559, disc_loss = 0.09884196621528187
Trained batch 218 in epoch 13, gen_loss = 0.39794381949455226, disc_loss = 0.09916515946898559
Trained batch 219 in epoch 13, gen_loss = 0.3979908088391477, disc_loss = 0.09896970593624495
Trained batch 220 in epoch 13, gen_loss = 0.3974246108963479, disc_loss = 0.0994060359035547
Trained batch 221 in epoch 13, gen_loss = 0.39778588067840887, disc_loss = 0.0998043063440704
Trained batch 222 in epoch 13, gen_loss = 0.397734069637119, disc_loss = 0.09956179957653108
Trained batch 223 in epoch 13, gen_loss = 0.3974588437538062, disc_loss = 0.09933993212845442
Trained batch 224 in epoch 13, gen_loss = 0.39737284474902684, disc_loss = 0.0990920303348038
Trained batch 225 in epoch 13, gen_loss = 0.39746014365052756, disc_loss = 0.09883667460222424
Trained batch 226 in epoch 13, gen_loss = 0.39735721662181067, disc_loss = 0.09878924276499233
Trained batch 227 in epoch 13, gen_loss = 0.39710984117629233, disc_loss = 0.0993366103962456
Trained batch 228 in epoch 13, gen_loss = 0.39733402879998153, disc_loss = 0.10034650887106443
Trained batch 229 in epoch 13, gen_loss = 0.3975692719221115, disc_loss = 0.10024561976770992
Trained batch 230 in epoch 13, gen_loss = 0.39718364340402346, disc_loss = 0.10044239413847914
Trained batch 231 in epoch 13, gen_loss = 0.3972668420394947, disc_loss = 0.10018277355341305
Trained batch 232 in epoch 13, gen_loss = 0.39678009679389104, disc_loss = 0.09985058424522693
Trained batch 233 in epoch 13, gen_loss = 0.39665200886053914, disc_loss = 0.09949720573699118
Trained batch 234 in epoch 13, gen_loss = 0.39637387496359805, disc_loss = 0.09913158437356036
Trained batch 235 in epoch 13, gen_loss = 0.39652715358188595, disc_loss = 0.09888164465457706
Trained batch 236 in epoch 13, gen_loss = 0.39698379364194747, disc_loss = 0.09867419780306676
Trained batch 237 in epoch 13, gen_loss = 0.39678764030212116, disc_loss = 0.09829854852120791
Trained batch 238 in epoch 13, gen_loss = 0.3966375258926567, disc_loss = 0.09807895466482665
Trained batch 239 in epoch 13, gen_loss = 0.39656607347230116, disc_loss = 0.09783764319727198
Trained batch 240 in epoch 13, gen_loss = 0.39662999743247923, disc_loss = 0.09774529930451475
Trained batch 241 in epoch 13, gen_loss = 0.39654957681648, disc_loss = 0.09766688770114267
Trained batch 242 in epoch 13, gen_loss = 0.3964952895180188, disc_loss = 0.09790108361714539
Trained batch 243 in epoch 13, gen_loss = 0.3966584840758902, disc_loss = 0.09864122243063739
Trained batch 244 in epoch 13, gen_loss = 0.39672270818632477, disc_loss = 0.09835898453863907
Trained batch 245 in epoch 13, gen_loss = 0.39651089579593846, disc_loss = 0.09866063100308543
Trained batch 246 in epoch 13, gen_loss = 0.3969032502608743, disc_loss = 0.09880642095573156
Trained batch 247 in epoch 13, gen_loss = 0.3970069825168579, disc_loss = 0.09844497162022538
Trained batch 248 in epoch 13, gen_loss = 0.3972098811802615, disc_loss = 0.0981837569597555
Trained batch 249 in epoch 13, gen_loss = 0.397083512544632, disc_loss = 0.09832665591314435
Trained batch 250 in epoch 13, gen_loss = 0.3973253021439708, disc_loss = 0.09840856844640941
Trained batch 251 in epoch 13, gen_loss = 0.39708635435690953, disc_loss = 0.09822637103276238
Trained batch 252 in epoch 13, gen_loss = 0.39736971694961365, disc_loss = 0.09810137171887244
Trained batch 253 in epoch 13, gen_loss = 0.39728583372014714, disc_loss = 0.09813893962226163
Trained batch 254 in epoch 13, gen_loss = 0.39711736405597015, disc_loss = 0.09809729568295035
Trained batch 255 in epoch 13, gen_loss = 0.39709126576781273, disc_loss = 0.09789770066345227
Trained batch 256 in epoch 13, gen_loss = 0.3974366675091161, disc_loss = 0.09841001380582844
Trained batch 257 in epoch 13, gen_loss = 0.39711354568947194, disc_loss = 0.09818372536493941
Trained batch 258 in epoch 13, gen_loss = 0.396843871439746, disc_loss = 0.09920031766130312
Trained batch 259 in epoch 13, gen_loss = 0.3972942170042258, disc_loss = 0.09899195772595704
Trained batch 260 in epoch 13, gen_loss = 0.3974138297340422, disc_loss = 0.09878119601158004
Trained batch 261 in epoch 13, gen_loss = 0.3972416418881817, disc_loss = 0.09867508087008622
Trained batch 262 in epoch 13, gen_loss = 0.3974490770822242, disc_loss = 0.09852352697657202
Trained batch 263 in epoch 13, gen_loss = 0.3972429087893529, disc_loss = 0.09863682163554724
Trained batch 264 in epoch 13, gen_loss = 0.39735840547759577, disc_loss = 0.09845066031546525
Trained batch 265 in epoch 13, gen_loss = 0.39688217673534737, disc_loss = 0.09959762711848195
Trained batch 266 in epoch 13, gen_loss = 0.39672352100133, disc_loss = 0.09979927657374393
Trained batch 267 in epoch 13, gen_loss = 0.3965864934360803, disc_loss = 0.09973453819654438
Trained batch 268 in epoch 13, gen_loss = 0.3966289422990664, disc_loss = 0.09979333532247069
Trained batch 269 in epoch 13, gen_loss = 0.3965327218726829, disc_loss = 0.09989263945500608
Trained batch 270 in epoch 13, gen_loss = 0.39662122957380935, disc_loss = 0.09960187911451193
Trained batch 271 in epoch 13, gen_loss = 0.3964345359846073, disc_loss = 0.09996112502138953
Trained batch 272 in epoch 13, gen_loss = 0.39687328799303634, disc_loss = 0.10015080209084593
Trained batch 273 in epoch 13, gen_loss = 0.3971158647841781, disc_loss = 0.09988038049820457
Trained batch 274 in epoch 13, gen_loss = 0.3972835938497023, disc_loss = 0.09968013790182093
Trained batch 275 in epoch 13, gen_loss = 0.39721502223308536, disc_loss = 0.09952337248588278
Trained batch 276 in epoch 13, gen_loss = 0.39746953003673346, disc_loss = 0.09927494455774445
Trained batch 277 in epoch 13, gen_loss = 0.39715544622150256, disc_loss = 0.09921080812396442
Trained batch 278 in epoch 13, gen_loss = 0.39713381385717766, disc_loss = 0.09921336820596115
Trained batch 279 in epoch 13, gen_loss = 0.3966899843088218, disc_loss = 0.09940368464283113
Trained batch 280 in epoch 13, gen_loss = 0.3968840732481132, disc_loss = 0.0992057565831682
Trained batch 281 in epoch 13, gen_loss = 0.3972221063383928, disc_loss = 0.09910013400189949
Trained batch 282 in epoch 13, gen_loss = 0.3969457856126051, disc_loss = 0.09891730262947272
Trained batch 283 in epoch 13, gen_loss = 0.3966943005650816, disc_loss = 0.09874362496226291
Trained batch 284 in epoch 13, gen_loss = 0.3967787824178997, disc_loss = 0.09846145643019362
Trained batch 285 in epoch 13, gen_loss = 0.3969319991090081, disc_loss = 0.09823546416966336
Trained batch 286 in epoch 13, gen_loss = 0.39672302597491166, disc_loss = 0.09833897540235458
Trained batch 287 in epoch 13, gen_loss = 0.39653965396185714, disc_loss = 0.09830276791277963
Trained batch 288 in epoch 13, gen_loss = 0.3962967348346248, disc_loss = 0.0980978934803275
Trained batch 289 in epoch 13, gen_loss = 0.39654785096645356, disc_loss = 0.09786069439724088
Trained batch 290 in epoch 13, gen_loss = 0.3964482146440093, disc_loss = 0.09760317698927577
Trained batch 291 in epoch 13, gen_loss = 0.39612297040142425, disc_loss = 0.09751501200682394
Trained batch 292 in epoch 13, gen_loss = 0.3962462710235713, disc_loss = 0.09721360478626481
Trained batch 293 in epoch 13, gen_loss = 0.39640949240752626, disc_loss = 0.09700949210990346
Trained batch 294 in epoch 13, gen_loss = 0.396278575214289, disc_loss = 0.09734262914665169
Trained batch 295 in epoch 13, gen_loss = 0.39665611501078346, disc_loss = 0.09775817232848322
Trained batch 296 in epoch 13, gen_loss = 0.3965459916527424, disc_loss = 0.0975327099820831
Trained batch 297 in epoch 13, gen_loss = 0.39666928190912976, disc_loss = 0.09742516575806193
Trained batch 298 in epoch 13, gen_loss = 0.396743826742555, disc_loss = 0.09717292408692497
Trained batch 299 in epoch 13, gen_loss = 0.3970212207237879, disc_loss = 0.09710837794157366
Trained batch 300 in epoch 13, gen_loss = 0.3969683924386668, disc_loss = 0.09701233035714622
Trained batch 301 in epoch 13, gen_loss = 0.3970840324629222, disc_loss = 0.09686525404416271
Trained batch 302 in epoch 13, gen_loss = 0.3972740792008516, disc_loss = 0.09686799174352939
Trained batch 303 in epoch 13, gen_loss = 0.39750132072520883, disc_loss = 0.09660556845942904
Trained batch 304 in epoch 13, gen_loss = 0.3973250762360995, disc_loss = 0.09645811939520425
Trained batch 305 in epoch 13, gen_loss = 0.3971548020060546, disc_loss = 0.09657238740047891
Trained batch 306 in epoch 13, gen_loss = 0.39745484355606553, disc_loss = 0.09676876173624678
Trained batch 307 in epoch 13, gen_loss = 0.39746699075807224, disc_loss = 0.09684370946465665
Trained batch 308 in epoch 13, gen_loss = 0.3974850224059762, disc_loss = 0.0966623489832367
Trained batch 309 in epoch 13, gen_loss = 0.39765942606233784, disc_loss = 0.09639439899474382
Trained batch 310 in epoch 13, gen_loss = 0.3974098682020255, disc_loss = 0.09619404231213105
Trained batch 311 in epoch 13, gen_loss = 0.39717139074435603, disc_loss = 0.09654036626960032
Trained batch 312 in epoch 13, gen_loss = 0.39760456831691365, disc_loss = 0.09710894276896795
Trained batch 313 in epoch 13, gen_loss = 0.3978146982800429, disc_loss = 0.09699480193459493
Trained batch 314 in epoch 13, gen_loss = 0.39777263270484076, disc_loss = 0.09706468935168924
Trained batch 315 in epoch 13, gen_loss = 0.3978408205358288, disc_loss = 0.0968193469356887
Trained batch 316 in epoch 13, gen_loss = 0.3978109916301932, disc_loss = 0.09706692171961727
Trained batch 317 in epoch 13, gen_loss = 0.39752157379246356, disc_loss = 0.09790018392996218
Trained batch 318 in epoch 13, gen_loss = 0.3975375069533022, disc_loss = 0.09772284087202392
Trained batch 319 in epoch 13, gen_loss = 0.39755975930020215, disc_loss = 0.09820961706573143
Trained batch 320 in epoch 13, gen_loss = 0.39731043354373113, disc_loss = 0.09839446031462366
Trained batch 321 in epoch 13, gen_loss = 0.39690954733339157, disc_loss = 0.09866232319694498
Trained batch 322 in epoch 13, gen_loss = 0.39716118020538943, disc_loss = 0.09882591375302605
Trained batch 323 in epoch 13, gen_loss = 0.3970732018351555, disc_loss = 0.09873754005695198
Trained batch 324 in epoch 13, gen_loss = 0.3970098607356732, disc_loss = 0.09889872627762648
Trained batch 325 in epoch 13, gen_loss = 0.39698126528160704, disc_loss = 0.09903365093643314
Trained batch 326 in epoch 13, gen_loss = 0.3965827221170478, disc_loss = 0.09903925893093468
Trained batch 327 in epoch 13, gen_loss = 0.39651587641820674, disc_loss = 0.09890002484728651
Trained batch 328 in epoch 13, gen_loss = 0.3966219408896194, disc_loss = 0.0987583983768808
Trained batch 329 in epoch 13, gen_loss = 0.39665049757018234, disc_loss = 0.09879385761239312
Trained batch 330 in epoch 13, gen_loss = 0.39685593009715353, disc_loss = 0.09878959153353987
Trained batch 331 in epoch 13, gen_loss = 0.3968808875385537, disc_loss = 0.09864392189914922
Trained batch 332 in epoch 13, gen_loss = 0.3968722764794175, disc_loss = 0.09844354108289198
Trained batch 333 in epoch 13, gen_loss = 0.39692108208190896, disc_loss = 0.0981843510508805
Trained batch 334 in epoch 13, gen_loss = 0.39684831073035054, disc_loss = 0.09837886203469626
Trained batch 335 in epoch 13, gen_loss = 0.39661971896532033, disc_loss = 0.09913624469966938
Trained batch 336 in epoch 13, gen_loss = 0.39676473712001425, disc_loss = 0.09909782452005837
Trained batch 337 in epoch 13, gen_loss = 0.39667950588217854, disc_loss = 0.09893155925130175
Trained batch 338 in epoch 13, gen_loss = 0.3966010164546404, disc_loss = 0.09883544084706665
Trained batch 339 in epoch 13, gen_loss = 0.39642185524982565, disc_loss = 0.09884185846347143
Trained batch 340 in epoch 13, gen_loss = 0.3964450713301684, disc_loss = 0.09873539434958938
Trained batch 341 in epoch 13, gen_loss = 0.39635188790441256, disc_loss = 0.09869982211235148
Trained batch 342 in epoch 13, gen_loss = 0.3961361402499085, disc_loss = 0.0990110927752868
Trained batch 343 in epoch 13, gen_loss = 0.39635108679879544, disc_loss = 0.09911255946187952
Trained batch 344 in epoch 13, gen_loss = 0.3964329989060112, disc_loss = 0.09893951714578746
Trained batch 345 in epoch 13, gen_loss = 0.39641526263917803, disc_loss = 0.09892521700095062
Trained batch 346 in epoch 13, gen_loss = 0.3965271627181545, disc_loss = 0.09869837475892275
Trained batch 347 in epoch 13, gen_loss = 0.3966727219093805, disc_loss = 0.0987208520340594
Trained batch 348 in epoch 13, gen_loss = 0.3969014018005491, disc_loss = 0.09878593081752517
Trained batch 349 in epoch 13, gen_loss = 0.3968115641389574, disc_loss = 0.09853784727198737
Trained batch 350 in epoch 13, gen_loss = 0.39688091570155914, disc_loss = 0.09833489871050557
Trained batch 351 in epoch 13, gen_loss = 0.3968536476181312, disc_loss = 0.0981713392750614
Trained batch 352 in epoch 13, gen_loss = 0.39659297297426394, disc_loss = 0.09824289800467302
Trained batch 353 in epoch 13, gen_loss = 0.39684242498403216, disc_loss = 0.09905212874508511
Trained batch 354 in epoch 13, gen_loss = 0.39688675059399137, disc_loss = 0.09887036946667752
Trained batch 355 in epoch 13, gen_loss = 0.39675566294554915, disc_loss = 0.09865826819866394
Trained batch 356 in epoch 13, gen_loss = 0.39660217890552446, disc_loss = 0.09862818557988196
Trained batch 357 in epoch 13, gen_loss = 0.3965020351236759, disc_loss = 0.0985480484256115
Trained batch 358 in epoch 13, gen_loss = 0.3967980805545796, disc_loss = 0.0984489779276021
Trained batch 359 in epoch 13, gen_loss = 0.3968678501745065, disc_loss = 0.09843227612372074
Trained batch 360 in epoch 13, gen_loss = 0.3968075278558229, disc_loss = 0.09823725868398298
Trained batch 361 in epoch 13, gen_loss = 0.3967080560837003, disc_loss = 0.09807648702694402
Trained batch 362 in epoch 13, gen_loss = 0.39664007932686607, disc_loss = 0.0981823809742517
Trained batch 363 in epoch 13, gen_loss = 0.39669618780141347, disc_loss = 0.09823518816975284
Trained batch 364 in epoch 13, gen_loss = 0.3969204539305543, disc_loss = 0.09863971657030386
Trained batch 365 in epoch 13, gen_loss = 0.39688570023885844, disc_loss = 0.09896445768513804
Trained batch 366 in epoch 13, gen_loss = 0.3968209093208209, disc_loss = 0.09894266677385942
Trained batch 367 in epoch 13, gen_loss = 0.3968269846037678, disc_loss = 0.09884589523299718
Trained batch 368 in epoch 13, gen_loss = 0.39707130112945227, disc_loss = 0.09877897986289123
Trained batch 369 in epoch 13, gen_loss = 0.39718675492583094, disc_loss = 0.09861181362758617
Trained batch 370 in epoch 13, gen_loss = 0.3971503712738942, disc_loss = 0.09842966151024614
Trained batch 371 in epoch 13, gen_loss = 0.39717154188822673, disc_loss = 0.09819405806070615
Trained batch 372 in epoch 13, gen_loss = 0.3971397600289005, disc_loss = 0.09810090739899202
Trained batch 373 in epoch 13, gen_loss = 0.3970976362732005, disc_loss = 0.0984225336457279
Trained batch 374 in epoch 13, gen_loss = 0.39719184072812397, disc_loss = 0.09841477590550979
Trained batch 375 in epoch 13, gen_loss = 0.39713692189531125, disc_loss = 0.0983886884183603
Trained batch 376 in epoch 13, gen_loss = 0.3974762854588759, disc_loss = 0.09824052458722886
Trained batch 377 in epoch 13, gen_loss = 0.3973862215009316, disc_loss = 0.09816139064995306
Trained batch 378 in epoch 13, gen_loss = 0.3974357670404037, disc_loss = 0.09821019922985172
Trained batch 379 in epoch 13, gen_loss = 0.39734431575787693, disc_loss = 0.09834788443373614
Trained batch 380 in epoch 13, gen_loss = 0.39763835291537086, disc_loss = 0.09836191288745544
Trained batch 381 in epoch 13, gen_loss = 0.39769447965459676, disc_loss = 0.09815585786593756
Trained batch 382 in epoch 13, gen_loss = 0.39781503165359594, disc_loss = 0.09793734549260248
Trained batch 383 in epoch 13, gen_loss = 0.39769602838593227, disc_loss = 0.09776042776502436
Trained batch 384 in epoch 13, gen_loss = 0.3977784716463708, disc_loss = 0.09761281887480577
Trained batch 385 in epoch 13, gen_loss = 0.39817680047892534, disc_loss = 0.09786312771632959
Trained batch 386 in epoch 13, gen_loss = 0.3978280456645236, disc_loss = 0.09797621088328673
Trained batch 387 in epoch 13, gen_loss = 0.3978140079944404, disc_loss = 0.09796871378604975
Trained batch 388 in epoch 13, gen_loss = 0.39775065928314524, disc_loss = 0.097779113131367
Trained batch 389 in epoch 13, gen_loss = 0.397961993324451, disc_loss = 0.09780300304723474
Trained batch 390 in epoch 13, gen_loss = 0.39818289555856945, disc_loss = 0.09782150911067224
Trained batch 391 in epoch 13, gen_loss = 0.39833702207828053, disc_loss = 0.0976093300660996
Trained batch 392 in epoch 13, gen_loss = 0.3980961366160832, disc_loss = 0.0975836255912297
Trained batch 393 in epoch 13, gen_loss = 0.3979178689004201, disc_loss = 0.0979200841948806
Trained batch 394 in epoch 13, gen_loss = 0.39779256770882426, disc_loss = 0.09770560216017161
Trained batch 395 in epoch 13, gen_loss = 0.3977293369896484, disc_loss = 0.09754646421325477
Trained batch 396 in epoch 13, gen_loss = 0.3978430026724597, disc_loss = 0.09737815741233771
Trained batch 397 in epoch 13, gen_loss = 0.39791150248829443, disc_loss = 0.09733863880193264
Trained batch 398 in epoch 13, gen_loss = 0.39789016324475895, disc_loss = 0.0972802887313572
Trained batch 399 in epoch 13, gen_loss = 0.39759973824024203, disc_loss = 0.09745393115561456
Trained batch 400 in epoch 13, gen_loss = 0.3980027313838873, disc_loss = 0.09791103209324757
Trained batch 401 in epoch 13, gen_loss = 0.3980002871793301, disc_loss = 0.09772936630048859
Trained batch 402 in epoch 13, gen_loss = 0.3978157442053849, disc_loss = 0.09805182296385244
Trained batch 403 in epoch 13, gen_loss = 0.39772318694556114, disc_loss = 0.09806392147288759
Trained batch 404 in epoch 13, gen_loss = 0.3977257749180735, disc_loss = 0.09792122053511348
Trained batch 405 in epoch 13, gen_loss = 0.3977717648586029, disc_loss = 0.09773637285556992
Trained batch 406 in epoch 13, gen_loss = 0.39773571915942857, disc_loss = 0.09768144882464877
Trained batch 407 in epoch 13, gen_loss = 0.39766373302714497, disc_loss = 0.09825962852211852
Trained batch 408 in epoch 13, gen_loss = 0.39763548562171114, disc_loss = 0.09834179141009933
Trained batch 409 in epoch 13, gen_loss = 0.39763255802596487, disc_loss = 0.0983427245169878
Trained batch 410 in epoch 13, gen_loss = 0.3976418723300136, disc_loss = 0.09834495610092968
Trained batch 411 in epoch 13, gen_loss = 0.3976553577965903, disc_loss = 0.09883565762197798
Trained batch 412 in epoch 13, gen_loss = 0.39754752977131064, disc_loss = 0.09891844476791906
Trained batch 413 in epoch 13, gen_loss = 0.39767647739769757, disc_loss = 0.09872990083129365
Trained batch 414 in epoch 13, gen_loss = 0.3976294383945235, disc_loss = 0.09862178614789463
Trained batch 415 in epoch 13, gen_loss = 0.39755066863905925, disc_loss = 0.09867897793167056
Trained batch 416 in epoch 13, gen_loss = 0.39758014771864, disc_loss = 0.09855261504453577
Trained batch 417 in epoch 13, gen_loss = 0.3976771995496522, disc_loss = 0.09840242713957169
Trained batch 418 in epoch 13, gen_loss = 0.39764953114821405, disc_loss = 0.09827455515953265
Trained batch 419 in epoch 13, gen_loss = 0.39767308646724336, disc_loss = 0.0982836384547963
Trained batch 420 in epoch 13, gen_loss = 0.3979146404107789, disc_loss = 0.0985282826283836
Trained batch 421 in epoch 13, gen_loss = 0.39795506643175516, disc_loss = 0.09831943195224939
Trained batch 422 in epoch 13, gen_loss = 0.39787693353409465, disc_loss = 0.09839199097655343
Trained batch 423 in epoch 13, gen_loss = 0.3980417837792972, disc_loss = 0.0982351922430098
Trained batch 424 in epoch 13, gen_loss = 0.39806702115956477, disc_loss = 0.09829130850294057
Trained batch 425 in epoch 13, gen_loss = 0.39793084743716906, disc_loss = 0.09822874770722759
Trained batch 426 in epoch 13, gen_loss = 0.3978771184171949, disc_loss = 0.09808469554125844
Trained batch 427 in epoch 13, gen_loss = 0.3979993828824747, disc_loss = 0.09795163596205622
Trained batch 428 in epoch 13, gen_loss = 0.39802349551574334, disc_loss = 0.09785294208875348
Trained batch 429 in epoch 13, gen_loss = 0.39814722565717475, disc_loss = 0.0979040194649336
Trained batch 430 in epoch 13, gen_loss = 0.3980225406915572, disc_loss = 0.09823866688976984
Trained batch 431 in epoch 13, gen_loss = 0.3980298203036741, disc_loss = 0.09855683088406092
Trained batch 432 in epoch 13, gen_loss = 0.3978495124305919, disc_loss = 0.0985384570998215
Trained batch 433 in epoch 13, gen_loss = 0.3977632203272411, disc_loss = 0.09845487182865495
Trained batch 434 in epoch 13, gen_loss = 0.3976414187886249, disc_loss = 0.09838817590612105
Trained batch 435 in epoch 13, gen_loss = 0.3977933179484595, disc_loss = 0.09825071354969106
Trained batch 436 in epoch 13, gen_loss = 0.3979008930907915, disc_loss = 0.09813823026671017
Trained batch 437 in epoch 13, gen_loss = 0.39786875622185397, disc_loss = 0.09825661253677384
Trained batch 438 in epoch 13, gen_loss = 0.39783670873739724, disc_loss = 0.09836613313042493
Trained batch 439 in epoch 13, gen_loss = 0.3979723284190351, disc_loss = 0.09838513277301734
Trained batch 440 in epoch 13, gen_loss = 0.3981218429244294, disc_loss = 0.09820114355745499
Trained batch 441 in epoch 13, gen_loss = 0.3982544652611961, disc_loss = 0.09825480500935699
Trained batch 442 in epoch 13, gen_loss = 0.3980699659201146, disc_loss = 0.09871576713822765
Trained batch 443 in epoch 13, gen_loss = 0.3981799338314984, disc_loss = 0.09865145661306006
Trained batch 444 in epoch 13, gen_loss = 0.3982619035110045, disc_loss = 0.09863273776816518
Trained batch 445 in epoch 13, gen_loss = 0.3983357468528063, disc_loss = 0.09844715219208211
Trained batch 446 in epoch 13, gen_loss = 0.3981489148449311, disc_loss = 0.09828787967896034
Trained batch 447 in epoch 13, gen_loss = 0.39817706355825067, disc_loss = 0.09808491759447081
Trained batch 448 in epoch 13, gen_loss = 0.3980862034322955, disc_loss = 0.09790985255848558
Trained batch 449 in epoch 13, gen_loss = 0.3980758493476444, disc_loss = 0.09770668327084019
Trained batch 450 in epoch 13, gen_loss = 0.3981972301085614, disc_loss = 0.09753978990551142
Trained batch 451 in epoch 13, gen_loss = 0.398172783904371, disc_loss = 0.09741760880698705
Trained batch 452 in epoch 13, gen_loss = 0.39817271518128333, disc_loss = 0.09727590163207508
Trained batch 453 in epoch 13, gen_loss = 0.39802905483918044, disc_loss = 0.09731285688098076
Trained batch 454 in epoch 13, gen_loss = 0.39820745567699056, disc_loss = 0.09767338267251194
Trained batch 455 in epoch 13, gen_loss = 0.39795574009941337, disc_loss = 0.09766331119483271
Trained batch 456 in epoch 13, gen_loss = 0.3977409863367644, disc_loss = 0.09757713258319435
Trained batch 457 in epoch 13, gen_loss = 0.39772518141821483, disc_loss = 0.09787380586858171
Trained batch 458 in epoch 13, gen_loss = 0.39779394176790656, disc_loss = 0.0980715013945106
Testing Epoch 13
Training Epoch 14
Trained batch 0 in epoch 14, gen_loss = 0.3445538580417633, disc_loss = 0.05676154047250748
Trained batch 1 in epoch 14, gen_loss = 0.3624247610569, disc_loss = 0.078191589564085
Trained batch 2 in epoch 14, gen_loss = 0.33511126041412354, disc_loss = 0.0914819488922755
Trained batch 3 in epoch 14, gen_loss = 0.3200514018535614, disc_loss = 0.09163766913115978
Trained batch 4 in epoch 14, gen_loss = 0.3556811213493347, disc_loss = 0.08705079406499863
Trained batch 5 in epoch 14, gen_loss = 0.35386922955513, disc_loss = 0.08279141100744407
Trained batch 6 in epoch 14, gen_loss = 0.3627582149846213, disc_loss = 0.08651729939239365
Trained batch 7 in epoch 14, gen_loss = 0.3707239367067814, disc_loss = 0.11750512523576617
Trained batch 8 in epoch 14, gen_loss = 0.37425412403212654, disc_loss = 0.11836502245730823
Trained batch 9 in epoch 14, gen_loss = 0.37414484918117524, disc_loss = 0.1082386240363121
Trained batch 10 in epoch 14, gen_loss = 0.3853272931142287, disc_loss = 0.10227682204409079
Trained batch 11 in epoch 14, gen_loss = 0.37863536675771076, disc_loss = 0.10876282770186663
Trained batch 12 in epoch 14, gen_loss = 0.3800298090164478, disc_loss = 0.10857322955360779
Trained batch 13 in epoch 14, gen_loss = 0.3783924792494093, disc_loss = 0.10993614393685545
Trained batch 14 in epoch 14, gen_loss = 0.3851799209912618, disc_loss = 0.11142851834495862
Trained batch 15 in epoch 14, gen_loss = 0.38409707322716713, disc_loss = 0.1124323841650039
Trained batch 16 in epoch 14, gen_loss = 0.38334169282632713, disc_loss = 0.11100204047911308
Trained batch 17 in epoch 14, gen_loss = 0.38903609414895374, disc_loss = 0.11027541446189086
Trained batch 18 in epoch 14, gen_loss = 0.3912777602672577, disc_loss = 0.10969529830311474
Trained batch 19 in epoch 14, gen_loss = 0.39156989455223085, disc_loss = 0.10623457841575146
Trained batch 20 in epoch 14, gen_loss = 0.3862843754745665, disc_loss = 0.10505471520480655
Trained batch 21 in epoch 14, gen_loss = 0.3855442987246947, disc_loss = 0.10135251723907211
Trained batch 22 in epoch 14, gen_loss = 0.386295717695485, disc_loss = 0.09887133911252022
Trained batch 23 in epoch 14, gen_loss = 0.38367584471901256, disc_loss = 0.09737794303024809
Trained batch 24 in epoch 14, gen_loss = 0.3884177243709564, disc_loss = 0.09580282717943192
Trained batch 25 in epoch 14, gen_loss = 0.38955186995176166, disc_loss = 0.09311308532666701
Trained batch 26 in epoch 14, gen_loss = 0.388318321219197, disc_loss = 0.09389940890725013
Trained batch 27 in epoch 14, gen_loss = 0.38927250994103296, disc_loss = 0.0929501606816692
Trained batch 28 in epoch 14, gen_loss = 0.3874700901837185, disc_loss = 0.09439203573455071
Trained batch 29 in epoch 14, gen_loss = 0.38816599249839784, disc_loss = 0.09477190369119247
Trained batch 30 in epoch 14, gen_loss = 0.3879522931191229, disc_loss = 0.09205891020716198
Trained batch 31 in epoch 14, gen_loss = 0.38731138687580824, disc_loss = 0.09003113195649348
Trained batch 32 in epoch 14, gen_loss = 0.38559918963547907, disc_loss = 0.08943364100361412
Trained batch 33 in epoch 14, gen_loss = 0.38868673145771027, disc_loss = 0.09069755046135362
Trained batch 34 in epoch 14, gen_loss = 0.3900949920926775, disc_loss = 0.08879047970154456
Trained batch 35 in epoch 14, gen_loss = 0.38976524107986027, disc_loss = 0.08828459035915633
Trained batch 36 in epoch 14, gen_loss = 0.3904336078746899, disc_loss = 0.0871689814721813
Trained batch 37 in epoch 14, gen_loss = 0.3901987091491097, disc_loss = 0.0860522702875498
Trained batch 38 in epoch 14, gen_loss = 0.38952974936900997, disc_loss = 0.08914243981528741
Trained batch 39 in epoch 14, gen_loss = 0.3910439059138298, disc_loss = 0.09305521023925394
Trained batch 40 in epoch 14, gen_loss = 0.39079212270131924, disc_loss = 0.09127220663628201
Trained batch 41 in epoch 14, gen_loss = 0.3910613599277678, disc_loss = 0.08999418394107904
Trained batch 42 in epoch 14, gen_loss = 0.3907581138056378, disc_loss = 0.08986009481947782
Trained batch 43 in epoch 14, gen_loss = 0.38961952179670334, disc_loss = 0.09327490591782737
Trained batch 44 in epoch 14, gen_loss = 0.3903370625442929, disc_loss = 0.10093946289271116
Trained batch 45 in epoch 14, gen_loss = 0.39222396651039954, disc_loss = 0.10015804772062795
Trained batch 46 in epoch 14, gen_loss = 0.3927274441465418, disc_loss = 0.09911340322504018
Trained batch 47 in epoch 14, gen_loss = 0.39078482799232006, disc_loss = 0.0976058513042517
Trained batch 48 in epoch 14, gen_loss = 0.3891324869224003, disc_loss = 0.09609684794761088
Trained batch 49 in epoch 14, gen_loss = 0.3880081820487976, disc_loss = 0.09540591603145003
Trained batch 50 in epoch 14, gen_loss = 0.3892715491500555, disc_loss = 0.09393525143683541
Trained batch 51 in epoch 14, gen_loss = 0.3893367906029408, disc_loss = 0.09351981766163729
Trained batch 52 in epoch 14, gen_loss = 0.38746279702996306, disc_loss = 0.09391659334793968
Trained batch 53 in epoch 14, gen_loss = 0.38737468587027657, disc_loss = 0.09518042929401552
Trained batch 54 in epoch 14, gen_loss = 0.3873816728591919, disc_loss = 0.09613387779417364
Trained batch 55 in epoch 14, gen_loss = 0.3874911963939667, disc_loss = 0.09666943847800472
Trained batch 56 in epoch 14, gen_loss = 0.3877155310229251, disc_loss = 0.0958330737622945
Trained batch 57 in epoch 14, gen_loss = 0.3867970509775754, disc_loss = 0.09508977019517072
Trained batch 58 in epoch 14, gen_loss = 0.3855095020795273, disc_loss = 0.09631553985241612
Trained batch 59 in epoch 14, gen_loss = 0.3857860232392947, disc_loss = 0.09651805670000613
Trained batch 60 in epoch 14, gen_loss = 0.38601054764184795, disc_loss = 0.09549475044439562
Trained batch 61 in epoch 14, gen_loss = 0.38662394208292805, disc_loss = 0.09473353280355373
Trained batch 62 in epoch 14, gen_loss = 0.3862368180638268, disc_loss = 0.09439732907487759
Trained batch 63 in epoch 14, gen_loss = 0.3856815262697637, disc_loss = 0.09384130749094766
Trained batch 64 in epoch 14, gen_loss = 0.3859175416139456, disc_loss = 0.09507985130812113
Trained batch 65 in epoch 14, gen_loss = 0.38521125732046185, disc_loss = 0.09832458258747603
Trained batch 66 in epoch 14, gen_loss = 0.38629305674068964, disc_loss = 0.0983566844613472
Trained batch 67 in epoch 14, gen_loss = 0.3867355138063431, disc_loss = 0.0976824074956205
Trained batch 68 in epoch 14, gen_loss = 0.3866035860517751, disc_loss = 0.09728323143191528
Trained batch 69 in epoch 14, gen_loss = 0.38564815946987696, disc_loss = 0.09722604766221983
Trained batch 70 in epoch 14, gen_loss = 0.3876447769957529, disc_loss = 0.09695250691819779
Trained batch 71 in epoch 14, gen_loss = 0.38860483798715806, disc_loss = 0.09687991371740484
Trained batch 72 in epoch 14, gen_loss = 0.3887002953927811, disc_loss = 0.09674326783326799
Trained batch 73 in epoch 14, gen_loss = 0.38885154313332326, disc_loss = 0.09588514262105564
Trained batch 74 in epoch 14, gen_loss = 0.3886483180522919, disc_loss = 0.09535971108824015
Trained batch 75 in epoch 14, gen_loss = 0.38742438821416153, disc_loss = 0.09482546786679641
Trained batch 76 in epoch 14, gen_loss = 0.38765369916891124, disc_loss = 0.0952515382343879
Trained batch 77 in epoch 14, gen_loss = 0.38839344947766036, disc_loss = 0.09517220034001347
Trained batch 78 in epoch 14, gen_loss = 0.3881889015813417, disc_loss = 0.09509051608841253
Trained batch 79 in epoch 14, gen_loss = 0.38751509264111517, disc_loss = 0.09435484817950054
Trained batch 80 in epoch 14, gen_loss = 0.3885687173884592, disc_loss = 0.09417579340300074
Trained batch 81 in epoch 14, gen_loss = 0.3878673914729095, disc_loss = 0.09454139475369962
Trained batch 82 in epoch 14, gen_loss = 0.38886260663170413, disc_loss = 0.09620002727865813
Trained batch 83 in epoch 14, gen_loss = 0.388193500538667, disc_loss = 0.09950904751063458
Trained batch 84 in epoch 14, gen_loss = 0.38798710388295793, disc_loss = 0.09883438829770859
Trained batch 85 in epoch 14, gen_loss = 0.3887512586837591, disc_loss = 0.09892932220557055
Trained batch 86 in epoch 14, gen_loss = 0.3888313602442029, disc_loss = 0.09898882281120824
Trained batch 87 in epoch 14, gen_loss = 0.3895260989665985, disc_loss = 0.09836017436728897
Trained batch 88 in epoch 14, gen_loss = 0.38898004306836076, disc_loss = 0.09823601403053892
Trained batch 89 in epoch 14, gen_loss = 0.3885882851150301, disc_loss = 0.09773187839115659
Trained batch 90 in epoch 14, gen_loss = 0.387918362905691, disc_loss = 0.09749036408183011
Trained batch 91 in epoch 14, gen_loss = 0.3880763912330503, disc_loss = 0.09690941954234047
Trained batch 92 in epoch 14, gen_loss = 0.38772499913810404, disc_loss = 0.09638209159295726
Trained batch 93 in epoch 14, gen_loss = 0.3887989666867763, disc_loss = 0.09553600935899514
Trained batch 94 in epoch 14, gen_loss = 0.3887107726774718, disc_loss = 0.09568157149968963
Trained batch 95 in epoch 14, gen_loss = 0.38781510076175135, disc_loss = 0.09535693417031628
Trained batch 96 in epoch 14, gen_loss = 0.38786743596657036, disc_loss = 0.09479994531336826
Trained batch 97 in epoch 14, gen_loss = 0.3866699322754023, disc_loss = 0.09531576244388612
Trained batch 98 in epoch 14, gen_loss = 0.3877065798850975, disc_loss = 0.0951875699307732
Trained batch 99 in epoch 14, gen_loss = 0.3887325066328049, disc_loss = 0.0945058190729469
Trained batch 100 in epoch 14, gen_loss = 0.38817576459138703, disc_loss = 0.09456092686309378
Trained batch 101 in epoch 14, gen_loss = 0.3880664037138808, disc_loss = 0.09405519067328058
Trained batch 102 in epoch 14, gen_loss = 0.3874858328439657, disc_loss = 0.09338852406018278
Trained batch 103 in epoch 14, gen_loss = 0.38737328723073006, disc_loss = 0.09261370744878569
Trained batch 104 in epoch 14, gen_loss = 0.38684057309514003, disc_loss = 0.09205470192467882
Trained batch 105 in epoch 14, gen_loss = 0.3876070585453285, disc_loss = 0.09161213874149154
Trained batch 106 in epoch 14, gen_loss = 0.3870386807160957, disc_loss = 0.09096361661033932
Trained batch 107 in epoch 14, gen_loss = 0.38768325442517243, disc_loss = 0.09024846266644697
Trained batch 108 in epoch 14, gen_loss = 0.38790331657873384, disc_loss = 0.09033862626983212
Trained batch 109 in epoch 14, gen_loss = 0.388134814934297, disc_loss = 0.09039915856820616
Trained batch 110 in epoch 14, gen_loss = 0.3887154470692884, disc_loss = 0.08989255468419811
Trained batch 111 in epoch 14, gen_loss = 0.3885658183800323, disc_loss = 0.08968788840242528
Trained batch 112 in epoch 14, gen_loss = 0.389687623334142, disc_loss = 0.08932875649822233
Trained batch 113 in epoch 14, gen_loss = 0.39036808254425986, disc_loss = 0.08883107469106714
Trained batch 114 in epoch 14, gen_loss = 0.3902798582678256, disc_loss = 0.08864855678023204
Trained batch 115 in epoch 14, gen_loss = 0.38999701984997454, disc_loss = 0.08842371875452328
Trained batch 116 in epoch 14, gen_loss = 0.3907142627952445, disc_loss = 0.08852438369972838
Trained batch 117 in epoch 14, gen_loss = 0.3905443455708229, disc_loss = 0.08829745280130183
Trained batch 118 in epoch 14, gen_loss = 0.3906619666504259, disc_loss = 0.08816642116191757
Trained batch 119 in epoch 14, gen_loss = 0.3908848484357198, disc_loss = 0.0877088613420104
Trained batch 120 in epoch 14, gen_loss = 0.39078594928930616, disc_loss = 0.08744838497455208
Trained batch 121 in epoch 14, gen_loss = 0.3911797367647046, disc_loss = 0.08711436765695937
Trained batch 122 in epoch 14, gen_loss = 0.3912898476530866, disc_loss = 0.08684613467080564
Trained batch 123 in epoch 14, gen_loss = 0.3915050717130784, disc_loss = 0.08820357500395228
Trained batch 124 in epoch 14, gen_loss = 0.39095254492759707, disc_loss = 0.09048456182330847
Trained batch 125 in epoch 14, gen_loss = 0.3918065535170691, disc_loss = 0.0909467714631723
Trained batch 126 in epoch 14, gen_loss = 0.39254450868433854, disc_loss = 0.09032467784228053
Trained batch 127 in epoch 14, gen_loss = 0.3925459401216358, disc_loss = 0.09002306329057319
Trained batch 128 in epoch 14, gen_loss = 0.3930267714714819, disc_loss = 0.0896254264092607
Trained batch 129 in epoch 14, gen_loss = 0.39310399821171393, disc_loss = 0.09002751446543977
Trained batch 130 in epoch 14, gen_loss = 0.3929167433094432, disc_loss = 0.09032614451641117
Trained batch 131 in epoch 14, gen_loss = 0.39392736170328024, disc_loss = 0.08990549778029548
Trained batch 132 in epoch 14, gen_loss = 0.393490840841953, disc_loss = 0.08980326149332568
Trained batch 133 in epoch 14, gen_loss = 0.3938097562362899, disc_loss = 0.08947347851692518
Trained batch 134 in epoch 14, gen_loss = 0.3933550538840117, disc_loss = 0.08920786658784857
Trained batch 135 in epoch 14, gen_loss = 0.3933588746277725, disc_loss = 0.08902667037567452
Trained batch 136 in epoch 14, gen_loss = 0.39259833880584605, disc_loss = 0.08940042024410337
Trained batch 137 in epoch 14, gen_loss = 0.39287916776062787, disc_loss = 0.08954817112670213
Trained batch 138 in epoch 14, gen_loss = 0.39298729759326084, disc_loss = 0.08903548705036478
Trained batch 139 in epoch 14, gen_loss = 0.39322670080832073, disc_loss = 0.08857866381295025
Trained batch 140 in epoch 14, gen_loss = 0.3933907267472423, disc_loss = 0.08866149963190158
Trained batch 141 in epoch 14, gen_loss = 0.3939158190304125, disc_loss = 0.08835888645467414
Trained batch 142 in epoch 14, gen_loss = 0.3940746775873891, disc_loss = 0.08820430681083377
Trained batch 143 in epoch 14, gen_loss = 0.39343206708629924, disc_loss = 0.08868356170003405
Trained batch 144 in epoch 14, gen_loss = 0.39356631801046177, disc_loss = 0.08823738521414584
Trained batch 145 in epoch 14, gen_loss = 0.39312868902128034, disc_loss = 0.08893596597194467
Trained batch 146 in epoch 14, gen_loss = 0.3931504287281815, disc_loss = 0.08896792453846761
Trained batch 147 in epoch 14, gen_loss = 0.3932583758959899, disc_loss = 0.08842984031306932
Trained batch 148 in epoch 14, gen_loss = 0.39252659978482546, disc_loss = 0.08804303340788856
Trained batch 149 in epoch 14, gen_loss = 0.3935794687271118, disc_loss = 0.08848145358885327
Trained batch 150 in epoch 14, gen_loss = 0.393425354697057, disc_loss = 0.08936459904795649
Trained batch 151 in epoch 14, gen_loss = 0.3940469126560186, disc_loss = 0.0893909122218917
Trained batch 152 in epoch 14, gen_loss = 0.3940505687317817, disc_loss = 0.08900525794041897
Trained batch 153 in epoch 14, gen_loss = 0.39342531058695407, disc_loss = 0.08853928595418473
Trained batch 154 in epoch 14, gen_loss = 0.39300805157230745, disc_loss = 0.08841939477790747
Trained batch 155 in epoch 14, gen_loss = 0.3931705437791653, disc_loss = 0.08839279437700334
Trained batch 156 in epoch 14, gen_loss = 0.3935590428151902, disc_loss = 0.0880221834192705
Trained batch 157 in epoch 14, gen_loss = 0.3932860884108121, disc_loss = 0.08805747231751491
Trained batch 158 in epoch 14, gen_loss = 0.3936476833040609, disc_loss = 0.08878491299355742
Trained batch 159 in epoch 14, gen_loss = 0.39364633429795504, disc_loss = 0.08831635041278788
Trained batch 160 in epoch 14, gen_loss = 0.39349104862035433, disc_loss = 0.08802724799129719
Trained batch 161 in epoch 14, gen_loss = 0.39372489757743884, disc_loss = 0.08754597754321164
Trained batch 162 in epoch 14, gen_loss = 0.39379213174427946, disc_loss = 0.0872783894290679
Trained batch 163 in epoch 14, gen_loss = 0.3934205848632789, disc_loss = 0.08751036983732952
Trained batch 164 in epoch 14, gen_loss = 0.3939673494208943, disc_loss = 0.08752685878425837
Trained batch 165 in epoch 14, gen_loss = 0.3945462166903967, disc_loss = 0.0881042547176132
Trained batch 166 in epoch 14, gen_loss = 0.39411010053343404, disc_loss = 0.08896966870249567
Trained batch 167 in epoch 14, gen_loss = 0.39428096850003513, disc_loss = 0.08933088727228876
Trained batch 168 in epoch 14, gen_loss = 0.3942754088774235, disc_loss = 0.08897117228307844
Trained batch 169 in epoch 14, gen_loss = 0.3942589531926548, disc_loss = 0.08884884652079028
Trained batch 170 in epoch 14, gen_loss = 0.3945501986999958, disc_loss = 0.08842923980729099
Trained batch 171 in epoch 14, gen_loss = 0.39483103849167045, disc_loss = 0.088183531716336
Trained batch 172 in epoch 14, gen_loss = 0.39491514370620595, disc_loss = 0.08809602312808264
Trained batch 173 in epoch 14, gen_loss = 0.3948693124727271, disc_loss = 0.08795621614881802
Trained batch 174 in epoch 14, gen_loss = 0.39490702254431587, disc_loss = 0.08783714814377683
Trained batch 175 in epoch 14, gen_loss = 0.3947439464655789, disc_loss = 0.08749179033541375
Trained batch 176 in epoch 14, gen_loss = 0.3949251228806663, disc_loss = 0.0876023833308432
Trained batch 177 in epoch 14, gen_loss = 0.3948476204041685, disc_loss = 0.08737243891411116
Trained batch 178 in epoch 14, gen_loss = 0.39474930593421337, disc_loss = 0.08785065695872353
Trained batch 179 in epoch 14, gen_loss = 0.39516035169363023, disc_loss = 0.08798633887846437
Trained batch 180 in epoch 14, gen_loss = 0.3953008521656964, disc_loss = 0.08755635233976729
Trained batch 181 in epoch 14, gen_loss = 0.3952187786062995, disc_loss = 0.087435982205424
Trained batch 182 in epoch 14, gen_loss = 0.3958636162385263, disc_loss = 0.08713451005986643
Trained batch 183 in epoch 14, gen_loss = 0.39582911927414977, disc_loss = 0.08706760210612707
Trained batch 184 in epoch 14, gen_loss = 0.395552466850023, disc_loss = 0.08750104105251061
Trained batch 185 in epoch 14, gen_loss = 0.395639909371253, disc_loss = 0.08767537883312632
Trained batch 186 in epoch 14, gen_loss = 0.39605404301123187, disc_loss = 0.0873687078897408
Trained batch 187 in epoch 14, gen_loss = 0.39573050686653627, disc_loss = 0.08736930348157407
Trained batch 188 in epoch 14, gen_loss = 0.39647335192513844, disc_loss = 0.08742108519765593
Trained batch 189 in epoch 14, gen_loss = 0.39637983221756784, disc_loss = 0.08723365947310077
Trained batch 190 in epoch 14, gen_loss = 0.39644393106405645, disc_loss = 0.08693926543953064
Trained batch 191 in epoch 14, gen_loss = 0.39704514962310594, disc_loss = 0.08659730178866691
Trained batch 192 in epoch 14, gen_loss = 0.3970537956205674, disc_loss = 0.08635569240782082
Trained batch 193 in epoch 14, gen_loss = 0.3974421084234395, disc_loss = 0.08639431664643367
Trained batch 194 in epoch 14, gen_loss = 0.39705520715468967, disc_loss = 0.0872794657611312
Trained batch 195 in epoch 14, gen_loss = 0.3975717160774737, disc_loss = 0.08741236611611533
Trained batch 196 in epoch 14, gen_loss = 0.3977178907031335, disc_loss = 0.08703956530349055
Trained batch 197 in epoch 14, gen_loss = 0.39738874032039834, disc_loss = 0.08669825933516176
Trained batch 198 in epoch 14, gen_loss = 0.3973798378927624, disc_loss = 0.08673013735974404
Trained batch 199 in epoch 14, gen_loss = 0.39737723842263223, disc_loss = 0.08685102344024927
Trained batch 200 in epoch 14, gen_loss = 0.39742938025080743, disc_loss = 0.08687886570242062
Trained batch 201 in epoch 14, gen_loss = 0.3971362072642487, disc_loss = 0.08670443186241358
Trained batch 202 in epoch 14, gen_loss = 0.3977699925746824, disc_loss = 0.08770205271820276
Trained batch 203 in epoch 14, gen_loss = 0.3975062976573028, disc_loss = 0.0876078254351502
Trained batch 204 in epoch 14, gen_loss = 0.3970090579695818, disc_loss = 0.0882939416506305
Trained batch 205 in epoch 14, gen_loss = 0.3971362812715827, disc_loss = 0.08809297145299107
Trained batch 206 in epoch 14, gen_loss = 0.3974796385292846, disc_loss = 0.0877664947324401
Trained batch 207 in epoch 14, gen_loss = 0.39761923640393293, disc_loss = 0.0875225195956703
Trained batch 208 in epoch 14, gen_loss = 0.3983055805190328, disc_loss = 0.08714986250749188
Trained batch 209 in epoch 14, gen_loss = 0.39816436072190603, disc_loss = 0.08702301326695652
Trained batch 210 in epoch 14, gen_loss = 0.3982088184469684, disc_loss = 0.08677742853142781
Trained batch 211 in epoch 14, gen_loss = 0.39782684240138755, disc_loss = 0.08675855289670234
Trained batch 212 in epoch 14, gen_loss = 0.3976053325503085, disc_loss = 0.08647793921873743
Trained batch 213 in epoch 14, gen_loss = 0.39776401611689094, disc_loss = 0.0863485716013499
Trained batch 214 in epoch 14, gen_loss = 0.39776131053303565, disc_loss = 0.0862190694006723
Trained batch 215 in epoch 14, gen_loss = 0.3977525627447499, disc_loss = 0.08628002192428405
Trained batch 216 in epoch 14, gen_loss = 0.39754866042994136, disc_loss = 0.087362173622826
Trained batch 217 in epoch 14, gen_loss = 0.39795277889715425, disc_loss = 0.08921187115115446
Trained batch 218 in epoch 14, gen_loss = 0.3977408943927451, disc_loss = 0.0896334074241998
Trained batch 219 in epoch 14, gen_loss = 0.39756731580604204, disc_loss = 0.08968417946333912
Trained batch 220 in epoch 14, gen_loss = 0.3975272633101606, disc_loss = 0.0894785713598267
Trained batch 221 in epoch 14, gen_loss = 0.3973822829959629, disc_loss = 0.09012771284140579
Trained batch 222 in epoch 14, gen_loss = 0.3968998745685201, disc_loss = 0.09033596081734371
Trained batch 223 in epoch 14, gen_loss = 0.3971645881288818, disc_loss = 0.09018570417954054
Trained batch 224 in epoch 14, gen_loss = 0.3974997321764628, disc_loss = 0.09007150226583084
Trained batch 225 in epoch 14, gen_loss = 0.3973435568334782, disc_loss = 0.08997845129250029
Trained batch 226 in epoch 14, gen_loss = 0.39710931420851386, disc_loss = 0.09010207998086309
Trained batch 227 in epoch 14, gen_loss = 0.3970165182101099, disc_loss = 0.09013714386852817
Trained batch 228 in epoch 14, gen_loss = 0.3970134436563633, disc_loss = 0.08991025391901034
Trained batch 229 in epoch 14, gen_loss = 0.3967286790194719, disc_loss = 0.08983553719666341
Trained batch 230 in epoch 14, gen_loss = 0.39677248527477316, disc_loss = 0.08959771123880045
Trained batch 231 in epoch 14, gen_loss = 0.39699634305875875, disc_loss = 0.08979006829783963
Trained batch 232 in epoch 14, gen_loss = 0.39702965709272886, disc_loss = 0.0911200499210043
Trained batch 233 in epoch 14, gen_loss = 0.39716395379131675, disc_loss = 0.09091524762682553
Trained batch 234 in epoch 14, gen_loss = 0.39731131538431697, disc_loss = 0.0907115761785114
Trained batch 235 in epoch 14, gen_loss = 0.3970955299623942, disc_loss = 0.0906373653758191
Trained batch 236 in epoch 14, gen_loss = 0.39718975950394, disc_loss = 0.09044786091925348
Trained batch 237 in epoch 14, gen_loss = 0.39722891665306415, disc_loss = 0.0903240913924362
Trained batch 238 in epoch 14, gen_loss = 0.3973443543063048, disc_loss = 0.09039202530841074
Trained batch 239 in epoch 14, gen_loss = 0.39716338738799095, disc_loss = 0.09063712940939392
Trained batch 240 in epoch 14, gen_loss = 0.3970464348051063, disc_loss = 0.0903533952372512
Trained batch 241 in epoch 14, gen_loss = 0.39736113728077943, disc_loss = 0.09027590866254503
Trained batch 242 in epoch 14, gen_loss = 0.3973704797250253, disc_loss = 0.09020743928773045
Trained batch 243 in epoch 14, gen_loss = 0.3975660620165653, disc_loss = 0.09008196521871036
Trained batch 244 in epoch 14, gen_loss = 0.39737882614135744, disc_loss = 0.08995005234847872
Trained batch 245 in epoch 14, gen_loss = 0.3969542895390735, disc_loss = 0.08995415266164071
Trained batch 246 in epoch 14, gen_loss = 0.3967105075415329, disc_loss = 0.08973811146414835
Trained batch 247 in epoch 14, gen_loss = 0.3968577870438176, disc_loss = 0.08951840248154176
Trained batch 248 in epoch 14, gen_loss = 0.39736441603626116, disc_loss = 0.08928146997623775
Trained batch 249 in epoch 14, gen_loss = 0.3972125324010849, disc_loss = 0.0897888750769198
Trained batch 250 in epoch 14, gen_loss = 0.3969886211522547, disc_loss = 0.0897463792267133
Trained batch 251 in epoch 14, gen_loss = 0.397613073743525, disc_loss = 0.089559993754688
Trained batch 252 in epoch 14, gen_loss = 0.3974961711483982, disc_loss = 0.08924856967855938
Trained batch 253 in epoch 14, gen_loss = 0.39707529838160266, disc_loss = 0.08981127858411257
Trained batch 254 in epoch 14, gen_loss = 0.39743965501878775, disc_loss = 0.0911807618633497
Trained batch 255 in epoch 14, gen_loss = 0.3976461178390309, disc_loss = 0.0909419522540702
Trained batch 256 in epoch 14, gen_loss = 0.3975629202354743, disc_loss = 0.09095499760576375
Trained batch 257 in epoch 14, gen_loss = 0.3976295029008111, disc_loss = 0.09085064323965547
Trained batch 258 in epoch 14, gen_loss = 0.3972302359963936, disc_loss = 0.09067155608123449
Trained batch 259 in epoch 14, gen_loss = 0.3971899126584713, disc_loss = 0.09059867650055542
Trained batch 260 in epoch 14, gen_loss = 0.39693703002856606, disc_loss = 0.09045744049666142
Trained batch 261 in epoch 14, gen_loss = 0.3965838460521844, disc_loss = 0.09037329531310283
Trained batch 262 in epoch 14, gen_loss = 0.39656799646384816, disc_loss = 0.09035406696889904
Trained batch 263 in epoch 14, gen_loss = 0.3963251432234591, disc_loss = 0.0903417770786098
Trained batch 264 in epoch 14, gen_loss = 0.3959394504439156, disc_loss = 0.09060274060674996
Trained batch 265 in epoch 14, gen_loss = 0.39627242693327425, disc_loss = 0.09062244862500102
Trained batch 266 in epoch 14, gen_loss = 0.39625024438350837, disc_loss = 0.09042478844258334
Trained batch 267 in epoch 14, gen_loss = 0.3962300187393801, disc_loss = 0.09038226084380563
Trained batch 268 in epoch 14, gen_loss = 0.39626570029329633, disc_loss = 0.09010802418145882
Trained batch 269 in epoch 14, gen_loss = 0.3964699198802312, disc_loss = 0.08997373056287566
Trained batch 270 in epoch 14, gen_loss = 0.39633896902918375, disc_loss = 0.08990663245691474
Trained batch 271 in epoch 14, gen_loss = 0.3962358771001591, disc_loss = 0.08985313641331981
Trained batch 272 in epoch 14, gen_loss = 0.39652132987976074, disc_loss = 0.08996640554810073
Trained batch 273 in epoch 14, gen_loss = 0.39647428756647735, disc_loss = 0.09001965434324459
Trained batch 274 in epoch 14, gen_loss = 0.3962444585019892, disc_loss = 0.08980795071544972
Trained batch 275 in epoch 14, gen_loss = 0.3964896947145462, disc_loss = 0.08990813777916998
Trained batch 276 in epoch 14, gen_loss = 0.3963719672029199, disc_loss = 0.09057252724665059
Trained batch 277 in epoch 14, gen_loss = 0.3964902595650378, disc_loss = 0.09067068870427261
Trained batch 278 in epoch 14, gen_loss = 0.3962410176740325, disc_loss = 0.09045189879100275
Trained batch 279 in epoch 14, gen_loss = 0.39580225657139506, disc_loss = 0.09071049486353461
Trained batch 280 in epoch 14, gen_loss = 0.3959874404706989, disc_loss = 0.09052866024836845
Trained batch 281 in epoch 14, gen_loss = 0.39614074312626046, disc_loss = 0.0903497313558791
Trained batch 282 in epoch 14, gen_loss = 0.3962532957956563, disc_loss = 0.09038477744775505
Trained batch 283 in epoch 14, gen_loss = 0.3962820119840998, disc_loss = 0.09033347601661275
Trained batch 284 in epoch 14, gen_loss = 0.3958544986289844, disc_loss = 0.09068378794023342
Trained batch 285 in epoch 14, gen_loss = 0.3960870808654732, disc_loss = 0.09068592524129923
Trained batch 286 in epoch 14, gen_loss = 0.39612238591971716, disc_loss = 0.09053616122852115
Trained batch 287 in epoch 14, gen_loss = 0.3959607134262721, disc_loss = 0.09085735389898117
Trained batch 288 in epoch 14, gen_loss = 0.3959483815724462, disc_loss = 0.09178589940212899
Trained batch 289 in epoch 14, gen_loss = 0.3958124535864797, disc_loss = 0.09163013494669878
Trained batch 290 in epoch 14, gen_loss = 0.3956973866089103, disc_loss = 0.09199482303343176
Trained batch 291 in epoch 14, gen_loss = 0.39595273565756134, disc_loss = 0.09223588911676142
Trained batch 292 in epoch 14, gen_loss = 0.39589352727750055, disc_loss = 0.09213302328661338
Trained batch 293 in epoch 14, gen_loss = 0.3956531619741803, disc_loss = 0.09221423529785405
Trained batch 294 in epoch 14, gen_loss = 0.3956020138021243, disc_loss = 0.09196397420650317
Trained batch 295 in epoch 14, gen_loss = 0.3955335978519272, disc_loss = 0.09193528479758047
Trained batch 296 in epoch 14, gen_loss = 0.3956076548958467, disc_loss = 0.09219819840093955
Trained batch 297 in epoch 14, gen_loss = 0.39565407129742153, disc_loss = 0.09198914536731255
Trained batch 298 in epoch 14, gen_loss = 0.39559536434734943, disc_loss = 0.0918268261689157
Trained batch 299 in epoch 14, gen_loss = 0.39585529069105785, disc_loss = 0.09164175068028271
Trained batch 300 in epoch 14, gen_loss = 0.39574557077449024, disc_loss = 0.09156018604162425
Trained batch 301 in epoch 14, gen_loss = 0.3959723555094359, disc_loss = 0.09173842455069257
Trained batch 302 in epoch 14, gen_loss = 0.39582520693835643, disc_loss = 0.092075400961188
Trained batch 303 in epoch 14, gen_loss = 0.39580440678094564, disc_loss = 0.09208653587541592
Trained batch 304 in epoch 14, gen_loss = 0.39581027597677515, disc_loss = 0.09187889052402289
Trained batch 305 in epoch 14, gen_loss = 0.39580486315527774, disc_loss = 0.09171334120560608
Trained batch 306 in epoch 14, gen_loss = 0.39569269135254603, disc_loss = 0.09150319924147296
Trained batch 307 in epoch 14, gen_loss = 0.3956369877635659, disc_loss = 0.09128585367390958
Trained batch 308 in epoch 14, gen_loss = 0.3956148566551579, disc_loss = 0.09110909939402997
Trained batch 309 in epoch 14, gen_loss = 0.3957709815232984, disc_loss = 0.0908999637640532
Trained batch 310 in epoch 14, gen_loss = 0.3960241960942554, disc_loss = 0.0906915955419182
Trained batch 311 in epoch 14, gen_loss = 0.39597241828838986, disc_loss = 0.0905019512358241
Trained batch 312 in epoch 14, gen_loss = 0.39637621294576136, disc_loss = 0.09070456760248151
Trained batch 313 in epoch 14, gen_loss = 0.39619921432558897, disc_loss = 0.09131613790478771
Trained batch 314 in epoch 14, gen_loss = 0.39623685696768385, disc_loss = 0.09124145215998093
Trained batch 315 in epoch 14, gen_loss = 0.396183652119546, disc_loss = 0.09118865080519661
Trained batch 316 in epoch 14, gen_loss = 0.396045861936142, disc_loss = 0.09103445018045252
Trained batch 317 in epoch 14, gen_loss = 0.39584756000611765, disc_loss = 0.09082923244110912
Trained batch 318 in epoch 14, gen_loss = 0.3959500525251825, disc_loss = 0.09061859300809688
Trained batch 319 in epoch 14, gen_loss = 0.3960195490159094, disc_loss = 0.09038291962933727
Trained batch 320 in epoch 14, gen_loss = 0.39620103782211136, disc_loss = 0.09015797185958174
Trained batch 321 in epoch 14, gen_loss = 0.39608057731797236, disc_loss = 0.09001415261640126
Trained batch 322 in epoch 14, gen_loss = 0.3961045544582993, disc_loss = 0.089846127928918
Trained batch 323 in epoch 14, gen_loss = 0.39623304750816324, disc_loss = 0.08982364018735142
Trained batch 324 in epoch 14, gen_loss = 0.3962827911743751, disc_loss = 0.08996258152792087
Trained batch 325 in epoch 14, gen_loss = 0.3961040425154329, disc_loss = 0.08991702839709316
Trained batch 326 in epoch 14, gen_loss = 0.39609929973926017, disc_loss = 0.08976793459499831
Trained batch 327 in epoch 14, gen_loss = 0.3958832752413866, disc_loss = 0.08964566922201435
Trained batch 328 in epoch 14, gen_loss = 0.3958565427901897, disc_loss = 0.08967124894374591
Trained batch 329 in epoch 14, gen_loss = 0.396026209267703, disc_loss = 0.08968006642817548
Trained batch 330 in epoch 14, gen_loss = 0.3959560391585992, disc_loss = 0.08943741407886913
Trained batch 331 in epoch 14, gen_loss = 0.3963038669113653, disc_loss = 0.089245604962694
Trained batch 332 in epoch 14, gen_loss = 0.396284156733447, disc_loss = 0.08912570407060352
Trained batch 333 in epoch 14, gen_loss = 0.396768578512226, disc_loss = 0.08952610381505267
Trained batch 334 in epoch 14, gen_loss = 0.3964162501826215, disc_loss = 0.08954812083115328
Trained batch 335 in epoch 14, gen_loss = 0.39635832155389444, disc_loss = 0.08937683476999934
Trained batch 336 in epoch 14, gen_loss = 0.3966548904467054, disc_loss = 0.08932357473238109
Trained batch 337 in epoch 14, gen_loss = 0.39668166707958696, disc_loss = 0.08940617091534935
Trained batch 338 in epoch 14, gen_loss = 0.39687221099493425, disc_loss = 0.08924613135336598
Trained batch 339 in epoch 14, gen_loss = 0.3970536451129352, disc_loss = 0.08903044831993825
Trained batch 340 in epoch 14, gen_loss = 0.39711094033683153, disc_loss = 0.08889967123936873
Trained batch 341 in epoch 14, gen_loss = 0.39718952295724413, disc_loss = 0.08871714725589369
Trained batch 342 in epoch 14, gen_loss = 0.39708024367646644, disc_loss = 0.08916639776102134
Trained batch 343 in epoch 14, gen_loss = 0.396897523988818, disc_loss = 0.09063493684042505
Trained batch 344 in epoch 14, gen_loss = 0.3967566258665444, disc_loss = 0.09071929926133675
Trained batch 345 in epoch 14, gen_loss = 0.3967408886706898, disc_loss = 0.09083495164731506
Trained batch 346 in epoch 14, gen_loss = 0.3965880207781833, disc_loss = 0.09095645672842989
Trained batch 347 in epoch 14, gen_loss = 0.39612252616334237, disc_loss = 0.09108364972253812
Trained batch 348 in epoch 14, gen_loss = 0.3960905844468442, disc_loss = 0.0909995756306843
Trained batch 349 in epoch 14, gen_loss = 0.3963170706374305, disc_loss = 0.0909249305778316
Trained batch 350 in epoch 14, gen_loss = 0.3963842053189237, disc_loss = 0.09076338366968849
Trained batch 351 in epoch 14, gen_loss = 0.3965483933517879, disc_loss = 0.09079202367733656
Trained batch 352 in epoch 14, gen_loss = 0.3966582247792155, disc_loss = 0.09109551484350949
Trained batch 353 in epoch 14, gen_loss = 0.3966998024343771, disc_loss = 0.09111668377335967
Trained batch 354 in epoch 14, gen_loss = 0.3966250011618708, disc_loss = 0.09090158853312613
Trained batch 355 in epoch 14, gen_loss = 0.3965612398774436, disc_loss = 0.0907636381832234
Trained batch 356 in epoch 14, gen_loss = 0.3965655644567741, disc_loss = 0.090851497239008
Trained batch 357 in epoch 14, gen_loss = 0.3966090679168701, disc_loss = 0.0906655247838304
Trained batch 358 in epoch 14, gen_loss = 0.39655405067135696, disc_loss = 0.09072868327784007
Trained batch 359 in epoch 14, gen_loss = 0.3965336881577969, disc_loss = 0.09064789082234105
Trained batch 360 in epoch 14, gen_loss = 0.39683965360358814, disc_loss = 0.09056234714727322
Trained batch 361 in epoch 14, gen_loss = 0.39668828438329434, disc_loss = 0.09112771299991819
Trained batch 362 in epoch 14, gen_loss = 0.39684046111159416, disc_loss = 0.09111362131256046
Trained batch 363 in epoch 14, gen_loss = 0.396947654066505, disc_loss = 0.09100707849630943
Trained batch 364 in epoch 14, gen_loss = 0.39690201511121775, disc_loss = 0.09117151951953156
Trained batch 365 in epoch 14, gen_loss = 0.3971779940069699, disc_loss = 0.09165869641010879
Trained batch 366 in epoch 14, gen_loss = 0.39698010496287645, disc_loss = 0.09155819423963653
Trained batch 367 in epoch 14, gen_loss = 0.39696943152533926, disc_loss = 0.09154756767067897
Trained batch 368 in epoch 14, gen_loss = 0.3970904775912846, disc_loss = 0.09139120405120901
Trained batch 369 in epoch 14, gen_loss = 0.39718644151816496, disc_loss = 0.09121155883814837
Trained batch 370 in epoch 14, gen_loss = 0.39718357427422246, disc_loss = 0.0910396655353735
Trained batch 371 in epoch 14, gen_loss = 0.39705191192127043, disc_loss = 0.0909465125571656
Trained batch 372 in epoch 14, gen_loss = 0.3971637101499389, disc_loss = 0.09087311356620559
Trained batch 373 in epoch 14, gen_loss = 0.3973868979330369, disc_loss = 0.09068684242068127
Trained batch 374 in epoch 14, gen_loss = 0.39726202956835427, disc_loss = 0.09073394604523977
Trained batch 375 in epoch 14, gen_loss = 0.39735386798039396, disc_loss = 0.09086939898577143
Trained batch 376 in epoch 14, gen_loss = 0.3972350952637923, disc_loss = 0.09078741996531778
Trained batch 377 in epoch 14, gen_loss = 0.39725996971761107, disc_loss = 0.09058289782996609
Trained batch 378 in epoch 14, gen_loss = 0.39726803532376453, disc_loss = 0.09043122823337844
Trained batch 379 in epoch 14, gen_loss = 0.3972622662782669, disc_loss = 0.09027871686818176
Trained batch 380 in epoch 14, gen_loss = 0.39722976440519797, disc_loss = 0.09023105839311373
Trained batch 381 in epoch 14, gen_loss = 0.3971548349601436, disc_loss = 0.09008644956422492
Trained batch 382 in epoch 14, gen_loss = 0.397165194270505, disc_loss = 0.0899481848976514
Trained batch 383 in epoch 14, gen_loss = 0.39721022693750757, disc_loss = 0.08988122643252912
Trained batch 384 in epoch 14, gen_loss = 0.3973436680707065, disc_loss = 0.09015637234869328
Trained batch 385 in epoch 14, gen_loss = 0.39750637090885577, disc_loss = 0.09015951086791145
Trained batch 386 in epoch 14, gen_loss = 0.39753267746563103, disc_loss = 0.09002207691518913
Trained batch 387 in epoch 14, gen_loss = 0.3974845056066808, disc_loss = 0.08993284694475996
Trained batch 388 in epoch 14, gen_loss = 0.39749460087030897, disc_loss = 0.0897911004650294
Trained batch 389 in epoch 14, gen_loss = 0.39763810711029246, disc_loss = 0.08971071182391964
Trained batch 390 in epoch 14, gen_loss = 0.3976482607214652, disc_loss = 0.08956053476456714
Trained batch 391 in epoch 14, gen_loss = 0.39761281796559994, disc_loss = 0.08947843984862296
Trained batch 392 in epoch 14, gen_loss = 0.397510694865962, disc_loss = 0.08945098135184316
Trained batch 393 in epoch 14, gen_loss = 0.397263501425685, disc_loss = 0.08948187986483352
Trained batch 394 in epoch 14, gen_loss = 0.3974093117291414, disc_loss = 0.09007058855429104
Trained batch 395 in epoch 14, gen_loss = 0.3973080923761984, disc_loss = 0.08997322298877995
Trained batch 396 in epoch 14, gen_loss = 0.3969351448099919, disc_loss = 0.09002526779835035
Trained batch 397 in epoch 14, gen_loss = 0.3970893641662358, disc_loss = 0.08998582596146507
Trained batch 398 in epoch 14, gen_loss = 0.3970281283807635, disc_loss = 0.08981823077878184
Trained batch 399 in epoch 14, gen_loss = 0.39687635250389575, disc_loss = 0.08976397390244528
Trained batch 400 in epoch 14, gen_loss = 0.3967747538167045, disc_loss = 0.08967403201456008
Trained batch 401 in epoch 14, gen_loss = 0.3967449239533932, disc_loss = 0.08956102227829212
Trained batch 402 in epoch 14, gen_loss = 0.3967421562884641, disc_loss = 0.08945385789817602
Trained batch 403 in epoch 14, gen_loss = 0.39664501652564155, disc_loss = 0.089501885492078
Trained batch 404 in epoch 14, gen_loss = 0.3965977555439796, disc_loss = 0.09033133357901264
Trained batch 405 in epoch 14, gen_loss = 0.3965234320445601, disc_loss = 0.09038290069232066
Trained batch 406 in epoch 14, gen_loss = 0.39640301597792044, disc_loss = 0.09028066118780972
Trained batch 407 in epoch 14, gen_loss = 0.3960772623472354, disc_loss = 0.0903832054783718
Trained batch 408 in epoch 14, gen_loss = 0.3957386556056426, disc_loss = 0.09043639869836767
Trained batch 409 in epoch 14, gen_loss = 0.3959298377356878, disc_loss = 0.09023369081522815
Trained batch 410 in epoch 14, gen_loss = 0.39607851196379557, disc_loss = 0.09030861298410889
Trained batch 411 in epoch 14, gen_loss = 0.3958566941827246, disc_loss = 0.09051435156521903
Trained batch 412 in epoch 14, gen_loss = 0.39589626354686286, disc_loss = 0.090504648264263
Trained batch 413 in epoch 14, gen_loss = 0.3959716844961839, disc_loss = 0.09033712148688877
Trained batch 414 in epoch 14, gen_loss = 0.3958955929940005, disc_loss = 0.09024721178147628
Trained batch 415 in epoch 14, gen_loss = 0.3957895707482329, disc_loss = 0.09017943715018471
Trained batch 416 in epoch 14, gen_loss = 0.3956515688976224, disc_loss = 0.09008976908811599
Trained batch 417 in epoch 14, gen_loss = 0.39539807763966645, disc_loss = 0.09043875813114337
Trained batch 418 in epoch 14, gen_loss = 0.3956605379507479, disc_loss = 0.09036347076745797
Trained batch 419 in epoch 14, gen_loss = 0.3958859550101416, disc_loss = 0.09024650197853112
Trained batch 420 in epoch 14, gen_loss = 0.395868700360459, disc_loss = 0.09015750072369985
Trained batch 421 in epoch 14, gen_loss = 0.39592131011858933, disc_loss = 0.09028327621859432
Trained batch 422 in epoch 14, gen_loss = 0.3959110405991827, disc_loss = 0.09026605917369819
Trained batch 423 in epoch 14, gen_loss = 0.3959088772535324, disc_loss = 0.09017246825958795
Trained batch 424 in epoch 14, gen_loss = 0.3957084980431725, disc_loss = 0.09014066332951189
Trained batch 425 in epoch 14, gen_loss = 0.39580616501855176, disc_loss = 0.09056087469292953
Trained batch 426 in epoch 14, gen_loss = 0.3957489559326574, disc_loss = 0.09099501840425633
Trained batch 427 in epoch 14, gen_loss = 0.39579892854824245, disc_loss = 0.09097758346023996
Trained batch 428 in epoch 14, gen_loss = 0.39575041868747807, disc_loss = 0.09088917323746361
Trained batch 429 in epoch 14, gen_loss = 0.39572395647681036, disc_loss = 0.09111826753048877
Trained batch 430 in epoch 14, gen_loss = 0.3957129470710135, disc_loss = 0.09095577748812164
Trained batch 431 in epoch 14, gen_loss = 0.39555810805824065, disc_loss = 0.09097294192179106
Trained batch 432 in epoch 14, gen_loss = 0.39562674985196244, disc_loss = 0.09101236506750243
Trained batch 433 in epoch 14, gen_loss = 0.3957203504401967, disc_loss = 0.09091197815294537
Trained batch 434 in epoch 14, gen_loss = 0.395678375370201, disc_loss = 0.09084718096466071
Trained batch 435 in epoch 14, gen_loss = 0.39564343425658866, disc_loss = 0.0907809434024993
Trained batch 436 in epoch 14, gen_loss = 0.39581869607386383, disc_loss = 0.09070657565443856
Trained batch 437 in epoch 14, gen_loss = 0.3956877506895152, disc_loss = 0.09062175201060735
Trained batch 438 in epoch 14, gen_loss = 0.3958042688277425, disc_loss = 0.09058203499081093
Trained batch 439 in epoch 14, gen_loss = 0.3955257522788915, disc_loss = 0.09096778814194047
Trained batch 440 in epoch 14, gen_loss = 0.3958039486489328, disc_loss = 0.09135941705030817
Trained batch 441 in epoch 14, gen_loss = 0.3958509482814176, disc_loss = 0.09133121386545445
Trained batch 442 in epoch 14, gen_loss = 0.39582486312760723, disc_loss = 0.09144162036936823
Trained batch 443 in epoch 14, gen_loss = 0.395761424423875, disc_loss = 0.0913513447126575
Trained batch 444 in epoch 14, gen_loss = 0.3958363805594069, disc_loss = 0.09124825100487705
Trained batch 445 in epoch 14, gen_loss = 0.3957144595983317, disc_loss = 0.09121471465640438
Trained batch 446 in epoch 14, gen_loss = 0.395677575862381, disc_loss = 0.09103827625075543
Trained batch 447 in epoch 14, gen_loss = 0.3958110392891935, disc_loss = 0.09087730865888131
Trained batch 448 in epoch 14, gen_loss = 0.39571145827361365, disc_loss = 0.09081091989715374
Trained batch 449 in epoch 14, gen_loss = 0.395587555832333, disc_loss = 0.090740661131632
Trained batch 450 in epoch 14, gen_loss = 0.39569126317347764, disc_loss = 0.09094402957976096
Trained batch 451 in epoch 14, gen_loss = 0.3958480432629585, disc_loss = 0.09094254587533826
Trained batch 452 in epoch 14, gen_loss = 0.3960063901563354, disc_loss = 0.0907902001016763
Trained batch 453 in epoch 14, gen_loss = 0.3958907407679747, disc_loss = 0.09090180641208419
Trained batch 454 in epoch 14, gen_loss = 0.3958660664139213, disc_loss = 0.09088266374297686
Trained batch 455 in epoch 14, gen_loss = 0.3959547613927147, disc_loss = 0.09080472288208016
Trained batch 456 in epoch 14, gen_loss = 0.3959243136500895, disc_loss = 0.09086004752539407
Trained batch 457 in epoch 14, gen_loss = 0.39623436923891175, disc_loss = 0.09095910216242432
Trained batch 458 in epoch 14, gen_loss = 0.3969729210946035, disc_loss = 0.09084789282368387
Testing Epoch 14
Training Epoch 15
Trained batch 0 in epoch 15, gen_loss = 0.35793375968933105, disc_loss = 0.01263895072042942
Trained batch 1 in epoch 15, gen_loss = 0.33376339077949524, disc_loss = 0.05824780184775591
Trained batch 2 in epoch 15, gen_loss = 0.3718960682551066, disc_loss = 0.050624661768476166
Trained batch 3 in epoch 15, gen_loss = 0.3751029819250107, disc_loss = 0.042399004101753235
Trained batch 4 in epoch 15, gen_loss = 0.376137787103653, disc_loss = 0.040677505731582644
Trained batch 5 in epoch 15, gen_loss = 0.3835880210002263, disc_loss = 0.055078499019145966
Trained batch 6 in epoch 15, gen_loss = 0.3906827356134142, disc_loss = 0.06895280735833305
Trained batch 7 in epoch 15, gen_loss = 0.4001735635101795, disc_loss = 0.06491080392152071
Trained batch 8 in epoch 15, gen_loss = 0.40620629323853386, disc_loss = 0.06379331193036503
Trained batch 9 in epoch 15, gen_loss = 0.4103120923042297, disc_loss = 0.05951698459684849
Trained batch 10 in epoch 15, gen_loss = 0.40671310370618646, disc_loss = 0.055215058086270634
Trained batch 11 in epoch 15, gen_loss = 0.4110771467288335, disc_loss = 0.05185331217944622
Trained batch 12 in epoch 15, gen_loss = 0.41041452151078445, disc_loss = 0.048708277682845406
Trained batch 13 in epoch 15, gen_loss = 0.40766548046043943, disc_loss = 0.05225047828363521
Trained batch 14 in epoch 15, gen_loss = 0.4087503890196482, disc_loss = 0.0550589744001627
Trained batch 15 in epoch 15, gen_loss = 0.4101288430392742, disc_loss = 0.055565595044754446
Trained batch 16 in epoch 15, gen_loss = 0.412151492693845, disc_loss = 0.05561888973940821
Trained batch 17 in epoch 15, gen_loss = 0.4124677942858802, disc_loss = 0.053894619146982826
Trained batch 18 in epoch 15, gen_loss = 0.41651851095651327, disc_loss = 0.07272512348074663
Trained batch 19 in epoch 15, gen_loss = 0.41190682500600817, disc_loss = 0.07313941717147827
Trained batch 20 in epoch 15, gen_loss = 0.41198810793104623, disc_loss = 0.07157977989741734
Trained batch 21 in epoch 15, gen_loss = 0.4141440012238242, disc_loss = 0.076559033583511
Trained batch 22 in epoch 15, gen_loss = 0.4122180938720703, disc_loss = 0.07419182870375074
Trained batch 23 in epoch 15, gen_loss = 0.410703635464112, disc_loss = 0.08791643187093238
Trained batch 24 in epoch 15, gen_loss = 0.4134060037136078, disc_loss = 0.08955408208072185
Trained batch 25 in epoch 15, gen_loss = 0.4159271510747763, disc_loss = 0.08828513116504137
Trained batch 26 in epoch 15, gen_loss = 0.41349536842770046, disc_loss = 0.08532522180704055
Trained batch 27 in epoch 15, gen_loss = 0.4134367172207151, disc_loss = 0.08395354080546115
Trained batch 28 in epoch 15, gen_loss = 0.4117586088591608, disc_loss = 0.08197004132871998
Trained batch 29 in epoch 15, gen_loss = 0.4101262867450714, disc_loss = 0.08025053214902679
Trained batch 30 in epoch 15, gen_loss = 0.4116899198101413, disc_loss = 0.0785171443356141
Trained batch 31 in epoch 15, gen_loss = 0.41161783784627914, disc_loss = 0.07777970781899057
Trained batch 32 in epoch 15, gen_loss = 0.40982930317069544, disc_loss = 0.07687782007975108
Trained batch 33 in epoch 15, gen_loss = 0.4072739964022356, disc_loss = 0.07671638191951548
Trained batch 34 in epoch 15, gen_loss = 0.4094841011932918, disc_loss = 0.07615739221551589
Trained batch 35 in epoch 15, gen_loss = 0.4113212832146221, disc_loss = 0.07703252185860442
Trained batch 36 in epoch 15, gen_loss = 0.4116187836672809, disc_loss = 0.0762949911877513
Trained batch 37 in epoch 15, gen_loss = 0.4114202088431308, disc_loss = 0.07564057672004167
Trained batch 38 in epoch 15, gen_loss = 0.4083200311049437, disc_loss = 0.07778523124467868
Trained batch 39 in epoch 15, gen_loss = 0.4093191884458065, disc_loss = 0.08237522456329316
Trained batch 40 in epoch 15, gen_loss = 0.40980561041250463, disc_loss = 0.08101009825108255
Trained batch 41 in epoch 15, gen_loss = 0.4116236638455164, disc_loss = 0.08002778348912086
Trained batch 42 in epoch 15, gen_loss = 0.40961635597916535, disc_loss = 0.08047532318376524
Trained batch 43 in epoch 15, gen_loss = 0.4097399731928652, disc_loss = 0.07975740639746866
Trained batch 44 in epoch 15, gen_loss = 0.40976530114809673, disc_loss = 0.07893336160729329
Trained batch 45 in epoch 15, gen_loss = 0.4080885933793109, disc_loss = 0.07997987721034366
Trained batch 46 in epoch 15, gen_loss = 0.4081789813143142, disc_loss = 0.07942379624681904
Trained batch 47 in epoch 15, gen_loss = 0.4079034278790156, disc_loss = 0.08155025722226128
Trained batch 48 in epoch 15, gen_loss = 0.40641806867657876, disc_loss = 0.08460813450950141
Trained batch 49 in epoch 15, gen_loss = 0.406574175953865, disc_loss = 0.08388358863070607
Trained batch 50 in epoch 15, gen_loss = 0.4073575700030607, disc_loss = 0.0839818327632897
Trained batch 51 in epoch 15, gen_loss = 0.4063760804442259, disc_loss = 0.08355124604601699
Trained batch 52 in epoch 15, gen_loss = 0.40645599309003577, disc_loss = 0.08391047924546138
Trained batch 53 in epoch 15, gen_loss = 0.4054622710854919, disc_loss = 0.0834628470690438
Trained batch 54 in epoch 15, gen_loss = 0.4059942294250835, disc_loss = 0.08208462258970195
Trained batch 55 in epoch 15, gen_loss = 0.4058390499225685, disc_loss = 0.08107318291773222
Trained batch 56 in epoch 15, gen_loss = 0.40474016154021547, disc_loss = 0.08079386883202874
Trained batch 57 in epoch 15, gen_loss = 0.4041682892832263, disc_loss = 0.07952205693060212
Trained batch 58 in epoch 15, gen_loss = 0.4040640036938554, disc_loss = 0.08063779352232814
Trained batch 59 in epoch 15, gen_loss = 0.4028592362999916, disc_loss = 0.08335225766059011
Trained batch 60 in epoch 15, gen_loss = 0.4032541391302328, disc_loss = 0.08296000784201944
Trained batch 61 in epoch 15, gen_loss = 0.4044918624624129, disc_loss = 0.08233548974948784
Trained batch 62 in epoch 15, gen_loss = 0.40459756103772965, disc_loss = 0.08211505588232762
Trained batch 63 in epoch 15, gen_loss = 0.4043041421100497, disc_loss = 0.08218263005983317
Trained batch 64 in epoch 15, gen_loss = 0.4037115766451909, disc_loss = 0.08151981140701817
Trained batch 65 in epoch 15, gen_loss = 0.4037093005397103, disc_loss = 0.08060761770431066
Trained batch 66 in epoch 15, gen_loss = 0.4034526170189701, disc_loss = 0.0802241894416511
Trained batch 67 in epoch 15, gen_loss = 0.40344419286531563, disc_loss = 0.07984197959440816
Trained batch 68 in epoch 15, gen_loss = 0.40435971384463104, disc_loss = 0.07912776735948696
Trained batch 69 in epoch 15, gen_loss = 0.4034252294472286, disc_loss = 0.07835738236483719
Trained batch 70 in epoch 15, gen_loss = 0.40398468601871546, disc_loss = 0.078147994728208
Trained batch 71 in epoch 15, gen_loss = 0.4032909559706847, disc_loss = 0.07841046613046071
Trained batch 72 in epoch 15, gen_loss = 0.4033511799492248, disc_loss = 0.0778720100053063
Trained batch 73 in epoch 15, gen_loss = 0.4036570739101719, disc_loss = 0.0770044739899301
Trained batch 74 in epoch 15, gen_loss = 0.40322792331377666, disc_loss = 0.07650590850040316
Trained batch 75 in epoch 15, gen_loss = 0.40285549822606537, disc_loss = 0.07629287157722406
Trained batch 76 in epoch 15, gen_loss = 0.4049288436963961, disc_loss = 0.07588779097181056
Trained batch 77 in epoch 15, gen_loss = 0.4039572267196117, disc_loss = 0.0750113484951166
Trained batch 78 in epoch 15, gen_loss = 0.40291312487819525, disc_loss = 0.07435541161442105
Trained batch 79 in epoch 15, gen_loss = 0.402318798750639, disc_loss = 0.07400246327742935
Trained batch 80 in epoch 15, gen_loss = 0.4019862516426746, disc_loss = 0.0739809779657258
Trained batch 81 in epoch 15, gen_loss = 0.4020324102262171, disc_loss = 0.07354221411231088
Trained batch 82 in epoch 15, gen_loss = 0.40251765911837656, disc_loss = 0.07350661623549748
Trained batch 83 in epoch 15, gen_loss = 0.4021408061186473, disc_loss = 0.07423630241482031
Trained batch 84 in epoch 15, gen_loss = 0.4021162706262925, disc_loss = 0.07377340605153757
Trained batch 85 in epoch 15, gen_loss = 0.4017323505046756, disc_loss = 0.0742771779295317
Trained batch 86 in epoch 15, gen_loss = 0.40100494266926556, disc_loss = 0.07561027211533196
Trained batch 87 in epoch 15, gen_loss = 0.40123038535768335, disc_loss = 0.07513588493351232
Trained batch 88 in epoch 15, gen_loss = 0.40231918685891654, disc_loss = 0.07509473631723543
Trained batch 89 in epoch 15, gen_loss = 0.40099623633755577, disc_loss = 0.07539804275665019
Trained batch 90 in epoch 15, gen_loss = 0.40097357676579404, disc_loss = 0.07541345285026582
Trained batch 91 in epoch 15, gen_loss = 0.40018488272376684, disc_loss = 0.07521920825314263
Trained batch 92 in epoch 15, gen_loss = 0.40001110620396113, disc_loss = 0.07497657258664409
Trained batch 93 in epoch 15, gen_loss = 0.3997749755991266, disc_loss = 0.07558119138504596
Trained batch 94 in epoch 15, gen_loss = 0.40113393883956106, disc_loss = 0.07732259913494713
Trained batch 95 in epoch 15, gen_loss = 0.40053298852096003, disc_loss = 0.0773474167411526
Trained batch 96 in epoch 15, gen_loss = 0.4005853423138255, disc_loss = 0.07704787098408974
Trained batch 97 in epoch 15, gen_loss = 0.4003506631267314, disc_loss = 0.07778430536237298
Trained batch 98 in epoch 15, gen_loss = 0.4002149740252832, disc_loss = 0.07742022899816735
Trained batch 99 in epoch 15, gen_loss = 0.39953856736421584, disc_loss = 0.0783040325716138
Trained batch 100 in epoch 15, gen_loss = 0.39965384431404644, disc_loss = 0.07815987981929637
Trained batch 101 in epoch 15, gen_loss = 0.3998389068771811, disc_loss = 0.07833125811143249
Trained batch 102 in epoch 15, gen_loss = 0.4006213406914646, disc_loss = 0.0784126288320833
Trained batch 103 in epoch 15, gen_loss = 0.40089379623532295, disc_loss = 0.07851293722454172
Trained batch 104 in epoch 15, gen_loss = 0.4004812913281577, disc_loss = 0.07844700518818129
Trained batch 105 in epoch 15, gen_loss = 0.4011739045381546, disc_loss = 0.07791917019014089
Trained batch 106 in epoch 15, gen_loss = 0.40105017685444555, disc_loss = 0.0781194307258196
Trained batch 107 in epoch 15, gen_loss = 0.4015997435759615, disc_loss = 0.07997447045312987
Trained batch 108 in epoch 15, gen_loss = 0.4014934033428857, disc_loss = 0.07976320563653193
Trained batch 109 in epoch 15, gen_loss = 0.40135207420045677, disc_loss = 0.07936600910669023
Trained batch 110 in epoch 15, gen_loss = 0.40117754109270937, disc_loss = 0.07878761316506981
Trained batch 111 in epoch 15, gen_loss = 0.4019126370549202, disc_loss = 0.07838479969151584
Trained batch 112 in epoch 15, gen_loss = 0.40209602307429354, disc_loss = 0.07812594438581603
Trained batch 113 in epoch 15, gen_loss = 0.4020012750437385, disc_loss = 0.07792489038649619
Trained batch 114 in epoch 15, gen_loss = 0.4016624168209408, disc_loss = 0.0781910840988807
Trained batch 115 in epoch 15, gen_loss = 0.4020805312641736, disc_loss = 0.07831743556267486
Trained batch 116 in epoch 15, gen_loss = 0.4018706737929939, disc_loss = 0.07777875369717167
Trained batch 117 in epoch 15, gen_loss = 0.4015995157977282, disc_loss = 0.07754852863470629
Trained batch 118 in epoch 15, gen_loss = 0.4020686883385442, disc_loss = 0.07785665776831012
Trained batch 119 in epoch 15, gen_loss = 0.4015711148579915, disc_loss = 0.07945125265202174
Trained batch 120 in epoch 15, gen_loss = 0.4028767731564104, disc_loss = 0.07994456269801402
Trained batch 121 in epoch 15, gen_loss = 0.40226359152403035, disc_loss = 0.07959836905394665
Trained batch 122 in epoch 15, gen_loss = 0.40172824627015646, disc_loss = 0.0795986510707232
Trained batch 123 in epoch 15, gen_loss = 0.4024289841613462, disc_loss = 0.07925770207188063
Trained batch 124 in epoch 15, gen_loss = 0.4024279637336731, disc_loss = 0.07889848989993334
Trained batch 125 in epoch 15, gen_loss = 0.4022306963091805, disc_loss = 0.07890916959426943
Trained batch 126 in epoch 15, gen_loss = 0.4017916277168304, disc_loss = 0.08080741435318715
Trained batch 127 in epoch 15, gen_loss = 0.4017438942100853, disc_loss = 0.081251677016553
Trained batch 128 in epoch 15, gen_loss = 0.40230678587920904, disc_loss = 0.08081518546064463
Trained batch 129 in epoch 15, gen_loss = 0.4018712722338163, disc_loss = 0.08077914731290478
Trained batch 130 in epoch 15, gen_loss = 0.40192907138635187, disc_loss = 0.08104554483425298
Trained batch 131 in epoch 15, gen_loss = 0.4015630770361785, disc_loss = 0.0807545783604975
Trained batch 132 in epoch 15, gen_loss = 0.4012874053385025, disc_loss = 0.0806887303514028
Trained batch 133 in epoch 15, gen_loss = 0.4020347081458391, disc_loss = 0.0805291770818407
Trained batch 134 in epoch 15, gen_loss = 0.4018940927805724, disc_loss = 0.08047657133666454
Trained batch 135 in epoch 15, gen_loss = 0.40137579927549644, disc_loss = 0.08158567426589262
Trained batch 136 in epoch 15, gen_loss = 0.4013941638226057, disc_loss = 0.08243188359196821
Trained batch 137 in epoch 15, gen_loss = 0.40151400518590125, disc_loss = 0.08198158777035448
Trained batch 138 in epoch 15, gen_loss = 0.401201589502019, disc_loss = 0.08193389845596587
Trained batch 139 in epoch 15, gen_loss = 0.40160658678838185, disc_loss = 0.0815443716876741
Trained batch 140 in epoch 15, gen_loss = 0.40200826948416146, disc_loss = 0.08114341077731645
Trained batch 141 in epoch 15, gen_loss = 0.4017087827685853, disc_loss = 0.08092519307089313
Trained batch 142 in epoch 15, gen_loss = 0.401443209056254, disc_loss = 0.08055743102922097
Trained batch 143 in epoch 15, gen_loss = 0.40151822856730884, disc_loss = 0.08030676652237566
Trained batch 144 in epoch 15, gen_loss = 0.40124970181234954, disc_loss = 0.0799237936670924
Trained batch 145 in epoch 15, gen_loss = 0.4010075924739446, disc_loss = 0.07971581688456952
Trained batch 146 in epoch 15, gen_loss = 0.4006925042794675, disc_loss = 0.07940881247600527
Trained batch 147 in epoch 15, gen_loss = 0.39988279624565226, disc_loss = 0.07935075199458043
Trained batch 148 in epoch 15, gen_loss = 0.3999703698510292, disc_loss = 0.07898006835114836
Trained batch 149 in epoch 15, gen_loss = 0.40007869640986127, disc_loss = 0.07949603648856282
Trained batch 150 in epoch 15, gen_loss = 0.3997606291676199, disc_loss = 0.08102418918359951
Trained batch 151 in epoch 15, gen_loss = 0.39958283344381734, disc_loss = 0.0806134738407931
Trained batch 152 in epoch 15, gen_loss = 0.4002636939871545, disc_loss = 0.08055563370265018
Trained batch 153 in epoch 15, gen_loss = 0.39981235428289935, disc_loss = 0.08059140872331215
Trained batch 154 in epoch 15, gen_loss = 0.4003529131412506, disc_loss = 0.0811269125330352
Trained batch 155 in epoch 15, gen_loss = 0.4001423676426594, disc_loss = 0.08084844092790706
Trained batch 156 in epoch 15, gen_loss = 0.4003530120014385, disc_loss = 0.08040289315068798
Trained batch 157 in epoch 15, gen_loss = 0.4006252217141888, disc_loss = 0.08013304275802419
Trained batch 158 in epoch 15, gen_loss = 0.40025891597915747, disc_loss = 0.08006417212433785
Trained batch 159 in epoch 15, gen_loss = 0.4003643779084086, disc_loss = 0.0799708970822394
Trained batch 160 in epoch 15, gen_loss = 0.4005917258884596, disc_loss = 0.07956533778389419
Trained batch 161 in epoch 15, gen_loss = 0.40046558777491253, disc_loss = 0.07918895761493916
Trained batch 162 in epoch 15, gen_loss = 0.40067929980213657, disc_loss = 0.07897223073966299
Trained batch 163 in epoch 15, gen_loss = 0.40043509497148233, disc_loss = 0.0786712701068964
Trained batch 164 in epoch 15, gen_loss = 0.4003893115303733, disc_loss = 0.07842580404019717
Trained batch 165 in epoch 15, gen_loss = 0.4005850919757981, disc_loss = 0.07861770805061223
Trained batch 166 in epoch 15, gen_loss = 0.40019436528582775, disc_loss = 0.07901143517992097
Trained batch 167 in epoch 15, gen_loss = 0.4004487336746284, disc_loss = 0.0788908620874974
Trained batch 168 in epoch 15, gen_loss = 0.4000734720357071, disc_loss = 0.0789841187445546
Trained batch 169 in epoch 15, gen_loss = 0.4007672571084079, disc_loss = 0.08023037556558847
Trained batch 170 in epoch 15, gen_loss = 0.40059547065294276, disc_loss = 0.08050761582079338
Trained batch 171 in epoch 15, gen_loss = 0.40071265087571256, disc_loss = 0.0801289451720063
Trained batch 172 in epoch 15, gen_loss = 0.40058146615248885, disc_loss = 0.08005993272786195
Trained batch 173 in epoch 15, gen_loss = 0.4006175799616452, disc_loss = 0.0803232792251069
Trained batch 174 in epoch 15, gen_loss = 0.400553811277662, disc_loss = 0.07996500199394567
Trained batch 175 in epoch 15, gen_loss = 0.4006108937954361, disc_loss = 0.07966767070518638
Trained batch 176 in epoch 15, gen_loss = 0.40070257449554186, disc_loss = 0.07931976647531919
Trained batch 177 in epoch 15, gen_loss = 0.40013647431068206, disc_loss = 0.07948415429237184
Trained batch 178 in epoch 15, gen_loss = 0.40054170995451216, disc_loss = 0.08007582285384227
Trained batch 179 in epoch 15, gen_loss = 0.4004800154103173, disc_loss = 0.07994345912916792
Trained batch 180 in epoch 15, gen_loss = 0.4004851505571966, disc_loss = 0.07999322960636893
Trained batch 181 in epoch 15, gen_loss = 0.4008701857957211, disc_loss = 0.08070217963349033
Trained batch 182 in epoch 15, gen_loss = 0.40045329016414494, disc_loss = 0.0805460703381098
Trained batch 183 in epoch 15, gen_loss = 0.4000279357575852, disc_loss = 0.08085114689057936
Trained batch 184 in epoch 15, gen_loss = 0.40033701497155266, disc_loss = 0.08067855055670481
Trained batch 185 in epoch 15, gen_loss = 0.4005114179785534, disc_loss = 0.08085052871335578
Trained batch 186 in epoch 15, gen_loss = 0.4006568097813244, disc_loss = 0.08085429558859152
Trained batch 187 in epoch 15, gen_loss = 0.4006792184837321, disc_loss = 0.08057904542681385
Trained batch 188 in epoch 15, gen_loss = 0.40070197884998626, disc_loss = 0.0802825126580145
Trained batch 189 in epoch 15, gen_loss = 0.40115264748272145, disc_loss = 0.08027290158758038
Trained batch 190 in epoch 15, gen_loss = 0.4009317671441283, disc_loss = 0.08024362386911327
Trained batch 191 in epoch 15, gen_loss = 0.4007508180414637, disc_loss = 0.080549920462848
Trained batch 192 in epoch 15, gen_loss = 0.40095528944786346, disc_loss = 0.0815097458197354
Trained batch 193 in epoch 15, gen_loss = 0.4003276391742156, disc_loss = 0.08206147679425392
Trained batch 194 in epoch 15, gen_loss = 0.4004363264793005, disc_loss = 0.08191280408929556
Trained batch 195 in epoch 15, gen_loss = 0.40063626912175393, disc_loss = 0.08155368441449744
Trained batch 196 in epoch 15, gen_loss = 0.4003804828309771, disc_loss = 0.08139965047842355
Trained batch 197 in epoch 15, gen_loss = 0.40049869830560203, disc_loss = 0.08120915508179953
Trained batch 198 in epoch 15, gen_loss = 0.40017688184527295, disc_loss = 0.08115598697907961
Trained batch 199 in epoch 15, gen_loss = 0.4002335198223591, disc_loss = 0.0813498705253005
Trained batch 200 in epoch 15, gen_loss = 0.40016857353015917, disc_loss = 0.08187761995478056
Trained batch 201 in epoch 15, gen_loss = 0.4000810058695255, disc_loss = 0.08175443474314001
Trained batch 202 in epoch 15, gen_loss = 0.4002021899070646, disc_loss = 0.0815217414402903
Trained batch 203 in epoch 15, gen_loss = 0.39956507685722087, disc_loss = 0.08154494021380064
Trained batch 204 in epoch 15, gen_loss = 0.3998296321892157, disc_loss = 0.08121333749192516
Trained batch 205 in epoch 15, gen_loss = 0.3998428243167192, disc_loss = 0.08131376471261954
Trained batch 206 in epoch 15, gen_loss = 0.3997908587329054, disc_loss = 0.0811539439007568
Trained batch 207 in epoch 15, gen_loss = 0.3999072413604993, disc_loss = 0.08093864588926618
Trained batch 208 in epoch 15, gen_loss = 0.4005850020207857, disc_loss = 0.08072377397326762
Trained batch 209 in epoch 15, gen_loss = 0.40065924936816805, disc_loss = 0.08059502165941965
Trained batch 210 in epoch 15, gen_loss = 0.40043531972650104, disc_loss = 0.08048456644206815
Trained batch 211 in epoch 15, gen_loss = 0.4009808791133593, disc_loss = 0.0801670848356806
Trained batch 212 in epoch 15, gen_loss = 0.4009950947313801, disc_loss = 0.08018489634102219
Trained batch 213 in epoch 15, gen_loss = 0.4009841421497202, disc_loss = 0.07992438616004781
Trained batch 214 in epoch 15, gen_loss = 0.4014165321061777, disc_loss = 0.07989329324038916
Trained batch 215 in epoch 15, gen_loss = 0.4009821241100629, disc_loss = 0.07988077390904504
Trained batch 216 in epoch 15, gen_loss = 0.401049637574754, disc_loss = 0.07959178654039235
Trained batch 217 in epoch 15, gen_loss = 0.400847183455021, disc_loss = 0.0793968664242997
Trained batch 218 in epoch 15, gen_loss = 0.40098416097632283, disc_loss = 0.07925683413908634
Trained batch 219 in epoch 15, gen_loss = 0.40108444609425287, disc_loss = 0.07894792672754689
Trained batch 220 in epoch 15, gen_loss = 0.4013260218622458, disc_loss = 0.07902737249245201
Trained batch 221 in epoch 15, gen_loss = 0.4009949411894824, disc_loss = 0.07909919970106703
Trained batch 222 in epoch 15, gen_loss = 0.40092665438160235, disc_loss = 0.07885546563819652
Trained batch 223 in epoch 15, gen_loss = 0.40122498385608196, disc_loss = 0.07898059403357495
Trained batch 224 in epoch 15, gen_loss = 0.4009140784210629, disc_loss = 0.07910185743537214
Trained batch 225 in epoch 15, gen_loss = 0.4010589958819668, disc_loss = 0.07895848086614789
Trained batch 226 in epoch 15, gen_loss = 0.40099802376940386, disc_loss = 0.0792933765897273
Trained batch 227 in epoch 15, gen_loss = 0.4013455033040883, disc_loss = 0.07979501670291811
Trained batch 228 in epoch 15, gen_loss = 0.40084833908809847, disc_loss = 0.08056243373219363
Trained batch 229 in epoch 15, gen_loss = 0.40103854316732157, disc_loss = 0.08191799771688554
Trained batch 230 in epoch 15, gen_loss = 0.401107663845087, disc_loss = 0.08177211816983047
Trained batch 231 in epoch 15, gen_loss = 0.4005729231084215, disc_loss = 0.08198428906275537
Trained batch 232 in epoch 15, gen_loss = 0.40074699093855504, disc_loss = 0.0818009663597069
Trained batch 233 in epoch 15, gen_loss = 0.4009080033781182, disc_loss = 0.08157214786634485
Trained batch 234 in epoch 15, gen_loss = 0.401056222078648, disc_loss = 0.08163527126641984
Trained batch 235 in epoch 15, gen_loss = 0.4008847312149355, disc_loss = 0.08153544977244179
Trained batch 236 in epoch 15, gen_loss = 0.4006533517113215, disc_loss = 0.0818728942125407
Trained batch 237 in epoch 15, gen_loss = 0.4004932942510653, disc_loss = 0.08178077145096134
Trained batch 238 in epoch 15, gen_loss = 0.400232184880947, disc_loss = 0.08167553755404061
Trained batch 239 in epoch 15, gen_loss = 0.4004615690559149, disc_loss = 0.08140037974032263
Trained batch 240 in epoch 15, gen_loss = 0.40038722914284197, disc_loss = 0.08138386984027272
Trained batch 241 in epoch 15, gen_loss = 0.4002745469247014, disc_loss = 0.08179161240431396
Trained batch 242 in epoch 15, gen_loss = 0.4000691345935005, disc_loss = 0.08263025673512568
Trained batch 243 in epoch 15, gen_loss = 0.4002271596281255, disc_loss = 0.08245769315628243
Trained batch 244 in epoch 15, gen_loss = 0.4006563331399645, disc_loss = 0.08253425485929665
Trained batch 245 in epoch 15, gen_loss = 0.40043101490028504, disc_loss = 0.08243039462382232
Trained batch 246 in epoch 15, gen_loss = 0.4000072434604892, disc_loss = 0.08311641608413897
Trained batch 247 in epoch 15, gen_loss = 0.4001333052592893, disc_loss = 0.08327167853713036
Trained batch 248 in epoch 15, gen_loss = 0.4000349590577275, disc_loss = 0.08298926172127206
Trained batch 249 in epoch 15, gen_loss = 0.4001989349126816, disc_loss = 0.0827776783555746
Trained batch 250 in epoch 15, gen_loss = 0.39990943967108705, disc_loss = 0.08285686369258094
Trained batch 251 in epoch 15, gen_loss = 0.40055544260475373, disc_loss = 0.08314326891882552
Trained batch 252 in epoch 15, gen_loss = 0.4008148271340155, disc_loss = 0.08298206009824756
Trained batch 253 in epoch 15, gen_loss = 0.4002179720505016, disc_loss = 0.0838325868294699
Trained batch 254 in epoch 15, gen_loss = 0.4003434254842646, disc_loss = 0.08489890564598289
Trained batch 255 in epoch 15, gen_loss = 0.40037875913549215, disc_loss = 0.08473716718435753
Trained batch 256 in epoch 15, gen_loss = 0.40044391016088104, disc_loss = 0.08494651817684044
Trained batch 257 in epoch 15, gen_loss = 0.4002958662057108, disc_loss = 0.08474661177385223
Trained batch 258 in epoch 15, gen_loss = 0.40020818151102105, disc_loss = 0.0845503617639017
Trained batch 259 in epoch 15, gen_loss = 0.40000371417173974, disc_loss = 0.08457874837689675
Trained batch 260 in epoch 15, gen_loss = 0.3993613777603683, disc_loss = 0.08488060024449195
Trained batch 261 in epoch 15, gen_loss = 0.39976513982956646, disc_loss = 0.08467622327383693
Trained batch 262 in epoch 15, gen_loss = 0.39984333634149893, disc_loss = 0.0845161815786543
Trained batch 263 in epoch 15, gen_loss = 0.3997388484916001, disc_loss = 0.08462235766152541
Trained batch 264 in epoch 15, gen_loss = 0.39977872354804345, disc_loss = 0.08557470277795252
Trained batch 265 in epoch 15, gen_loss = 0.3997338685886304, disc_loss = 0.08555560486209124
Trained batch 266 in epoch 15, gen_loss = 0.399538307321652, disc_loss = 0.08552570836374376
Trained batch 267 in epoch 15, gen_loss = 0.3992330235665414, disc_loss = 0.0854674385888363
Trained batch 268 in epoch 15, gen_loss = 0.39935546841984787, disc_loss = 0.08528971400624315
Trained batch 269 in epoch 15, gen_loss = 0.39923642691638733, disc_loss = 0.08524037831359439
Trained batch 270 in epoch 15, gen_loss = 0.39916397125298686, disc_loss = 0.08509558890138605
Trained batch 271 in epoch 15, gen_loss = 0.3990863894167192, disc_loss = 0.08500580081497044
Trained batch 272 in epoch 15, gen_loss = 0.3990979505218429, disc_loss = 0.08490267959542763
Trained batch 273 in epoch 15, gen_loss = 0.39939116871487484, disc_loss = 0.08535931723015587
Trained batch 274 in epoch 15, gen_loss = 0.39908845766024154, disc_loss = 0.08589838283983144
Trained batch 275 in epoch 15, gen_loss = 0.3990254889687766, disc_loss = 0.08571999412083971
Trained batch 276 in epoch 15, gen_loss = 0.39921742274227556, disc_loss = 0.08579123324112772
Trained batch 277 in epoch 15, gen_loss = 0.39878987917582764, disc_loss = 0.08609940216159649
Trained batch 278 in epoch 15, gen_loss = 0.39886834987816416, disc_loss = 0.08589606872996762
Trained batch 279 in epoch 15, gen_loss = 0.3986493721072163, disc_loss = 0.08566323261308884
Trained batch 280 in epoch 15, gen_loss = 0.3987911435314769, disc_loss = 0.08552394622399925
Trained batch 281 in epoch 15, gen_loss = 0.3988917310926931, disc_loss = 0.08554772594745488
Trained batch 282 in epoch 15, gen_loss = 0.398847959540758, disc_loss = 0.08589523225733121
Trained batch 283 in epoch 15, gen_loss = 0.3990199431042436, disc_loss = 0.08594029051133655
Trained batch 284 in epoch 15, gen_loss = 0.39904910895908086, disc_loss = 0.08578650540296445
Trained batch 285 in epoch 15, gen_loss = 0.3993029652254565, disc_loss = 0.08557137063463459
Trained batch 286 in epoch 15, gen_loss = 0.39934017864876925, disc_loss = 0.085334570747427
Trained batch 287 in epoch 15, gen_loss = 0.39941030259554583, disc_loss = 0.08514847902632836
Trained batch 288 in epoch 15, gen_loss = 0.3995022203992395, disc_loss = 0.08521894611753394
Trained batch 289 in epoch 15, gen_loss = 0.39978231165943473, disc_loss = 0.08536460138857364
Trained batch 290 in epoch 15, gen_loss = 0.39957796416126984, disc_loss = 0.08538895516409907
Trained batch 291 in epoch 15, gen_loss = 0.3996418147564751, disc_loss = 0.08546936112672907
Trained batch 292 in epoch 15, gen_loss = 0.39954499351083217, disc_loss = 0.0854853925266567
Trained batch 293 in epoch 15, gen_loss = 0.3996005006083826, disc_loss = 0.08524026463226396
Trained batch 294 in epoch 15, gen_loss = 0.39940658257169237, disc_loss = 0.08505269679225097
Trained batch 295 in epoch 15, gen_loss = 0.3992685333800477, disc_loss = 0.08503430786014006
Trained batch 296 in epoch 15, gen_loss = 0.3991016744062154, disc_loss = 0.08524714020215703
Trained batch 297 in epoch 15, gen_loss = 0.39919572353563054, disc_loss = 0.08501601509199846
Trained batch 298 in epoch 15, gen_loss = 0.3992878754302411, disc_loss = 0.08537872778532099
Trained batch 299 in epoch 15, gen_loss = 0.39895741100112597, disc_loss = 0.08543333073457082
Trained batch 300 in epoch 15, gen_loss = 0.3986136888051746, disc_loss = 0.08535458808424465
Trained batch 301 in epoch 15, gen_loss = 0.3987520199441752, disc_loss = 0.08517775183777936
Trained batch 302 in epoch 15, gen_loss = 0.39876617265023023, disc_loss = 0.085109679317317
Trained batch 303 in epoch 15, gen_loss = 0.3984291668687212, disc_loss = 0.08509897195587032
Trained batch 304 in epoch 15, gen_loss = 0.39854877938012606, disc_loss = 0.0848535954219396
Trained batch 305 in epoch 15, gen_loss = 0.3988429668779467, disc_loss = 0.08465416039175847
Trained batch 306 in epoch 15, gen_loss = 0.3991176668032761, disc_loss = 0.08449708473798895
Trained batch 307 in epoch 15, gen_loss = 0.39899515984700873, disc_loss = 0.08426999227542963
Trained batch 308 in epoch 15, gen_loss = 0.3989342819043348, disc_loss = 0.08438800470029459
Trained batch 309 in epoch 15, gen_loss = 0.39912908110887774, disc_loss = 0.08486334082460212
Trained batch 310 in epoch 15, gen_loss = 0.39928039194494963, disc_loss = 0.08466114348752897
Trained batch 311 in epoch 15, gen_loss = 0.39904916673325574, disc_loss = 0.08470947463184786
Trained batch 312 in epoch 15, gen_loss = 0.39912443500928607, disc_loss = 0.08480551887077455
Trained batch 313 in epoch 15, gen_loss = 0.3994168580812254, disc_loss = 0.08457651782697838
Trained batch 314 in epoch 15, gen_loss = 0.39934050019771333, disc_loss = 0.08445851848652912
Trained batch 315 in epoch 15, gen_loss = 0.3991095494903341, disc_loss = 0.08461467670335705
Trained batch 316 in epoch 15, gen_loss = 0.3992723807081439, disc_loss = 0.08505260759570903
Trained batch 317 in epoch 15, gen_loss = 0.3994236282488835, disc_loss = 0.08490670736843967
Trained batch 318 in epoch 15, gen_loss = 0.3993228230637069, disc_loss = 0.08485845331289459
Trained batch 319 in epoch 15, gen_loss = 0.3992980031762272, disc_loss = 0.08483255523897242
Trained batch 320 in epoch 15, gen_loss = 0.3991935033571683, disc_loss = 0.08477933846147168
Trained batch 321 in epoch 15, gen_loss = 0.3991390314439069, disc_loss = 0.08475520820154445
Trained batch 322 in epoch 15, gen_loss = 0.3992428441442572, disc_loss = 0.08488964778154903
Trained batch 323 in epoch 15, gen_loss = 0.39920436439138873, disc_loss = 0.08472646063159185
Trained batch 324 in epoch 15, gen_loss = 0.39920417771889616, disc_loss = 0.08463205471348303
Trained batch 325 in epoch 15, gen_loss = 0.39927321293054185, disc_loss = 0.08443748983811655
Trained batch 326 in epoch 15, gen_loss = 0.3994123941623472, disc_loss = 0.08428941127938142
Trained batch 327 in epoch 15, gen_loss = 0.3996041432113909, disc_loss = 0.08435672034066534
Trained batch 328 in epoch 15, gen_loss = 0.39962100561447783, disc_loss = 0.0844042402717616
Trained batch 329 in epoch 15, gen_loss = 0.39973516766772127, disc_loss = 0.0842523449382773
Trained batch 330 in epoch 15, gen_loss = 0.39971013619280293, disc_loss = 0.08410220204647124
Trained batch 331 in epoch 15, gen_loss = 0.39976424566773044, disc_loss = 0.08405615942249725
Trained batch 332 in epoch 15, gen_loss = 0.3995825227226939, disc_loss = 0.08434726115226657
Trained batch 333 in epoch 15, gen_loss = 0.4001584111484225, disc_loss = 0.08456291549164288
Trained batch 334 in epoch 15, gen_loss = 0.40022672001105636, disc_loss = 0.0843478855468444
Trained batch 335 in epoch 15, gen_loss = 0.40005836578174714, disc_loss = 0.08422992250970787
Trained batch 336 in epoch 15, gen_loss = 0.4000820601994631, disc_loss = 0.0840780976772839
Trained batch 337 in epoch 15, gen_loss = 0.40014331602662273, disc_loss = 0.08394223456023008
Trained batch 338 in epoch 15, gen_loss = 0.400205187081939, disc_loss = 0.08375295787873872
Trained batch 339 in epoch 15, gen_loss = 0.40017602255239204, disc_loss = 0.08361963662592804
Trained batch 340 in epoch 15, gen_loss = 0.4005394019077251, disc_loss = 0.0834138753859441
Trained batch 341 in epoch 15, gen_loss = 0.4005586008666552, disc_loss = 0.08347142047156193
Trained batch 342 in epoch 15, gen_loss = 0.400341102272359, disc_loss = 0.08353775641378612
Trained batch 343 in epoch 15, gen_loss = 0.4002797344136377, disc_loss = 0.08335116640989516
Trained batch 344 in epoch 15, gen_loss = 0.4004392966412116, disc_loss = 0.08345466442946074
Trained batch 345 in epoch 15, gen_loss = 0.4002375176790133, disc_loss = 0.08390647647740869
Trained batch 346 in epoch 15, gen_loss = 0.4003817504781811, disc_loss = 0.08383876821750866
Trained batch 347 in epoch 15, gen_loss = 0.4001799717802426, disc_loss = 0.08390331088468947
Trained batch 348 in epoch 15, gen_loss = 0.4000352597595286, disc_loss = 0.08423701351385746
Trained batch 349 in epoch 15, gen_loss = 0.4001541675414358, disc_loss = 0.0841530071411814
Trained batch 350 in epoch 15, gen_loss = 0.4002775006908976, disc_loss = 0.0840167269386627
Trained batch 351 in epoch 15, gen_loss = 0.4002336695874957, disc_loss = 0.0838206681867384
Trained batch 352 in epoch 15, gen_loss = 0.40025548510274533, disc_loss = 0.0839935850679199
Trained batch 353 in epoch 15, gen_loss = 0.4003328469260938, disc_loss = 0.08390204822065803
Trained batch 354 in epoch 15, gen_loss = 0.40043246137424254, disc_loss = 0.08372521116070344
Trained batch 355 in epoch 15, gen_loss = 0.400425040278207, disc_loss = 0.08358553010091353
Trained batch 356 in epoch 15, gen_loss = 0.40029936022952156, disc_loss = 0.08343361446983508
Trained batch 357 in epoch 15, gen_loss = 0.40025036340818726, disc_loss = 0.08358156776274216
Trained batch 358 in epoch 15, gen_loss = 0.3999220827246775, disc_loss = 0.08376998418532208
Trained batch 359 in epoch 15, gen_loss = 0.39990328728324837, disc_loss = 0.08371967097433905
Trained batch 360 in epoch 15, gen_loss = 0.4000619457121371, disc_loss = 0.08359035576624058
Trained batch 361 in epoch 15, gen_loss = 0.3999530134197757, disc_loss = 0.08348343323257582
Trained batch 362 in epoch 15, gen_loss = 0.3998016854209348, disc_loss = 0.08341409025339219
Trained batch 363 in epoch 15, gen_loss = 0.3995439183007885, disc_loss = 0.08357011430108777
Trained batch 364 in epoch 15, gen_loss = 0.3995585082736734, disc_loss = 0.08443046695463462
Trained batch 365 in epoch 15, gen_loss = 0.39950307613350655, disc_loss = 0.08427975090637885
Trained batch 366 in epoch 15, gen_loss = 0.3994571028597024, disc_loss = 0.08413845573727051
Trained batch 367 in epoch 15, gen_loss = 0.3995145316762121, disc_loss = 0.08401910940428144
Trained batch 368 in epoch 15, gen_loss = 0.39942605736940534, disc_loss = 0.08388483800942982
Trained batch 369 in epoch 15, gen_loss = 0.399194746524901, disc_loss = 0.08375245390107502
Trained batch 370 in epoch 15, gen_loss = 0.39905079110774067, disc_loss = 0.08369992041804719
Trained batch 371 in epoch 15, gen_loss = 0.39890412293294425, disc_loss = 0.08356125695851221
Trained batch 372 in epoch 15, gen_loss = 0.3987560137587003, disc_loss = 0.08365368047084949
Trained batch 373 in epoch 15, gen_loss = 0.39875286877314675, disc_loss = 0.08411342115763994
Trained batch 374 in epoch 15, gen_loss = 0.39871555046240487, disc_loss = 0.08393573904534181
Trained batch 375 in epoch 15, gen_loss = 0.3988171870958932, disc_loss = 0.08384660806288903
Trained batch 376 in epoch 15, gen_loss = 0.399084345850135, disc_loss = 0.08367887390802173
Trained batch 377 in epoch 15, gen_loss = 0.39895624407227076, disc_loss = 0.08352426534627007
Trained batch 378 in epoch 15, gen_loss = 0.399075514840891, disc_loss = 0.08350975770690039
Trained batch 379 in epoch 15, gen_loss = 0.3988332293143398, disc_loss = 0.08399343994985285
Trained batch 380 in epoch 15, gen_loss = 0.3989688949243916, disc_loss = 0.08396426170301718
Trained batch 381 in epoch 15, gen_loss = 0.39898221807174034, disc_loss = 0.08388803651098026
Trained batch 382 in epoch 15, gen_loss = 0.39885757902428004, disc_loss = 0.08391836892045042
Trained batch 383 in epoch 15, gen_loss = 0.39896031729100895, disc_loss = 0.08385609522520099
Trained batch 384 in epoch 15, gen_loss = 0.3989767558775939, disc_loss = 0.08378827534615993
Trained batch 385 in epoch 15, gen_loss = 0.39880714310728826, disc_loss = 0.08364491399686416
Trained batch 386 in epoch 15, gen_loss = 0.3989450626980119, disc_loss = 0.08358986998694042
Trained batch 387 in epoch 15, gen_loss = 0.39897242084760026, disc_loss = 0.083457901685009
Trained batch 388 in epoch 15, gen_loss = 0.39903513573895383, disc_loss = 0.08331579908939285
Trained batch 389 in epoch 15, gen_loss = 0.39909717971697833, disc_loss = 0.08318307798546859
Trained batch 390 in epoch 15, gen_loss = 0.39894403982192966, disc_loss = 0.0830524436834142
Trained batch 391 in epoch 15, gen_loss = 0.39895976695935337, disc_loss = 0.08291092149115034
Trained batch 392 in epoch 15, gen_loss = 0.39898173033281137, disc_loss = 0.08282304635750125
Trained batch 393 in epoch 15, gen_loss = 0.39923614206804237, disc_loss = 0.08296075965358218
Trained batch 394 in epoch 15, gen_loss = 0.39910739965831177, disc_loss = 0.08304298447468612
Trained batch 395 in epoch 15, gen_loss = 0.3990870068846929, disc_loss = 0.08290888335687494
Trained batch 396 in epoch 15, gen_loss = 0.39913263883188327, disc_loss = 0.08287858113327465
Trained batch 397 in epoch 15, gen_loss = 0.3991252540718371, disc_loss = 0.08272080006424207
Trained batch 398 in epoch 15, gen_loss = 0.39888561754149005, disc_loss = 0.08258060916772761
Trained batch 399 in epoch 15, gen_loss = 0.3990941281989217, disc_loss = 0.08244045342318713
Trained batch 400 in epoch 15, gen_loss = 0.39905271918845, disc_loss = 0.08236756428444475
Trained batch 401 in epoch 15, gen_loss = 0.3988026456527449, disc_loss = 0.08266318176145578
Trained batch 402 in epoch 15, gen_loss = 0.3990788356615947, disc_loss = 0.0830542538915911
Trained batch 403 in epoch 15, gen_loss = 0.3990286962304375, disc_loss = 0.08287146348865831
Trained batch 404 in epoch 15, gen_loss = 0.3987514790561464, disc_loss = 0.08277789084585728
Trained batch 405 in epoch 15, gen_loss = 0.3985299050000501, disc_loss = 0.08262332262508021
Trained batch 406 in epoch 15, gen_loss = 0.3985386519013224, disc_loss = 0.082575975876091
Trained batch 407 in epoch 15, gen_loss = 0.39873804886113196, disc_loss = 0.08249682394157656
Trained batch 408 in epoch 15, gen_loss = 0.39869806793470547, disc_loss = 0.08237900475408964
Trained batch 409 in epoch 15, gen_loss = 0.398709595239744, disc_loss = 0.08230942009562035
Trained batch 410 in epoch 15, gen_loss = 0.3985276482908685, disc_loss = 0.08225385078575707
Trained batch 411 in epoch 15, gen_loss = 0.39859831915463056, disc_loss = 0.08230085649925456
Trained batch 412 in epoch 15, gen_loss = 0.3983988715358277, disc_loss = 0.08255967437165629
Trained batch 413 in epoch 15, gen_loss = 0.39854927746138136, disc_loss = 0.08254124131278644
Trained batch 414 in epoch 15, gen_loss = 0.3986262356301388, disc_loss = 0.08236619683139655
Trained batch 415 in epoch 15, gen_loss = 0.39859013334633064, disc_loss = 0.08219095880989559
Trained batch 416 in epoch 15, gen_loss = 0.39866072643432116, disc_loss = 0.08202853244762841
Trained batch 417 in epoch 15, gen_loss = 0.3988550111081041, disc_loss = 0.08188735264794607
Trained batch 418 in epoch 15, gen_loss = 0.3990006937260844, disc_loss = 0.08176345087205525
Trained batch 419 in epoch 15, gen_loss = 0.39894350203020235, disc_loss = 0.08176968930333497
Trained batch 420 in epoch 15, gen_loss = 0.39883765305730906, disc_loss = 0.08207733131670825
Trained batch 421 in epoch 15, gen_loss = 0.39852796830413467, disc_loss = 0.08252015228546555
Trained batch 422 in epoch 15, gen_loss = 0.39870942671107346, disc_loss = 0.08246255651706429
Trained batch 423 in epoch 15, gen_loss = 0.3986383913752605, disc_loss = 0.08239260140832795
Trained batch 424 in epoch 15, gen_loss = 0.39859249293804166, disc_loss = 0.08224594584063571
Trained batch 425 in epoch 15, gen_loss = 0.39868611170792245, disc_loss = 0.08212981822336433
Trained batch 426 in epoch 15, gen_loss = 0.39856597910301467, disc_loss = 0.08233553172684595
Trained batch 427 in epoch 15, gen_loss = 0.3985721534727333, disc_loss = 0.08252717556092436
Trained batch 428 in epoch 15, gen_loss = 0.39867071598976644, disc_loss = 0.08237688215384326
Trained batch 429 in epoch 15, gen_loss = 0.3985272232529729, disc_loss = 0.08230366613932474
Trained batch 430 in epoch 15, gen_loss = 0.3985218005708641, disc_loss = 0.08214393279919284
Trained batch 431 in epoch 15, gen_loss = 0.398468971700856, disc_loss = 0.0819990429014002
Trained batch 432 in epoch 15, gen_loss = 0.398355277216462, disc_loss = 0.08184005459663017
Trained batch 433 in epoch 15, gen_loss = 0.3984318042886422, disc_loss = 0.08176855953444602
Trained batch 434 in epoch 15, gen_loss = 0.398441096181157, disc_loss = 0.08163886693916445
Trained batch 435 in epoch 15, gen_loss = 0.39840353126509476, disc_loss = 0.08157606161660899
Trained batch 436 in epoch 15, gen_loss = 0.3984392377072668, disc_loss = 0.08149207245507352
Trained batch 437 in epoch 15, gen_loss = 0.39841492259747363, disc_loss = 0.0814666899121005
Trained batch 438 in epoch 15, gen_loss = 0.3986138429552113, disc_loss = 0.08174015788874825
Trained batch 439 in epoch 15, gen_loss = 0.3984220121733167, disc_loss = 0.08207141530319033
Trained batch 440 in epoch 15, gen_loss = 0.39864975758015164, disc_loss = 0.08198959954175887
Trained batch 441 in epoch 15, gen_loss = 0.398945686268321, disc_loss = 0.08194264161244574
Trained batch 442 in epoch 15, gen_loss = 0.3987743646310092, disc_loss = 0.08198832007625369
Trained batch 443 in epoch 15, gen_loss = 0.3987963744984554, disc_loss = 0.08211416927552237
Trained batch 444 in epoch 15, gen_loss = 0.39855521163913643, disc_loss = 0.0822682625310642
Trained batch 445 in epoch 15, gen_loss = 0.39862278200719387, disc_loss = 0.082211102198208
Trained batch 446 in epoch 15, gen_loss = 0.3985368451082733, disc_loss = 0.08207314411674103
Trained batch 447 in epoch 15, gen_loss = 0.3984942519039448, disc_loss = 0.08201223420785807
Trained batch 448 in epoch 15, gen_loss = 0.39849284075549024, disc_loss = 0.08232675922748307
Trained batch 449 in epoch 15, gen_loss = 0.3986582976910803, disc_loss = 0.08255017822194431
Trained batch 450 in epoch 15, gen_loss = 0.3987337265271041, disc_loss = 0.08238988127889826
Trained batch 451 in epoch 15, gen_loss = 0.39870588517690125, disc_loss = 0.08228695685398328
Trained batch 452 in epoch 15, gen_loss = 0.39865059676944026, disc_loss = 0.08217124670340986
Trained batch 453 in epoch 15, gen_loss = 0.3986475007846492, disc_loss = 0.08204798671388219
Trained batch 454 in epoch 15, gen_loss = 0.3990377399620119, disc_loss = 0.0819143707423911
Trained batch 455 in epoch 15, gen_loss = 0.3993053143157771, disc_loss = 0.08180466368426814
Trained batch 456 in epoch 15, gen_loss = 0.3994308115030013, disc_loss = 0.08173602799675071
Trained batch 457 in epoch 15, gen_loss = 0.3992971575871826, disc_loss = 0.08162668901881992
Trained batch 458 in epoch 15, gen_loss = 0.3990295124534428, disc_loss = 0.08166823467779458
Testing Epoch 15
Training Epoch 16
Trained batch 0 in epoch 16, gen_loss = 0.39622047543525696, disc_loss = 0.09363937377929688
Trained batch 1 in epoch 16, gen_loss = 0.3848038762807846, disc_loss = 0.13882271945476532
Trained batch 2 in epoch 16, gen_loss = 0.41485994060834247, disc_loss = 0.10668620963891347
Trained batch 3 in epoch 16, gen_loss = 0.41377366334199905, disc_loss = 0.08256130572408438
Trained batch 4 in epoch 16, gen_loss = 0.41511900424957277, disc_loss = 0.07294377535581589
Trained batch 5 in epoch 16, gen_loss = 0.4058081805706024, disc_loss = 0.06238588644191623
Trained batch 6 in epoch 16, gen_loss = 0.3985168550695692, disc_loss = 0.05632077170802014
Trained batch 7 in epoch 16, gen_loss = 0.39545057341456413, disc_loss = 0.054702268098481
Trained batch 8 in epoch 16, gen_loss = 0.4037968913714091, disc_loss = 0.05483574430561728
Trained batch 9 in epoch 16, gen_loss = 0.4144322514533997, disc_loss = 0.0678064906038344
Trained batch 10 in epoch 16, gen_loss = 0.4078958278352564, disc_loss = 0.0709495267576792
Trained batch 11 in epoch 16, gen_loss = 0.41153427461783093, disc_loss = 0.0670071574083219
Trained batch 12 in epoch 16, gen_loss = 0.4109536180129418, disc_loss = 0.07466310785653499
Trained batch 13 in epoch 16, gen_loss = 0.4057794894490923, disc_loss = 0.08184403028073055
Trained batch 14 in epoch 16, gen_loss = 0.4036740024884542, disc_loss = 0.0800856014713645
Trained batch 15 in epoch 16, gen_loss = 0.4054907150566578, disc_loss = 0.0759641228360124
Trained batch 16 in epoch 16, gen_loss = 0.40149611234664917, disc_loss = 0.07594150726628654
Trained batch 17 in epoch 16, gen_loss = 0.40430046452416313, disc_loss = 0.0735631513202356
Trained batch 18 in epoch 16, gen_loss = 0.40360036649202047, disc_loss = 0.07200084415901649
Trained batch 19 in epoch 16, gen_loss = 0.4027243569493294, disc_loss = 0.0730140230152756
Trained batch 20 in epoch 16, gen_loss = 0.40306529828480314, disc_loss = 0.07092028390616179
Trained batch 21 in epoch 16, gen_loss = 0.4069646244699305, disc_loss = 0.07995954659682783
Trained batch 22 in epoch 16, gen_loss = 0.40403408200844476, disc_loss = 0.08109920403069776
Trained batch 23 in epoch 16, gen_loss = 0.40342139701048535, disc_loss = 0.07854448130819947
Trained batch 24 in epoch 16, gen_loss = 0.4040540361404419, disc_loss = 0.07618825223296881
Trained batch 25 in epoch 16, gen_loss = 0.40425917506217957, disc_loss = 0.0783900168294517
Trained batch 26 in epoch 16, gen_loss = 0.4019762487323196, disc_loss = 0.08677114128928494
Trained batch 27 in epoch 16, gen_loss = 0.40051871644599096, disc_loss = 0.08559355309366115
Trained batch 28 in epoch 16, gen_loss = 0.4005877324219408, disc_loss = 0.08620186724924836
Trained batch 29 in epoch 16, gen_loss = 0.3973697712024053, disc_loss = 0.08823190142090122
Trained batch 30 in epoch 16, gen_loss = 0.39739163748679623, disc_loss = 0.08617866625108066
Trained batch 31 in epoch 16, gen_loss = 0.3970855278894305, disc_loss = 0.08398755683447234
Trained batch 32 in epoch 16, gen_loss = 0.39646472081993567, disc_loss = 0.08294129255933291
Trained batch 33 in epoch 16, gen_loss = 0.3939065784215927, disc_loss = 0.08205941886476734
Trained batch 34 in epoch 16, gen_loss = 0.392400940826961, disc_loss = 0.08283316469086068
Trained batch 35 in epoch 16, gen_loss = 0.39569927255312604, disc_loss = 0.08629715377982292
Trained batch 36 in epoch 16, gen_loss = 0.39586672670132406, disc_loss = 0.08515828291608675
Trained batch 37 in epoch 16, gen_loss = 0.3953113422582024, disc_loss = 0.0844531606049522
Trained batch 38 in epoch 16, gen_loss = 0.3943133812684279, disc_loss = 0.08792723197107896
Trained batch 39 in epoch 16, gen_loss = 0.39457764476537704, disc_loss = 0.08739094303455204
Trained batch 40 in epoch 16, gen_loss = 0.39648581423410556, disc_loss = 0.08655668920042311
Trained batch 41 in epoch 16, gen_loss = 0.3955597338222322, disc_loss = 0.08501661575532385
Trained batch 42 in epoch 16, gen_loss = 0.3951680493909259, disc_loss = 0.08432966832418082
Trained batch 43 in epoch 16, gen_loss = 0.3947027623653412, disc_loss = 0.08303227159194648
Trained batch 44 in epoch 16, gen_loss = 0.3954996969964769, disc_loss = 0.08143057138141659
Trained batch 45 in epoch 16, gen_loss = 0.39534826965435693, disc_loss = 0.0799457757409824
Trained batch 46 in epoch 16, gen_loss = 0.3957814682037272, disc_loss = 0.07870936764285286
Trained batch 47 in epoch 16, gen_loss = 0.39571604194740456, disc_loss = 0.0804234819758373
Trained batch 48 in epoch 16, gen_loss = 0.3962828717669662, disc_loss = 0.08347378600844924
Trained batch 49 in epoch 16, gen_loss = 0.3958119243383408, disc_loss = 0.08352534612640738
Trained batch 50 in epoch 16, gen_loss = 0.3956316242031023, disc_loss = 0.08250835119728364
Trained batch 51 in epoch 16, gen_loss = 0.3960395323542448, disc_loss = 0.0812665333147519
Trained batch 52 in epoch 16, gen_loss = 0.39636284675238265, disc_loss = 0.08073780335977955
Trained batch 53 in epoch 16, gen_loss = 0.39550621034922423, disc_loss = 0.08020882889697398
Trained batch 54 in epoch 16, gen_loss = 0.3957840464331887, disc_loss = 0.0796630562198433
Trained batch 55 in epoch 16, gen_loss = 0.3953693083354405, disc_loss = 0.0789438376502533
Trained batch 56 in epoch 16, gen_loss = 0.395971349456854, disc_loss = 0.07846529358638483
Trained batch 57 in epoch 16, gen_loss = 0.39576720112356645, disc_loss = 0.07766032805024035
Trained batch 58 in epoch 16, gen_loss = 0.3971867137036081, disc_loss = 0.07699989939455763
Trained batch 59 in epoch 16, gen_loss = 0.39719437559445697, disc_loss = 0.07625192231498659
Trained batch 60 in epoch 16, gen_loss = 0.39645954966545105, disc_loss = 0.0760057925353529
Trained batch 61 in epoch 16, gen_loss = 0.3966677111964072, disc_loss = 0.0756409978944688
Trained batch 62 in epoch 16, gen_loss = 0.3977169493834178, disc_loss = 0.0746097183002839
Trained batch 63 in epoch 16, gen_loss = 0.3963232459500432, disc_loss = 0.07549950425163843
Trained batch 64 in epoch 16, gen_loss = 0.39680496683487526, disc_loss = 0.07633840180933475
Trained batch 65 in epoch 16, gen_loss = 0.39637038789012213, disc_loss = 0.07535825401657459
Trained batch 66 in epoch 16, gen_loss = 0.3965346595244621, disc_loss = 0.07497899303796576
Trained batch 67 in epoch 16, gen_loss = 0.3967103554921992, disc_loss = 0.0760158760856618
Trained batch 68 in epoch 16, gen_loss = 0.3961017261380735, disc_loss = 0.07558758246401946
Trained batch 69 in epoch 16, gen_loss = 0.3959727346897125, disc_loss = 0.07561077574001891
Trained batch 70 in epoch 16, gen_loss = 0.39582772657904824, disc_loss = 0.07739307419200178
Trained batch 71 in epoch 16, gen_loss = 0.39451999507016605, disc_loss = 0.07758785424650544
Trained batch 72 in epoch 16, gen_loss = 0.394075578614457, disc_loss = 0.07689493192895634
Trained batch 73 in epoch 16, gen_loss = 0.39427354287456823, disc_loss = 0.07912267012068548
Trained batch 74 in epoch 16, gen_loss = 0.3934114968776703, disc_loss = 0.0799539032826821
Trained batch 75 in epoch 16, gen_loss = 0.3939877956321365, disc_loss = 0.0793848649696692
Trained batch 76 in epoch 16, gen_loss = 0.39524368728910175, disc_loss = 0.07900108147847962
Trained batch 77 in epoch 16, gen_loss = 0.3957707079557272, disc_loss = 0.07842783474673827
Trained batch 78 in epoch 16, gen_loss = 0.39490526990045477, disc_loss = 0.07866793198958982
Trained batch 79 in epoch 16, gen_loss = 0.3956782303750515, disc_loss = 0.07857461299281568
Trained batch 80 in epoch 16, gen_loss = 0.39656502118817083, disc_loss = 0.07787804091694178
Trained batch 81 in epoch 16, gen_loss = 0.3966368789353022, disc_loss = 0.07746615890050079
Trained batch 82 in epoch 16, gen_loss = 0.3965922856187246, disc_loss = 0.07849203276795795
Trained batch 83 in epoch 16, gen_loss = 0.39579330668562934, disc_loss = 0.07945866255267035
Trained batch 84 in epoch 16, gen_loss = 0.3964611004380619, disc_loss = 0.07968699539847234
Trained batch 85 in epoch 16, gen_loss = 0.39601937664109604, disc_loss = 0.07909122079091016
Trained batch 86 in epoch 16, gen_loss = 0.3955597387648177, disc_loss = 0.08188470208953166
Trained batch 87 in epoch 16, gen_loss = 0.3970380855554884, disc_loss = 0.08322736083275893
Trained batch 88 in epoch 16, gen_loss = 0.39796158470464554, disc_loss = 0.0829318133967646
Trained batch 89 in epoch 16, gen_loss = 0.3986873206165102, disc_loss = 0.08221623473283317
Trained batch 90 in epoch 16, gen_loss = 0.39934313199022314, disc_loss = 0.08173947361717512
Trained batch 91 in epoch 16, gen_loss = 0.3989422946520474, disc_loss = 0.08103250046058194
Trained batch 92 in epoch 16, gen_loss = 0.39867926060512504, disc_loss = 0.08035559844105475
Trained batch 93 in epoch 16, gen_loss = 0.39860310199412896, disc_loss = 0.07975804472857333
Trained batch 94 in epoch 16, gen_loss = 0.39806338140839026, disc_loss = 0.07939308611185927
Trained batch 95 in epoch 16, gen_loss = 0.398554755995671, disc_loss = 0.0791747960417221
Trained batch 96 in epoch 16, gen_loss = 0.39793041471353513, disc_loss = 0.078687037389303
Trained batch 97 in epoch 16, gen_loss = 0.3971364169704671, disc_loss = 0.07954306064211593
Trained batch 98 in epoch 16, gen_loss = 0.39755131379522457, disc_loss = 0.08352739898243336
Trained batch 99 in epoch 16, gen_loss = 0.39791292160749436, disc_loss = 0.08333489134907722
Trained batch 100 in epoch 16, gen_loss = 0.39711674369207706, disc_loss = 0.08307566102778557
Trained batch 101 in epoch 16, gen_loss = 0.39654793078992884, disc_loss = 0.08292220043493252
Trained batch 102 in epoch 16, gen_loss = 0.39619923361296794, disc_loss = 0.08262312585867725
Trained batch 103 in epoch 16, gen_loss = 0.3961215835924332, disc_loss = 0.08253349256343566
Trained batch 104 in epoch 16, gen_loss = 0.39573045316196626, disc_loss = 0.08190316472734724
Trained batch 105 in epoch 16, gen_loss = 0.39532791162436864, disc_loss = 0.08130574268552493
Trained batch 106 in epoch 16, gen_loss = 0.39575138493119, disc_loss = 0.08069508209406773
Trained batch 107 in epoch 16, gen_loss = 0.395733380207309, disc_loss = 0.0801577721722424
Trained batch 108 in epoch 16, gen_loss = 0.3959978813425117, disc_loss = 0.07952238795338967
Trained batch 109 in epoch 16, gen_loss = 0.39593101306395095, disc_loss = 0.07927903300997886
Trained batch 110 in epoch 16, gen_loss = 0.39564923525930523, disc_loss = 0.07896506630286977
Trained batch 111 in epoch 16, gen_loss = 0.39531119726598263, disc_loss = 0.07892994554380753
Trained batch 112 in epoch 16, gen_loss = 0.39516635938028316, disc_loss = 0.07928110143186244
Trained batch 113 in epoch 16, gen_loss = 0.39435804360791255, disc_loss = 0.07918207960105256
Trained batch 114 in epoch 16, gen_loss = 0.3936761571013409, disc_loss = 0.07856095431615477
Trained batch 115 in epoch 16, gen_loss = 0.3938054532326501, disc_loss = 0.078048685405018
Trained batch 116 in epoch 16, gen_loss = 0.39447048000800305, disc_loss = 0.07773759435766782
Trained batch 117 in epoch 16, gen_loss = 0.3943896887160964, disc_loss = 0.0776173679821067
Trained batch 118 in epoch 16, gen_loss = 0.39393964935751524, disc_loss = 0.07823589196851273
Trained batch 119 in epoch 16, gen_loss = 0.39483348429203036, disc_loss = 0.07917113952959577
Trained batch 120 in epoch 16, gen_loss = 0.39392652664302796, disc_loss = 0.07911772634987989
Trained batch 121 in epoch 16, gen_loss = 0.3941394014925253, disc_loss = 0.07870510931997025
Trained batch 122 in epoch 16, gen_loss = 0.3933871698573353, disc_loss = 0.07938820562832724
Trained batch 123 in epoch 16, gen_loss = 0.39364672332040723, disc_loss = 0.08101053971556886
Trained batch 124 in epoch 16, gen_loss = 0.39415570068359373, disc_loss = 0.08090200451016426
Trained batch 125 in epoch 16, gen_loss = 0.39321218501953853, disc_loss = 0.08057942430651377
Trained batch 126 in epoch 16, gen_loss = 0.39282170078885836, disc_loss = 0.0805247941707063
Trained batch 127 in epoch 16, gen_loss = 0.3925420348532498, disc_loss = 0.08005588424566668
Trained batch 128 in epoch 16, gen_loss = 0.39286332190498824, disc_loss = 0.08014858732101067
Trained batch 129 in epoch 16, gen_loss = 0.39278896428071536, disc_loss = 0.08101757539866063
Trained batch 130 in epoch 16, gen_loss = 0.392760117317884, disc_loss = 0.08082621895800565
Trained batch 131 in epoch 16, gen_loss = 0.39333835944081796, disc_loss = 0.08124538605581179
Trained batch 132 in epoch 16, gen_loss = 0.39257474949485377, disc_loss = 0.08114018805212993
Trained batch 133 in epoch 16, gen_loss = 0.3914782467173107, disc_loss = 0.08333576919594363
Trained batch 134 in epoch 16, gen_loss = 0.3911973167348791, disc_loss = 0.08337226944665115
Trained batch 135 in epoch 16, gen_loss = 0.39140019675388055, disc_loss = 0.08393420721404254
Trained batch 136 in epoch 16, gen_loss = 0.3912113878848779, disc_loss = 0.08397836486951712
Trained batch 137 in epoch 16, gen_loss = 0.3912037187728329, disc_loss = 0.0837978273495168
Trained batch 138 in epoch 16, gen_loss = 0.3914676212149558, disc_loss = 0.08380323507749349
Trained batch 139 in epoch 16, gen_loss = 0.3914493009448051, disc_loss = 0.08347469383318509
Trained batch 140 in epoch 16, gen_loss = 0.3912817271465951, disc_loss = 0.08310105404585388
Trained batch 141 in epoch 16, gen_loss = 0.3912037879648343, disc_loss = 0.0829715388892612
Trained batch 142 in epoch 16, gen_loss = 0.3919457188853017, disc_loss = 0.08313953632918689
Trained batch 143 in epoch 16, gen_loss = 0.39222085517313743, disc_loss = 0.0828898087169768
Trained batch 144 in epoch 16, gen_loss = 0.39261940656037164, disc_loss = 0.08364932605161748
Trained batch 145 in epoch 16, gen_loss = 0.392918366887798, disc_loss = 0.08391495861674417
Trained batch 146 in epoch 16, gen_loss = 0.39319379962220485, disc_loss = 0.08374122338889002
Trained batch 147 in epoch 16, gen_loss = 0.3930116303869196, disc_loss = 0.08374733151867986
Trained batch 148 in epoch 16, gen_loss = 0.39291567790428267, disc_loss = 0.0834118878506374
Trained batch 149 in epoch 16, gen_loss = 0.3934429025650024, disc_loss = 0.08324862836549679
Trained batch 150 in epoch 16, gen_loss = 0.39395061332658426, disc_loss = 0.08294086295198526
Trained batch 151 in epoch 16, gen_loss = 0.3942966433732133, disc_loss = 0.0835918155621345
Trained batch 152 in epoch 16, gen_loss = 0.39479829633937163, disc_loss = 0.08360806982842536
Trained batch 153 in epoch 16, gen_loss = 0.3949584144276458, disc_loss = 0.08336297373057573
Trained batch 154 in epoch 16, gen_loss = 0.39471682848468903, disc_loss = 0.08290749122538875
Trained batch 155 in epoch 16, gen_loss = 0.39448446398362136, disc_loss = 0.08282663231381239
Trained batch 156 in epoch 16, gen_loss = 0.39434264400962055, disc_loss = 0.08296170667003674
Trained batch 157 in epoch 16, gen_loss = 0.39424184643769566, disc_loss = 0.08270702254074284
Trained batch 158 in epoch 16, gen_loss = 0.3943292015003708, disc_loss = 0.08265802449306602
Trained batch 159 in epoch 16, gen_loss = 0.39472673889249565, disc_loss = 0.08226189700653777
Trained batch 160 in epoch 16, gen_loss = 0.3945603502092895, disc_loss = 0.08202837501299677
Trained batch 161 in epoch 16, gen_loss = 0.394905929028252, disc_loss = 0.08296143687847587
Trained batch 162 in epoch 16, gen_loss = 0.39519259388461436, disc_loss = 0.08365048094441188
Trained batch 163 in epoch 16, gen_loss = 0.3953763186568167, disc_loss = 0.08340175394195973
Trained batch 164 in epoch 16, gen_loss = 0.3957890570163727, disc_loss = 0.08303271971191421
Trained batch 165 in epoch 16, gen_loss = 0.3959227513117963, disc_loss = 0.08273869439824877
Trained batch 166 in epoch 16, gen_loss = 0.39565090023115007, disc_loss = 0.08246507077383067
Trained batch 167 in epoch 16, gen_loss = 0.3957608148810409, disc_loss = 0.08212196932262963
Trained batch 168 in epoch 16, gen_loss = 0.3960600627597267, disc_loss = 0.0831312251404016
Trained batch 169 in epoch 16, gen_loss = 0.39575413903769324, disc_loss = 0.08379317512187888
Trained batch 170 in epoch 16, gen_loss = 0.39596155425261337, disc_loss = 0.08357250358234024
Trained batch 171 in epoch 16, gen_loss = 0.3962854481367178, disc_loss = 0.083492636843043
Trained batch 172 in epoch 16, gen_loss = 0.39628265703344623, disc_loss = 0.08348699485764682
Trained batch 173 in epoch 16, gen_loss = 0.39604305039192067, disc_loss = 0.08341757618104932
Trained batch 174 in epoch 16, gen_loss = 0.3958739507198334, disc_loss = 0.08334036519484861
Trained batch 175 in epoch 16, gen_loss = 0.39591307599436154, disc_loss = 0.08301685607611117
Trained batch 176 in epoch 16, gen_loss = 0.3962382552987438, disc_loss = 0.08268853324323387
Trained batch 177 in epoch 16, gen_loss = 0.3962205917982573, disc_loss = 0.08244529568454188
Trained batch 178 in epoch 16, gen_loss = 0.39652292621868285, disc_loss = 0.08215331247690337
Trained batch 179 in epoch 16, gen_loss = 0.3969420888357692, disc_loss = 0.08197562776298986
Trained batch 180 in epoch 16, gen_loss = 0.3965407799291347, disc_loss = 0.08254054854546793
Trained batch 181 in epoch 16, gen_loss = 0.3969916331244039, disc_loss = 0.08304644841700792
Trained batch 182 in epoch 16, gen_loss = 0.3970885319136531, disc_loss = 0.08265683088003775
Trained batch 183 in epoch 16, gen_loss = 0.3967388461789359, disc_loss = 0.08243564941981078
Trained batch 184 in epoch 16, gen_loss = 0.39655291051478, disc_loss = 0.08205366521771695
Trained batch 185 in epoch 16, gen_loss = 0.3962182375372097, disc_loss = 0.08187098937830137
Trained batch 186 in epoch 16, gen_loss = 0.39611093054480734, disc_loss = 0.08190680100497874
Trained batch 187 in epoch 16, gen_loss = 0.39604592465973915, disc_loss = 0.0815595105696628
Trained batch 188 in epoch 16, gen_loss = 0.3962267260387461, disc_loss = 0.08137453091700399
Trained batch 189 in epoch 16, gen_loss = 0.3960598865621968, disc_loss = 0.08137051985157948
Trained batch 190 in epoch 16, gen_loss = 0.3963771629395909, disc_loss = 0.08114742000553152
Trained batch 191 in epoch 16, gen_loss = 0.39594222512096167, disc_loss = 0.08093874808885933
Trained batch 192 in epoch 16, gen_loss = 0.3963091617421165, disc_loss = 0.08060418249353998
Trained batch 193 in epoch 16, gen_loss = 0.39641083454348375, disc_loss = 0.08046818231280471
Trained batch 194 in epoch 16, gen_loss = 0.396730853502567, disc_loss = 0.0803588180253521
Trained batch 195 in epoch 16, gen_loss = 0.39642701054714163, disc_loss = 0.08007315285408831
Trained batch 196 in epoch 16, gen_loss = 0.3964077450599767, disc_loss = 0.07982771069775832
Trained batch 197 in epoch 16, gen_loss = 0.39713500981981104, disc_loss = 0.0799249336264576
Trained batch 198 in epoch 16, gen_loss = 0.39676249970742805, disc_loss = 0.07979269753954368
Trained batch 199 in epoch 16, gen_loss = 0.39689117401838303, disc_loss = 0.07980211181100458
Trained batch 200 in epoch 16, gen_loss = 0.39697696172182834, disc_loss = 0.07981265471108369
Trained batch 201 in epoch 16, gen_loss = 0.3968246897848526, disc_loss = 0.07974618361193207
Trained batch 202 in epoch 16, gen_loss = 0.39731771928336235, disc_loss = 0.07940687858063745
Trained batch 203 in epoch 16, gen_loss = 0.3977457349206887, disc_loss = 0.07936576022036082
Trained batch 204 in epoch 16, gen_loss = 0.39793546912146777, disc_loss = 0.07918793145203736
Trained batch 205 in epoch 16, gen_loss = 0.3979864260814722, disc_loss = 0.07920222259714331
Trained batch 206 in epoch 16, gen_loss = 0.3981038379496422, disc_loss = 0.07917561893607827
Trained batch 207 in epoch 16, gen_loss = 0.39805737438683325, disc_loss = 0.07885042392165185
Trained batch 208 in epoch 16, gen_loss = 0.39813657981927314, disc_loss = 0.07872697604490382
Trained batch 209 in epoch 16, gen_loss = 0.39831194224811733, disc_loss = 0.0784631968209786
Trained batch 210 in epoch 16, gen_loss = 0.39804557403681967, disc_loss = 0.07847403151852683
Trained batch 211 in epoch 16, gen_loss = 0.3981482033740799, disc_loss = 0.07818611217926275
Trained batch 212 in epoch 16, gen_loss = 0.39793213516333853, disc_loss = 0.07857134713061119
Trained batch 213 in epoch 16, gen_loss = 0.3980020487976966, disc_loss = 0.07903006824743107
Trained batch 214 in epoch 16, gen_loss = 0.39826228466144825, disc_loss = 0.07870124274821476
Trained batch 215 in epoch 16, gen_loss = 0.3982811179701929, disc_loss = 0.07847459819081619
Trained batch 216 in epoch 16, gen_loss = 0.39793920475766403, disc_loss = 0.07839564420712021
Trained batch 217 in epoch 16, gen_loss = 0.39810619605790587, disc_loss = 0.07822051271369014
Trained batch 218 in epoch 16, gen_loss = 0.3979677545697722, disc_loss = 0.07825275908169001
Trained batch 219 in epoch 16, gen_loss = 0.398301589218053, disc_loss = 0.07812780322591689
Trained batch 220 in epoch 16, gen_loss = 0.397731221639193, disc_loss = 0.07814450522808872
Trained batch 221 in epoch 16, gen_loss = 0.3975789044891392, disc_loss = 0.07796436522642637
Trained batch 222 in epoch 16, gen_loss = 0.39776312556501997, disc_loss = 0.07769152678699638
Trained batch 223 in epoch 16, gen_loss = 0.3975753141567111, disc_loss = 0.0774573961430828
Trained batch 224 in epoch 16, gen_loss = 0.3976616934935252, disc_loss = 0.07720056858741575
Trained batch 225 in epoch 16, gen_loss = 0.39769025819491494, disc_loss = 0.0770717000020091
Trained batch 226 in epoch 16, gen_loss = 0.3976382670948684, disc_loss = 0.0768479529792845
Trained batch 227 in epoch 16, gen_loss = 0.3979260500585824, disc_loss = 0.07715774532162438
Trained batch 228 in epoch 16, gen_loss = 0.3974565383388486, disc_loss = 0.0780037989856179
Trained batch 229 in epoch 16, gen_loss = 0.39774903642094656, disc_loss = 0.07782799762309245
Trained batch 230 in epoch 16, gen_loss = 0.39792869114256524, disc_loss = 0.07778746785104146
Trained batch 231 in epoch 16, gen_loss = 0.3977309986948967, disc_loss = 0.07764292982455086
Trained batch 232 in epoch 16, gen_loss = 0.39784982583041867, disc_loss = 0.07806859659870423
Trained batch 233 in epoch 16, gen_loss = 0.3979993392514367, disc_loss = 0.07806833587093358
Trained batch 234 in epoch 16, gen_loss = 0.3982728275846928, disc_loss = 0.07779368224375426
Trained batch 235 in epoch 16, gen_loss = 0.39847346685700497, disc_loss = 0.07751883924701962
Trained batch 236 in epoch 16, gen_loss = 0.3986037540787886, disc_loss = 0.07727802272901757
Trained batch 237 in epoch 16, gen_loss = 0.3984979116866569, disc_loss = 0.07719003830198981
Trained batch 238 in epoch 16, gen_loss = 0.3985763561276711, disc_loss = 0.07714289861680573
Trained batch 239 in epoch 16, gen_loss = 0.398751121511062, disc_loss = 0.07691531544551253
Trained batch 240 in epoch 16, gen_loss = 0.39901957175543695, disc_loss = 0.0774711720119868
Trained batch 241 in epoch 16, gen_loss = 0.3988167429265897, disc_loss = 0.07838747099288239
Trained batch 242 in epoch 16, gen_loss = 0.3990830153594782, disc_loss = 0.07819795367833028
Trained batch 243 in epoch 16, gen_loss = 0.3993138565880353, disc_loss = 0.07825374595637692
Trained batch 244 in epoch 16, gen_loss = 0.39947944222664344, disc_loss = 0.07799120947186436
Trained batch 245 in epoch 16, gen_loss = 0.3993520678543463, disc_loss = 0.07819040846912478
Trained batch 246 in epoch 16, gen_loss = 0.3998350455210759, disc_loss = 0.07797874353810964
Trained batch 247 in epoch 16, gen_loss = 0.3998057067153915, disc_loss = 0.07782874734426339
Trained batch 248 in epoch 16, gen_loss = 0.39980707960913936, disc_loss = 0.07756813431914193
Trained batch 249 in epoch 16, gen_loss = 0.3999258967638016, disc_loss = 0.07738002340868115
Trained batch 250 in epoch 16, gen_loss = 0.3996179261768007, disc_loss = 0.07770065730623159
Trained batch 251 in epoch 16, gen_loss = 0.39969273656606674, disc_loss = 0.07769599186241745
Trained batch 252 in epoch 16, gen_loss = 0.3997498581060779, disc_loss = 0.07762292468103142
Trained batch 253 in epoch 16, gen_loss = 0.39965667335067206, disc_loss = 0.07821494064066471
Trained batch 254 in epoch 16, gen_loss = 0.39991323199926637, disc_loss = 0.07813245474780892
Trained batch 255 in epoch 16, gen_loss = 0.40013498079497367, disc_loss = 0.07825031191532617
Trained batch 256 in epoch 16, gen_loss = 0.4001075868940539, disc_loss = 0.07799657648030654
Trained batch 257 in epoch 16, gen_loss = 0.4000988492901011, disc_loss = 0.07817735337442899
Trained batch 258 in epoch 16, gen_loss = 0.3996754095361039, disc_loss = 0.07797316355364663
Trained batch 259 in epoch 16, gen_loss = 0.3996827102624453, disc_loss = 0.07780596129596233
Trained batch 260 in epoch 16, gen_loss = 0.399946511134334, disc_loss = 0.07759489617899232
Trained batch 261 in epoch 16, gen_loss = 0.39969027042388916, disc_loss = 0.07754043511733527
Trained batch 262 in epoch 16, gen_loss = 0.39969789415257967, disc_loss = 0.07731830234508325
Trained batch 263 in epoch 16, gen_loss = 0.39996344528414984, disc_loss = 0.07742786344676984
Trained batch 264 in epoch 16, gen_loss = 0.40007101049963034, disc_loss = 0.0775923148289604
Trained batch 265 in epoch 16, gen_loss = 0.4002311686824139, disc_loss = 0.07736253445001698
Trained batch 266 in epoch 16, gen_loss = 0.40033896987357837, disc_loss = 0.07724734558287855
Trained batch 267 in epoch 16, gen_loss = 0.4005600011615611, disc_loss = 0.07708582388403923
Trained batch 268 in epoch 16, gen_loss = 0.4005699811371729, disc_loss = 0.07698414339701261
Trained batch 269 in epoch 16, gen_loss = 0.40089864565266503, disc_loss = 0.07691994414975246
Trained batch 270 in epoch 16, gen_loss = 0.40071194253284553, disc_loss = 0.07690057277377021
Trained batch 271 in epoch 16, gen_loss = 0.4008959813372177, disc_loss = 0.07685186399612576
Trained batch 272 in epoch 16, gen_loss = 0.4010046856962281, disc_loss = 0.07661562455961338
Trained batch 273 in epoch 16, gen_loss = 0.4010071520605227, disc_loss = 0.07669671134764913
Trained batch 274 in epoch 16, gen_loss = 0.4013518087430434, disc_loss = 0.07705687982792205
Trained batch 275 in epoch 16, gen_loss = 0.4014544182497522, disc_loss = 0.07685519676601542
Trained batch 276 in epoch 16, gen_loss = 0.40174014613516495, disc_loss = 0.07682809779682745
Trained batch 277 in epoch 16, gen_loss = 0.40167502040485686, disc_loss = 0.07665192941538722
Trained batch 278 in epoch 16, gen_loss = 0.40198531949819205, disc_loss = 0.07654117539151167
Trained batch 279 in epoch 16, gen_loss = 0.4019381184663091, disc_loss = 0.07644842118024826
Trained batch 280 in epoch 16, gen_loss = 0.40195184086989677, disc_loss = 0.07628407381024224
Trained batch 281 in epoch 16, gen_loss = 0.40168091570231934, disc_loss = 0.0760697033982856
Trained batch 282 in epoch 16, gen_loss = 0.4017849113831672, disc_loss = 0.07584860990672988
Trained batch 283 in epoch 16, gen_loss = 0.4017001781874979, disc_loss = 0.07574384377508515
Trained batch 284 in epoch 16, gen_loss = 0.4017329708526009, disc_loss = 0.07574028415899528
Trained batch 285 in epoch 16, gen_loss = 0.40185781521397035, disc_loss = 0.07583472292896334
Trained batch 286 in epoch 16, gen_loss = 0.4018613442726667, disc_loss = 0.07659297583150947
Trained batch 287 in epoch 16, gen_loss = 0.4018922857940197, disc_loss = 0.07649308868632135
Trained batch 288 in epoch 16, gen_loss = 0.4018551320559426, disc_loss = 0.07640023325863181
Trained batch 289 in epoch 16, gen_loss = 0.40166868094740243, disc_loss = 0.07638808049518486
Trained batch 290 in epoch 16, gen_loss = 0.40162152953164276, disc_loss = 0.07619390688529334
Trained batch 291 in epoch 16, gen_loss = 0.40154010506525434, disc_loss = 0.07603834989187244
Trained batch 292 in epoch 16, gen_loss = 0.40167549944168063, disc_loss = 0.07622493174143212
Trained batch 293 in epoch 16, gen_loss = 0.40145221899966804, disc_loss = 0.07697997770595308
Trained batch 294 in epoch 16, gen_loss = 0.4017039860709239, disc_loss = 0.07713069315936606
Trained batch 295 in epoch 16, gen_loss = 0.402015666099819, disc_loss = 0.07700777822803404
Trained batch 296 in epoch 16, gen_loss = 0.4020581576559279, disc_loss = 0.07692112452554381
Trained batch 297 in epoch 16, gen_loss = 0.402045253739261, disc_loss = 0.0767797747964427
Trained batch 298 in epoch 16, gen_loss = 0.4019436137532709, disc_loss = 0.07663170290631195
Trained batch 299 in epoch 16, gen_loss = 0.4022614460190137, disc_loss = 0.07690888633330663
Trained batch 300 in epoch 16, gen_loss = 0.402015816234671, disc_loss = 0.0774370464573667
Trained batch 301 in epoch 16, gen_loss = 0.40209185060681096, disc_loss = 0.07809986963572092
Trained batch 302 in epoch 16, gen_loss = 0.4019395588058056, disc_loss = 0.07798085586711911
Trained batch 303 in epoch 16, gen_loss = 0.4017770714861782, disc_loss = 0.07793518872686515
Trained batch 304 in epoch 16, gen_loss = 0.40154885483569785, disc_loss = 0.07789202328832423
Trained batch 305 in epoch 16, gen_loss = 0.4017050431834327, disc_loss = 0.07797921430684772
Trained batch 306 in epoch 16, gen_loss = 0.4014214981068229, disc_loss = 0.07786075802404639
Trained batch 307 in epoch 16, gen_loss = 0.40125512699415156, disc_loss = 0.07787511879941086
Trained batch 308 in epoch 16, gen_loss = 0.4013562939313623, disc_loss = 0.0778265490790401
Trained batch 309 in epoch 16, gen_loss = 0.40165218874331443, disc_loss = 0.07762288333727949
Trained batch 310 in epoch 16, gen_loss = 0.4017582734106438, disc_loss = 0.07742818719572672
Trained batch 311 in epoch 16, gen_loss = 0.40196335583161086, disc_loss = 0.07735083948593968
Trained batch 312 in epoch 16, gen_loss = 0.4018448317964999, disc_loss = 0.07725988736989113
Trained batch 313 in epoch 16, gen_loss = 0.401903323212247, disc_loss = 0.07711780238837289
Trained batch 314 in epoch 16, gen_loss = 0.4016214522104415, disc_loss = 0.0770648429584172
Trained batch 315 in epoch 16, gen_loss = 0.4015567193302927, disc_loss = 0.07717692901828338
Trained batch 316 in epoch 16, gen_loss = 0.40119001128320064, disc_loss = 0.07779462633460572
Trained batch 317 in epoch 16, gen_loss = 0.40143508300091485, disc_loss = 0.07792745109167208
Trained batch 318 in epoch 16, gen_loss = 0.4017057001217032, disc_loss = 0.07773254156918455
Trained batch 319 in epoch 16, gen_loss = 0.40190524738281963, disc_loss = 0.0776526002358878
Trained batch 320 in epoch 16, gen_loss = 0.4016616472574038, disc_loss = 0.07765998110186738
Trained batch 321 in epoch 16, gen_loss = 0.40152355510255566, disc_loss = 0.0778931961163462
Trained batch 322 in epoch 16, gen_loss = 0.401397927349935, disc_loss = 0.07772712021108844
Trained batch 323 in epoch 16, gen_loss = 0.401264884221701, disc_loss = 0.0775747640133134
Trained batch 324 in epoch 16, gen_loss = 0.4012815183859605, disc_loss = 0.07741266768425703
Trained batch 325 in epoch 16, gen_loss = 0.4013467561796399, disc_loss = 0.07735477103080395
Trained batch 326 in epoch 16, gen_loss = 0.401325147359743, disc_loss = 0.07722149325380905
Trained batch 327 in epoch 16, gen_loss = 0.40121345167479866, disc_loss = 0.07720959098816554
Trained batch 328 in epoch 16, gen_loss = 0.40140897515696955, disc_loss = 0.07699956072601957
Trained batch 329 in epoch 16, gen_loss = 0.4012098997831345, disc_loss = 0.07681786008461407
Trained batch 330 in epoch 16, gen_loss = 0.4014406449124892, disc_loss = 0.07661849231349467
Trained batch 331 in epoch 16, gen_loss = 0.4013102786189102, disc_loss = 0.07647051406653979
Trained batch 332 in epoch 16, gen_loss = 0.4012323725330937, disc_loss = 0.0764979601560815
Trained batch 333 in epoch 16, gen_loss = 0.4016420384367069, disc_loss = 0.0765666189871193
Trained batch 334 in epoch 16, gen_loss = 0.4016021034610805, disc_loss = 0.0763774301022736
Trained batch 335 in epoch 16, gen_loss = 0.40152552927888574, disc_loss = 0.0763246190756382
Trained batch 336 in epoch 16, gen_loss = 0.40153204068232007, disc_loss = 0.0761803776987494
Trained batch 337 in epoch 16, gen_loss = 0.40146171685153914, disc_loss = 0.07603079476807068
Trained batch 338 in epoch 16, gen_loss = 0.4014922498250078, disc_loss = 0.07590801522113756
Trained batch 339 in epoch 16, gen_loss = 0.4013201813487446, disc_loss = 0.07580385011456468
Trained batch 340 in epoch 16, gen_loss = 0.4015095694498582, disc_loss = 0.07569674084023122
Trained batch 341 in epoch 16, gen_loss = 0.40140973955218556, disc_loss = 0.0756885524218281
Trained batch 342 in epoch 16, gen_loss = 0.40176245170501507, disc_loss = 0.07581556080664038
Trained batch 343 in epoch 16, gen_loss = 0.40144759468561, disc_loss = 0.07571636075912
Trained batch 344 in epoch 16, gen_loss = 0.4013775283875673, disc_loss = 0.07571220895194489
Trained batch 345 in epoch 16, gen_loss = 0.4013062488998292, disc_loss = 0.07561408473727847
Trained batch 346 in epoch 16, gen_loss = 0.40139342874546213, disc_loss = 0.07607352247821322
Trained batch 347 in epoch 16, gen_loss = 0.4011694375297119, disc_loss = 0.07641931549892172
Trained batch 348 in epoch 16, gen_loss = 0.4013944264810885, disc_loss = 0.07626383287303769
Trained batch 349 in epoch 16, gen_loss = 0.4014984610251018, disc_loss = 0.07618041740996497
Trained batch 350 in epoch 16, gen_loss = 0.40165535311753253, disc_loss = 0.07602102146019624
Trained batch 351 in epoch 16, gen_loss = 0.40167385272004386, disc_loss = 0.0758879390725104
Trained batch 352 in epoch 16, gen_loss = 0.4014100466166272, disc_loss = 0.07582191674951622
Trained batch 353 in epoch 16, gen_loss = 0.40131242430142766, disc_loss = 0.07576073695100465
Trained batch 354 in epoch 16, gen_loss = 0.4010460041778188, disc_loss = 0.07562939171535028
Trained batch 355 in epoch 16, gen_loss = 0.4012317485856206, disc_loss = 0.07569013895425067
Trained batch 356 in epoch 16, gen_loss = 0.4013143644279459, disc_loss = 0.07566855818095829
Trained batch 357 in epoch 16, gen_loss = 0.4013135487307383, disc_loss = 0.07550946818196408
Trained batch 358 in epoch 16, gen_loss = 0.4011563534192056, disc_loss = 0.07540619113381361
Trained batch 359 in epoch 16, gen_loss = 0.40114449742767544, disc_loss = 0.07526034652255476
Trained batch 360 in epoch 16, gen_loss = 0.40112008967558105, disc_loss = 0.07533805016067055
Trained batch 361 in epoch 16, gen_loss = 0.40101108555965004, disc_loss = 0.07527140717829953
Trained batch 362 in epoch 16, gen_loss = 0.40125766133802326, disc_loss = 0.07531038136542172
Trained batch 363 in epoch 16, gen_loss = 0.4012070172926882, disc_loss = 0.07523295308391635
Trained batch 364 in epoch 16, gen_loss = 0.40113672254836724, disc_loss = 0.07505733866295586
Trained batch 365 in epoch 16, gen_loss = 0.4011077871088122, disc_loss = 0.07490281807513186
Trained batch 366 in epoch 16, gen_loss = 0.4012705834749934, disc_loss = 0.07476092118272502
Trained batch 367 in epoch 16, gen_loss = 0.40122783953404945, disc_loss = 0.07483768194367219
Trained batch 368 in epoch 16, gen_loss = 0.4012234880510708, disc_loss = 0.07556016891084227
Trained batch 369 in epoch 16, gen_loss = 0.4016065976909689, disc_loss = 0.07554559768555132
Trained batch 370 in epoch 16, gen_loss = 0.4017797791250954, disc_loss = 0.07556645432110584
Trained batch 371 in epoch 16, gen_loss = 0.40166432722922296, disc_loss = 0.07542307241769727
Trained batch 372 in epoch 16, gen_loss = 0.40150600168404565, disc_loss = 0.07564414537763947
Trained batch 373 in epoch 16, gen_loss = 0.4016828011860822, disc_loss = 0.07591877909088358
Trained batch 374 in epoch 16, gen_loss = 0.4017297511100769, disc_loss = 0.07579172293345134
Trained batch 375 in epoch 16, gen_loss = 0.40162414439181066, disc_loss = 0.07565490367445857
Trained batch 376 in epoch 16, gen_loss = 0.40161065919329697, disc_loss = 0.07555127384966184
Trained batch 377 in epoch 16, gen_loss = 0.40158250770240866, disc_loss = 0.07538914153470642
Trained batch 378 in epoch 16, gen_loss = 0.40150712355774754, disc_loss = 0.07523204659733498
Trained batch 379 in epoch 16, gen_loss = 0.40139532551953666, disc_loss = 0.07509276075043568
Trained batch 380 in epoch 16, gen_loss = 0.40123325648896024, disc_loss = 0.07514274445193725
Trained batch 381 in epoch 16, gen_loss = 0.40110792328861994, disc_loss = 0.07548695990172122
Trained batch 382 in epoch 16, gen_loss = 0.40130056296876454, disc_loss = 0.07599251536657309
Trained batch 383 in epoch 16, gen_loss = 0.40120388683862984, disc_loss = 0.07586250310365965
Trained batch 384 in epoch 16, gen_loss = 0.40084413065538776, disc_loss = 0.07618670033702216
Trained batch 385 in epoch 16, gen_loss = 0.400863841176033, disc_loss = 0.0760411080817446
Trained batch 386 in epoch 16, gen_loss = 0.4008756728135338, disc_loss = 0.07601285055616644
Trained batch 387 in epoch 16, gen_loss = 0.40095654974893197, disc_loss = 0.07584719626549824
Trained batch 388 in epoch 16, gen_loss = 0.400882342940431, disc_loss = 0.0757037208350926
Trained batch 389 in epoch 16, gen_loss = 0.40069597760836284, disc_loss = 0.07561031710117673
Trained batch 390 in epoch 16, gen_loss = 0.40067024273640667, disc_loss = 0.07546158747323563
Trained batch 391 in epoch 16, gen_loss = 0.40056178992500113, disc_loss = 0.07532052111061176
Trained batch 392 in epoch 16, gen_loss = 0.40053680425381843, disc_loss = 0.0754661163144553
Trained batch 393 in epoch 16, gen_loss = 0.4006531737782628, disc_loss = 0.07570422827242519
Trained batch 394 in epoch 16, gen_loss = 0.4006122128118443, disc_loss = 0.07558632870027913
Trained batch 395 in epoch 16, gen_loss = 0.4007524315154914, disc_loss = 0.07546636903178737
Trained batch 396 in epoch 16, gen_loss = 0.4007814633906338, disc_loss = 0.07534761311866399
Trained batch 397 in epoch 16, gen_loss = 0.40063831839130154, disc_loss = 0.0753649584738416
Trained batch 398 in epoch 16, gen_loss = 0.4004850040999869, disc_loss = 0.07585075445109069
Trained batch 399 in epoch 16, gen_loss = 0.4007075282931328, disc_loss = 0.07574758760398254
Trained batch 400 in epoch 16, gen_loss = 0.40083762780389287, disc_loss = 0.07587839495576454
Trained batch 401 in epoch 16, gen_loss = 0.4005905150329296, disc_loss = 0.07600137709746536
Trained batch 402 in epoch 16, gen_loss = 0.4006473048597057, disc_loss = 0.07603050457549376
Trained batch 403 in epoch 16, gen_loss = 0.4007939119445215, disc_loss = 0.07632664760510151
Trained batch 404 in epoch 16, gen_loss = 0.4005158648078824, disc_loss = 0.07651671038503632
Trained batch 405 in epoch 16, gen_loss = 0.40048949303004544, disc_loss = 0.07669210877829218
Trained batch 406 in epoch 16, gen_loss = 0.4006609416564501, disc_loss = 0.07716268860947807
Trained batch 407 in epoch 16, gen_loss = 0.4008812108168415, disc_loss = 0.0770732766706679
Trained batch 408 in epoch 16, gen_loss = 0.4008153464217058, disc_loss = 0.07694727716817176
Trained batch 409 in epoch 16, gen_loss = 0.4006209209197905, disc_loss = 0.07687148688724492
Trained batch 410 in epoch 16, gen_loss = 0.40065073343379076, disc_loss = 0.07676477054782085
Trained batch 411 in epoch 16, gen_loss = 0.400515856022395, disc_loss = 0.07681662020345842
Trained batch 412 in epoch 16, gen_loss = 0.40069523771219046, disc_loss = 0.07677574553831365
Trained batch 413 in epoch 16, gen_loss = 0.4006680934037563, disc_loss = 0.07667705576623911
Trained batch 414 in epoch 16, gen_loss = 0.40048053745763845, disc_loss = 0.07657845024558076
Trained batch 415 in epoch 16, gen_loss = 0.4004612836556939, disc_loss = 0.07651012663756354
Trained batch 416 in epoch 16, gen_loss = 0.40066239680889415, disc_loss = 0.07637532559006835
Trained batch 417 in epoch 16, gen_loss = 0.40063500803623475, disc_loss = 0.07638304885343145
Trained batch 418 in epoch 16, gen_loss = 0.40048970228732345, disc_loss = 0.0764938201155149
Trained batch 419 in epoch 16, gen_loss = 0.4004016610128539, disc_loss = 0.07637592498878283
Trained batch 420 in epoch 16, gen_loss = 0.40041282447386806, disc_loss = 0.07622134848110679
Trained batch 421 in epoch 16, gen_loss = 0.40029359605357545, disc_loss = 0.07609245401114155
Trained batch 422 in epoch 16, gen_loss = 0.40015936531919116, disc_loss = 0.07601930993008064
Trained batch 423 in epoch 16, gen_loss = 0.40028840429940316, disc_loss = 0.07601549570615632
Trained batch 424 in epoch 16, gen_loss = 0.400169080285465, disc_loss = 0.07599781535346718
Trained batch 425 in epoch 16, gen_loss = 0.4002162837226626, disc_loss = 0.07590725793428894
Trained batch 426 in epoch 16, gen_loss = 0.40008023695309214, disc_loss = 0.07593097046794113
Trained batch 427 in epoch 16, gen_loss = 0.40010603350178103, disc_loss = 0.07581438301087609
Trained batch 428 in epoch 16, gen_loss = 0.3999513154263263, disc_loss = 0.0758351683725184
Trained batch 429 in epoch 16, gen_loss = 0.40008921872737796, disc_loss = 0.07573753307075348
Trained batch 430 in epoch 16, gen_loss = 0.40036569255687243, disc_loss = 0.07559397638388618
Trained batch 431 in epoch 16, gen_loss = 0.40028797614353673, disc_loss = 0.0754755011013778
Trained batch 432 in epoch 16, gen_loss = 0.40017937540182064, disc_loss = 0.07551321443858584
Trained batch 433 in epoch 16, gen_loss = 0.40013279954683945, disc_loss = 0.07546668995626717
Trained batch 434 in epoch 16, gen_loss = 0.40027043874236357, disc_loss = 0.07533726490734295
Trained batch 435 in epoch 16, gen_loss = 0.4003101372664128, disc_loss = 0.07524017266578836
Trained batch 436 in epoch 16, gen_loss = 0.4002730369704266, disc_loss = 0.07511384837815295
Trained batch 437 in epoch 16, gen_loss = 0.4001903304634573, disc_loss = 0.0751282967367639
Trained batch 438 in epoch 16, gen_loss = 0.40013078819103287, disc_loss = 0.07511077369595104
Trained batch 439 in epoch 16, gen_loss = 0.4001166966828433, disc_loss = 0.07498464081224732
Trained batch 440 in epoch 16, gen_loss = 0.40003631174429205, disc_loss = 0.07487187946168812
Trained batch 441 in epoch 16, gen_loss = 0.3999363629661534, disc_loss = 0.07499871326492451
Trained batch 442 in epoch 16, gen_loss = 0.40014138945607514, disc_loss = 0.07540815699694187
Trained batch 443 in epoch 16, gen_loss = 0.40031768898437686, disc_loss = 0.07530139587811185
Trained batch 444 in epoch 16, gen_loss = 0.400267783376608, disc_loss = 0.07521087049893783
Trained batch 445 in epoch 16, gen_loss = 0.400248668453084, disc_loss = 0.07509980368482225
Trained batch 446 in epoch 16, gen_loss = 0.40024542488507775, disc_loss = 0.07498445590828823
Trained batch 447 in epoch 16, gen_loss = 0.40031605353578925, disc_loss = 0.07489661034820269
Trained batch 448 in epoch 16, gen_loss = 0.4003161761436802, disc_loss = 0.07477925737535701
Trained batch 449 in epoch 16, gen_loss = 0.4003342666890886, disc_loss = 0.07466828609299328
Trained batch 450 in epoch 16, gen_loss = 0.40035143897697295, disc_loss = 0.07457392791414141
Trained batch 451 in epoch 16, gen_loss = 0.400595181547435, disc_loss = 0.07447085174138501
Trained batch 452 in epoch 16, gen_loss = 0.40059021286353896, disc_loss = 0.07451444774430253
Trained batch 453 in epoch 16, gen_loss = 0.4004506047995605, disc_loss = 0.07486225899907921
Trained batch 454 in epoch 16, gen_loss = 0.40037746671791913, disc_loss = 0.07476029622235468
Trained batch 455 in epoch 16, gen_loss = 0.4004817454046325, disc_loss = 0.07466147142143822
Trained batch 456 in epoch 16, gen_loss = 0.4004022111256222, disc_loss = 0.07479358033870125
Trained batch 457 in epoch 16, gen_loss = 0.4002965195470502, disc_loss = 0.07486462335846505
Trained batch 458 in epoch 16, gen_loss = 0.40023765370477, disc_loss = 0.07503208673654493
Testing Epoch 16
Training Epoch 17
Trained batch 0 in epoch 17, gen_loss = 0.3638494610786438, disc_loss = 0.17418412864208221
Trained batch 1 in epoch 17, gen_loss = 0.4106728583574295, disc_loss = 0.12433067709207535
Trained batch 2 in epoch 17, gen_loss = 0.4272015194098155, disc_loss = 0.08727872278541327
Trained batch 3 in epoch 17, gen_loss = 0.41133134812116623, disc_loss = 0.11010923539288342
Trained batch 4 in epoch 17, gen_loss = 0.4229761600494385, disc_loss = 0.12032034937292338
Trained batch 5 in epoch 17, gen_loss = 0.40363116562366486, disc_loss = 0.12444120598956943
Trained batch 6 in epoch 17, gen_loss = 0.4047787572656359, disc_loss = 0.1187003655359149
Trained batch 7 in epoch 17, gen_loss = 0.39629529044032097, disc_loss = 0.11173291655723006
Trained batch 8 in epoch 17, gen_loss = 0.3927173846297794, disc_loss = 0.10479588278879721
Trained batch 9 in epoch 17, gen_loss = 0.39607892036437986, disc_loss = 0.0989117001183331
Trained batch 10 in epoch 17, gen_loss = 0.3968674052845348, disc_loss = 0.09360795713622462
Trained batch 11 in epoch 17, gen_loss = 0.39681650946537655, disc_loss = 0.0868356969828407
Trained batch 12 in epoch 17, gen_loss = 0.402981888789397, disc_loss = 0.08722840048945867
Trained batch 13 in epoch 17, gen_loss = 0.39713382933820995, disc_loss = 0.1013801856232541
Trained batch 14 in epoch 17, gen_loss = 0.40618735750516255, disc_loss = 0.10016175632675489
Trained batch 15 in epoch 17, gen_loss = 0.4062113892287016, disc_loss = 0.0958481184206903
Trained batch 16 in epoch 17, gen_loss = 0.40499016467262716, disc_loss = 0.09196348926600288
Trained batch 17 in epoch 17, gen_loss = 0.4079244136810303, disc_loss = 0.08880756050348282
Trained batch 18 in epoch 17, gen_loss = 0.4090760742363177, disc_loss = 0.08509737694341886
Trained batch 19 in epoch 17, gen_loss = 0.412889601290226, disc_loss = 0.08157990099862218
Trained batch 20 in epoch 17, gen_loss = 0.4111380378405253, disc_loss = 0.08130112157336303
Trained batch 21 in epoch 17, gen_loss = 0.4122248657725074, disc_loss = 0.08429493628103625
Trained batch 22 in epoch 17, gen_loss = 0.4124990507312443, disc_loss = 0.08284939898420936
Trained batch 23 in epoch 17, gen_loss = 0.41153643901149434, disc_loss = 0.07993001859479894
Trained batch 24 in epoch 17, gen_loss = 0.40911375641822817, disc_loss = 0.07910289537161588
Trained batch 25 in epoch 17, gen_loss = 0.4103910567668768, disc_loss = 0.07810490474534723
Trained batch 26 in epoch 17, gen_loss = 0.41311776969167924, disc_loss = 0.07666962273004982
Trained batch 27 in epoch 17, gen_loss = 0.4105064400604793, disc_loss = 0.07550867510560368
Trained batch 28 in epoch 17, gen_loss = 0.41296726670758477, disc_loss = 0.07505573637398152
Trained batch 29 in epoch 17, gen_loss = 0.41481032967567444, disc_loss = 0.07298384041835865
Trained batch 30 in epoch 17, gen_loss = 0.4126302465315788, disc_loss = 0.07545440553897811
Trained batch 31 in epoch 17, gen_loss = 0.4141593165695667, disc_loss = 0.07610654860036448
Trained batch 32 in epoch 17, gen_loss = 0.414173935398911, disc_loss = 0.07489886975875407
Trained batch 33 in epoch 17, gen_loss = 0.4110284763223985, disc_loss = 0.07703910247587106
Trained batch 34 in epoch 17, gen_loss = 0.4085843937737601, disc_loss = 0.07521641813218594
Trained batch 35 in epoch 17, gen_loss = 0.41087163653638625, disc_loss = 0.07445194887825185
Trained batch 36 in epoch 17, gen_loss = 0.410567521243482, disc_loss = 0.07262453546344831
Trained batch 37 in epoch 17, gen_loss = 0.40989527263139425, disc_loss = 0.0711225371832322
Trained batch 38 in epoch 17, gen_loss = 0.4106938433952821, disc_loss = 0.07006950863899711
Trained batch 39 in epoch 17, gen_loss = 0.41012618616223334, disc_loss = 0.06856132295215503
Trained batch 40 in epoch 17, gen_loss = 0.41157269768598603, disc_loss = 0.067111303064427
Trained batch 41 in epoch 17, gen_loss = 0.4107455809911092, disc_loss = 0.06621852516019273
Trained batch 42 in epoch 17, gen_loss = 0.410269103077955, disc_loss = 0.06528191457957376
Trained batch 43 in epoch 17, gen_loss = 0.40937355160713196, disc_loss = 0.06553549115249718
Trained batch 44 in epoch 17, gen_loss = 0.40735012623998856, disc_loss = 0.07208792168854011
Trained batch 45 in epoch 17, gen_loss = 0.4074270828910496, disc_loss = 0.07166376239215226
Trained batch 46 in epoch 17, gen_loss = 0.4071607196584661, disc_loss = 0.07111940119772199
Trained batch 47 in epoch 17, gen_loss = 0.4072108169396718, disc_loss = 0.07149198231248495
Trained batch 48 in epoch 17, gen_loss = 0.4041171791602154, disc_loss = 0.07179466025827795
Trained batch 49 in epoch 17, gen_loss = 0.4055621099472046, disc_loss = 0.07146927162073552
Trained batch 50 in epoch 17, gen_loss = 0.4060015643344206, disc_loss = 0.07178175755246889
Trained batch 51 in epoch 17, gen_loss = 0.4054173758396736, disc_loss = 0.07429647602391644
Trained batch 52 in epoch 17, gen_loss = 0.4060990146870883, disc_loss = 0.07459607677323357
Trained batch 53 in epoch 17, gen_loss = 0.40551995679184244, disc_loss = 0.07392494779735527
Trained batch 54 in epoch 17, gen_loss = 0.406025061824105, disc_loss = 0.07360561983659863
Trained batch 55 in epoch 17, gen_loss = 0.40578529132264, disc_loss = 0.07282399465163637
Trained batch 56 in epoch 17, gen_loss = 0.40641109671509057, disc_loss = 0.07294744409195948
Trained batch 57 in epoch 17, gen_loss = 0.40604373298842333, disc_loss = 0.07386196403892646
Trained batch 58 in epoch 17, gen_loss = 0.4079279636932632, disc_loss = 0.07422741931089658
Trained batch 59 in epoch 17, gen_loss = 0.4080657511949539, disc_loss = 0.07319335328259816
Trained batch 60 in epoch 17, gen_loss = 0.40835620633891373, disc_loss = 0.07245707721831124
Trained batch 61 in epoch 17, gen_loss = 0.40885308432963585, disc_loss = 0.07157141723549895
Trained batch 62 in epoch 17, gen_loss = 0.4094183113839891, disc_loss = 0.0708644305769768
Trained batch 63 in epoch 17, gen_loss = 0.40976126957684755, disc_loss = 0.07030751302227145
Trained batch 64 in epoch 17, gen_loss = 0.4092100877028245, disc_loss = 0.06960316279616494
Trained batch 65 in epoch 17, gen_loss = 0.409239623131174, disc_loss = 0.0691737294634522
Trained batch 66 in epoch 17, gen_loss = 0.40826574990998454, disc_loss = 0.0687881960227752
Trained batch 67 in epoch 17, gen_loss = 0.40792424056459875, disc_loss = 0.06842935262658797
Trained batch 68 in epoch 17, gen_loss = 0.40868768398312555, disc_loss = 0.07155176869634053
Trained batch 69 in epoch 17, gen_loss = 0.4083633405821664, disc_loss = 0.0714821226030056
Trained batch 70 in epoch 17, gen_loss = 0.4094350300204586, disc_loss = 0.07084181631298762
Trained batch 71 in epoch 17, gen_loss = 0.4105669669806957, disc_loss = 0.07112196470067526
Trained batch 72 in epoch 17, gen_loss = 0.40960532426834106, disc_loss = 0.07131290720928818
Trained batch 73 in epoch 17, gen_loss = 0.4101767664825594, disc_loss = 0.07101936280299481
Trained batch 74 in epoch 17, gen_loss = 0.4099012251694997, disc_loss = 0.07295354807749391
Trained batch 75 in epoch 17, gen_loss = 0.40943972178195653, disc_loss = 0.07246503292117268
Trained batch 76 in epoch 17, gen_loss = 0.4088041995252882, disc_loss = 0.07255617576929463
Trained batch 77 in epoch 17, gen_loss = 0.40990687562869144, disc_loss = 0.07319659490783054
Trained batch 78 in epoch 17, gen_loss = 0.4096860149993172, disc_loss = 0.07260984615599618
Trained batch 79 in epoch 17, gen_loss = 0.40814213193953036, disc_loss = 0.07325680460198783
Trained batch 80 in epoch 17, gen_loss = 0.40900744442586545, disc_loss = 0.0745848853221554
Trained batch 81 in epoch 17, gen_loss = 0.4091995936341402, disc_loss = 0.07408522809401336
Trained batch 82 in epoch 17, gen_loss = 0.4088248272976243, disc_loss = 0.07418886854324534
Trained batch 83 in epoch 17, gen_loss = 0.40894608483428047, disc_loss = 0.07431015464854204
Trained batch 84 in epoch 17, gen_loss = 0.4085738567744984, disc_loss = 0.07480625137138892
Trained batch 85 in epoch 17, gen_loss = 0.4089545621428379, disc_loss = 0.07507533783114753
Trained batch 86 in epoch 17, gen_loss = 0.4087082647729194, disc_loss = 0.07560631927723686
Trained batch 87 in epoch 17, gen_loss = 0.4091738438741727, disc_loss = 0.07540400567020035
Trained batch 88 in epoch 17, gen_loss = 0.4100360060006045, disc_loss = 0.07472696746019332
Trained batch 89 in epoch 17, gen_loss = 0.4098712235689163, disc_loss = 0.07427911026299827
Trained batch 90 in epoch 17, gen_loss = 0.40941793348763017, disc_loss = 0.07434466960686413
Trained batch 91 in epoch 17, gen_loss = 0.40896607287552045, disc_loss = 0.07549530596209122
Trained batch 92 in epoch 17, gen_loss = 0.4097889277242845, disc_loss = 0.07759958125590798
Trained batch 93 in epoch 17, gen_loss = 0.40950597283687995, disc_loss = 0.0772556924568291
Trained batch 94 in epoch 17, gen_loss = 0.40879373079852055, disc_loss = 0.07805973640888145
Trained batch 95 in epoch 17, gen_loss = 0.40883403675009805, disc_loss = 0.07796710415762693
Trained batch 96 in epoch 17, gen_loss = 0.4091389652380009, disc_loss = 0.07735790312770255
Trained batch 97 in epoch 17, gen_loss = 0.4094586612618699, disc_loss = 0.07687333317910683
Trained batch 98 in epoch 17, gen_loss = 0.4090428665430859, disc_loss = 0.0766188962940089
Trained batch 99 in epoch 17, gen_loss = 0.4088845363259315, disc_loss = 0.07660728171933442
Trained batch 100 in epoch 17, gen_loss = 0.4086909665919767, disc_loss = 0.07680247628618733
Trained batch 101 in epoch 17, gen_loss = 0.40859681835361555, disc_loss = 0.07630720605398071
Trained batch 102 in epoch 17, gen_loss = 0.4077888255559125, disc_loss = 0.0758073345703769
Trained batch 103 in epoch 17, gen_loss = 0.40786978430472887, disc_loss = 0.0770141780242109
Trained batch 104 in epoch 17, gen_loss = 0.4078157507237934, disc_loss = 0.07792059380472416
Trained batch 105 in epoch 17, gen_loss = 0.40741471159008313, disc_loss = 0.07730817246988837
Trained batch 106 in epoch 17, gen_loss = 0.4080497892660515, disc_loss = 0.0773601551522788
Trained batch 107 in epoch 17, gen_loss = 0.40788733545276856, disc_loss = 0.07686740912376316
Trained batch 108 in epoch 17, gen_loss = 0.407384867515039, disc_loss = 0.07699516873994688
Trained batch 109 in epoch 17, gen_loss = 0.4076618270440535, disc_loss = 0.07772122425535186
Trained batch 110 in epoch 17, gen_loss = 0.40842606462873854, disc_loss = 0.0772534466247905
Trained batch 111 in epoch 17, gen_loss = 0.40847902345870224, disc_loss = 0.07692910964085188
Trained batch 112 in epoch 17, gen_loss = 0.40804040062744007, disc_loss = 0.0766638130056713
Trained batch 113 in epoch 17, gen_loss = 0.40857453330567006, disc_loss = 0.07626614203725599
Trained batch 114 in epoch 17, gen_loss = 0.4086253821849823, disc_loss = 0.0759319527682079
Trained batch 115 in epoch 17, gen_loss = 0.40791566515791006, disc_loss = 0.07588850334688121
Trained batch 116 in epoch 17, gen_loss = 0.4075892516690442, disc_loss = 0.07593377781872693
Trained batch 117 in epoch 17, gen_loss = 0.40806180188211344, disc_loss = 0.07548526144523363
Trained batch 118 in epoch 17, gen_loss = 0.40886141021712485, disc_loss = 0.07508507117769923
Trained batch 119 in epoch 17, gen_loss = 0.4087119663755099, disc_loss = 0.07497486863673354
Trained batch 120 in epoch 17, gen_loss = 0.40917503094870195, disc_loss = 0.07449170845860908
Trained batch 121 in epoch 17, gen_loss = 0.40877994137709256, disc_loss = 0.07397155511406724
Trained batch 122 in epoch 17, gen_loss = 0.4092212166728043, disc_loss = 0.07350291892113846
Trained batch 123 in epoch 17, gen_loss = 0.40897070231937593, disc_loss = 0.07331604773794571
Trained batch 124 in epoch 17, gen_loss = 0.4077780346870422, disc_loss = 0.0731320788450539
Trained batch 125 in epoch 17, gen_loss = 0.40799477270671297, disc_loss = 0.07309341048156577
Trained batch 126 in epoch 17, gen_loss = 0.4081400757230173, disc_loss = 0.07293494995023439
Trained batch 127 in epoch 17, gen_loss = 0.4084583502262831, disc_loss = 0.07254396222197101
Trained batch 128 in epoch 17, gen_loss = 0.40818957302921505, disc_loss = 0.07206861548082427
Trained batch 129 in epoch 17, gen_loss = 0.407782513820208, disc_loss = 0.0717343757681262
Trained batch 130 in epoch 17, gen_loss = 0.407730589386161, disc_loss = 0.07135137406938517
Trained batch 131 in epoch 17, gen_loss = 0.4078868650125735, disc_loss = 0.07095992997302815
Trained batch 132 in epoch 17, gen_loss = 0.40802805853965585, disc_loss = 0.07089986784131568
Trained batch 133 in epoch 17, gen_loss = 0.40801859035420773, disc_loss = 0.07071152235270102
Trained batch 134 in epoch 17, gen_loss = 0.40852906593570004, disc_loss = 0.07033734963516947
Trained batch 135 in epoch 17, gen_loss = 0.4083335890489466, disc_loss = 0.06994390245595508
Trained batch 136 in epoch 17, gen_loss = 0.40816302151575573, disc_loss = 0.06958570184838707
Trained batch 137 in epoch 17, gen_loss = 0.40772972893023834, disc_loss = 0.06957202442867709
Trained batch 138 in epoch 17, gen_loss = 0.4080583665439551, disc_loss = 0.0699178444107713
Trained batch 139 in epoch 17, gen_loss = 0.4078271461384637, disc_loss = 0.06950941005655165
Trained batch 140 in epoch 17, gen_loss = 0.407307264441294, disc_loss = 0.0703357964826761
Trained batch 141 in epoch 17, gen_loss = 0.4077874852318159, disc_loss = 0.07053990562079133
Trained batch 142 in epoch 17, gen_loss = 0.40786425362933765, disc_loss = 0.07013085090809247
Trained batch 143 in epoch 17, gen_loss = 0.40759480289287037, disc_loss = 0.06969920582357897
Trained batch 144 in epoch 17, gen_loss = 0.40798715044712197, disc_loss = 0.06948787811822418
Trained batch 145 in epoch 17, gen_loss = 0.40774644850051567, disc_loss = 0.06920768513522838
Trained batch 146 in epoch 17, gen_loss = 0.40859385655850783, disc_loss = 0.06883551413193345
Trained batch 147 in epoch 17, gen_loss = 0.40893391056640727, disc_loss = 0.06848751924416
Trained batch 148 in epoch 17, gen_loss = 0.4090463407087646, disc_loss = 0.06809372948357623
Trained batch 149 in epoch 17, gen_loss = 0.408975426753362, disc_loss = 0.0677499421282361
Trained batch 150 in epoch 17, gen_loss = 0.4088376373644696, disc_loss = 0.06748301021150307
Trained batch 151 in epoch 17, gen_loss = 0.40923122551880386, disc_loss = 0.06723447988042608
Trained batch 152 in epoch 17, gen_loss = 0.4099126290651708, disc_loss = 0.06723085421691435
Trained batch 153 in epoch 17, gen_loss = 0.4093102090931558, disc_loss = 0.06728989631844709
Trained batch 154 in epoch 17, gen_loss = 0.4096636293395873, disc_loss = 0.06708718411804687
Trained batch 155 in epoch 17, gen_loss = 0.40972462105445373, disc_loss = 0.06728666751848486
Trained batch 156 in epoch 17, gen_loss = 0.40988003846946036, disc_loss = 0.0680286442819437
Trained batch 157 in epoch 17, gen_loss = 0.4097241050080408, disc_loss = 0.06791323381829771
Trained batch 158 in epoch 17, gen_loss = 0.4094549889834422, disc_loss = 0.06766584441475805
Trained batch 159 in epoch 17, gen_loss = 0.4095208629965782, disc_loss = 0.06729316403216216
Trained batch 160 in epoch 17, gen_loss = 0.40970177698579635, disc_loss = 0.06704263459972065
Trained batch 161 in epoch 17, gen_loss = 0.40965013058833133, disc_loss = 0.06679284585536355
Trained batch 162 in epoch 17, gen_loss = 0.4094630028206878, disc_loss = 0.06643322671540768
Trained batch 163 in epoch 17, gen_loss = 0.4097094599430154, disc_loss = 0.06609144219390412
Trained batch 164 in epoch 17, gen_loss = 0.4093553864594662, disc_loss = 0.06618487345844959
Trained batch 165 in epoch 17, gen_loss = 0.4090405377637909, disc_loss = 0.0677539505013994
Trained batch 166 in epoch 17, gen_loss = 0.40882263765363636, disc_loss = 0.06780359763261712
Trained batch 167 in epoch 17, gen_loss = 0.4088872442288058, disc_loss = 0.06775635248881631
Trained batch 168 in epoch 17, gen_loss = 0.4084416726637169, disc_loss = 0.06774508982577179
Trained batch 169 in epoch 17, gen_loss = 0.4080138725392959, disc_loss = 0.06745217704104588
Trained batch 170 in epoch 17, gen_loss = 0.4081060746956987, disc_loss = 0.0671458130794964
Trained batch 171 in epoch 17, gen_loss = 0.4079724472276, disc_loss = 0.06692738621766398
Trained batch 172 in epoch 17, gen_loss = 0.4076166521607107, disc_loss = 0.06708993270422596
Trained batch 173 in epoch 17, gen_loss = 0.4077061287973119, disc_loss = 0.06715007801540196
Trained batch 174 in epoch 17, gen_loss = 0.4081436828204564, disc_loss = 0.06707145419237868
Trained batch 175 in epoch 17, gen_loss = 0.4075176180763678, disc_loss = 0.06752032118542543
Trained batch 176 in epoch 17, gen_loss = 0.40788155810981147, disc_loss = 0.06726438579238993
Trained batch 177 in epoch 17, gen_loss = 0.40766085918699757, disc_loss = 0.0677836323654007
Trained batch 178 in epoch 17, gen_loss = 0.4075206033677362, disc_loss = 0.06759254257428829
Trained batch 179 in epoch 17, gen_loss = 0.4074036844902568, disc_loss = 0.06759732139762491
Trained batch 180 in epoch 17, gen_loss = 0.40743289221057577, disc_loss = 0.06742400690161968
Trained batch 181 in epoch 17, gen_loss = 0.40723082226711316, disc_loss = 0.0673326789938773
Trained batch 182 in epoch 17, gen_loss = 0.40643964536854477, disc_loss = 0.06774893148339105
Trained batch 183 in epoch 17, gen_loss = 0.4068953255596368, disc_loss = 0.06840474350610748
Trained batch 184 in epoch 17, gen_loss = 0.4067374427576323, disc_loss = 0.06825739447077786
Trained batch 185 in epoch 17, gen_loss = 0.4065708750358192, disc_loss = 0.06813568359250904
Trained batch 186 in epoch 17, gen_loss = 0.40649907729204965, disc_loss = 0.0679089767723917
Trained batch 187 in epoch 17, gen_loss = 0.4069440209485115, disc_loss = 0.06796405049031005
Trained batch 188 in epoch 17, gen_loss = 0.4066779447926415, disc_loss = 0.06786972811327331
Trained batch 189 in epoch 17, gen_loss = 0.40657911802593033, disc_loss = 0.06768635821920868
Trained batch 190 in epoch 17, gen_loss = 0.4069304906260905, disc_loss = 0.06749568845228297
Trained batch 191 in epoch 17, gen_loss = 0.4074301303674777, disc_loss = 0.0675809636474393
Trained batch 192 in epoch 17, gen_loss = 0.4071558247576106, disc_loss = 0.06740284206133355
Trained batch 193 in epoch 17, gen_loss = 0.4067030877796645, disc_loss = 0.06727354740003873
Trained batch 194 in epoch 17, gen_loss = 0.4065603794195713, disc_loss = 0.06709363938858494
Trained batch 195 in epoch 17, gen_loss = 0.4064832302380581, disc_loss = 0.06706607017466533
Trained batch 196 in epoch 17, gen_loss = 0.4063791803599614, disc_loss = 0.0682115690465922
Trained batch 197 in epoch 17, gen_loss = 0.40680368365061403, disc_loss = 0.06829677991371488
Trained batch 198 in epoch 17, gen_loss = 0.40678513244767883, disc_loss = 0.0681116502221917
Trained batch 199 in epoch 17, gen_loss = 0.4068386670947075, disc_loss = 0.06810863020597026
Trained batch 200 in epoch 17, gen_loss = 0.4072688631157377, disc_loss = 0.06788945185780451
Trained batch 201 in epoch 17, gen_loss = 0.4068603372514838, disc_loss = 0.06769877823189564
Trained batch 202 in epoch 17, gen_loss = 0.40675764086798494, disc_loss = 0.06817931028339884
Trained batch 203 in epoch 17, gen_loss = 0.40649593957498964, disc_loss = 0.068269655654006
Trained batch 204 in epoch 17, gen_loss = 0.40626729508725606, disc_loss = 0.06806825233805107
Trained batch 205 in epoch 17, gen_loss = 0.40719460413872616, disc_loss = 0.06851516072457493
Trained batch 206 in epoch 17, gen_loss = 0.4073487759212365, disc_loss = 0.068251293744208
Trained batch 207 in epoch 17, gen_loss = 0.4066787614272191, disc_loss = 0.06821627289620945
Trained batch 208 in epoch 17, gen_loss = 0.406603589012292, disc_loss = 0.06809000512050313
Trained batch 209 in epoch 17, gen_loss = 0.4067483711810339, disc_loss = 0.06792664215456518
Trained batch 210 in epoch 17, gen_loss = 0.4069282836258694, disc_loss = 0.06785898800206622
Trained batch 211 in epoch 17, gen_loss = 0.4065386953781236, disc_loss = 0.06839144243726963
Trained batch 212 in epoch 17, gen_loss = 0.40688757017744537, disc_loss = 0.06850417091034598
Trained batch 213 in epoch 17, gen_loss = 0.4068534594272899, disc_loss = 0.06843531817397991
Trained batch 214 in epoch 17, gen_loss = 0.406448227305745, disc_loss = 0.06863477326886253
Trained batch 215 in epoch 17, gen_loss = 0.4064428545534611, disc_loss = 0.06842870227087082
Trained batch 216 in epoch 17, gen_loss = 0.40640129334366265, disc_loss = 0.0681995017097808
Trained batch 217 in epoch 17, gen_loss = 0.4062610070366378, disc_loss = 0.06797133894304001
Trained batch 218 in epoch 17, gen_loss = 0.40645470589263255, disc_loss = 0.06777796462884164
Trained batch 219 in epoch 17, gen_loss = 0.4066253441301259, disc_loss = 0.06767653122501956
Trained batch 220 in epoch 17, gen_loss = 0.40658671688709863, disc_loss = 0.06781400865516983
Trained batch 221 in epoch 17, gen_loss = 0.4065633067139634, disc_loss = 0.0677457877774597
Trained batch 222 in epoch 17, gen_loss = 0.4068022378357002, disc_loss = 0.0676890537372452
Trained batch 223 in epoch 17, gen_loss = 0.40679964423179626, disc_loss = 0.06878919745421237
Trained batch 224 in epoch 17, gen_loss = 0.4067108592722151, disc_loss = 0.06899739883633124
Trained batch 225 in epoch 17, gen_loss = 0.40668888891165234, disc_loss = 0.0689088830505951
Trained batch 226 in epoch 17, gen_loss = 0.4064042539323479, disc_loss = 0.0687525776575939
Trained batch 227 in epoch 17, gen_loss = 0.4061337429703328, disc_loss = 0.0686317370252749
Trained batch 228 in epoch 17, gen_loss = 0.4061683752130733, disc_loss = 0.06847260274830799
Trained batch 229 in epoch 17, gen_loss = 0.40610460159571277, disc_loss = 0.0684266546882851
Trained batch 230 in epoch 17, gen_loss = 0.4061164092191886, disc_loss = 0.06846371916167084
Trained batch 231 in epoch 17, gen_loss = 0.40645928012913674, disc_loss = 0.06839994176347129
Trained batch 232 in epoch 17, gen_loss = 0.406594133300331, disc_loss = 0.068214927833975
Trained batch 233 in epoch 17, gen_loss = 0.4065167501441434, disc_loss = 0.06811261507204901
Trained batch 234 in epoch 17, gen_loss = 0.4062204009674965, disc_loss = 0.06799150333402956
Trained batch 235 in epoch 17, gen_loss = 0.4061575734009177, disc_loss = 0.06828138884748884
Trained batch 236 in epoch 17, gen_loss = 0.4058148462309616, disc_loss = 0.06903972903282268
Trained batch 237 in epoch 17, gen_loss = 0.4060261692820477, disc_loss = 0.0695600685166555
Trained batch 238 in epoch 17, gen_loss = 0.40620510386123815, disc_loss = 0.06936923546763332
Trained batch 239 in epoch 17, gen_loss = 0.4059055323402087, disc_loss = 0.06927481142920441
Trained batch 240 in epoch 17, gen_loss = 0.4059610904747025, disc_loss = 0.06922950000305084
Trained batch 241 in epoch 17, gen_loss = 0.4059940340105167, disc_loss = 0.06964515902155871
Trained batch 242 in epoch 17, gen_loss = 0.4056511321430834, disc_loss = 0.0696410185527133
Trained batch 243 in epoch 17, gen_loss = 0.4057532060341757, disc_loss = 0.06950443569135653
Trained batch 244 in epoch 17, gen_loss = 0.40592886124338423, disc_loss = 0.0694395030164445
Trained batch 245 in epoch 17, gen_loss = 0.40580348973351765, disc_loss = 0.06930838232837254
Trained batch 246 in epoch 17, gen_loss = 0.4060404277764834, disc_loss = 0.06912946800403448
Trained batch 247 in epoch 17, gen_loss = 0.40580722917952844, disc_loss = 0.06908285378801426
Trained batch 248 in epoch 17, gen_loss = 0.40564137374062137, disc_loss = 0.06935494092207058
Trained batch 249 in epoch 17, gen_loss = 0.4054699113368988, disc_loss = 0.06981466014496981
Trained batch 250 in epoch 17, gen_loss = 0.4054033311002283, disc_loss = 0.06963796604728972
Trained batch 251 in epoch 17, gen_loss = 0.405379777153333, disc_loss = 0.06983241766861212
Trained batch 252 in epoch 17, gen_loss = 0.40519049763679504, disc_loss = 0.06994450937316057
Trained batch 253 in epoch 17, gen_loss = 0.4051151950293639, disc_loss = 0.06970915017011539
Trained batch 254 in epoch 17, gen_loss = 0.4052429479711196, disc_loss = 0.06948592962478013
Trained batch 255 in epoch 17, gen_loss = 0.40575789101421833, disc_loss = 0.06935451181379904
Trained batch 256 in epoch 17, gen_loss = 0.4054140109960207, disc_loss = 0.06971343292343768
Trained batch 257 in epoch 17, gen_loss = 0.4056596781394278, disc_loss = 0.06980403395939994
Trained batch 258 in epoch 17, gen_loss = 0.40571070914102797, disc_loss = 0.06967475108665677
Trained batch 259 in epoch 17, gen_loss = 0.405917543058212, disc_loss = 0.06970700468473996
Trained batch 260 in epoch 17, gen_loss = 0.4060807161860996, disc_loss = 0.06955276583267868
Trained batch 261 in epoch 17, gen_loss = 0.4058255546420585, disc_loss = 0.06937945861803041
Trained batch 262 in epoch 17, gen_loss = 0.4061367942353165, disc_loss = 0.06915476243100183
Trained batch 263 in epoch 17, gen_loss = 0.40610122161381174, disc_loss = 0.06907596772670689
Trained batch 264 in epoch 17, gen_loss = 0.4060850548294355, disc_loss = 0.06890991124025775
Trained batch 265 in epoch 17, gen_loss = 0.40600266873388363, disc_loss = 0.06870467745684984
Trained batch 266 in epoch 17, gen_loss = 0.40612946668367705, disc_loss = 0.06883951048244642
Trained batch 267 in epoch 17, gen_loss = 0.40605660294418905, disc_loss = 0.06911589230806914
Trained batch 268 in epoch 17, gen_loss = 0.40624831777522996, disc_loss = 0.0689741250276427
Trained batch 269 in epoch 17, gen_loss = 0.4058811531022743, disc_loss = 0.06875594381622419
Trained batch 270 in epoch 17, gen_loss = 0.40597121631967187, disc_loss = 0.06863496193277385
Trained batch 271 in epoch 17, gen_loss = 0.40564522771712613, disc_loss = 0.0687234011831392
Trained batch 272 in epoch 17, gen_loss = 0.40567848217356334, disc_loss = 0.06862833268169463
Trained batch 273 in epoch 17, gen_loss = 0.4055503440381837, disc_loss = 0.06848828588190903
Trained batch 274 in epoch 17, gen_loss = 0.4054675251787359, disc_loss = 0.06856366684321653
Trained batch 275 in epoch 17, gen_loss = 0.4056475748834403, disc_loss = 0.06837323884162512
Trained batch 276 in epoch 17, gen_loss = 0.4059017265101202, disc_loss = 0.06836670382782171
Trained batch 277 in epoch 17, gen_loss = 0.4054030407246926, disc_loss = 0.06841659930320255
Trained batch 278 in epoch 17, gen_loss = 0.40514223870410715, disc_loss = 0.06829055812456862
Trained batch 279 in epoch 17, gen_loss = 0.4050110014421599, disc_loss = 0.06830862355917426
Trained batch 280 in epoch 17, gen_loss = 0.4052105380547004, disc_loss = 0.06814591489646094
Trained batch 281 in epoch 17, gen_loss = 0.40491924936889756, disc_loss = 0.06820533903982781
Trained batch 282 in epoch 17, gen_loss = 0.4052435085967236, disc_loss = 0.06838780295189352
Trained batch 283 in epoch 17, gen_loss = 0.4051268442835606, disc_loss = 0.0682366473951154
Trained batch 284 in epoch 17, gen_loss = 0.4050379399667706, disc_loss = 0.06815777037848245
Trained batch 285 in epoch 17, gen_loss = 0.4050408603844943, disc_loss = 0.06830493156094808
Trained batch 286 in epoch 17, gen_loss = 0.40488048463748305, disc_loss = 0.06873521524017437
Trained batch 287 in epoch 17, gen_loss = 0.4052518817285697, disc_loss = 0.06870974825223028
Trained batch 288 in epoch 17, gen_loss = 0.4055937497673563, disc_loss = 0.06855569668855377
Trained batch 289 in epoch 17, gen_loss = 0.40554557391281787, disc_loss = 0.06835511437424555
Trained batch 290 in epoch 17, gen_loss = 0.40528011864812924, disc_loss = 0.06839005249837266
Trained batch 291 in epoch 17, gen_loss = 0.405325919287662, disc_loss = 0.06837307866056744
Trained batch 292 in epoch 17, gen_loss = 0.4053182446305662, disc_loss = 0.06826977579418964
Trained batch 293 in epoch 17, gen_loss = 0.40534142430136805, disc_loss = 0.06842015845998868
Trained batch 294 in epoch 17, gen_loss = 0.4052951911748466, disc_loss = 0.06824411482281857
Trained batch 295 in epoch 17, gen_loss = 0.4053001218550914, disc_loss = 0.06872849201789831
Trained batch 296 in epoch 17, gen_loss = 0.40527735354523065, disc_loss = 0.06865568151885662
Trained batch 297 in epoch 17, gen_loss = 0.4052842050390756, disc_loss = 0.0685423382717316
Trained batch 298 in epoch 17, gen_loss = 0.4052764200247251, disc_loss = 0.06844220703069033
Trained batch 299 in epoch 17, gen_loss = 0.4052468344569206, disc_loss = 0.06838289195206017
Trained batch 300 in epoch 17, gen_loss = 0.40493000434878657, disc_loss = 0.068524341809059
Trained batch 301 in epoch 17, gen_loss = 0.40495113673194355, disc_loss = 0.06879939761981121
Trained batch 302 in epoch 17, gen_loss = 0.4046375574451862, disc_loss = 0.06864420802366271
Trained batch 303 in epoch 17, gen_loss = 0.4043878193356489, disc_loss = 0.06859510963764287
Trained batch 304 in epoch 17, gen_loss = 0.40403901651257373, disc_loss = 0.06888283000892548
Trained batch 305 in epoch 17, gen_loss = 0.40408162081163695, disc_loss = 0.06872887498078246
Trained batch 306 in epoch 17, gen_loss = 0.40376286184360616, disc_loss = 0.06894094516532283
Trained batch 307 in epoch 17, gen_loss = 0.40403736527864037, disc_loss = 0.0692265937724695
Trained batch 308 in epoch 17, gen_loss = 0.4037945192415737, disc_loss = 0.06906379672659495
Trained batch 309 in epoch 17, gen_loss = 0.4033376487993425, disc_loss = 0.06922056612618749
Trained batch 310 in epoch 17, gen_loss = 0.4034368337350643, disc_loss = 0.06911137624766522
Trained batch 311 in epoch 17, gen_loss = 0.40350932284043384, disc_loss = 0.06906691844461676
Trained batch 312 in epoch 17, gen_loss = 0.4034690856933594, disc_loss = 0.0689759414312772
Trained batch 313 in epoch 17, gen_loss = 0.4035205225086516, disc_loss = 0.06882724053356915
Trained batch 314 in epoch 17, gen_loss = 0.40344163482151335, disc_loss = 0.06867120899407873
Trained batch 315 in epoch 17, gen_loss = 0.40310646989677523, disc_loss = 0.06856434855498138
Trained batch 316 in epoch 17, gen_loss = 0.4028697321279568, disc_loss = 0.06842523611852847
Trained batch 317 in epoch 17, gen_loss = 0.4029517095981154, disc_loss = 0.06825346832233921
Trained batch 318 in epoch 17, gen_loss = 0.4029436302969822, disc_loss = 0.0681320761890971
Trained batch 319 in epoch 17, gen_loss = 0.40295315273106097, disc_loss = 0.06796126241533784
Trained batch 320 in epoch 17, gen_loss = 0.40277740498569525, disc_loss = 0.06781325057421657
Trained batch 321 in epoch 17, gen_loss = 0.4025080327106559, disc_loss = 0.06815735808203448
Trained batch 322 in epoch 17, gen_loss = 0.4027226246178335, disc_loss = 0.06837440111267816
Trained batch 323 in epoch 17, gen_loss = 0.4027721720897121, disc_loss = 0.06825244550759915
Trained batch 324 in epoch 17, gen_loss = 0.4027510350484114, disc_loss = 0.0681762003655044
Trained batch 325 in epoch 17, gen_loss = 0.40269758593451027, disc_loss = 0.0680587870323105
Trained batch 326 in epoch 17, gen_loss = 0.40282800629598287, disc_loss = 0.06791603827097137
Trained batch 327 in epoch 17, gen_loss = 0.40255174840368874, disc_loss = 0.0678800460754712
Trained batch 328 in epoch 17, gen_loss = 0.40249295428531146, disc_loss = 0.06783939458537383
Trained batch 329 in epoch 17, gen_loss = 0.4024090360511433, disc_loss = 0.06770845154215667
Trained batch 330 in epoch 17, gen_loss = 0.4026835012471928, disc_loss = 0.06762667032228811
Trained batch 331 in epoch 17, gen_loss = 0.40290343806327106, disc_loss = 0.06746284535059324
Trained batch 332 in epoch 17, gen_loss = 0.4028233945727706, disc_loss = 0.06733760543519983
Trained batch 333 in epoch 17, gen_loss = 0.40276922062485515, disc_loss = 0.06725818767981927
Trained batch 334 in epoch 17, gen_loss = 0.40267969485539107, disc_loss = 0.06746612103767137
Trained batch 335 in epoch 17, gen_loss = 0.40255923267631305, disc_loss = 0.06804991630321768
Trained batch 336 in epoch 17, gen_loss = 0.4024492832956399, disc_loss = 0.06791272524396062
Trained batch 337 in epoch 17, gen_loss = 0.4026349569566151, disc_loss = 0.06778594996289697
Trained batch 338 in epoch 17, gen_loss = 0.40253415281793714, disc_loss = 0.0676570540022072
Trained batch 339 in epoch 17, gen_loss = 0.40242033556980245, disc_loss = 0.06751014993334299
Trained batch 340 in epoch 17, gen_loss = 0.40238599168939676, disc_loss = 0.06744013281943292
Trained batch 341 in epoch 17, gen_loss = 0.40217098175433647, disc_loss = 0.06728592143688154
Trained batch 342 in epoch 17, gen_loss = 0.40221841359625055, disc_loss = 0.06742969908108039
Trained batch 343 in epoch 17, gen_loss = 0.4019817761037239, disc_loss = 0.0674363941422577
Trained batch 344 in epoch 17, gen_loss = 0.4018977934035702, disc_loss = 0.06734951658012427
Trained batch 345 in epoch 17, gen_loss = 0.40202065079198407, disc_loss = 0.06724976255246196
Trained batch 346 in epoch 17, gen_loss = 0.40218918837113066, disc_loss = 0.06713007208663078
Trained batch 347 in epoch 17, gen_loss = 0.40195503736706983, disc_loss = 0.06699858838826118
Trained batch 348 in epoch 17, gen_loss = 0.40184301163542235, disc_loss = 0.06690453273246871
Trained batch 349 in epoch 17, gen_loss = 0.4020540395804814, disc_loss = 0.06675991828553379
Trained batch 350 in epoch 17, gen_loss = 0.402226677986971, disc_loss = 0.06660925671909312
Trained batch 351 in epoch 17, gen_loss = 0.40213253552263434, disc_loss = 0.06646800542975226
Trained batch 352 in epoch 17, gen_loss = 0.4019094080830431, disc_loss = 0.06670741633599143
Trained batch 353 in epoch 17, gen_loss = 0.40208163941647374, disc_loss = 0.06699437376685272
Trained batch 354 in epoch 17, gen_loss = 0.40224363644358135, disc_loss = 0.06683645999373894
Trained batch 355 in epoch 17, gen_loss = 0.402302723587229, disc_loss = 0.06668160173105432
Trained batch 356 in epoch 17, gen_loss = 0.4023952101792942, disc_loss = 0.06655163935278686
Trained batch 357 in epoch 17, gen_loss = 0.4022375901318129, disc_loss = 0.06640410228299404
Trained batch 358 in epoch 17, gen_loss = 0.4021492843674418, disc_loss = 0.0662634320321044
Trained batch 359 in epoch 17, gen_loss = 0.4019455091820823, disc_loss = 0.06613123627612368
Trained batch 360 in epoch 17, gen_loss = 0.4019707440504407, disc_loss = 0.06598462441605915
Trained batch 361 in epoch 17, gen_loss = 0.40194737672476477, disc_loss = 0.06583674295898012
Trained batch 362 in epoch 17, gen_loss = 0.40179156468919486, disc_loss = 0.0656904215442104
Trained batch 363 in epoch 17, gen_loss = 0.4017053117136379, disc_loss = 0.06565356487024493
Trained batch 364 in epoch 17, gen_loss = 0.4017735891962705, disc_loss = 0.06551687398619235
Trained batch 365 in epoch 17, gen_loss = 0.40171506952066893, disc_loss = 0.06541000251770224
Trained batch 366 in epoch 17, gen_loss = 0.4015981257773875, disc_loss = 0.06545848080797034
Trained batch 367 in epoch 17, gen_loss = 0.4018396178017492, disc_loss = 0.06550703396256406
Trained batch 368 in epoch 17, gen_loss = 0.40182500463837206, disc_loss = 0.06541740728875364
Trained batch 369 in epoch 17, gen_loss = 0.4019456146536647, disc_loss = 0.06547478812092261
Trained batch 370 in epoch 17, gen_loss = 0.402318632506296, disc_loss = 0.0660110416048962
Trained batch 371 in epoch 17, gen_loss = 0.4023022416939018, disc_loss = 0.06595303294604384
Trained batch 372 in epoch 17, gen_loss = 0.40238894981609274, disc_loss = 0.06581567353057119
Trained batch 373 in epoch 17, gen_loss = 0.40243466118759014, disc_loss = 0.06566931901594256
Trained batch 374 in epoch 17, gen_loss = 0.4024081430435181, disc_loss = 0.06552958128477136
Trained batch 375 in epoch 17, gen_loss = 0.40229231459980314, disc_loss = 0.06550868346598594
Trained batch 376 in epoch 17, gen_loss = 0.40225181963778933, disc_loss = 0.06602401623937156
Trained batch 377 in epoch 17, gen_loss = 0.40209027706946016, disc_loss = 0.06689339134689401
Trained batch 378 in epoch 17, gen_loss = 0.4021367063465722, disc_loss = 0.06716317488470343
Trained batch 379 in epoch 17, gen_loss = 0.40202772782037133, disc_loss = 0.06745067101192513
Trained batch 380 in epoch 17, gen_loss = 0.40205369260054563, disc_loss = 0.06768107327835493
Trained batch 381 in epoch 17, gen_loss = 0.4019735609205605, disc_loss = 0.06798616792465419
Trained batch 382 in epoch 17, gen_loss = 0.4019308841882113, disc_loss = 0.06814132432037522
Trained batch 383 in epoch 17, gen_loss = 0.4018742626843353, disc_loss = 0.06818543909685104
Trained batch 384 in epoch 17, gen_loss = 0.4019588547867614, disc_loss = 0.06813421315791739
Trained batch 385 in epoch 17, gen_loss = 0.40178015990269617, disc_loss = 0.06807851035345751
Trained batch 386 in epoch 17, gen_loss = 0.40169900725054186, disc_loss = 0.06808886550564212
Trained batch 387 in epoch 17, gen_loss = 0.4013956850490619, disc_loss = 0.06829587729844581
Trained batch 388 in epoch 17, gen_loss = 0.40125759087675333, disc_loss = 0.0688177704066517
Trained batch 389 in epoch 17, gen_loss = 0.4012634644141564, disc_loss = 0.06888431918759567
Trained batch 390 in epoch 17, gen_loss = 0.40123613060587815, disc_loss = 0.06874770914678417
Trained batch 391 in epoch 17, gen_loss = 0.40143601535534373, disc_loss = 0.06864239634323523
Trained batch 392 in epoch 17, gen_loss = 0.40149598358241656, disc_loss = 0.06856596085619722
Trained batch 393 in epoch 17, gen_loss = 0.40113780900911633, disc_loss = 0.06873524267117724
Trained batch 394 in epoch 17, gen_loss = 0.4012844632698011, disc_loss = 0.06896440000685898
Trained batch 395 in epoch 17, gen_loss = 0.4012126909060912, disc_loss = 0.06886581463311243
Trained batch 396 in epoch 17, gen_loss = 0.4008592094672417, disc_loss = 0.06890071054066646
Trained batch 397 in epoch 17, gen_loss = 0.40080530911534273, disc_loss = 0.0691525924157576
Trained batch 398 in epoch 17, gen_loss = 0.40089087535564166, disc_loss = 0.06908798916265368
Trained batch 399 in epoch 17, gen_loss = 0.400567876547575, disc_loss = 0.06922974202898331
Trained batch 400 in epoch 17, gen_loss = 0.40079749893963784, disc_loss = 0.06929679148182497
Trained batch 401 in epoch 17, gen_loss = 0.40081312985562567, disc_loss = 0.06916951012464045
Trained batch 402 in epoch 17, gen_loss = 0.4008935268404466, disc_loss = 0.06921084691647893
Trained batch 403 in epoch 17, gen_loss = 0.40101340472108066, disc_loss = 0.06909230825984573
Trained batch 404 in epoch 17, gen_loss = 0.4010416403228854, disc_loss = 0.06903367782655505
Trained batch 405 in epoch 17, gen_loss = 0.40079242739771387, disc_loss = 0.06910607821234671
Trained batch 406 in epoch 17, gen_loss = 0.40104502468788655, disc_loss = 0.06910482133768445
Trained batch 407 in epoch 17, gen_loss = 0.40122854826497095, disc_loss = 0.06905176901080481
Trained batch 408 in epoch 17, gen_loss = 0.40134465818300225, disc_loss = 0.06904602423879548
Trained batch 409 in epoch 17, gen_loss = 0.40130408086427827, disc_loss = 0.0692751950391273
Trained batch 410 in epoch 17, gen_loss = 0.40143955196197306, disc_loss = 0.06924092613382678
Trained batch 411 in epoch 17, gen_loss = 0.40160217338684695, disc_loss = 0.06914020643130994
Trained batch 412 in epoch 17, gen_loss = 0.40164855165862573, disc_loss = 0.06908340882577597
Trained batch 413 in epoch 17, gen_loss = 0.40165979159626986, disc_loss = 0.06917822228380195
Trained batch 414 in epoch 17, gen_loss = 0.40169608262648065, disc_loss = 0.0694059911677726
Trained batch 415 in epoch 17, gen_loss = 0.40161945355626255, disc_loss = 0.06930772781197447
Trained batch 416 in epoch 17, gen_loss = 0.40145390554011867, disc_loss = 0.06920829575343562
Trained batch 417 in epoch 17, gen_loss = 0.4013872905211015, disc_loss = 0.06916795889445933
Trained batch 418 in epoch 17, gen_loss = 0.4013703412827558, disc_loss = 0.06912087488292687
Trained batch 419 in epoch 17, gen_loss = 0.4013237863779068, disc_loss = 0.0691873471751543
Trained batch 420 in epoch 17, gen_loss = 0.4014568513617663, disc_loss = 0.06932808604918757
Trained batch 421 in epoch 17, gen_loss = 0.4013172484828398, disc_loss = 0.06926541763216575
Trained batch 422 in epoch 17, gen_loss = 0.40117134840775887, disc_loss = 0.0691668139363311
Trained batch 423 in epoch 17, gen_loss = 0.4010881559466416, disc_loss = 0.06904398688699452
Trained batch 424 in epoch 17, gen_loss = 0.4008996647245744, disc_loss = 0.068913131830666
Trained batch 425 in epoch 17, gen_loss = 0.40102375428161713, disc_loss = 0.06879686359687766
Trained batch 426 in epoch 17, gen_loss = 0.40087488928779225, disc_loss = 0.06879687677541053
Trained batch 427 in epoch 17, gen_loss = 0.40108433790574566, disc_loss = 0.06870611135686844
Trained batch 428 in epoch 17, gen_loss = 0.40116513706309537, disc_loss = 0.06861039857751319
Trained batch 429 in epoch 17, gen_loss = 0.4010153482819712, disc_loss = 0.06847620084123729
Trained batch 430 in epoch 17, gen_loss = 0.40093400631869197, disc_loss = 0.06845906888633932
Trained batch 431 in epoch 17, gen_loss = 0.40075041608953915, disc_loss = 0.06839982897185513
Trained batch 432 in epoch 17, gen_loss = 0.4006359103645519, disc_loss = 0.06831862768975644
Trained batch 433 in epoch 17, gen_loss = 0.4006962796784766, disc_loss = 0.06842687880633236
Trained batch 434 in epoch 17, gen_loss = 0.40053764574829187, disc_loss = 0.06882018388794928
Trained batch 435 in epoch 17, gen_loss = 0.4006151201528147, disc_loss = 0.06873663229581584
Trained batch 436 in epoch 17, gen_loss = 0.4007792116848228, disc_loss = 0.06866605672878756
Trained batch 437 in epoch 17, gen_loss = 0.400903275296024, disc_loss = 0.06857108655725883
Trained batch 438 in epoch 17, gen_loss = 0.40077898272892337, disc_loss = 0.06853606348331161
Trained batch 439 in epoch 17, gen_loss = 0.40070241472937845, disc_loss = 0.06876392853975466
Trained batch 440 in epoch 17, gen_loss = 0.40074321404606306, disc_loss = 0.06868996422277455
Trained batch 441 in epoch 17, gen_loss = 0.4007215571349563, disc_loss = 0.06860662524048998
Trained batch 442 in epoch 17, gen_loss = 0.40071744312012975, disc_loss = 0.06849095301542843
Trained batch 443 in epoch 17, gen_loss = 0.40078586541317607, disc_loss = 0.06837800318094155
Trained batch 444 in epoch 17, gen_loss = 0.40107862440387854, disc_loss = 0.06829698234064023
Trained batch 445 in epoch 17, gen_loss = 0.40098343194867464, disc_loss = 0.06820644440876963
Trained batch 446 in epoch 17, gen_loss = 0.40111441780256746, disc_loss = 0.06811864727949703
Trained batch 447 in epoch 17, gen_loss = 0.4010202874695616, disc_loss = 0.06804897778056329
Trained batch 448 in epoch 17, gen_loss = 0.4010021728370131, disc_loss = 0.06797894850095323
Trained batch 449 in epoch 17, gen_loss = 0.4008999172184202, disc_loss = 0.0681822764676892
Trained batch 450 in epoch 17, gen_loss = 0.4009268045293254, disc_loss = 0.06818875407453155
Trained batch 451 in epoch 17, gen_loss = 0.40116907240806426, disc_loss = 0.0681458313102562
Trained batch 452 in epoch 17, gen_loss = 0.40099630582148404, disc_loss = 0.06841539807523093
Trained batch 453 in epoch 17, gen_loss = 0.4010362657287572, disc_loss = 0.0685143036909385
Trained batch 454 in epoch 17, gen_loss = 0.4009068407200195, disc_loss = 0.06846700299756377
Trained batch 455 in epoch 17, gen_loss = 0.40084739722180784, disc_loss = 0.06834608307128706
Trained batch 456 in epoch 17, gen_loss = 0.40094581442014915, disc_loss = 0.06822225208856834
Trained batch 457 in epoch 17, gen_loss = 0.4010403870755408, disc_loss = 0.06811034940813535
Trained batch 458 in epoch 17, gen_loss = 0.40149345623901467, disc_loss = 0.06832256362406225
Testing Epoch 17
Training Epoch 18
Trained batch 0 in epoch 18, gen_loss = 0.29904288053512573, disc_loss = 0.2276277095079422
Trained batch 1 in epoch 18, gen_loss = 0.3320406675338745, disc_loss = 0.15545016154646873
Trained batch 2 in epoch 18, gen_loss = 0.37470194697380066, disc_loss = 0.1106756863494714
Trained batch 3 in epoch 18, gen_loss = 0.3952530473470688, disc_loss = 0.08678818657062948
Trained batch 4 in epoch 18, gen_loss = 0.3933890700340271, disc_loss = 0.07109503094106913
Trained batch 5 in epoch 18, gen_loss = 0.3846946954727173, disc_loss = 0.06546341332917412
Trained batch 6 in epoch 18, gen_loss = 0.3951766107763563, disc_loss = 0.06585181783884764
Trained batch 7 in epoch 18, gen_loss = 0.4031471312046051, disc_loss = 0.06187981285620481
Trained batch 8 in epoch 18, gen_loss = 0.39978088272942436, disc_loss = 0.056610505717496075
Trained batch 9 in epoch 18, gen_loss = 0.40103861391544343, disc_loss = 0.05547467181459069
Trained batch 10 in epoch 18, gen_loss = 0.39603385058316315, disc_loss = 0.06270723053338853
Trained batch 11 in epoch 18, gen_loss = 0.4039485106865565, disc_loss = 0.06747416228366394
Trained batch 12 in epoch 18, gen_loss = 0.40745405967418963, disc_loss = 0.06410309478927118
Trained batch 13 in epoch 18, gen_loss = 0.4045148513146809, disc_loss = 0.06182822671585849
Trained batch 14 in epoch 18, gen_loss = 0.40815261205037434, disc_loss = 0.05928871128708124
Trained batch 15 in epoch 18, gen_loss = 0.41168640926480293, disc_loss = 0.058131040481384844
Trained batch 16 in epoch 18, gen_loss = 0.41389161173035116, disc_loss = 0.05732758337741389
Trained batch 17 in epoch 18, gen_loss = 0.41036418908172184, disc_loss = 0.05478340739177333
Trained batch 18 in epoch 18, gen_loss = 0.40559381873984085, disc_loss = 0.06425675926239867
Trained batch 19 in epoch 18, gen_loss = 0.412952846288681, disc_loss = 0.08626219350844622
Trained batch 20 in epoch 18, gen_loss = 0.41399291299638297, disc_loss = 0.08497074459280286
Trained batch 21 in epoch 18, gen_loss = 0.4099489558826793, disc_loss = 0.08369736559689045
Trained batch 22 in epoch 18, gen_loss = 0.40805733981339826, disc_loss = 0.08248609110065129
Trained batch 23 in epoch 18, gen_loss = 0.40785493950049084, disc_loss = 0.07986226483869056
Trained batch 24 in epoch 18, gen_loss = 0.40736328840255737, disc_loss = 0.07874627344310284
Trained batch 25 in epoch 18, gen_loss = 0.4061895448427934, disc_loss = 0.07700269074680713
Trained batch 26 in epoch 18, gen_loss = 0.4071498215198517, disc_loss = 0.0753247233590594
Trained batch 27 in epoch 18, gen_loss = 0.40887520568711416, disc_loss = 0.07289922317223889
Trained batch 28 in epoch 18, gen_loss = 0.41029634044088165, disc_loss = 0.07172299895820947
Trained batch 29 in epoch 18, gen_loss = 0.4082252244154612, disc_loss = 0.07023244431863228
Trained batch 30 in epoch 18, gen_loss = 0.4073855463535555, disc_loss = 0.07567408662890235
Trained batch 31 in epoch 18, gen_loss = 0.40830743592232466, disc_loss = 0.07886625436367467
Trained batch 32 in epoch 18, gen_loss = 0.41150679100643506, disc_loss = 0.07688903673128648
Trained batch 33 in epoch 18, gen_loss = 0.4105434926117168, disc_loss = 0.07544057684786179
Trained batch 34 in epoch 18, gen_loss = 0.4084104870046888, disc_loss = 0.07428321412631443
Trained batch 35 in epoch 18, gen_loss = 0.4076905623078346, disc_loss = 0.0728595686248607
Trained batch 36 in epoch 18, gen_loss = 0.4078080066152521, disc_loss = 0.07248028820833645
Trained batch 37 in epoch 18, gen_loss = 0.4050144357116599, disc_loss = 0.07350234540277406
Trained batch 38 in epoch 18, gen_loss = 0.40649601969963467, disc_loss = 0.07219930838506955
Trained batch 39 in epoch 18, gen_loss = 0.40612833946943283, disc_loss = 0.07074471157975495
Trained batch 40 in epoch 18, gen_loss = 0.405400069748483, disc_loss = 0.06925971624327869
Trained batch 41 in epoch 18, gen_loss = 0.40393132751896266, disc_loss = 0.06993984750338963
Trained batch 42 in epoch 18, gen_loss = 0.4047503110974334, disc_loss = 0.06953377328639807
Trained batch 43 in epoch 18, gen_loss = 0.4040184352885593, disc_loss = 0.06821049823933704
Trained batch 44 in epoch 18, gen_loss = 0.4040629247824351, disc_loss = 0.06713426529119412
Trained batch 45 in epoch 18, gen_loss = 0.403320897532546, disc_loss = 0.06591467006617914
Trained batch 46 in epoch 18, gen_loss = 0.40357666129761555, disc_loss = 0.06519279270333812
Trained batch 47 in epoch 18, gen_loss = 0.402589854473869, disc_loss = 0.06589741172501817
Trained batch 48 in epoch 18, gen_loss = 0.40230600566280134, disc_loss = 0.06785924525513333
Trained batch 49 in epoch 18, gen_loss = 0.4017210829257965, disc_loss = 0.06723159736022354
Trained batch 50 in epoch 18, gen_loss = 0.4013257949959998, disc_loss = 0.06726118562487411
Trained batch 51 in epoch 18, gen_loss = 0.40131864754053265, disc_loss = 0.0661149396507356
Trained batch 52 in epoch 18, gen_loss = 0.4012200135105061, disc_loss = 0.06554206422934274
Trained batch 53 in epoch 18, gen_loss = 0.40267029625398143, disc_loss = 0.06449636897175676
Trained batch 54 in epoch 18, gen_loss = 0.4022603452205658, disc_loss = 0.06349107623946938
Trained batch 55 in epoch 18, gen_loss = 0.4007754160889557, disc_loss = 0.0626586955123847
Trained batch 56 in epoch 18, gen_loss = 0.40181911566801237, disc_loss = 0.06173727560886427
Trained batch 57 in epoch 18, gen_loss = 0.40240556875179556, disc_loss = 0.0610145603162076
Trained batch 58 in epoch 18, gen_loss = 0.4028129900916148, disc_loss = 0.060655732568100855
Trained batch 59 in epoch 18, gen_loss = 0.4030425697565079, disc_loss = 0.06039482483174652
Trained batch 60 in epoch 18, gen_loss = 0.4011519404708362, disc_loss = 0.05972731886736927
Trained batch 61 in epoch 18, gen_loss = 0.400017513863502, disc_loss = 0.060429112482515555
Trained batch 62 in epoch 18, gen_loss = 0.3988571053459531, disc_loss = 0.06034096842631698
Trained batch 63 in epoch 18, gen_loss = 0.3986146254464984, disc_loss = 0.05958522298169555
Trained batch 64 in epoch 18, gen_loss = 0.3976316296137296, disc_loss = 0.059045681851701094
Trained batch 65 in epoch 18, gen_loss = 0.3990386412902312, disc_loss = 0.05969217084489311
Trained batch 66 in epoch 18, gen_loss = 0.39876165941580016, disc_loss = 0.06173706035922045
Trained batch 67 in epoch 18, gen_loss = 0.4002781817141701, disc_loss = 0.06178632995579392
Trained batch 68 in epoch 18, gen_loss = 0.4005037321560625, disc_loss = 0.061774518212600465
Trained batch 69 in epoch 18, gen_loss = 0.4015642694064549, disc_loss = 0.061781749481867466
Trained batch 70 in epoch 18, gen_loss = 0.4022766737870767, disc_loss = 0.061162857555220246
Trained batch 71 in epoch 18, gen_loss = 0.40192629396915436, disc_loss = 0.06084384327469808
Trained batch 72 in epoch 18, gen_loss = 0.402168334755179, disc_loss = 0.06036811409365028
Trained batch 73 in epoch 18, gen_loss = 0.40232897006176616, disc_loss = 0.05975478359598767
Trained batch 74 in epoch 18, gen_loss = 0.40262097358703614, disc_loss = 0.05979760404055317
Trained batch 75 in epoch 18, gen_loss = 0.4011911157714693, disc_loss = 0.06036650306716757
Trained batch 76 in epoch 18, gen_loss = 0.40170540051026776, disc_loss = 0.060003489503854666
Trained batch 77 in epoch 18, gen_loss = 0.40188055084301877, disc_loss = 0.060274461576810635
Trained batch 78 in epoch 18, gen_loss = 0.4023463201673725, disc_loss = 0.06055816126798716
Trained batch 79 in epoch 18, gen_loss = 0.40091443844139574, disc_loss = 0.06302414597594179
Trained batch 80 in epoch 18, gen_loss = 0.40088923772176105, disc_loss = 0.06295435448510596
Trained batch 81 in epoch 18, gen_loss = 0.40142864933828026, disc_loss = 0.06305315814026427
Trained batch 82 in epoch 18, gen_loss = 0.40151404652250816, disc_loss = 0.06305676299786891
Trained batch 83 in epoch 18, gen_loss = 0.40224199138936545, disc_loss = 0.06304632052446582
Trained batch 84 in epoch 18, gen_loss = 0.4017964661121368, disc_loss = 0.06326103346860584
Trained batch 85 in epoch 18, gen_loss = 0.40117958985095803, disc_loss = 0.06276422018336869
Trained batch 86 in epoch 18, gen_loss = 0.40096193963083726, disc_loss = 0.06223148409940902
Trained batch 87 in epoch 18, gen_loss = 0.40080987695943227, disc_loss = 0.06258334509964864
Trained batch 88 in epoch 18, gen_loss = 0.40119063653302994, disc_loss = 0.06198129578483071
Trained batch 89 in epoch 18, gen_loss = 0.4002543565299776, disc_loss = 0.061972389220156604
Trained batch 90 in epoch 18, gen_loss = 0.40100910015158603, disc_loss = 0.06514464917971374
Trained batch 91 in epoch 18, gen_loss = 0.40058248328125995, disc_loss = 0.06687817975129608
Trained batch 92 in epoch 18, gen_loss = 0.40217557004702986, disc_loss = 0.066819365481816
Trained batch 93 in epoch 18, gen_loss = 0.4027254768508546, disc_loss = 0.06639188053978091
Trained batch 94 in epoch 18, gen_loss = 0.40320270626168503, disc_loss = 0.06593144049279784
Trained batch 95 in epoch 18, gen_loss = 0.40310499848177034, disc_loss = 0.06558065053832252
Trained batch 96 in epoch 18, gen_loss = 0.4031328712542033, disc_loss = 0.06515171057688668
Trained batch 97 in epoch 18, gen_loss = 0.40377597419583067, disc_loss = 0.06507887878949392
Trained batch 98 in epoch 18, gen_loss = 0.4037542364211998, disc_loss = 0.06467530463888037
Trained batch 99 in epoch 18, gen_loss = 0.4034916001558304, disc_loss = 0.06434798413421959
Trained batch 100 in epoch 18, gen_loss = 0.4036008544487528, disc_loss = 0.06432488503045228
Trained batch 101 in epoch 18, gen_loss = 0.40528855312104317, disc_loss = 0.0641959430238999
Trained batch 102 in epoch 18, gen_loss = 0.4053867676304382, disc_loss = 0.06426468861822798
Trained batch 103 in epoch 18, gen_loss = 0.40573237005334634, disc_loss = 0.06480298020715754
Trained batch 104 in epoch 18, gen_loss = 0.40558386473428637, disc_loss = 0.06564020217795458
Trained batch 105 in epoch 18, gen_loss = 0.4053910866660892, disc_loss = 0.06522595537562836
Trained batch 106 in epoch 18, gen_loss = 0.40559432384009675, disc_loss = 0.06470257236630977
Trained batch 107 in epoch 18, gen_loss = 0.40596338444285923, disc_loss = 0.0643596483213413
Trained batch 108 in epoch 18, gen_loss = 0.4059298492352897, disc_loss = 0.06500890505406151
Trained batch 109 in epoch 18, gen_loss = 0.4060981820930134, disc_loss = 0.0663478861774572
Trained batch 110 in epoch 18, gen_loss = 0.40566528917432904, disc_loss = 0.06630044779111002
Trained batch 111 in epoch 18, gen_loss = 0.40538734729800907, disc_loss = 0.06584026812925003
Trained batch 112 in epoch 18, gen_loss = 0.4048308176276958, disc_loss = 0.06544003713529854
Trained batch 113 in epoch 18, gen_loss = 0.4048284754941338, disc_loss = 0.06512869556695876
Trained batch 114 in epoch 18, gen_loss = 0.4041978999324467, disc_loss = 0.06516226182246337
Trained batch 115 in epoch 18, gen_loss = 0.40353227637965106, disc_loss = 0.06526631388636626
Trained batch 116 in epoch 18, gen_loss = 0.4033913556327168, disc_loss = 0.06484177700267771
Trained batch 117 in epoch 18, gen_loss = 0.40306298535759166, disc_loss = 0.06473880606482468
Trained batch 118 in epoch 18, gen_loss = 0.402824811324352, disc_loss = 0.06440744050895843
Trained batch 119 in epoch 18, gen_loss = 0.40333638762434326, disc_loss = 0.06433240267991398
Trained batch 120 in epoch 18, gen_loss = 0.4036195177184649, disc_loss = 0.06427536516504223
Trained batch 121 in epoch 18, gen_loss = 0.4034024936253907, disc_loss = 0.06401627418798868
Trained batch 122 in epoch 18, gen_loss = 0.403944277181858, disc_loss = 0.06375259387768745
Trained batch 123 in epoch 18, gen_loss = 0.404204283510485, disc_loss = 0.0635863930970851
Trained batch 124 in epoch 18, gen_loss = 0.4040987737178802, disc_loss = 0.06357460936531424
Trained batch 125 in epoch 18, gen_loss = 0.40425395658091895, disc_loss = 0.06313445770536505
Trained batch 126 in epoch 18, gen_loss = 0.40448589845905153, disc_loss = 0.06269158547245494
Trained batch 127 in epoch 18, gen_loss = 0.4043393158353865, disc_loss = 0.06247118573446642
Trained batch 128 in epoch 18, gen_loss = 0.40455241166343986, disc_loss = 0.06215344722808678
Trained batch 129 in epoch 18, gen_loss = 0.40393126950814173, disc_loss = 0.062034066376061396
Trained batch 130 in epoch 18, gen_loss = 0.4038349101106629, disc_loss = 0.06263475883254455
Trained batch 131 in epoch 18, gen_loss = 0.402834568511356, disc_loss = 0.06359505360931948
Trained batch 132 in epoch 18, gen_loss = 0.40331719177109854, disc_loss = 0.06444644514485297
Trained batch 133 in epoch 18, gen_loss = 0.4029411577911519, disc_loss = 0.06404796714977876
Trained batch 134 in epoch 18, gen_loss = 0.4034420702192518, disc_loss = 0.06385042777422953
Trained batch 135 in epoch 18, gen_loss = 0.40316881020279494, disc_loss = 0.06364445974160095
Trained batch 136 in epoch 18, gen_loss = 0.4036320352206265, disc_loss = 0.06331250634058004
Trained batch 137 in epoch 18, gen_loss = 0.4033932940683503, disc_loss = 0.06298500210033271
Trained batch 138 in epoch 18, gen_loss = 0.4038640408635997, disc_loss = 0.06269052882993714
Trained batch 139 in epoch 18, gen_loss = 0.4040761958275523, disc_loss = 0.06237774943334184
Trained batch 140 in epoch 18, gen_loss = 0.4040390980159137, disc_loss = 0.06206434210498177
Trained batch 141 in epoch 18, gen_loss = 0.40363465522376585, disc_loss = 0.06185463651634333
Trained batch 142 in epoch 18, gen_loss = 0.4038273233633775, disc_loss = 0.06158099760841969
Trained batch 143 in epoch 18, gen_loss = 0.40393466336859596, disc_loss = 0.06251988575159986
Trained batch 144 in epoch 18, gen_loss = 0.4043592500275579, disc_loss = 0.06292783992750378
Trained batch 145 in epoch 18, gen_loss = 0.40445722435435205, disc_loss = 0.06265392775443217
Trained batch 146 in epoch 18, gen_loss = 0.40411730789813866, disc_loss = 0.06250188315642022
Trained batch 147 in epoch 18, gen_loss = 0.40362252254743836, disc_loss = 0.06255249511387602
Trained batch 148 in epoch 18, gen_loss = 0.403904455820186, disc_loss = 0.06239228869082044
Trained batch 149 in epoch 18, gen_loss = 0.404013960758845, disc_loss = 0.062158495544766386
Trained batch 150 in epoch 18, gen_loss = 0.40391632657966864, disc_loss = 0.06190314564224801
Trained batch 151 in epoch 18, gen_loss = 0.40326606756762456, disc_loss = 0.062337021695719544
Trained batch 152 in epoch 18, gen_loss = 0.40349876919603034, disc_loss = 0.06339092962626441
Trained batch 153 in epoch 18, gen_loss = 0.4028734742821037, disc_loss = 0.06318920481550906
Trained batch 154 in epoch 18, gen_loss = 0.40269523512932565, disc_loss = 0.0628520546150544
Trained batch 155 in epoch 18, gen_loss = 0.40273335098456114, disc_loss = 0.06251717008686122
Trained batch 156 in epoch 18, gen_loss = 0.40277730450508703, disc_loss = 0.06222807941958308
Trained batch 157 in epoch 18, gen_loss = 0.40293807923039304, disc_loss = 0.06200990359935485
Trained batch 158 in epoch 18, gen_loss = 0.4026586838863181, disc_loss = 0.06183420171750323
Trained batch 159 in epoch 18, gen_loss = 0.402411793731153, disc_loss = 0.06162120252556633
Trained batch 160 in epoch 18, gen_loss = 0.4019820586494777, disc_loss = 0.061282638121997905
Trained batch 161 in epoch 18, gen_loss = 0.40162517811045234, disc_loss = 0.060980922539637966
Trained batch 162 in epoch 18, gen_loss = 0.40169041818636325, disc_loss = 0.061062372246745725
Trained batch 163 in epoch 18, gen_loss = 0.40237698485938517, disc_loss = 0.06105127874705032
Trained batch 164 in epoch 18, gen_loss = 0.40284759095220857, disc_loss = 0.06073854373429309
Trained batch 165 in epoch 18, gen_loss = 0.40240267224340553, disc_loss = 0.0605579378302153
Trained batch 166 in epoch 18, gen_loss = 0.4025179624200581, disc_loss = 0.060538228732271646
Trained batch 167 in epoch 18, gen_loss = 0.4022718531390031, disc_loss = 0.0611282357962669
Trained batch 168 in epoch 18, gen_loss = 0.402159741291633, disc_loss = 0.06108223990476608
Trained batch 169 in epoch 18, gen_loss = 0.4029759035390966, disc_loss = 0.06091246043660623
Trained batch 170 in epoch 18, gen_loss = 0.4031276941648004, disc_loss = 0.06060881668440344
Trained batch 171 in epoch 18, gen_loss = 0.4031090984164282, disc_loss = 0.06050663248386754
Trained batch 172 in epoch 18, gen_loss = 0.40363601315228237, disc_loss = 0.06022246748564302
Trained batch 173 in epoch 18, gen_loss = 0.4034223659285184, disc_loss = 0.059974693824355114
Trained batch 174 in epoch 18, gen_loss = 0.40353089605058945, disc_loss = 0.05968582420742938
Trained batch 175 in epoch 18, gen_loss = 0.4032950022003867, disc_loss = 0.059499755493809724
Trained batch 176 in epoch 18, gen_loss = 0.4031771966966532, disc_loss = 0.05923303421639369
Trained batch 177 in epoch 18, gen_loss = 0.40288657937826733, disc_loss = 0.058972162840720474
Trained batch 178 in epoch 18, gen_loss = 0.4024797163529103, disc_loss = 0.05896041903114103
Trained batch 179 in epoch 18, gen_loss = 0.4025046726067861, disc_loss = 0.05872495840562301
Trained batch 180 in epoch 18, gen_loss = 0.4024819519309049, disc_loss = 0.058666771614810875
Trained batch 181 in epoch 18, gen_loss = 0.4025103258235114, disc_loss = 0.058560812659049916
Trained batch 182 in epoch 18, gen_loss = 0.40268047504086313, disc_loss = 0.05838904625232347
Trained batch 183 in epoch 18, gen_loss = 0.40271323805917864, disc_loss = 0.058105045028597764
Trained batch 184 in epoch 18, gen_loss = 0.4024483630786071, disc_loss = 0.05783603014172734
Trained batch 185 in epoch 18, gen_loss = 0.4029665965867299, disc_loss = 0.05756369678764253
Trained batch 186 in epoch 18, gen_loss = 0.4026717749190203, disc_loss = 0.057307945579330236
Trained batch 187 in epoch 18, gen_loss = 0.40272359248805556, disc_loss = 0.057059395805674984
Trained batch 188 in epoch 18, gen_loss = 0.4024658712445113, disc_loss = 0.05680969554103083
Trained batch 189 in epoch 18, gen_loss = 0.4027024328708649, disc_loss = 0.056627871238283424
Trained batch 190 in epoch 18, gen_loss = 0.4023462563597095, disc_loss = 0.05661645803249475
Trained batch 191 in epoch 18, gen_loss = 0.40221255241582793, disc_loss = 0.057176342374683976
Trained batch 192 in epoch 18, gen_loss = 0.40272923640018915, disc_loss = 0.05742103327065706
Trained batch 193 in epoch 18, gen_loss = 0.40279892394223166, disc_loss = 0.05719893587004278
Trained batch 194 in epoch 18, gen_loss = 0.4023758533673409, disc_loss = 0.05698109772056341
Trained batch 195 in epoch 18, gen_loss = 0.40259233603672107, disc_loss = 0.056735844223056824
Trained batch 196 in epoch 18, gen_loss = 0.40283040074527565, disc_loss = 0.05658163521249736
Trained batch 197 in epoch 18, gen_loss = 0.4029779485379807, disc_loss = 0.05638346150799683
Trained batch 198 in epoch 18, gen_loss = 0.40277358979436023, disc_loss = 0.05623352064765129
Trained batch 199 in epoch 18, gen_loss = 0.40265367478132247, disc_loss = 0.05608592779841274
Trained batch 200 in epoch 18, gen_loss = 0.4025562920084047, disc_loss = 0.05600994331901198
Trained batch 201 in epoch 18, gen_loss = 0.40237508832228064, disc_loss = 0.056117360097457575
Trained batch 202 in epoch 18, gen_loss = 0.40233713579295305, disc_loss = 0.05602312190320544
Trained batch 203 in epoch 18, gen_loss = 0.40226445946038936, disc_loss = 0.05604093802599784
Trained batch 204 in epoch 18, gen_loss = 0.40259759571494125, disc_loss = 0.056049408813620485
Trained batch 205 in epoch 18, gen_loss = 0.40305554128966287, disc_loss = 0.05601774123090419
Trained batch 206 in epoch 18, gen_loss = 0.40299299301732566, disc_loss = 0.056467943536882524
Trained batch 207 in epoch 18, gen_loss = 0.40314809820399833, disc_loss = 0.05626180308620231
Trained batch 208 in epoch 18, gen_loss = 0.40318144636861447, disc_loss = 0.056211587371367014
Trained batch 209 in epoch 18, gen_loss = 0.4033724627324513, disc_loss = 0.05598096938892489
Trained batch 210 in epoch 18, gen_loss = 0.4030864550886561, disc_loss = 0.055762473387882046
Trained batch 211 in epoch 18, gen_loss = 0.4028570861467775, disc_loss = 0.05557536031558828
Trained batch 212 in epoch 18, gen_loss = 0.40282464251271993, disc_loss = 0.05534734853058004
Trained batch 213 in epoch 18, gen_loss = 0.4031730926482477, disc_loss = 0.05515616810793562
Trained batch 214 in epoch 18, gen_loss = 0.4034716360790785, disc_loss = 0.05495214492385817
Trained batch 215 in epoch 18, gen_loss = 0.40336841096480686, disc_loss = 0.054736762602934266
Trained batch 216 in epoch 18, gen_loss = 0.403402757534783, disc_loss = 0.05451574456161274
Trained batch 217 in epoch 18, gen_loss = 0.4033821879997166, disc_loss = 0.05430295785948839
Trained batch 218 in epoch 18, gen_loss = 0.40300313822210654, disc_loss = 0.054143382102404145
Trained batch 219 in epoch 18, gen_loss = 0.40275644836100666, disc_loss = 0.05397697242865847
Trained batch 220 in epoch 18, gen_loss = 0.40313791729745824, disc_loss = 0.05377606199042897
Trained batch 221 in epoch 18, gen_loss = 0.4034832983135103, disc_loss = 0.0537182939687727
Trained batch 222 in epoch 18, gen_loss = 0.40358011230759555, disc_loss = 0.054981228074835686
Trained batch 223 in epoch 18, gen_loss = 0.40330701002052854, disc_loss = 0.05678663654959694
Trained batch 224 in epoch 18, gen_loss = 0.40344223711225724, disc_loss = 0.056894672771708836
Trained batch 225 in epoch 18, gen_loss = 0.40373659489956576, disc_loss = 0.05691312177032562
Trained batch 226 in epoch 18, gen_loss = 0.4036065638065338, disc_loss = 0.056846709595788025
Trained batch 227 in epoch 18, gen_loss = 0.4036276131345515, disc_loss = 0.056729889256275146
Trained batch 228 in epoch 18, gen_loss = 0.40422391448999595, disc_loss = 0.0566473297030547
Trained batch 229 in epoch 18, gen_loss = 0.40400792995224827, disc_loss = 0.05662846992237736
Trained batch 230 in epoch 18, gen_loss = 0.4039158775950923, disc_loss = 0.056826240179487765
Trained batch 231 in epoch 18, gen_loss = 0.4039508981694435, disc_loss = 0.05707317696089439
Trained batch 232 in epoch 18, gen_loss = 0.4039593660012847, disc_loss = 0.056953147639292635
Trained batch 233 in epoch 18, gen_loss = 0.403783217836649, disc_loss = 0.056855961976923115
Trained batch 234 in epoch 18, gen_loss = 0.4042004297388361, disc_loss = 0.056706427158589694
Trained batch 235 in epoch 18, gen_loss = 0.40409407865698055, disc_loss = 0.05664484415369077
Trained batch 236 in epoch 18, gen_loss = 0.4041346863603793, disc_loss = 0.0564956974006309
Trained batch 237 in epoch 18, gen_loss = 0.40441942765933125, disc_loss = 0.05645784689700466
Trained batch 238 in epoch 18, gen_loss = 0.40456230121676395, disc_loss = 0.057153021419911826
Trained batch 239 in epoch 18, gen_loss = 0.4044566753009955, disc_loss = 0.05742291576267841
Trained batch 240 in epoch 18, gen_loss = 0.4046671294077798, disc_loss = 0.05724738374221065
Trained batch 241 in epoch 18, gen_loss = 0.40487442048620587, disc_loss = 0.05706183990071074
Trained batch 242 in epoch 18, gen_loss = 0.4049115062005235, disc_loss = 0.056853406600761436
Trained batch 243 in epoch 18, gen_loss = 0.4048740599976211, disc_loss = 0.05668827560234082
Trained batch 244 in epoch 18, gen_loss = 0.4046816019379363, disc_loss = 0.05665161787741342
Trained batch 245 in epoch 18, gen_loss = 0.4050392856200536, disc_loss = 0.056455788571705544
Trained batch 246 in epoch 18, gen_loss = 0.4049243209091758, disc_loss = 0.05640256544952149
Trained batch 247 in epoch 18, gen_loss = 0.4047821053574162, disc_loss = 0.05626123733330338
Trained batch 248 in epoch 18, gen_loss = 0.40477867298815623, disc_loss = 0.05608462079065332
Trained batch 249 in epoch 18, gen_loss = 0.40464876425266266, disc_loss = 0.05590142281912267
Trained batch 250 in epoch 18, gen_loss = 0.40431654013960483, disc_loss = 0.05591510722146507
Trained batch 251 in epoch 18, gen_loss = 0.4038392688546862, disc_loss = 0.05603638456003474
Trained batch 252 in epoch 18, gen_loss = 0.40392995281181787, disc_loss = 0.05591842039440401
Trained batch 253 in epoch 18, gen_loss = 0.4037886796973822, disc_loss = 0.055911469110104396
Trained batch 254 in epoch 18, gen_loss = 0.40370867743211636, disc_loss = 0.055885875595770046
Trained batch 255 in epoch 18, gen_loss = 0.4039181157713756, disc_loss = 0.055896836614920176
Trained batch 256 in epoch 18, gen_loss = 0.40410512477043536, disc_loss = 0.05574421568480157
Trained batch 257 in epoch 18, gen_loss = 0.40354645182920057, disc_loss = 0.05590806743888141
Trained batch 258 in epoch 18, gen_loss = 0.4036596088335781, disc_loss = 0.0567574667147429
Trained batch 259 in epoch 18, gen_loss = 0.40375175842872035, disc_loss = 0.056604894356300624
Trained batch 260 in epoch 18, gen_loss = 0.40332838013711103, disc_loss = 0.056595046378286745
Trained batch 261 in epoch 18, gen_loss = 0.4034698710186791, disc_loss = 0.056759148045222606
Trained batch 262 in epoch 18, gen_loss = 0.40339312852562154, disc_loss = 0.057211880396853265
Trained batch 263 in epoch 18, gen_loss = 0.4031652362283432, disc_loss = 0.0570814987753913
Trained batch 264 in epoch 18, gen_loss = 0.40317981861672314, disc_loss = 0.056952934858020186
Trained batch 265 in epoch 18, gen_loss = 0.4029419779553449, disc_loss = 0.05682656152657044
Trained batch 266 in epoch 18, gen_loss = 0.40300198853685615, disc_loss = 0.05671415294342664
Trained batch 267 in epoch 18, gen_loss = 0.40303181723427417, disc_loss = 0.05665086678736635
Trained batch 268 in epoch 18, gen_loss = 0.4032859275996907, disc_loss = 0.05650000885426721
Trained batch 269 in epoch 18, gen_loss = 0.40308898621135286, disc_loss = 0.056361706477279463
Trained batch 270 in epoch 18, gen_loss = 0.40291612515590286, disc_loss = 0.05627415287119381
Trained batch 271 in epoch 18, gen_loss = 0.40261378555613403, disc_loss = 0.05659299786716206
Trained batch 272 in epoch 18, gen_loss = 0.40282124695760424, disc_loss = 0.05725026768444604
Trained batch 273 in epoch 18, gen_loss = 0.4028499725743802, disc_loss = 0.05709045564069202
Trained batch 274 in epoch 18, gen_loss = 0.4025898429480466, disc_loss = 0.05717101255770434
Trained batch 275 in epoch 18, gen_loss = 0.4026740064871484, disc_loss = 0.05699343547947111
Trained batch 276 in epoch 18, gen_loss = 0.40281864667197, disc_loss = 0.05714161514341562
Trained batch 277 in epoch 18, gen_loss = 0.402739116185003, disc_loss = 0.057060914695356714
Trained batch 278 in epoch 18, gen_loss = 0.40247549634680524, disc_loss = 0.05709192336213151
Trained batch 279 in epoch 18, gen_loss = 0.40285735172884807, disc_loss = 0.05711172644015668
Trained batch 280 in epoch 18, gen_loss = 0.40263850833173326, disc_loss = 0.05693695814352072
Trained batch 281 in epoch 18, gen_loss = 0.4024768125080893, disc_loss = 0.05684524055418446
Trained batch 282 in epoch 18, gen_loss = 0.40234863968704276, disc_loss = 0.0567136019116182
Trained batch 283 in epoch 18, gen_loss = 0.4025761133558314, disc_loss = 0.05655369901878785
Trained batch 284 in epoch 18, gen_loss = 0.40269284196067273, disc_loss = 0.05643839480747518
Trained batch 285 in epoch 18, gen_loss = 0.40266113723074637, disc_loss = 0.05632511163097839
Trained batch 286 in epoch 18, gen_loss = 0.4026707078521675, disc_loss = 0.056924452468142796
Trained batch 287 in epoch 18, gen_loss = 0.4027928842438592, disc_loss = 0.05710150828074095
Trained batch 288 in epoch 18, gen_loss = 0.4029415693250082, disc_loss = 0.05697924549817059
Trained batch 289 in epoch 18, gen_loss = 0.40293338350180924, disc_loss = 0.056961863284031376
Trained batch 290 in epoch 18, gen_loss = 0.4028024259711459, disc_loss = 0.056853096940173826
Trained batch 291 in epoch 18, gen_loss = 0.4031155441109448, disc_loss = 0.05743591525202796
Trained batch 292 in epoch 18, gen_loss = 0.40277729852207694, disc_loss = 0.05783868611094132
Trained batch 293 in epoch 18, gen_loss = 0.4028318987614444, disc_loss = 0.05774964380306097
Trained batch 294 in epoch 18, gen_loss = 0.4033333116668766, disc_loss = 0.05761322413997377
Trained batch 295 in epoch 18, gen_loss = 0.4034498071146978, disc_loss = 0.05747000548856433
Trained batch 296 in epoch 18, gen_loss = 0.40349703395005426, disc_loss = 0.057322310589517304
Trained batch 297 in epoch 18, gen_loss = 0.4034856501841705, disc_loss = 0.057224523499545536
Trained batch 298 in epoch 18, gen_loss = 0.4035615026950836, disc_loss = 0.05712511143600412
Trained batch 299 in epoch 18, gen_loss = 0.40371057818333306, disc_loss = 0.05697612371761352
Trained batch 300 in epoch 18, gen_loss = 0.4033590173998544, disc_loss = 0.0568657687778563
Trained batch 301 in epoch 18, gen_loss = 0.4034085999064098, disc_loss = 0.05673919022175798
Trained batch 302 in epoch 18, gen_loss = 0.40320472689745057, disc_loss = 0.056737977296740995
Trained batch 303 in epoch 18, gen_loss = 0.40292918535047456, disc_loss = 0.057127039106011294
Trained batch 304 in epoch 18, gen_loss = 0.4032171949988506, disc_loss = 0.0578638246908906
Trained batch 305 in epoch 18, gen_loss = 0.4034198807929856, disc_loss = 0.05773499052137672
Trained batch 306 in epoch 18, gen_loss = 0.40346499306759537, disc_loss = 0.05776261974350589
Trained batch 307 in epoch 18, gen_loss = 0.40350568981526735, disc_loss = 0.05765919353927836
Trained batch 308 in epoch 18, gen_loss = 0.4036032032812297, disc_loss = 0.057556773760449445
Trained batch 309 in epoch 18, gen_loss = 0.40365466273600054, disc_loss = 0.057428625717218365
Trained batch 310 in epoch 18, gen_loss = 0.4035173560645419, disc_loss = 0.057550933138674
Trained batch 311 in epoch 18, gen_loss = 0.40338603942058027, disc_loss = 0.05784477019915357
Trained batch 312 in epoch 18, gen_loss = 0.40335784781093414, disc_loss = 0.05771097236613448
Trained batch 313 in epoch 18, gen_loss = 0.40321281875015064, disc_loss = 0.05769617801419442
Trained batch 314 in epoch 18, gen_loss = 0.40325924262167917, disc_loss = 0.057813955445788684
Trained batch 315 in epoch 18, gen_loss = 0.4027739911799944, disc_loss = 0.058380177649787236
Trained batch 316 in epoch 18, gen_loss = 0.40293955628992256, disc_loss = 0.05831906557147764
Trained batch 317 in epoch 18, gen_loss = 0.40291964037800737, disc_loss = 0.05846441725017093
Trained batch 318 in epoch 18, gen_loss = 0.4027137796987187, disc_loss = 0.05837875050361207
Trained batch 319 in epoch 18, gen_loss = 0.40246752272360026, disc_loss = 0.05829550687194569
Trained batch 320 in epoch 18, gen_loss = 0.402280993318632, disc_loss = 0.05817647736571799
Trained batch 321 in epoch 18, gen_loss = 0.4023415954864543, disc_loss = 0.05815378840150809
Trained batch 322 in epoch 18, gen_loss = 0.4023192958104721, disc_loss = 0.05818013103978691
Trained batch 323 in epoch 18, gen_loss = 0.40240834271650255, disc_loss = 0.05809017203972434
Trained batch 324 in epoch 18, gen_loss = 0.40247556736836065, disc_loss = 0.05804576347510402
Trained batch 325 in epoch 18, gen_loss = 0.40241681062187884, disc_loss = 0.05799527799830618
Trained batch 326 in epoch 18, gen_loss = 0.4023751285189153, disc_loss = 0.0579442893359981
Trained batch 327 in epoch 18, gen_loss = 0.40243683968920535, disc_loss = 0.05807603961396281
Trained batch 328 in epoch 18, gen_loss = 0.40237796419840816, disc_loss = 0.05838277544061962
Trained batch 329 in epoch 18, gen_loss = 0.4025488332817049, disc_loss = 0.058304320184062376
Trained batch 330 in epoch 18, gen_loss = 0.40276710067810967, disc_loss = 0.05850824479469495
Trained batch 331 in epoch 18, gen_loss = 0.40281299335590326, disc_loss = 0.0584178458413962
Trained batch 332 in epoch 18, gen_loss = 0.4026957331924467, disc_loss = 0.058401367248122664
Trained batch 333 in epoch 18, gen_loss = 0.4025608072291591, disc_loss = 0.058326583655417236
Trained batch 334 in epoch 18, gen_loss = 0.4024932184770926, disc_loss = 0.05821801572899098
Trained batch 335 in epoch 18, gen_loss = 0.4026878464168736, disc_loss = 0.0581066499206437
Trained batch 336 in epoch 18, gen_loss = 0.4028120424255773, disc_loss = 0.05797011255305979
Trained batch 337 in epoch 18, gen_loss = 0.4029942947114713, disc_loss = 0.057913498461147295
Trained batch 338 in epoch 18, gen_loss = 0.4029992363006316, disc_loss = 0.057793214174047945
Trained batch 339 in epoch 18, gen_loss = 0.4030478452496669, disc_loss = 0.05775355870205471
Trained batch 340 in epoch 18, gen_loss = 0.40307970266363136, disc_loss = 0.05778539969921768
Trained batch 341 in epoch 18, gen_loss = 0.4027085634961463, disc_loss = 0.05814006569936915
Trained batch 342 in epoch 18, gen_loss = 0.40282475127249345, disc_loss = 0.05874351746981024
Trained batch 343 in epoch 18, gen_loss = 0.4030838806701954, disc_loss = 0.05870063934708014
Trained batch 344 in epoch 18, gen_loss = 0.40305662902369016, disc_loss = 0.05859474160074108
Trained batch 345 in epoch 18, gen_loss = 0.4028855956272583, disc_loss = 0.058703077605769385
Trained batch 346 in epoch 18, gen_loss = 0.4032201914261672, disc_loss = 0.058563207787453525
Trained batch 347 in epoch 18, gen_loss = 0.40320547751482877, disc_loss = 0.05843255507904265
Trained batch 348 in epoch 18, gen_loss = 0.4032652580037841, disc_loss = 0.05829479428339098
Trained batch 349 in epoch 18, gen_loss = 0.40312225976160593, disc_loss = 0.05820854569519205
Trained batch 350 in epoch 18, gen_loss = 0.40296798974190684, disc_loss = 0.058165301660346426
Trained batch 351 in epoch 18, gen_loss = 0.4032563781789081, disc_loss = 0.05809051987307612
Trained batch 352 in epoch 18, gen_loss = 0.4031151550434129, disc_loss = 0.05809050458997868
Trained batch 353 in epoch 18, gen_loss = 0.40308594859420915, disc_loss = 0.05812322209841746
Trained batch 354 in epoch 18, gen_loss = 0.40309650087860266, disc_loss = 0.05798301151494535
Trained batch 355 in epoch 18, gen_loss = 0.4032037010772175, disc_loss = 0.05786005789911102
Trained batch 356 in epoch 18, gen_loss = 0.403247113112642, disc_loss = 0.05776384157579945
Trained batch 357 in epoch 18, gen_loss = 0.40324586359315745, disc_loss = 0.057705986182148145
Trained batch 358 in epoch 18, gen_loss = 0.40294499853029225, disc_loss = 0.05766852582807453
Trained batch 359 in epoch 18, gen_loss = 0.403213681653142, disc_loss = 0.05763524635048169
Trained batch 360 in epoch 18, gen_loss = 0.40302033697634193, disc_loss = 0.05751577312632405
Trained batch 361 in epoch 18, gen_loss = 0.4029755218170624, disc_loss = 0.057435361270983164
Trained batch 362 in epoch 18, gen_loss = 0.4027976857975495, disc_loss = 0.05732321772421646
Trained batch 363 in epoch 18, gen_loss = 0.40287691178721385, disc_loss = 0.05721379640885721
Trained batch 364 in epoch 18, gen_loss = 0.40290281703210856, disc_loss = 0.0571251489770637
Trained batch 365 in epoch 18, gen_loss = 0.4029125475574061, disc_loss = 0.05720510018628111
Trained batch 366 in epoch 18, gen_loss = 0.4027729760804683, disc_loss = 0.05754313366589129
Trained batch 367 in epoch 18, gen_loss = 0.4029650911283882, disc_loss = 0.05780807046761291
Trained batch 368 in epoch 18, gen_loss = 0.40334316591421765, disc_loss = 0.05770781990973567
Trained batch 369 in epoch 18, gen_loss = 0.40324974120468704, disc_loss = 0.05785476369405719
Trained batch 370 in epoch 18, gen_loss = 0.40328323073946243, disc_loss = 0.05776359653351402
Trained batch 371 in epoch 18, gen_loss = 0.40346369399659093, disc_loss = 0.0577291554899045
Trained batch 372 in epoch 18, gen_loss = 0.40359462621863984, disc_loss = 0.05759921227144851
Trained batch 373 in epoch 18, gen_loss = 0.40350081134129334, disc_loss = 0.057514579176036196
Trained batch 374 in epoch 18, gen_loss = 0.40318647531668345, disc_loss = 0.05738972559198737
Trained batch 375 in epoch 18, gen_loss = 0.4033462916045113, disc_loss = 0.057258080045861054
Trained batch 376 in epoch 18, gen_loss = 0.40339362206288293, disc_loss = 0.057131611402405906
Trained batch 377 in epoch 18, gen_loss = 0.40324756719921, disc_loss = 0.05703676852555305
Trained batch 378 in epoch 18, gen_loss = 0.4031153831994628, disc_loss = 0.056998237474799394
Trained batch 379 in epoch 18, gen_loss = 0.40290418106474374, disc_loss = 0.056886594182517576
Trained batch 380 in epoch 18, gen_loss = 0.40287479957726996, disc_loss = 0.056817689562201734
Trained batch 381 in epoch 18, gen_loss = 0.40283206702058855, disc_loss = 0.056965409255103835
Trained batch 382 in epoch 18, gen_loss = 0.4024328007788322, disc_loss = 0.057602496150219645
Trained batch 383 in epoch 18, gen_loss = 0.40259678588093567, disc_loss = 0.05754872906133338
Trained batch 384 in epoch 18, gen_loss = 0.4025713316418908, disc_loss = 0.05757784332426918
Trained batch 385 in epoch 18, gen_loss = 0.40274607729880924, disc_loss = 0.057567811169338276
Trained batch 386 in epoch 18, gen_loss = 0.4026132269500146, disc_loss = 0.057904091010288906
Trained batch 387 in epoch 18, gen_loss = 0.402458558799987, disc_loss = 0.05833909351297069
Trained batch 388 in epoch 18, gen_loss = 0.4027218278928404, disc_loss = 0.05833341540280337
Trained batch 389 in epoch 18, gen_loss = 0.4026830339661011, disc_loss = 0.058307823862355106
Trained batch 390 in epoch 18, gen_loss = 0.40266945458891445, disc_loss = 0.05845056502672527
Trained batch 391 in epoch 18, gen_loss = 0.4027421382845056, disc_loss = 0.05902005581788681
Trained batch 392 in epoch 18, gen_loss = 0.40259702329265556, disc_loss = 0.05901040804972896
Trained batch 393 in epoch 18, gen_loss = 0.4024969422953383, disc_loss = 0.05903979913605765
Trained batch 394 in epoch 18, gen_loss = 0.4024703931582125, disc_loss = 0.05899910033574399
Trained batch 395 in epoch 18, gen_loss = 0.4027474220428202, disc_loss = 0.05893212609402271
Trained batch 396 in epoch 18, gen_loss = 0.4027250409501626, disc_loss = 0.05892325051818559
Trained batch 397 in epoch 18, gen_loss = 0.402507478155982, disc_loss = 0.05886559177016905
Trained batch 398 in epoch 18, gen_loss = 0.4024355597887422, disc_loss = 0.059022310980009776
Trained batch 399 in epoch 18, gen_loss = 0.40273122530430555, disc_loss = 0.059311760327545926
Trained batch 400 in epoch 18, gen_loss = 0.40271900549642464, disc_loss = 0.05938801986799387
Trained batch 401 in epoch 18, gen_loss = 0.40271434955187696, disc_loss = 0.05937481901274799
Trained batch 402 in epoch 18, gen_loss = 0.40275989450680705, disc_loss = 0.05927339194703006
Trained batch 403 in epoch 18, gen_loss = 0.4026522922265057, disc_loss = 0.05925313483273592
Trained batch 404 in epoch 18, gen_loss = 0.40276114488089526, disc_loss = 0.05925576076440421
Trained batch 405 in epoch 18, gen_loss = 0.4027711134312188, disc_loss = 0.05946724021720145
Trained batch 406 in epoch 18, gen_loss = 0.40259529789337656, disc_loss = 0.05975485441483173
Trained batch 407 in epoch 18, gen_loss = 0.40287578620893116, disc_loss = 0.059877757388212736
Trained batch 408 in epoch 18, gen_loss = 0.4029947112344005, disc_loss = 0.05975230686562386
Trained batch 409 in epoch 18, gen_loss = 0.40275012098434493, disc_loss = 0.05976270037339773
Trained batch 410 in epoch 18, gen_loss = 0.4027728495299091, disc_loss = 0.05970229553693221
Trained batch 411 in epoch 18, gen_loss = 0.4027693606189732, disc_loss = 0.05964316640080866
Trained batch 412 in epoch 18, gen_loss = 0.4025881430066527, disc_loss = 0.05961331565352495
Trained batch 413 in epoch 18, gen_loss = 0.402744642454357, disc_loss = 0.05980600509230173
Trained batch 414 in epoch 18, gen_loss = 0.40259771135198064, disc_loss = 0.06014234049200832
Trained batch 415 in epoch 18, gen_loss = 0.4027514590595204, disc_loss = 0.06016729566908907
Trained batch 416 in epoch 18, gen_loss = 0.40283347651969903, disc_loss = 0.06006121116732772
Trained batch 417 in epoch 18, gen_loss = 0.4026891826228662, disc_loss = 0.060174594560869786
Trained batch 418 in epoch 18, gen_loss = 0.40270764208209825, disc_loss = 0.06008107428436739
Trained batch 419 in epoch 18, gen_loss = 0.40260814985349064, disc_loss = 0.06001327736635825
Trained batch 420 in epoch 18, gen_loss = 0.40236049957768083, disc_loss = 0.05996885209846489
Trained batch 421 in epoch 18, gen_loss = 0.40242606122488095, disc_loss = 0.05994583598240963
Trained batch 422 in epoch 18, gen_loss = 0.4024835692863938, disc_loss = 0.05999397133184205
Trained batch 423 in epoch 18, gen_loss = 0.4022697193091208, disc_loss = 0.05989873630130874
Trained batch 424 in epoch 18, gen_loss = 0.40223285938010495, disc_loss = 0.05982673546737608
Trained batch 425 in epoch 18, gen_loss = 0.4022689606871963, disc_loss = 0.059713926722684725
Trained batch 426 in epoch 18, gen_loss = 0.4024998027421272, disc_loss = 0.05961962566063227
Trained batch 427 in epoch 18, gen_loss = 0.40232710836228924, disc_loss = 0.059590880995155006
Trained batch 428 in epoch 18, gen_loss = 0.40254848031869855, disc_loss = 0.059702356014887006
Trained batch 429 in epoch 18, gen_loss = 0.40234758607869925, disc_loss = 0.05960934749631168
Trained batch 430 in epoch 18, gen_loss = 0.4021444397086057, disc_loss = 0.05958272625741888
Trained batch 431 in epoch 18, gen_loss = 0.4020542498608982, disc_loss = 0.0595088827831205
Trained batch 432 in epoch 18, gen_loss = 0.40208949726806226, disc_loss = 0.05958571017549887
Trained batch 433 in epoch 18, gen_loss = 0.4020058355092453, disc_loss = 0.059598672629681666
Trained batch 434 in epoch 18, gen_loss = 0.4019914771976142, disc_loss = 0.059503562976445615
Trained batch 435 in epoch 18, gen_loss = 0.4021024022832376, disc_loss = 0.05943978318641253
Trained batch 436 in epoch 18, gen_loss = 0.4023959759102806, disc_loss = 0.05932382984061297
Trained batch 437 in epoch 18, gen_loss = 0.4026235360737261, disc_loss = 0.059249116950902285
Trained batch 438 in epoch 18, gen_loss = 0.4026657444401591, disc_loss = 0.05915176905458263
Trained batch 439 in epoch 18, gen_loss = 0.4025094420733777, disc_loss = 0.05914318915985694
Trained batch 440 in epoch 18, gen_loss = 0.40228955643652786, disc_loss = 0.059353912689526674
Trained batch 441 in epoch 18, gen_loss = 0.40238739304008525, disc_loss = 0.05943800907316554
Trained batch 442 in epoch 18, gen_loss = 0.4024718354369932, disc_loss = 0.05932132044226839
Trained batch 443 in epoch 18, gen_loss = 0.40251227417910423, disc_loss = 0.05922606743993825
Trained batch 444 in epoch 18, gen_loss = 0.40240253434422313, disc_loss = 0.059143138548170916
Trained batch 445 in epoch 18, gen_loss = 0.40239997826215934, disc_loss = 0.05904559382329373
Trained batch 446 in epoch 18, gen_loss = 0.40233158801892727, disc_loss = 0.05897117046205956
Trained batch 447 in epoch 18, gen_loss = 0.4025095099516745, disc_loss = 0.05891493826909157
Trained batch 448 in epoch 18, gen_loss = 0.4025941561816264, disc_loss = 0.05884799445960629
Trained batch 449 in epoch 18, gen_loss = 0.40258424629767736, disc_loss = 0.05874992058819367
Trained batch 450 in epoch 18, gen_loss = 0.40256967093225593, disc_loss = 0.05869223125704343
Trained batch 451 in epoch 18, gen_loss = 0.4027247810324209, disc_loss = 0.05860608511509588
Trained batch 452 in epoch 18, gen_loss = 0.4027986807078452, disc_loss = 0.05856697463120023
Trained batch 453 in epoch 18, gen_loss = 0.4027650649392657, disc_loss = 0.05855841563280163
Trained batch 454 in epoch 18, gen_loss = 0.4027967758558609, disc_loss = 0.05853247274388815
Trained batch 455 in epoch 18, gen_loss = 0.4030093033389564, disc_loss = 0.05900330258545613
Trained batch 456 in epoch 18, gen_loss = 0.40302541600927483, disc_loss = 0.05903649226104111
Trained batch 457 in epoch 18, gen_loss = 0.4028889304230307, disc_loss = 0.05893471217144883
Trained batch 458 in epoch 18, gen_loss = 0.4025829227596586, disc_loss = 0.05884142559983469
Testing Epoch 18
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 14:01:23,856
------------------------------------------------------------
Training Epoch 19
Trained batch 0 in epoch 19, gen_loss = 0.4030086100101471, disc_loss = 0.00855845957994461
Trained batch 1 in epoch 19, gen_loss = 0.41222429275512695, disc_loss = 0.015406718477606773
Trained batch 2 in epoch 19, gen_loss = 0.4337661564350128, disc_loss = 0.019775961215297382
Trained batch 3 in epoch 19, gen_loss = 0.43485695123672485, disc_loss = 0.025966438930481672
Trained batch 4 in epoch 19, gen_loss = 0.4467559218406677, disc_loss = 0.08561506532132626
Trained batch 5 in epoch 19, gen_loss = 0.4331427713235219, disc_loss = 0.07650289436181386
Trained batch 6 in epoch 19, gen_loss = 0.41778272816113066, disc_loss = 0.08275230654648372
Trained batch 7 in epoch 19, gen_loss = 0.4076370410621166, disc_loss = 0.0761233156081289
Trained batch 8 in epoch 19, gen_loss = 0.41356992059283787, disc_loss = 0.06981197144422266
Trained batch 9 in epoch 19, gen_loss = 0.4154390633106232, disc_loss = 0.06392283011227846
Trained batch 10 in epoch 19, gen_loss = 0.41153190352699975, disc_loss = 0.06159496832300316
Trained batch 11 in epoch 19, gen_loss = 0.4085271432995796, disc_loss = 0.06048972144102057
Trained batch 12 in epoch 19, gen_loss = 0.4061107864746681, disc_loss = 0.057032227086333126
Trained batch 13 in epoch 19, gen_loss = 0.40361818245479036, disc_loss = 0.05412412980305297
Trained batch 14 in epoch 19, gen_loss = 0.39888052344322206, disc_loss = 0.05165421391526858
Trained batch 15 in epoch 19, gen_loss = 0.39703291468322277, disc_loss = 0.050902801332995296
Trained batch 16 in epoch 19, gen_loss = 0.3937842021970188, disc_loss = 0.04913913009359556
Trained batch 17 in epoch 19, gen_loss = 0.3927248368660609, disc_loss = 0.04733456754022174
Trained batch 18 in epoch 19, gen_loss = 0.3983865333230872, disc_loss = 0.04655741586496955
Trained batch 19 in epoch 19, gen_loss = 0.4024724647402763, disc_loss = 0.046066290326416494
Trained batch 20 in epoch 19, gen_loss = 0.4052048282963889, disc_loss = 0.044875932236512504
Trained batch 21 in epoch 19, gen_loss = 0.40779339183460583, disc_loss = 0.04314359914596108
Trained batch 22 in epoch 19, gen_loss = 0.4063488841056824, disc_loss = 0.04187449316858598
Trained batch 23 in epoch 19, gen_loss = 0.40387820079922676, disc_loss = 0.04229233155880744
Trained batch 24 in epoch 19, gen_loss = 0.4044054698944092, disc_loss = 0.04260981684550643
Trained batch 25 in epoch 19, gen_loss = 0.40658133305036104, disc_loss = 0.041574738471983716
Trained batch 26 in epoch 19, gen_loss = 0.40880076200873766, disc_loss = 0.040320618733487745
Trained batch 27 in epoch 19, gen_loss = 0.4112743767244475, disc_loss = 0.03963614105513053
Trained batch 28 in epoch 19, gen_loss = 0.4134368300437927, disc_loss = 0.039730684735394754
Trained batch 29 in epoch 19, gen_loss = 0.41504957775274914, disc_loss = 0.04132279129698872
Trained batch 30 in epoch 19, gen_loss = 0.4133967507270075, disc_loss = 0.041608674121239496
Trained batch 31 in epoch 19, gen_loss = 0.4129537809640169, disc_loss = 0.040777893183985725
Trained batch 32 in epoch 19, gen_loss = 0.41302478313446045, disc_loss = 0.039850072229676174
Trained batch 33 in epoch 19, gen_loss = 0.41256464404218335, disc_loss = 0.03987521023544319
Trained batch 34 in epoch 19, gen_loss = 0.41312769736562455, disc_loss = 0.04013914873025247
Trained batch 35 in epoch 19, gen_loss = 0.41400379521979225, disc_loss = 0.03996096471221083
Trained batch 36 in epoch 19, gen_loss = 0.4158868958821168, disc_loss = 0.03925713665179304
Trained batch 37 in epoch 19, gen_loss = 0.4137496414937471, disc_loss = 0.03902943040195264
Trained batch 38 in epoch 19, gen_loss = 0.41546636208509785, disc_loss = 0.04213257057544512
Trained batch 39 in epoch 19, gen_loss = 0.41462250277400015, disc_loss = 0.04250994306057691
Trained batch 40 in epoch 19, gen_loss = 0.41390831877545614, disc_loss = 0.04215827457061628
Trained batch 41 in epoch 19, gen_loss = 0.41559513977595736, disc_loss = 0.04391693448026975
Trained batch 42 in epoch 19, gen_loss = 0.4147425682045693, disc_loss = 0.046580603476180586
Trained batch 43 in epoch 19, gen_loss = 0.41432552987878973, disc_loss = 0.04625640580938621
Trained batch 44 in epoch 19, gen_loss = 0.4145750860373179, disc_loss = 0.045897446986701756
Trained batch 45 in epoch 19, gen_loss = 0.4144344705602397, disc_loss = 0.04573177683936513
Trained batch 46 in epoch 19, gen_loss = 0.41427945646833864, disc_loss = 0.046107557622042106
Trained batch 47 in epoch 19, gen_loss = 0.41214677691459656, disc_loss = 0.04747586394660175
Trained batch 48 in epoch 19, gen_loss = 0.4124587123491326, disc_loss = 0.04810827004970336
Trained batch 49 in epoch 19, gen_loss = 0.41093116462230683, disc_loss = 0.04801053687930107
Trained batch 50 in epoch 19, gen_loss = 0.4104539395547381, disc_loss = 0.047580481525145324
Trained batch 51 in epoch 19, gen_loss = 0.4084838709005943, disc_loss = 0.04737419169396162
Trained batch 52 in epoch 19, gen_loss = 0.4084231341784855, disc_loss = 0.04680987018740402
Trained batch 53 in epoch 19, gen_loss = 0.4093211050386782, disc_loss = 0.04636925245048823
Trained batch 54 in epoch 19, gen_loss = 0.4086037874221802, disc_loss = 0.04598613635382869
Trained batch 55 in epoch 19, gen_loss = 0.40843688962715013, disc_loss = 0.04670795169658959
Trained batch 56 in epoch 19, gen_loss = 0.4081843165974868, disc_loss = 0.046915074156826005
Trained batch 57 in epoch 19, gen_loss = 0.40700044765554627, disc_loss = 0.04624161744040662
Trained batch 58 in epoch 19, gen_loss = 0.4064874356075869, disc_loss = 0.04567060586443897
Trained batch 59 in epoch 19, gen_loss = 0.4071292981505394, disc_loss = 0.04525287382615109
Trained batch 60 in epoch 19, gen_loss = 0.4080882155504383, disc_loss = 0.044648408492813346
Trained batch 61 in epoch 19, gen_loss = 0.4067742786099834, disc_loss = 0.044189840855617675
Trained batch 62 in epoch 19, gen_loss = 0.40672973366010756, disc_loss = 0.04424601633633886
Trained batch 63 in epoch 19, gen_loss = 0.4071020232513547, disc_loss = 0.04417012067278847
Trained batch 64 in epoch 19, gen_loss = 0.40745961299309363, disc_loss = 0.04364535705401347
Trained batch 65 in epoch 19, gen_loss = 0.4082466702569615, disc_loss = 0.043263485937407524
Trained batch 66 in epoch 19, gen_loss = 0.40867214460871115, disc_loss = 0.042746092734941794
Trained batch 67 in epoch 19, gen_loss = 0.4071660751805586, disc_loss = 0.043134696233798474
Trained batch 68 in epoch 19, gen_loss = 0.4078798510026241, disc_loss = 0.04430487158073895
Trained batch 69 in epoch 19, gen_loss = 0.4069829421383994, disc_loss = 0.04392636844090053
Trained batch 70 in epoch 19, gen_loss = 0.40636353677427267, disc_loss = 0.04343135909400356
Trained batch 71 in epoch 19, gen_loss = 0.4060605044166247, disc_loss = 0.043390316190198064
Trained batch 72 in epoch 19, gen_loss = 0.406695107891135, disc_loss = 0.04299822315726787
Trained batch 73 in epoch 19, gen_loss = 0.4060745392296765, disc_loss = 0.04303255066829356
Trained batch 74 in epoch 19, gen_loss = 0.4058164389928182, disc_loss = 0.04280021412918965
Trained batch 75 in epoch 19, gen_loss = 0.4065453100361322, disc_loss = 0.042390250024924934
Trained batch 76 in epoch 19, gen_loss = 0.40871644136193513, disc_loss = 0.04195275319764366
Trained batch 77 in epoch 19, gen_loss = 0.40913030084891194, disc_loss = 0.04156114559811659
Trained batch 78 in epoch 19, gen_loss = 0.40959700413897066, disc_loss = 0.041160581892804256
Trained batch 79 in epoch 19, gen_loss = 0.409800649061799, disc_loss = 0.04131122869439423
Trained batch 80 in epoch 19, gen_loss = 0.4100973197707423, disc_loss = 0.041628344973296295
Trained batch 81 in epoch 19, gen_loss = 0.4093133265652308, disc_loss = 0.04174403023974198
Trained batch 82 in epoch 19, gen_loss = 0.409458930233875, disc_loss = 0.04171999009797372
Trained batch 83 in epoch 19, gen_loss = 0.40882922850904013, disc_loss = 0.04200912173837423
Trained batch 84 in epoch 19, gen_loss = 0.4090725937310387, disc_loss = 0.04192355419783031
Trained batch 85 in epoch 19, gen_loss = 0.40871798195118125, disc_loss = 0.04215266711490099
Trained batch 86 in epoch 19, gen_loss = 0.408932158316689, disc_loss = 0.042111467141872166
Trained batch 87 in epoch 19, gen_loss = 0.4096560806713321, disc_loss = 0.04211479802192612
Trained batch 88 in epoch 19, gen_loss = 0.4085729152299045, disc_loss = 0.0448677446483896
Trained batch 89 in epoch 19, gen_loss = 0.409336323539416, disc_loss = 0.04553081604341666
Trained batch 90 in epoch 19, gen_loss = 0.4095140332049066, disc_loss = 0.04529617966285774
Trained batch 91 in epoch 19, gen_loss = 0.40949998569229373, disc_loss = 0.04495066747514774
Trained batch 92 in epoch 19, gen_loss = 0.4089860188704665, disc_loss = 0.04460985150428549
Trained batch 93 in epoch 19, gen_loss = 0.40954619994822966, disc_loss = 0.04423183447463398
Trained batch 94 in epoch 19, gen_loss = 0.4100497471658807, disc_loss = 0.043967592471132154
Trained batch 95 in epoch 19, gen_loss = 0.4095434279491504, disc_loss = 0.044282523362198845
Trained batch 96 in epoch 19, gen_loss = 0.4096892740308624, disc_loss = 0.04477443760164927
Trained batch 97 in epoch 19, gen_loss = 0.40909608651180657, disc_loss = 0.04534677628009599
Trained batch 98 in epoch 19, gen_loss = 0.4090967115127679, disc_loss = 0.04574541009097087
Trained batch 99 in epoch 19, gen_loss = 0.40830897480249406, disc_loss = 0.04548728979192674
Trained batch 100 in epoch 19, gen_loss = 0.40853271124386553, disc_loss = 0.045595232941357804
Trained batch 101 in epoch 19, gen_loss = 0.4086586757033479, disc_loss = 0.0455754001844017
Trained batch 102 in epoch 19, gen_loss = 0.40896612376842684, disc_loss = 0.045249132123025296
Trained batch 103 in epoch 19, gen_loss = 0.4084323753531163, disc_loss = 0.04519792777808526
Trained batch 104 in epoch 19, gen_loss = 0.40854253825687226, disc_loss = 0.04496439887831608
Trained batch 105 in epoch 19, gen_loss = 0.40870545916962175, disc_loss = 0.04490692545396258
Trained batch 106 in epoch 19, gen_loss = 0.4080627006348048, disc_loss = 0.04466516753467165
Trained batch 107 in epoch 19, gen_loss = 0.4080505903672289, disc_loss = 0.04444577419888918
Trained batch 108 in epoch 19, gen_loss = 0.40866707579805217, disc_loss = 0.04419574062040913
Trained batch 109 in epoch 19, gen_loss = 0.40864554047584534, disc_loss = 0.0439644931984896
Trained batch 110 in epoch 19, gen_loss = 0.40900991655684804, disc_loss = 0.04365650014867922
Trained batch 111 in epoch 19, gen_loss = 0.40929166839591097, disc_loss = 0.04333073827936979
Trained batch 112 in epoch 19, gen_loss = 0.40943020740441516, disc_loss = 0.043316884304240216
Trained batch 113 in epoch 19, gen_loss = 0.4090128242969513, disc_loss = 0.04314352198618285
Trained batch 114 in epoch 19, gen_loss = 0.40920533537864684, disc_loss = 0.04295752156201912
Trained batch 115 in epoch 19, gen_loss = 0.409617827370249, disc_loss = 0.0427598453142905
Trained batch 116 in epoch 19, gen_loss = 0.40916669139495265, disc_loss = 0.044267276883061625
Trained batch 117 in epoch 19, gen_loss = 0.40990531469805763, disc_loss = 0.045256382793630076
Trained batch 118 in epoch 19, gen_loss = 0.4098260202327696, disc_loss = 0.045170331256417166
Trained batch 119 in epoch 19, gen_loss = 0.40896681398153306, disc_loss = 0.04510631445640077
Trained batch 120 in epoch 19, gen_loss = 0.40873445139443576, disc_loss = 0.04492143032810658
Trained batch 121 in epoch 19, gen_loss = 0.4087928223316787, disc_loss = 0.04473650840981329
Trained batch 122 in epoch 19, gen_loss = 0.4092347895711418, disc_loss = 0.04442484537139535
Trained batch 123 in epoch 19, gen_loss = 0.40919963318494057, disc_loss = 0.044128260530170896
Trained batch 124 in epoch 19, gen_loss = 0.40924583792686464, disc_loss = 0.04385962068289519
Trained batch 125 in epoch 19, gen_loss = 0.40872443053457475, disc_loss = 0.04360851787385486
Trained batch 126 in epoch 19, gen_loss = 0.4080697795537513, disc_loss = 0.04336918416748366
Trained batch 127 in epoch 19, gen_loss = 0.40826984611339867, disc_loss = 0.043099973976495676
Trained batch 128 in epoch 19, gen_loss = 0.40805509871290635, disc_loss = 0.0428811874269515
Trained batch 129 in epoch 19, gen_loss = 0.407335197696319, disc_loss = 0.04289635402651933
Trained batch 130 in epoch 19, gen_loss = 0.4074770669445737, disc_loss = 0.04262897816579078
Trained batch 131 in epoch 19, gen_loss = 0.4077186155499834, disc_loss = 0.042731122826367166
Trained batch 132 in epoch 19, gen_loss = 0.40727954184202325, disc_loss = 0.042755673961587866
Trained batch 133 in epoch 19, gen_loss = 0.4069057004665261, disc_loss = 0.04272153471082227
Trained batch 134 in epoch 19, gen_loss = 0.4073215206464132, disc_loss = 0.04270884287716062
Trained batch 135 in epoch 19, gen_loss = 0.40741370004766125, disc_loss = 0.04250310609281501
Trained batch 136 in epoch 19, gen_loss = 0.4072146485321713, disc_loss = 0.04230244580765058
Trained batch 137 in epoch 19, gen_loss = 0.407179758168649, disc_loss = 0.042171792106945875
Trained batch 138 in epoch 19, gen_loss = 0.40663393066941406, disc_loss = 0.042587834128962575
Trained batch 139 in epoch 19, gen_loss = 0.40583945236035757, disc_loss = 0.04442689721472561
Trained batch 140 in epoch 19, gen_loss = 0.40581531643022034, disc_loss = 0.04471574670219041
Trained batch 141 in epoch 19, gen_loss = 0.40608999091134945, disc_loss = 0.044911760882749945
Trained batch 142 in epoch 19, gen_loss = 0.40543030671306424, disc_loss = 0.045049305139044364
Trained batch 143 in epoch 19, gen_loss = 0.4055116472558843, disc_loss = 0.045314955622113
Trained batch 144 in epoch 19, gen_loss = 0.4058896872504004, disc_loss = 0.04581610837244782
Trained batch 145 in epoch 19, gen_loss = 0.4060170113632124, disc_loss = 0.04647285909047478
Trained batch 146 in epoch 19, gen_loss = 0.40622004724684213, disc_loss = 0.04737529543158757
Trained batch 147 in epoch 19, gen_loss = 0.4056063864279438, disc_loss = 0.04734976012637285
Trained batch 148 in epoch 19, gen_loss = 0.4058062354190238, disc_loss = 0.04725714539796514
Trained batch 149 in epoch 19, gen_loss = 0.40501583317915596, disc_loss = 0.04715117818986376
Trained batch 150 in epoch 19, gen_loss = 0.40538711559693547, disc_loss = 0.047369165302852526
Trained batch 151 in epoch 19, gen_loss = 0.4054233251433623, disc_loss = 0.047167618532272935
Trained batch 152 in epoch 19, gen_loss = 0.4051828559707193, disc_loss = 0.0477897100381894
Trained batch 153 in epoch 19, gen_loss = 0.40558586027715116, disc_loss = 0.0483220227534411
Trained batch 154 in epoch 19, gen_loss = 0.4056919607423967, disc_loss = 0.048094481752524454
Trained batch 155 in epoch 19, gen_loss = 0.40521098807072026, disc_loss = 0.047958432810190015
Trained batch 156 in epoch 19, gen_loss = 0.4053545975761049, disc_loss = 0.04780339638874599
Trained batch 157 in epoch 19, gen_loss = 0.40570566718336903, disc_loss = 0.04761846294579438
Trained batch 158 in epoch 19, gen_loss = 0.40575042966776675, disc_loss = 0.04737879137901015
Trained batch 159 in epoch 19, gen_loss = 0.4059007244184613, disc_loss = 0.0473567828652449
Trained batch 160 in epoch 19, gen_loss = 0.4050937148725024, disc_loss = 0.04783612634315624
Trained batch 161 in epoch 19, gen_loss = 0.4051683061284783, disc_loss = 0.048513940236542694
Trained batch 162 in epoch 19, gen_loss = 0.40521864474185404, disc_loss = 0.04871043897708135
Trained batch 163 in epoch 19, gen_loss = 0.40508251691736824, disc_loss = 0.04854249624853454
Trained batch 164 in epoch 19, gen_loss = 0.4052120992631623, disc_loss = 0.04846359331047896
Trained batch 165 in epoch 19, gen_loss = 0.40483292219150496, disc_loss = 0.048371991277279626
Trained batch 166 in epoch 19, gen_loss = 0.4049033592204134, disc_loss = 0.04813099598991657
Trained batch 167 in epoch 19, gen_loss = 0.4044049128535248, disc_loss = 0.047980405612006075
Trained batch 168 in epoch 19, gen_loss = 0.4038408347488155, disc_loss = 0.04808441293839167
Trained batch 169 in epoch 19, gen_loss = 0.40408648515448853, disc_loss = 0.048263136078329646
Trained batch 170 in epoch 19, gen_loss = 0.4042498769118772, disc_loss = 0.04824246224342731
Trained batch 171 in epoch 19, gen_loss = 0.4041145625849103, disc_loss = 0.04800984560143809
Trained batch 172 in epoch 19, gen_loss = 0.4040594621200782, disc_loss = 0.047800226600011646
Trained batch 173 in epoch 19, gen_loss = 0.40484128909549494, disc_loss = 0.0476017312318001
Trained batch 174 in epoch 19, gen_loss = 0.40525851913860866, disc_loss = 0.04748522266213383
Trained batch 175 in epoch 19, gen_loss = 0.4050722648812966, disc_loss = 0.04751163777704774
Trained batch 176 in epoch 19, gen_loss = 0.4051914388513834, disc_loss = 0.047498773083638
Trained batch 177 in epoch 19, gen_loss = 0.4048892596129621, disc_loss = 0.04731367111959484
Trained batch 178 in epoch 19, gen_loss = 0.40485514492295976, disc_loss = 0.04721715924584999
Trained batch 179 in epoch 19, gen_loss = 0.4044969321952926, disc_loss = 0.04717131930713852
Trained batch 180 in epoch 19, gen_loss = 0.4041455635049725, disc_loss = 0.047034023092925877
Trained batch 181 in epoch 19, gen_loss = 0.40424721450596063, disc_loss = 0.04685264884156513
Trained batch 182 in epoch 19, gen_loss = 0.4042627010189119, disc_loss = 0.046925868564209
Trained batch 183 in epoch 19, gen_loss = 0.4037719995755216, disc_loss = 0.047260325310913766
Trained batch 184 in epoch 19, gen_loss = 0.40425983909014107, disc_loss = 0.0474971113877522
Trained batch 185 in epoch 19, gen_loss = 0.4042570682302598, disc_loss = 0.04740874532369837
Trained batch 186 in epoch 19, gen_loss = 0.40406656552126063, disc_loss = 0.047302886694271296
Trained batch 187 in epoch 19, gen_loss = 0.40399638040268676, disc_loss = 0.04718868067844751
Trained batch 188 in epoch 19, gen_loss = 0.4037983661921567, disc_loss = 0.04709911296173694
Trained batch 189 in epoch 19, gen_loss = 0.4040567711779946, disc_loss = 0.04699231612643129
Trained batch 190 in epoch 19, gen_loss = 0.40452071447022925, disc_loss = 0.04699459969412282
Trained batch 191 in epoch 19, gen_loss = 0.4044454769852261, disc_loss = 0.046927576758510746
Trained batch 192 in epoch 19, gen_loss = 0.4044760922693836, disc_loss = 0.047083486691889366
Trained batch 193 in epoch 19, gen_loss = 0.404811138191174, disc_loss = 0.046879685733505747
Trained batch 194 in epoch 19, gen_loss = 0.4052080635841076, disc_loss = 0.04670019563383017
Trained batch 195 in epoch 19, gen_loss = 0.404959826445093, disc_loss = 0.046573733530786574
Trained batch 196 in epoch 19, gen_loss = 0.40485446086994886, disc_loss = 0.04660593154769258
Trained batch 197 in epoch 19, gen_loss = 0.4051845589972506, disc_loss = 0.046400699717453635
Trained batch 198 in epoch 19, gen_loss = 0.4055465006049554, disc_loss = 0.04637631868484931
Trained batch 199 in epoch 19, gen_loss = 0.4054339921474457, disc_loss = 0.046214063251391053
Trained batch 200 in epoch 19, gen_loss = 0.4058612863815839, disc_loss = 0.0461137251307567
Trained batch 201 in epoch 19, gen_loss = 0.40617277495341725, disc_loss = 0.04592375899895583
Trained batch 202 in epoch 19, gen_loss = 0.40590067038982375, disc_loss = 0.04577512360118293
Trained batch 203 in epoch 19, gen_loss = 0.40624630115195814, disc_loss = 0.045591840534197056
Trained batch 204 in epoch 19, gen_loss = 0.40603688882618416, disc_loss = 0.045430319206561987
Trained batch 205 in epoch 19, gen_loss = 0.4061226852021171, disc_loss = 0.04527218705404875
Trained batch 206 in epoch 19, gen_loss = 0.40655711638754694, disc_loss = 0.045198300200995904
Trained batch 207 in epoch 19, gen_loss = 0.4066045576563248, disc_loss = 0.045712143348422475
Trained batch 208 in epoch 19, gen_loss = 0.40666865546737563, disc_loss = 0.046178484741045814
Trained batch 209 in epoch 19, gen_loss = 0.40664140042804536, disc_loss = 0.04607377850140135
Trained batch 210 in epoch 19, gen_loss = 0.406347937069798, disc_loss = 0.04619999356585515
Trained batch 211 in epoch 19, gen_loss = 0.40695291574833525, disc_loss = 0.04759926214937191
Trained batch 212 in epoch 19, gen_loss = 0.40713332432536453, disc_loss = 0.047416111200768066
Trained batch 213 in epoch 19, gen_loss = 0.407198589956649, disc_loss = 0.047310769958334546
Trained batch 214 in epoch 19, gen_loss = 0.40728136675302373, disc_loss = 0.04715330567384182
Trained batch 215 in epoch 19, gen_loss = 0.4073228440075009, disc_loss = 0.04698859760968911
Trained batch 216 in epoch 19, gen_loss = 0.4070149903198541, disc_loss = 0.046864729430440656
Trained batch 217 in epoch 19, gen_loss = 0.40697909235407453, disc_loss = 0.046679621261177126
Trained batch 218 in epoch 19, gen_loss = 0.4069923731290042, disc_loss = 0.04656215543437698
Trained batch 219 in epoch 19, gen_loss = 0.4069267533042214, disc_loss = 0.04639962458856065
Trained batch 220 in epoch 19, gen_loss = 0.4068159887154178, disc_loss = 0.04633635590358624
Trained batch 221 in epoch 19, gen_loss = 0.4065533151497712, disc_loss = 0.046211470147124956
Trained batch 222 in epoch 19, gen_loss = 0.40638715095584166, disc_loss = 0.04614084316083468
Trained batch 223 in epoch 19, gen_loss = 0.40646897509161917, disc_loss = 0.04604691952408757
Trained batch 224 in epoch 19, gen_loss = 0.4062683277659946, disc_loss = 0.04591500700554914
Trained batch 225 in epoch 19, gen_loss = 0.4062144864449459, disc_loss = 0.045764810296467846
Trained batch 226 in epoch 19, gen_loss = 0.406267374228801, disc_loss = 0.04575307314214399
Trained batch 227 in epoch 19, gen_loss = 0.40562614916186585, disc_loss = 0.04602450728538985
Trained batch 228 in epoch 19, gen_loss = 0.40567839926507276, disc_loss = 0.04637147637295606
Trained batch 229 in epoch 19, gen_loss = 0.40530344714289124, disc_loss = 0.04653452503413934
Trained batch 230 in epoch 19, gen_loss = 0.4052939747835135, disc_loss = 0.04646632487954193
Trained batch 231 in epoch 19, gen_loss = 0.40519710887095023, disc_loss = 0.046408415175894085
Trained batch 232 in epoch 19, gen_loss = 0.40487048451992574, disc_loss = 0.046410247105945206
Trained batch 233 in epoch 19, gen_loss = 0.4045732737096966, disc_loss = 0.04628954234564852
Trained batch 234 in epoch 19, gen_loss = 0.4045434925150364, disc_loss = 0.0464385895870943
Trained batch 235 in epoch 19, gen_loss = 0.4045420238527201, disc_loss = 0.046636299930623404
Trained batch 236 in epoch 19, gen_loss = 0.40447302005462005, disc_loss = 0.04648270089973063
Trained batch 237 in epoch 19, gen_loss = 0.40487802078743945, disc_loss = 0.04633149930604679
Trained batch 238 in epoch 19, gen_loss = 0.4050446569171411, disc_loss = 0.04624874143428695
Trained batch 239 in epoch 19, gen_loss = 0.40503055676817895, disc_loss = 0.046138293096252406
Trained batch 240 in epoch 19, gen_loss = 0.4049248788119352, disc_loss = 0.046323902211325915
Trained batch 241 in epoch 19, gen_loss = 0.404655532772876, disc_loss = 0.04712328101000325
Trained batch 242 in epoch 19, gen_loss = 0.40487904215055237, disc_loss = 0.047431856165774194
Trained batch 243 in epoch 19, gen_loss = 0.40501273496717705, disc_loss = 0.04732751499166804
Trained batch 244 in epoch 19, gen_loss = 0.4050140113246684, disc_loss = 0.04724443077622932
Trained batch 245 in epoch 19, gen_loss = 0.4047975188832942, disc_loss = 0.04722052032877577
Trained batch 246 in epoch 19, gen_loss = 0.40450744759216, disc_loss = 0.047062381628810275
Trained batch 247 in epoch 19, gen_loss = 0.40445456737952845, disc_loss = 0.04700331689767359
Trained batch 248 in epoch 19, gen_loss = 0.4046812586516262, disc_loss = 0.04685265315232806
Trained batch 249 in epoch 19, gen_loss = 0.40454211390018463, disc_loss = 0.04731563459523022
Trained batch 250 in epoch 19, gen_loss = 0.40512940168855677, disc_loss = 0.047811540520835326
Trained batch 251 in epoch 19, gen_loss = 0.40510675736836027, disc_loss = 0.04766157078593674
Trained batch 252 in epoch 19, gen_loss = 0.4049139080547061, disc_loss = 0.04755995449657909
Trained batch 253 in epoch 19, gen_loss = 0.4050956177195226, disc_loss = 0.04739719250158766
Trained batch 254 in epoch 19, gen_loss = 0.4050440562706368, disc_loss = 0.047308163994959754
Trained batch 255 in epoch 19, gen_loss = 0.404976952704601, disc_loss = 0.047296677897975314
Trained batch 256 in epoch 19, gen_loss = 0.40486401667390814, disc_loss = 0.047306806610078196
Trained batch 257 in epoch 19, gen_loss = 0.40480575046336004, disc_loss = 0.04716234107667855
Trained batch 258 in epoch 19, gen_loss = 0.40479976019343816, disc_loss = 0.047032381476237506
Trained batch 259 in epoch 19, gen_loss = 0.4052523203767263, disc_loss = 0.04689190129104715
Trained batch 260 in epoch 19, gen_loss = 0.4053240546321504, disc_loss = 0.046754041451147234
Trained batch 261 in epoch 19, gen_loss = 0.40512638738137163, disc_loss = 0.046630856140253654
Trained batch 262 in epoch 19, gen_loss = 0.40488854809858954, disc_loss = 0.04652339058570536
Trained batch 263 in epoch 19, gen_loss = 0.40492900777043717, disc_loss = 0.04639525370051464
Trained batch 264 in epoch 19, gen_loss = 0.40526095066430434, disc_loss = 0.04662734497830553
Trained batch 265 in epoch 19, gen_loss = 0.4050865577799933, disc_loss = 0.047401186358883865
Trained batch 266 in epoch 19, gen_loss = 0.4049740183665958, disc_loss = 0.047583936891529
Trained batch 267 in epoch 19, gen_loss = 0.40537547865020696, disc_loss = 0.047831865166550254
Trained batch 268 in epoch 19, gen_loss = 0.4052420436892811, disc_loss = 0.04803781596369017
Trained batch 269 in epoch 19, gen_loss = 0.4050776055565587, disc_loss = 0.04822943577611888
Trained batch 270 in epoch 19, gen_loss = 0.405122793468602, disc_loss = 0.048098242061549445
Trained batch 271 in epoch 19, gen_loss = 0.40522900662001443, disc_loss = 0.04798343865310445
Trained batch 272 in epoch 19, gen_loss = 0.40518976262200884, disc_loss = 0.04787634351314642
Trained batch 273 in epoch 19, gen_loss = 0.4053327727274303, disc_loss = 0.04789156852847468
Trained batch 274 in epoch 19, gen_loss = 0.4051358400691639, disc_loss = 0.04850880308584733
Trained batch 275 in epoch 19, gen_loss = 0.4053795640019403, disc_loss = 0.04849387116838193
Trained batch 276 in epoch 19, gen_loss = 0.4053769748563801, disc_loss = 0.04858285602894931
Trained batch 277 in epoch 19, gen_loss = 0.40512503286917434, disc_loss = 0.04881614529722029
Trained batch 278 in epoch 19, gen_loss = 0.40514680582989926, disc_loss = 0.04871525911874668
Trained batch 279 in epoch 19, gen_loss = 0.405428713879415, disc_loss = 0.048888337425887586
Trained batch 280 in epoch 19, gen_loss = 0.4052897736271081, disc_loss = 0.049027225406992905
Trained batch 281 in epoch 19, gen_loss = 0.4051515873230941, disc_loss = 0.04897343591912418
Trained batch 282 in epoch 19, gen_loss = 0.40520166371399435, disc_loss = 0.04888200471605513
Trained batch 283 in epoch 19, gen_loss = 0.40531153882473286, disc_loss = 0.04877039501574677
Trained batch 284 in epoch 19, gen_loss = 0.40533673982871204, disc_loss = 0.04868461566797474
Trained batch 285 in epoch 19, gen_loss = 0.4050711477761502, disc_loss = 0.048728763692445685
Trained batch 286 in epoch 19, gen_loss = 0.4054294115367251, disc_loss = 0.04886496856237538
Trained batch 287 in epoch 19, gen_loss = 0.4054814958944917, disc_loss = 0.048888024628265865
Trained batch 288 in epoch 19, gen_loss = 0.4058645383090709, disc_loss = 0.0488310846722456
Trained batch 289 in epoch 19, gen_loss = 0.4058947901273596, disc_loss = 0.048756612387710604
Trained batch 290 in epoch 19, gen_loss = 0.40609338101242826, disc_loss = 0.04866042633339302
Trained batch 291 in epoch 19, gen_loss = 0.4059896375218483, disc_loss = 0.04868050036977415
Trained batch 292 in epoch 19, gen_loss = 0.40597767960089465, disc_loss = 0.048567170181880635
Trained batch 293 in epoch 19, gen_loss = 0.4058758288013692, disc_loss = 0.04857224812667792
Trained batch 294 in epoch 19, gen_loss = 0.4060303704213288, disc_loss = 0.048487146009328
Trained batch 295 in epoch 19, gen_loss = 0.40612360210837545, disc_loss = 0.04836279454301237
Trained batch 296 in epoch 19, gen_loss = 0.4061193676910015, disc_loss = 0.048271552565498185
Trained batch 297 in epoch 19, gen_loss = 0.4060751420739513, disc_loss = 0.04839588272629068
Trained batch 298 in epoch 19, gen_loss = 0.4059039863655001, disc_loss = 0.04855437866757845
Trained batch 299 in epoch 19, gen_loss = 0.4062775209546089, disc_loss = 0.04845597243246933
Trained batch 300 in epoch 19, gen_loss = 0.40610149978007193, disc_loss = 0.0486706825084613
Trained batch 301 in epoch 19, gen_loss = 0.4060937654695764, disc_loss = 0.04858477882707849
Trained batch 302 in epoch 19, gen_loss = 0.4063508401412775, disc_loss = 0.049057696030011075
Trained batch 303 in epoch 19, gen_loss = 0.4060935177105038, disc_loss = 0.04929780168765176
Trained batch 304 in epoch 19, gen_loss = 0.4060244363839509, disc_loss = 0.04915396745820515
Trained batch 305 in epoch 19, gen_loss = 0.40591708945682625, disc_loss = 0.04920275383963694
Trained batch 306 in epoch 19, gen_loss = 0.4060409731119386, disc_loss = 0.04910803247085418
Trained batch 307 in epoch 19, gen_loss = 0.40604023983726256, disc_loss = 0.04903495037783082
Trained batch 308 in epoch 19, gen_loss = 0.4058124117288003, disc_loss = 0.048964054857208894
Trained batch 309 in epoch 19, gen_loss = 0.40603921230762235, disc_loss = 0.0488877764632625
Trained batch 310 in epoch 19, gen_loss = 0.4056995333774297, disc_loss = 0.048949851867087016
Trained batch 311 in epoch 19, gen_loss = 0.40587164127291775, disc_loss = 0.04954741517893779
Trained batch 312 in epoch 19, gen_loss = 0.40599173088424123, disc_loss = 0.04948188259769171
Trained batch 313 in epoch 19, gen_loss = 0.4059238704336677, disc_loss = 0.0493914202852234
Trained batch 314 in epoch 19, gen_loss = 0.4059698648869045, disc_loss = 0.04928713711126456
Trained batch 315 in epoch 19, gen_loss = 0.4058740015459966, disc_loss = 0.04918806175288709
Trained batch 316 in epoch 19, gen_loss = 0.4058712233880341, disc_loss = 0.049072260301477905
Trained batch 317 in epoch 19, gen_loss = 0.40566821068337877, disc_loss = 0.04903705880842494
Trained batch 318 in epoch 19, gen_loss = 0.40565878685365275, disc_loss = 0.0493713193062144
Trained batch 319 in epoch 19, gen_loss = 0.40543514443561435, disc_loss = 0.049978500267025085
Trained batch 320 in epoch 19, gen_loss = 0.40531217634120836, disc_loss = 0.0498825907823267
Trained batch 321 in epoch 19, gen_loss = 0.4055310956994939, disc_loss = 0.050388717561127234
Trained batch 322 in epoch 19, gen_loss = 0.4055941020925717, disc_loss = 0.050303216256639534
Trained batch 323 in epoch 19, gen_loss = 0.4052029993431068, disc_loss = 0.05035035956627977
Trained batch 324 in epoch 19, gen_loss = 0.4050190913677216, disc_loss = 0.05024599545850204
Trained batch 325 in epoch 19, gen_loss = 0.4048939485308583, disc_loss = 0.05015129762833104
Trained batch 326 in epoch 19, gen_loss = 0.40487808289877864, disc_loss = 0.05006435078309581
Trained batch 327 in epoch 19, gen_loss = 0.40506624875635633, disc_loss = 0.04994614069668076
Trained batch 328 in epoch 19, gen_loss = 0.40485694768943326, disc_loss = 0.04998507028541847
Trained batch 329 in epoch 19, gen_loss = 0.4046280650478421, disc_loss = 0.050313466578496224
Trained batch 330 in epoch 19, gen_loss = 0.4048901509122186, disc_loss = 0.05053578874833454
Trained batch 331 in epoch 19, gen_loss = 0.4048435679939856, disc_loss = 0.05041764284405543
Trained batch 332 in epoch 19, gen_loss = 0.40505974375091874, disc_loss = 0.05033665232628853
Trained batch 333 in epoch 19, gen_loss = 0.40500281920690023, disc_loss = 0.05027781336005041
Trained batch 334 in epoch 19, gen_loss = 0.40524663498152547, disc_loss = 0.050374677160115386
Trained batch 335 in epoch 19, gen_loss = 0.4053201799591382, disc_loss = 0.05035078603707786
Trained batch 336 in epoch 19, gen_loss = 0.40528956878079153, disc_loss = 0.05022638233361948
Trained batch 337 in epoch 19, gen_loss = 0.4052074538356454, disc_loss = 0.050145597629712005
Trained batch 338 in epoch 19, gen_loss = 0.4052997609507018, disc_loss = 0.05009271107493161
Trained batch 339 in epoch 19, gen_loss = 0.40544251387610153, disc_loss = 0.049990909793140255
Trained batch 340 in epoch 19, gen_loss = 0.40535728122132264, disc_loss = 0.04990663586998265
Trained batch 341 in epoch 19, gen_loss = 0.40556073363064327, disc_loss = 0.04978988022265727
Trained batch 342 in epoch 19, gen_loss = 0.4054688024103815, disc_loss = 0.049736317073377855
Trained batch 343 in epoch 19, gen_loss = 0.4053916381022265, disc_loss = 0.049628738340986675
Trained batch 344 in epoch 19, gen_loss = 0.40542791693106944, disc_loss = 0.049528335491060345
Trained batch 345 in epoch 19, gen_loss = 0.4055985818708563, disc_loss = 0.04940745836080757
Trained batch 346 in epoch 19, gen_loss = 0.40572944377959635, disc_loss = 0.04930137936562643
Trained batch 347 in epoch 19, gen_loss = 0.4055887634555499, disc_loss = 0.049667490895131026
Trained batch 348 in epoch 19, gen_loss = 0.40569553291558536, disc_loss = 0.04961422883390441
Trained batch 349 in epoch 19, gen_loss = 0.40581145295075005, disc_loss = 0.04951059792989067
Trained batch 350 in epoch 19, gen_loss = 0.4061522004101691, disc_loss = 0.049405256235849994
Trained batch 351 in epoch 19, gen_loss = 0.40602540758184413, disc_loss = 0.04938560071009719
Trained batch 352 in epoch 19, gen_loss = 0.40611295136108616, disc_loss = 0.04967641014415802
Trained batch 353 in epoch 19, gen_loss = 0.4058439896605109, disc_loss = 0.049924893807198875
Trained batch 354 in epoch 19, gen_loss = 0.4059861543312879, disc_loss = 0.04981853479493252
Trained batch 355 in epoch 19, gen_loss = 0.4062101662661252, disc_loss = 0.05001087991384726
Trained batch 356 in epoch 19, gen_loss = 0.4062985849647629, disc_loss = 0.04996935422440954
Trained batch 357 in epoch 19, gen_loss = 0.40610024116558735, disc_loss = 0.04985065511870068
Trained batch 358 in epoch 19, gen_loss = 0.40590374566054277, disc_loss = 0.04975693393498659
Trained batch 359 in epoch 19, gen_loss = 0.40593639347288346, disc_loss = 0.04967841406921959
Trained batch 360 in epoch 19, gen_loss = 0.40584205078616364, disc_loss = 0.04964081918526637
Trained batch 361 in epoch 19, gen_loss = 0.4056846695380975, disc_loss = 0.0496114989902145
Trained batch 362 in epoch 19, gen_loss = 0.4056707472019616, disc_loss = 0.049509726844461165
Trained batch 363 in epoch 19, gen_loss = 0.40583268659455435, disc_loss = 0.04949295192260991
Trained batch 364 in epoch 19, gen_loss = 0.4056869346801549, disc_loss = 0.04953412000242978
Trained batch 365 in epoch 19, gen_loss = 0.4058585666079339, disc_loss = 0.04941475243419612
Trained batch 366 in epoch 19, gen_loss = 0.40590564017399783, disc_loss = 0.049330675402245096
Trained batch 367 in epoch 19, gen_loss = 0.40578555777345016, disc_loss = 0.049251348186415904
Trained batch 368 in epoch 19, gen_loss = 0.40561792004076125, disc_loss = 0.049335933173060176
Trained batch 369 in epoch 19, gen_loss = 0.405492616183049, disc_loss = 0.04927958586454593
Trained batch 370 in epoch 19, gen_loss = 0.4054973059587402, disc_loss = 0.04920799128153936
Trained batch 371 in epoch 19, gen_loss = 0.4055491193167625, disc_loss = 0.049118529741091516
Trained batch 372 in epoch 19, gen_loss = 0.4055401945721368, disc_loss = 0.049064136388644215
Trained batch 373 in epoch 19, gen_loss = 0.4056021025314688, disc_loss = 0.048979001947713485
Trained batch 374 in epoch 19, gen_loss = 0.40545935106277464, disc_loss = 0.048875676702708
Trained batch 375 in epoch 19, gen_loss = 0.4055091697484889, disc_loss = 0.04876239539342041
Trained batch 376 in epoch 19, gen_loss = 0.4057388911987173, disc_loss = 0.04865342320563069
Trained batch 377 in epoch 19, gen_loss = 0.40573008736920735, disc_loss = 0.04858187497125337
Trained batch 378 in epoch 19, gen_loss = 0.40553982072266553, disc_loss = 0.04872180458335181
Trained batch 379 in epoch 19, gen_loss = 0.4056840060572875, disc_loss = 0.048662402958756214
Trained batch 380 in epoch 19, gen_loss = 0.40558761350438977, disc_loss = 0.048709216028979915
Trained batch 381 in epoch 19, gen_loss = 0.4052384255444192, disc_loss = 0.048830233482614706
Trained batch 382 in epoch 19, gen_loss = 0.4053186623296912, disc_loss = 0.04872957018128652
Trained batch 383 in epoch 19, gen_loss = 0.4054713607765734, disc_loss = 0.04862736957390249
Trained batch 384 in epoch 19, gen_loss = 0.4055528838913162, disc_loss = 0.048552082587855976
Trained batch 385 in epoch 19, gen_loss = 0.40561092610186245, disc_loss = 0.04846475091207907
Trained batch 386 in epoch 19, gen_loss = 0.4057157818969214, disc_loss = 0.04838631964632784
Trained batch 387 in epoch 19, gen_loss = 0.40570642822182057, disc_loss = 0.0483314453974635
Trained batch 388 in epoch 19, gen_loss = 0.4057141951546264, disc_loss = 0.048229294683027696
Trained batch 389 in epoch 19, gen_loss = 0.405756636766287, disc_loss = 0.048127609104491195
Trained batch 390 in epoch 19, gen_loss = 0.40560140039609827, disc_loss = 0.04805573103163401
Trained batch 391 in epoch 19, gen_loss = 0.4056905804544079, disc_loss = 0.04805994401115696
Trained batch 392 in epoch 19, gen_loss = 0.4056722084984525, disc_loss = 0.048006030188224094
Trained batch 393 in epoch 19, gen_loss = 0.40552624833160245, disc_loss = 0.04793941384171925
Trained batch 394 in epoch 19, gen_loss = 0.4057974340040473, disc_loss = 0.047882646991859505
Trained batch 395 in epoch 19, gen_loss = 0.40564671482401665, disc_loss = 0.04792550086711693
Trained batch 396 in epoch 19, gen_loss = 0.4055430367401325, disc_loss = 0.04836991674240951
Trained batch 397 in epoch 19, gen_loss = 0.4057358120703817, disc_loss = 0.048515336082583696
Trained batch 398 in epoch 19, gen_loss = 0.40580303096830994, disc_loss = 0.04846353245838394
Trained batch 399 in epoch 19, gen_loss = 0.405825454890728, disc_loss = 0.0484095739480108
Trained batch 400 in epoch 19, gen_loss = 0.4056192482647456, disc_loss = 0.04837455357102087
Trained batch 401 in epoch 19, gen_loss = 0.40578324151276357, disc_loss = 0.04828538219282283
Trained batch 402 in epoch 19, gen_loss = 0.4057257633203312, disc_loss = 0.04822486722680091
Trained batch 403 in epoch 19, gen_loss = 0.40580933135334807, disc_loss = 0.04833738041562167
Trained batch 404 in epoch 19, gen_loss = 0.4059972079447758, disc_loss = 0.048443298138402126
Trained batch 405 in epoch 19, gen_loss = 0.405734009637034, disc_loss = 0.04848473394757568
Trained batch 406 in epoch 19, gen_loss = 0.40588234097717435, disc_loss = 0.04847968792135505
Trained batch 407 in epoch 19, gen_loss = 0.405919640745018, disc_loss = 0.04838836038777349
Trained batch 408 in epoch 19, gen_loss = 0.40598042101615217, disc_loss = 0.04833531040415933
Trained batch 409 in epoch 19, gen_loss = 0.40598497368940495, disc_loss = 0.04846332147263172
Trained batch 410 in epoch 19, gen_loss = 0.405988797291642, disc_loss = 0.04854076462197333
Trained batch 411 in epoch 19, gen_loss = 0.40580774793057767, disc_loss = 0.0485175453008885
Trained batch 412 in epoch 19, gen_loss = 0.40581938999617073, disc_loss = 0.04843822861717197
Trained batch 413 in epoch 19, gen_loss = 0.4059056089696101, disc_loss = 0.04841056965957373
Trained batch 414 in epoch 19, gen_loss = 0.4058153064136045, disc_loss = 0.04846923216189965
Trained batch 415 in epoch 19, gen_loss = 0.40595350027657473, disc_loss = 0.048456032505223096
Trained batch 416 in epoch 19, gen_loss = 0.4061886759684812, disc_loss = 0.04836342738588437
Trained batch 417 in epoch 19, gen_loss = 0.4061768065656772, disc_loss = 0.04830509747498842
Trained batch 418 in epoch 19, gen_loss = 0.4061560134330058, disc_loss = 0.04823477966110789
Trained batch 419 in epoch 19, gen_loss = 0.40614326284045266, disc_loss = 0.048146878167365986
Trained batch 420 in epoch 19, gen_loss = 0.406216715477991, disc_loss = 0.048061087597028804
Trained batch 421 in epoch 19, gen_loss = 0.4062529123648648, disc_loss = 0.0479720604244037
Trained batch 422 in epoch 19, gen_loss = 0.4061932913941413, disc_loss = 0.04801641713088074
Trained batch 423 in epoch 19, gen_loss = 0.40624252418583295, disc_loss = 0.04799724213190307
Trained batch 424 in epoch 19, gen_loss = 0.4063280076840345, disc_loss = 0.04796382182880359
Trained batch 425 in epoch 19, gen_loss = 0.4063891894380811, disc_loss = 0.047977835344404265
Trained batch 426 in epoch 19, gen_loss = 0.406670734251411, disc_loss = 0.048137158768325694
Trained batch 427 in epoch 19, gen_loss = 0.40683930513457717, disc_loss = 0.04807585531575866
Trained batch 428 in epoch 19, gen_loss = 0.40680414702230955, disc_loss = 0.04805960658816121
Trained batch 429 in epoch 19, gen_loss = 0.40681172879629357, disc_loss = 0.047980202015402706
Trained batch 430 in epoch 19, gen_loss = 0.406734085414913, disc_loss = 0.047940599289128506
Trained batch 431 in epoch 19, gen_loss = 0.40670061359802884, disc_loss = 0.047897219972650486
Trained batch 432 in epoch 19, gen_loss = 0.40675819429459253, disc_loss = 0.047854824232552676
Trained batch 433 in epoch 19, gen_loss = 0.4067527817278963, disc_loss = 0.04778650014184862
Trained batch 434 in epoch 19, gen_loss = 0.4069101739888904, disc_loss = 0.04772922233089633
Trained batch 435 in epoch 19, gen_loss = 0.40702752290515726, disc_loss = 0.04775059058271144
Trained batch 436 in epoch 19, gen_loss = 0.4072119375388191, disc_loss = 0.04788732137403172
Trained batch 437 in epoch 19, gen_loss = 0.407035305687826, disc_loss = 0.048548026078435925
Trained batch 438 in epoch 19, gen_loss = 0.40726796715840663, disc_loss = 0.04871359801000506
Trained batch 439 in epoch 19, gen_loss = 0.4074026269668883, disc_loss = 0.04869564091786742
Trained batch 440 in epoch 19, gen_loss = 0.407293150078953, disc_loss = 0.04862955389143118
Trained batch 441 in epoch 19, gen_loss = 0.4071390525652812, disc_loss = 0.04870912897067642
Trained batch 442 in epoch 19, gen_loss = 0.4072191803369242, disc_loss = 0.048641147188690934
Trained batch 443 in epoch 19, gen_loss = 0.40734232613095295, disc_loss = 0.04862641021273695
Trained batch 444 in epoch 19, gen_loss = 0.4073430087459221, disc_loss = 0.048537677415552434
Trained batch 445 in epoch 19, gen_loss = 0.4074339104206573, disc_loss = 0.04849372012958331
Trained batch 446 in epoch 19, gen_loss = 0.4072730639903604, disc_loss = 0.0484584315140342
Trained batch 447 in epoch 19, gen_loss = 0.40714477208842126, disc_loss = 0.04837610940739978
Trained batch 448 in epoch 19, gen_loss = 0.4071511812093263, disc_loss = 0.04834159392083607
Trained batch 449 in epoch 19, gen_loss = 0.407354322804345, disc_loss = 0.0482696730705599
Trained batch 450 in epoch 19, gen_loss = 0.4073043480152037, disc_loss = 0.04818280957465756
Trained batch 451 in epoch 19, gen_loss = 0.4071774934377291, disc_loss = 0.04809167247628216
Trained batch 452 in epoch 19, gen_loss = 0.40716040687055777, disc_loss = 0.048001323514114284
Trained batch 453 in epoch 19, gen_loss = 0.4071404889291604, disc_loss = 0.047930513752731066
Trained batch 454 in epoch 19, gen_loss = 0.4071092807984614, disc_loss = 0.04784258702299097
Trained batch 455 in epoch 19, gen_loss = 0.40698580522286265, disc_loss = 0.04786707661849888
Trained batch 456 in epoch 19, gen_loss = 0.40708217018281867, disc_loss = 0.047835905398333885
Trained batch 457 in epoch 19, gen_loss = 0.40713314809653434, disc_loss = 0.04778757645833961
Trained batch 458 in epoch 19, gen_loss = 0.4072353975575474, disc_loss = 0.04777173980388766
Testing Epoch 19
------------------------------------------------------------
WARNING    : Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
SOURCE     : matplotlib.image.set_data
TIME STAMP : 2022-08-31 14:04:00,603
------------------------------------------------------------